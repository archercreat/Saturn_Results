digraph F_180001010
{
"  %0 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 33, i32 0, i32 0, !remill_register !0"
"  %0 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 33, i32 0, i32 0, !remill_register !0" -> "  store i64 %20718, i64* %0, align 8, !alias.scope !84, !noalias !87"
"  %1 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 27, i32 0, i32 0, !remill_register !1"
"  %1 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 27, i32 0, i32 0, !remill_register !1" -> "  store i64 %20713, i64* %1, align 8, !tbaa !77, !alias.scope !84, !noalias !87""  %1 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 27, i32 0, i32 0, !remill_register !1" -> "  %26 = load i64, i64* %1, align 8, !alias.scope !17, !noalias !20"
"  %2 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 21, i32 0, i32 0, !remill_register !2"
"  %2 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 21, i32 0, i32 0, !remill_register !2" -> "  store i64 %20568, i64* %2, align 8, !tbaa !77, !alias.scope !79, !noalias !82"
"  %3 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 5, i32 0, i32 0, !remill_register !3"
"  %3 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 5, i32 0, i32 0, !remill_register !3" -> "  store i64 %20669, i64* %3, align 8, !tbaa !77, !alias.scope !84, !noalias !87""  %3 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 5, i32 0, i32 0, !remill_register !3" -> "  %61 = load i64, i64* %3, align 8, !alias.scope !17, !noalias !20"
"  %4 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 19, i32 0, i32 0, !remill_register !4"
"  %4 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 19, i32 0, i32 0, !remill_register !4" -> "  store i64 %20595, i64* %4, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  %5 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 25, i32 0, i32 0, !remill_register !5"
"  %5 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 25, i32 0, i32 0, !remill_register !5" -> "  store i64 %20712, i64* %5, align 8, !tbaa !77, !alias.scope !84, !noalias !87""  %5 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 25, i32 0, i32 0, !remill_register !5" -> "  %30 = load i64, i64* %5, align 8, !alias.scope !17, !noalias !20"
"  %6 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 17, i32 0, i32 0, !remill_register !6"
"  %6 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 17, i32 0, i32 0, !remill_register !6" -> "  store i64 %20578, i64* %6, align 8, !tbaa !77, !alias.scope !79, !noalias !82"
"  %7 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 9, i32 0, i32 0, !remill_register !7"
"  %7 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 9, i32 0, i32 0, !remill_register !7" -> "  store i64 %20711, i64* %7, align 8, !tbaa !77, !alias.scope !84, !noalias !87""  %7 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 9, i32 0, i32 0, !remill_register !7" -> "  %34 = load i64, i64* %7, align 8, !alias.scope !17, !noalias !20"
"  %8 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 29, i32 0, i32 0, !remill_register !8"
"  %8 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 29, i32 0, i32 0, !remill_register !8" -> "  store i64 %20714, i64* %8, align 8, !tbaa !77, !alias.scope !84, !noalias !87""  %8 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 29, i32 0, i32 0, !remill_register !8" -> "  %22 = load i64, i64* %8, align 8, !alias.scope !17, !noalias !20"
"  %9 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 7, i32 0, i32 0, !remill_register !9"
"  %9 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 7, i32 0, i32 0, !remill_register !9" -> "  store i64 %20666, i64* %9, align 8, !tbaa !77, !alias.scope !84, !noalias !87""  %9 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 7, i32 0, i32 0, !remill_register !9" -> "  %58 = load i64, i64* %9, align 8, !noalias !31"
"  %10 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 31, i32 0, i32 0, !remill_register !10"
"  %10 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 31, i32 0, i32 0, !remill_register !10" -> "  store i64 %20715, i64* %10, align 8, !tbaa !77, !alias.scope !84, !noalias !87""  %10 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 31, i32 0, i32 0, !remill_register !10" -> "  %17 = load i64, i64* %10, align 8, !alias.scope !17, !noalias !20"
"  %11 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 11, i32 0, i32 0, !remill_register !11"
"  %11 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 11, i32 0, i32 0, !remill_register !11" -> "  store i64 %20710, i64* %11, align 8, !tbaa !77, !alias.scope !84, !noalias !87""  %11 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 11, i32 0, i32 0, !remill_register !11" -> "  %38 = load i64, i64* %11, align 8, !alias.scope !17, !noalias !20"
"  %12 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 3, i32 0, i32 0, !remill_register !12"
"  %12 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 3, i32 0, i32 0, !remill_register !12" -> "  store i64 %20708, i64* %12, align 8, !tbaa !77, !alias.scope !84, !noalias !87""  %12 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 3, i32 0, i32 0, !remill_register !12" -> "  %46 = load i64, i64* %12, align 8, !alias.scope !17, !noalias !20"
"  %13 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 15, i32 0, i32 0, !remill_register !13"
"  %13 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 15, i32 0, i32 0, !remill_register !13" -> "  store i64 %20709, i64* %13, align 8, !tbaa !77, !alias.scope !84, !noalias !87""  %13 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 15, i32 0, i32 0, !remill_register !13" -> "  %42 = load i64, i64* %13, align 8, !alias.scope !17, !noalias !20"
"  %14 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 23, i32 0, i32 0, !remill_register !14"
"  %14 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 23, i32 0, i32 0, !remill_register !14" -> "  store i64 %20573, i64* %14, align 8, !tbaa !77, !alias.scope !79, !noalias !82"
"  %15 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 1, i32 0, i32 0, !remill_register !15"
"  %15 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 1, i32 0, i32 0, !remill_register !15" -> "  store i64 %58, i64* %15, align 8, !tbaa !77, !alias.scope !79, !noalias !82"
"  %16 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 13, i32 0, i32 0, !remill_register !16"
"  %16 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 13, i32 0, i32 0, !remill_register !16" -> "  store i64 %20719, i64* %16, align 8, !tbaa !77, !alias.scope !84, !noalias !87""  %16 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 6, i32 13, i32 0, i32 0, !remill_register !16" -> "  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20"
"  %17 = load i64, i64* %10, align 8, !alias.scope !17, !noalias !20"
"  %17 = load i64, i64* %10, align 8, !alias.scope !17, !noalias !20" -> "  store i64 %17, i64* %21, align 1, !noalias !20"
"  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20"
"  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %20719 = add i64 %18, 8""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %20716 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %18""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %7007 = add i64 %18, -76""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2995 = add i64 %18, -88""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2979 = add i64 %18, -84""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2973 = add i64 %18, -112""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2815 = add i64 %18, -140""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2788 = add i64 %18, -144""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2779 = add i64 %18, -124""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2396 = add i64 %18, -176""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2387 = add i64 %18, -228""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2207 = add i64 %18, -152""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2201 = add i64 %18, -208""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2052 = add i64 %18, -184""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2043 = add i64 %18, -160""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2016 = add i64 %18, -180""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %2007 = add i64 %18, -204""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %1875 = add i64 %18, -220""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %1857 = add i64 %18, -244""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %1818 = add i64 %18, -156""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %1807 = add i64 %18, -172""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %1739 = add i64 %18, -168""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %1726 = add i64 %18, -200""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %1692 = add i64 %18, -164""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %1351 = add i64 %18, -196""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %679 = add i64 %18, -216""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %660 = add i64 %18, -236""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %646 = add i64 %18, -100""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %635 = add i64 %18, -240""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %622 = add i64 %18, -212""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %612 = add i64 %18, -252""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %584 = add i64 %18, -148""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %573 = add i64 %18, -276""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %563 = add i64 %18, -264""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %558 = add i64 %18, -248""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %554 = add i64 %18, -80""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %538 = add i64 %18, -260""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %532 = add i64 %18, -272""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %389 = add i64 %18, -104""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %295 = add i64 %18, -288""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %286 = add i64 %18, -284""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %271 = add i64 %18, -268""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %265 = add i64 %18, -108""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %258 = add i64 %18, -120""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %252 = add i64 %18, -280""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %238 = add i64 %18, -128""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %226 = add i64 %18, -96""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %219 = add i64 %18, -292""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %170 = add i64 %18, -136""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %165 = add i64 %18, -224""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %160 = add i64 %18, -188""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %151 = add i64 %18, -256""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %125 = add i64 %18, -192""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %84 = add i64 %18, -232""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %71 = add i64 %18, -116""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %57 = add i64 %18, -72""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %50 = add i64 %18, -296""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %47 = add i64 %18, -64""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %43 = add i64 %18, -56""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %39 = add i64 %18, -48""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %35 = add i64 %18, -40""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %31 = add i64 %18, -32""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %27 = add i64 %18, -24""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %23 = add i64 %18, -16""  %18 = load i64, i64* %16, align 8, !tbaa !22, !alias.scope !17, !noalias !20" -> "  %19 = add i64 %18, -8"
"  %19 = add i64 %18, -8"
"  %19 = add i64 %18, -8" -> "  %20 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %19"
"  %20 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %19"
"  %20 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %19" -> "  %21 = bitcast i8* %20 to i64*"
"  %21 = bitcast i8* %20 to i64*"
"  %21 = bitcast i8* %20 to i64*" -> "  %20715 = load i64, i64* %21, align 1, !noalias !87""  %21 = bitcast i8* %20 to i64*" -> "  store i64 %17, i64* %21, align 1, !noalias !20"
"  store i64 %17, i64* %21, align 1, !noalias !20"

"  %22 = load i64, i64* %8, align 8, !alias.scope !17, !noalias !20"
"  %22 = load i64, i64* %8, align 8, !alias.scope !17, !noalias !20" -> "  store i64 %22, i64* %25, align 1, !noalias !20"
"  %23 = add i64 %18, -16"
"  %23 = add i64 %18, -16" -> "  %24 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %23"
"  %24 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %23"
"  %24 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %23" -> "  %25 = bitcast i8* %24 to i64*"
"  %25 = bitcast i8* %24 to i64*"
"  %25 = bitcast i8* %24 to i64*" -> "  %20714 = load i64, i64* %25, align 1, !noalias !87""  %25 = bitcast i8* %24 to i64*" -> "  store i64 %22, i64* %25, align 1, !noalias !20"
"  store i64 %22, i64* %25, align 1, !noalias !20"

"  %26 = load i64, i64* %1, align 8, !alias.scope !17, !noalias !20"
"  %26 = load i64, i64* %1, align 8, !alias.scope !17, !noalias !20" -> "  store i64 %26, i64* %29, align 1, !noalias !20"
"  %27 = add i64 %18, -24"
"  %27 = add i64 %18, -24" -> "  %28 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %27"
"  %28 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %27"
"  %28 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %27" -> "  %29 = bitcast i8* %28 to i64*"
"  %29 = bitcast i8* %28 to i64*"
"  %29 = bitcast i8* %28 to i64*" -> "  %20713 = load i64, i64* %29, align 1, !noalias !87""  %29 = bitcast i8* %28 to i64*" -> "  store i64 %26, i64* %29, align 1, !noalias !20"
"  store i64 %26, i64* %29, align 1, !noalias !20"

"  %30 = load i64, i64* %5, align 8, !alias.scope !17, !noalias !20"
"  %30 = load i64, i64* %5, align 8, !alias.scope !17, !noalias !20" -> "  store i64 %30, i64* %33, align 1, !noalias !20"
"  %31 = add i64 %18, -32"
"  %31 = add i64 %18, -32" -> "  %32 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %31"
"  %32 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %31"
"  %32 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %31" -> "  %33 = bitcast i8* %32 to i64*"
"  %33 = bitcast i8* %32 to i64*"
"  %33 = bitcast i8* %32 to i64*" -> "  %20712 = load i64, i64* %33, align 1, !noalias !87""  %33 = bitcast i8* %32 to i64*" -> "  store i64 %30, i64* %33, align 1, !noalias !20"
"  store i64 %30, i64* %33, align 1, !noalias !20"

"  %34 = load i64, i64* %7, align 8, !alias.scope !17, !noalias !20"
"  %34 = load i64, i64* %7, align 8, !alias.scope !17, !noalias !20" -> "  store i64 %34, i64* %37, align 1, !noalias !20"
"  %35 = add i64 %18, -40"
"  %35 = add i64 %18, -40" -> "  %36 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %35"
"  %36 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %35"
"  %36 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %35" -> "  %37 = bitcast i8* %36 to i64*"
"  %37 = bitcast i8* %36 to i64*"
"  %37 = bitcast i8* %36 to i64*" -> "  %20711 = load i64, i64* %37, align 1, !noalias !87""  %37 = bitcast i8* %36 to i64*" -> "  store i64 %34, i64* %37, align 1, !noalias !20"
"  store i64 %34, i64* %37, align 1, !noalias !20"

"  %38 = load i64, i64* %11, align 8, !alias.scope !17, !noalias !20"
"  %38 = load i64, i64* %11, align 8, !alias.scope !17, !noalias !20" -> "  store i64 %38, i64* %41, align 1, !noalias !20"
"  %39 = add i64 %18, -48"
"  %39 = add i64 %18, -48" -> "  %40 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %39"
"  %40 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %39"
"  %40 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %39" -> "  %41 = bitcast i8* %40 to i64*"
"  %41 = bitcast i8* %40 to i64*"
"  %41 = bitcast i8* %40 to i64*" -> "  %20710 = load i64, i64* %41, align 1, !noalias !87""  %41 = bitcast i8* %40 to i64*" -> "  store i64 %38, i64* %41, align 1, !noalias !20"
"  store i64 %38, i64* %41, align 1, !noalias !20"

"  %42 = load i64, i64* %13, align 8, !alias.scope !17, !noalias !20"
"  %42 = load i64, i64* %13, align 8, !alias.scope !17, !noalias !20" -> "  store i64 %42, i64* %45, align 1, !noalias !20"
"  %43 = add i64 %18, -56"
"  %43 = add i64 %18, -56" -> "  %44 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %43"
"  %44 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %43"
"  %44 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %43" -> "  %45 = bitcast i8* %44 to i64*"
"  %45 = bitcast i8* %44 to i64*"
"  %45 = bitcast i8* %44 to i64*" -> "  %20709 = load i64, i64* %45, align 1, !noalias !87""  %45 = bitcast i8* %44 to i64*" -> "  store i64 %42, i64* %45, align 1, !noalias !20"
"  store i64 %42, i64* %45, align 1, !noalias !20"

"  %46 = load i64, i64* %12, align 8, !alias.scope !17, !noalias !20"
"  %46 = load i64, i64* %12, align 8, !alias.scope !17, !noalias !20" -> "  store i64 %46, i64* %49, align 1, !noalias !20"
"  %47 = add i64 %18, -64"
"  %47 = add i64 %18, -64" -> "  %20689 = trunc i64 %47 to i32""  %47 = add i64 %18, -64" -> "  %20695 = xor i64 %47, %50""  %47 = add i64 %18, -64" -> "  %20699 = icmp eq i64 %47, 0""  %47 = add i64 %18, -64" -> "  %20701 = lshr i64 %47, 63""  %47 = add i64 %18, -64" -> "  %48 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %47"
"  %48 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %47"
"  %48 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %47" -> "  %49 = bitcast i8* %48 to i64*"
"  %49 = bitcast i8* %48 to i64*"
"  %49 = bitcast i8* %48 to i64*" -> "  %20708 = load i64, i64* %49, align 1, !noalias !87""  %49 = bitcast i8* %48 to i64*" -> "  store i64 %46, i64* %49, align 1, !noalias !20"
"  store i64 %46, i64* %49, align 1, !noalias !20"

"  %50 = add i64 %18, -296"
"  %50 = add i64 %18, -296" -> "  %20687 = icmp ugt i64 %50, -233""  %50 = add i64 %18, -296" -> "  %20695 = xor i64 %47, %50""  %50 = add i64 %18, -296" -> "  %20703 = lshr i64 %50, 63"
"  %51 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 1, !remill_register !25"
"  %51 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 1, !remill_register !25" -> "  store i8 %20688, i8* %51, align 1, !tbaa !89, !alias.scope !84, !noalias !87"
"  %52 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 3, !remill_register !26"
"  %52 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 3, !remill_register !26" -> "  store i8 %20694, i8* %52, align 1, !tbaa !105, !alias.scope !84, !noalias !87"
"  %53 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 5, !remill_register !27"
"  %53 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 5, !remill_register !27" -> "  store i8 %20698, i8* %53, align 1, !tbaa !106, !alias.scope !84, !noalias !87"
"  %54 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 7, !remill_register !28"
"  %54 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 7, !remill_register !28" -> "  store i8 %20700, i8* %54, align 1, !tbaa !107, !alias.scope !84, !noalias !87"
"  %55 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 9, !remill_register !29"
"  %55 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 9, !remill_register !29" -> "  store i8 %20702, i8* %55, align 1, !tbaa !108, !alias.scope !84, !noalias !87"
"  %56 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 13, !remill_register !30"
"  %56 = getelementptr inbounds %struct.State, %struct.State* %state, i64 0, i32 2, i32 13, !remill_register !30" -> "  store i8 %20707, i8* %56, align 1, !tbaa !109, !alias.scope !84, !noalias !87"
"  %57 = add i64 %18, -72"
"  %57 = add i64 %18, -72" -> "  %59 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %57"
"  %58 = load i64, i64* %9, align 8, !noalias !31"
"  %58 = load i64, i64* %9, align 8, !noalias !31" -> "  store i64 %58, i64* %15, align 8, !tbaa !77, !alias.scope !79, !noalias !82""  %58 = load i64, i64* %9, align 8, !noalias !31" -> "  %20592 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %58""  %58 = load i64, i64* %9, align 8, !noalias !31" -> "  %20683 = add i64 %58, 14""  %58 = load i64, i64* %9, align 8, !noalias !31" -> "  %20678 = add i64 %58, 12""  %58 = load i64, i64* %9, align 8, !noalias !31" -> "  %20661 = add i64 %58, 10""  %58 = load i64, i64* %9, align 8, !noalias !31" -> "  %20655 = add i64 %58, 8""  %58 = load i64, i64* %9, align 8, !noalias !31" -> "  %20626 = add i64 %58, 6""  %58 = load i64, i64* %9, align 8, !noalias !31" -> "  %20620 = add i64 %58, 4""  %58 = load i64, i64* %9, align 8, !noalias !31" -> "  %20599 = add i64 %58, 2""  %58 = load i64, i64* %9, align 8, !noalias !31" -> "  store i64 %58, i64* %60, align 1, !noalias !20"
"  %59 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %57"
"  %59 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %57" -> "  %60 = bitcast i8* %59 to i64*"
"  %60 = bitcast i8* %59 to i64*"
"  %60 = bitcast i8* %59 to i64*" -> "  store i64 %58, i64* %60, align 1, !noalias !20"
"  store i64 %58, i64* %60, align 1, !noalias !20"

"  %61 = load i64, i64* %3, align 8, !alias.scope !17, !noalias !20"
"  %61 = load i64, i64* %3, align 8, !alias.scope !17, !noalias !20" -> "  %190 = add i64 %61, 8""  %61 = load i64, i64* %3, align 8, !alias.scope !17, !noalias !20" -> "  %62 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %61"
"  %62 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %61"
"  %62 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %61" -> "  %63 = bitcast i8* %62 to i64*"
"  %63 = bitcast i8* %62 to i64*"
"  %63 = bitcast i8* %62 to i64*" -> "  %64 = load i64, i64* %63, align 1, !noalias !20"
"  %64 = load i64, i64* %63, align 1, !noalias !20"
"  %64 = load i64, i64* %63, align 1, !noalias !20" -> "  %68 = lshr i64 %64, 48""  %64 = load i64, i64* %63, align 1, !noalias !20" -> "  %67 = lshr i64 %64, 32""  %64 = load i64, i64* %63, align 1, !noalias !20" -> "  %65 = trunc i64 %64 to i32"
"  %65 = trunc i64 %64 to i32"
"  %65 = trunc i64 %64 to i32" -> "  %69 = and i32 %65, 65535""  %65 = trunc i64 %64 to i32" -> "  %66 = lshr i32 %65, 16"
"  %66 = lshr i32 %65, 16"
"  %66 = lshr i32 %65, 16" -> "  %321 = mul nuw nsw i32 %66, 18212""  %66 = lshr i32 %65, 16" -> "  %305 = mul nuw nsw i32 %66, 10135""  %66 = lshr i32 %65, 16" -> "  %299 = mul nuw nsw i32 %66, 23650""  %66 = lshr i32 %65, 16" -> "  %139 = mul nuw i32 %66, 60287""  %66 = lshr i32 %65, 16" -> "  %130 = mul nuw i32 %66, 54862""  %66 = lshr i32 %65, 16" -> "  %88 = mul nuw nsw i32 %66, 1564""  %66 = lshr i32 %65, 16" -> "  %75 = mul nuw nsw i32 %66, 6717"
"  %67 = lshr i64 %64, 32"
"  %67 = lshr i64 %64, 32" -> "  %94 = trunc i64 %67 to i32"
"  %68 = lshr i64 %64, 48"
"  %68 = lshr i64 %64, 48" -> "  store i64 %68, i64* %172, align 1, !noalias !20""  %68 = lshr i64 %64, 48" -> "  %98 = trunc i64 %68 to i32"
"  %69 = and i32 %65, 65535"
"  %69 = and i32 %65, 65535" -> "  %294 = mul nuw nsw i32 %69, 23650""  %69 = and i32 %65, 65535" -> "  %301 = mul nuw nsw i32 %69, 10135""  %69 = and i32 %65, 65535" -> "  %318 = mul nuw nsw i32 %69, 29319""  %69 = and i32 %65, 65535" -> "  %319 = mul nuw nsw i32 %69, 18212""  %69 = and i32 %65, 65535" -> "  %137 = mul nuw i32 %69, 60287""  %69 = and i32 %65, 65535" -> "  %128 = mul nuw i32 %69, 54862""  %69 = and i32 %65, 65535" -> "  store i32 %69, i32* %127, align 1, !noalias !20""  %69 = and i32 %65, 65535" -> "  %82 = mul nuw nsw i32 %69, 1564""  %69 = and i32 %65, 65535" -> "  %70 = mul nuw nsw i32 %69, 6717"
"  %70 = mul nuw nsw i32 %69, 6717"
"  %70 = mul nuw nsw i32 %69, 6717" -> "  %344 = and i32 %70, 65535""  %70 = mul nuw nsw i32 %69, 6717" -> "  %74 = lshr i32 %70, 16""  %70 = mul nuw nsw i32 %69, 6717" -> "  store i32 %70, i32* %73, align 1, !noalias !20"
"  %71 = add i64 %18, -116"
"  %71 = add i64 %18, -116" -> "  %72 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %71"
"  %72 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %71"
"  %72 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %71" -> "  %73 = bitcast i8* %72 to i32*"
"  %73 = bitcast i8* %72 to i32*"
"  %73 = bitcast i8* %72 to i32*" -> "  %20606 = load i32, i32* %73, align 1, !noalias !87""  %73 = bitcast i8* %72 to i32*" -> "  store i32 %17261, i32* %73, align 1, !noalias !44""  %73 = bitcast i8* %72 to i32*" -> "  store i32 %70, i32* %73, align 1, !noalias !20"
"  store i32 %70, i32* %73, align 1, !noalias !20"

"  %74 = lshr i32 %70, 16"
"  %74 = lshr i32 %70, 16" -> "  %78 = add nuw nsw i32 %74, %76"
"  %75 = mul nuw nsw i32 %66, 6717"
"  %75 = mul nuw nsw i32 %66, 6717" -> "  %77 = and i32 %75, 536805376""  %75 = mul nuw nsw i32 %66, 6717" -> "  %76 = and i32 %75, 65535"
"  %76 = and i32 %75, 65535"
"  %76 = and i32 %75, 65535" -> "  %78 = add nuw nsw i32 %74, %76"
"  %77 = and i32 %75, 536805376"
"  %77 = and i32 %75, 536805376" -> "  %79 = add nuw nsw i32 %78, %77"
"  %78 = add nuw nsw i32 %74, %76"
"  %78 = add nuw nsw i32 %74, %76" -> "  %79 = add nuw nsw i32 %78, %77"
"  %79 = add nuw nsw i32 %78, %77"
"  %79 = add nuw nsw i32 %78, %77" -> "  %81 = lshr i32 %79, 16""  %79 = add nuw nsw i32 %78, %77" -> "  %80 = and i32 %79, 65535"
"  %80 = and i32 %79, 65535"
"  %80 = and i32 %79, 65535" -> "  %83 = add nuw nsw i32 %80, %82"
"  %81 = lshr i32 %79, 16"
"  %81 = lshr i32 %79, 16" -> "  %89 = add nuw nsw i32 %81, %88"
"  %82 = mul nuw nsw i32 %69, 1564"
"  %82 = mul nuw nsw i32 %69, 1564" -> "  %83 = add nuw nsw i32 %80, %82"
"  %83 = add nuw nsw i32 %80, %82"
"  %83 = add nuw nsw i32 %80, %82" -> "  %345 = and i32 %83, 65535""  %83 = add nuw nsw i32 %80, %82" -> "  %87 = lshr i32 %83, 16""  %83 = add nuw nsw i32 %80, %82" -> "  store i32 %83, i32* %86, align 1, !noalias !20"
"  %84 = add i64 %18, -232"
"  %84 = add i64 %18, -232" -> "  %85 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %84"
"  %85 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %84"
"  %85 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %84" -> "  %86 = bitcast i8* %85 to i32*"
"  %86 = bitcast i8* %85 to i32*"
"  %86 = bitcast i8* %85 to i32*" -> "  %20610 = load i32, i32* %86, align 1, !noalias !87""  %86 = bitcast i8* %85 to i32*" -> "  store i32 %17264, i32* %86, align 1, !noalias !44""  %86 = bitcast i8* %85 to i32*" -> "  store i32 %83, i32* %86, align 1, !noalias !20"
"  store i32 %83, i32* %86, align 1, !noalias !20"

"  %87 = lshr i32 %83, 16"
"  %87 = lshr i32 %83, 16" -> "  %92 = add nuw nsw i32 %87, %90"
"  %88 = mul nuw nsw i32 %66, 1564"
"  %88 = mul nuw nsw i32 %66, 1564" -> "  %89 = add nuw nsw i32 %81, %88"
"  %89 = add nuw nsw i32 %81, %88"
"  %89 = add nuw nsw i32 %81, %88" -> "  %91 = and i32 %89, 268369920""  %89 = add nuw nsw i32 %81, %88" -> "  %90 = and i32 %89, 65535"
"  %90 = and i32 %89, 65535"
"  %90 = and i32 %89, 65535" -> "  %92 = add nuw nsw i32 %87, %90"
"  %91 = and i32 %89, 268369920"
"  %91 = and i32 %89, 268369920" -> "  %93 = add nuw nsw i32 %92, %91"
"  %92 = add nuw nsw i32 %87, %90"
"  %92 = add nuw nsw i32 %87, %90" -> "  %93 = add nuw nsw i32 %92, %91"
"  %93 = add nuw nsw i32 %92, %91"
"  %93 = add nuw nsw i32 %92, %91" -> "  %114 = lshr i32 %93, 16""  %93 = add nuw nsw i32 %92, %91" -> "  %113 = and i32 %93, 65535"
"  %94 = trunc i64 %67 to i32"
"  %94 = trunc i64 %67 to i32" -> "  %95 = and i32 %94, 65535"
"  %95 = and i32 %94, 65535"
"  %95 = and i32 %94, 65535" -> "  %312 = mul nuw nsw i32 %95, 23650""  %95 = and i32 %94, 65535" -> "  %322 = mul nuw nsw i32 %95, 10135""  %95 = and i32 %94, 65535" -> "  %175 = mul nuw i32 %95, 60287""  %95 = and i32 %94, 65535" -> "  %168 = mul nuw i32 %95, 54862""  %95 = and i32 %94, 65535" -> "  store i32 %95, i32* %167, align 1, !noalias !20""  %95 = and i32 %94, 65535" -> "  %103 = mul nuw nsw i32 %95, 1564""  %95 = and i32 %94, 65535" -> "  %96 = mul nuw nsw i32 %95, 6717"
"  %96 = mul nuw nsw i32 %95, 6717"
"  %96 = mul nuw nsw i32 %95, 6717" -> "  %115 = and i32 %96, 65535""  %96 = mul nuw nsw i32 %95, 6717" -> "  %97 = lshr i32 %96, 16"
"  %97 = lshr i32 %96, 16"
"  %97 = lshr i32 %96, 16" -> "  %100 = add nuw nsw i32 %97, %99"
"  %98 = trunc i64 %68 to i32"
"  %98 = trunc i64 %68 to i32" -> "  %317 = mul nuw nsw i32 %98, 23650""  %98 = trunc i64 %68 to i32" -> "  %179 = mul nuw i32 %98, 60287""  %98 = trunc i64 %68 to i32" -> "  %173 = mul nuw i32 %98, 54862""  %98 = trunc i64 %68 to i32" -> "  %107 = mul nuw nsw i32 %98, 1564""  %98 = trunc i64 %68 to i32" -> "  %99 = mul nuw nsw i32 %98, 6717"
"  %99 = mul nuw nsw i32 %98, 6717"
"  %99 = mul nuw nsw i32 %98, 6717" -> "  %100 = add nuw nsw i32 %97, %99"
"  %100 = add nuw nsw i32 %97, %99"
"  %100 = add nuw nsw i32 %97, %99" -> "  %102 = lshr i32 %100, 16""  %100 = add nuw nsw i32 %97, %99" -> "  %101 = and i32 %100, 65535"
"  %101 = and i32 %100, 65535"
"  %101 = and i32 %100, 65535" -> "  %104 = add nuw nsw i32 %101, %103"
"  %102 = lshr i32 %100, 16"
"  %102 = lshr i32 %100, 16" -> "  %108 = add nuw nsw i32 %102, %107"
"  %103 = mul nuw nsw i32 %95, 1564"
"  %103 = mul nuw nsw i32 %95, 1564" -> "  %104 = add nuw nsw i32 %101, %103"
"  %104 = add nuw nsw i32 %101, %103"
"  %104 = add nuw nsw i32 %101, %103" -> "  %106 = lshr i32 %104, 16""  %104 = add nuw nsw i32 %101, %103" -> "  %105 = and i32 %104, 65535"
"  %105 = and i32 %104, 65535"
"  %105 = and i32 %104, 65535" -> "  %118 = add nuw nsw i32 %114, %105"
"  %106 = lshr i32 %104, 16"
"  %106 = lshr i32 %104, 16" -> "  %111 = add nuw nsw i32 %106, %109"
"  %107 = mul nuw nsw i32 %98, 1564"
"  %107 = mul nuw nsw i32 %98, 1564" -> "  %108 = add nuw nsw i32 %102, %107"
"  %108 = add nuw nsw i32 %102, %107"
"  %108 = add nuw nsw i32 %102, %107" -> "  %110 = and i32 %108, 268369920""  %108 = add nuw nsw i32 %102, %107" -> "  %109 = and i32 %108, 65535"
"  %109 = and i32 %108, 65535"
"  %109 = and i32 %108, 65535" -> "  %111 = add nuw nsw i32 %106, %109"
"  %110 = and i32 %108, 268369920"
"  %110 = and i32 %108, 268369920" -> "  %112 = add nuw nsw i32 %111, %110"
"  %111 = add nuw nsw i32 %106, %109"
"  %111 = add nuw nsw i32 %106, %109" -> "  %112 = add nuw nsw i32 %111, %110"
"  %112 = add nuw nsw i32 %111, %110"
"  %112 = add nuw nsw i32 %111, %110" -> "  %121 = add nuw nsw i32 %112, %120"
"  %113 = and i32 %93, 65535"
"  %113 = and i32 %93, 65535" -> "  %116 = add nuw nsw i32 %113, %115"
"  %114 = lshr i32 %93, 16"
"  %114 = lshr i32 %93, 16" -> "  %118 = add nuw nsw i32 %114, %105"
"  %115 = and i32 %96, 65535"
"  %115 = and i32 %96, 65535" -> "  %116 = add nuw nsw i32 %113, %115"
"  %116 = add nuw nsw i32 %113, %115"
"  %116 = add nuw nsw i32 %113, %115" -> "  %145 = and i32 %116, 65535""  %116 = add nuw nsw i32 %113, %115" -> "  %117 = lshr i32 %116, 16"
"  %117 = lshr i32 %116, 16"
"  %117 = lshr i32 %116, 16" -> "  %122 = add nuw nsw i32 %117, %119"
"  %118 = add nuw nsw i32 %114, %105"
"  %118 = add nuw nsw i32 %114, %105" -> "  %120 = lshr i32 %118, 16""  %118 = add nuw nsw i32 %114, %105" -> "  %119 = and i32 %118, 65535"
"  %119 = and i32 %118, 65535"
"  %119 = and i32 %118, 65535" -> "  %122 = add nuw nsw i32 %117, %119"
"  %120 = lshr i32 %118, 16"
"  %120 = lshr i32 %118, 16" -> "  %121 = add nuw nsw i32 %112, %120"
"  %121 = add nuw nsw i32 %112, %120"
"  %121 = add nuw nsw i32 %112, %120" -> "  %124 = add nuw nsw i32 %121, %123"
"  %122 = add nuw nsw i32 %117, %119"
"  %122 = add nuw nsw i32 %117, %119" -> "  %144 = and i32 %122, 65535""  %122 = add nuw nsw i32 %117, %119" -> "  %123 = lshr i32 %122, 16"
"  %123 = lshr i32 %122, 16"
"  %123 = lshr i32 %122, 16" -> "  %124 = add nuw nsw i32 %121, %123"
"  %124 = add nuw nsw i32 %121, %123"
"  %124 = add nuw nsw i32 %121, %123" -> "  %194 = lshr i32 %124, 16""  %124 = add nuw nsw i32 %121, %123" -> "  %186 = and i32 %124, 65535"
"  %125 = add i64 %18, -192"
"  %125 = add i64 %18, -192" -> "  %126 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %125"
"  %126 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %125"
"  %126 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %125" -> "  %127 = bitcast i8* %126 to i32*"
"  %127 = bitcast i8* %126 to i32*"
"  %127 = bitcast i8* %126 to i32*" -> "  %20632 = load i32, i32* %127, align 1, !noalias !87""  %127 = bitcast i8* %126 to i32*" -> "  store i32 %17375, i32* %127, align 1, !noalias !47""  %127 = bitcast i8* %126 to i32*" -> "  store i32 %69, i32* %127, align 1, !noalias !20"
"  store i32 %69, i32* %127, align 1, !noalias !20"

"  %128 = mul nuw i32 %69, 54862"
"  %128 = mul nuw i32 %69, 54862" -> "  %149 = and i32 %128, 65534""  %128 = mul nuw i32 %69, 54862" -> "  %129 = lshr i32 %128, 16"
"  %129 = lshr i32 %128, 16"
"  %129 = lshr i32 %128, 16" -> "  %133 = add nuw nsw i32 %129, %132"
"  %130 = mul nuw i32 %66, 54862"
"  %130 = mul nuw i32 %66, 54862" -> "  %132 = and i32 %130, 65534""  %130 = mul nuw i32 %66, 54862" -> "  %131 = and i32 %130, -65536"
"  %131 = and i32 %130, -65536"
"  %131 = and i32 %130, -65536" -> "  %134 = add nuw i32 %133, %131"
"  %132 = and i32 %130, 65534"
"  %132 = and i32 %130, 65534" -> "  %133 = add nuw nsw i32 %129, %132"
"  %133 = add nuw nsw i32 %129, %132"
"  %133 = add nuw nsw i32 %129, %132" -> "  %134 = add nuw i32 %133, %131"
"  %134 = add nuw i32 %133, %131"
"  %134 = add nuw i32 %133, %131" -> "  %136 = lshr i32 %134, 16""  %134 = add nuw i32 %133, %131" -> "  %135 = and i32 %134, 65535"
"  %135 = and i32 %134, 65535"
"  %135 = and i32 %134, 65535" -> "  %138 = add nuw i32 %135, %137"
"  %136 = lshr i32 %134, 16"
"  %136 = lshr i32 %134, 16" -> "  %140 = add nuw i32 %136, %139"
"  %137 = mul nuw i32 %69, 60287"
"  %137 = mul nuw i32 %69, 60287" -> "  %138 = add nuw i32 %135, %137"
"  %138 = add nuw i32 %135, %137"
"  %138 = add nuw i32 %135, %137" -> "  %146 = and i32 %138, 65535""  %138 = add nuw i32 %135, %137" -> "  %141 = lshr i32 %138, 16"
"  %139 = mul nuw i32 %66, 60287"
"  %139 = mul nuw i32 %66, 60287" -> "  %140 = add nuw i32 %136, %139"
"  %140 = add nuw i32 %136, %139"
"  %140 = add nuw i32 %136, %139" -> "  %147 = and i32 %140, -65536""  %140 = add nuw i32 %136, %139" -> "  %142 = and i32 %140, 65535"
"  %141 = lshr i32 %138, 16"
"  %141 = lshr i32 %138, 16" -> "  %143 = add nuw nsw i32 %141, %142"
"  %142 = and i32 %140, 65535"
"  %142 = and i32 %140, 65535" -> "  %143 = add nuw nsw i32 %141, %142"
"  %143 = add nuw nsw i32 %141, %142"
"  %143 = add nuw nsw i32 %141, %142" -> "  %148 = add nuw i32 %143, %147"
"  %144 = and i32 %122, 65535"
"  %144 = and i32 %122, 65535" -> "  %155 = add nuw nsw i32 %144, %146"
"  %145 = and i32 %116, 65535"
"  %145 = and i32 %116, 65535" -> "  %150 = add nuw nsw i32 %145, %149"
"  %146 = and i32 %138, 65535"
"  %146 = and i32 %138, 65535" -> "  %155 = add nuw nsw i32 %144, %146"
"  %147 = and i32 %140, -65536"
"  %147 = and i32 %140, -65536" -> "  %148 = add nuw i32 %143, %147"
"  %148 = add nuw i32 %143, %147"
"  %148 = add nuw i32 %143, %147" -> "  %158 = add nuw i32 %148, %157"
"  %149 = and i32 %128, 65534"
"  %149 = and i32 %128, 65534" -> "  %150 = add nuw nsw i32 %145, %149"
"  %150 = add nuw nsw i32 %145, %149"
"  %150 = add nuw nsw i32 %145, %149" -> "  %346 = and i32 %150, 65535""  %150 = add nuw nsw i32 %145, %149" -> "  %154 = lshr i32 %150, 16""  %150 = add nuw nsw i32 %145, %149" -> "  store i32 %150, i32* %153, align 1, !noalias !20"
"  %151 = add i64 %18, -256"
"  %151 = add i64 %18, -256" -> "  %152 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %151"
"  %152 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %151"
"  %152 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %151" -> "  %153 = bitcast i8* %152 to i32*"
"  %153 = bitcast i8* %152 to i32*"
"  %153 = bitcast i8* %152 to i32*" -> "  store i32 %17241, i32* %153, align 1, !noalias !44""  %153 = bitcast i8* %152 to i32*" -> "  store i32 %150, i32* %153, align 1, !noalias !20"
"  store i32 %150, i32* %153, align 1, !noalias !20"

"  %154 = lshr i32 %150, 16"
"  %154 = lshr i32 %150, 16" -> "  %159 = add nuw nsw i32 %156, %154"
"  %155 = add nuw nsw i32 %144, %146"
"  %155 = add nuw nsw i32 %144, %146" -> "  %157 = lshr i32 %155, 16""  %155 = add nuw nsw i32 %144, %146" -> "  %156 = and i32 %155, 65535"
"  %156 = and i32 %155, 65535"
"  %156 = and i32 %155, 65535" -> "  %159 = add nuw nsw i32 %156, %154"
"  %157 = lshr i32 %155, 16"
"  %157 = lshr i32 %155, 16" -> "  %158 = add nuw i32 %148, %157"
"  %158 = add nuw i32 %148, %157"
"  %158 = add nuw i32 %148, %157" -> "  %164 = add nuw i32 %158, %163"
"  %159 = add nuw nsw i32 %156, %154"
"  %159 = add nuw nsw i32 %156, %154" -> "  %347 = and i32 %159, 65535""  %159 = add nuw nsw i32 %156, %154" -> "  %163 = lshr i32 %159, 16""  %159 = add nuw nsw i32 %156, %154" -> "  store i32 %159, i32* %162, align 1, !noalias !20"
"  %160 = add i64 %18, -188"
"  %160 = add i64 %18, -188" -> "  %161 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %160"
"  %161 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %160"
"  %161 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %160" -> "  %162 = bitcast i8* %161 to i32*"
"  %162 = bitcast i8* %161 to i32*"
"  %162 = bitcast i8* %161 to i32*" -> "  store i32 %17244, i32* %162, align 1, !noalias !44""  %162 = bitcast i8* %161 to i32*" -> "  store i32 %159, i32* %162, align 1, !noalias !20"
"  store i32 %159, i32* %162, align 1, !noalias !20"

"  %163 = lshr i32 %159, 16"
"  %163 = lshr i32 %159, 16" -> "  %164 = add nuw i32 %158, %163"
"  %164 = add nuw i32 %158, %163"
"  %164 = add nuw i32 %158, %163" -> "  %206 = lshr i32 %164, 16""  %164 = add nuw i32 %158, %163" -> "  %205 = and i32 %164, 65535"
"  %165 = add i64 %18, -224"
"  %165 = add i64 %18, -224" -> "  %166 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %165"
"  %166 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %165"
"  %166 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %165" -> "  %167 = bitcast i8* %166 to i32*"
"  %167 = bitcast i8* %166 to i32*"
"  %167 = bitcast i8* %166 to i32*" -> "  %20643 = load i32, i32* %167, align 1, !noalias !87""  %167 = bitcast i8* %166 to i32*" -> "  store i32 %17395, i32* %167, align 1, !noalias !47""  %167 = bitcast i8* %166 to i32*" -> "  store i32 %95, i32* %167, align 1, !noalias !20"
"  store i32 %95, i32* %167, align 1, !noalias !20"

"  %168 = mul nuw i32 %95, 54862"
"  %168 = mul nuw i32 %95, 54862" -> "  %187 = and i32 %168, 65534""  %168 = mul nuw i32 %95, 54862" -> "  %169 = lshr i32 %168, 16"
"  %169 = lshr i32 %168, 16"
"  %169 = lshr i32 %168, 16" -> "  %174 = add nuw i32 %169, %173"
"  %170 = add i64 %18, -136"
"  %170 = add i64 %18, -136" -> "  %171 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %170"
"  %171 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %170"
"  %171 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %170" -> "  %316 = bitcast i8* %171 to i32*""  %171 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %170" -> "  %172 = bitcast i8* %171 to i64*"
"  %172 = bitcast i8* %171 to i64*"
"  %172 = bitcast i8* %171 to i64*" -> "  store i64 %68, i64* %172, align 1, !noalias !20"
"  store i64 %68, i64* %172, align 1, !noalias !20"

"  %173 = mul nuw i32 %98, 54862"
"  %173 = mul nuw i32 %98, 54862" -> "  %174 = add nuw i32 %169, %173"
"  %174 = add nuw i32 %169, %173"
"  %174 = add nuw i32 %169, %173" -> "  %178 = lshr i32 %174, 16""  %174 = add nuw i32 %169, %173" -> "  %176 = and i32 %174, 65535"
"  %175 = mul nuw i32 %95, 60287"
"  %175 = mul nuw i32 %95, 60287" -> "  %177 = add nuw i32 %176, %175"
"  %176 = and i32 %174, 65535"
"  %176 = and i32 %174, 65535" -> "  %177 = add nuw i32 %176, %175"
"  %177 = add nuw i32 %176, %175"
"  %177 = add nuw i32 %176, %175" -> "  %189 = and i32 %177, 65535""  %177 = add nuw i32 %176, %175" -> "  %181 = lshr i32 %177, 16"
"  %178 = lshr i32 %174, 16"
"  %178 = lshr i32 %174, 16" -> "  %180 = add nuw i32 %178, %179"
"  %179 = mul nuw i32 %98, 60287"
"  %179 = mul nuw i32 %98, 60287" -> "  %180 = add nuw i32 %178, %179"
"  %180 = add nuw i32 %178, %179"
"  %180 = add nuw i32 %178, %179" -> "  %184 = and i32 %180, -65536""  %180 = add nuw i32 %178, %179" -> "  %182 = and i32 %180, 65535"
"  %181 = lshr i32 %177, 16"
"  %181 = lshr i32 %177, 16" -> "  %183 = add nuw nsw i32 %181, %182"
"  %182 = and i32 %180, 65535"
"  %182 = and i32 %180, 65535" -> "  %183 = add nuw nsw i32 %181, %182"
"  %183 = add nuw nsw i32 %181, %182"
"  %183 = add nuw nsw i32 %181, %182" -> "  %185 = add nuw i32 %183, %184"
"  %184 = and i32 %180, -65536"
"  %184 = and i32 %180, -65536" -> "  %185 = add nuw i32 %183, %184"
"  %185 = add nuw i32 %183, %184"
"  %185 = add nuw i32 %183, %184" -> "  %198 = add nuw i32 %185, %197"
"  %186 = and i32 %124, 65535"
"  %186 = and i32 %124, 65535" -> "  %188 = add nuw nsw i32 %186, %187"
"  %187 = and i32 %168, 65534"
"  %187 = and i32 %168, 65534" -> "  %188 = add nuw nsw i32 %186, %187"
"  %188 = add nuw nsw i32 %186, %187"
"  %188 = add nuw nsw i32 %186, %187" -> "  %200 = lshr i32 %188, 16""  %188 = add nuw nsw i32 %186, %187" -> "  %199 = and i32 %188, 65535"
"  %189 = and i32 %177, 65535"
"  %189 = and i32 %177, 65535" -> "  %195 = add nuw nsw i32 %194, %189"
"  %190 = add i64 %61, 8"
"  %190 = add i64 %61, 8" -> "  %191 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %190"
"  %191 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %190"
"  %191 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %190" -> "  %192 = bitcast i8* %191 to i64*"
"  %192 = bitcast i8* %191 to i64*"
"  %192 = bitcast i8* %191 to i64*" -> "  %193 = load i64, i64* %192, align 1, !noalias !31"
"  %193 = load i64, i64* %192, align 1, !noalias !31"
"  %193 = load i64, i64* %192, align 1, !noalias !31" -> "  %222 = trunc i64 %193 to i32""  %193 = load i64, i64* %192, align 1, !noalias !31" -> "  %324 = lshr i64 %193, 48""  %193 = load i64, i64* %192, align 1, !noalias !31" -> "  %251 = lshr i64 %193, 32""  %193 = load i64, i64* %192, align 1, !noalias !31" -> "  %229 = lshr i64 %193, 16""  %193 = load i64, i64* %192, align 1, !noalias !31" -> "  store i64 %193, i64* %228, align 1, !noalias !20"
"  %194 = lshr i32 %124, 16"
"  %194 = lshr i32 %124, 16" -> "  %195 = add nuw nsw i32 %194, %189"
"  %195 = add nuw nsw i32 %194, %189"
"  %195 = add nuw nsw i32 %194, %189" -> "  %197 = lshr i32 %195, 16""  %195 = add nuw nsw i32 %194, %189" -> "  %196 = and i32 %195, 65535"
"  %196 = and i32 %195, 65535"
"  %196 = and i32 %195, 65535" -> "  %201 = add nuw nsw i32 %200, %196"
"  %197 = lshr i32 %195, 16"
"  %197 = lshr i32 %195, 16" -> "  %198 = add nuw i32 %185, %197"
"  %198 = add nuw i32 %185, %197"
"  %198 = add nuw i32 %185, %197" -> "  %204 = add nuw i32 %198, %203"
"  %199 = and i32 %188, 65535"
"  %199 = and i32 %188, 65535" -> "  %207 = add nuw nsw i32 %205, %199"
"  %200 = lshr i32 %188, 16"
"  %200 = lshr i32 %188, 16" -> "  %201 = add nuw nsw i32 %200, %196"
"  %201 = add nuw nsw i32 %200, %196"
"  %201 = add nuw nsw i32 %200, %196" -> "  %203 = lshr i32 %201, 16""  %201 = add nuw nsw i32 %200, %196" -> "  %202 = and i32 %201, 65535"
"  %202 = and i32 %201, 65535"
"  %202 = and i32 %201, 65535" -> "  %209 = add nuw nsw i32 %206, %202"
"  %203 = lshr i32 %201, 16"
"  %203 = lshr i32 %201, 16" -> "  %204 = add nuw i32 %198, %203"
"  %204 = add nuw i32 %198, %203"
"  %204 = add nuw i32 %198, %203" -> "  %213 = and i32 %204, -65536""  %204 = add nuw i32 %198, %203" -> "  %212 = and i32 %204, 65535"
"  %205 = and i32 %164, 65535"
"  %205 = and i32 %164, 65535" -> "  %207 = add nuw nsw i32 %205, %199"
"  %206 = lshr i32 %164, 16"
"  %206 = lshr i32 %164, 16" -> "  %209 = add nuw nsw i32 %206, %202"
"  %207 = add nuw nsw i32 %205, %199"
"  %207 = add nuw nsw i32 %205, %199" -> "  %275 = and i32 %207, 65535""  %207 = add nuw nsw i32 %205, %199" -> "  %208 = lshr i32 %207, 16"
"  %208 = lshr i32 %207, 16"
"  %208 = lshr i32 %207, 16" -> "  %211 = add nuw nsw i32 %208, %210"
"  %209 = add nuw nsw i32 %206, %202"
"  %209 = add nuw nsw i32 %206, %202" -> "  %214 = lshr i32 %209, 16""  %209 = add nuw nsw i32 %206, %202" -> "  %210 = and i32 %209, 65535"
"  %210 = and i32 %209, 65535"
"  %210 = and i32 %209, 65535" -> "  %211 = add nuw nsw i32 %208, %210"
"  %211 = add nuw nsw i32 %208, %210"
"  %211 = add nuw nsw i32 %208, %210" -> "  %278 = and i32 %211, 65535""  %211 = add nuw nsw i32 %208, %210" -> "  %216 = lshr i32 %211, 16"
"  %212 = and i32 %204, 65535"
"  %212 = and i32 %204, 65535" -> "  %215 = add nuw nsw i32 %214, %212"
"  %213 = and i32 %204, -65536"
"  %213 = and i32 %204, -65536" -> "  %217 = add nuw i32 %215, %213"
"  %214 = lshr i32 %209, 16"
"  %214 = lshr i32 %209, 16" -> "  %215 = add nuw nsw i32 %214, %212"
"  %215 = add nuw nsw i32 %214, %212"
"  %215 = add nuw nsw i32 %214, %212" -> "  %217 = add nuw i32 %215, %213"
"  %216 = lshr i32 %211, 16"
"  %216 = lshr i32 %211, 16" -> "  %218 = add nuw i32 %217, %216"
"  %217 = add nuw i32 %215, %213"
"  %217 = add nuw i32 %215, %213" -> "  %218 = add nuw i32 %217, %216"
"  %218 = add nuw i32 %217, %216"
"  %218 = add nuw i32 %217, %216" -> "  %349 = lshr i32 %218, 16""  %218 = add nuw i32 %217, %216" -> "  %284 = and i32 %218, 65535"
"  %219 = add i64 %18, -292"
"  %219 = add i64 %18, -292" -> "  %220 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %219"
"  %220 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %219"
"  %220 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %219" -> "  %221 = bitcast i8* %220 to i32*"
"  %221 = bitcast i8* %220 to i32*"
"  %221 = bitcast i8* %220 to i32*" -> "  store i32 %20303, i32* %221, align 1, !noalias !74"
"  %222 = trunc i64 %193 to i32"
"  %222 = trunc i64 %193 to i32" -> "  %223 = and i32 %222, 65535"
"  %223 = and i32 %222, 65535"
"  %223 = and i32 %222, 65535" -> "  %237 = mul nuw nsw i32 %223, 1564""  %223 = and i32 %222, 65535" -> "  %264 = mul nuw i32 %223, 54862""  %223 = and i32 %222, 65535" -> "  %323 = mul nuw i32 %223, 60287""  %223 = and i32 %222, 65535" -> "  %224 = mul nuw nsw i32 %223, 6717"
"  %224 = mul nuw nsw i32 %223, 6717"
"  %224 = mul nuw nsw i32 %223, 6717" -> "  %225 = lshr i32 %224, 16""  %224 = mul nuw nsw i32 %223, 6717" -> "  %274 = and i32 %224, 65535"
"  %225 = lshr i32 %224, 16"
"  %225 = lshr i32 %224, 16" -> "  %234 = add nuw nsw i32 %233, %225"
"  %226 = add i64 %18, -96"
"  %226 = add i64 %18, -96" -> "  %227 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %226"
"  %227 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %226"
"  %227 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %226" -> "  %651 = bitcast i8* %227 to i32*""  %227 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %226" -> "  %228 = bitcast i8* %227 to i64*"
"  %228 = bitcast i8* %227 to i64*"
"  %228 = bitcast i8* %227 to i64*" -> "  store i64 %193, i64* %228, align 1, !noalias !20"
"  store i64 %193, i64* %228, align 1, !noalias !20"

"  %229 = lshr i64 %193, 16"
"  %229 = lshr i64 %193, 16" -> "  %230 = trunc i64 %229 to i32"
"  %230 = trunc i64 %229 to i32"
"  %230 = trunc i64 %229 to i32" -> "  %231 = and i32 %230, 65535"
"  %231 = and i32 %230, 65535"
"  %231 = and i32 %230, 65535" -> "  %232 = mul nuw nsw i32 %231, 6717""  %231 = and i32 %230, 65535" -> "  %244 = mul nuw nsw i32 %231, 1564""  %231 = and i32 %230, 65535" -> "  %329 = mul nuw i32 %231, 54862"
"  %232 = mul nuw nsw i32 %231, 6717"
"  %232 = mul nuw nsw i32 %231, 6717" -> "  %235 = and i32 %232, 536805376""  %232 = mul nuw nsw i32 %231, 6717" -> "  %233 = and i32 %232, 65535"
"  %233 = and i32 %232, 65535"
"  %233 = and i32 %232, 65535" -> "  %234 = add nuw nsw i32 %233, %225"
"  %234 = add nuw nsw i32 %233, %225"
"  %234 = add nuw nsw i32 %233, %225" -> "  %236 = add nuw nsw i32 %234, %235"
"  %235 = and i32 %232, 536805376"
"  %235 = and i32 %232, 536805376" -> "  %236 = add nuw nsw i32 %234, %235"
"  %236 = add nuw nsw i32 %234, %235"
"  %236 = add nuw nsw i32 %234, %235" -> "  %243 = lshr i32 %236, 16""  %236 = add nuw nsw i32 %234, %235" -> "  %241 = and i32 %236, 65535"
"  %237 = mul nuw nsw i32 %223, 1564"
"  %237 = mul nuw nsw i32 %223, 1564" -> "  %242 = add nuw nsw i32 %241, %237"
"  %238 = add i64 %18, -128"
"  %238 = add i64 %18, -128" -> "  %239 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %238"
"  %239 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %238"
"  %239 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %238" -> "  %240 = bitcast i8* %239 to i32*"
"  %240 = bitcast i8* %239 to i32*"
"  %240 = bitcast i8* %239 to i32*" -> "  store i32 %20046, i32* %240, align 1, !noalias !71"
"  %241 = and i32 %236, 65535"
"  %241 = and i32 %236, 65535" -> "  %242 = add nuw nsw i32 %241, %237"
"  %242 = add nuw nsw i32 %241, %237"
"  %242 = add nuw nsw i32 %241, %237" -> "  %277 = and i32 %242, 65535""  %242 = add nuw nsw i32 %241, %237" -> "  %246 = lshr i32 %242, 16"
"  %243 = lshr i32 %236, 16"
"  %243 = lshr i32 %236, 16" -> "  %245 = add nuw nsw i32 %243, %244"
"  %244 = mul nuw nsw i32 %231, 1564"
"  %244 = mul nuw nsw i32 %231, 1564" -> "  %245 = add nuw nsw i32 %243, %244"
"  %245 = add nuw nsw i32 %243, %244"
"  %245 = add nuw nsw i32 %243, %244" -> "  %249 = and i32 %245, 268369920""  %245 = add nuw nsw i32 %243, %244" -> "  %247 = and i32 %245, 65535"
"  %246 = lshr i32 %242, 16"
"  %246 = lshr i32 %242, 16" -> "  %248 = add nuw nsw i32 %246, %247"
"  %247 = and i32 %245, 65535"
"  %247 = and i32 %245, 65535" -> "  %248 = add nuw nsw i32 %246, %247"
"  %248 = add nuw nsw i32 %246, %247"
"  %248 = add nuw nsw i32 %246, %247" -> "  %250 = add nuw nsw i32 %248, %249"
"  %249 = and i32 %245, 268369920"
"  %249 = and i32 %245, 268369920" -> "  %250 = add nuw nsw i32 %248, %249"
"  %250 = add nuw nsw i32 %248, %249"
"  %250 = add nuw nsw i32 %248, %249" -> "  %333 = lshr i32 %250, 16""  %250 = add nuw nsw i32 %248, %249" -> "  %261 = and i32 %250, 65535"
"  %251 = lshr i64 %193, 32"
"  %251 = lshr i64 %193, 32" -> "  %253 = trunc i64 %251 to i32"
"  %252 = add i64 %18, -280"
"  %252 = add i64 %18, -280" -> "  %255 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %252"
"  %253 = trunc i64 %251 to i32"
"  %253 = trunc i64 %251 to i32" -> "  %254 = and i32 %253, 65535"
"  %254 = and i32 %253, 65535"
"  %254 = and i32 %253, 65535" -> "  %330 = mul nuw nsw i32 %254, 1564""  %254 = and i32 %253, 65535" -> "  %257 = mul nuw nsw i32 %254, 6717"
"  %255 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %252"
"  %255 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %252" -> "  %256 = bitcast i8* %255 to i32*"
"  %256 = bitcast i8* %255 to i32*"
"  %256 = bitcast i8* %255 to i32*" -> "  store i32 %20266, i32* %256, align 1, !noalias !74"
"  %257 = mul nuw nsw i32 %254, 6717"
"  %257 = mul nuw nsw i32 %254, 6717" -> "  %331 = lshr i32 %257, 16""  %257 = mul nuw nsw i32 %254, 6717" -> "  %262 = and i32 %257, 65535"
"  %258 = add i64 %18, -120"
"  %258 = add i64 %18, -120" -> "  %259 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %258"
"  %259 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %258"
"  %259 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %258" -> "  %260 = bitcast i8* %259 to i32*"
"  %260 = bitcast i8* %259 to i32*"
"  %260 = bitcast i8* %259 to i32*" -> "  store i32 %20371, i32* %260, align 1, !noalias !74"
"  %261 = and i32 %250, 65535"
"  %261 = and i32 %250, 65535" -> "  %263 = add nuw nsw i32 %261, %262"
"  %262 = and i32 %257, 65535"
"  %262 = and i32 %257, 65535" -> "  %263 = add nuw nsw i32 %261, %262"
"  %263 = add nuw nsw i32 %261, %262"
"  %263 = add nuw nsw i32 %261, %262" -> "  %268 = and i32 %263, 65535""  %263 = add nuw nsw i32 %261, %262" -> "  %335 = lshr i32 %263, 16"
"  %264 = mul nuw i32 %223, 54862"
"  %264 = mul nuw i32 %223, 54862" -> "  %328 = lshr i32 %264, 16""  %264 = mul nuw i32 %223, 54862" -> "  %269 = and i32 %264, 65534"
"  %265 = add i64 %18, -108"
"  %265 = add i64 %18, -108" -> "  %266 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %265"
"  %266 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %265"
"  %266 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %265" -> "  %267 = bitcast i8* %266 to i32*"
"  %267 = bitcast i8* %266 to i32*"
"  %267 = bitcast i8* %266 to i32*" -> "  store i32 %19860, i32* %267, align 1, !noalias !68"
"  %268 = and i32 %263, 65535"
"  %268 = and i32 %263, 65535" -> "  %270 = add nuw nsw i32 %268, %269"
"  %269 = and i32 %264, 65534"
"  %269 = and i32 %264, 65534" -> "  %270 = add nuw nsw i32 %268, %269"
"  %270 = add nuw nsw i32 %268, %269"
"  %270 = add nuw nsw i32 %268, %269" -> "  %348 = lshr i32 %270, 16""  %270 = add nuw nsw i32 %268, %269" -> "  %283 = and i32 %270, 65535"
"  %271 = add i64 %18, -268"
"  %271 = add i64 %18, -268" -> "  %272 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %271"
"  %272 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %271"
"  %272 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %271" -> "  %273 = bitcast i8* %272 to i32*"
"  %273 = bitcast i8* %272 to i32*"
"  %273 = bitcast i8* %272 to i32*" -> "  store i32 %20294, i32* %273, align 1, !noalias !74"
"  %274 = and i32 %224, 65535"
"  %274 = and i32 %224, 65535" -> "  %276 = add nuw nsw i32 %275, %274"
"  %275 = and i32 %207, 65535"
"  %275 = and i32 %207, 65535" -> "  %276 = add nuw nsw i32 %275, %274"
"  %276 = add nuw nsw i32 %275, %274"
"  %276 = add nuw nsw i32 %275, %274" -> "  %340 = and i32 %276, 65535""  %276 = add nuw nsw i32 %275, %274" -> "  %280 = lshr i32 %276, 16"
"  %277 = and i32 %242, 65535"
"  %277 = and i32 %242, 65535" -> "  %279 = add nuw nsw i32 %278, %277"
"  %278 = and i32 %211, 65535"
"  %278 = and i32 %211, 65535" -> "  %279 = add nuw nsw i32 %278, %277"
"  %279 = add nuw nsw i32 %278, %277"
"  %279 = add nuw nsw i32 %278, %277" -> "  %289 = lshr i32 %279, 16""  %279 = add nuw nsw i32 %278, %277" -> "  %281 = and i32 %279, 65535"
"  %280 = lshr i32 %276, 16"
"  %280 = lshr i32 %276, 16" -> "  %282 = add nuw nsw i32 %281, %280"
"  %281 = and i32 %279, 65535"
"  %281 = and i32 %279, 65535" -> "  %282 = add nuw nsw i32 %281, %280"
"  %282 = add nuw nsw i32 %281, %280"
"  %282 = add nuw nsw i32 %281, %280" -> "  %341 = and i32 %282, 65535""  %282 = add nuw nsw i32 %281, %280" -> "  %292 = lshr i32 %282, 16"
"  %283 = and i32 %270, 65535"
"  %283 = and i32 %270, 65535" -> "  %285 = add nuw nsw i32 %284, %283"
"  %284 = and i32 %218, 65535"
"  %284 = and i32 %218, 65535" -> "  %285 = add nuw nsw i32 %284, %283"
"  %285 = add nuw nsw i32 %284, %283"
"  %285 = add nuw nsw i32 %284, %283" -> "  %350 = lshr i32 %285, 16""  %285 = add nuw nsw i32 %284, %283" -> "  %290 = and i32 %285, 65535"
"  %286 = add i64 %18, -284"
"  %286 = add i64 %18, -284" -> "  %287 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %286"
"  %287 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %286"
"  %287 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %286" -> "  %288 = bitcast i8* %287 to i32*"
"  %288 = bitcast i8* %287 to i32*"
"  %288 = bitcast i8* %287 to i32*" -> "  store i32 %20284, i32* %288, align 1, !noalias !74"
"  %289 = lshr i32 %279, 16"
"  %289 = lshr i32 %279, 16" -> "  %291 = add nuw nsw i32 %290, %289"
"  %290 = and i32 %285, 65535"
"  %290 = and i32 %285, 65535" -> "  %291 = add nuw nsw i32 %290, %289"
"  %291 = add nuw nsw i32 %290, %289"
"  %291 = add nuw nsw i32 %290, %289" -> "  %293 = add nuw nsw i32 %291, %292"
"  %292 = lshr i32 %282, 16"
"  %292 = lshr i32 %282, 16" -> "  %293 = add nuw nsw i32 %291, %292"
"  %293 = add nuw nsw i32 %291, %292"
"  %293 = add nuw nsw i32 %291, %292" -> "  %352 = lshr i32 %293, 16""  %293 = add nuw nsw i32 %291, %292" -> "  %351 = and i32 %293, 65535"
"  %294 = mul nuw nsw i32 %69, 23650"
"  %294 = mul nuw nsw i32 %69, 23650" -> "  %353 = and i32 %294, 65534""  %294 = mul nuw nsw i32 %69, 23650" -> "  %298 = lshr i32 %294, 16"
"  %295 = add i64 %18, -288"
"  %295 = add i64 %18, -288" -> "  %296 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %295"
"  %296 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %295"
"  %296 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %295" -> "  %297 = bitcast i8* %296 to i32*"
"  %297 = bitcast i8* %296 to i32*"
"  %297 = bitcast i8* %296 to i32*" -> "  store i32 %20078, i32* %297, align 1, !noalias !71"
"  %298 = lshr i32 %294, 16"
"  %298 = lshr i32 %294, 16" -> "  %300 = add nuw nsw i32 %298, %299"
"  %299 = mul nuw nsw i32 %66, 23650"
"  %299 = mul nuw nsw i32 %66, 23650" -> "  %300 = add nuw nsw i32 %298, %299"
"  %300 = add nuw nsw i32 %298, %299"
"  %300 = add nuw nsw i32 %298, %299" -> "  %304 = lshr i32 %300, 16""  %300 = add nuw nsw i32 %298, %299" -> "  %302 = and i32 %300, 65535"
"  %301 = mul nuw nsw i32 %69, 10135"
"  %301 = mul nuw nsw i32 %69, 10135" -> "  %303 = add nuw nsw i32 %302, %301"
"  %302 = and i32 %300, 65535"
"  %302 = and i32 %300, 65535" -> "  %303 = add nuw nsw i32 %302, %301"
"  %303 = add nuw nsw i32 %302, %301"
"  %303 = add nuw nsw i32 %302, %301" -> "  %342 = and i32 %303, 65535""  %303 = add nuw nsw i32 %302, %301" -> "  %307 = lshr i32 %303, 16"
"  %304 = lshr i32 %300, 16"
"  %304 = lshr i32 %300, 16" -> "  %306 = add nuw nsw i32 %304, %305"
"  %305 = mul nuw nsw i32 %66, 10135"
"  %305 = mul nuw nsw i32 %66, 10135" -> "  %306 = add nuw nsw i32 %304, %305"
"  %306 = add nuw nsw i32 %304, %305"
"  %306 = add nuw nsw i32 %304, %305" -> "  %310 = and i32 %306, 2147418112""  %306 = add nuw nsw i32 %304, %305" -> "  %308 = and i32 %306, 65535"
"  %307 = lshr i32 %303, 16"
"  %307 = lshr i32 %303, 16" -> "  %309 = add nuw nsw i32 %307, %308"
"  %308 = and i32 %306, 65535"
"  %308 = and i32 %306, 65535" -> "  %309 = add nuw nsw i32 %307, %308"
"  %309 = add nuw nsw i32 %307, %308"
"  %309 = add nuw nsw i32 %307, %308" -> "  %311 = add nuw nsw i32 %309, %310"
"  %310 = and i32 %306, 2147418112"
"  %310 = and i32 %306, 2147418112" -> "  %311 = add nuw nsw i32 %309, %310"
"  %311 = add nuw nsw i32 %309, %310"
"  %311 = add nuw nsw i32 %309, %310" -> "  %332 = lshr i32 %311, 16""  %311 = add nuw nsw i32 %309, %310" -> "  %313 = and i32 %311, 65535"
"  %312 = mul nuw nsw i32 %95, 23650"
"  %312 = mul nuw nsw i32 %95, 23650" -> "  %327 = lshr i32 %312, 16""  %312 = mul nuw nsw i32 %95, 23650" -> "  %314 = and i32 %312, 65534"
"  %313 = and i32 %311, 65535"
"  %313 = and i32 %311, 65535" -> "  %315 = add nuw nsw i32 %313, %314"
"  %314 = and i32 %312, 65534"
"  %314 = and i32 %312, 65534" -> "  %315 = add nuw nsw i32 %313, %314"
"  %315 = add nuw nsw i32 %313, %314"
"  %315 = add nuw nsw i32 %313, %314" -> "  %336 = and i32 %315, 65535""  %315 = add nuw nsw i32 %313, %314" -> "  %334 = lshr i32 %315, 16"
"  %316 = bitcast i8* %171 to i32*"
"  %316 = bitcast i8* %171 to i32*" -> "  %20636 = load i32, i32* %316, align 1, !noalias !87""  %316 = bitcast i8* %171 to i32*" -> "  store i32 %17376, i32* %316, align 1, !noalias !47"
"  %317 = mul nuw nsw i32 %98, 23650"
"  %317 = mul nuw nsw i32 %98, 23650" -> "  %368 = add i32 %367, %317"
"  %318 = mul nuw nsw i32 %69, 29319"
"  %318 = mul nuw nsw i32 %69, 29319" -> "  %367 = add nuw i32 %318, %321"
"  %319 = mul nuw nsw i32 %69, 18212"
"  %319 = mul nuw nsw i32 %69, 18212" -> "  %337 = and i32 %319, 65532""  %319 = mul nuw nsw i32 %69, 18212" -> "  %320 = lshr i32 %319, 16"
"  %320 = lshr i32 %319, 16"
"  %320 = lshr i32 %319, 16" -> "  %369 = add i32 %368, %320"
"  %321 = mul nuw nsw i32 %66, 18212"
"  %321 = mul nuw nsw i32 %66, 18212" -> "  %367 = add nuw i32 %318, %321"
"  %322 = mul nuw nsw i32 %95, 10135"
"  %322 = mul nuw nsw i32 %95, 10135" -> "  %370 = add i32 %369, %322"
"  %323 = mul nuw i32 %223, 60287"
"  %323 = mul nuw i32 %223, 60287" -> "  %372 = add i32 %371, %323"
"  %324 = lshr i64 %193, 48"
"  %324 = lshr i64 %193, 48" -> "  %325 = trunc i64 %324 to i32"
"  %325 = trunc i64 %324 to i32"
"  %325 = trunc i64 %324 to i32" -> "  %326 = mul nuw nsw i32 %325, 6717"
"  %326 = mul nuw nsw i32 %325, 6717"
"  %326 = mul nuw nsw i32 %325, 6717" -> "  %373 = add i32 %372, %326"
"  %327 = lshr i32 %312, 16"
"  %327 = lshr i32 %312, 16" -> "  %371 = add i32 %370, %327"
"  %328 = lshr i32 %264, 16"
"  %328 = lshr i32 %264, 16" -> "  %375 = add i32 %374, %328"
"  %329 = mul nuw i32 %231, 54862"
"  %329 = mul nuw i32 %231, 54862" -> "  %376 = add i32 %375, %329"
"  %330 = mul nuw nsw i32 %254, 1564"
"  %330 = mul nuw nsw i32 %254, 1564" -> "  %377 = add i32 %376, %330"
"  %331 = lshr i32 %257, 16"
"  %331 = lshr i32 %257, 16" -> "  %378 = add i32 %377, %331"
"  %332 = lshr i32 %311, 16"
"  %332 = lshr i32 %311, 16" -> "  %374 = add i32 %373, %332"
"  %333 = lshr i32 %250, 16"
"  %333 = lshr i32 %250, 16" -> "  %381 = add i32 %380, %333"
"  %334 = lshr i32 %315, 16"
"  %334 = lshr i32 %315, 16" -> "  %379 = add i32 %378, %334"
"  %335 = lshr i32 %263, 16"
"  %335 = lshr i32 %263, 16" -> "  %382 = add i32 %381, %335"
"  %336 = and i32 %315, 65535"
"  %336 = and i32 %315, 65535" -> "  %338 = add nuw nsw i32 %336, %337"
"  %337 = and i32 %319, 65532"
"  %337 = and i32 %319, 65532" -> "  %338 = add nuw nsw i32 %336, %337"
"  %338 = add nuw nsw i32 %336, %337"
"  %338 = add nuw nsw i32 %336, %337" -> "  %343 = and i32 %338, 65535""  %338 = add nuw nsw i32 %336, %337" -> "  %339 = lshr i32 %338, 16"
"  %339 = lshr i32 %338, 16"
"  %339 = lshr i32 %338, 16" -> "  %380 = add i32 %379, %339"
"  %340 = and i32 %276, 65535"
"  %340 = and i32 %276, 65535" -> "  %354 = add nuw nsw i32 %340, %353"
"  %341 = and i32 %282, 65535"
"  %341 = and i32 %282, 65535" -> "  %356 = add nuw nsw i32 %341, %342"
"  %342 = and i32 %303, 65535"
"  %342 = and i32 %303, 65535" -> "  %356 = add nuw nsw i32 %341, %342"
"  %343 = and i32 %338, 65535"
"  %343 = and i32 %338, 65535" -> "  %362 = add nuw nsw i32 %351, %343"
"  %344 = and i32 %70, 65535"
"  %344 = and i32 %70, 65535" -> "  %16734 = mul nuw i32 %16733, %344""  %344 = and i32 %70, 65535" -> "  %16731 = mul nuw i32 %16730, %344""  %344 = and i32 %70, 65535" -> "  %16714 = mul nuw i32 %16713, %344""  %344 = and i32 %70, 65535" -> "  %16711 = mul nuw i32 %16710, %344""  %344 = and i32 %70, 65535" -> "  %16603 = mul nuw i32 %16600, %344""  %344 = and i32 %70, 65535" -> "  %16601 = mul nuw i32 %16599, %344""  %344 = and i32 %70, 65535" -> "  %16583 = mul nuw i32 %16580, %344""  %344 = and i32 %70, 65535" -> "  %16581 = mul nuw i32 %16579, %344""  %344 = and i32 %70, 65535" -> "  %550 = mul nuw i32 %549, %344""  %344 = and i32 %70, 65535" -> "  %547 = mul nuw i32 %546, %344""  %344 = and i32 %70, 65535" -> "  %518 = mul nuw i32 %515, %344""  %344 = and i32 %70, 65535" -> "  %516 = mul nuw i32 %514, %344""  %344 = and i32 %70, 65535" -> "  %411 = mul nuw i32 %347, %344""  %344 = and i32 %70, 65535" -> "  %409 = mul nuw i32 %346, %344""  %344 = and i32 %70, 65535" -> "  %394 = mul nuw i32 %345, %344""  %344 = and i32 %70, 65535" -> "  %392 = mul nuw i32 %344, %344""  %344 = and i32 %70, 65535" -> "  %392 = mul nuw i32 %344, %344"
"  %345 = and i32 %83, 65535"
"  %345 = and i32 %83, 65535" -> "  %16743 = mul nuw i32 %16733, %345""  %345 = and i32 %83, 65535" -> "  %16739 = mul nuw i32 %16730, %345""  %345 = and i32 %83, 65535" -> "  %16723 = mul nuw i32 %16713, %345""  %345 = and i32 %83, 65535" -> "  %16719 = mul nuw i32 %16710, %345""  %345 = and i32 %83, 65535" -> "  %16612 = mul nuw i32 %16600, %345""  %345 = and i32 %83, 65535" -> "  %16608 = mul nuw i32 %16599, %345""  %345 = and i32 %83, 65535" -> "  %16592 = mul nuw i32 %16580, %345""  %345 = and i32 %83, 65535" -> "  %16588 = mul nuw i32 %16579, %345""  %345 = and i32 %83, 65535" -> "  %572 = mul nuw i32 %549, %345""  %345 = and i32 %83, 65535" -> "  %553 = mul nuw i32 %546, %345""  %345 = and i32 %83, 65535" -> "  %537 = mul nuw i32 %515, %345""  %345 = and i32 %83, 65535" -> "  %521 = mul nuw i32 %514, %345""  %345 = and i32 %83, 65535" -> "  %427 = mul nuw i32 %347, %345""  %345 = and i32 %83, 65535" -> "  %414 = mul nuw i32 %346, %345""  %345 = and i32 %83, 65535" -> "  %394 = mul nuw i32 %345, %344""  %345 = and i32 %83, 65535" -> "  %403 = mul nuw i32 %345, %345""  %345 = and i32 %83, 65535" -> "  %403 = mul nuw i32 %345, %345"
"  %346 = and i32 %150, 65535"
"  %346 = and i32 %150, 65535" -> "  %16796 = mul nuw i32 %16733, %346""  %346 = and i32 %150, 65535" -> "  %16794 = mul nuw i32 %16730, %346""  %346 = and i32 %150, 65535" -> "  %16765 = mul nuw i32 %16713, %346""  %346 = and i32 %150, 65535" -> "  %16763 = mul nuw i32 %16710, %346""  %346 = and i32 %150, 65535" -> "  %16665 = mul nuw i32 %16600, %346""  %346 = and i32 %150, 65535" -> "  %16663 = mul nuw i32 %16599, %346""  %346 = and i32 %150, 65535" -> "  %16634 = mul nuw i32 %16580, %346""  %346 = and i32 %150, 65535" -> "  %16632 = mul nuw i32 %16579, %346""  %346 = and i32 %150, 65535" -> "  %652 = mul nuw i32 %549, %346""  %346 = and i32 %150, 65535" -> "  %649 = mul nuw i32 %546, %346""  %346 = and i32 %150, 65535" -> "  %602 = mul nuw i32 %515, %346""  %346 = and i32 %150, 65535" -> "  %600 = mul nuw i32 %514, %346""  %346 = and i32 %150, 65535" -> "  %470 = mul nuw i32 %347, %346""  %346 = and i32 %150, 65535" -> "  %414 = mul nuw i32 %346, %345""  %346 = and i32 %150, 65535" -> "  %409 = mul nuw i32 %346, %344""  %346 = and i32 %150, 65535" -> "  %468 = mul nuw i32 %346, %346""  %346 = and i32 %150, 65535" -> "  %468 = mul nuw i32 %346, %346"
"  %347 = and i32 %159, 65535"
"  %347 = and i32 %159, 65535" -> "  %16805 = mul nuw i32 %16733, %347""  %347 = and i32 %159, 65535" -> "  %16801 = mul nuw i32 %16730, %347""  %347 = and i32 %159, 65535" -> "  %16774 = mul nuw i32 %16713, %347""  %347 = and i32 %159, 65535" -> "  %16770 = mul nuw i32 %16710, %347""  %347 = and i32 %159, 65535" -> "  %16674 = mul nuw i32 %16600, %347""  %347 = and i32 %159, 65535" -> "  %16670 = mul nuw i32 %16599, %347""  %347 = and i32 %159, 65535" -> "  %16643 = mul nuw i32 %16580, %347""  %347 = and i32 %159, 65535" -> "  %16639 = mul nuw i32 %16579, %347""  %347 = and i32 %159, 65535" -> "  %668 = mul nuw i32 %549, %347""  %347 = and i32 %159, 65535" -> "  %653 = mul nuw i32 %546, %347""  %347 = and i32 %159, 65535" -> "  %621 = mul nuw i32 %515, %347""  %347 = and i32 %159, 65535" -> "  %605 = mul nuw i32 %514, %347""  %347 = and i32 %159, 65535" -> "  %470 = mul nuw i32 %347, %346""  %347 = and i32 %159, 65535" -> "  %427 = mul nuw i32 %347, %345""  %347 = and i32 %159, 65535" -> "  %411 = mul nuw i32 %347, %344""  %347 = and i32 %159, 65535" -> "  %478 = mul nuw i32 %347, %347""  %347 = and i32 %159, 65535" -> "  %478 = mul nuw i32 %347, %347"
"  %348 = lshr i32 %270, 16"
"  %348 = lshr i32 %270, 16" -> "  %383 = add i32 %382, %348"
"  %349 = lshr i32 %218, 16"
"  %349 = lshr i32 %218, 16" -> "  %384 = add i32 %383, %349"
"  %350 = lshr i32 %285, 16"
"  %350 = lshr i32 %285, 16" -> "  %385 = add i32 %384, %350"
"  %351 = and i32 %293, 65535"
"  %351 = and i32 %293, 65535" -> "  %362 = add nuw nsw i32 %351, %343"
"  %352 = lshr i32 %293, 16"
"  %352 = lshr i32 %293, 16" -> "  %386 = add i32 %385, %352"
"  %353 = and i32 %294, 65534"
"  %353 = and i32 %294, 65534" -> "  %354 = add nuw nsw i32 %340, %353"
"  %354 = add nuw nsw i32 %340, %353"
"  %354 = add nuw nsw i32 %340, %353" -> "  %514 = and i32 %354, 65535""  %354 = add nuw nsw i32 %340, %353" -> "  %355 = lshr i32 %354, 16"
"  %355 = lshr i32 %354, 16"
"  %355 = lshr i32 %354, 16" -> "  %359 = add nuw nsw i32 %357, %355"
"  %356 = add nuw nsw i32 %341, %342"
"  %356 = add nuw nsw i32 %341, %342" -> "  %358 = lshr i32 %356, 16""  %356 = add nuw nsw i32 %341, %342" -> "  %357 = and i32 %356, 65535"
"  %357 = and i32 %356, 65535"
"  %357 = and i32 %356, 65535" -> "  %359 = add nuw nsw i32 %357, %355"
"  %358 = lshr i32 %356, 16"
"  %358 = lshr i32 %356, 16" -> "  %361 = add nuw nsw i32 %360, %358"
"  %359 = add nuw nsw i32 %357, %355"
"  %359 = add nuw nsw i32 %357, %355" -> "  %515 = and i32 %359, 65535""  %359 = add nuw nsw i32 %357, %355" -> "  %360 = lshr i32 %359, 16"
"  %360 = lshr i32 %359, 16"
"  %360 = lshr i32 %359, 16" -> "  %361 = add nuw nsw i32 %360, %358"
"  %361 = add nuw nsw i32 %360, %358"
"  %361 = add nuw nsw i32 %360, %358" -> "  %365 = add nuw nsw i32 %361, %363"
"  %362 = add nuw nsw i32 %351, %343"
"  %362 = add nuw nsw i32 %351, %343" -> "  %364 = lshr i32 %362, 16""  %362 = add nuw nsw i32 %351, %343" -> "  %363 = and i32 %362, 65535"
"  %363 = and i32 %362, 65535"
"  %363 = and i32 %362, 65535" -> "  %365 = add nuw nsw i32 %361, %363"
"  %364 = lshr i32 %362, 16"
"  %364 = lshr i32 %362, 16" -> "  %387 = add i32 %386, %364"
"  %365 = add nuw nsw i32 %361, %363"
"  %365 = add nuw nsw i32 %361, %363" -> "  %546 = and i32 %365, 65535""  %365 = add nuw nsw i32 %361, %363" -> "  %366 = lshr i32 %365, 16"
"  %366 = lshr i32 %365, 16"
"  %366 = lshr i32 %365, 16" -> "  %388 = add i32 %387, %366"
"  %367 = add nuw i32 %318, %321"
"  %367 = add nuw i32 %318, %321" -> "  %368 = add i32 %367, %317"
"  %368 = add i32 %367, %317"
"  %368 = add i32 %367, %317" -> "  %369 = add i32 %368, %320"
"  %369 = add i32 %368, %320"
"  %369 = add i32 %368, %320" -> "  %370 = add i32 %369, %322"
"  %370 = add i32 %369, %322"
"  %370 = add i32 %369, %322" -> "  %371 = add i32 %370, %327"
"  %371 = add i32 %370, %327"
"  %371 = add i32 %370, %327" -> "  %372 = add i32 %371, %323"
"  %372 = add i32 %371, %323"
"  %372 = add i32 %371, %323" -> "  %373 = add i32 %372, %326"
"  %373 = add i32 %372, %326"
"  %373 = add i32 %372, %326" -> "  %374 = add i32 %373, %332"
"  %374 = add i32 %373, %332"
"  %374 = add i32 %373, %332" -> "  %375 = add i32 %374, %328"
"  %375 = add i32 %374, %328"
"  %375 = add i32 %374, %328" -> "  %376 = add i32 %375, %329"
"  %376 = add i32 %375, %329"
"  %376 = add i32 %375, %329" -> "  %377 = add i32 %376, %330"
"  %377 = add i32 %376, %330"
"  %377 = add i32 %376, %330" -> "  %378 = add i32 %377, %331"
"  %378 = add i32 %377, %331"
"  %378 = add i32 %377, %331" -> "  %379 = add i32 %378, %334"
"  %379 = add i32 %378, %334"
"  %379 = add i32 %378, %334" -> "  %380 = add i32 %379, %339"
"  %380 = add i32 %379, %339"
"  %380 = add i32 %379, %339" -> "  %381 = add i32 %380, %333"
"  %381 = add i32 %380, %333"
"  %381 = add i32 %380, %333" -> "  %382 = add i32 %381, %335"
"  %382 = add i32 %381, %335"
"  %382 = add i32 %381, %335" -> "  %383 = add i32 %382, %348"
"  %383 = add i32 %382, %348"
"  %383 = add i32 %382, %348" -> "  %384 = add i32 %383, %349"
"  %384 = add i32 %383, %349"
"  %384 = add i32 %383, %349" -> "  %385 = add i32 %384, %350"
"  %385 = add i32 %384, %350"
"  %385 = add i32 %384, %350" -> "  %386 = add i32 %385, %352"
"  %386 = add i32 %385, %352"
"  %386 = add i32 %385, %352" -> "  %387 = add i32 %386, %364"
"  %387 = add i32 %386, %364"
"  %387 = add i32 %386, %364" -> "  %388 = add i32 %387, %366"
"  %388 = add i32 %387, %366"
"  %388 = add i32 %387, %366" -> "  %549 = and i32 %388, 65535"
"  %389 = add i64 %18, -104"
"  %389 = add i64 %18, -104" -> "  %390 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %389"
"  %390 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %389"
"  %390 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %389" -> "  %391 = bitcast i8* %390 to i32*"
"  %391 = bitcast i8* %390 to i32*"
"  %391 = bitcast i8* %390 to i32*" -> "  store i32 %18659, i32* %391, align 1, !noalias !50"
"  %392 = mul nuw i32 %344, %344"
"  %392 = mul nuw i32 %344, %344" -> "  %1044 = and i32 %392, 65535""  %392 = mul nuw i32 %344, %344" -> "  %393 = lshr i32 %392, 16"
"  %393 = lshr i32 %392, 16"
"  %393 = lshr i32 %392, 16" -> "  %397 = add nuw nsw i32 %396, %393"
"  %394 = mul nuw i32 %345, %344"
"  %394 = mul nuw i32 %345, %344" -> "  %401 = add nuw i32 %399, %394""  %394 = mul nuw i32 %345, %344" -> "  %395 = and i32 %394, -65536""  %394 = mul nuw i32 %345, %344" -> "  %396 = and i32 %394, 65535"
"  %395 = and i32 %394, -65536"
"  %395 = and i32 %394, -65536" -> "  %398 = add nuw i32 %397, %395"
"  %396 = and i32 %394, 65535"
"  %396 = and i32 %394, 65535" -> "  %397 = add nuw nsw i32 %396, %393"
"  %397 = add nuw nsw i32 %396, %393"
"  %397 = add nuw nsw i32 %396, %393" -> "  %398 = add nuw i32 %397, %395"
"  %398 = add nuw i32 %397, %395"
"  %398 = add nuw i32 %397, %395" -> "  %400 = lshr i32 %398, 16""  %398 = add nuw i32 %397, %395" -> "  %399 = and i32 %398, 65535"
"  %399 = and i32 %398, 65535"
"  %399 = and i32 %398, 65535" -> "  %401 = add nuw i32 %399, %394"
"  %400 = lshr i32 %398, 16"
"  %400 = lshr i32 %398, 16" -> "  %404 = add nuw i32 %400, %403"
"  %401 = add nuw i32 %399, %394"
"  %401 = add nuw i32 %399, %394" -> "  %1047 = and i32 %401, 65535""  %401 = add nuw i32 %399, %394" -> "  %402 = lshr i32 %401, 16"
"  %402 = lshr i32 %401, 16"
"  %402 = lshr i32 %401, 16" -> "  %407 = add nuw nsw i32 %402, %405"
"  %403 = mul nuw i32 %345, %345"
"  %403 = mul nuw i32 %345, %345" -> "  %404 = add nuw i32 %400, %403"
"  %404 = add nuw i32 %400, %403"
"  %404 = add nuw i32 %400, %403" -> "  %406 = and i32 %404, -65536""  %404 = add nuw i32 %400, %403" -> "  %405 = and i32 %404, 65535"
"  %405 = and i32 %404, 65535"
"  %405 = and i32 %404, 65535" -> "  %407 = add nuw nsw i32 %402, %405"
"  %406 = and i32 %404, -65536"
"  %406 = and i32 %404, -65536" -> "  %408 = add i32 %407, %406"
"  %407 = add nuw nsw i32 %402, %405"
"  %407 = add nuw nsw i32 %402, %405" -> "  %408 = add i32 %407, %406"
"  %408 = add i32 %407, %406"
"  %408 = add i32 %407, %406" -> "  %437 = and i32 %408, 65535""  %408 = add i32 %407, %406" -> "  %434 = lshr i32 %408, 16"
"  %409 = mul nuw i32 %346, %344"
"  %409 = mul nuw i32 %346, %344" -> "  %436 = and i32 %409, 65535""  %409 = mul nuw i32 %346, %344" -> "  %410 = lshr i32 %409, 16"
"  %410 = lshr i32 %409, 16"
"  %410 = lshr i32 %409, 16" -> "  %413 = add nuw nsw i32 %412, %410""  %410 = lshr i32 %409, 16" -> "  %416 = add nuw nsw i32 %410, %415"
"  %411 = mul nuw i32 %347, %344"
"  %411 = mul nuw i32 %347, %344" -> "  %412 = and i32 %411, 65535""  %411 = mul nuw i32 %347, %344" -> "  %421 = and i32 %411, -65536""  %411 = mul nuw i32 %347, %344" -> "  %420 = add nuw i32 %419, %411"
"  %412 = and i32 %411, 65535"
"  %412 = and i32 %411, 65535" -> "  %413 = add nuw nsw i32 %412, %410"
"  %413 = add nuw nsw i32 %412, %410"
"  %413 = add nuw nsw i32 %412, %410" -> "  %422 = add nuw i32 %413, %421"
"  %414 = mul nuw i32 %346, %345"
"  %414 = mul nuw i32 %346, %345" -> "  %424 = add nuw i32 %423, %414""  %414 = mul nuw i32 %346, %345" -> "  %415 = and i32 %414, 65535""  %414 = mul nuw i32 %346, %345" -> "  %417 = and i32 %414, -65536"
"  %415 = and i32 %414, 65535"
"  %415 = and i32 %414, 65535" -> "  %416 = add nuw nsw i32 %410, %415"
"  %416 = add nuw nsw i32 %410, %415"
"  %416 = add nuw nsw i32 %410, %415" -> "  %418 = add nuw i32 %416, %417"
"  %417 = and i32 %414, -65536"
"  %417 = and i32 %414, -65536" -> "  %418 = add nuw i32 %416, %417"
"  %418 = add nuw i32 %416, %417"
"  %418 = add nuw i32 %416, %417" -> "  %449 = lshr i32 %418, 16""  %418 = add nuw i32 %416, %417" -> "  %419 = and i32 %418, 65535"
"  %419 = and i32 %418, 65535"
"  %419 = and i32 %418, 65535" -> "  %420 = add nuw i32 %419, %411"
"  %420 = add nuw i32 %419, %411"
"  %420 = add nuw i32 %419, %411" -> "  %459 = and i32 %420, 65535""  %420 = add nuw i32 %419, %411" -> "  %451 = lshr i32 %420, 16"
"  %421 = and i32 %411, -65536"
"  %421 = and i32 %411, -65536" -> "  %422 = add nuw i32 %413, %421"
"  %422 = add nuw i32 %413, %421"
"  %422 = add nuw i32 %413, %421" -> "  %425 = lshr i32 %422, 16""  %422 = add nuw i32 %413, %421" -> "  %423 = and i32 %422, 65535"
"  %423 = and i32 %422, 65535"
"  %423 = and i32 %422, 65535" -> "  %424 = add nuw i32 %423, %414"
"  %424 = add nuw i32 %423, %414"
"  %424 = add nuw i32 %423, %414" -> "  %433 = and i32 %424, 65535""  %424 = add nuw i32 %423, %414" -> "  %426 = lshr i32 %424, 16"
"  %425 = lshr i32 %422, 16"
"  %425 = lshr i32 %422, 16" -> "  %428 = add nuw i32 %425, %427"
"  %426 = lshr i32 %424, 16"
"  %426 = lshr i32 %424, 16" -> "  %430 = add nuw nsw i32 %426, %429"
"  %427 = mul nuw i32 %347, %345"
"  %427 = mul nuw i32 %347, %345" -> "  %428 = add nuw i32 %425, %427""  %427 = mul nuw i32 %347, %345" -> "  %450 = add nuw i32 %449, %427"
"  %428 = add nuw i32 %425, %427"
"  %428 = add nuw i32 %425, %427" -> "  %431 = and i32 %428, -65536""  %428 = add nuw i32 %425, %427" -> "  %429 = and i32 %428, 65535"
"  %429 = and i32 %428, 65535"
"  %429 = and i32 %428, 65535" -> "  %430 = add nuw nsw i32 %426, %429"
"  %430 = add nuw nsw i32 %426, %429"
"  %430 = add nuw nsw i32 %426, %429" -> "  %432 = add i32 %430, %431"
"  %431 = and i32 %428, -65536"
"  %431 = and i32 %428, -65536" -> "  %432 = add i32 %430, %431"
"  %432 = add i32 %430, %431"
"  %432 = add i32 %430, %431" -> "  %443 = and i32 %432, 65535""  %432 = add i32 %430, %431" -> "  %445 = and i32 %432, -65536"
"  %433 = and i32 %424, 65535"
"  %433 = and i32 %424, 65535" -> "  %435 = add nuw nsw i32 %433, %434"
"  %434 = lshr i32 %408, 16"
"  %434 = lshr i32 %408, 16" -> "  %435 = add nuw nsw i32 %433, %434"
"  %435 = add nuw nsw i32 %433, %434"
"  %435 = add nuw nsw i32 %433, %434" -> "  %440 = and i32 %435, 65535""  %435 = add nuw nsw i32 %433, %434" -> "  %442 = lshr i32 %435, 16"
"  %436 = and i32 %409, 65535"
"  %436 = and i32 %409, 65535" -> "  %457 = add nuw nsw i32 %456, %436""  %436 = and i32 %409, 65535" -> "  %438 = add nuw nsw i32 %437, %436"
"  %437 = and i32 %408, 65535"
"  %437 = and i32 %408, 65535" -> "  %438 = add nuw nsw i32 %437, %436"
"  %438 = add nuw nsw i32 %437, %436"
"  %438 = add nuw nsw i32 %437, %436" -> "  %456 = and i32 %438, 65535""  %438 = add nuw nsw i32 %437, %436" -> "  %439 = lshr i32 %438, 16"
"  %439 = lshr i32 %438, 16"
"  %439 = lshr i32 %438, 16" -> "  %441 = add nuw nsw i32 %440, %439"
"  %440 = and i32 %435, 65535"
"  %440 = and i32 %435, 65535" -> "  %441 = add nuw nsw i32 %440, %439"
"  %441 = add nuw nsw i32 %440, %439"
"  %441 = add nuw nsw i32 %440, %439" -> "  %458 = and i32 %441, 65535""  %441 = add nuw nsw i32 %440, %439" -> "  %446 = lshr i32 %441, 16"
"  %442 = lshr i32 %435, 16"
"  %442 = lshr i32 %435, 16" -> "  %444 = add nuw nsw i32 %443, %442"
"  %443 = and i32 %432, 65535"
"  %443 = and i32 %432, 65535" -> "  %444 = add nuw nsw i32 %443, %442"
"  %444 = add nuw nsw i32 %443, %442"
"  %444 = add nuw nsw i32 %443, %442" -> "  %447 = add i32 %444, %445"
"  %445 = and i32 %432, -65536"
"  %445 = and i32 %432, -65536" -> "  %447 = add i32 %444, %445"
"  %446 = lshr i32 %441, 16"
"  %446 = lshr i32 %441, 16" -> "  %448 = add i32 %447, %446"
"  %447 = add i32 %444, %445"
"  %447 = add i32 %444, %445" -> "  %448 = add i32 %447, %446"
"  %448 = add i32 %447, %446"
"  %448 = add i32 %447, %446" -> "  %489 = lshr i32 %448, 16""  %448 = add i32 %447, %446" -> "  %485 = and i32 %448, 65535"
"  %449 = lshr i32 %418, 16"
"  %449 = lshr i32 %418, 16" -> "  %450 = add nuw i32 %449, %427"
"  %450 = add nuw i32 %449, %427"
"  %450 = add nuw i32 %449, %427" -> "  %454 = and i32 %450, -65536""  %450 = add nuw i32 %449, %427" -> "  %452 = and i32 %450, 65535"
"  %451 = lshr i32 %420, 16"
"  %451 = lshr i32 %420, 16" -> "  %453 = add nuw nsw i32 %451, %452"
"  %452 = and i32 %450, 65535"
"  %452 = and i32 %450, 65535" -> "  %453 = add nuw nsw i32 %451, %452"
"  %453 = add nuw nsw i32 %451, %452"
"  %453 = add nuw nsw i32 %451, %452" -> "  %455 = add i32 %453, %454"
"  %454 = and i32 %450, -65536"
"  %454 = and i32 %450, -65536" -> "  %455 = add i32 %453, %454"
"  %455 = add i32 %453, %454"
"  %455 = add i32 %453, %454" -> "  %462 = add i32 %455, %461"
"  %456 = and i32 %438, 65535"
"  %456 = and i32 %438, 65535" -> "  %457 = add nuw nsw i32 %456, %436"
"  %457 = add nuw nsw i32 %456, %436"
"  %457 = add nuw nsw i32 %456, %436" -> "  %1064 = and i32 %457, 65535""  %457 = add nuw nsw i32 %456, %436" -> "  %464 = lshr i32 %457, 16"
"  %458 = and i32 %441, 65535"
"  %458 = and i32 %441, 65535" -> "  %460 = add nuw nsw i32 %458, %459"
"  %459 = and i32 %420, 65535"
"  %459 = and i32 %420, 65535" -> "  %460 = add nuw nsw i32 %458, %459"
"  %460 = add nuw nsw i32 %458, %459"
"  %460 = add nuw nsw i32 %458, %459" -> "  %463 = and i32 %460, 65535""  %460 = add nuw nsw i32 %458, %459" -> "  %461 = lshr i32 %460, 16"
"  %461 = lshr i32 %460, 16"
"  %461 = lshr i32 %460, 16" -> "  %462 = add i32 %455, %461"
"  %462 = add i32 %455, %461"
"  %462 = add i32 %455, %461" -> "  %467 = add i32 %462, %466"
"  %463 = and i32 %460, 65535"
"  %463 = and i32 %460, 65535" -> "  %465 = add nuw nsw i32 %463, %464"
"  %464 = lshr i32 %457, 16"
"  %464 = lshr i32 %457, 16" -> "  %465 = add nuw nsw i32 %463, %464"
"  %465 = add nuw nsw i32 %463, %464"
"  %465 = add nuw nsw i32 %463, %464" -> "  %1065 = and i32 %465, 65535""  %465 = add nuw nsw i32 %463, %464" -> "  %466 = lshr i32 %465, 16"
"  %466 = lshr i32 %465, 16"
"  %466 = lshr i32 %465, 16" -> "  %467 = add i32 %462, %466"
"  %467 = add i32 %462, %466"
"  %467 = add i32 %462, %466" -> "  %502 = lshr i32 %467, 16""  %467 = add i32 %462, %466" -> "  %499 = and i32 %467, 65535"
"  %468 = mul nuw i32 %346, %346"
"  %468 = mul nuw i32 %346, %346" -> "  %486 = and i32 %468, 65535""  %468 = mul nuw i32 %346, %346" -> "  %469 = lshr i32 %468, 16"
"  %469 = lshr i32 %468, 16"
"  %469 = lshr i32 %468, 16" -> "  %472 = add nuw nsw i32 %471, %469"
"  %470 = mul nuw i32 %347, %346"
"  %470 = mul nuw i32 %347, %346" -> "  %476 = add nuw i32 %475, %470""  %470 = mul nuw i32 %347, %346" -> "  %473 = and i32 %470, -65536""  %470 = mul nuw i32 %347, %346" -> "  %471 = and i32 %470, 65535"
"  %471 = and i32 %470, 65535"
"  %471 = and i32 %470, 65535" -> "  %472 = add nuw nsw i32 %471, %469"
"  %472 = add nuw nsw i32 %471, %469"
"  %472 = add nuw nsw i32 %471, %469" -> "  %474 = add nuw i32 %472, %473"
"  %473 = and i32 %470, -65536"
"  %473 = and i32 %470, -65536" -> "  %474 = add nuw i32 %472, %473"
"  %474 = add nuw i32 %472, %473"
"  %474 = add nuw i32 %472, %473" -> "  %477 = lshr i32 %474, 16""  %474 = add nuw i32 %472, %473" -> "  %475 = and i32 %474, 65535"
"  %475 = and i32 %474, 65535"
"  %475 = and i32 %474, 65535" -> "  %476 = add nuw i32 %475, %470"
"  %476 = add nuw i32 %475, %470"
"  %476 = add nuw i32 %475, %470" -> "  %488 = and i32 %476, 65535""  %476 = add nuw i32 %475, %470" -> "  %480 = lshr i32 %476, 16"
"  %477 = lshr i32 %474, 16"
"  %477 = lshr i32 %474, 16" -> "  %479 = add nuw i32 %477, %478"
"  %478 = mul nuw i32 %347, %347"
"  %478 = mul nuw i32 %347, %347" -> "  %479 = add nuw i32 %477, %478"
"  %479 = add nuw i32 %477, %478"
"  %479 = add nuw i32 %477, %478" -> "  %483 = and i32 %479, -65536""  %479 = add nuw i32 %477, %478" -> "  %481 = and i32 %479, 65535"
"  %480 = lshr i32 %476, 16"
"  %480 = lshr i32 %476, 16" -> "  %482 = add nuw nsw i32 %480, %481"
"  %481 = and i32 %479, 65535"
"  %481 = and i32 %479, 65535" -> "  %482 = add nuw nsw i32 %480, %481"
"  %482 = add nuw nsw i32 %480, %481"
"  %482 = add nuw nsw i32 %480, %481" -> "  %484 = add i32 %482, %483"
"  %483 = and i32 %479, -65536"
"  %483 = and i32 %479, -65536" -> "  %484 = add i32 %482, %483"
"  %484 = add i32 %482, %483"
"  %484 = add i32 %482, %483" -> "  %492 = add i32 %484, %491"
"  %485 = and i32 %448, 65535"
"  %485 = and i32 %448, 65535" -> "  %487 = add nuw nsw i32 %485, %486"
"  %486 = and i32 %468, 65535"
"  %486 = and i32 %468, 65535" -> "  %487 = add nuw nsw i32 %485, %486"
"  %487 = add nuw nsw i32 %485, %486"
"  %487 = add nuw nsw i32 %485, %486" -> "  %498 = and i32 %487, 65535""  %487 = add nuw nsw i32 %485, %486" -> "  %494 = lshr i32 %487, 16"
"  %488 = and i32 %476, 65535"
"  %488 = and i32 %476, 65535" -> "  %490 = add nuw nsw i32 %489, %488"
"  %489 = lshr i32 %448, 16"
"  %489 = lshr i32 %448, 16" -> "  %490 = add nuw nsw i32 %489, %488"
"  %490 = add nuw nsw i32 %489, %488"
"  %490 = add nuw nsw i32 %489, %488" -> "  %493 = and i32 %490, 65535""  %490 = add nuw nsw i32 %489, %488" -> "  %491 = lshr i32 %490, 16"
"  %491 = lshr i32 %490, 16"
"  %491 = lshr i32 %490, 16" -> "  %492 = add i32 %484, %491"
"  %492 = add i32 %484, %491"
"  %492 = add i32 %484, %491" -> "  %497 = add i32 %492, %496"
"  %493 = and i32 %490, 65535"
"  %493 = and i32 %490, 65535" -> "  %495 = add nuw nsw i32 %493, %494"
"  %494 = lshr i32 %487, 16"
"  %494 = lshr i32 %487, 16" -> "  %495 = add nuw nsw i32 %493, %494"
"  %495 = add nuw nsw i32 %493, %494"
"  %495 = add nuw nsw i32 %493, %494" -> "  %501 = and i32 %495, 65535""  %495 = add nuw nsw i32 %493, %494" -> "  %496 = lshr i32 %495, 16"
"  %496 = lshr i32 %495, 16"
"  %496 = lshr i32 %495, 16" -> "  %497 = add i32 %492, %496"
"  %497 = add i32 %492, %496"
"  %497 = add i32 %492, %496" -> "  %510 = and i32 %497, -65536""  %497 = add i32 %492, %496" -> "  %508 = and i32 %497, 65535"
"  %498 = and i32 %487, 65535"
"  %498 = and i32 %487, 65535" -> "  %500 = add nuw nsw i32 %499, %498"
"  %499 = and i32 %467, 65535"
"  %499 = and i32 %467, 65535" -> "  %500 = add nuw nsw i32 %499, %498"
"  %500 = add nuw nsw i32 %499, %498"
"  %500 = add nuw nsw i32 %499, %498" -> "  %710 = and i32 %500, 65535""  %500 = add nuw nsw i32 %499, %498" -> "  %504 = lshr i32 %500, 16"
"  %501 = and i32 %495, 65535"
"  %501 = and i32 %495, 65535" -> "  %503 = add nuw nsw i32 %501, %502"
"  %502 = lshr i32 %467, 16"
"  %502 = lshr i32 %467, 16" -> "  %503 = add nuw nsw i32 %501, %502"
"  %503 = add nuw nsw i32 %501, %502"
"  %503 = add nuw nsw i32 %501, %502" -> "  %507 = lshr i32 %503, 16""  %503 = add nuw nsw i32 %501, %502" -> "  %505 = and i32 %503, 65535"
"  %504 = lshr i32 %500, 16"
"  %504 = lshr i32 %500, 16" -> "  %506 = add nuw nsw i32 %505, %504"
"  %505 = and i32 %503, 65535"
"  %505 = and i32 %503, 65535" -> "  %506 = add nuw nsw i32 %505, %504"
"  %506 = add nuw nsw i32 %505, %504"
"  %506 = add nuw nsw i32 %505, %504" -> "  %707 = and i32 %506, 65535""  %506 = add nuw nsw i32 %505, %504" -> "  %512 = lshr i32 %506, 16"
"  %507 = lshr i32 %503, 16"
"  %507 = lshr i32 %503, 16" -> "  %509 = add nuw nsw i32 %507, %508"
"  %508 = and i32 %497, 65535"
"  %508 = and i32 %497, 65535" -> "  %509 = add nuw nsw i32 %507, %508"
"  %509 = add nuw nsw i32 %507, %508"
"  %509 = add nuw nsw i32 %507, %508" -> "  %511 = add i32 %509, %510"
"  %510 = and i32 %497, -65536"
"  %510 = and i32 %497, -65536" -> "  %511 = add i32 %509, %510"
"  %511 = add i32 %509, %510"
"  %511 = add i32 %509, %510" -> "  %513 = add i32 %511, %512"
"  %512 = lshr i32 %506, 16"
"  %512 = lshr i32 %506, 16" -> "  %513 = add i32 %511, %512"
"  %513 = add i32 %511, %512"
"  %513 = add i32 %511, %512" -> "  %719 = and i32 %513, 65535""  %513 = add i32 %511, %512" -> "  %722 = lshr i32 %513, 16"
"  %514 = and i32 %354, 65535"
"  %514 = and i32 %354, 65535" -> "  %17061 = mul nuw i32 %16733, %514""  %514 = and i32 %354, 65535" -> "  %17059 = mul nuw i32 %16730, %514""  %514 = and i32 %354, 65535" -> "  %17043 = mul nuw i32 %16713, %514""  %514 = and i32 %354, 65535" -> "  %17041 = mul nuw i32 %16710, %514""  %514 = and i32 %354, 65535" -> "  %16896 = mul nuw i32 %16600, %514""  %514 = and i32 %354, 65535" -> "  %16894 = mul nuw i32 %16599, %514""  %514 = and i32 %354, 65535" -> "  %16878 = mul nuw i32 %16580, %514""  %514 = and i32 %354, 65535" -> "  %16876 = mul nuw i32 %16579, %514""  %514 = and i32 %354, 65535" -> "  %874 = mul nuw i32 %549, %514""  %514 = and i32 %354, 65535" -> "  %872 = mul nuw i32 %546, %514""  %514 = and i32 %354, 65535" -> "  %860 = mul nuw i32 %515, %514""  %514 = and i32 %354, 65535" -> "  %605 = mul nuw i32 %514, %347""  %514 = and i32 %354, 65535" -> "  %600 = mul nuw i32 %514, %346""  %514 = and i32 %354, 65535" -> "  %521 = mul nuw i32 %514, %345""  %514 = and i32 %354, 65535" -> "  %516 = mul nuw i32 %514, %344""  %514 = and i32 %354, 65535" -> "  %858 = mul nuw i32 %514, %514""  %514 = and i32 %354, 65535" -> "  %858 = mul nuw i32 %514, %514"
"  %515 = and i32 %359, 65535"
"  %515 = and i32 %359, 65535" -> "  %17067 = mul nuw i32 %16733, %515""  %515 = and i32 %359, 65535" -> "  %17063 = mul nuw i32 %16730, %515""  %515 = and i32 %359, 65535" -> "  %17052 = mul nuw i32 %16713, %515""  %515 = and i32 %359, 65535" -> "  %17048 = mul nuw i32 %16710, %515""  %515 = and i32 %359, 65535" -> "  %16905 = mul nuw i32 %16600, %515""  %515 = and i32 %359, 65535" -> "  %16901 = mul nuw i32 %16599, %515""  %515 = and i32 %359, 65535" -> "  %16887 = mul nuw i32 %16580, %515""  %515 = and i32 %359, 65535" -> "  %16883 = mul nuw i32 %16579, %515""  %515 = and i32 %359, 65535" -> "  %884 = mul nuw i32 %549, %515""  %515 = and i32 %359, 65535" -> "  %875 = mul nuw i32 %546, %515""  %515 = and i32 %359, 65535" -> "  %860 = mul nuw i32 %515, %514""  %515 = and i32 %359, 65535" -> "  %621 = mul nuw i32 %515, %347""  %515 = and i32 %359, 65535" -> "  %602 = mul nuw i32 %515, %346""  %515 = and i32 %359, 65535" -> "  %537 = mul nuw i32 %515, %345""  %515 = and i32 %359, 65535" -> "  %518 = mul nuw i32 %515, %344""  %515 = and i32 %359, 65535" -> "  %865 = mul nuw i32 %515, %515""  %515 = and i32 %359, 65535" -> "  %865 = mul nuw i32 %515, %515"
"  %516 = mul nuw i32 %514, %344"
"  %516 = mul nuw i32 %514, %344" -> "  %709 = and i32 %516, 65535""  %516 = mul nuw i32 %514, %344" -> "  %517 = lshr i32 %516, 16"
"  %517 = lshr i32 %516, 16"
"  %517 = lshr i32 %516, 16" -> "  %520 = add nuw nsw i32 %519, %517""  %517 = lshr i32 %516, 16" -> "  %523 = add nuw nsw i32 %522, %517"
"  %518 = mul nuw i32 %515, %344"
"  %518 = mul nuw i32 %515, %344" -> "  %527 = add nuw i32 %518, %526""  %518 = mul nuw i32 %515, %344" -> "  %528 = and i32 %518, -65536""  %518 = mul nuw i32 %515, %344" -> "  %519 = and i32 %518, 65535"
"  %519 = and i32 %518, 65535"
"  %519 = and i32 %518, 65535" -> "  %520 = add nuw nsw i32 %519, %517"
"  %520 = add nuw nsw i32 %519, %517"
"  %520 = add nuw nsw i32 %519, %517" -> "  %529 = add nuw i32 %520, %528"
"  %521 = mul nuw i32 %514, %345"
"  %521 = mul nuw i32 %514, %345" -> "  %531 = add nuw i32 %530, %521""  %521 = mul nuw i32 %514, %345" -> "  %524 = and i32 %521, -65536""  %521 = mul nuw i32 %514, %345" -> "  %522 = and i32 %521, 65535"
"  %522 = and i32 %521, 65535"
"  %522 = and i32 %521, 65535" -> "  %523 = add nuw nsw i32 %522, %517"
"  %523 = add nuw nsw i32 %522, %517"
"  %523 = add nuw nsw i32 %522, %517" -> "  %525 = add nuw i32 %523, %524"
"  %524 = and i32 %521, -65536"
"  %524 = and i32 %521, -65536" -> "  %525 = add nuw i32 %523, %524"
"  %525 = add nuw i32 %523, %524"
"  %525 = add nuw i32 %523, %524" -> "  %744 = lshr i32 %525, 16""  %525 = add nuw i32 %523, %524" -> "  %526 = and i32 %525, 65535"
"  %526 = and i32 %525, 65535"
"  %526 = and i32 %525, 65535" -> "  %527 = add nuw i32 %518, %526"
"  %527 = add nuw i32 %518, %526"
"  %527 = add nuw i32 %518, %526" -> "  %746 = lshr i32 %527, 16""  %527 = add nuw i32 %518, %526" -> "  %821 = and i32 %527, 65535"
"  %528 = and i32 %518, -65536"
"  %528 = and i32 %518, -65536" -> "  %529 = add nuw i32 %520, %528"
"  %529 = add nuw i32 %520, %528"
"  %529 = add nuw i32 %520, %528" -> "  %535 = lshr i32 %529, 16""  %529 = add nuw i32 %520, %528" -> "  %530 = and i32 %529, 65535"
"  %530 = and i32 %529, 65535"
"  %530 = and i32 %529, 65535" -> "  %531 = add nuw i32 %530, %521"
"  %531 = add nuw i32 %530, %521"
"  %531 = add nuw i32 %530, %521" -> "  %706 = and i32 %531, 65535""  %531 = add nuw i32 %530, %521" -> "  %536 = lshr i32 %531, 16"
"  %532 = add i64 %18, -272"
"  %532 = add i64 %18, -272" -> "  %533 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %532"
"  %533 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %532"
"  %533 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %532" -> "  %534 = bitcast i8* %533 to i32*"
"  %534 = bitcast i8* %533 to i32*"
"  %534 = bitcast i8* %533 to i32*" -> "  store i32 %18670, i32* %534, align 1, !noalias !50"
"  %535 = lshr i32 %529, 16"
"  %535 = lshr i32 %529, 16" -> "  %541 = add nuw i32 %535, %537"
"  %536 = lshr i32 %531, 16"
"  %536 = lshr i32 %531, 16" -> "  %543 = add nuw nsw i32 %536, %542"
"  %537 = mul nuw i32 %515, %345"
"  %537 = mul nuw i32 %515, %345" -> "  %745 = add nuw i32 %537, %744""  %537 = mul nuw i32 %515, %345" -> "  %541 = add nuw i32 %535, %537"
"  %538 = add i64 %18, -260"
"  %538 = add i64 %18, -260" -> "  %539 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %538"
"  %539 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %538"
"  %539 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %538" -> "  %540 = bitcast i8* %539 to i32*"
"  %540 = bitcast i8* %539 to i32*"
"  %540 = bitcast i8* %539 to i32*" -> "  %20646 = load i32, i32* %540, align 1, !noalias !87""  %540 = bitcast i8* %539 to i32*" -> "  store i32 %17028, i32* %540, align 1, !noalias !41"
"  %541 = add nuw i32 %535, %537"
"  %541 = add nuw i32 %535, %537" -> "  %544 = and i32 %541, -65536""  %541 = add nuw i32 %535, %537" -> "  %542 = and i32 %541, 65535"
"  %542 = and i32 %541, 65535"
"  %542 = and i32 %541, 65535" -> "  %543 = add nuw nsw i32 %536, %542"
"  %543 = add nuw nsw i32 %536, %542"
"  %543 = add nuw nsw i32 %536, %542" -> "  %545 = add i32 %543, %544"
"  %544 = and i32 %541, -65536"
"  %544 = and i32 %541, -65536" -> "  %545 = add i32 %543, %544"
"  %545 = add i32 %543, %544"
"  %545 = add i32 %543, %544" -> "  %588 = and i32 %545, 65535""  %545 = add i32 %543, %544" -> "  %582 = lshr i32 %545, 16"
"  %546 = and i32 %365, 65535"
"  %546 = and i32 %365, 65535" -> "  %17120 = mul nuw i32 %16733, %546""  %546 = and i32 %365, 65535" -> "  %17118 = mul nuw i32 %16730, %546""  %546 = and i32 %365, 65535" -> "  %17089 = mul nuw i32 %16713, %546""  %546 = and i32 %365, 65535" -> "  %17087 = mul nuw i32 %16710, %546""  %546 = and i32 %365, 65535" -> "  %16958 = mul nuw i32 %16600, %546""  %546 = and i32 %365, 65535" -> "  %16956 = mul nuw i32 %16599, %546""  %546 = and i32 %365, 65535" -> "  %16927 = mul nuw i32 %16580, %546""  %546 = and i32 %365, 65535" -> "  %16925 = mul nuw i32 %16579, %546""  %546 = and i32 %365, 65535" -> "  %924 = mul nuw i32 %549, %546""  %546 = and i32 %365, 65535" -> "  %875 = mul nuw i32 %546, %515""  %546 = and i32 %365, 65535" -> "  %872 = mul nuw i32 %546, %514""  %546 = and i32 %365, 65535" -> "  %653 = mul nuw i32 %546, %347""  %546 = and i32 %365, 65535" -> "  %649 = mul nuw i32 %546, %346""  %546 = and i32 %365, 65535" -> "  %553 = mul nuw i32 %546, %345""  %546 = and i32 %365, 65535" -> "  %547 = mul nuw i32 %546, %344""  %546 = and i32 %365, 65535" -> "  %922 = mul nuw i32 %546, %546""  %546 = and i32 %365, 65535" -> "  %922 = mul nuw i32 %546, %546"
"  %547 = mul nuw i32 %546, %344"
"  %547 = mul nuw i32 %546, %344" -> "  %585 = and i32 %547, 65535""  %547 = mul nuw i32 %546, %344" -> "  %548 = lshr i32 %547, 16"
"  %548 = lshr i32 %547, 16"
"  %548 = lshr i32 %547, 16" -> "  %552 = add nuw nsw i32 %551, %548""  %548 = lshr i32 %547, 16" -> "  %557 = add nuw i32 %548, %553"
"  %549 = and i32 %388, 65535"
"  %549 = and i32 %388, 65535" -> "  %17128 = mul nuw i32 %16733, %549""  %549 = and i32 %388, 65535" -> "  %17125 = mul nuw i32 %16730, %549""  %549 = and i32 %388, 65535" -> "  %17098 = mul nuw i32 %16713, %549""  %549 = and i32 %388, 65535" -> "  %17094 = mul nuw i32 %16710, %549""  %549 = and i32 %388, 65535" -> "  %16967 = mul nuw i32 %16600, %549""  %549 = and i32 %388, 65535" -> "  %16963 = mul nuw i32 %16599, %549""  %549 = and i32 %388, 65535" -> "  %16936 = mul nuw i32 %16580, %549""  %549 = and i32 %388, 65535" -> "  %16932 = mul nuw i32 %16579, %549""  %549 = and i32 %388, 65535" -> "  %924 = mul nuw i32 %549, %546""  %549 = and i32 %388, 65535" -> "  %884 = mul nuw i32 %549, %515""  %549 = and i32 %388, 65535" -> "  %874 = mul nuw i32 %549, %514""  %549 = and i32 %388, 65535" -> "  %668 = mul nuw i32 %549, %347""  %549 = and i32 %388, 65535" -> "  %652 = mul nuw i32 %549, %346""  %549 = and i32 %388, 65535" -> "  %572 = mul nuw i32 %549, %345""  %549 = and i32 %388, 65535" -> "  %550 = mul nuw i32 %549, %344""  %549 = and i32 %388, 65535" -> "  %932 = mul nuw i32 %549, %549""  %549 = and i32 %388, 65535" -> "  %932 = mul nuw i32 %549, %549"
"  %550 = mul nuw i32 %549, %344"
"  %550 = mul nuw i32 %549, %344" -> "  %562 = add nuw i32 %561, %550""  %550 = mul nuw i32 %549, %344" -> "  %566 = and i32 %550, -65536""  %550 = mul nuw i32 %549, %344" -> "  %551 = and i32 %550, 65535"
"  %551 = and i32 %550, 65535"
"  %551 = and i32 %550, 65535" -> "  %552 = add nuw nsw i32 %551, %548"
"  %552 = add nuw nsw i32 %551, %548"
"  %552 = add nuw nsw i32 %551, %548" -> "  %567 = add nuw i32 %552, %566"
"  %553 = mul nuw i32 %546, %345"
"  %553 = mul nuw i32 %546, %345" -> "  %569 = add nuw i32 %568, %553""  %553 = mul nuw i32 %546, %345" -> "  %557 = add nuw i32 %548, %553"
"  %554 = add i64 %18, -80"
"  %554 = add i64 %18, -80" -> "  %555 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %554"
"  %555 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %554"
"  %555 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %554" -> "  %556 = bitcast i8* %555 to i32*"
"  %556 = bitcast i8* %555 to i32*"
"  %556 = bitcast i8* %555 to i32*" -> "  store i32 %18656, i32* %556, align 1, !noalias !50"
"  %557 = add nuw i32 %548, %553"
"  %557 = add nuw i32 %548, %553" -> "  %770 = lshr i32 %557, 16""  %557 = add nuw i32 %548, %553" -> "  %561 = and i32 %557, 65535"
"  %558 = add i64 %18, -248"
"  %558 = add i64 %18, -248" -> "  %559 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %558"
"  %559 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %558"
"  %559 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %558" -> "  %560 = bitcast i8* %559 to i32*"
"  %560 = bitcast i8* %559 to i32*"
"  %560 = bitcast i8* %559 to i32*" -> "  store i32 %18668, i32* %560, align 1, !noalias !50"
"  %561 = and i32 %557, 65535"
"  %561 = and i32 %557, 65535" -> "  %562 = add nuw i32 %561, %550"
"  %562 = add nuw i32 %561, %550"
"  %562 = add nuw i32 %561, %550" -> "  %772 = lshr i32 %562, 16""  %562 = add nuw i32 %561, %550" -> "  %780 = and i32 %562, 65535"
"  %563 = add i64 %18, -264"
"  %563 = add i64 %18, -264" -> "  %564 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %563"
"  %564 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %563"
"  %564 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %563" -> "  %565 = bitcast i8* %564 to i32*"
"  %565 = bitcast i8* %564 to i32*"
"  %565 = bitcast i8* %564 to i32*" -> "  store i32 %18665, i32* %565, align 1, !noalias !50"
"  %566 = and i32 %550, -65536"
"  %566 = and i32 %550, -65536" -> "  %567 = add nuw i32 %552, %566"
"  %567 = add nuw i32 %552, %566"
"  %567 = add nuw i32 %552, %566" -> "  %570 = lshr i32 %567, 16""  %567 = add nuw i32 %552, %566" -> "  %568 = and i32 %567, 65535"
"  %568 = and i32 %567, 65535"
"  %568 = and i32 %567, 65535" -> "  %569 = add nuw i32 %568, %553"
"  %569 = add nuw i32 %568, %553"
"  %569 = add nuw i32 %568, %553" -> "  %581 = and i32 %569, 65535""  %569 = add nuw i32 %568, %553" -> "  %571 = lshr i32 %569, 16"
"  %570 = lshr i32 %567, 16"
"  %570 = lshr i32 %567, 16" -> "  %576 = add nuw i32 %570, %572"
"  %571 = lshr i32 %569, 16"
"  %571 = lshr i32 %569, 16" -> "  %578 = add nuw nsw i32 %571, %577"
"  %572 = mul nuw i32 %549, %345"
"  %572 = mul nuw i32 %549, %345" -> "  %771 = add nuw i32 %770, %572""  %572 = mul nuw i32 %549, %345" -> "  %576 = add nuw i32 %570, %572"
"  %573 = add i64 %18, -276"
"  %573 = add i64 %18, -276" -> "  %574 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %573"
"  %574 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %573"
"  %574 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %573" -> "  %575 = bitcast i8* %574 to i32*"
"  %575 = bitcast i8* %574 to i32*"
"  %575 = bitcast i8* %574 to i32*" -> "  store i32 %18662, i32* %575, align 1, !noalias !50"
"  %576 = add nuw i32 %570, %572"
"  %576 = add nuw i32 %570, %572" -> "  %579 = and i32 %576, -65536""  %576 = add nuw i32 %570, %572" -> "  %577 = and i32 %576, 65535"
"  %577 = and i32 %576, 65535"
"  %577 = and i32 %576, 65535" -> "  %578 = add nuw nsw i32 %571, %577"
"  %578 = add nuw nsw i32 %571, %577"
"  %578 = add nuw nsw i32 %571, %577" -> "  %580 = add i32 %578, %579"
"  %579 = and i32 %576, -65536"
"  %579 = and i32 %576, -65536" -> "  %580 = add i32 %578, %579"
"  %580 = add i32 %578, %579"
"  %580 = add i32 %578, %579" -> "  %596 = and i32 %580, -65536""  %580 = add i32 %578, %579" -> "  %594 = and i32 %580, 65535"
"  %581 = and i32 %569, 65535"
"  %581 = and i32 %569, 65535" -> "  %583 = add nuw nsw i32 %581, %582"
"  %582 = lshr i32 %545, 16"
"  %582 = lshr i32 %545, 16" -> "  %583 = add nuw nsw i32 %581, %582"
"  %583 = add nuw nsw i32 %581, %582"
"  %583 = add nuw nsw i32 %581, %582" -> "  %593 = lshr i32 %583, 16""  %583 = add nuw nsw i32 %581, %582" -> "  %591 = and i32 %583, 65535"
"  %584 = add i64 %18, -148"
"  %584 = add i64 %18, -148" -> "  %586 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %584"
"  %585 = and i32 %547, 65535"
"  %585 = and i32 %547, 65535" -> "  %778 = add nuw nsw i32 %777, %585""  %585 = and i32 %547, 65535" -> "  %589 = add nuw nsw i32 %588, %585"
"  %586 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %584"
"  %586 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %584" -> "  %587 = bitcast i8* %586 to i32*"
"  %587 = bitcast i8* %586 to i32*"
"  %587 = bitcast i8* %586 to i32*" -> "  store i32 %19419, i32* %587, align 1, !noalias !59"
"  %588 = and i32 %545, 65535"
"  %588 = and i32 %545, 65535" -> "  %589 = add nuw nsw i32 %588, %585"
"  %589 = add nuw nsw i32 %588, %585"
"  %589 = add nuw nsw i32 %588, %585" -> "  %640 = and i32 %589, 65535""  %589 = add nuw nsw i32 %588, %585" -> "  %590 = lshr i32 %589, 16"
"  %590 = lshr i32 %589, 16"
"  %590 = lshr i32 %589, 16" -> "  %592 = add nuw nsw i32 %591, %590"
"  %591 = and i32 %583, 65535"
"  %591 = and i32 %583, 65535" -> "  %592 = add nuw nsw i32 %591, %590"
"  %592 = add nuw nsw i32 %591, %590"
"  %592 = add nuw nsw i32 %591, %590" -> "  %631 = and i32 %592, 65535""  %592 = add nuw nsw i32 %591, %590" -> "  %598 = lshr i32 %592, 16"
"  %593 = lshr i32 %583, 16"
"  %593 = lshr i32 %583, 16" -> "  %595 = add nuw nsw i32 %594, %593"
"  %594 = and i32 %580, 65535"
"  %594 = and i32 %580, 65535" -> "  %595 = add nuw nsw i32 %594, %593"
"  %595 = add nuw nsw i32 %594, %593"
"  %595 = add nuw nsw i32 %594, %593" -> "  %597 = add i32 %595, %596"
"  %596 = and i32 %580, -65536"
"  %596 = and i32 %580, -65536" -> "  %597 = add i32 %595, %596"
"  %597 = add i32 %595, %596"
"  %597 = add i32 %595, %596" -> "  %599 = add i32 %597, %598"
"  %598 = lshr i32 %592, 16"
"  %598 = lshr i32 %592, 16" -> "  %599 = add i32 %597, %598"
"  %599 = add i32 %597, %598"
"  %599 = add i32 %597, %598" -> "  %684 = and i32 %599, 65535""  %599 = add i32 %597, %598" -> "  %675 = lshr i32 %599, 16"
"  %600 = mul nuw i32 %514, %346"
"  %600 = mul nuw i32 %514, %346" -> "  %636 = and i32 %600, 65535""  %600 = mul nuw i32 %514, %346" -> "  %601 = lshr i32 %600, 16"
"  %601 = lshr i32 %600, 16"
"  %601 = lshr i32 %600, 16" -> "  %604 = add nuw nsw i32 %603, %601""  %601 = lshr i32 %600, 16" -> "  %607 = add nuw nsw i32 %606, %601"
"  %602 = mul nuw i32 %515, %346"
"  %602 = mul nuw i32 %515, %346" -> "  %611 = add nuw i32 %602, %610""  %602 = mul nuw i32 %515, %346" -> "  %615 = and i32 %602, -65536""  %602 = mul nuw i32 %515, %346" -> "  %603 = and i32 %602, 65535"
"  %603 = and i32 %602, 65535"
"  %603 = and i32 %602, 65535" -> "  %604 = add nuw nsw i32 %603, %601"
"  %604 = add nuw nsw i32 %603, %601"
"  %604 = add nuw nsw i32 %603, %601" -> "  %616 = add nuw i32 %604, %615"
"  %605 = mul nuw i32 %514, %347"
"  %605 = mul nuw i32 %514, %347" -> "  %618 = add nuw i32 %617, %605""  %605 = mul nuw i32 %514, %347" -> "  %608 = and i32 %605, -65536""  %605 = mul nuw i32 %514, %347" -> "  %606 = and i32 %605, 65535"
"  %606 = and i32 %605, 65535"
"  %606 = and i32 %605, 65535" -> "  %607 = add nuw nsw i32 %606, %601"
"  %607 = add nuw nsw i32 %606, %601"
"  %607 = add nuw nsw i32 %606, %601" -> "  %609 = add nuw i32 %607, %608"
"  %608 = and i32 %605, -65536"
"  %608 = and i32 %605, -65536" -> "  %609 = add nuw i32 %607, %608"
"  %609 = add nuw i32 %607, %608"
"  %609 = add nuw i32 %607, %608" -> "  %751 = lshr i32 %609, 16""  %609 = add nuw i32 %607, %608" -> "  %610 = and i32 %609, 65535"
"  %610 = and i32 %609, 65535"
"  %610 = and i32 %609, 65535" -> "  %611 = add nuw i32 %602, %610"
"  %611 = add nuw i32 %602, %610"
"  %611 = add nuw i32 %602, %610" -> "  %760 = and i32 %611, 65535""  %611 = add nuw i32 %602, %610" -> "  %753 = lshr i32 %611, 16"
"  %612 = add i64 %18, -252"
"  %612 = add i64 %18, -252" -> "  %613 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %612"
"  %613 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %612"
"  %613 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %612" -> "  %614 = bitcast i8* %613 to i32*"
"  %614 = bitcast i8* %613 to i32*"
"  %614 = bitcast i8* %613 to i32*" -> "  store i32 %19416, i32* %614, align 1, !noalias !59"
"  %615 = and i32 %602, -65536"
"  %615 = and i32 %602, -65536" -> "  %616 = add nuw i32 %604, %615"
"  %616 = add nuw i32 %604, %615"
"  %616 = add nuw i32 %604, %615" -> "  %619 = lshr i32 %616, 16""  %616 = add nuw i32 %604, %615" -> "  %617 = and i32 %616, 65535"
"  %617 = and i32 %616, 65535"
"  %617 = and i32 %616, 65535" -> "  %618 = add nuw i32 %617, %605"
"  %618 = add nuw i32 %617, %605"
"  %618 = add nuw i32 %617, %605" -> "  %630 = and i32 %618, 65535""  %618 = add nuw i32 %617, %605" -> "  %620 = lshr i32 %618, 16"
"  %619 = lshr i32 %616, 16"
"  %619 = lshr i32 %616, 16" -> "  %625 = add nuw i32 %619, %621"
"  %620 = lshr i32 %618, 16"
"  %620 = lshr i32 %618, 16" -> "  %627 = add nuw nsw i32 %626, %620"
"  %621 = mul nuw i32 %515, %347"
"  %621 = mul nuw i32 %515, %347" -> "  %752 = add nuw i32 %621, %751""  %621 = mul nuw i32 %515, %347" -> "  %625 = add nuw i32 %619, %621"
"  %622 = add i64 %18, -212"
"  %622 = add i64 %18, -212" -> "  %623 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %622"
"  %623 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %622"
"  %623 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %622" -> "  %624 = bitcast i8* %623 to i32*"
"  %624 = bitcast i8* %623 to i32*"
"  %624 = bitcast i8* %623 to i32*" -> "  store i32 %19413, i32* %624, align 1, !noalias !59"
"  %625 = add nuw i32 %619, %621"
"  %625 = add nuw i32 %619, %621" -> "  %628 = and i32 %625, -65536""  %625 = add nuw i32 %619, %621" -> "  %626 = and i32 %625, 65535"
"  %626 = and i32 %625, 65535"
"  %626 = and i32 %625, 65535" -> "  %627 = add nuw nsw i32 %626, %620"
"  %627 = add nuw nsw i32 %626, %620"
"  %627 = add nuw nsw i32 %626, %620" -> "  %629 = add i32 %627, %628"
"  %628 = and i32 %625, -65536"
"  %628 = and i32 %625, -65536" -> "  %629 = add i32 %627, %628"
"  %629 = add i32 %627, %628"
"  %629 = add i32 %627, %628" -> "  %634 = add i32 %629, %633"
"  %630 = and i32 %618, 65535"
"  %630 = and i32 %618, 65535" -> "  %632 = add nuw nsw i32 %631, %630"
"  %631 = and i32 %592, 65535"
"  %631 = and i32 %592, 65535" -> "  %632 = add nuw nsw i32 %631, %630"
"  %632 = add nuw nsw i32 %631, %630"
"  %632 = add nuw nsw i32 %631, %630" -> "  %639 = and i32 %632, 65535""  %632 = add nuw nsw i32 %631, %630" -> "  %633 = lshr i32 %632, 16"
"  %633 = lshr i32 %632, 16"
"  %633 = lshr i32 %632, 16" -> "  %634 = add i32 %629, %633"
"  %634 = add i32 %629, %633"
"  %634 = add i32 %629, %633" -> "  %645 = add i32 %634, %644"
"  %635 = add i64 %18, -240"
"  %635 = add i64 %18, -240" -> "  %637 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %635"
"  %636 = and i32 %600, 65535"
"  %636 = and i32 %600, 65535" -> "  %759 = add nuw nsw i32 %758, %636""  %636 = and i32 %600, 65535" -> "  %641 = add nuw nsw i32 %640, %636"
"  %637 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %635"
"  %637 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %635" -> "  %638 = bitcast i8* %637 to i32*"
"  %638 = bitcast i8* %637 to i32*"
"  %638 = bitcast i8* %637 to i32*" -> "  store i32 %19410, i32* %638, align 1, !noalias !59"
"  %639 = and i32 %632, 65535"
"  %639 = and i32 %632, 65535" -> "  %643 = add nuw nsw i32 %639, %642"
"  %640 = and i32 %589, 65535"
"  %640 = and i32 %589, 65535" -> "  %641 = add nuw nsw i32 %640, %636"
"  %641 = add nuw nsw i32 %640, %636"
"  %641 = add nuw nsw i32 %640, %636" -> "  %718 = and i32 %641, 65535""  %641 = add nuw nsw i32 %640, %636" -> "  %642 = lshr i32 %641, 16"
"  %642 = lshr i32 %641, 16"
"  %642 = lshr i32 %641, 16" -> "  %643 = add nuw nsw i32 %639, %642"
"  %643 = add nuw nsw i32 %639, %642"
"  %643 = add nuw nsw i32 %639, %642" -> "  %721 = and i32 %643, 65535""  %643 = add nuw nsw i32 %639, %642" -> "  %644 = lshr i32 %643, 16"
"  %644 = lshr i32 %643, 16"
"  %644 = lshr i32 %643, 16" -> "  %645 = add i32 %634, %644"
"  %645 = add i32 %634, %644"
"  %645 = add i32 %634, %644" -> "  %694 = lshr i32 %645, 16""  %645 = add i32 %634, %644" -> "  %691 = and i32 %645, 65535"
"  %646 = add i64 %18, -100"
"  %646 = add i64 %18, -100" -> "  %647 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %646"
"  %647 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %646"
"  %647 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %646" -> "  %648 = bitcast i8* %647 to i32*"
"  %648 = bitcast i8* %647 to i32*"
"  %648 = bitcast i8* %647 to i32*" -> "  store i32 %20084, i32* %648, align 1, !noalias !71"
"  %649 = mul nuw i32 %546, %346"
"  %649 = mul nuw i32 %546, %346" -> "  %680 = and i32 %649, 65535""  %649 = mul nuw i32 %546, %346" -> "  %650 = lshr i32 %649, 16"
"  %650 = lshr i32 %649, 16"
"  %650 = lshr i32 %649, 16" -> "  %663 = add nuw i32 %652, %650""  %650 = lshr i32 %649, 16" -> "  %655 = add nuw nsw i32 %650, %654"
"  %651 = bitcast i8* %227 to i32*"
"  %651 = bitcast i8* %227 to i32*" -> "  store i32 %20288, i32* %651, align 1, !noalias !74"
"  %652 = mul nuw i32 %549, %346"
"  %652 = mul nuw i32 %549, %346" -> "  %663 = add nuw i32 %652, %650""  %652 = mul nuw i32 %549, %346" -> "  %659 = add nuw i32 %658, %652"
"  %653 = mul nuw i32 %546, %347"
"  %653 = mul nuw i32 %546, %347" -> "  %665 = add nuw i32 %664, %653""  %653 = mul nuw i32 %546, %347" -> "  %656 = and i32 %653, -65536""  %653 = mul nuw i32 %546, %347" -> "  %654 = and i32 %653, 65535"
"  %654 = and i32 %653, 65535"
"  %654 = and i32 %653, 65535" -> "  %655 = add nuw nsw i32 %650, %654"
"  %655 = add nuw nsw i32 %650, %654"
"  %655 = add nuw nsw i32 %650, %654" -> "  %657 = add nuw i32 %655, %656"
"  %656 = and i32 %653, -65536"
"  %656 = and i32 %653, -65536" -> "  %657 = add nuw i32 %655, %656"
"  %657 = add nuw i32 %655, %656"
"  %657 = add nuw i32 %655, %656" -> "  %789 = lshr i32 %657, 16""  %657 = add nuw i32 %655, %656" -> "  %658 = and i32 %657, 65535"
"  %658 = and i32 %657, 65535"
"  %658 = and i32 %657, 65535" -> "  %659 = add nuw i32 %658, %652"
"  %659 = add nuw i32 %658, %652"
"  %659 = add nuw i32 %658, %652" -> "  %791 = lshr i32 %659, 16""  %659 = add nuw i32 %658, %652" -> "  %798 = and i32 %659, 65535"
"  %660 = add i64 %18, -236"
"  %660 = add i64 %18, -236" -> "  %661 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %660"
"  %661 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %660"
"  %661 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %660" -> "  %662 = bitcast i8* %661 to i32*"
"  %662 = bitcast i8* %661 to i32*"
"  %662 = bitcast i8* %661 to i32*" -> "  store i32 %19404, i32* %662, align 1, !noalias !59"
"  %663 = add nuw i32 %652, %650"
"  %663 = add nuw i32 %652, %650" -> "  %666 = lshr i32 %663, 16""  %663 = add nuw i32 %652, %650" -> "  %664 = and i32 %663, 65535"
"  %664 = and i32 %663, 65535"
"  %664 = and i32 %663, 65535" -> "  %665 = add nuw i32 %664, %653"
"  %665 = add nuw i32 %664, %653"
"  %665 = add nuw i32 %664, %653" -> "  %674 = and i32 %665, 65535""  %665 = add nuw i32 %664, %653" -> "  %667 = lshr i32 %665, 16"
"  %666 = lshr i32 %663, 16"
"  %666 = lshr i32 %663, 16" -> "  %669 = add nuw i32 %666, %668"
"  %667 = lshr i32 %665, 16"
"  %667 = lshr i32 %665, 16" -> "  %671 = add nuw nsw i32 %670, %667"
"  %668 = mul nuw i32 %549, %347"
"  %668 = mul nuw i32 %549, %347" -> "  %790 = add nuw i32 %789, %668""  %668 = mul nuw i32 %549, %347" -> "  %669 = add nuw i32 %666, %668"
"  %669 = add nuw i32 %666, %668"
"  %669 = add nuw i32 %666, %668" -> "  %672 = and i32 %669, -65536""  %669 = add nuw i32 %666, %668" -> "  %670 = and i32 %669, 65535"
"  %670 = and i32 %669, 65535"
"  %670 = and i32 %669, 65535" -> "  %671 = add nuw nsw i32 %670, %667"
"  %671 = add nuw nsw i32 %670, %667"
"  %671 = add nuw nsw i32 %670, %667" -> "  %673 = add i32 %671, %672"
"  %672 = and i32 %669, -65536"
"  %672 = and i32 %669, -65536" -> "  %673 = add i32 %671, %672"
"  %673 = add i32 %671, %672"
"  %673 = add i32 %671, %672" -> "  %678 = add i32 %673, %677"
"  %674 = and i32 %665, 65535"
"  %674 = and i32 %665, 65535" -> "  %676 = add nuw nsw i32 %675, %674"
"  %675 = lshr i32 %599, 16"
"  %675 = lshr i32 %599, 16" -> "  %676 = add nuw nsw i32 %675, %674"
"  %676 = add nuw nsw i32 %675, %674"
"  %676 = add nuw nsw i32 %675, %674" -> "  %683 = and i32 %676, 65535""  %676 = add nuw nsw i32 %675, %674" -> "  %677 = lshr i32 %676, 16"
"  %677 = lshr i32 %676, 16"
"  %677 = lshr i32 %676, 16" -> "  %678 = add i32 %673, %677"
"  %678 = add i32 %673, %677"
"  %678 = add i32 %673, %677" -> "  %689 = add i32 %678, %688"
"  %679 = add i64 %18, -216"
"  %679 = add i64 %18, -216" -> "  %681 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %679"
"  %680 = and i32 %649, 65535"
"  %680 = and i32 %649, 65535" -> "  %797 = add nuw nsw i32 %796, %680""  %680 = and i32 %649, 65535" -> "  %685 = add nuw nsw i32 %684, %680"
"  %681 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %679"
"  %681 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %679" -> "  %682 = bitcast i8* %681 to i32*"
"  %682 = bitcast i8* %681 to i32*"
"  %682 = bitcast i8* %681 to i32*" -> "  store i32 %19408, i32* %682, align 1, !noalias !59"
"  %683 = and i32 %676, 65535"
"  %683 = and i32 %676, 65535" -> "  %687 = add nuw nsw i32 %683, %686"
"  %684 = and i32 %599, 65535"
"  %684 = and i32 %599, 65535" -> "  %685 = add nuw nsw i32 %684, %680"
"  %685 = add nuw nsw i32 %684, %680"
"  %685 = add nuw nsw i32 %684, %680" -> "  %690 = and i32 %685, 65535""  %685 = add nuw nsw i32 %684, %680" -> "  %686 = lshr i32 %685, 16"
"  %686 = lshr i32 %685, 16"
"  %686 = lshr i32 %685, 16" -> "  %687 = add nuw nsw i32 %683, %686"
"  %687 = add nuw nsw i32 %683, %686"
"  %687 = add nuw nsw i32 %683, %686" -> "  %693 = and i32 %687, 65535""  %687 = add nuw nsw i32 %683, %686" -> "  %688 = lshr i32 %687, 16"
"  %688 = lshr i32 %687, 16"
"  %688 = lshr i32 %687, 16" -> "  %689 = add i32 %678, %688"
"  %689 = add i32 %678, %688"
"  %689 = add i32 %678, %688" -> "  %702 = and i32 %689, -65536""  %689 = add i32 %678, %688" -> "  %700 = and i32 %689, 65535"
"  %690 = and i32 %685, 65535"
"  %690 = and i32 %685, 65535" -> "  %692 = add nuw nsw i32 %691, %690"
"  %691 = and i32 %645, 65535"
"  %691 = and i32 %645, 65535" -> "  %692 = add nuw nsw i32 %691, %690"
"  %692 = add nuw nsw i32 %691, %690"
"  %692 = add nuw nsw i32 %691, %690" -> "  %732 = and i32 %692, 65535""  %692 = add nuw nsw i32 %691, %690" -> "  %696 = lshr i32 %692, 16"
"  %693 = and i32 %687, 65535"
"  %693 = and i32 %687, 65535" -> "  %695 = add nuw nsw i32 %693, %694"
"  %694 = lshr i32 %645, 16"
"  %694 = lshr i32 %645, 16" -> "  %695 = add nuw nsw i32 %693, %694"
"  %695 = add nuw nsw i32 %693, %694"
"  %695 = add nuw nsw i32 %693, %694" -> "  %699 = lshr i32 %695, 16""  %695 = add nuw nsw i32 %693, %694" -> "  %697 = and i32 %695, 65535"
"  %696 = lshr i32 %692, 16"
"  %696 = lshr i32 %692, 16" -> "  %698 = add nuw nsw i32 %697, %696"
"  %697 = and i32 %695, 65535"
"  %697 = and i32 %695, 65535" -> "  %698 = add nuw nsw i32 %697, %696"
"  %698 = add nuw nsw i32 %697, %696"
"  %698 = add nuw nsw i32 %697, %696" -> "  %739 = and i32 %698, 65535""  %698 = add nuw nsw i32 %697, %696" -> "  %704 = lshr i32 %698, 16"
"  %699 = lshr i32 %695, 16"
"  %699 = lshr i32 %695, 16" -> "  %701 = add nuw nsw i32 %699, %700"
"  %700 = and i32 %689, 65535"
"  %700 = and i32 %689, 65535" -> "  %701 = add nuw nsw i32 %699, %700"
"  %701 = add nuw nsw i32 %699, %700"
"  %701 = add nuw nsw i32 %699, %700" -> "  %703 = add i32 %701, %702"
"  %702 = and i32 %689, -65536"
"  %702 = and i32 %689, -65536" -> "  %703 = add i32 %701, %702"
"  %703 = add i32 %701, %702"
"  %703 = add i32 %701, %702" -> "  %705 = add i32 %703, %704"
"  %704 = lshr i32 %698, 16"
"  %704 = lshr i32 %698, 16" -> "  %705 = add i32 %703, %704"
"  %705 = add i32 %703, %704"
"  %705 = add i32 %703, %704" -> "  %743 = add i32 %705, %742"
"  %706 = and i32 %531, 65535"
"  %706 = and i32 %531, 65535" -> "  %708 = add nuw nsw i32 %707, %706"
"  %707 = and i32 %506, 65535"
"  %707 = and i32 %506, 65535" -> "  %708 = add nuw nsw i32 %707, %706"
"  %708 = add nuw nsw i32 %707, %706"
"  %708 = add nuw nsw i32 %707, %706" -> "  %715 = lshr i32 %708, 16""  %708 = add nuw nsw i32 %707, %706" -> "  %713 = and i32 %708, 65535"
"  %709 = and i32 %516, 65535"
"  %709 = and i32 %516, 65535" -> "  %820 = add nuw nsw i32 %819, %709""  %709 = and i32 %516, 65535" -> "  %711 = add nuw nsw i32 %710, %709"
"  %710 = and i32 %500, 65535"
"  %710 = and i32 %500, 65535" -> "  %711 = add nuw nsw i32 %710, %709"
"  %711 = add nuw nsw i32 %710, %709"
"  %711 = add nuw nsw i32 %710, %709" -> "  %819 = and i32 %711, 65535""  %711 = add nuw nsw i32 %710, %709" -> "  %712 = lshr i32 %711, 16"
"  %712 = lshr i32 %711, 16"
"  %712 = lshr i32 %711, 16" -> "  %714 = add nuw nsw i32 %713, %712"
"  %713 = and i32 %708, 65535"
"  %713 = and i32 %708, 65535" -> "  %714 = add nuw nsw i32 %713, %712"
"  %714 = add nuw nsw i32 %713, %712"
"  %714 = add nuw nsw i32 %713, %712" -> "  %822 = and i32 %714, 65535""  %714 = add nuw nsw i32 %713, %712" -> "  %716 = lshr i32 %714, 16"
"  %715 = lshr i32 %708, 16"
"  %715 = lshr i32 %708, 16" -> "  %717 = add nuw nsw i32 %716, %715"
"  %716 = lshr i32 %714, 16"
"  %716 = lshr i32 %714, 16" -> "  %717 = add nuw nsw i32 %716, %715"
"  %717 = add nuw nsw i32 %716, %715"
"  %717 = add nuw nsw i32 %716, %715" -> "  %728 = add nuw nsw i32 %717, %727"
"  %718 = and i32 %641, 65535"
"  %718 = and i32 %641, 65535" -> "  %720 = add nuw nsw i32 %718, %719"
"  %719 = and i32 %513, 65535"
"  %719 = and i32 %513, 65535" -> "  %720 = add nuw nsw i32 %718, %719"
"  %720 = add nuw nsw i32 %718, %719"
"  %720 = add nuw nsw i32 %718, %719" -> "  %727 = and i32 %720, 65535""  %720 = add nuw nsw i32 %718, %719" -> "  %724 = lshr i32 %720, 16"
"  %721 = and i32 %643, 65535"
"  %721 = and i32 %643, 65535" -> "  %723 = add nuw nsw i32 %721, %722"
"  %722 = lshr i32 %513, 16"
"  %722 = lshr i32 %513, 16" -> "  %723 = add nuw nsw i32 %721, %722"
"  %723 = add nuw nsw i32 %721, %722"
"  %723 = add nuw nsw i32 %721, %722" -> "  %733 = lshr i32 %723, 16""  %723 = add nuw nsw i32 %721, %722" -> "  %725 = and i32 %723, 65535"
"  %724 = lshr i32 %720, 16"
"  %724 = lshr i32 %720, 16" -> "  %726 = add nuw nsw i32 %725, %724"
"  %725 = and i32 %723, 65535"
"  %725 = and i32 %723, 65535" -> "  %726 = add nuw nsw i32 %725, %724"
"  %726 = add nuw nsw i32 %725, %724"
"  %726 = add nuw nsw i32 %725, %724" -> "  %735 = lshr i32 %726, 16""  %726 = add nuw nsw i32 %725, %724" -> "  %730 = and i32 %726, 65535"
"  %727 = and i32 %720, 65535"
"  %727 = and i32 %720, 65535" -> "  %728 = add nuw nsw i32 %717, %727"
"  %728 = add nuw nsw i32 %717, %727"
"  %728 = add nuw nsw i32 %717, %727" -> "  %831 = and i32 %728, 65535""  %728 = add nuw nsw i32 %717, %727" -> "  %729 = lshr i32 %728, 16"
"  %729 = lshr i32 %728, 16"
"  %729 = lshr i32 %728, 16" -> "  %731 = add nuw nsw i32 %730, %729"
"  %730 = and i32 %726, 65535"
"  %730 = and i32 %726, 65535" -> "  %731 = add nuw nsw i32 %730, %729"
"  %731 = add nuw nsw i32 %730, %729"
"  %731 = add nuw nsw i32 %730, %729" -> "  %834 = and i32 %731, 65535""  %731 = add nuw nsw i32 %730, %729" -> "  %737 = lshr i32 %731, 16"
"  %732 = and i32 %692, 65535"
"  %732 = and i32 %692, 65535" -> "  %734 = add nuw nsw i32 %732, %733"
"  %733 = lshr i32 %723, 16"
"  %733 = lshr i32 %723, 16" -> "  %734 = add nuw nsw i32 %732, %733"
"  %734 = add nuw nsw i32 %732, %733"
"  %734 = add nuw nsw i32 %732, %733" -> "  %736 = add nuw nsw i32 %734, %735"
"  %735 = lshr i32 %726, 16"
"  %735 = lshr i32 %726, 16" -> "  %736 = add nuw nsw i32 %734, %735"
"  %736 = add nuw nsw i32 %734, %735"
"  %736 = add nuw nsw i32 %734, %735" -> "  %738 = add nuw nsw i32 %736, %737"
"  %737 = lshr i32 %731, 16"
"  %737 = lshr i32 %731, 16" -> "  %738 = add nuw nsw i32 %736, %737"
"  %738 = add nuw nsw i32 %736, %737"
"  %738 = add nuw nsw i32 %736, %737" -> "  %969 = and i32 %738, 65535""  %738 = add nuw nsw i32 %736, %737" -> "  %740 = lshr i32 %738, 16"
"  %739 = and i32 %698, 65535"
"  %739 = and i32 %698, 65535" -> "  %741 = add nuw nsw i32 %740, %739"
"  %740 = lshr i32 %738, 16"
"  %740 = lshr i32 %738, 16" -> "  %741 = add nuw nsw i32 %740, %739"
"  %741 = add nuw nsw i32 %740, %739"
"  %741 = add nuw nsw i32 %740, %739" -> "  %972 = and i32 %741, 65535""  %741 = add nuw nsw i32 %740, %739" -> "  %742 = lshr i32 %741, 16"
"  %742 = lshr i32 %741, 16"
"  %742 = lshr i32 %741, 16" -> "  %743 = add i32 %705, %742"
"  %743 = add i32 %705, %742"
"  %743 = add i32 %705, %742" -> "  %978 = and i32 %743, 65535""  %743 = add i32 %705, %742" -> "  %981 = lshr i32 %743, 16"
"  %744 = lshr i32 %525, 16"
"  %744 = lshr i32 %525, 16" -> "  %745 = add nuw i32 %537, %744"
"  %745 = add nuw i32 %537, %744"
"  %745 = add nuw i32 %537, %744" -> "  %749 = and i32 %745, -65536""  %745 = add nuw i32 %537, %744" -> "  %747 = and i32 %745, 65535"
"  %746 = lshr i32 %527, 16"
"  %746 = lshr i32 %527, 16" -> "  %748 = add nuw nsw i32 %746, %747"
"  %747 = and i32 %745, 65535"
"  %747 = and i32 %745, 65535" -> "  %748 = add nuw nsw i32 %746, %747"
"  %748 = add nuw nsw i32 %746, %747"
"  %748 = add nuw nsw i32 %746, %747" -> "  %750 = add i32 %748, %749"
"  %749 = and i32 %745, -65536"
"  %749 = and i32 %745, -65536" -> "  %750 = add i32 %748, %749"
"  %750 = add i32 %748, %749"
"  %750 = add i32 %748, %749" -> "  %761 = lshr i32 %750, 16""  %750 = add i32 %748, %749" -> "  %758 = and i32 %750, 65535"
"  %751 = lshr i32 %609, 16"
"  %751 = lshr i32 %609, 16" -> "  %752 = add nuw i32 %621, %751"
"  %752 = add nuw i32 %621, %751"
"  %752 = add nuw i32 %621, %751" -> "  %756 = and i32 %752, -65536""  %752 = add nuw i32 %621, %751" -> "  %754 = and i32 %752, 65535"
"  %753 = lshr i32 %611, 16"
"  %753 = lshr i32 %611, 16" -> "  %755 = add nuw nsw i32 %753, %754"
"  %754 = and i32 %752, 65535"
"  %754 = and i32 %752, 65535" -> "  %755 = add nuw nsw i32 %753, %754"
"  %755 = add nuw nsw i32 %753, %754"
"  %755 = add nuw nsw i32 %753, %754" -> "  %757 = add i32 %755, %756"
"  %756 = and i32 %752, -65536"
"  %756 = and i32 %752, -65536" -> "  %757 = add i32 %755, %756"
"  %757 = add i32 %755, %756"
"  %757 = add i32 %755, %756" -> "  %764 = add i32 %757, %763"
"  %758 = and i32 %750, 65535"
"  %758 = and i32 %750, 65535" -> "  %759 = add nuw nsw i32 %758, %636"
"  %759 = add nuw nsw i32 %758, %636"
"  %759 = add nuw nsw i32 %758, %636" -> "  %777 = and i32 %759, 65535""  %759 = add nuw nsw i32 %758, %636" -> "  %765 = lshr i32 %759, 16"
"  %760 = and i32 %611, 65535"
"  %760 = and i32 %611, 65535" -> "  %762 = add nuw nsw i32 %761, %760"
"  %761 = lshr i32 %750, 16"
"  %761 = lshr i32 %750, 16" -> "  %762 = add nuw nsw i32 %761, %760"
"  %762 = add nuw nsw i32 %761, %760"
"  %762 = add nuw nsw i32 %761, %760" -> "  %766 = and i32 %762, 65535""  %762 = add nuw nsw i32 %761, %760" -> "  %763 = lshr i32 %762, 16"
"  %763 = lshr i32 %762, 16"
"  %763 = lshr i32 %762, 16" -> "  %764 = add i32 %757, %763"
"  %764 = add i32 %757, %763"
"  %764 = add i32 %757, %763" -> "  %769 = add i32 %764, %768"
"  %765 = lshr i32 %759, 16"
"  %765 = lshr i32 %759, 16" -> "  %767 = add nuw nsw i32 %765, %766"
"  %766 = and i32 %762, 65535"
"  %766 = and i32 %762, 65535" -> "  %767 = add nuw nsw i32 %765, %766"
"  %767 = add nuw nsw i32 %765, %766"
"  %767 = add nuw nsw i32 %765, %766" -> "  %779 = and i32 %767, 65535""  %767 = add nuw nsw i32 %765, %766" -> "  %768 = lshr i32 %767, 16"
"  %768 = lshr i32 %767, 16"
"  %768 = lshr i32 %767, 16" -> "  %769 = add i32 %764, %768"
"  %769 = add i32 %764, %768"
"  %769 = add i32 %764, %768" -> "  %799 = lshr i32 %769, 16""  %769 = add i32 %764, %768" -> "  %796 = and i32 %769, 65535"
"  %770 = lshr i32 %557, 16"
"  %770 = lshr i32 %557, 16" -> "  %771 = add nuw i32 %770, %572"
"  %771 = add nuw i32 %770, %572"
"  %771 = add nuw i32 %770, %572" -> "  %775 = and i32 %771, -65536""  %771 = add nuw i32 %770, %572" -> "  %773 = and i32 %771, 65535"
"  %772 = lshr i32 %562, 16"
"  %772 = lshr i32 %562, 16" -> "  %774 = add nuw nsw i32 %772, %773"
"  %773 = and i32 %771, 65535"
"  %773 = and i32 %771, 65535" -> "  %774 = add nuw nsw i32 %772, %773"
"  %774 = add nuw nsw i32 %772, %773"
"  %774 = add nuw nsw i32 %772, %773" -> "  %776 = add i32 %774, %775"
"  %775 = and i32 %771, -65536"
"  %775 = and i32 %771, -65536" -> "  %776 = add i32 %774, %775"
"  %776 = add i32 %774, %775"
"  %776 = add i32 %774, %775" -> "  %783 = add i32 %776, %782"
"  %777 = and i32 %759, 65535"
"  %777 = and i32 %759, 65535" -> "  %778 = add nuw nsw i32 %777, %585"
"  %778 = add nuw nsw i32 %777, %585"
"  %778 = add nuw nsw i32 %777, %585" -> "  %830 = and i32 %778, 65535""  %778 = add nuw nsw i32 %777, %585" -> "  %785 = lshr i32 %778, 16"
"  %779 = and i32 %767, 65535"
"  %779 = and i32 %767, 65535" -> "  %781 = add nuw nsw i32 %779, %780"
"  %780 = and i32 %562, 65535"
"  %780 = and i32 %562, 65535" -> "  %781 = add nuw nsw i32 %779, %780"
"  %781 = add nuw nsw i32 %779, %780"
"  %781 = add nuw nsw i32 %779, %780" -> "  %784 = and i32 %781, 65535""  %781 = add nuw nsw i32 %779, %780" -> "  %782 = lshr i32 %781, 16"
"  %782 = lshr i32 %781, 16"
"  %782 = lshr i32 %781, 16" -> "  %783 = add i32 %776, %782"
"  %783 = add i32 %776, %782"
"  %783 = add i32 %776, %782" -> "  %788 = add i32 %783, %787"
"  %784 = and i32 %781, 65535"
"  %784 = and i32 %781, 65535" -> "  %786 = add nuw nsw i32 %784, %785"
"  %785 = lshr i32 %778, 16"
"  %785 = lshr i32 %778, 16" -> "  %786 = add nuw nsw i32 %784, %785"
"  %786 = add nuw nsw i32 %784, %785"
"  %786 = add nuw nsw i32 %784, %785" -> "  %833 = and i32 %786, 65535""  %786 = add nuw nsw i32 %784, %785" -> "  %787 = lshr i32 %786, 16"
"  %787 = lshr i32 %786, 16"
"  %787 = lshr i32 %786, 16" -> "  %788 = add i32 %783, %787"
"  %788 = add i32 %783, %787"
"  %788 = add i32 %783, %787" -> "  %812 = lshr i32 %788, 16""  %788 = add i32 %783, %787" -> "  %809 = and i32 %788, 65535"
"  %789 = lshr i32 %657, 16"
"  %789 = lshr i32 %657, 16" -> "  %790 = add nuw i32 %789, %668"
"  %790 = add nuw i32 %789, %668"
"  %790 = add nuw i32 %789, %668" -> "  %794 = and i32 %790, -65536""  %790 = add nuw i32 %789, %668" -> "  %792 = and i32 %790, 65535"
"  %791 = lshr i32 %659, 16"
"  %791 = lshr i32 %659, 16" -> "  %793 = add nuw nsw i32 %791, %792"
"  %792 = and i32 %790, 65535"
"  %792 = and i32 %790, 65535" -> "  %793 = add nuw nsw i32 %791, %792"
"  %793 = add nuw nsw i32 %791, %792"
"  %793 = add nuw nsw i32 %791, %792" -> "  %795 = add i32 %793, %794"
"  %794 = and i32 %790, -65536"
"  %794 = and i32 %790, -65536" -> "  %795 = add i32 %793, %794"
"  %795 = add i32 %793, %794"
"  %795 = add i32 %793, %794" -> "  %802 = add i32 %795, %801"
"  %796 = and i32 %769, 65535"
"  %796 = and i32 %769, 65535" -> "  %797 = add nuw nsw i32 %796, %680"
"  %797 = add nuw nsw i32 %796, %680"
"  %797 = add nuw nsw i32 %796, %680" -> "  %808 = and i32 %797, 65535""  %797 = add nuw nsw i32 %796, %680" -> "  %804 = lshr i32 %797, 16"
"  %798 = and i32 %659, 65535"
"  %798 = and i32 %659, 65535" -> "  %800 = add nuw nsw i32 %799, %798"
"  %799 = lshr i32 %769, 16"
"  %799 = lshr i32 %769, 16" -> "  %800 = add nuw nsw i32 %799, %798"
"  %800 = add nuw nsw i32 %799, %798"
"  %800 = add nuw nsw i32 %799, %798" -> "  %803 = and i32 %800, 65535""  %800 = add nuw nsw i32 %799, %798" -> "  %801 = lshr i32 %800, 16"
"  %801 = lshr i32 %800, 16"
"  %801 = lshr i32 %800, 16" -> "  %802 = add i32 %795, %801"
"  %802 = add i32 %795, %801"
"  %802 = add i32 %795, %801" -> "  %807 = add i32 %802, %806"
"  %803 = and i32 %800, 65535"
"  %803 = and i32 %800, 65535" -> "  %805 = add nuw nsw i32 %803, %804"
"  %804 = lshr i32 %797, 16"
"  %804 = lshr i32 %797, 16" -> "  %805 = add nuw nsw i32 %803, %804"
"  %805 = add nuw nsw i32 %803, %804"
"  %805 = add nuw nsw i32 %803, %804" -> "  %811 = and i32 %805, 65535""  %805 = add nuw nsw i32 %803, %804" -> "  %806 = lshr i32 %805, 16"
"  %806 = lshr i32 %805, 16"
"  %806 = lshr i32 %805, 16" -> "  %807 = add i32 %802, %806"
"  %807 = add i32 %802, %806"
"  %807 = add i32 %802, %806" -> "  %855 = add i32 %807, %817"
"  %808 = and i32 %797, 65535"
"  %808 = and i32 %797, 65535" -> "  %810 = add nuw nsw i32 %809, %808"
"  %809 = and i32 %788, 65535"
"  %809 = and i32 %788, 65535" -> "  %810 = add nuw nsw i32 %809, %808"
"  %810 = add nuw nsw i32 %809, %808"
"  %810 = add nuw nsw i32 %809, %808" -> "  %844 = and i32 %810, 65535""  %810 = add nuw nsw i32 %809, %808" -> "  %814 = lshr i32 %810, 16"
"  %811 = and i32 %805, 65535"
"  %811 = and i32 %805, 65535" -> "  %813 = add nuw nsw i32 %812, %811"
"  %812 = lshr i32 %788, 16"
"  %812 = lshr i32 %788, 16" -> "  %813 = add nuw nsw i32 %812, %811"
"  %813 = add nuw nsw i32 %812, %811"
"  %813 = add nuw nsw i32 %812, %811" -> "  %817 = lshr i32 %813, 16""  %813 = add nuw nsw i32 %812, %811" -> "  %815 = and i32 %813, 65535"
"  %814 = lshr i32 %810, 16"
"  %814 = lshr i32 %810, 16" -> "  %816 = add nuw nsw i32 %815, %814"
"  %815 = and i32 %813, 65535"
"  %815 = and i32 %813, 65535" -> "  %816 = add nuw nsw i32 %815, %814"
"  %816 = add nuw nsw i32 %815, %814"
"  %816 = add nuw nsw i32 %815, %814" -> "  %851 = and i32 %816, 65535""  %816 = add nuw nsw i32 %815, %814" -> "  %818 = lshr i32 %816, 16"
"  %817 = lshr i32 %813, 16"
"  %817 = lshr i32 %813, 16" -> "  %855 = add i32 %807, %817"
"  %818 = lshr i32 %816, 16"
"  %818 = lshr i32 %816, 16" -> "  %856 = add i32 %855, %818"
"  %819 = and i32 %711, 65535"
"  %819 = and i32 %711, 65535" -> "  %820 = add nuw nsw i32 %819, %709"
"  %820 = add nuw nsw i32 %819, %709"
"  %820 = add nuw nsw i32 %819, %709" -> "  %1178 = and i32 %820, 65535""  %820 = add nuw nsw i32 %819, %709" -> "  %824 = lshr i32 %820, 16"
"  %821 = and i32 %527, 65535"
"  %821 = and i32 %527, 65535" -> "  %823 = add nuw nsw i32 %822, %821"
"  %822 = and i32 %714, 65535"
"  %822 = and i32 %714, 65535" -> "  %823 = add nuw nsw i32 %822, %821"
"  %823 = add nuw nsw i32 %822, %821"
"  %823 = add nuw nsw i32 %822, %821" -> "  %827 = lshr i32 %823, 16""  %823 = add nuw nsw i32 %822, %821" -> "  %825 = and i32 %823, 65535"
"  %824 = lshr i32 %820, 16"
"  %824 = lshr i32 %820, 16" -> "  %826 = add nuw nsw i32 %825, %824"
"  %825 = and i32 %823, 65535"
"  %825 = and i32 %823, 65535" -> "  %826 = add nuw nsw i32 %825, %824"
"  %826 = add nuw nsw i32 %825, %824"
"  %826 = add nuw nsw i32 %825, %824" -> "  %1179 = and i32 %826, 65535""  %826 = add nuw nsw i32 %825, %824" -> "  %828 = lshr i32 %826, 16"
"  %827 = lshr i32 %823, 16"
"  %827 = lshr i32 %823, 16" -> "  %829 = add nuw nsw i32 %828, %827"
"  %828 = lshr i32 %826, 16"
"  %828 = lshr i32 %826, 16" -> "  %829 = add nuw nsw i32 %828, %827"
"  %829 = add nuw nsw i32 %828, %827"
"  %829 = add nuw nsw i32 %828, %827" -> "  %840 = add nuw nsw i32 %829, %839"
"  %830 = and i32 %778, 65535"
"  %830 = and i32 %778, 65535" -> "  %832 = add nuw nsw i32 %831, %830"
"  %831 = and i32 %728, 65535"
"  %831 = and i32 %728, 65535" -> "  %832 = add nuw nsw i32 %831, %830"
"  %832 = add nuw nsw i32 %831, %830"
"  %832 = add nuw nsw i32 %831, %830" -> "  %839 = and i32 %832, 65535""  %832 = add nuw nsw i32 %831, %830" -> "  %836 = lshr i32 %832, 16"
"  %833 = and i32 %786, 65535"
"  %833 = and i32 %786, 65535" -> "  %835 = add nuw nsw i32 %834, %833"
"  %834 = and i32 %731, 65535"
"  %834 = and i32 %731, 65535" -> "  %835 = add nuw nsw i32 %834, %833"
"  %835 = add nuw nsw i32 %834, %833"
"  %835 = add nuw nsw i32 %834, %833" -> "  %845 = lshr i32 %835, 16""  %835 = add nuw nsw i32 %834, %833" -> "  %837 = and i32 %835, 65535"
"  %836 = lshr i32 %832, 16"
"  %836 = lshr i32 %832, 16" -> "  %838 = add nuw nsw i32 %837, %836"
"  %837 = and i32 %835, 65535"
"  %837 = and i32 %835, 65535" -> "  %838 = add nuw nsw i32 %837, %836"
"  %838 = add nuw nsw i32 %837, %836"
"  %838 = add nuw nsw i32 %837, %836" -> "  %847 = lshr i32 %838, 16""  %838 = add nuw nsw i32 %837, %836" -> "  %842 = and i32 %838, 65535"
"  %839 = and i32 %832, 65535"
"  %839 = and i32 %832, 65535" -> "  %840 = add nuw nsw i32 %829, %839"
"  %840 = add nuw nsw i32 %829, %839"
"  %840 = add nuw nsw i32 %829, %839" -> "  %1198 = and i32 %840, 65535""  %840 = add nuw nsw i32 %829, %839" -> "  %841 = lshr i32 %840, 16"
"  %841 = lshr i32 %840, 16"
"  %841 = lshr i32 %840, 16" -> "  %843 = add nuw nsw i32 %842, %841"
"  %842 = and i32 %838, 65535"
"  %842 = and i32 %838, 65535" -> "  %843 = add nuw nsw i32 %842, %841"
"  %843 = add nuw nsw i32 %842, %841"
"  %843 = add nuw nsw i32 %842, %841" -> "  %4490 = add nuw nsw i32 %4489, %843""  %843 = add nuw nsw i32 %842, %841" -> "  %1201 = and i32 %843, 65535""  %843 = add nuw nsw i32 %842, %841" -> "  %849 = lshr i32 %843, 16"
"  %844 = and i32 %810, 65535"
"  %844 = and i32 %810, 65535" -> "  %846 = add nuw nsw i32 %845, %844"
"  %845 = lshr i32 %835, 16"
"  %845 = lshr i32 %835, 16" -> "  %846 = add nuw nsw i32 %845, %844"
"  %846 = add nuw nsw i32 %845, %844"
"  %846 = add nuw nsw i32 %845, %844" -> "  %848 = add nuw nsw i32 %846, %847"
"  %847 = lshr i32 %838, 16"
"  %847 = lshr i32 %838, 16" -> "  %848 = add nuw nsw i32 %846, %847"
"  %848 = add nuw nsw i32 %846, %847"
"  %848 = add nuw nsw i32 %846, %847" -> "  %850 = add nuw nsw i32 %848, %849"
"  %849 = lshr i32 %843, 16"
"  %849 = lshr i32 %843, 16" -> "  %850 = add nuw nsw i32 %848, %849"
"  %850 = add nuw nsw i32 %848, %849"
"  %850 = add nuw nsw i32 %848, %849" -> "  %1007 = and i32 %850, 65535""  %850 = add nuw nsw i32 %848, %849" -> "  %852 = lshr i32 %850, 16"
"  %851 = and i32 %816, 65535"
"  %851 = and i32 %816, 65535" -> "  %853 = add nuw nsw i32 %852, %851"
"  %852 = lshr i32 %850, 16"
"  %852 = lshr i32 %850, 16" -> "  %853 = add nuw nsw i32 %852, %851"
"  %853 = add nuw nsw i32 %852, %851"
"  %853 = add nuw nsw i32 %852, %851" -> "  %1010 = and i32 %853, 65535""  %853 = add nuw nsw i32 %852, %851" -> "  %854 = lshr i32 %853, 16"
"  %854 = lshr i32 %853, 16"
"  %854 = lshr i32 %853, 16" -> "  %857 = add i32 %856, %854"
"  %855 = add i32 %807, %817"
"  %855 = add i32 %807, %817" -> "  %856 = add i32 %855, %818"
"  %856 = add i32 %855, %818"
"  %856 = add i32 %855, %818" -> "  %857 = add i32 %856, %854"
"  %857 = add i32 %856, %854"
"  %857 = add i32 %856, %854" -> "  %1016 = and i32 %857, 65535""  %857 = add i32 %856, %854" -> "  %1019 = lshr i32 %857, 16"
"  %858 = mul nuw i32 %514, %514"
"  %858 = mul nuw i32 %514, %514" -> "  %859 = lshr i32 %858, 16""  %858 = mul nuw i32 %514, %514" -> "  %968 = and i32 %858, 65535"
"  %859 = lshr i32 %858, 16"
"  %859 = lshr i32 %858, 16" -> "  %861 = add nuw i32 %860, %859"
"  %860 = mul nuw i32 %515, %514"
"  %860 = mul nuw i32 %515, %514" -> "  %863 = add nuw i32 %862, %860""  %860 = mul nuw i32 %515, %514" -> "  %861 = add nuw i32 %860, %859"
"  %861 = add nuw i32 %860, %859"
"  %861 = add nuw i32 %860, %859" -> "  %864 = lshr i32 %861, 16""  %861 = add nuw i32 %860, %859" -> "  %862 = and i32 %861, 65535"
"  %862 = and i32 %861, 65535"
"  %862 = and i32 %861, 65535" -> "  %863 = add nuw i32 %862, %860"
"  %863 = add nuw i32 %862, %860"
"  %863 = add nuw i32 %862, %860" -> "  %971 = and i32 %863, 65535""  %863 = add nuw i32 %862, %860" -> "  %867 = lshr i32 %863, 16"
"  %864 = lshr i32 %861, 16"
"  %864 = lshr i32 %861, 16" -> "  %866 = add nuw i32 %864, %865"
"  %865 = mul nuw i32 %515, %515"
"  %865 = mul nuw i32 %515, %515" -> "  %866 = add nuw i32 %864, %865"
"  %866 = add nuw i32 %864, %865"
"  %866 = add nuw i32 %864, %865" -> "  %870 = and i32 %866, -65536""  %866 = add nuw i32 %864, %865" -> "  %868 = and i32 %866, 65535"
"  %867 = lshr i32 %863, 16"
"  %867 = lshr i32 %863, 16" -> "  %869 = add nuw nsw i32 %867, %868"
"  %868 = and i32 %866, 65535"
"  %868 = and i32 %866, 65535" -> "  %869 = add nuw nsw i32 %867, %868"
"  %869 = add nuw nsw i32 %867, %868"
"  %869 = add nuw nsw i32 %867, %868" -> "  %871 = add i32 %869, %870"
"  %870 = and i32 %866, -65536"
"  %870 = and i32 %866, -65536" -> "  %871 = add i32 %869, %870"
"  %871 = add i32 %869, %870"
"  %871 = add i32 %869, %870" -> "  %896 = and i32 %871, 65535""  %871 = add i32 %869, %870" -> "  %891 = lshr i32 %871, 16"
"  %872 = mul nuw i32 %546, %514"
"  %872 = mul nuw i32 %546, %514" -> "  %895 = and i32 %872, 65535""  %872 = mul nuw i32 %546, %514" -> "  %873 = lshr i32 %872, 16"
"  %873 = lshr i32 %872, 16"
"  %873 = lshr i32 %872, 16" -> "  %879 = add nuw i32 %874, %873""  %873 = lshr i32 %872, 16" -> "  %876 = add nuw i32 %873, %875"
"  %874 = mul nuw i32 %549, %514"
"  %874 = mul nuw i32 %549, %514" -> "  %879 = add nuw i32 %874, %873""  %874 = mul nuw i32 %549, %514" -> "  %878 = add nuw i32 %877, %874"
"  %875 = mul nuw i32 %546, %515"
"  %875 = mul nuw i32 %546, %515" -> "  %881 = add nuw i32 %880, %875""  %875 = mul nuw i32 %546, %515" -> "  %876 = add nuw i32 %873, %875"
"  %876 = add nuw i32 %873, %875"
"  %876 = add nuw i32 %873, %875" -> "  %903 = lshr i32 %876, 16""  %876 = add nuw i32 %873, %875" -> "  %877 = and i32 %876, 65535"
"  %877 = and i32 %876, 65535"
"  %877 = and i32 %876, 65535" -> "  %878 = add nuw i32 %877, %874"
"  %878 = add nuw i32 %877, %874"
"  %878 = add nuw i32 %877, %874" -> "  %912 = and i32 %878, 65535""  %878 = add nuw i32 %877, %874" -> "  %905 = lshr i32 %878, 16"
"  %879 = add nuw i32 %874, %873"
"  %879 = add nuw i32 %874, %873" -> "  %882 = lshr i32 %879, 16""  %879 = add nuw i32 %874, %873" -> "  %880 = and i32 %879, 65535"
"  %880 = and i32 %879, 65535"
"  %880 = and i32 %879, 65535" -> "  %881 = add nuw i32 %880, %875"
"  %881 = add nuw i32 %880, %875"
"  %881 = add nuw i32 %880, %875" -> "  %890 = and i32 %881, 65535""  %881 = add nuw i32 %880, %875" -> "  %883 = lshr i32 %881, 16"
"  %882 = lshr i32 %879, 16"
"  %882 = lshr i32 %879, 16" -> "  %885 = add nuw i32 %882, %884"
"  %883 = lshr i32 %881, 16"
"  %883 = lshr i32 %881, 16" -> "  %887 = add nuw nsw i32 %883, %886"
"  %884 = mul nuw i32 %549, %515"
"  %884 = mul nuw i32 %549, %515" -> "  %904 = add nuw i32 %903, %884""  %884 = mul nuw i32 %549, %515" -> "  %885 = add nuw i32 %882, %884"
"  %885 = add nuw i32 %882, %884"
"  %885 = add nuw i32 %882, %884" -> "  %888 = and i32 %885, -65536""  %885 = add nuw i32 %882, %884" -> "  %886 = and i32 %885, 65535"
"  %886 = and i32 %885, 65535"
"  %886 = and i32 %885, 65535" -> "  %887 = add nuw nsw i32 %883, %886"
"  %887 = add nuw nsw i32 %883, %886"
"  %887 = add nuw nsw i32 %883, %886" -> "  %889 = add i32 %887, %888"
"  %888 = and i32 %885, -65536"
"  %888 = and i32 %885, -65536" -> "  %889 = add i32 %887, %888"
"  %889 = add i32 %887, %888"
"  %889 = add i32 %887, %888" -> "  %894 = add i32 %889, %893"
"  %890 = and i32 %881, 65535"
"  %890 = and i32 %881, 65535" -> "  %892 = add nuw nsw i32 %890, %891"
"  %891 = lshr i32 %871, 16"
"  %891 = lshr i32 %871, 16" -> "  %892 = add nuw nsw i32 %890, %891"
"  %892 = add nuw nsw i32 %890, %891"
"  %892 = add nuw nsw i32 %890, %891" -> "  %897 = and i32 %892, 65535""  %892 = add nuw nsw i32 %890, %891" -> "  %893 = lshr i32 %892, 16"
"  %893 = lshr i32 %892, 16"
"  %893 = lshr i32 %892, 16" -> "  %894 = add i32 %889, %893"
"  %894 = add i32 %889, %893"
"  %894 = add i32 %889, %893" -> "  %902 = add i32 %894, %901"
"  %895 = and i32 %872, 65535"
"  %895 = and i32 %872, 65535" -> "  %911 = add nuw nsw i32 %910, %895""  %895 = and i32 %872, 65535" -> "  %898 = add nuw nsw i32 %896, %895"
"  %896 = and i32 %871, 65535"
"  %896 = and i32 %871, 65535" -> "  %898 = add nuw nsw i32 %896, %895"
"  %897 = and i32 %892, 65535"
"  %897 = and i32 %892, 65535" -> "  %900 = add nuw nsw i32 %897, %899"
"  %898 = add nuw nsw i32 %896, %895"
"  %898 = add nuw nsw i32 %896, %895" -> "  %910 = and i32 %898, 65535""  %898 = add nuw nsw i32 %896, %895" -> "  %899 = lshr i32 %898, 16"
"  %899 = lshr i32 %898, 16"
"  %899 = lshr i32 %898, 16" -> "  %900 = add nuw nsw i32 %897, %899"
"  %900 = add nuw nsw i32 %897, %899"
"  %900 = add nuw nsw i32 %897, %899" -> "  %913 = and i32 %900, 65535""  %900 = add nuw nsw i32 %897, %899" -> "  %901 = lshr i32 %900, 16"
"  %901 = lshr i32 %900, 16"
"  %901 = lshr i32 %900, 16" -> "  %902 = add i32 %894, %901"
"  %902 = add i32 %894, %901"
"  %902 = add i32 %894, %901" -> "  %943 = lshr i32 %902, 16""  %902 = add i32 %894, %901" -> "  %939 = and i32 %902, 65535"
"  %903 = lshr i32 %876, 16"
"  %903 = lshr i32 %876, 16" -> "  %904 = add nuw i32 %903, %884"
"  %904 = add nuw i32 %903, %884"
"  %904 = add nuw i32 %903, %884" -> "  %908 = and i32 %904, -65536""  %904 = add nuw i32 %903, %884" -> "  %906 = and i32 %904, 65535"
"  %905 = lshr i32 %878, 16"
"  %905 = lshr i32 %878, 16" -> "  %907 = add nuw nsw i32 %905, %906"
"  %906 = and i32 %904, 65535"
"  %906 = and i32 %904, 65535" -> "  %907 = add nuw nsw i32 %905, %906"
"  %907 = add nuw nsw i32 %905, %906"
"  %907 = add nuw nsw i32 %905, %906" -> "  %909 = add i32 %907, %908"
"  %908 = and i32 %904, -65536"
"  %908 = and i32 %904, -65536" -> "  %909 = add i32 %907, %908"
"  %909 = add i32 %907, %908"
"  %909 = add i32 %907, %908" -> "  %916 = add i32 %909, %915"
"  %910 = and i32 %898, 65535"
"  %910 = and i32 %898, 65535" -> "  %911 = add nuw nsw i32 %910, %895"
"  %911 = add nuw nsw i32 %910, %895"
"  %911 = add nuw nsw i32 %910, %895" -> "  %977 = and i32 %911, 65535""  %911 = add nuw nsw i32 %910, %895" -> "  %918 = lshr i32 %911, 16"
"  %912 = and i32 %878, 65535"
"  %912 = and i32 %878, 65535" -> "  %914 = add nuw nsw i32 %913, %912"
"  %913 = and i32 %900, 65535"
"  %913 = and i32 %900, 65535" -> "  %914 = add nuw nsw i32 %913, %912"
"  %914 = add nuw nsw i32 %913, %912"
"  %914 = add nuw nsw i32 %913, %912" -> "  %917 = and i32 %914, 65535""  %914 = add nuw nsw i32 %913, %912" -> "  %915 = lshr i32 %914, 16"
"  %915 = lshr i32 %914, 16"
"  %915 = lshr i32 %914, 16" -> "  %916 = add i32 %909, %915"
"  %916 = add i32 %909, %915"
"  %916 = add i32 %909, %915" -> "  %921 = add i32 %916, %920"
"  %917 = and i32 %914, 65535"
"  %917 = and i32 %914, 65535" -> "  %919 = add nuw nsw i32 %917, %918"
"  %918 = lshr i32 %911, 16"
"  %918 = lshr i32 %911, 16" -> "  %919 = add nuw nsw i32 %917, %918"
"  %919 = add nuw nsw i32 %917, %918"
"  %919 = add nuw nsw i32 %917, %918" -> "  %980 = and i32 %919, 65535""  %919 = add nuw nsw i32 %917, %918" -> "  %920 = lshr i32 %919, 16"
"  %920 = lshr i32 %919, 16"
"  %920 = lshr i32 %919, 16" -> "  %921 = add i32 %916, %920"
"  %921 = add i32 %916, %920"
"  %921 = add i32 %916, %920" -> "  %956 = lshr i32 %921, 16""  %921 = add i32 %916, %920" -> "  %953 = and i32 %921, 65535"
"  %922 = mul nuw i32 %546, %546"
"  %922 = mul nuw i32 %546, %546" -> "  %940 = and i32 %922, 65535""  %922 = mul nuw i32 %546, %546" -> "  %923 = lshr i32 %922, 16"
"  %923 = lshr i32 %922, 16"
"  %923 = lshr i32 %922, 16" -> "  %926 = add nuw nsw i32 %925, %923"
"  %924 = mul nuw i32 %549, %546"
"  %924 = mul nuw i32 %549, %546" -> "  %930 = add nuw i32 %929, %924""  %924 = mul nuw i32 %549, %546" -> "  %927 = and i32 %924, -65536""  %924 = mul nuw i32 %549, %546" -> "  %925 = and i32 %924, 65535"
"  %925 = and i32 %924, 65535"
"  %925 = and i32 %924, 65535" -> "  %926 = add nuw nsw i32 %925, %923"
"  %926 = add nuw nsw i32 %925, %923"
"  %926 = add nuw nsw i32 %925, %923" -> "  %928 = add nuw i32 %926, %927"
"  %927 = and i32 %924, -65536"
"  %927 = and i32 %924, -65536" -> "  %928 = add nuw i32 %926, %927"
"  %928 = add nuw i32 %926, %927"
"  %928 = add nuw i32 %926, %927" -> "  %931 = lshr i32 %928, 16""  %928 = add nuw i32 %926, %927" -> "  %929 = and i32 %928, 65535"
"  %929 = and i32 %928, 65535"
"  %929 = and i32 %928, 65535" -> "  %930 = add nuw i32 %929, %924"
"  %930 = add nuw i32 %929, %924"
"  %930 = add nuw i32 %929, %924" -> "  %942 = and i32 %930, 65535""  %930 = add nuw i32 %929, %924" -> "  %934 = lshr i32 %930, 16"
"  %931 = lshr i32 %928, 16"
"  %931 = lshr i32 %928, 16" -> "  %933 = add nuw i32 %931, %932"
"  %932 = mul nuw i32 %549, %549"
"  %932 = mul nuw i32 %549, %549" -> "  %933 = add nuw i32 %931, %932"
"  %933 = add nuw i32 %931, %932"
"  %933 = add nuw i32 %931, %932" -> "  %937 = and i32 %933, -65536""  %933 = add nuw i32 %931, %932" -> "  %935 = and i32 %933, 65535"
"  %934 = lshr i32 %930, 16"
"  %934 = lshr i32 %930, 16" -> "  %936 = add nuw nsw i32 %934, %935"
"  %935 = and i32 %933, 65535"
"  %935 = and i32 %933, 65535" -> "  %936 = add nuw nsw i32 %934, %935"
"  %936 = add nuw nsw i32 %934, %935"
"  %936 = add nuw nsw i32 %934, %935" -> "  %938 = add i32 %936, %937"
"  %937 = and i32 %933, -65536"
"  %937 = and i32 %933, -65536" -> "  %938 = add i32 %936, %937"
"  %938 = add i32 %936, %937"
"  %938 = add i32 %936, %937" -> "  %946 = add i32 %938, %945"
"  %939 = and i32 %902, 65535"
"  %939 = and i32 %902, 65535" -> "  %941 = add nuw nsw i32 %939, %940"
"  %940 = and i32 %922, 65535"
"  %940 = and i32 %922, 65535" -> "  %941 = add nuw nsw i32 %939, %940"
"  %941 = add nuw nsw i32 %939, %940"
"  %941 = add nuw nsw i32 %939, %940" -> "  %952 = and i32 %941, 65535""  %941 = add nuw nsw i32 %939, %940" -> "  %948 = lshr i32 %941, 16"
"  %942 = and i32 %930, 65535"
"  %942 = and i32 %930, 65535" -> "  %944 = add nuw nsw i32 %943, %942"
"  %943 = lshr i32 %902, 16"
"  %943 = lshr i32 %902, 16" -> "  %944 = add nuw nsw i32 %943, %942"
"  %944 = add nuw nsw i32 %943, %942"
"  %944 = add nuw nsw i32 %943, %942" -> "  %947 = and i32 %944, 65535""  %944 = add nuw nsw i32 %943, %942" -> "  %945 = lshr i32 %944, 16"
"  %945 = lshr i32 %944, 16"
"  %945 = lshr i32 %944, 16" -> "  %946 = add i32 %938, %945"
"  %946 = add i32 %938, %945"
"  %946 = add i32 %938, %945" -> "  %951 = add i32 %946, %950"
"  %947 = and i32 %944, 65535"
"  %947 = and i32 %944, 65535" -> "  %949 = add nuw nsw i32 %947, %948"
"  %948 = lshr i32 %941, 16"
"  %948 = lshr i32 %941, 16" -> "  %949 = add nuw nsw i32 %947, %948"
"  %949 = add nuw nsw i32 %947, %948"
"  %949 = add nuw nsw i32 %947, %948" -> "  %955 = and i32 %949, 65535""  %949 = add nuw nsw i32 %947, %948" -> "  %950 = lshr i32 %949, 16"
"  %950 = lshr i32 %949, 16"
"  %950 = lshr i32 %949, 16" -> "  %951 = add i32 %946, %950"
"  %951 = add i32 %946, %950"
"  %951 = add i32 %946, %950" -> "  %964 = and i32 %951, -65536""  %951 = add i32 %946, %950" -> "  %962 = and i32 %951, 65535"
"  %952 = and i32 %941, 65535"
"  %952 = and i32 %941, 65535" -> "  %954 = add nuw nsw i32 %953, %952"
"  %953 = and i32 %921, 65535"
"  %953 = and i32 %921, 65535" -> "  %954 = add nuw nsw i32 %953, %952"
"  %954 = add nuw nsw i32 %953, %952"
"  %954 = add nuw nsw i32 %953, %952" -> "  %994 = and i32 %954, 65535""  %954 = add nuw nsw i32 %953, %952" -> "  %958 = lshr i32 %954, 16"
"  %955 = and i32 %949, 65535"
"  %955 = and i32 %949, 65535" -> "  %957 = add nuw nsw i32 %955, %956"
"  %956 = lshr i32 %921, 16"
"  %956 = lshr i32 %921, 16" -> "  %957 = add nuw nsw i32 %955, %956"
"  %957 = add nuw nsw i32 %955, %956"
"  %957 = add nuw nsw i32 %955, %956" -> "  %961 = lshr i32 %957, 16""  %957 = add nuw nsw i32 %955, %956" -> "  %959 = and i32 %957, 65535"
"  %958 = lshr i32 %954, 16"
"  %958 = lshr i32 %954, 16" -> "  %960 = add nuw nsw i32 %959, %958"
"  %959 = and i32 %957, 65535"
"  %959 = and i32 %957, 65535" -> "  %960 = add nuw nsw i32 %959, %958"
"  %960 = add nuw nsw i32 %959, %958"
"  %960 = add nuw nsw i32 %959, %958" -> "  %1001 = and i32 %960, 65535""  %960 = add nuw nsw i32 %959, %958" -> "  %966 = lshr i32 %960, 16"
"  %961 = lshr i32 %957, 16"
"  %961 = lshr i32 %957, 16" -> "  %963 = add nuw nsw i32 %961, %962"
"  %962 = and i32 %951, 65535"
"  %962 = and i32 %951, 65535" -> "  %963 = add nuw nsw i32 %961, %962"
"  %963 = add nuw nsw i32 %961, %962"
"  %963 = add nuw nsw i32 %961, %962" -> "  %965 = add i32 %963, %964"
"  %964 = and i32 %951, -65536"
"  %964 = and i32 %951, -65536" -> "  %965 = add i32 %963, %964"
"  %965 = add i32 %963, %964"
"  %965 = add i32 %963, %964" -> "  %967 = add i32 %965, %966"
"  %966 = lshr i32 %960, 16"
"  %966 = lshr i32 %960, 16" -> "  %967 = add i32 %965, %966"
"  %967 = add i32 %965, %966"
"  %967 = add i32 %965, %966" -> "  %1005 = add i32 %967, %1004"
"  %968 = and i32 %858, 65535"
"  %968 = and i32 %858, 65535" -> "  %970 = add nuw nsw i32 %969, %968"
"  %969 = and i32 %738, 65535"
"  %969 = and i32 %738, 65535" -> "  %970 = add nuw nsw i32 %969, %968"
"  %970 = add nuw nsw i32 %969, %968"
"  %970 = add nuw nsw i32 %969, %968" -> "  %1006 = and i32 %970, 65535""  %970 = add nuw nsw i32 %969, %968" -> "  %974 = lshr i32 %970, 16"
"  %971 = and i32 %863, 65535"
"  %971 = and i32 %863, 65535" -> "  %973 = add nuw nsw i32 %972, %971"
"  %972 = and i32 %741, 65535"
"  %972 = and i32 %741, 65535" -> "  %973 = add nuw nsw i32 %972, %971"
"  %973 = add nuw nsw i32 %972, %971"
"  %973 = add nuw nsw i32 %972, %971" -> "  %987 = lshr i32 %973, 16""  %973 = add nuw nsw i32 %972, %971" -> "  %975 = and i32 %973, 65535"
"  %974 = lshr i32 %970, 16"
"  %974 = lshr i32 %970, 16" -> "  %976 = add nuw nsw i32 %975, %974"
"  %975 = and i32 %973, 65535"
"  %975 = and i32 %973, 65535" -> "  %976 = add nuw nsw i32 %975, %974"
"  %976 = add nuw nsw i32 %975, %974"
"  %976 = add nuw nsw i32 %975, %974" -> "  %1009 = and i32 %976, 65535""  %976 = add nuw nsw i32 %975, %974" -> "  %988 = lshr i32 %976, 16"
"  %977 = and i32 %911, 65535"
"  %977 = and i32 %911, 65535" -> "  %979 = add nuw nsw i32 %978, %977"
"  %978 = and i32 %743, 65535"
"  %978 = and i32 %743, 65535" -> "  %979 = add nuw nsw i32 %978, %977"
"  %979 = add nuw nsw i32 %978, %977"
"  %979 = add nuw nsw i32 %978, %977" -> "  %986 = and i32 %979, 65535""  %979 = add nuw nsw i32 %978, %977" -> "  %983 = lshr i32 %979, 16"
"  %980 = and i32 %919, 65535"
"  %980 = and i32 %919, 65535" -> "  %982 = add nuw nsw i32 %981, %980"
"  %981 = lshr i32 %743, 16"
"  %981 = lshr i32 %743, 16" -> "  %982 = add nuw nsw i32 %981, %980"
"  %982 = add nuw nsw i32 %981, %980"
"  %982 = add nuw nsw i32 %981, %980" -> "  %995 = lshr i32 %982, 16""  %982 = add nuw nsw i32 %981, %980" -> "  %984 = and i32 %982, 65535"
"  %983 = lshr i32 %979, 16"
"  %983 = lshr i32 %979, 16" -> "  %985 = add nuw nsw i32 %984, %983"
"  %984 = and i32 %982, 65535"
"  %984 = and i32 %982, 65535" -> "  %985 = add nuw nsw i32 %984, %983"
"  %985 = add nuw nsw i32 %984, %983"
"  %985 = add nuw nsw i32 %984, %983" -> "  %997 = lshr i32 %985, 16""  %985 = add nuw nsw i32 %984, %983" -> "  %992 = and i32 %985, 65535"
"  %986 = and i32 %979, 65535"
"  %986 = and i32 %979, 65535" -> "  %990 = add nuw nsw i32 %989, %986"
"  %987 = lshr i32 %973, 16"
"  %987 = lshr i32 %973, 16" -> "  %989 = add nuw nsw i32 %988, %987"
"  %988 = lshr i32 %976, 16"
"  %988 = lshr i32 %976, 16" -> "  %989 = add nuw nsw i32 %988, %987"
"  %989 = add nuw nsw i32 %988, %987"
"  %989 = add nuw nsw i32 %988, %987" -> "  %990 = add nuw nsw i32 %989, %986"
"  %990 = add nuw nsw i32 %989, %986"
"  %990 = add nuw nsw i32 %989, %986" -> "  %1015 = and i32 %990, 65535""  %990 = add nuw nsw i32 %989, %986" -> "  %991 = lshr i32 %990, 16"
"  %991 = lshr i32 %990, 16"
"  %991 = lshr i32 %990, 16" -> "  %993 = add nuw nsw i32 %991, %992"
"  %992 = and i32 %985, 65535"
"  %992 = and i32 %985, 65535" -> "  %993 = add nuw nsw i32 %991, %992"
"  %993 = add nuw nsw i32 %991, %992"
"  %993 = add nuw nsw i32 %991, %992" -> "  %1018 = and i32 %993, 65535""  %993 = add nuw nsw i32 %991, %992" -> "  %999 = lshr i32 %993, 16"
"  %994 = and i32 %954, 65535"
"  %994 = and i32 %954, 65535" -> "  %996 = add nuw nsw i32 %995, %994"
"  %995 = lshr i32 %982, 16"
"  %995 = lshr i32 %982, 16" -> "  %996 = add nuw nsw i32 %995, %994"
"  %996 = add nuw nsw i32 %995, %994"
"  %996 = add nuw nsw i32 %995, %994" -> "  %998 = add nuw nsw i32 %996, %997"
"  %997 = lshr i32 %985, 16"
"  %997 = lshr i32 %985, 16" -> "  %998 = add nuw nsw i32 %996, %997"
"  %998 = add nuw nsw i32 %996, %997"
"  %998 = add nuw nsw i32 %996, %997" -> "  %1000 = add nuw nsw i32 %998, %999"
"  %999 = lshr i32 %993, 16"
"  %999 = lshr i32 %993, 16" -> "  %1000 = add nuw nsw i32 %998, %999"
"  %1000 = add nuw nsw i32 %998, %999"
"  %1000 = add nuw nsw i32 %998, %999" -> "  %1032 = and i32 %1000, 65535""  %1000 = add nuw nsw i32 %998, %999" -> "  %1002 = lshr i32 %1000, 16"
"  %1001 = and i32 %960, 65535"
"  %1001 = and i32 %960, 65535" -> "  %1003 = add nuw nsw i32 %1002, %1001"
"  %1002 = lshr i32 %1000, 16"
"  %1002 = lshr i32 %1000, 16" -> "  %1003 = add nuw nsw i32 %1002, %1001"
"  %1003 = add nuw nsw i32 %1002, %1001"
"  %1003 = add nuw nsw i32 %1002, %1001" -> "  %1039 = and i32 %1003, 65535""  %1003 = add nuw nsw i32 %1002, %1001" -> "  %1004 = lshr i32 %1003, 16"
"  %1004 = lshr i32 %1003, 16"
"  %1004 = lshr i32 %1003, 16" -> "  %1005 = add i32 %967, %1004"
"  %1005 = add i32 %967, %1004"
"  %1005 = add i32 %967, %1004" -> "  %1043 = add i32 %1005, %1042"
"  %1006 = and i32 %970, 65535"
"  %1006 = and i32 %970, 65535" -> "  %1008 = add nuw nsw i32 %1007, %1006"
"  %1007 = and i32 %850, 65535"
"  %1007 = and i32 %850, 65535" -> "  %1008 = add nuw nsw i32 %1007, %1006"
"  %1008 = add nuw nsw i32 %1007, %1006"
"  %1008 = add nuw nsw i32 %1007, %1006" -> "  %1724 = and i32 %1008, 65535""  %1008 = add nuw nsw i32 %1007, %1006" -> "  %1012 = lshr i32 %1008, 16"
"  %1009 = and i32 %976, 65535"
"  %1009 = and i32 %976, 65535" -> "  %1011 = add nuw nsw i32 %1010, %1009"
"  %1010 = and i32 %853, 65535"
"  %1010 = and i32 %853, 65535" -> "  %1011 = add nuw nsw i32 %1010, %1009"
"  %1011 = add nuw nsw i32 %1010, %1009"
"  %1011 = add nuw nsw i32 %1010, %1009" -> "  %1025 = lshr i32 %1011, 16""  %1011 = add nuw nsw i32 %1010, %1009" -> "  %1013 = and i32 %1011, 65535"
"  %1012 = lshr i32 %1008, 16"
"  %1012 = lshr i32 %1008, 16" -> "  %1014 = add nuw nsw i32 %1013, %1012"
"  %1013 = and i32 %1011, 65535"
"  %1013 = and i32 %1011, 65535" -> "  %1014 = add nuw nsw i32 %1013, %1012"
"  %1014 = add nuw nsw i32 %1013, %1012"
"  %1014 = add nuw nsw i32 %1013, %1012" -> "  %1730 = and i32 %1014, 65535""  %1014 = add nuw nsw i32 %1013, %1012" -> "  %1026 = lshr i32 %1014, 16"
"  %1015 = and i32 %990, 65535"
"  %1015 = and i32 %990, 65535" -> "  %1017 = add nuw nsw i32 %1016, %1015"
"  %1016 = and i32 %857, 65535"
"  %1016 = and i32 %857, 65535" -> "  %1017 = add nuw nsw i32 %1016, %1015"
"  %1017 = add nuw nsw i32 %1016, %1015"
"  %1017 = add nuw nsw i32 %1016, %1015" -> "  %1024 = and i32 %1017, 65535""  %1017 = add nuw nsw i32 %1016, %1015" -> "  %1021 = lshr i32 %1017, 16"
"  %1018 = and i32 %993, 65535"
"  %1018 = and i32 %993, 65535" -> "  %1020 = add nuw nsw i32 %1018, %1019"
"  %1019 = lshr i32 %857, 16"
"  %1019 = lshr i32 %857, 16" -> "  %1020 = add nuw nsw i32 %1018, %1019"
"  %1020 = add nuw nsw i32 %1018, %1019"
"  %1020 = add nuw nsw i32 %1018, %1019" -> "  %1033 = lshr i32 %1020, 16""  %1020 = add nuw nsw i32 %1018, %1019" -> "  %1022 = and i32 %1020, 65535"
"  %1021 = lshr i32 %1017, 16"
"  %1021 = lshr i32 %1017, 16" -> "  %1023 = add nuw nsw i32 %1022, %1021"
"  %1022 = and i32 %1020, 65535"
"  %1022 = and i32 %1020, 65535" -> "  %1023 = add nuw nsw i32 %1022, %1021"
"  %1023 = add nuw nsw i32 %1022, %1021"
"  %1023 = add nuw nsw i32 %1022, %1021" -> "  %1035 = lshr i32 %1023, 16""  %1023 = add nuw nsw i32 %1022, %1021" -> "  %1030 = and i32 %1023, 65535"
"  %1024 = and i32 %1017, 65535"
"  %1024 = and i32 %1017, 65535" -> "  %1028 = add nuw nsw i32 %1027, %1024"
"  %1025 = lshr i32 %1011, 16"
"  %1025 = lshr i32 %1011, 16" -> "  %1027 = add nuw nsw i32 %1026, %1025"
"  %1026 = lshr i32 %1014, 16"
"  %1026 = lshr i32 %1014, 16" -> "  %1027 = add nuw nsw i32 %1026, %1025"
"  %1027 = add nuw nsw i32 %1026, %1025"
"  %1027 = add nuw nsw i32 %1026, %1025" -> "  %1028 = add nuw nsw i32 %1027, %1024"
"  %1028 = add nuw nsw i32 %1027, %1024"
"  %1028 = add nuw nsw i32 %1027, %1024" -> "  %1750 = and i32 %1028, 65535""  %1028 = add nuw nsw i32 %1027, %1024" -> "  %1029 = lshr i32 %1028, 16"
"  %1029 = lshr i32 %1028, 16"
"  %1029 = lshr i32 %1028, 16" -> "  %1031 = add nuw nsw i32 %1030, %1029"
"  %1030 = and i32 %1023, 65535"
"  %1030 = and i32 %1023, 65535" -> "  %1031 = add nuw nsw i32 %1030, %1029"
"  %1031 = add nuw nsw i32 %1030, %1029"
"  %1031 = add nuw nsw i32 %1030, %1029" -> "  %1751 = and i32 %1031, 65535""  %1031 = add nuw nsw i32 %1030, %1029" -> "  %1037 = lshr i32 %1031, 16"
"  %1032 = and i32 %1000, 65535"
"  %1032 = and i32 %1000, 65535" -> "  %1034 = add nuw nsw i32 %1033, %1032"
"  %1033 = lshr i32 %1020, 16"
"  %1033 = lshr i32 %1020, 16" -> "  %1034 = add nuw nsw i32 %1033, %1032"
"  %1034 = add nuw nsw i32 %1033, %1032"
"  %1034 = add nuw nsw i32 %1033, %1032" -> "  %1036 = add nuw nsw i32 %1034, %1035"
"  %1035 = lshr i32 %1023, 16"
"  %1035 = lshr i32 %1023, 16" -> "  %1036 = add nuw nsw i32 %1034, %1035"
"  %1036 = add nuw nsw i32 %1034, %1035"
"  %1036 = add nuw nsw i32 %1034, %1035" -> "  %1038 = add nuw nsw i32 %1036, %1037"
"  %1037 = lshr i32 %1031, 16"
"  %1037 = lshr i32 %1031, 16" -> "  %1038 = add nuw nsw i32 %1036, %1037"
"  %1038 = add nuw nsw i32 %1036, %1037"
"  %1038 = add nuw nsw i32 %1036, %1037" -> "  %1873 = and i32 %1038, 65535""  %1038 = add nuw nsw i32 %1036, %1037" -> "  %1040 = lshr i32 %1038, 16"
"  %1039 = and i32 %1003, 65535"
"  %1039 = and i32 %1003, 65535" -> "  %1041 = add nuw nsw i32 %1040, %1039"
"  %1040 = lshr i32 %1038, 16"
"  %1040 = lshr i32 %1038, 16" -> "  %1041 = add nuw nsw i32 %1040, %1039"
"  %1041 = add nuw nsw i32 %1040, %1039"
"  %1041 = add nuw nsw i32 %1040, %1039" -> "  %1879 = and i32 %1041, 65535""  %1041 = add nuw nsw i32 %1040, %1039" -> "  %1042 = lshr i32 %1041, 16"
"  %1042 = lshr i32 %1041, 16"
"  %1042 = lshr i32 %1041, 16" -> "  %1043 = add i32 %1005, %1042"
"  %1043 = add i32 %1005, %1042"
"  %1043 = add i32 %1005, %1042" -> "  %1896 = and i32 %1043, 65535""  %1043 = add i32 %1005, %1042" -> "  %1897 = lshr i32 %1043, 16"
"  %1044 = and i32 %392, 65535"
"  %1044 = and i32 %392, 65535" -> "  %4454 = add nuw nsw i32 %4453, %1044""  %1044 = and i32 %392, 65535" -> "  %2823 = mul nuw nsw i32 %1044, 4087""  %1044 = and i32 %392, 65535" -> "  %1045 = mul nuw i32 %1044, 37996""  %1044 = and i32 %392, 65535" -> "  %1053 = mul nuw i32 %1044, 45147""  %1044 = and i32 %392, 65535" -> "  %1107 = mul nuw i32 %1044, 62728""  %1044 = and i32 %392, 65535" -> "  %1100 = mul nuw nsw i32 %1044, 1324""  %1044 = and i32 %392, 65535" -> "  %1409 = mul nuw i32 %1044, 42170""  %1044 = and i32 %392, 65535" -> "  %1402 = mul nuw nsw i32 %1044, 31112""  %1044 = and i32 %392, 65535" -> "  %1360 = mul nuw i32 %1044, 46547""  %1044 = and i32 %392, 65535" -> "  %1350 = mul nuw nsw i32 %1044, 17857""  %1044 = and i32 %392, 65535" -> "  %2578 = mul nuw nsw i32 %1044, 29744""  %1044 = and i32 %392, 65535" -> "  %2571 = mul nuw nsw i32 %1044, 24315""  %1044 = and i32 %392, 65535" -> "  %2529 = mul nuw nsw i32 %1044, 9871""  %1044 = and i32 %392, 65535" -> "  %2522 = mul nuw i32 %1044, 42779""  %1044 = and i32 %392, 65535" -> "  %2879 = mul nuw i32 %1044, 36786""  %1044 = and i32 %392, 65535" -> "  %2872 = mul nuw nsw i32 %1044, 21884""  %1044 = and i32 %392, 65535" -> "  %2830 = mul nuw nsw i32 %1044, 11561"
"  %1045 = mul nuw i32 %1044, 37996"
"  %1045 = mul nuw i32 %1044, 37996" -> "  %1046 = lshr i32 %1045, 16"
"  %1046 = lshr i32 %1045, 16"
"  %1046 = lshr i32 %1045, 16" -> "  %1050 = add nuw nsw i32 %1049, %1046"
"  %1047 = and i32 %401, 65535"
"  %1047 = and i32 %401, 65535" -> "  %4456 = add nuw nsw i32 %4455, %1047""  %1047 = and i32 %401, 65535" -> "  %1048 = mul nuw i32 %1047, 37996""  %1047 = and i32 %401, 65535" -> "  %1057 = mul nuw i32 %1047, 45147""  %1047 = and i32 %401, 65535" -> "  %1111 = mul nuw i32 %1047, 62728""  %1047 = and i32 %401, 65535" -> "  %1102 = mul nuw nsw i32 %1047, 1324""  %1047 = and i32 %401, 65535" -> "  %1413 = mul nuw i32 %1047, 42170""  %1047 = and i32 %401, 65535" -> "  %1404 = mul nuw nsw i32 %1047, 31112""  %1047 = and i32 %401, 65535" -> "  %1364 = mul nuw i32 %1047, 46547""  %1047 = and i32 %401, 65535" -> "  %1355 = mul nuw nsw i32 %1047, 17857""  %1047 = and i32 %401, 65535" -> "  %2582 = mul nuw nsw i32 %1047, 29744""  %1047 = and i32 %401, 65535" -> "  %2573 = mul nuw nsw i32 %1047, 24315""  %1047 = and i32 %401, 65535" -> "  %2533 = mul nuw nsw i32 %1047, 9871""  %1047 = and i32 %401, 65535" -> "  %2524 = mul nuw i32 %1047, 42779""  %1047 = and i32 %401, 65535" -> "  %2883 = mul nuw i32 %1047, 36786""  %1047 = and i32 %401, 65535" -> "  %2874 = mul nuw nsw i32 %1047, 21884""  %1047 = and i32 %401, 65535" -> "  %2834 = mul nuw nsw i32 %1047, 11561""  %1047 = and i32 %401, 65535" -> "  %2825 = mul nuw nsw i32 %1047, 4087"
"  %1048 = mul nuw i32 %1047, 37996"
"  %1048 = mul nuw i32 %1047, 37996" -> "  %1051 = and i32 %1048, -65536""  %1048 = mul nuw i32 %1047, 37996" -> "  %1049 = and i32 %1048, 65532"
"  %1049 = and i32 %1048, 65532"
"  %1049 = and i32 %1048, 65532" -> "  %1050 = add nuw nsw i32 %1049, %1046"
"  %1050 = add nuw nsw i32 %1049, %1046"
"  %1050 = add nuw nsw i32 %1049, %1046" -> "  %1052 = add nuw i32 %1050, %1051"
"  %1051 = and i32 %1048, -65536"
"  %1051 = and i32 %1048, -65536" -> "  %1052 = add nuw i32 %1050, %1051"
"  %1052 = add nuw i32 %1050, %1051"
"  %1052 = add nuw i32 %1050, %1051" -> "  %1056 = lshr i32 %1052, 16""  %1052 = add nuw i32 %1050, %1051" -> "  %1054 = and i32 %1052, 65535"
"  %1053 = mul nuw i32 %1044, 45147"
"  %1053 = mul nuw i32 %1044, 45147" -> "  %1055 = add nuw i32 %1054, %1053"
"  %1054 = and i32 %1052, 65535"
"  %1054 = and i32 %1052, 65535" -> "  %1055 = add nuw i32 %1054, %1053"
"  %1055 = add nuw i32 %1054, %1053"
"  %1055 = add nuw i32 %1054, %1053" -> "  %1059 = lshr i32 %1055, 16"
"  %1056 = lshr i32 %1052, 16"
"  %1056 = lshr i32 %1052, 16" -> "  %1058 = add nuw i32 %1056, %1057"
"  %1057 = mul nuw i32 %1047, 45147"
"  %1057 = mul nuw i32 %1047, 45147" -> "  %1058 = add nuw i32 %1056, %1057"
"  %1058 = add nuw i32 %1056, %1057"
"  %1058 = add nuw i32 %1056, %1057" -> "  %1060 = and i32 %1058, 65535""  %1058 = add nuw i32 %1056, %1057" -> "  %1062 = and i32 %1058, -65536"
"  %1059 = lshr i32 %1055, 16"
"  %1059 = lshr i32 %1055, 16" -> "  %1061 = add nuw nsw i32 %1059, %1060"
"  %1060 = and i32 %1058, 65535"
"  %1060 = and i32 %1058, 65535" -> "  %1061 = add nuw nsw i32 %1059, %1060"
"  %1061 = add nuw nsw i32 %1059, %1060"
"  %1061 = add nuw nsw i32 %1059, %1060" -> "  %1063 = add nuw i32 %1061, %1062"
"  %1062 = and i32 %1058, -65536"
"  %1062 = and i32 %1058, -65536" -> "  %1063 = add nuw i32 %1061, %1062"
"  %1063 = add nuw i32 %1061, %1062"
"  %1063 = add nuw i32 %1061, %1062" -> "  %1088 = lshr i32 %1063, 16""  %1063 = add nuw i32 %1061, %1062" -> "  %1084 = and i32 %1063, 65535"
"  %1064 = and i32 %457, 65535"
"  %1064 = and i32 %457, 65535" -> "  %4463 = add nuw nsw i32 %4462, %1064""  %1064 = and i32 %457, 65535" -> "  %2903 = mul nuw nsw i32 %1064, 21884""  %1064 = and i32 %457, 65535" -> "  %1066 = mul nuw i32 %1064, 37996""  %1064 = and i32 %457, 65535" -> "  %1073 = mul nuw i32 %1064, 45147""  %1064 = and i32 %457, 65535" -> "  %1131 = mul nuw nsw i32 %1064, 1324""  %1064 = and i32 %457, 65535" -> "  %1138 = mul nuw i32 %1064, 62728""  %1064 = and i32 %457, 65535" -> "  %1440 = mul nuw i32 %1064, 42170""  %1064 = and i32 %457, 65535" -> "  %1433 = mul nuw nsw i32 %1064, 31112""  %1064 = and i32 %457, 65535" -> "  %1378 = mul nuw i32 %1064, 46547""  %1064 = and i32 %457, 65535" -> "  %1371 = mul nuw nsw i32 %1064, 17857""  %1064 = and i32 %457, 65535" -> "  %2609 = mul nuw nsw i32 %1064, 29744""  %1064 = and i32 %457, 65535" -> "  %2602 = mul nuw nsw i32 %1064, 24315""  %1064 = and i32 %457, 65535" -> "  %2547 = mul nuw nsw i32 %1064, 9871""  %1064 = and i32 %457, 65535" -> "  %2540 = mul nuw i32 %1064, 42779""  %1064 = and i32 %457, 65535" -> "  %2910 = mul nuw i32 %1064, 36786""  %1064 = and i32 %457, 65535" -> "  %2848 = mul nuw nsw i32 %1064, 11561""  %1064 = and i32 %457, 65535" -> "  %2841 = mul nuw nsw i32 %1064, 4087"
"  %1065 = and i32 %465, 65535"
"  %1065 = and i32 %465, 65535" -> "  %4465 = add nuw nsw i32 %4464, %1065""  %1065 = and i32 %465, 65535" -> "  %1068 = mul nuw i32 %1065, 37996""  %1065 = and i32 %465, 65535" -> "  %1077 = mul nuw i32 %1065, 45147""  %1065 = and i32 %465, 65535" -> "  %1133 = mul nuw nsw i32 %1065, 1324""  %1065 = and i32 %465, 65535" -> "  %1142 = mul nuw i32 %1065, 62728""  %1065 = and i32 %465, 65535" -> "  %1444 = mul nuw i32 %1065, 42170""  %1065 = and i32 %465, 65535" -> "  %1435 = mul nuw nsw i32 %1065, 31112""  %1065 = and i32 %465, 65535" -> "  %1382 = mul nuw i32 %1065, 46547""  %1065 = and i32 %465, 65535" -> "  %1373 = mul nuw nsw i32 %1065, 17857""  %1065 = and i32 %465, 65535" -> "  %2613 = mul nuw nsw i32 %1065, 29744""  %1065 = and i32 %465, 65535" -> "  %2604 = mul nuw nsw i32 %1065, 24315""  %1065 = and i32 %465, 65535" -> "  %2551 = mul nuw nsw i32 %1065, 9871""  %1065 = and i32 %465, 65535" -> "  %2542 = mul nuw i32 %1065, 42779""  %1065 = and i32 %465, 65535" -> "  %2914 = mul nuw i32 %1065, 36786""  %1065 = and i32 %465, 65535" -> "  %2905 = mul nuw nsw i32 %1065, 21884""  %1065 = and i32 %465, 65535" -> "  %2852 = mul nuw nsw i32 %1065, 11561""  %1065 = and i32 %465, 65535" -> "  %2843 = mul nuw nsw i32 %1065, 4087"
"  %1066 = mul nuw i32 %1064, 37996"
"  %1066 = mul nuw i32 %1064, 37996" -> "  %1085 = and i32 %1066, 65532""  %1066 = mul nuw i32 %1064, 37996" -> "  %1067 = lshr i32 %1066, 16"
"  %1067 = lshr i32 %1066, 16"
"  %1067 = lshr i32 %1066, 16" -> "  %1070 = add nuw nsw i32 %1069, %1067"
"  %1068 = mul nuw i32 %1065, 37996"
"  %1068 = mul nuw i32 %1065, 37996" -> "  %1071 = and i32 %1068, -65536""  %1068 = mul nuw i32 %1065, 37996" -> "  %1069 = and i32 %1068, 65532"
"  %1069 = and i32 %1068, 65532"
"  %1069 = and i32 %1068, 65532" -> "  %1070 = add nuw nsw i32 %1069, %1067"
"  %1070 = add nuw nsw i32 %1069, %1067"
"  %1070 = add nuw nsw i32 %1069, %1067" -> "  %1072 = add nuw i32 %1070, %1071"
"  %1071 = and i32 %1068, -65536"
"  %1071 = and i32 %1068, -65536" -> "  %1072 = add nuw i32 %1070, %1071"
"  %1072 = add nuw i32 %1070, %1071"
"  %1072 = add nuw i32 %1070, %1071" -> "  %1076 = lshr i32 %1072, 16""  %1072 = add nuw i32 %1070, %1071" -> "  %1074 = and i32 %1072, 65535"
"  %1073 = mul nuw i32 %1064, 45147"
"  %1073 = mul nuw i32 %1064, 45147" -> "  %1075 = add nuw i32 %1074, %1073"
"  %1074 = and i32 %1072, 65535"
"  %1074 = and i32 %1072, 65535" -> "  %1075 = add nuw i32 %1074, %1073"
"  %1075 = add nuw i32 %1074, %1073"
"  %1075 = add nuw i32 %1074, %1073" -> "  %1087 = and i32 %1075, 65535""  %1075 = add nuw i32 %1074, %1073" -> "  %1079 = lshr i32 %1075, 16"
"  %1076 = lshr i32 %1072, 16"
"  %1076 = lshr i32 %1072, 16" -> "  %1078 = add nuw i32 %1076, %1077"
"  %1077 = mul nuw i32 %1065, 45147"
"  %1077 = mul nuw i32 %1065, 45147" -> "  %1078 = add nuw i32 %1076, %1077"
"  %1078 = add nuw i32 %1076, %1077"
"  %1078 = add nuw i32 %1076, %1077" -> "  %1082 = and i32 %1078, -65536""  %1078 = add nuw i32 %1076, %1077" -> "  %1080 = and i32 %1078, 65535"
"  %1079 = lshr i32 %1075, 16"
"  %1079 = lshr i32 %1075, 16" -> "  %1081 = add nuw nsw i32 %1079, %1080"
"  %1080 = and i32 %1078, 65535"
"  %1080 = and i32 %1078, 65535" -> "  %1081 = add nuw nsw i32 %1079, %1080"
"  %1081 = add nuw nsw i32 %1079, %1080"
"  %1081 = add nuw nsw i32 %1079, %1080" -> "  %1083 = add nuw i32 %1081, %1082"
"  %1082 = and i32 %1078, -65536"
"  %1082 = and i32 %1078, -65536" -> "  %1083 = add nuw i32 %1081, %1082"
"  %1083 = add nuw i32 %1081, %1082"
"  %1083 = add nuw i32 %1081, %1082" -> "  %1096 = and i32 %1083, -65536""  %1083 = add nuw i32 %1081, %1082" -> "  %1094 = and i32 %1083, 65535"
"  %1084 = and i32 %1063, 65535"
"  %1084 = and i32 %1063, 65535" -> "  %1086 = add nuw nsw i32 %1084, %1085"
"  %1085 = and i32 %1066, 65532"
"  %1085 = and i32 %1066, 65532" -> "  %1086 = add nuw nsw i32 %1084, %1085"
"  %1086 = add nuw nsw i32 %1084, %1085"
"  %1086 = add nuw nsw i32 %1084, %1085" -> "  %1118 = and i32 %1086, 65535""  %1086 = add nuw nsw i32 %1084, %1085" -> "  %1090 = lshr i32 %1086, 16"
"  %1087 = and i32 %1075, 65535"
"  %1087 = and i32 %1075, 65535" -> "  %1089 = add nuw nsw i32 %1087, %1088"
"  %1088 = lshr i32 %1063, 16"
"  %1088 = lshr i32 %1063, 16" -> "  %1089 = add nuw nsw i32 %1087, %1088"
"  %1089 = add nuw nsw i32 %1087, %1088"
"  %1089 = add nuw nsw i32 %1087, %1088" -> "  %1093 = lshr i32 %1089, 16""  %1089 = add nuw nsw i32 %1087, %1088" -> "  %1091 = and i32 %1089, 65535"
"  %1090 = lshr i32 %1086, 16"
"  %1090 = lshr i32 %1086, 16" -> "  %1092 = add nuw nsw i32 %1091, %1090"
"  %1091 = and i32 %1089, 65535"
"  %1091 = and i32 %1089, 65535" -> "  %1092 = add nuw nsw i32 %1091, %1090"
"  %1092 = add nuw nsw i32 %1091, %1090"
"  %1092 = add nuw nsw i32 %1091, %1090" -> "  %1121 = and i32 %1092, 65535""  %1092 = add nuw nsw i32 %1091, %1090" -> "  %1098 = lshr i32 %1092, 16"
"  %1093 = lshr i32 %1089, 16"
"  %1093 = lshr i32 %1089, 16" -> "  %1095 = add nuw nsw i32 %1094, %1093"
"  %1094 = and i32 %1083, 65535"
"  %1094 = and i32 %1083, 65535" -> "  %1095 = add nuw nsw i32 %1094, %1093"
"  %1095 = add nuw nsw i32 %1094, %1093"
"  %1095 = add nuw nsw i32 %1094, %1093" -> "  %1097 = add nuw i32 %1095, %1096"
"  %1096 = and i32 %1083, -65536"
"  %1096 = and i32 %1083, -65536" -> "  %1097 = add nuw i32 %1095, %1096"
"  %1097 = add nuw i32 %1095, %1096"
"  %1097 = add nuw i32 %1095, %1096" -> "  %1099 = add nuw i32 %1097, %1098"
"  %1098 = lshr i32 %1092, 16"
"  %1098 = lshr i32 %1092, 16" -> "  %1099 = add nuw i32 %1097, %1098"
"  %1099 = add nuw i32 %1097, %1098"
"  %1099 = add nuw i32 %1097, %1098" -> "  %1153 = lshr i32 %1099, 16""  %1099 = add nuw i32 %1097, %1098" -> "  %1149 = and i32 %1099, 65535"
"  %1100 = mul nuw nsw i32 %1044, 1324"
"  %1100 = mul nuw nsw i32 %1044, 1324" -> "  %1119 = and i32 %1100, 65532""  %1100 = mul nuw nsw i32 %1044, 1324" -> "  %1101 = lshr i32 %1100, 16"
"  %1101 = lshr i32 %1100, 16"
"  %1101 = lshr i32 %1100, 16" -> "  %1104 = add nuw nsw i32 %1103, %1101"
"  %1102 = mul nuw nsw i32 %1047, 1324"
"  %1102 = mul nuw nsw i32 %1047, 1324" -> "  %1105 = and i32 %1102, 134152192""  %1102 = mul nuw nsw i32 %1047, 1324" -> "  %1103 = and i32 %1102, 65532"
"  %1103 = and i32 %1102, 65532"
"  %1103 = and i32 %1102, 65532" -> "  %1104 = add nuw nsw i32 %1103, %1101"
"  %1104 = add nuw nsw i32 %1103, %1101"
"  %1104 = add nuw nsw i32 %1103, %1101" -> "  %1106 = add nuw nsw i32 %1104, %1105"
"  %1105 = and i32 %1102, 134152192"
"  %1105 = and i32 %1102, 134152192" -> "  %1106 = add nuw nsw i32 %1104, %1105"
"  %1106 = add nuw nsw i32 %1104, %1105"
"  %1106 = add nuw nsw i32 %1104, %1105" -> "  %1110 = lshr i32 %1106, 16""  %1106 = add nuw nsw i32 %1104, %1105" -> "  %1108 = and i32 %1106, 65535"
"  %1107 = mul nuw i32 %1044, 62728"
"  %1107 = mul nuw i32 %1044, 62728" -> "  %1109 = add nuw i32 %1108, %1107"
"  %1108 = and i32 %1106, 65535"
"  %1108 = and i32 %1106, 65535" -> "  %1109 = add nuw i32 %1108, %1107"
"  %1109 = add nuw i32 %1108, %1107"
"  %1109 = add nuw i32 %1108, %1107" -> "  %1122 = and i32 %1109, 65535""  %1109 = add nuw i32 %1108, %1107" -> "  %1113 = lshr i32 %1109, 16"
"  %1110 = lshr i32 %1106, 16"
"  %1110 = lshr i32 %1106, 16" -> "  %1112 = add nuw i32 %1110, %1111"
"  %1111 = mul nuw i32 %1047, 62728"
"  %1111 = mul nuw i32 %1047, 62728" -> "  %1112 = add nuw i32 %1110, %1111"
"  %1112 = add nuw i32 %1110, %1111"
"  %1112 = add nuw i32 %1110, %1111" -> "  %1116 = and i32 %1112, -65536""  %1112 = add nuw i32 %1110, %1111" -> "  %1114 = and i32 %1112, 65535"
"  %1113 = lshr i32 %1109, 16"
"  %1113 = lshr i32 %1109, 16" -> "  %1115 = add nuw nsw i32 %1113, %1114"
"  %1114 = and i32 %1112, 65535"
"  %1114 = and i32 %1112, 65535" -> "  %1115 = add nuw nsw i32 %1113, %1114"
"  %1115 = add nuw nsw i32 %1113, %1114"
"  %1115 = add nuw nsw i32 %1113, %1114" -> "  %1117 = add nuw i32 %1115, %1116"
"  %1116 = and i32 %1112, -65536"
"  %1116 = and i32 %1112, -65536" -> "  %1117 = add nuw i32 %1115, %1116"
"  %1117 = add nuw i32 %1115, %1116"
"  %1117 = add nuw i32 %1115, %1116" -> "  %1125 = add nuw i32 %1117, %1124"
"  %1118 = and i32 %1086, 65535"
"  %1118 = and i32 %1086, 65535" -> "  %1120 = add nuw nsw i32 %1118, %1119"
"  %1119 = and i32 %1100, 65532"
"  %1119 = and i32 %1100, 65532" -> "  %1120 = add nuw nsw i32 %1118, %1119"
"  %1120 = add nuw nsw i32 %1118, %1119"
"  %1120 = add nuw nsw i32 %1118, %1119" -> "  %1127 = lshr i32 %1120, 16"
"  %1121 = and i32 %1092, 65535"
"  %1121 = and i32 %1092, 65535" -> "  %1123 = add nuw nsw i32 %1121, %1122"
"  %1122 = and i32 %1109, 65535"
"  %1122 = and i32 %1109, 65535" -> "  %1123 = add nuw nsw i32 %1121, %1122"
"  %1123 = add nuw nsw i32 %1121, %1122"
"  %1123 = add nuw nsw i32 %1121, %1122" -> "  %1126 = and i32 %1123, 65535""  %1123 = add nuw nsw i32 %1121, %1122" -> "  %1124 = lshr i32 %1123, 16"
"  %1124 = lshr i32 %1123, 16"
"  %1124 = lshr i32 %1123, 16" -> "  %1125 = add nuw i32 %1117, %1124"
"  %1125 = add nuw i32 %1117, %1124"
"  %1125 = add nuw i32 %1117, %1124" -> "  %1130 = add nuw i32 %1125, %1129"
"  %1126 = and i32 %1123, 65535"
"  %1126 = and i32 %1123, 65535" -> "  %1128 = add nuw nsw i32 %1126, %1127"
"  %1127 = lshr i32 %1120, 16"
"  %1127 = lshr i32 %1120, 16" -> "  %1128 = add nuw nsw i32 %1126, %1127"
"  %1128 = add nuw nsw i32 %1126, %1127"
"  %1128 = add nuw nsw i32 %1126, %1127" -> "  %1129 = lshr i32 %1128, 16"
"  %1129 = lshr i32 %1128, 16"
"  %1129 = lshr i32 %1128, 16" -> "  %1130 = add nuw i32 %1125, %1129"
"  %1130 = add nuw i32 %1125, %1129"
"  %1130 = add nuw i32 %1125, %1129" -> "  %1166 = lshr i32 %1130, 16""  %1130 = add nuw i32 %1125, %1129" -> "  %1163 = and i32 %1130, 65535"
"  %1131 = mul nuw nsw i32 %1064, 1324"
"  %1131 = mul nuw nsw i32 %1064, 1324" -> "  %1150 = and i32 %1131, 65532""  %1131 = mul nuw nsw i32 %1064, 1324" -> "  %1132 = lshr i32 %1131, 16"
"  %1132 = lshr i32 %1131, 16"
"  %1132 = lshr i32 %1131, 16" -> "  %1135 = add nuw nsw i32 %1134, %1132"
"  %1133 = mul nuw nsw i32 %1065, 1324"
"  %1133 = mul nuw nsw i32 %1065, 1324" -> "  %1136 = and i32 %1133, 134152192""  %1133 = mul nuw nsw i32 %1065, 1324" -> "  %1134 = and i32 %1133, 65532"
"  %1134 = and i32 %1133, 65532"
"  %1134 = and i32 %1133, 65532" -> "  %1135 = add nuw nsw i32 %1134, %1132"
"  %1135 = add nuw nsw i32 %1134, %1132"
"  %1135 = add nuw nsw i32 %1134, %1132" -> "  %1137 = add nuw nsw i32 %1135, %1136"
"  %1136 = and i32 %1133, 134152192"
"  %1136 = and i32 %1133, 134152192" -> "  %1137 = add nuw nsw i32 %1135, %1136"
"  %1137 = add nuw nsw i32 %1135, %1136"
"  %1137 = add nuw nsw i32 %1135, %1136" -> "  %1141 = lshr i32 %1137, 16""  %1137 = add nuw nsw i32 %1135, %1136" -> "  %1139 = and i32 %1137, 65535"
"  %1138 = mul nuw i32 %1064, 62728"
"  %1138 = mul nuw i32 %1064, 62728" -> "  %1140 = add nuw i32 %1139, %1138"
"  %1139 = and i32 %1137, 65535"
"  %1139 = and i32 %1137, 65535" -> "  %1140 = add nuw i32 %1139, %1138"
"  %1140 = add nuw i32 %1139, %1138"
"  %1140 = add nuw i32 %1139, %1138" -> "  %1152 = and i32 %1140, 65535""  %1140 = add nuw i32 %1139, %1138" -> "  %1144 = lshr i32 %1140, 16"
"  %1141 = lshr i32 %1137, 16"
"  %1141 = lshr i32 %1137, 16" -> "  %1143 = add nuw i32 %1141, %1142"
"  %1142 = mul nuw i32 %1065, 62728"
"  %1142 = mul nuw i32 %1065, 62728" -> "  %1143 = add nuw i32 %1141, %1142"
"  %1143 = add nuw i32 %1141, %1142"
"  %1143 = add nuw i32 %1141, %1142" -> "  %1147 = and i32 %1143, -65536""  %1143 = add nuw i32 %1141, %1142" -> "  %1145 = and i32 %1143, 65535"
"  %1144 = lshr i32 %1140, 16"
"  %1144 = lshr i32 %1140, 16" -> "  %1146 = add nuw nsw i32 %1144, %1145"
"  %1145 = and i32 %1143, 65535"
"  %1145 = and i32 %1143, 65535" -> "  %1146 = add nuw nsw i32 %1144, %1145"
"  %1146 = add nuw nsw i32 %1144, %1145"
"  %1146 = add nuw nsw i32 %1144, %1145" -> "  %1148 = add nuw i32 %1146, %1147"
"  %1147 = and i32 %1143, -65536"
"  %1147 = and i32 %1143, -65536" -> "  %1148 = add nuw i32 %1146, %1147"
"  %1148 = add nuw i32 %1146, %1147"
"  %1148 = add nuw i32 %1146, %1147" -> "  %1156 = add nuw i32 %1148, %1155"
"  %1149 = and i32 %1099, 65535"
"  %1149 = and i32 %1099, 65535" -> "  %1151 = add nuw nsw i32 %1149, %1150"
"  %1150 = and i32 %1131, 65532"
"  %1150 = and i32 %1131, 65532" -> "  %1151 = add nuw nsw i32 %1149, %1150"
"  %1151 = add nuw nsw i32 %1149, %1150"
"  %1151 = add nuw nsw i32 %1149, %1150" -> "  %1162 = and i32 %1151, 65535""  %1151 = add nuw nsw i32 %1149, %1150" -> "  %1158 = lshr i32 %1151, 16"
"  %1152 = and i32 %1140, 65535"
"  %1152 = and i32 %1140, 65535" -> "  %1154 = add nuw nsw i32 %1153, %1152"
"  %1153 = lshr i32 %1099, 16"
"  %1153 = lshr i32 %1099, 16" -> "  %1154 = add nuw nsw i32 %1153, %1152"
"  %1154 = add nuw nsw i32 %1153, %1152"
"  %1154 = add nuw nsw i32 %1153, %1152" -> "  %1157 = and i32 %1154, 65535""  %1154 = add nuw nsw i32 %1153, %1152" -> "  %1155 = lshr i32 %1154, 16"
"  %1155 = lshr i32 %1154, 16"
"  %1155 = lshr i32 %1154, 16" -> "  %1156 = add nuw i32 %1148, %1155"
"  %1156 = add nuw i32 %1148, %1155"
"  %1156 = add nuw i32 %1148, %1155" -> "  %1161 = add nuw i32 %1156, %1160"
"  %1157 = and i32 %1154, 65535"
"  %1157 = and i32 %1154, 65535" -> "  %1159 = add nuw nsw i32 %1158, %1157"
"  %1158 = lshr i32 %1151, 16"
"  %1158 = lshr i32 %1151, 16" -> "  %1159 = add nuw nsw i32 %1158, %1157"
"  %1159 = add nuw nsw i32 %1158, %1157"
"  %1159 = add nuw nsw i32 %1158, %1157" -> "  %1165 = and i32 %1159, 65535""  %1159 = add nuw nsw i32 %1158, %1157" -> "  %1160 = lshr i32 %1159, 16"
"  %1160 = lshr i32 %1159, 16"
"  %1160 = lshr i32 %1159, 16" -> "  %1161 = add nuw i32 %1156, %1160"
"  %1161 = add nuw i32 %1156, %1160"
"  %1161 = add nuw i32 %1156, %1160" -> "  %1174 = and i32 %1161, -65536""  %1161 = add nuw i32 %1156, %1160" -> "  %1172 = and i32 %1161, 65535"
"  %1162 = and i32 %1151, 65535"
"  %1162 = and i32 %1151, 65535" -> "  %1164 = add nuw nsw i32 %1163, %1162"
"  %1163 = and i32 %1130, 65535"
"  %1163 = and i32 %1130, 65535" -> "  %1164 = add nuw nsw i32 %1163, %1162"
"  %1164 = add nuw nsw i32 %1163, %1162"
"  %1164 = add nuw nsw i32 %1163, %1162" -> "  %1313 = and i32 %1164, 65535""  %1164 = add nuw nsw i32 %1163, %1162" -> "  %1168 = lshr i32 %1164, 16"
"  %1165 = and i32 %1159, 65535"
"  %1165 = and i32 %1159, 65535" -> "  %1167 = add nuw nsw i32 %1165, %1166"
"  %1166 = lshr i32 %1130, 16"
"  %1166 = lshr i32 %1130, 16" -> "  %1167 = add nuw nsw i32 %1165, %1166"
"  %1167 = add nuw nsw i32 %1165, %1166"
"  %1167 = add nuw nsw i32 %1165, %1166" -> "  %1171 = lshr i32 %1167, 16""  %1167 = add nuw nsw i32 %1165, %1166" -> "  %1169 = and i32 %1167, 65535"
"  %1168 = lshr i32 %1164, 16"
"  %1168 = lshr i32 %1164, 16" -> "  %1170 = add nuw nsw i32 %1169, %1168"
"  %1169 = and i32 %1167, 65535"
"  %1169 = and i32 %1167, 65535" -> "  %1170 = add nuw nsw i32 %1169, %1168"
"  %1170 = add nuw nsw i32 %1169, %1168"
"  %1170 = add nuw nsw i32 %1169, %1168" -> "  %1316 = and i32 %1170, 65535""  %1170 = add nuw nsw i32 %1169, %1168" -> "  %1176 = lshr i32 %1170, 16"
"  %1171 = lshr i32 %1167, 16"
"  %1171 = lshr i32 %1167, 16" -> "  %1173 = add nuw nsw i32 %1171, %1172"
"  %1172 = and i32 %1161, 65535"
"  %1172 = and i32 %1161, 65535" -> "  %1173 = add nuw nsw i32 %1171, %1172"
"  %1173 = add nuw nsw i32 %1171, %1172"
"  %1173 = add nuw nsw i32 %1171, %1172" -> "  %1175 = add nuw i32 %1173, %1174"
"  %1174 = and i32 %1161, -65536"
"  %1174 = and i32 %1161, -65536" -> "  %1175 = add nuw i32 %1173, %1174"
"  %1175 = add nuw i32 %1173, %1174"
"  %1175 = add nuw i32 %1173, %1174" -> "  %1177 = add nuw i32 %1175, %1176"
"  %1176 = lshr i32 %1170, 16"
"  %1176 = lshr i32 %1170, 16" -> "  %1177 = add nuw i32 %1175, %1176"
"  %1177 = add nuw i32 %1175, %1176"
"  %1177 = add nuw i32 %1175, %1176" -> "  %1324 = and i32 %1177, 65535""  %1177 = add nuw i32 %1175, %1176" -> "  %1327 = lshr i32 %1177, 16"
"  %1178 = and i32 %820, 65535"
"  %1178 = and i32 %820, 65535" -> "  %4479 = add nuw nsw i32 %4478, %1178""  %1178 = and i32 %820, 65535" -> "  %2649 = mul nuw i32 %1178, 42779""  %1178 = and i32 %820, 65535" -> "  %2656 = mul nuw nsw i32 %1178, 9871""  %1178 = and i32 %820, 65535" -> "  %2698 = mul nuw nsw i32 %1178, 24315""  %1178 = and i32 %820, 65535" -> "  %2705 = mul nuw nsw i32 %1178, 29744""  %1178 = and i32 %820, 65535" -> "  %3053 = mul nuw i32 %1178, 36786""  %1178 = and i32 %820, 65535" -> "  %3046 = mul nuw nsw i32 %1178, 21884""  %1178 = and i32 %820, 65535" -> "  %3004 = mul nuw nsw i32 %1178, 11561""  %1178 = and i32 %820, 65535" -> "  %2994 = mul nuw nsw i32 %1178, 4087""  %1178 = and i32 %820, 65535" -> "  %1187 = mul nuw i32 %1178, 45147""  %1178 = and i32 %820, 65535" -> "  %1180 = mul nuw i32 %1178, 37996""  %1178 = and i32 %820, 65535" -> "  %1567 = mul nuw nsw i32 %1178, 31112""  %1178 = and i32 %820, 65535" -> "  %1574 = mul nuw i32 %1178, 42170""  %1178 = and i32 %820, 65535" -> "  %1234 = mul nuw nsw i32 %1178, 1324""  %1178 = and i32 %820, 65535" -> "  %1241 = mul nuw i32 %1178, 62728""  %1178 = and i32 %820, 65535" -> "  %1525 = mul nuw i32 %1178, 46547""  %1178 = and i32 %820, 65535" -> "  %1518 = mul nuw nsw i32 %1178, 17857"
"  %1179 = and i32 %826, 65535"
"  %1179 = and i32 %826, 65535" -> "  %4481 = add nuw nsw i32 %4480, %1179""  %1179 = and i32 %826, 65535" -> "  %2651 = mul nuw i32 %1179, 42779""  %1179 = and i32 %826, 65535" -> "  %2660 = mul nuw nsw i32 %1179, 9871""  %1179 = and i32 %826, 65535" -> "  %2700 = mul nuw nsw i32 %1179, 24315""  %1179 = and i32 %826, 65535" -> "  %2709 = mul nuw nsw i32 %1179, 29744""  %1179 = and i32 %826, 65535" -> "  %3057 = mul nuw i32 %1179, 36786""  %1179 = and i32 %826, 65535" -> "  %3048 = mul nuw nsw i32 %1179, 21884""  %1179 = and i32 %826, 65535" -> "  %3008 = mul nuw nsw i32 %1179, 11561""  %1179 = and i32 %826, 65535" -> "  %2999 = mul nuw nsw i32 %1179, 4087""  %1179 = and i32 %826, 65535" -> "  %1191 = mul nuw i32 %1179, 45147""  %1179 = and i32 %826, 65535" -> "  %1182 = mul nuw i32 %1179, 37996""  %1179 = and i32 %826, 65535" -> "  %1578 = mul nuw i32 %1179, 42170""  %1179 = and i32 %826, 65535" -> "  %1569 = mul nuw nsw i32 %1179, 31112""  %1179 = and i32 %826, 65535" -> "  %1236 = mul nuw nsw i32 %1179, 1324""  %1179 = and i32 %826, 65535" -> "  %1245 = mul nuw i32 %1179, 62728""  %1179 = and i32 %826, 65535" -> "  %1529 = mul nuw i32 %1179, 46547""  %1179 = and i32 %826, 65535" -> "  %1520 = mul nuw nsw i32 %1179, 17857"
"  %1180 = mul nuw i32 %1178, 37996"
"  %1180 = mul nuw i32 %1178, 37996" -> "  %1312 = and i32 %1180, 65532""  %1180 = mul nuw i32 %1178, 37996" -> "  %1181 = lshr i32 %1180, 16"
"  %1181 = lshr i32 %1180, 16"
"  %1181 = lshr i32 %1180, 16" -> "  %1184 = add nuw nsw i32 %1183, %1181"
"  %1182 = mul nuw i32 %1179, 37996"
"  %1182 = mul nuw i32 %1179, 37996" -> "  %1185 = and i32 %1182, -65536""  %1182 = mul nuw i32 %1179, 37996" -> "  %1183 = and i32 %1182, 65532"
"  %1183 = and i32 %1182, 65532"
"  %1183 = and i32 %1182, 65532" -> "  %1184 = add nuw nsw i32 %1183, %1181"
"  %1184 = add nuw nsw i32 %1183, %1181"
"  %1184 = add nuw nsw i32 %1183, %1181" -> "  %1186 = add nuw i32 %1184, %1185"
"  %1185 = and i32 %1182, -65536"
"  %1185 = and i32 %1182, -65536" -> "  %1186 = add nuw i32 %1184, %1185"
"  %1186 = add nuw i32 %1184, %1185"
"  %1186 = add nuw i32 %1184, %1185" -> "  %1190 = lshr i32 %1186, 16""  %1186 = add nuw i32 %1184, %1185" -> "  %1188 = and i32 %1186, 65535"
"  %1187 = mul nuw i32 %1178, 45147"
"  %1187 = mul nuw i32 %1178, 45147" -> "  %1189 = add nuw i32 %1188, %1187"
"  %1188 = and i32 %1186, 65535"
"  %1188 = and i32 %1186, 65535" -> "  %1189 = add nuw i32 %1188, %1187"
"  %1189 = add nuw i32 %1188, %1187"
"  %1189 = add nuw i32 %1188, %1187" -> "  %1315 = and i32 %1189, 65535""  %1189 = add nuw i32 %1188, %1187" -> "  %1193 = lshr i32 %1189, 16"
"  %1190 = lshr i32 %1186, 16"
"  %1190 = lshr i32 %1186, 16" -> "  %1192 = add nuw i32 %1190, %1191"
"  %1191 = mul nuw i32 %1179, 45147"
"  %1191 = mul nuw i32 %1179, 45147" -> "  %1192 = add nuw i32 %1190, %1191"
"  %1192 = add nuw i32 %1190, %1191"
"  %1192 = add nuw i32 %1190, %1191" -> "  %1196 = and i32 %1192, -65536""  %1192 = add nuw i32 %1190, %1191" -> "  %1194 = and i32 %1192, 65535"
"  %1193 = lshr i32 %1189, 16"
"  %1193 = lshr i32 %1189, 16" -> "  %1195 = add nuw nsw i32 %1193, %1194"
"  %1194 = and i32 %1192, 65535"
"  %1194 = and i32 %1192, 65535" -> "  %1195 = add nuw nsw i32 %1193, %1194"
"  %1195 = add nuw nsw i32 %1193, %1194"
"  %1195 = add nuw nsw i32 %1193, %1194" -> "  %1197 = add nuw i32 %1195, %1196"
"  %1196 = and i32 %1192, -65536"
"  %1196 = and i32 %1192, -65536" -> "  %1197 = add nuw i32 %1195, %1196"
"  %1197 = add nuw i32 %1195, %1196"
"  %1197 = add nuw i32 %1195, %1196" -> "  %1222 = lshr i32 %1197, 16""  %1197 = add nuw i32 %1195, %1196" -> "  %1218 = and i32 %1197, 65535"
"  %1198 = and i32 %840, 65535"
"  %1198 = and i32 %840, 65535" -> "  %4488 = add nuw nsw i32 %4487, %1198""  %1198 = and i32 %840, 65535" -> "  %2729 = mul nuw nsw i32 %1198, 24315""  %1198 = and i32 %840, 65535" -> "  %1199 = mul nuw i32 %1198, 37996""  %1198 = and i32 %840, 65535" -> "  %3077 = mul nuw nsw i32 %1198, 21884""  %1198 = and i32 %840, 65535" -> "  %2667 = mul nuw i32 %1198, 42779""  %1198 = and i32 %840, 65535" -> "  %2674 = mul nuw nsw i32 %1198, 9871""  %1198 = and i32 %840, 65535" -> "  %3022 = mul nuw nsw i32 %1198, 11561""  %1198 = and i32 %840, 65535" -> "  %3015 = mul nuw nsw i32 %1198, 4087""  %1198 = and i32 %840, 65535" -> "  %3081 = mul nuw i32 %1198, 36786""  %1198 = and i32 %840, 65535" -> "  %2736 = mul nuw nsw i32 %1198, 29744""  %1198 = and i32 %840, 65535" -> "  %1207 = mul nuw i32 %1198, 45147""  %1198 = and i32 %840, 65535" -> "  %1605 = mul nuw i32 %1198, 42170""  %1198 = and i32 %840, 65535" -> "  %1598 = mul nuw nsw i32 %1198, 31112""  %1198 = and i32 %840, 65535" -> "  %1265 = mul nuw nsw i32 %1198, 1324""  %1198 = and i32 %840, 65535" -> "  %1272 = mul nuw i32 %1198, 62728""  %1198 = and i32 %840, 65535" -> "  %1543 = mul nuw i32 %1198, 46547""  %1198 = and i32 %840, 65535" -> "  %1536 = mul nuw nsw i32 %1198, 17857"
"  %1199 = mul nuw i32 %1198, 37996"
"  %1199 = mul nuw i32 %1198, 37996" -> "  %1200 = lshr i32 %1199, 16""  %1199 = mul nuw i32 %1198, 37996" -> "  %1219 = and i32 %1199, 65532"
"  %1200 = lshr i32 %1199, 16"
"  %1200 = lshr i32 %1199, 16" -> "  %1204 = add nuw nsw i32 %1203, %1200"
"  %1201 = and i32 %843, 65535"
"  %1201 = and i32 %843, 65535" -> "  %2731 = mul nuw nsw i32 %1201, 24315""  %1201 = and i32 %843, 65535" -> "  %2669 = mul nuw i32 %1201, 42779""  %1201 = and i32 %843, 65535" -> "  %2678 = mul nuw nsw i32 %1201, 9871""  %1201 = and i32 %843, 65535" -> "  %3026 = mul nuw nsw i32 %1201, 11561""  %1201 = and i32 %843, 65535" -> "  %3017 = mul nuw nsw i32 %1201, 4087""  %1201 = and i32 %843, 65535" -> "  %3079 = mul nuw nsw i32 %1201, 21884""  %1201 = and i32 %843, 65535" -> "  %3085 = mul nuw i32 %1201, 36786""  %1201 = and i32 %843, 65535" -> "  %2740 = mul nuw nsw i32 %1201, 29744""  %1201 = and i32 %843, 65535" -> "  %1211 = mul nuw i32 %1201, 45147""  %1201 = and i32 %843, 65535" -> "  %1202 = mul nuw i32 %1201, 37996""  %1201 = and i32 %843, 65535" -> "  %1609 = mul nuw i32 %1201, 42170""  %1201 = and i32 %843, 65535" -> "  %1600 = mul nuw nsw i32 %1201, 31112""  %1201 = and i32 %843, 65535" -> "  %1267 = mul nuw nsw i32 %1201, 1324""  %1201 = and i32 %843, 65535" -> "  %1276 = mul nuw i32 %1201, 62728""  %1201 = and i32 %843, 65535" -> "  %1547 = mul nuw i32 %1201, 46547""  %1201 = and i32 %843, 65535" -> "  %1538 = mul nuw nsw i32 %1201, 17857"
"  %1202 = mul nuw i32 %1201, 37996"
"  %1202 = mul nuw i32 %1201, 37996" -> "  %1205 = and i32 %1202, -65536""  %1202 = mul nuw i32 %1201, 37996" -> "  %1203 = and i32 %1202, 65532"
"  %1203 = and i32 %1202, 65532"
"  %1203 = and i32 %1202, 65532" -> "  %1204 = add nuw nsw i32 %1203, %1200"
"  %1204 = add nuw nsw i32 %1203, %1200"
"  %1204 = add nuw nsw i32 %1203, %1200" -> "  %1206 = add nuw i32 %1204, %1205"
"  %1205 = and i32 %1202, -65536"
"  %1205 = and i32 %1202, -65536" -> "  %1206 = add nuw i32 %1204, %1205"
"  %1206 = add nuw i32 %1204, %1205"
"  %1206 = add nuw i32 %1204, %1205" -> "  %1210 = lshr i32 %1206, 16""  %1206 = add nuw i32 %1204, %1205" -> "  %1208 = and i32 %1206, 65535"
"  %1207 = mul nuw i32 %1198, 45147"
"  %1207 = mul nuw i32 %1198, 45147" -> "  %1209 = add nuw i32 %1208, %1207"
"  %1208 = and i32 %1206, 65535"
"  %1208 = and i32 %1206, 65535" -> "  %1209 = add nuw i32 %1208, %1207"
"  %1209 = add nuw i32 %1208, %1207"
"  %1209 = add nuw i32 %1208, %1207" -> "  %1221 = and i32 %1209, 65535""  %1209 = add nuw i32 %1208, %1207" -> "  %1213 = lshr i32 %1209, 16"
"  %1210 = lshr i32 %1206, 16"
"  %1210 = lshr i32 %1206, 16" -> "  %1212 = add nuw i32 %1210, %1211"
"  %1211 = mul nuw i32 %1201, 45147"
"  %1211 = mul nuw i32 %1201, 45147" -> "  %1212 = add nuw i32 %1210, %1211"
"  %1212 = add nuw i32 %1210, %1211"
"  %1212 = add nuw i32 %1210, %1211" -> "  %1216 = and i32 %1212, -65536""  %1212 = add nuw i32 %1210, %1211" -> "  %1214 = and i32 %1212, 65535"
"  %1213 = lshr i32 %1209, 16"
"  %1213 = lshr i32 %1209, 16" -> "  %1215 = add nuw nsw i32 %1213, %1214"
"  %1214 = and i32 %1212, 65535"
"  %1214 = and i32 %1212, 65535" -> "  %1215 = add nuw nsw i32 %1213, %1214"
"  %1215 = add nuw nsw i32 %1213, %1214"
"  %1215 = add nuw nsw i32 %1213, %1214" -> "  %1217 = add nuw i32 %1215, %1216"
"  %1216 = and i32 %1212, -65536"
"  %1216 = and i32 %1212, -65536" -> "  %1217 = add nuw i32 %1215, %1216"
"  %1217 = add nuw i32 %1215, %1216"
"  %1217 = add nuw i32 %1215, %1216" -> "  %1230 = and i32 %1217, -65536""  %1217 = add nuw i32 %1215, %1216" -> "  %1228 = and i32 %1217, 65535"
"  %1218 = and i32 %1197, 65535"
"  %1218 = and i32 %1197, 65535" -> "  %1220 = add nuw nsw i32 %1218, %1219"
"  %1219 = and i32 %1199, 65532"
"  %1219 = and i32 %1199, 65532" -> "  %1220 = add nuw nsw i32 %1218, %1219"
"  %1220 = add nuw nsw i32 %1218, %1219"
"  %1220 = add nuw nsw i32 %1218, %1219" -> "  %1252 = and i32 %1220, 65535""  %1220 = add nuw nsw i32 %1218, %1219" -> "  %1224 = lshr i32 %1220, 16"
"  %1221 = and i32 %1209, 65535"
"  %1221 = and i32 %1209, 65535" -> "  %1223 = add nuw nsw i32 %1221, %1222"
"  %1222 = lshr i32 %1197, 16"
"  %1222 = lshr i32 %1197, 16" -> "  %1223 = add nuw nsw i32 %1221, %1222"
"  %1223 = add nuw nsw i32 %1221, %1222"
"  %1223 = add nuw nsw i32 %1221, %1222" -> "  %1227 = lshr i32 %1223, 16""  %1223 = add nuw nsw i32 %1221, %1222" -> "  %1225 = and i32 %1223, 65535"
"  %1224 = lshr i32 %1220, 16"
"  %1224 = lshr i32 %1220, 16" -> "  %1226 = add nuw nsw i32 %1225, %1224"
"  %1225 = and i32 %1223, 65535"
"  %1225 = and i32 %1223, 65535" -> "  %1226 = add nuw nsw i32 %1225, %1224"
"  %1226 = add nuw nsw i32 %1225, %1224"
"  %1226 = add nuw nsw i32 %1225, %1224" -> "  %1256 = and i32 %1226, 65535""  %1226 = add nuw nsw i32 %1225, %1224" -> "  %1232 = lshr i32 %1226, 16"
"  %1227 = lshr i32 %1223, 16"
"  %1227 = lshr i32 %1223, 16" -> "  %1229 = add nuw nsw i32 %1228, %1227"
"  %1228 = and i32 %1217, 65535"
"  %1228 = and i32 %1217, 65535" -> "  %1229 = add nuw nsw i32 %1228, %1227"
"  %1229 = add nuw nsw i32 %1228, %1227"
"  %1229 = add nuw nsw i32 %1228, %1227" -> "  %1231 = add nuw i32 %1229, %1230"
"  %1230 = and i32 %1217, -65536"
"  %1230 = and i32 %1217, -65536" -> "  %1231 = add nuw i32 %1229, %1230"
"  %1231 = add nuw i32 %1229, %1230"
"  %1231 = add nuw i32 %1229, %1230" -> "  %1233 = add nuw i32 %1231, %1232"
"  %1232 = lshr i32 %1226, 16"
"  %1232 = lshr i32 %1226, 16" -> "  %1233 = add nuw i32 %1231, %1232"
"  %1233 = add nuw i32 %1231, %1232"
"  %1233 = add nuw i32 %1231, %1232" -> "  %1287 = lshr i32 %1233, 16""  %1233 = add nuw i32 %1231, %1232" -> "  %1283 = and i32 %1233, 65535"
"  %1234 = mul nuw nsw i32 %1178, 1324"
"  %1234 = mul nuw nsw i32 %1178, 1324" -> "  %1253 = and i32 %1234, 65532""  %1234 = mul nuw nsw i32 %1178, 1324" -> "  %1235 = lshr i32 %1234, 16"
"  %1235 = lshr i32 %1234, 16"
"  %1235 = lshr i32 %1234, 16" -> "  %1238 = add nuw nsw i32 %1237, %1235"
"  %1236 = mul nuw nsw i32 %1179, 1324"
"  %1236 = mul nuw nsw i32 %1179, 1324" -> "  %1239 = and i32 %1236, 134152192""  %1236 = mul nuw nsw i32 %1179, 1324" -> "  %1237 = and i32 %1236, 65532"
"  %1237 = and i32 %1236, 65532"
"  %1237 = and i32 %1236, 65532" -> "  %1238 = add nuw nsw i32 %1237, %1235"
"  %1238 = add nuw nsw i32 %1237, %1235"
"  %1238 = add nuw nsw i32 %1237, %1235" -> "  %1240 = add nuw nsw i32 %1238, %1239"
"  %1239 = and i32 %1236, 134152192"
"  %1239 = and i32 %1236, 134152192" -> "  %1240 = add nuw nsw i32 %1238, %1239"
"  %1240 = add nuw nsw i32 %1238, %1239"
"  %1240 = add nuw nsw i32 %1238, %1239" -> "  %1244 = lshr i32 %1240, 16""  %1240 = add nuw nsw i32 %1238, %1239" -> "  %1242 = and i32 %1240, 65535"
"  %1241 = mul nuw i32 %1178, 62728"
"  %1241 = mul nuw i32 %1178, 62728" -> "  %1243 = add nuw i32 %1242, %1241"
"  %1242 = and i32 %1240, 65535"
"  %1242 = and i32 %1240, 65535" -> "  %1243 = add nuw i32 %1242, %1241"
"  %1243 = add nuw i32 %1242, %1241"
"  %1243 = add nuw i32 %1242, %1241" -> "  %1255 = and i32 %1243, 65535""  %1243 = add nuw i32 %1242, %1241" -> "  %1247 = lshr i32 %1243, 16"
"  %1244 = lshr i32 %1240, 16"
"  %1244 = lshr i32 %1240, 16" -> "  %1246 = add nuw i32 %1244, %1245"
"  %1245 = mul nuw i32 %1179, 62728"
"  %1245 = mul nuw i32 %1179, 62728" -> "  %1246 = add nuw i32 %1244, %1245"
"  %1246 = add nuw i32 %1244, %1245"
"  %1246 = add nuw i32 %1244, %1245" -> "  %1250 = and i32 %1246, -65536""  %1246 = add nuw i32 %1244, %1245" -> "  %1248 = and i32 %1246, 65535"
"  %1247 = lshr i32 %1243, 16"
"  %1247 = lshr i32 %1243, 16" -> "  %1249 = add nuw nsw i32 %1247, %1248"
"  %1248 = and i32 %1246, 65535"
"  %1248 = and i32 %1246, 65535" -> "  %1249 = add nuw nsw i32 %1247, %1248"
"  %1249 = add nuw nsw i32 %1247, %1248"
"  %1249 = add nuw nsw i32 %1247, %1248" -> "  %1251 = add nuw i32 %1249, %1250"
"  %1250 = and i32 %1246, -65536"
"  %1250 = and i32 %1246, -65536" -> "  %1251 = add nuw i32 %1249, %1250"
"  %1251 = add nuw i32 %1249, %1250"
"  %1251 = add nuw i32 %1249, %1250" -> "  %1259 = add nuw i32 %1251, %1258"
"  %1252 = and i32 %1220, 65535"
"  %1252 = and i32 %1220, 65535" -> "  %1254 = add nuw nsw i32 %1252, %1253"
"  %1253 = and i32 %1234, 65532"
"  %1253 = and i32 %1234, 65532" -> "  %1254 = add nuw nsw i32 %1252, %1253"
"  %1254 = add nuw nsw i32 %1252, %1253"
"  %1254 = add nuw nsw i32 %1252, %1253" -> "  %1323 = and i32 %1254, 65535""  %1254 = add nuw nsw i32 %1252, %1253" -> "  %1261 = lshr i32 %1254, 16"
"  %1255 = and i32 %1243, 65535"
"  %1255 = and i32 %1243, 65535" -> "  %1257 = add nuw nsw i32 %1256, %1255"
"  %1256 = and i32 %1226, 65535"
"  %1256 = and i32 %1226, 65535" -> "  %1257 = add nuw nsw i32 %1256, %1255"
"  %1257 = add nuw nsw i32 %1256, %1255"
"  %1257 = add nuw nsw i32 %1256, %1255" -> "  %1260 = and i32 %1257, 65535""  %1257 = add nuw nsw i32 %1256, %1255" -> "  %1258 = lshr i32 %1257, 16"
"  %1258 = lshr i32 %1257, 16"
"  %1258 = lshr i32 %1257, 16" -> "  %1259 = add nuw i32 %1251, %1258"
"  %1259 = add nuw i32 %1251, %1258"
"  %1259 = add nuw i32 %1251, %1258" -> "  %1264 = add nuw i32 %1259, %1263"
"  %1260 = and i32 %1257, 65535"
"  %1260 = and i32 %1257, 65535" -> "  %1262 = add nuw nsw i32 %1260, %1261"
"  %1261 = lshr i32 %1254, 16"
"  %1261 = lshr i32 %1254, 16" -> "  %1262 = add nuw nsw i32 %1260, %1261"
"  %1262 = add nuw nsw i32 %1260, %1261"
"  %1262 = add nuw nsw i32 %1260, %1261" -> "  %1326 = and i32 %1262, 65535""  %1262 = add nuw nsw i32 %1260, %1261" -> "  %1263 = lshr i32 %1262, 16"
"  %1263 = lshr i32 %1262, 16"
"  %1263 = lshr i32 %1262, 16" -> "  %1264 = add nuw i32 %1259, %1263"
"  %1264 = add nuw i32 %1259, %1263"
"  %1264 = add nuw i32 %1259, %1263" -> "  %1300 = lshr i32 %1264, 16""  %1264 = add nuw i32 %1259, %1263" -> "  %1297 = and i32 %1264, 65535"
"  %1265 = mul nuw nsw i32 %1198, 1324"
"  %1265 = mul nuw nsw i32 %1198, 1324" -> "  %1284 = and i32 %1265, 65532""  %1265 = mul nuw nsw i32 %1198, 1324" -> "  %1266 = lshr i32 %1265, 16"
"  %1266 = lshr i32 %1265, 16"
"  %1266 = lshr i32 %1265, 16" -> "  %1269 = add nuw nsw i32 %1268, %1266"
"  %1267 = mul nuw nsw i32 %1201, 1324"
"  %1267 = mul nuw nsw i32 %1201, 1324" -> "  %1270 = and i32 %1267, 134152192""  %1267 = mul nuw nsw i32 %1201, 1324" -> "  %1268 = and i32 %1267, 65532"
"  %1268 = and i32 %1267, 65532"
"  %1268 = and i32 %1267, 65532" -> "  %1269 = add nuw nsw i32 %1268, %1266"
"  %1269 = add nuw nsw i32 %1268, %1266"
"  %1269 = add nuw nsw i32 %1268, %1266" -> "  %1271 = add nuw nsw i32 %1269, %1270"
"  %1270 = and i32 %1267, 134152192"
"  %1270 = and i32 %1267, 134152192" -> "  %1271 = add nuw nsw i32 %1269, %1270"
"  %1271 = add nuw nsw i32 %1269, %1270"
"  %1271 = add nuw nsw i32 %1269, %1270" -> "  %1275 = lshr i32 %1271, 16""  %1271 = add nuw nsw i32 %1269, %1270" -> "  %1273 = and i32 %1271, 65535"
"  %1272 = mul nuw i32 %1198, 62728"
"  %1272 = mul nuw i32 %1198, 62728" -> "  %1274 = add nuw i32 %1273, %1272"
"  %1273 = and i32 %1271, 65535"
"  %1273 = and i32 %1271, 65535" -> "  %1274 = add nuw i32 %1273, %1272"
"  %1274 = add nuw i32 %1273, %1272"
"  %1274 = add nuw i32 %1273, %1272" -> "  %1286 = and i32 %1274, 65535""  %1274 = add nuw i32 %1273, %1272" -> "  %1278 = lshr i32 %1274, 16"
"  %1275 = lshr i32 %1271, 16"
"  %1275 = lshr i32 %1271, 16" -> "  %1277 = add nuw i32 %1275, %1276"
"  %1276 = mul nuw i32 %1201, 62728"
"  %1276 = mul nuw i32 %1201, 62728" -> "  %1277 = add nuw i32 %1275, %1276"
"  %1277 = add nuw i32 %1275, %1276"
"  %1277 = add nuw i32 %1275, %1276" -> "  %1281 = and i32 %1277, -65536""  %1277 = add nuw i32 %1275, %1276" -> "  %1279 = and i32 %1277, 65535"
"  %1278 = lshr i32 %1274, 16"
"  %1278 = lshr i32 %1274, 16" -> "  %1280 = add nuw nsw i32 %1278, %1279"
"  %1279 = and i32 %1277, 65535"
"  %1279 = and i32 %1277, 65535" -> "  %1280 = add nuw nsw i32 %1278, %1279"
"  %1280 = add nuw nsw i32 %1278, %1279"
"  %1280 = add nuw nsw i32 %1278, %1279" -> "  %1282 = add nuw i32 %1280, %1281"
"  %1281 = and i32 %1277, -65536"
"  %1281 = and i32 %1277, -65536" -> "  %1282 = add nuw i32 %1280, %1281"
"  %1282 = add nuw i32 %1280, %1281"
"  %1282 = add nuw i32 %1280, %1281" -> "  %1290 = add nuw i32 %1282, %1289"
"  %1283 = and i32 %1233, 65535"
"  %1283 = and i32 %1233, 65535" -> "  %1285 = add nuw nsw i32 %1283, %1284"
"  %1284 = and i32 %1265, 65532"
"  %1284 = and i32 %1265, 65532" -> "  %1285 = add nuw nsw i32 %1283, %1284"
"  %1285 = add nuw nsw i32 %1283, %1284"
"  %1285 = add nuw nsw i32 %1283, %1284" -> "  %1296 = and i32 %1285, 65535""  %1285 = add nuw nsw i32 %1283, %1284" -> "  %1292 = lshr i32 %1285, 16"
"  %1286 = and i32 %1274, 65535"
"  %1286 = and i32 %1274, 65535" -> "  %1288 = add nuw nsw i32 %1287, %1286"
"  %1287 = lshr i32 %1233, 16"
"  %1287 = lshr i32 %1233, 16" -> "  %1288 = add nuw nsw i32 %1287, %1286"
"  %1288 = add nuw nsw i32 %1287, %1286"
"  %1288 = add nuw nsw i32 %1287, %1286" -> "  %1291 = and i32 %1288, 65535""  %1288 = add nuw nsw i32 %1287, %1286" -> "  %1289 = lshr i32 %1288, 16"
"  %1289 = lshr i32 %1288, 16"
"  %1289 = lshr i32 %1288, 16" -> "  %1290 = add nuw i32 %1282, %1289"
"  %1290 = add nuw i32 %1282, %1289"
"  %1290 = add nuw i32 %1282, %1289" -> "  %1295 = add nuw i32 %1290, %1294"
"  %1291 = and i32 %1288, 65535"
"  %1291 = and i32 %1288, 65535" -> "  %1293 = add nuw nsw i32 %1291, %1292"
"  %1292 = lshr i32 %1285, 16"
"  %1292 = lshr i32 %1285, 16" -> "  %1293 = add nuw nsw i32 %1291, %1292"
"  %1293 = add nuw nsw i32 %1291, %1292"
"  %1293 = add nuw nsw i32 %1291, %1292" -> "  %1299 = and i32 %1293, 65535""  %1293 = add nuw nsw i32 %1291, %1292" -> "  %1294 = lshr i32 %1293, 16"
"  %1294 = lshr i32 %1293, 16"
"  %1294 = lshr i32 %1293, 16" -> "  %1295 = add nuw i32 %1290, %1294"
"  %1295 = add nuw i32 %1290, %1294"
"  %1295 = add nuw i32 %1290, %1294" -> "  %1308 = and i32 %1295, -65536""  %1295 = add nuw i32 %1290, %1294" -> "  %1306 = and i32 %1295, 65535"
"  %1296 = and i32 %1285, 65535"
"  %1296 = and i32 %1285, 65535" -> "  %1298 = add nuw nsw i32 %1297, %1296"
"  %1297 = and i32 %1264, 65535"
"  %1297 = and i32 %1264, 65535" -> "  %1298 = add nuw nsw i32 %1297, %1296"
"  %1298 = add nuw nsw i32 %1297, %1296"
"  %1298 = add nuw nsw i32 %1297, %1296" -> "  %1338 = and i32 %1298, 65535""  %1298 = add nuw nsw i32 %1297, %1296" -> "  %1302 = lshr i32 %1298, 16"
"  %1299 = and i32 %1293, 65535"
"  %1299 = and i32 %1293, 65535" -> "  %1301 = add nuw nsw i32 %1299, %1300"
"  %1300 = lshr i32 %1264, 16"
"  %1300 = lshr i32 %1264, 16" -> "  %1301 = add nuw nsw i32 %1299, %1300"
"  %1301 = add nuw nsw i32 %1299, %1300"
"  %1301 = add nuw nsw i32 %1299, %1300" -> "  %1305 = lshr i32 %1301, 16""  %1301 = add nuw nsw i32 %1299, %1300" -> "  %1303 = and i32 %1301, 65535"
"  %1302 = lshr i32 %1298, 16"
"  %1302 = lshr i32 %1298, 16" -> "  %1304 = add nuw nsw i32 %1303, %1302"
"  %1303 = and i32 %1301, 65535"
"  %1303 = and i32 %1301, 65535" -> "  %1304 = add nuw nsw i32 %1303, %1302"
"  %1304 = add nuw nsw i32 %1303, %1302"
"  %1304 = add nuw nsw i32 %1303, %1302" -> "  %1345 = and i32 %1304, 65535""  %1304 = add nuw nsw i32 %1303, %1302" -> "  %1310 = lshr i32 %1304, 16"
"  %1305 = lshr i32 %1301, 16"
"  %1305 = lshr i32 %1301, 16" -> "  %1307 = add nuw nsw i32 %1305, %1306"
"  %1306 = and i32 %1295, 65535"
"  %1306 = and i32 %1295, 65535" -> "  %1307 = add nuw nsw i32 %1305, %1306"
"  %1307 = add nuw nsw i32 %1305, %1306"
"  %1307 = add nuw nsw i32 %1305, %1306" -> "  %1309 = add nuw i32 %1307, %1308"
"  %1308 = and i32 %1295, -65536"
"  %1308 = and i32 %1295, -65536" -> "  %1309 = add nuw i32 %1307, %1308"
"  %1309 = add nuw i32 %1307, %1308"
"  %1309 = add nuw i32 %1307, %1308" -> "  %1311 = add nuw i32 %1309, %1310"
"  %1310 = lshr i32 %1304, 16"
"  %1310 = lshr i32 %1304, 16" -> "  %1311 = add nuw i32 %1309, %1310"
"  %1311 = add nuw i32 %1309, %1310"
"  %1311 = add nuw i32 %1309, %1310" -> "  %1349 = add nuw i32 %1311, %1348"
"  %1312 = and i32 %1180, 65532"
"  %1312 = and i32 %1180, 65532" -> "  %1314 = add nuw nsw i32 %1313, %1312"
"  %1313 = and i32 %1164, 65535"
"  %1313 = and i32 %1164, 65535" -> "  %1314 = add nuw nsw i32 %1313, %1312"
"  %1314 = add nuw nsw i32 %1313, %1312"
"  %1314 = add nuw nsw i32 %1313, %1312" -> "  %1481 = and i32 %1314, 65535""  %1314 = add nuw nsw i32 %1313, %1312" -> "  %1318 = lshr i32 %1314, 16"
"  %1315 = and i32 %1189, 65535"
"  %1315 = and i32 %1189, 65535" -> "  %1317 = add nuw nsw i32 %1316, %1315"
"  %1316 = and i32 %1170, 65535"
"  %1316 = and i32 %1170, 65535" -> "  %1317 = add nuw nsw i32 %1316, %1315"
"  %1317 = add nuw nsw i32 %1316, %1315"
"  %1317 = add nuw nsw i32 %1316, %1315" -> "  %1321 = lshr i32 %1317, 16""  %1317 = add nuw nsw i32 %1316, %1315" -> "  %1319 = and i32 %1317, 65535"
"  %1318 = lshr i32 %1314, 16"
"  %1318 = lshr i32 %1314, 16" -> "  %1320 = add nuw nsw i32 %1319, %1318"
"  %1319 = and i32 %1317, 65535"
"  %1319 = and i32 %1317, 65535" -> "  %1320 = add nuw nsw i32 %1319, %1318"
"  %1320 = add nuw nsw i32 %1319, %1318"
"  %1320 = add nuw nsw i32 %1319, %1318" -> "  %1484 = and i32 %1320, 65535""  %1320 = add nuw nsw i32 %1319, %1318" -> "  %1322 = lshr i32 %1320, 16"
"  %1321 = lshr i32 %1317, 16"
"  %1321 = lshr i32 %1317, 16" -> "  %1333 = add nuw nsw i32 %1322, %1321"
"  %1322 = lshr i32 %1320, 16"
"  %1322 = lshr i32 %1320, 16" -> "  %1333 = add nuw nsw i32 %1322, %1321"
"  %1323 = and i32 %1254, 65535"
"  %1323 = and i32 %1254, 65535" -> "  %1325 = add nuw nsw i32 %1323, %1324"
"  %1324 = and i32 %1177, 65535"
"  %1324 = and i32 %1177, 65535" -> "  %1325 = add nuw nsw i32 %1323, %1324"
"  %1325 = add nuw nsw i32 %1323, %1324"
"  %1325 = add nuw nsw i32 %1323, %1324" -> "  %1332 = and i32 %1325, 65535""  %1325 = add nuw nsw i32 %1323, %1324" -> "  %1329 = lshr i32 %1325, 16"
"  %1326 = and i32 %1262, 65535"
"  %1326 = and i32 %1262, 65535" -> "  %1328 = add nuw nsw i32 %1326, %1327"
"  %1327 = lshr i32 %1177, 16"
"  %1327 = lshr i32 %1177, 16" -> "  %1328 = add nuw nsw i32 %1326, %1327"
"  %1328 = add nuw nsw i32 %1326, %1327"
"  %1328 = add nuw nsw i32 %1326, %1327" -> "  %1339 = lshr i32 %1328, 16""  %1328 = add nuw nsw i32 %1326, %1327" -> "  %1330 = and i32 %1328, 65535"
"  %1329 = lshr i32 %1325, 16"
"  %1329 = lshr i32 %1325, 16" -> "  %1331 = add nuw nsw i32 %1330, %1329"
"  %1330 = and i32 %1328, 65535"
"  %1330 = and i32 %1328, 65535" -> "  %1331 = add nuw nsw i32 %1330, %1329"
"  %1331 = add nuw nsw i32 %1330, %1329"
"  %1331 = add nuw nsw i32 %1330, %1329" -> "  %1341 = lshr i32 %1331, 16""  %1331 = add nuw nsw i32 %1330, %1329" -> "  %1336 = and i32 %1331, 65535"
"  %1332 = and i32 %1325, 65535"
"  %1332 = and i32 %1325, 65535" -> "  %1334 = add nuw nsw i32 %1333, %1332"
"  %1333 = add nuw nsw i32 %1322, %1321"
"  %1333 = add nuw nsw i32 %1322, %1321" -> "  %1334 = add nuw nsw i32 %1333, %1332"
"  %1334 = add nuw nsw i32 %1333, %1332"
"  %1334 = add nuw nsw i32 %1333, %1332" -> "  %1492 = and i32 %1334, 65535""  %1334 = add nuw nsw i32 %1333, %1332" -> "  %1335 = lshr i32 %1334, 16"
"  %1335 = lshr i32 %1334, 16"
"  %1335 = lshr i32 %1334, 16" -> "  %1337 = add nuw nsw i32 %1336, %1335"
"  %1336 = and i32 %1331, 65535"
"  %1336 = and i32 %1331, 65535" -> "  %1337 = add nuw nsw i32 %1336, %1335"
"  %1337 = add nuw nsw i32 %1336, %1335"
"  %1337 = add nuw nsw i32 %1336, %1335" -> "  %1495 = and i32 %1337, 65535""  %1337 = add nuw nsw i32 %1336, %1335" -> "  %1343 = lshr i32 %1337, 16"
"  %1338 = and i32 %1298, 65535"
"  %1338 = and i32 %1298, 65535" -> "  %1340 = add nuw nsw i32 %1338, %1339"
"  %1339 = lshr i32 %1328, 16"
"  %1339 = lshr i32 %1328, 16" -> "  %1340 = add nuw nsw i32 %1338, %1339"
"  %1340 = add nuw nsw i32 %1338, %1339"
"  %1340 = add nuw nsw i32 %1338, %1339" -> "  %1342 = add nuw nsw i32 %1340, %1341"
"  %1341 = lshr i32 %1331, 16"
"  %1341 = lshr i32 %1331, 16" -> "  %1342 = add nuw nsw i32 %1340, %1341"
"  %1342 = add nuw nsw i32 %1340, %1341"
"  %1342 = add nuw nsw i32 %1340, %1341" -> "  %1344 = add nuw nsw i32 %1342, %1343"
"  %1343 = lshr i32 %1337, 16"
"  %1343 = lshr i32 %1337, 16" -> "  %1344 = add nuw nsw i32 %1342, %1343"
"  %1344 = add nuw nsw i32 %1342, %1343"
"  %1344 = add nuw nsw i32 %1342, %1343" -> "  %1646 = and i32 %1344, 65535""  %1344 = add nuw nsw i32 %1342, %1343" -> "  %1346 = lshr i32 %1344, 16"
"  %1345 = and i32 %1304, 65535"
"  %1345 = and i32 %1304, 65535" -> "  %1347 = add nuw nsw i32 %1346, %1345"
"  %1346 = lshr i32 %1344, 16"
"  %1346 = lshr i32 %1344, 16" -> "  %1347 = add nuw nsw i32 %1346, %1345"
"  %1347 = add nuw nsw i32 %1346, %1345"
"  %1347 = add nuw nsw i32 %1346, %1345" -> "  %1649 = and i32 %1347, 65535""  %1347 = add nuw nsw i32 %1346, %1345" -> "  %1348 = lshr i32 %1347, 16"
"  %1348 = lshr i32 %1347, 16"
"  %1348 = lshr i32 %1347, 16" -> "  %1349 = add nuw i32 %1311, %1348"
"  %1349 = add nuw i32 %1311, %1348"
"  %1349 = add nuw i32 %1311, %1348" -> "  %1655 = and i32 %1349, 65535""  %1349 = add nuw i32 %1311, %1348" -> "  %1658 = lshr i32 %1349, 16"
"  %1350 = mul nuw nsw i32 %1044, 17857"
"  %1350 = mul nuw nsw i32 %1044, 17857" -> "  %1480 = and i32 %1350, 65535""  %1350 = mul nuw nsw i32 %1044, 17857" -> "  %1354 = lshr i32 %1350, 16"
"  %1351 = add i64 %18, -196"
"  %1351 = add i64 %18, -196" -> "  %1352 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1351"
"  %1352 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1351"
"  %1352 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1351" -> "  %1353 = bitcast i8* %1352 to i32*"
"  %1353 = bitcast i8* %1352 to i32*"
"  %1353 = bitcast i8* %1352 to i32*" -> "  store i32 %19422, i32* %1353, align 1, !noalias !59"
"  %1354 = lshr i32 %1350, 16"
"  %1354 = lshr i32 %1350, 16" -> "  %1357 = add nuw nsw i32 %1356, %1354"
"  %1355 = mul nuw nsw i32 %1047, 17857"
"  %1355 = mul nuw nsw i32 %1047, 17857" -> "  %1358 = and i32 %1355, 2147418112""  %1355 = mul nuw nsw i32 %1047, 17857" -> "  %1356 = and i32 %1355, 65535"
"  %1356 = and i32 %1355, 65535"
"  %1356 = and i32 %1355, 65535" -> "  %1357 = add nuw nsw i32 %1356, %1354"
"  %1357 = add nuw nsw i32 %1356, %1354"
"  %1357 = add nuw nsw i32 %1356, %1354" -> "  %1359 = add nuw nsw i32 %1357, %1358"
"  %1358 = and i32 %1355, 2147418112"
"  %1358 = and i32 %1355, 2147418112" -> "  %1359 = add nuw nsw i32 %1357, %1358"
"  %1359 = add nuw nsw i32 %1357, %1358"
"  %1359 = add nuw nsw i32 %1357, %1358" -> "  %1363 = lshr i32 %1359, 16""  %1359 = add nuw nsw i32 %1357, %1358" -> "  %1361 = and i32 %1359, 65535"
"  %1360 = mul nuw i32 %1044, 46547"
"  %1360 = mul nuw i32 %1044, 46547" -> "  %1362 = add nuw i32 %1361, %1360"
"  %1361 = and i32 %1359, 65535"
"  %1361 = and i32 %1359, 65535" -> "  %1362 = add nuw i32 %1361, %1360"
"  %1362 = add nuw i32 %1361, %1360"
"  %1362 = add nuw i32 %1361, %1360" -> "  %1483 = and i32 %1362, 65535""  %1362 = add nuw i32 %1361, %1360" -> "  %1366 = lshr i32 %1362, 16"
"  %1363 = lshr i32 %1359, 16"
"  %1363 = lshr i32 %1359, 16" -> "  %1365 = add nuw i32 %1363, %1364"
"  %1364 = mul nuw i32 %1047, 46547"
"  %1364 = mul nuw i32 %1047, 46547" -> "  %1365 = add nuw i32 %1363, %1364"
"  %1365 = add nuw i32 %1363, %1364"
"  %1365 = add nuw i32 %1363, %1364" -> "  %1369 = and i32 %1365, -65536""  %1365 = add nuw i32 %1363, %1364" -> "  %1367 = and i32 %1365, 65535"
"  %1366 = lshr i32 %1362, 16"
"  %1366 = lshr i32 %1362, 16" -> "  %1368 = add nuw nsw i32 %1366, %1367"
"  %1367 = and i32 %1365, 65535"
"  %1367 = and i32 %1365, 65535" -> "  %1368 = add nuw nsw i32 %1366, %1367"
"  %1368 = add nuw nsw i32 %1366, %1367"
"  %1368 = add nuw nsw i32 %1366, %1367" -> "  %1370 = add nuw i32 %1368, %1369"
"  %1369 = and i32 %1365, -65536"
"  %1369 = and i32 %1365, -65536" -> "  %1370 = add nuw i32 %1368, %1369"
"  %1370 = add nuw i32 %1368, %1369"
"  %1370 = add nuw i32 %1368, %1369" -> "  %1393 = lshr i32 %1370, 16""  %1370 = add nuw i32 %1368, %1369" -> "  %1389 = and i32 %1370, 65535"
"  %1371 = mul nuw nsw i32 %1064, 17857"
"  %1371 = mul nuw nsw i32 %1064, 17857" -> "  %1390 = and i32 %1371, 65535""  %1371 = mul nuw nsw i32 %1064, 17857" -> "  %1372 = lshr i32 %1371, 16"
"  %1372 = lshr i32 %1371, 16"
"  %1372 = lshr i32 %1371, 16" -> "  %1375 = add nuw nsw i32 %1374, %1372"
"  %1373 = mul nuw nsw i32 %1065, 17857"
"  %1373 = mul nuw nsw i32 %1065, 17857" -> "  %1376 = and i32 %1373, 2147418112""  %1373 = mul nuw nsw i32 %1065, 17857" -> "  %1374 = and i32 %1373, 65535"
"  %1374 = and i32 %1373, 65535"
"  %1374 = and i32 %1373, 65535" -> "  %1375 = add nuw nsw i32 %1374, %1372"
"  %1375 = add nuw nsw i32 %1374, %1372"
"  %1375 = add nuw nsw i32 %1374, %1372" -> "  %1377 = add nuw nsw i32 %1375, %1376"
"  %1376 = and i32 %1373, 2147418112"
"  %1376 = and i32 %1373, 2147418112" -> "  %1377 = add nuw nsw i32 %1375, %1376"
"  %1377 = add nuw nsw i32 %1375, %1376"
"  %1377 = add nuw nsw i32 %1375, %1376" -> "  %1381 = lshr i32 %1377, 16""  %1377 = add nuw nsw i32 %1375, %1376" -> "  %1379 = and i32 %1377, 65535"
"  %1378 = mul nuw i32 %1064, 46547"
"  %1378 = mul nuw i32 %1064, 46547" -> "  %1380 = add nuw i32 %1379, %1378"
"  %1379 = and i32 %1377, 65535"
"  %1379 = and i32 %1377, 65535" -> "  %1380 = add nuw i32 %1379, %1378"
"  %1380 = add nuw i32 %1379, %1378"
"  %1380 = add nuw i32 %1379, %1378" -> "  %1392 = and i32 %1380, 65535""  %1380 = add nuw i32 %1379, %1378" -> "  %1384 = lshr i32 %1380, 16"
"  %1381 = lshr i32 %1377, 16"
"  %1381 = lshr i32 %1377, 16" -> "  %1383 = add nuw i32 %1381, %1382"
"  %1382 = mul nuw i32 %1065, 46547"
"  %1382 = mul nuw i32 %1065, 46547" -> "  %1383 = add nuw i32 %1381, %1382"
"  %1383 = add nuw i32 %1381, %1382"
"  %1383 = add nuw i32 %1381, %1382" -> "  %1387 = and i32 %1383, -65536""  %1383 = add nuw i32 %1381, %1382" -> "  %1385 = and i32 %1383, 65535"
"  %1384 = lshr i32 %1380, 16"
"  %1384 = lshr i32 %1380, 16" -> "  %1386 = add nuw nsw i32 %1384, %1385"
"  %1385 = and i32 %1383, 65535"
"  %1385 = and i32 %1383, 65535" -> "  %1386 = add nuw nsw i32 %1384, %1385"
"  %1386 = add nuw nsw i32 %1384, %1385"
"  %1386 = add nuw nsw i32 %1384, %1385" -> "  %1388 = add nuw i32 %1386, %1387"
"  %1387 = and i32 %1383, -65536"
"  %1387 = and i32 %1383, -65536" -> "  %1388 = add nuw i32 %1386, %1387"
"  %1388 = add nuw i32 %1386, %1387"
"  %1388 = add nuw i32 %1386, %1387" -> "  %1396 = add nuw i32 %1388, %1395"
"  %1389 = and i32 %1370, 65535"
"  %1389 = and i32 %1370, 65535" -> "  %1391 = add nuw nsw i32 %1389, %1390"
"  %1390 = and i32 %1371, 65535"
"  %1390 = and i32 %1371, 65535" -> "  %1391 = add nuw nsw i32 %1389, %1390"
"  %1391 = add nuw nsw i32 %1389, %1390"
"  %1391 = add nuw nsw i32 %1389, %1390" -> "  %1420 = and i32 %1391, 65535""  %1391 = add nuw nsw i32 %1389, %1390" -> "  %1398 = lshr i32 %1391, 16"
"  %1392 = and i32 %1380, 65535"
"  %1392 = and i32 %1380, 65535" -> "  %1394 = add nuw nsw i32 %1392, %1393"
"  %1393 = lshr i32 %1370, 16"
"  %1393 = lshr i32 %1370, 16" -> "  %1394 = add nuw nsw i32 %1392, %1393"
"  %1394 = add nuw nsw i32 %1392, %1393"
"  %1394 = add nuw nsw i32 %1392, %1393" -> "  %1397 = and i32 %1394, 65535""  %1394 = add nuw nsw i32 %1392, %1393" -> "  %1395 = lshr i32 %1394, 16"
"  %1395 = lshr i32 %1394, 16"
"  %1395 = lshr i32 %1394, 16" -> "  %1396 = add nuw i32 %1388, %1395"
"  %1396 = add nuw i32 %1388, %1395"
"  %1396 = add nuw i32 %1388, %1395" -> "  %1401 = add nuw i32 %1396, %1400"
"  %1397 = and i32 %1394, 65535"
"  %1397 = and i32 %1394, 65535" -> "  %1399 = add nuw nsw i32 %1397, %1398"
"  %1398 = lshr i32 %1391, 16"
"  %1398 = lshr i32 %1391, 16" -> "  %1399 = add nuw nsw i32 %1397, %1398"
"  %1399 = add nuw nsw i32 %1397, %1398"
"  %1399 = add nuw nsw i32 %1397, %1398" -> "  %1423 = and i32 %1399, 65535""  %1399 = add nuw nsw i32 %1397, %1398" -> "  %1400 = lshr i32 %1399, 16"
"  %1400 = lshr i32 %1399, 16"
"  %1400 = lshr i32 %1399, 16" -> "  %1401 = add nuw i32 %1396, %1400"
"  %1401 = add nuw i32 %1396, %1400"
"  %1401 = add nuw i32 %1396, %1400" -> "  %1455 = lshr i32 %1401, 16""  %1401 = add nuw i32 %1396, %1400" -> "  %1451 = and i32 %1401, 65535"
"  %1402 = mul nuw nsw i32 %1044, 31112"
"  %1402 = mul nuw nsw i32 %1044, 31112" -> "  %1421 = and i32 %1402, 65528""  %1402 = mul nuw nsw i32 %1044, 31112" -> "  %1403 = lshr i32 %1402, 16"
"  %1403 = lshr i32 %1402, 16"
"  %1403 = lshr i32 %1402, 16" -> "  %1406 = add nuw nsw i32 %1405, %1403"
"  %1404 = mul nuw nsw i32 %1047, 31112"
"  %1404 = mul nuw nsw i32 %1047, 31112" -> "  %1407 = and i32 %1404, 2147418112""  %1404 = mul nuw nsw i32 %1047, 31112" -> "  %1405 = and i32 %1404, 65528"
"  %1405 = and i32 %1404, 65528"
"  %1405 = and i32 %1404, 65528" -> "  %1406 = add nuw nsw i32 %1405, %1403"
"  %1406 = add nuw nsw i32 %1405, %1403"
"  %1406 = add nuw nsw i32 %1405, %1403" -> "  %1408 = add nuw nsw i32 %1406, %1407"
"  %1407 = and i32 %1404, 2147418112"
"  %1407 = and i32 %1404, 2147418112" -> "  %1408 = add nuw nsw i32 %1406, %1407"
"  %1408 = add nuw nsw i32 %1406, %1407"
"  %1408 = add nuw nsw i32 %1406, %1407" -> "  %1412 = lshr i32 %1408, 16""  %1408 = add nuw nsw i32 %1406, %1407" -> "  %1410 = and i32 %1408, 65535"
"  %1409 = mul nuw i32 %1044, 42170"
"  %1409 = mul nuw i32 %1044, 42170" -> "  %1411 = add nuw i32 %1410, %1409"
"  %1410 = and i32 %1408, 65535"
"  %1410 = and i32 %1408, 65535" -> "  %1411 = add nuw i32 %1410, %1409"
"  %1411 = add nuw i32 %1410, %1409"
"  %1411 = add nuw i32 %1410, %1409" -> "  %1424 = and i32 %1411, 65535""  %1411 = add nuw i32 %1410, %1409" -> "  %1415 = lshr i32 %1411, 16"
"  %1412 = lshr i32 %1408, 16"
"  %1412 = lshr i32 %1408, 16" -> "  %1414 = add nuw i32 %1412, %1413"
"  %1413 = mul nuw i32 %1047, 42170"
"  %1413 = mul nuw i32 %1047, 42170" -> "  %1414 = add nuw i32 %1412, %1413"
"  %1414 = add nuw i32 %1412, %1413"
"  %1414 = add nuw i32 %1412, %1413" -> "  %1418 = and i32 %1414, -65536""  %1414 = add nuw i32 %1412, %1413" -> "  %1416 = and i32 %1414, 65535"
"  %1415 = lshr i32 %1411, 16"
"  %1415 = lshr i32 %1411, 16" -> "  %1417 = add nuw nsw i32 %1415, %1416"
"  %1416 = and i32 %1414, 65535"
"  %1416 = and i32 %1414, 65535" -> "  %1417 = add nuw nsw i32 %1415, %1416"
"  %1417 = add nuw nsw i32 %1415, %1416"
"  %1417 = add nuw nsw i32 %1415, %1416" -> "  %1419 = add nuw i32 %1417, %1418"
"  %1418 = and i32 %1414, -65536"
"  %1418 = and i32 %1414, -65536" -> "  %1419 = add nuw i32 %1417, %1418"
"  %1419 = add nuw i32 %1417, %1418"
"  %1419 = add nuw i32 %1417, %1418" -> "  %1427 = add nuw i32 %1419, %1426"
"  %1420 = and i32 %1391, 65535"
"  %1420 = and i32 %1391, 65535" -> "  %1422 = add nuw nsw i32 %1420, %1421"
"  %1421 = and i32 %1402, 65528"
"  %1421 = and i32 %1402, 65528" -> "  %1422 = add nuw nsw i32 %1420, %1421"
"  %1422 = add nuw nsw i32 %1420, %1421"
"  %1422 = add nuw nsw i32 %1420, %1421" -> "  %1491 = and i32 %1422, 65535""  %1422 = add nuw nsw i32 %1420, %1421" -> "  %1429 = lshr i32 %1422, 16"
"  %1423 = and i32 %1399, 65535"
"  %1423 = and i32 %1399, 65535" -> "  %1425 = add nuw nsw i32 %1423, %1424"
"  %1424 = and i32 %1411, 65535"
"  %1424 = and i32 %1411, 65535" -> "  %1425 = add nuw nsw i32 %1423, %1424"
"  %1425 = add nuw nsw i32 %1423, %1424"
"  %1425 = add nuw nsw i32 %1423, %1424" -> "  %1428 = and i32 %1425, 65535""  %1425 = add nuw nsw i32 %1423, %1424" -> "  %1426 = lshr i32 %1425, 16"
"  %1426 = lshr i32 %1425, 16"
"  %1426 = lshr i32 %1425, 16" -> "  %1427 = add nuw i32 %1419, %1426"
"  %1427 = add nuw i32 %1419, %1426"
"  %1427 = add nuw i32 %1419, %1426" -> "  %1432 = add nuw i32 %1427, %1431"
"  %1428 = and i32 %1425, 65535"
"  %1428 = and i32 %1425, 65535" -> "  %1430 = add nuw nsw i32 %1428, %1429"
"  %1429 = lshr i32 %1422, 16"
"  %1429 = lshr i32 %1422, 16" -> "  %1430 = add nuw nsw i32 %1428, %1429"
"  %1430 = add nuw nsw i32 %1428, %1429"
"  %1430 = add nuw nsw i32 %1428, %1429" -> "  %1494 = and i32 %1430, 65535""  %1430 = add nuw nsw i32 %1428, %1429" -> "  %1431 = lshr i32 %1430, 16"
"  %1431 = lshr i32 %1430, 16"
"  %1431 = lshr i32 %1430, 16" -> "  %1432 = add nuw i32 %1427, %1431"
"  %1432 = add nuw i32 %1427, %1431"
"  %1432 = add nuw i32 %1427, %1431" -> "  %1468 = lshr i32 %1432, 16""  %1432 = add nuw i32 %1427, %1431" -> "  %1465 = and i32 %1432, 65535"
"  %1433 = mul nuw nsw i32 %1064, 31112"
"  %1433 = mul nuw nsw i32 %1064, 31112" -> "  %1452 = and i32 %1433, 65528""  %1433 = mul nuw nsw i32 %1064, 31112" -> "  %1434 = lshr i32 %1433, 16"
"  %1434 = lshr i32 %1433, 16"
"  %1434 = lshr i32 %1433, 16" -> "  %1437 = add nuw nsw i32 %1436, %1434"
"  %1435 = mul nuw nsw i32 %1065, 31112"
"  %1435 = mul nuw nsw i32 %1065, 31112" -> "  %1438 = and i32 %1435, 2147418112""  %1435 = mul nuw nsw i32 %1065, 31112" -> "  %1436 = and i32 %1435, 65528"
"  %1436 = and i32 %1435, 65528"
"  %1436 = and i32 %1435, 65528" -> "  %1437 = add nuw nsw i32 %1436, %1434"
"  %1437 = add nuw nsw i32 %1436, %1434"
"  %1437 = add nuw nsw i32 %1436, %1434" -> "  %1439 = add nuw nsw i32 %1437, %1438"
"  %1438 = and i32 %1435, 2147418112"
"  %1438 = and i32 %1435, 2147418112" -> "  %1439 = add nuw nsw i32 %1437, %1438"
"  %1439 = add nuw nsw i32 %1437, %1438"
"  %1439 = add nuw nsw i32 %1437, %1438" -> "  %1443 = lshr i32 %1439, 16""  %1439 = add nuw nsw i32 %1437, %1438" -> "  %1441 = and i32 %1439, 65535"
"  %1440 = mul nuw i32 %1064, 42170"
"  %1440 = mul nuw i32 %1064, 42170" -> "  %1442 = add nuw i32 %1441, %1440"
"  %1441 = and i32 %1439, 65535"
"  %1441 = and i32 %1439, 65535" -> "  %1442 = add nuw i32 %1441, %1440"
"  %1442 = add nuw i32 %1441, %1440"
"  %1442 = add nuw i32 %1441, %1440" -> "  %1454 = and i32 %1442, 65535""  %1442 = add nuw i32 %1441, %1440" -> "  %1446 = lshr i32 %1442, 16"
"  %1443 = lshr i32 %1439, 16"
"  %1443 = lshr i32 %1439, 16" -> "  %1445 = add nuw i32 %1443, %1444"
"  %1444 = mul nuw i32 %1065, 42170"
"  %1444 = mul nuw i32 %1065, 42170" -> "  %1445 = add nuw i32 %1443, %1444"
"  %1445 = add nuw i32 %1443, %1444"
"  %1445 = add nuw i32 %1443, %1444" -> "  %1449 = and i32 %1445, -65536""  %1445 = add nuw i32 %1443, %1444" -> "  %1447 = and i32 %1445, 65535"
"  %1446 = lshr i32 %1442, 16"
"  %1446 = lshr i32 %1442, 16" -> "  %1448 = add nuw nsw i32 %1446, %1447"
"  %1447 = and i32 %1445, 65535"
"  %1447 = and i32 %1445, 65535" -> "  %1448 = add nuw nsw i32 %1446, %1447"
"  %1448 = add nuw nsw i32 %1446, %1447"
"  %1448 = add nuw nsw i32 %1446, %1447" -> "  %1450 = add nuw i32 %1448, %1449"
"  %1449 = and i32 %1445, -65536"
"  %1449 = and i32 %1445, -65536" -> "  %1450 = add nuw i32 %1448, %1449"
"  %1450 = add nuw i32 %1448, %1449"
"  %1450 = add nuw i32 %1448, %1449" -> "  %1458 = add nuw i32 %1450, %1457"
"  %1451 = and i32 %1401, 65535"
"  %1451 = and i32 %1401, 65535" -> "  %1453 = add nuw nsw i32 %1451, %1452"
"  %1452 = and i32 %1433, 65528"
"  %1452 = and i32 %1433, 65528" -> "  %1453 = add nuw nsw i32 %1451, %1452"
"  %1453 = add nuw nsw i32 %1451, %1452"
"  %1453 = add nuw nsw i32 %1451, %1452" -> "  %1464 = and i32 %1453, 65535""  %1453 = add nuw nsw i32 %1451, %1452" -> "  %1460 = lshr i32 %1453, 16"
"  %1454 = and i32 %1442, 65535"
"  %1454 = and i32 %1442, 65535" -> "  %1456 = add nuw nsw i32 %1455, %1454"
"  %1455 = lshr i32 %1401, 16"
"  %1455 = lshr i32 %1401, 16" -> "  %1456 = add nuw nsw i32 %1455, %1454"
"  %1456 = add nuw nsw i32 %1455, %1454"
"  %1456 = add nuw nsw i32 %1455, %1454" -> "  %1459 = and i32 %1456, 65535""  %1456 = add nuw nsw i32 %1455, %1454" -> "  %1457 = lshr i32 %1456, 16"
"  %1457 = lshr i32 %1456, 16"
"  %1457 = lshr i32 %1456, 16" -> "  %1458 = add nuw i32 %1450, %1457"
"  %1458 = add nuw i32 %1450, %1457"
"  %1458 = add nuw i32 %1450, %1457" -> "  %1463 = add nuw i32 %1458, %1462"
"  %1459 = and i32 %1456, 65535"
"  %1459 = and i32 %1456, 65535" -> "  %1461 = add nuw nsw i32 %1459, %1460"
"  %1460 = lshr i32 %1453, 16"
"  %1460 = lshr i32 %1453, 16" -> "  %1461 = add nuw nsw i32 %1459, %1460"
"  %1461 = add nuw nsw i32 %1459, %1460"
"  %1461 = add nuw nsw i32 %1459, %1460" -> "  %1467 = and i32 %1461, 65535""  %1461 = add nuw nsw i32 %1459, %1460" -> "  %1462 = lshr i32 %1461, 16"
"  %1462 = lshr i32 %1461, 16"
"  %1462 = lshr i32 %1461, 16" -> "  %1463 = add nuw i32 %1458, %1462"
"  %1463 = add nuw i32 %1458, %1462"
"  %1463 = add nuw i32 %1458, %1462" -> "  %1476 = and i32 %1463, -65536""  %1463 = add nuw i32 %1458, %1462" -> "  %1474 = and i32 %1463, 65535"
"  %1464 = and i32 %1453, 65535"
"  %1464 = and i32 %1453, 65535" -> "  %1466 = add nuw nsw i32 %1465, %1464"
"  %1465 = and i32 %1432, 65535"
"  %1465 = and i32 %1432, 65535" -> "  %1466 = add nuw nsw i32 %1465, %1464"
"  %1466 = add nuw nsw i32 %1465, %1464"
"  %1466 = add nuw nsw i32 %1465, %1464" -> "  %1506 = and i32 %1466, 65535""  %1466 = add nuw nsw i32 %1465, %1464" -> "  %1470 = lshr i32 %1466, 16"
"  %1467 = and i32 %1461, 65535"
"  %1467 = and i32 %1461, 65535" -> "  %1469 = add nuw nsw i32 %1467, %1468"
"  %1468 = lshr i32 %1432, 16"
"  %1468 = lshr i32 %1432, 16" -> "  %1469 = add nuw nsw i32 %1467, %1468"
"  %1469 = add nuw nsw i32 %1467, %1468"
"  %1469 = add nuw nsw i32 %1467, %1468" -> "  %1473 = lshr i32 %1469, 16""  %1469 = add nuw nsw i32 %1467, %1468" -> "  %1471 = and i32 %1469, 65535"
"  %1470 = lshr i32 %1466, 16"
"  %1470 = lshr i32 %1466, 16" -> "  %1472 = add nuw nsw i32 %1471, %1470"
"  %1471 = and i32 %1469, 65535"
"  %1471 = and i32 %1469, 65535" -> "  %1472 = add nuw nsw i32 %1471, %1470"
"  %1472 = add nuw nsw i32 %1471, %1470"
"  %1472 = add nuw nsw i32 %1471, %1470" -> "  %1513 = and i32 %1472, 65535""  %1472 = add nuw nsw i32 %1471, %1470" -> "  %1478 = lshr i32 %1472, 16"
"  %1473 = lshr i32 %1469, 16"
"  %1473 = lshr i32 %1469, 16" -> "  %1475 = add nuw nsw i32 %1473, %1474"
"  %1474 = and i32 %1463, 65535"
"  %1474 = and i32 %1463, 65535" -> "  %1475 = add nuw nsw i32 %1473, %1474"
"  %1475 = add nuw nsw i32 %1473, %1474"
"  %1475 = add nuw nsw i32 %1473, %1474" -> "  %1477 = add nuw i32 %1475, %1476"
"  %1476 = and i32 %1463, -65536"
"  %1476 = and i32 %1463, -65536" -> "  %1477 = add nuw i32 %1475, %1476"
"  %1477 = add nuw i32 %1475, %1476"
"  %1477 = add nuw i32 %1475, %1476" -> "  %1479 = add nuw i32 %1477, %1478"
"  %1478 = lshr i32 %1472, 16"
"  %1478 = lshr i32 %1472, 16" -> "  %1479 = add nuw i32 %1477, %1478"
"  %1479 = add nuw i32 %1477, %1478"
"  %1479 = add nuw i32 %1477, %1478" -> "  %1517 = add nuw i32 %1479, %1516"
"  %1480 = and i32 %1350, 65535"
"  %1480 = and i32 %1350, 65535" -> "  %1482 = add nuw nsw i32 %1481, %1480"
"  %1481 = and i32 %1314, 65535"
"  %1481 = and i32 %1314, 65535" -> "  %1482 = add nuw nsw i32 %1481, %1480"
"  %1482 = add nuw nsw i32 %1481, %1480"
"  %1482 = add nuw nsw i32 %1481, %1480" -> "  %1486 = lshr i32 %1482, 16"
"  %1483 = and i32 %1362, 65535"
"  %1483 = and i32 %1362, 65535" -> "  %1485 = add nuw nsw i32 %1484, %1483"
"  %1484 = and i32 %1320, 65535"
"  %1484 = and i32 %1320, 65535" -> "  %1485 = add nuw nsw i32 %1484, %1483"
"  %1485 = add nuw nsw i32 %1484, %1483"
"  %1485 = add nuw nsw i32 %1484, %1483" -> "  %1489 = lshr i32 %1485, 16""  %1485 = add nuw nsw i32 %1484, %1483" -> "  %1487 = and i32 %1485, 65535"
"  %1486 = lshr i32 %1482, 16"
"  %1486 = lshr i32 %1482, 16" -> "  %1488 = add nuw nsw i32 %1487, %1486"
"  %1487 = and i32 %1485, 65535"
"  %1487 = and i32 %1485, 65535" -> "  %1488 = add nuw nsw i32 %1487, %1486"
"  %1488 = add nuw nsw i32 %1487, %1486"
"  %1488 = add nuw nsw i32 %1487, %1486" -> "  %1490 = lshr i32 %1488, 16"
"  %1489 = lshr i32 %1485, 16"
"  %1489 = lshr i32 %1485, 16" -> "  %1501 = add nuw nsw i32 %1490, %1489"
"  %1490 = lshr i32 %1488, 16"
"  %1490 = lshr i32 %1488, 16" -> "  %1501 = add nuw nsw i32 %1490, %1489"
"  %1491 = and i32 %1422, 65535"
"  %1491 = and i32 %1422, 65535" -> "  %1493 = add nuw nsw i32 %1492, %1491"
"  %1492 = and i32 %1334, 65535"
"  %1492 = and i32 %1334, 65535" -> "  %1493 = add nuw nsw i32 %1492, %1491"
"  %1493 = add nuw nsw i32 %1492, %1491"
"  %1493 = add nuw nsw i32 %1492, %1491" -> "  %1500 = and i32 %1493, 65535""  %1493 = add nuw nsw i32 %1492, %1491" -> "  %1497 = lshr i32 %1493, 16"
"  %1494 = and i32 %1430, 65535"
"  %1494 = and i32 %1430, 65535" -> "  %1496 = add nuw nsw i32 %1495, %1494"
"  %1495 = and i32 %1337, 65535"
"  %1495 = and i32 %1337, 65535" -> "  %1496 = add nuw nsw i32 %1495, %1494"
"  %1496 = add nuw nsw i32 %1495, %1494"
"  %1496 = add nuw nsw i32 %1495, %1494" -> "  %1507 = lshr i32 %1496, 16""  %1496 = add nuw nsw i32 %1495, %1494" -> "  %1498 = and i32 %1496, 65535"
"  %1497 = lshr i32 %1493, 16"
"  %1497 = lshr i32 %1493, 16" -> "  %1499 = add nuw nsw i32 %1498, %1497"
"  %1498 = and i32 %1496, 65535"
"  %1498 = and i32 %1496, 65535" -> "  %1499 = add nuw nsw i32 %1498, %1497"
"  %1499 = add nuw nsw i32 %1498, %1497"
"  %1499 = add nuw nsw i32 %1498, %1497" -> "  %1509 = lshr i32 %1499, 16""  %1499 = add nuw nsw i32 %1498, %1497" -> "  %1504 = and i32 %1499, 65535"
"  %1500 = and i32 %1493, 65535"
"  %1500 = and i32 %1493, 65535" -> "  %1502 = add nuw nsw i32 %1501, %1500"
"  %1501 = add nuw nsw i32 %1490, %1489"
"  %1501 = add nuw nsw i32 %1490, %1489" -> "  %1502 = add nuw nsw i32 %1501, %1500"
"  %1502 = add nuw nsw i32 %1501, %1500"
"  %1502 = add nuw nsw i32 %1501, %1500" -> "  %1503 = lshr i32 %1502, 16"
"  %1503 = lshr i32 %1502, 16"
"  %1503 = lshr i32 %1502, 16" -> "  %1505 = add nuw nsw i32 %1504, %1503"
"  %1504 = and i32 %1499, 65535"
"  %1504 = and i32 %1499, 65535" -> "  %1505 = add nuw nsw i32 %1504, %1503"
"  %1505 = add nuw nsw i32 %1504, %1503"
"  %1505 = add nuw nsw i32 %1504, %1503" -> "  %1511 = lshr i32 %1505, 16"
"  %1506 = and i32 %1466, 65535"
"  %1506 = and i32 %1466, 65535" -> "  %1508 = add nuw nsw i32 %1507, %1506"
"  %1507 = lshr i32 %1496, 16"
"  %1507 = lshr i32 %1496, 16" -> "  %1508 = add nuw nsw i32 %1507, %1506"
"  %1508 = add nuw nsw i32 %1507, %1506"
"  %1508 = add nuw nsw i32 %1507, %1506" -> "  %1510 = add nuw nsw i32 %1508, %1509"
"  %1509 = lshr i32 %1499, 16"
"  %1509 = lshr i32 %1499, 16" -> "  %1510 = add nuw nsw i32 %1508, %1509"
"  %1510 = add nuw nsw i32 %1508, %1509"
"  %1510 = add nuw nsw i32 %1508, %1509" -> "  %1512 = add nuw nsw i32 %1510, %1511"
"  %1511 = lshr i32 %1505, 16"
"  %1511 = lshr i32 %1505, 16" -> "  %1512 = add nuw nsw i32 %1510, %1511"
"  %1512 = add nuw nsw i32 %1510, %1511"
"  %1512 = add nuw nsw i32 %1510, %1511" -> "  %1684 = and i32 %1512, 65535""  %1512 = add nuw nsw i32 %1510, %1511" -> "  %1514 = lshr i32 %1512, 16"
"  %1513 = and i32 %1472, 65535"
"  %1513 = and i32 %1472, 65535" -> "  %1515 = add nuw nsw i32 %1514, %1513"
"  %1514 = lshr i32 %1512, 16"
"  %1514 = lshr i32 %1512, 16" -> "  %1515 = add nuw nsw i32 %1514, %1513"
"  %1515 = add nuw nsw i32 %1514, %1513"
"  %1515 = add nuw nsw i32 %1514, %1513" -> "  %1687 = and i32 %1515, 65535""  %1515 = add nuw nsw i32 %1514, %1513" -> "  %1516 = lshr i32 %1515, 16"
"  %1516 = lshr i32 %1515, 16"
"  %1516 = lshr i32 %1515, 16" -> "  %1517 = add nuw i32 %1479, %1516"
"  %1517 = add nuw i32 %1479, %1516"
"  %1517 = add nuw i32 %1479, %1516" -> "  %1696 = and i32 %1517, 65535""  %1517 = add nuw i32 %1479, %1516" -> "  %1699 = lshr i32 %1517, 16"
"  %1518 = mul nuw nsw i32 %1178, 17857"
"  %1518 = mul nuw nsw i32 %1178, 17857" -> "  %1645 = and i32 %1518, 65535""  %1518 = mul nuw nsw i32 %1178, 17857" -> "  %1519 = lshr i32 %1518, 16"
"  %1519 = lshr i32 %1518, 16"
"  %1519 = lshr i32 %1518, 16" -> "  %1522 = add nuw nsw i32 %1521, %1519"
"  %1520 = mul nuw nsw i32 %1179, 17857"
"  %1520 = mul nuw nsw i32 %1179, 17857" -> "  %1523 = and i32 %1520, 2147418112""  %1520 = mul nuw nsw i32 %1179, 17857" -> "  %1521 = and i32 %1520, 65535"
"  %1521 = and i32 %1520, 65535"
"  %1521 = and i32 %1520, 65535" -> "  %1522 = add nuw nsw i32 %1521, %1519"
"  %1522 = add nuw nsw i32 %1521, %1519"
"  %1522 = add nuw nsw i32 %1521, %1519" -> "  %1524 = add nuw nsw i32 %1522, %1523"
"  %1523 = and i32 %1520, 2147418112"
"  %1523 = and i32 %1520, 2147418112" -> "  %1524 = add nuw nsw i32 %1522, %1523"
"  %1524 = add nuw nsw i32 %1522, %1523"
"  %1524 = add nuw nsw i32 %1522, %1523" -> "  %1528 = lshr i32 %1524, 16""  %1524 = add nuw nsw i32 %1522, %1523" -> "  %1526 = and i32 %1524, 65535"
"  %1525 = mul nuw i32 %1178, 46547"
"  %1525 = mul nuw i32 %1178, 46547" -> "  %1527 = add nuw i32 %1526, %1525"
"  %1526 = and i32 %1524, 65535"
"  %1526 = and i32 %1524, 65535" -> "  %1527 = add nuw i32 %1526, %1525"
"  %1527 = add nuw i32 %1526, %1525"
"  %1527 = add nuw i32 %1526, %1525" -> "  %1648 = and i32 %1527, 65535""  %1527 = add nuw i32 %1526, %1525" -> "  %1531 = lshr i32 %1527, 16"
"  %1528 = lshr i32 %1524, 16"
"  %1528 = lshr i32 %1524, 16" -> "  %1530 = add nuw i32 %1528, %1529"
"  %1529 = mul nuw i32 %1179, 46547"
"  %1529 = mul nuw i32 %1179, 46547" -> "  %1530 = add nuw i32 %1528, %1529"
"  %1530 = add nuw i32 %1528, %1529"
"  %1530 = add nuw i32 %1528, %1529" -> "  %1534 = and i32 %1530, -65536""  %1530 = add nuw i32 %1528, %1529" -> "  %1532 = and i32 %1530, 65535"
"  %1531 = lshr i32 %1527, 16"
"  %1531 = lshr i32 %1527, 16" -> "  %1533 = add nuw nsw i32 %1531, %1532"
"  %1532 = and i32 %1530, 65535"
"  %1532 = and i32 %1530, 65535" -> "  %1533 = add nuw nsw i32 %1531, %1532"
"  %1533 = add nuw nsw i32 %1531, %1532"
"  %1533 = add nuw nsw i32 %1531, %1532" -> "  %1535 = add nuw i32 %1533, %1534"
"  %1534 = and i32 %1530, -65536"
"  %1534 = and i32 %1530, -65536" -> "  %1535 = add nuw i32 %1533, %1534"
"  %1535 = add nuw i32 %1533, %1534"
"  %1535 = add nuw i32 %1533, %1534" -> "  %1558 = lshr i32 %1535, 16""  %1535 = add nuw i32 %1533, %1534" -> "  %1554 = and i32 %1535, 65535"
"  %1536 = mul nuw nsw i32 %1198, 17857"
"  %1536 = mul nuw nsw i32 %1198, 17857" -> "  %1555 = and i32 %1536, 65535""  %1536 = mul nuw nsw i32 %1198, 17857" -> "  %1537 = lshr i32 %1536, 16"
"  %1537 = lshr i32 %1536, 16"
"  %1537 = lshr i32 %1536, 16" -> "  %1540 = add nuw nsw i32 %1539, %1537"
"  %1538 = mul nuw nsw i32 %1201, 17857"
"  %1538 = mul nuw nsw i32 %1201, 17857" -> "  %1541 = and i32 %1538, 2147418112""  %1538 = mul nuw nsw i32 %1201, 17857" -> "  %1539 = and i32 %1538, 65535"
"  %1539 = and i32 %1538, 65535"
"  %1539 = and i32 %1538, 65535" -> "  %1540 = add nuw nsw i32 %1539, %1537"
"  %1540 = add nuw nsw i32 %1539, %1537"
"  %1540 = add nuw nsw i32 %1539, %1537" -> "  %1542 = add nuw nsw i32 %1540, %1541"
"  %1541 = and i32 %1538, 2147418112"
"  %1541 = and i32 %1538, 2147418112" -> "  %1542 = add nuw nsw i32 %1540, %1541"
"  %1542 = add nuw nsw i32 %1540, %1541"
"  %1542 = add nuw nsw i32 %1540, %1541" -> "  %1546 = lshr i32 %1542, 16""  %1542 = add nuw nsw i32 %1540, %1541" -> "  %1544 = and i32 %1542, 65535"
"  %1543 = mul nuw i32 %1198, 46547"
"  %1543 = mul nuw i32 %1198, 46547" -> "  %1545 = add nuw i32 %1544, %1543"
"  %1544 = and i32 %1542, 65535"
"  %1544 = and i32 %1542, 65535" -> "  %1545 = add nuw i32 %1544, %1543"
"  %1545 = add nuw i32 %1544, %1543"
"  %1545 = add nuw i32 %1544, %1543" -> "  %1557 = and i32 %1545, 65535""  %1545 = add nuw i32 %1544, %1543" -> "  %1549 = lshr i32 %1545, 16"
"  %1546 = lshr i32 %1542, 16"
"  %1546 = lshr i32 %1542, 16" -> "  %1548 = add nuw i32 %1546, %1547"
"  %1547 = mul nuw i32 %1201, 46547"
"  %1547 = mul nuw i32 %1201, 46547" -> "  %1548 = add nuw i32 %1546, %1547"
"  %1548 = add nuw i32 %1546, %1547"
"  %1548 = add nuw i32 %1546, %1547" -> "  %1552 = and i32 %1548, -65536""  %1548 = add nuw i32 %1546, %1547" -> "  %1550 = and i32 %1548, 65535"
"  %1549 = lshr i32 %1545, 16"
"  %1549 = lshr i32 %1545, 16" -> "  %1551 = add nuw nsw i32 %1549, %1550"
"  %1550 = and i32 %1548, 65535"
"  %1550 = and i32 %1548, 65535" -> "  %1551 = add nuw nsw i32 %1549, %1550"
"  %1551 = add nuw nsw i32 %1549, %1550"
"  %1551 = add nuw nsw i32 %1549, %1550" -> "  %1553 = add nuw i32 %1551, %1552"
"  %1552 = and i32 %1548, -65536"
"  %1552 = and i32 %1548, -65536" -> "  %1553 = add nuw i32 %1551, %1552"
"  %1553 = add nuw i32 %1551, %1552"
"  %1553 = add nuw i32 %1551, %1552" -> "  %1561 = add nuw i32 %1553, %1560"
"  %1554 = and i32 %1535, 65535"
"  %1554 = and i32 %1535, 65535" -> "  %1556 = add nuw nsw i32 %1554, %1555"
"  %1555 = and i32 %1536, 65535"
"  %1555 = and i32 %1536, 65535" -> "  %1556 = add nuw nsw i32 %1554, %1555"
"  %1556 = add nuw nsw i32 %1554, %1555"
"  %1556 = add nuw nsw i32 %1554, %1555" -> "  %1585 = and i32 %1556, 65535""  %1556 = add nuw nsw i32 %1554, %1555" -> "  %1563 = lshr i32 %1556, 16"
"  %1557 = and i32 %1545, 65535"
"  %1557 = and i32 %1545, 65535" -> "  %1559 = add nuw nsw i32 %1557, %1558"
"  %1558 = lshr i32 %1535, 16"
"  %1558 = lshr i32 %1535, 16" -> "  %1559 = add nuw nsw i32 %1557, %1558"
"  %1559 = add nuw nsw i32 %1557, %1558"
"  %1559 = add nuw nsw i32 %1557, %1558" -> "  %1562 = and i32 %1559, 65535""  %1559 = add nuw nsw i32 %1557, %1558" -> "  %1560 = lshr i32 %1559, 16"
"  %1560 = lshr i32 %1559, 16"
"  %1560 = lshr i32 %1559, 16" -> "  %1561 = add nuw i32 %1553, %1560"
"  %1561 = add nuw i32 %1553, %1560"
"  %1561 = add nuw i32 %1553, %1560" -> "  %1566 = add nuw i32 %1561, %1565"
"  %1562 = and i32 %1559, 65535"
"  %1562 = and i32 %1559, 65535" -> "  %1564 = add nuw nsw i32 %1562, %1563"
"  %1563 = lshr i32 %1556, 16"
"  %1563 = lshr i32 %1556, 16" -> "  %1564 = add nuw nsw i32 %1562, %1563"
"  %1564 = add nuw nsw i32 %1562, %1563"
"  %1564 = add nuw nsw i32 %1562, %1563" -> "  %1589 = and i32 %1564, 65535""  %1564 = add nuw nsw i32 %1562, %1563" -> "  %1565 = lshr i32 %1564, 16"
"  %1565 = lshr i32 %1564, 16"
"  %1565 = lshr i32 %1564, 16" -> "  %1566 = add nuw i32 %1561, %1565"
"  %1566 = add nuw i32 %1561, %1565"
"  %1566 = add nuw i32 %1561, %1565" -> "  %1616 = and i32 %1566, 65535""  %1566 = add nuw i32 %1561, %1565" -> "  %1620 = lshr i32 %1566, 16"
"  %1567 = mul nuw nsw i32 %1178, 31112"
"  %1567 = mul nuw nsw i32 %1178, 31112" -> "  %1586 = and i32 %1567, 65528""  %1567 = mul nuw nsw i32 %1178, 31112" -> "  %1568 = lshr i32 %1567, 16"
"  %1568 = lshr i32 %1567, 16"
"  %1568 = lshr i32 %1567, 16" -> "  %1571 = add nuw nsw i32 %1570, %1568"
"  %1569 = mul nuw nsw i32 %1179, 31112"
"  %1569 = mul nuw nsw i32 %1179, 31112" -> "  %1572 = and i32 %1569, 2147418112""  %1569 = mul nuw nsw i32 %1179, 31112" -> "  %1570 = and i32 %1569, 65528"
"  %1570 = and i32 %1569, 65528"
"  %1570 = and i32 %1569, 65528" -> "  %1571 = add nuw nsw i32 %1570, %1568"
"  %1571 = add nuw nsw i32 %1570, %1568"
"  %1571 = add nuw nsw i32 %1570, %1568" -> "  %1573 = add nuw nsw i32 %1571, %1572"
"  %1572 = and i32 %1569, 2147418112"
"  %1572 = and i32 %1569, 2147418112" -> "  %1573 = add nuw nsw i32 %1571, %1572"
"  %1573 = add nuw nsw i32 %1571, %1572"
"  %1573 = add nuw nsw i32 %1571, %1572" -> "  %1577 = lshr i32 %1573, 16""  %1573 = add nuw nsw i32 %1571, %1572" -> "  %1575 = and i32 %1573, 65535"
"  %1574 = mul nuw i32 %1178, 42170"
"  %1574 = mul nuw i32 %1178, 42170" -> "  %1576 = add nuw i32 %1575, %1574"
"  %1575 = and i32 %1573, 65535"
"  %1575 = and i32 %1573, 65535" -> "  %1576 = add nuw i32 %1575, %1574"
"  %1576 = add nuw i32 %1575, %1574"
"  %1576 = add nuw i32 %1575, %1574" -> "  %1588 = and i32 %1576, 65535""  %1576 = add nuw i32 %1575, %1574" -> "  %1580 = lshr i32 %1576, 16"
"  %1577 = lshr i32 %1573, 16"
"  %1577 = lshr i32 %1573, 16" -> "  %1579 = add nuw i32 %1577, %1578"
"  %1578 = mul nuw i32 %1179, 42170"
"  %1578 = mul nuw i32 %1179, 42170" -> "  %1579 = add nuw i32 %1577, %1578"
"  %1579 = add nuw i32 %1577, %1578"
"  %1579 = add nuw i32 %1577, %1578" -> "  %1583 = and i32 %1579, -65536""  %1579 = add nuw i32 %1577, %1578" -> "  %1581 = and i32 %1579, 65535"
"  %1580 = lshr i32 %1576, 16"
"  %1580 = lshr i32 %1576, 16" -> "  %1582 = add nuw nsw i32 %1580, %1581"
"  %1581 = and i32 %1579, 65535"
"  %1581 = and i32 %1579, 65535" -> "  %1582 = add nuw nsw i32 %1580, %1581"
"  %1582 = add nuw nsw i32 %1580, %1581"
"  %1582 = add nuw nsw i32 %1580, %1581" -> "  %1584 = add nuw i32 %1582, %1583"
"  %1583 = and i32 %1579, -65536"
"  %1583 = and i32 %1579, -65536" -> "  %1584 = add nuw i32 %1582, %1583"
"  %1584 = add nuw i32 %1582, %1583"
"  %1584 = add nuw i32 %1582, %1583" -> "  %1592 = add nuw i32 %1584, %1591"
"  %1585 = and i32 %1556, 65535"
"  %1585 = and i32 %1556, 65535" -> "  %1587 = add nuw nsw i32 %1585, %1586"
"  %1586 = and i32 %1567, 65528"
"  %1586 = and i32 %1567, 65528" -> "  %1587 = add nuw nsw i32 %1585, %1586"
"  %1587 = add nuw nsw i32 %1585, %1586"
"  %1587 = add nuw nsw i32 %1585, %1586" -> "  %1654 = and i32 %1587, 65535""  %1587 = add nuw nsw i32 %1585, %1586" -> "  %1594 = lshr i32 %1587, 16"
"  %1588 = and i32 %1576, 65535"
"  %1588 = and i32 %1576, 65535" -> "  %1590 = add nuw nsw i32 %1589, %1588"
"  %1589 = and i32 %1564, 65535"
"  %1589 = and i32 %1564, 65535" -> "  %1590 = add nuw nsw i32 %1589, %1588"
"  %1590 = add nuw nsw i32 %1589, %1588"
"  %1590 = add nuw nsw i32 %1589, %1588" -> "  %1593 = and i32 %1590, 65535""  %1590 = add nuw nsw i32 %1589, %1588" -> "  %1591 = lshr i32 %1590, 16"
"  %1591 = lshr i32 %1590, 16"
"  %1591 = lshr i32 %1590, 16" -> "  %1592 = add nuw i32 %1584, %1591"
"  %1592 = add nuw i32 %1584, %1591"
"  %1592 = add nuw i32 %1584, %1591" -> "  %1597 = add nuw i32 %1592, %1596"
"  %1593 = and i32 %1590, 65535"
"  %1593 = and i32 %1590, 65535" -> "  %1595 = add nuw nsw i32 %1593, %1594"
"  %1594 = lshr i32 %1587, 16"
"  %1594 = lshr i32 %1587, 16" -> "  %1595 = add nuw nsw i32 %1593, %1594"
"  %1595 = add nuw nsw i32 %1593, %1594"
"  %1595 = add nuw nsw i32 %1593, %1594" -> "  %1657 = and i32 %1595, 65535""  %1595 = add nuw nsw i32 %1593, %1594" -> "  %1596 = lshr i32 %1595, 16"
"  %1596 = lshr i32 %1595, 16"
"  %1596 = lshr i32 %1595, 16" -> "  %1597 = add nuw i32 %1592, %1596"
"  %1597 = add nuw i32 %1592, %1596"
"  %1597 = add nuw i32 %1592, %1596" -> "  %1633 = lshr i32 %1597, 16""  %1597 = add nuw i32 %1592, %1596" -> "  %1630 = and i32 %1597, 65535"
"  %1598 = mul nuw nsw i32 %1198, 31112"
"  %1598 = mul nuw nsw i32 %1198, 31112" -> "  %1617 = and i32 %1598, 65528""  %1598 = mul nuw nsw i32 %1198, 31112" -> "  %1599 = lshr i32 %1598, 16"
"  %1599 = lshr i32 %1598, 16"
"  %1599 = lshr i32 %1598, 16" -> "  %1602 = add nuw nsw i32 %1601, %1599"
"  %1600 = mul nuw nsw i32 %1201, 31112"
"  %1600 = mul nuw nsw i32 %1201, 31112" -> "  %1603 = and i32 %1600, 2147418112""  %1600 = mul nuw nsw i32 %1201, 31112" -> "  %1601 = and i32 %1600, 65528"
"  %1601 = and i32 %1600, 65528"
"  %1601 = and i32 %1600, 65528" -> "  %1602 = add nuw nsw i32 %1601, %1599"
"  %1602 = add nuw nsw i32 %1601, %1599"
"  %1602 = add nuw nsw i32 %1601, %1599" -> "  %1604 = add nuw nsw i32 %1602, %1603"
"  %1603 = and i32 %1600, 2147418112"
"  %1603 = and i32 %1600, 2147418112" -> "  %1604 = add nuw nsw i32 %1602, %1603"
"  %1604 = add nuw nsw i32 %1602, %1603"
"  %1604 = add nuw nsw i32 %1602, %1603" -> "  %1608 = lshr i32 %1604, 16""  %1604 = add nuw nsw i32 %1602, %1603" -> "  %1606 = and i32 %1604, 65535"
"  %1605 = mul nuw i32 %1198, 42170"
"  %1605 = mul nuw i32 %1198, 42170" -> "  %1607 = add nuw i32 %1606, %1605"
"  %1606 = and i32 %1604, 65535"
"  %1606 = and i32 %1604, 65535" -> "  %1607 = add nuw i32 %1606, %1605"
"  %1607 = add nuw i32 %1606, %1605"
"  %1607 = add nuw i32 %1606, %1605" -> "  %1619 = and i32 %1607, 65535""  %1607 = add nuw i32 %1606, %1605" -> "  %1611 = lshr i32 %1607, 16"
"  %1608 = lshr i32 %1604, 16"
"  %1608 = lshr i32 %1604, 16" -> "  %1610 = add nuw i32 %1608, %1609"
"  %1609 = mul nuw i32 %1201, 42170"
"  %1609 = mul nuw i32 %1201, 42170" -> "  %1610 = add nuw i32 %1608, %1609"
"  %1610 = add nuw i32 %1608, %1609"
"  %1610 = add nuw i32 %1608, %1609" -> "  %1614 = and i32 %1610, -65536""  %1610 = add nuw i32 %1608, %1609" -> "  %1612 = and i32 %1610, 65535"
"  %1611 = lshr i32 %1607, 16"
"  %1611 = lshr i32 %1607, 16" -> "  %1613 = add nuw nsw i32 %1611, %1612"
"  %1612 = and i32 %1610, 65535"
"  %1612 = and i32 %1610, 65535" -> "  %1613 = add nuw nsw i32 %1611, %1612"
"  %1613 = add nuw nsw i32 %1611, %1612"
"  %1613 = add nuw nsw i32 %1611, %1612" -> "  %1615 = add nuw i32 %1613, %1614"
"  %1614 = and i32 %1610, -65536"
"  %1614 = and i32 %1610, -65536" -> "  %1615 = add nuw i32 %1613, %1614"
"  %1615 = add nuw i32 %1613, %1614"
"  %1615 = add nuw i32 %1613, %1614" -> "  %1623 = add nuw i32 %1615, %1622"
"  %1616 = and i32 %1566, 65535"
"  %1616 = and i32 %1566, 65535" -> "  %1618 = add nuw nsw i32 %1616, %1617"
"  %1617 = and i32 %1598, 65528"
"  %1617 = and i32 %1598, 65528" -> "  %1618 = add nuw nsw i32 %1616, %1617"
"  %1618 = add nuw nsw i32 %1616, %1617"
"  %1618 = add nuw nsw i32 %1616, %1617" -> "  %1629 = and i32 %1618, 65535""  %1618 = add nuw nsw i32 %1616, %1617" -> "  %1625 = lshr i32 %1618, 16"
"  %1619 = and i32 %1607, 65535"
"  %1619 = and i32 %1607, 65535" -> "  %1621 = add nuw nsw i32 %1620, %1619"
"  %1620 = lshr i32 %1566, 16"
"  %1620 = lshr i32 %1566, 16" -> "  %1621 = add nuw nsw i32 %1620, %1619"
"  %1621 = add nuw nsw i32 %1620, %1619"
"  %1621 = add nuw nsw i32 %1620, %1619" -> "  %1624 = and i32 %1621, 65535""  %1621 = add nuw nsw i32 %1620, %1619" -> "  %1622 = lshr i32 %1621, 16"
"  %1622 = lshr i32 %1621, 16"
"  %1622 = lshr i32 %1621, 16" -> "  %1623 = add nuw i32 %1615, %1622"
"  %1623 = add nuw i32 %1615, %1622"
"  %1623 = add nuw i32 %1615, %1622" -> "  %1628 = add nuw i32 %1623, %1627"
"  %1624 = and i32 %1621, 65535"
"  %1624 = and i32 %1621, 65535" -> "  %1626 = add nuw nsw i32 %1624, %1625"
"  %1625 = lshr i32 %1618, 16"
"  %1625 = lshr i32 %1618, 16" -> "  %1626 = add nuw nsw i32 %1624, %1625"
"  %1626 = add nuw nsw i32 %1624, %1625"
"  %1626 = add nuw nsw i32 %1624, %1625" -> "  %1632 = and i32 %1626, 65535""  %1626 = add nuw nsw i32 %1624, %1625" -> "  %1627 = lshr i32 %1626, 16"
"  %1627 = lshr i32 %1626, 16"
"  %1627 = lshr i32 %1626, 16" -> "  %1628 = add nuw i32 %1623, %1627"
"  %1628 = add nuw i32 %1623, %1627"
"  %1628 = add nuw i32 %1623, %1627" -> "  %1641 = and i32 %1628, -65536""  %1628 = add nuw i32 %1623, %1627" -> "  %1639 = and i32 %1628, 65535"
"  %1629 = and i32 %1618, 65535"
"  %1629 = and i32 %1618, 65535" -> "  %1631 = add nuw nsw i32 %1630, %1629"
"  %1630 = and i32 %1597, 65535"
"  %1630 = and i32 %1597, 65535" -> "  %1631 = add nuw nsw i32 %1630, %1629"
"  %1631 = add nuw nsw i32 %1630, %1629"
"  %1631 = add nuw nsw i32 %1630, %1629" -> "  %1671 = and i32 %1631, 65535""  %1631 = add nuw nsw i32 %1630, %1629" -> "  %1635 = lshr i32 %1631, 16"
"  %1632 = and i32 %1626, 65535"
"  %1632 = and i32 %1626, 65535" -> "  %1634 = add nuw nsw i32 %1632, %1633"
"  %1633 = lshr i32 %1597, 16"
"  %1633 = lshr i32 %1597, 16" -> "  %1634 = add nuw nsw i32 %1632, %1633"
"  %1634 = add nuw nsw i32 %1632, %1633"
"  %1634 = add nuw nsw i32 %1632, %1633" -> "  %1638 = lshr i32 %1634, 16""  %1634 = add nuw nsw i32 %1632, %1633" -> "  %1636 = and i32 %1634, 65535"
"  %1635 = lshr i32 %1631, 16"
"  %1635 = lshr i32 %1631, 16" -> "  %1637 = add nuw nsw i32 %1636, %1635"
"  %1636 = and i32 %1634, 65535"
"  %1636 = and i32 %1634, 65535" -> "  %1637 = add nuw nsw i32 %1636, %1635"
"  %1637 = add nuw nsw i32 %1636, %1635"
"  %1637 = add nuw nsw i32 %1636, %1635" -> "  %1678 = and i32 %1637, 65535""  %1637 = add nuw nsw i32 %1636, %1635" -> "  %1643 = lshr i32 %1637, 16"
"  %1638 = lshr i32 %1634, 16"
"  %1638 = lshr i32 %1634, 16" -> "  %1640 = add nuw nsw i32 %1638, %1639"
"  %1639 = and i32 %1628, 65535"
"  %1639 = and i32 %1628, 65535" -> "  %1640 = add nuw nsw i32 %1638, %1639"
"  %1640 = add nuw nsw i32 %1638, %1639"
"  %1640 = add nuw nsw i32 %1638, %1639" -> "  %1642 = add nuw i32 %1640, %1641"
"  %1641 = and i32 %1628, -65536"
"  %1641 = and i32 %1628, -65536" -> "  %1642 = add nuw i32 %1640, %1641"
"  %1642 = add nuw i32 %1640, %1641"
"  %1642 = add nuw i32 %1640, %1641" -> "  %1644 = add nuw i32 %1642, %1643"
"  %1643 = lshr i32 %1637, 16"
"  %1643 = lshr i32 %1637, 16" -> "  %1644 = add nuw i32 %1642, %1643"
"  %1644 = add nuw i32 %1642, %1643"
"  %1644 = add nuw i32 %1642, %1643" -> "  %1682 = add nuw i32 %1644, %1681"
"  %1645 = and i32 %1518, 65535"
"  %1645 = and i32 %1518, 65535" -> "  %1647 = add nuw nsw i32 %1646, %1645"
"  %1646 = and i32 %1344, 65535"
"  %1646 = and i32 %1344, 65535" -> "  %1647 = add nuw nsw i32 %1646, %1645"
"  %1647 = add nuw nsw i32 %1646, %1645"
"  %1647 = add nuw nsw i32 %1646, %1645" -> "  %1683 = and i32 %1647, 65535""  %1647 = add nuw nsw i32 %1646, %1645" -> "  %1651 = lshr i32 %1647, 16"
"  %1648 = and i32 %1527, 65535"
"  %1648 = and i32 %1527, 65535" -> "  %1650 = add nuw nsw i32 %1649, %1648"
"  %1649 = and i32 %1347, 65535"
"  %1649 = and i32 %1347, 65535" -> "  %1650 = add nuw nsw i32 %1649, %1648"
"  %1650 = add nuw nsw i32 %1649, %1648"
"  %1650 = add nuw nsw i32 %1649, %1648" -> "  %1664 = lshr i32 %1650, 16""  %1650 = add nuw nsw i32 %1649, %1648" -> "  %1652 = and i32 %1650, 65535"
"  %1651 = lshr i32 %1647, 16"
"  %1651 = lshr i32 %1647, 16" -> "  %1653 = add nuw nsw i32 %1652, %1651"
"  %1652 = and i32 %1650, 65535"
"  %1652 = and i32 %1650, 65535" -> "  %1653 = add nuw nsw i32 %1652, %1651"
"  %1653 = add nuw nsw i32 %1652, %1651"
"  %1653 = add nuw nsw i32 %1652, %1651" -> "  %1686 = and i32 %1653, 65535""  %1653 = add nuw nsw i32 %1652, %1651" -> "  %1666 = lshr i32 %1653, 16"
"  %1654 = and i32 %1587, 65535"
"  %1654 = and i32 %1587, 65535" -> "  %1656 = add nuw nsw i32 %1655, %1654"
"  %1655 = and i32 %1349, 65535"
"  %1655 = and i32 %1349, 65535" -> "  %1656 = add nuw nsw i32 %1655, %1654"
"  %1656 = add nuw nsw i32 %1655, %1654"
"  %1656 = add nuw nsw i32 %1655, %1654" -> "  %1663 = and i32 %1656, 65535""  %1656 = add nuw nsw i32 %1655, %1654" -> "  %1660 = lshr i32 %1656, 16"
"  %1657 = and i32 %1595, 65535"
"  %1657 = and i32 %1595, 65535" -> "  %1659 = add nuw nsw i32 %1658, %1657"
"  %1658 = lshr i32 %1349, 16"
"  %1658 = lshr i32 %1349, 16" -> "  %1659 = add nuw nsw i32 %1658, %1657"
"  %1659 = add nuw nsw i32 %1658, %1657"
"  %1659 = add nuw nsw i32 %1658, %1657" -> "  %1672 = lshr i32 %1659, 16""  %1659 = add nuw nsw i32 %1658, %1657" -> "  %1661 = and i32 %1659, 65535"
"  %1660 = lshr i32 %1656, 16"
"  %1660 = lshr i32 %1656, 16" -> "  %1662 = add nuw nsw i32 %1660, %1661"
"  %1661 = and i32 %1659, 65535"
"  %1661 = and i32 %1659, 65535" -> "  %1662 = add nuw nsw i32 %1660, %1661"
"  %1662 = add nuw nsw i32 %1660, %1661"
"  %1662 = add nuw nsw i32 %1660, %1661" -> "  %1674 = lshr i32 %1662, 16""  %1662 = add nuw nsw i32 %1660, %1661" -> "  %1669 = and i32 %1662, 65535"
"  %1663 = and i32 %1656, 65535"
"  %1663 = and i32 %1656, 65535" -> "  %1665 = add nuw nsw i32 %1663, %1664"
"  %1664 = lshr i32 %1650, 16"
"  %1664 = lshr i32 %1650, 16" -> "  %1665 = add nuw nsw i32 %1663, %1664"
"  %1665 = add nuw nsw i32 %1663, %1664"
"  %1665 = add nuw nsw i32 %1663, %1664" -> "  %1667 = add nuw nsw i32 %1665, %1666"
"  %1666 = lshr i32 %1653, 16"
"  %1666 = lshr i32 %1653, 16" -> "  %1667 = add nuw nsw i32 %1665, %1666"
"  %1667 = add nuw nsw i32 %1665, %1666"
"  %1667 = add nuw nsw i32 %1665, %1666" -> "  %1695 = and i32 %1667, 65535""  %1667 = add nuw nsw i32 %1665, %1666" -> "  %1668 = lshr i32 %1667, 16"
"  %1668 = lshr i32 %1667, 16"
"  %1668 = lshr i32 %1667, 16" -> "  %1670 = add nuw nsw i32 %1668, %1669"
"  %1669 = and i32 %1662, 65535"
"  %1669 = and i32 %1662, 65535" -> "  %1670 = add nuw nsw i32 %1668, %1669"
"  %1670 = add nuw nsw i32 %1668, %1669"
"  %1670 = add nuw nsw i32 %1668, %1669" -> "  %1698 = and i32 %1670, 65535""  %1670 = add nuw nsw i32 %1668, %1669" -> "  %1676 = lshr i32 %1670, 16"
"  %1671 = and i32 %1631, 65535"
"  %1671 = and i32 %1631, 65535" -> "  %1673 = add nuw nsw i32 %1672, %1671"
"  %1672 = lshr i32 %1659, 16"
"  %1672 = lshr i32 %1659, 16" -> "  %1673 = add nuw nsw i32 %1672, %1671"
"  %1673 = add nuw nsw i32 %1672, %1671"
"  %1673 = add nuw nsw i32 %1672, %1671" -> "  %1675 = add nuw nsw i32 %1673, %1674"
"  %1674 = lshr i32 %1662, 16"
"  %1674 = lshr i32 %1662, 16" -> "  %1675 = add nuw nsw i32 %1673, %1674"
"  %1675 = add nuw nsw i32 %1673, %1674"
"  %1675 = add nuw nsw i32 %1673, %1674" -> "  %1677 = add nuw nsw i32 %1675, %1676"
"  %1676 = lshr i32 %1670, 16"
"  %1676 = lshr i32 %1670, 16" -> "  %1677 = add nuw nsw i32 %1675, %1676"
"  %1677 = add nuw nsw i32 %1675, %1676"
"  %1677 = add nuw nsw i32 %1675, %1676" -> "  %1712 = and i32 %1677, 65535""  %1677 = add nuw nsw i32 %1675, %1676" -> "  %1679 = lshr i32 %1677, 16"
"  %1678 = and i32 %1637, 65535"
"  %1678 = and i32 %1637, 65535" -> "  %1680 = add nuw nsw i32 %1679, %1678"
"  %1679 = lshr i32 %1677, 16"
"  %1679 = lshr i32 %1677, 16" -> "  %1680 = add nuw nsw i32 %1679, %1678"
"  %1680 = add nuw nsw i32 %1679, %1678"
"  %1680 = add nuw nsw i32 %1679, %1678" -> "  %1719 = and i32 %1680, 65535""  %1680 = add nuw nsw i32 %1679, %1678" -> "  %1681 = lshr i32 %1680, 16"
"  %1681 = lshr i32 %1680, 16"
"  %1681 = lshr i32 %1680, 16" -> "  %1682 = add nuw i32 %1644, %1681"
"  %1682 = add nuw i32 %1644, %1681"
"  %1682 = add nuw i32 %1644, %1681" -> "  %1723 = add nuw i32 %1682, %1722"
"  %1683 = and i32 %1647, 65535"
"  %1683 = and i32 %1647, 65535" -> "  %1685 = add nuw nsw i32 %1684, %1683"
"  %1684 = and i32 %1512, 65535"
"  %1684 = and i32 %1512, 65535" -> "  %1685 = add nuw nsw i32 %1684, %1683"
"  %1685 = add nuw nsw i32 %1684, %1683"
"  %1685 = add nuw nsw i32 %1684, %1683" -> "  %2428 = and i32 %1685, 65535""  %1685 = add nuw nsw i32 %1684, %1683" -> "  %1689 = lshr i32 %1685, 16"
"  %1686 = and i32 %1653, 65535"
"  %1686 = and i32 %1653, 65535" -> "  %1688 = add nuw nsw i32 %1687, %1686"
"  %1687 = and i32 %1515, 65535"
"  %1687 = and i32 %1515, 65535" -> "  %1688 = add nuw nsw i32 %1687, %1686"
"  %1688 = add nuw nsw i32 %1687, %1686"
"  %1688 = add nuw nsw i32 %1687, %1686" -> "  %1705 = lshr i32 %1688, 16""  %1688 = add nuw nsw i32 %1687, %1686" -> "  %1690 = and i32 %1688, 65535"
"  %1689 = lshr i32 %1685, 16"
"  %1689 = lshr i32 %1685, 16" -> "  %1691 = add nuw nsw i32 %1690, %1689"
"  %1690 = and i32 %1688, 65535"
"  %1690 = and i32 %1688, 65535" -> "  %1691 = add nuw nsw i32 %1690, %1689"
"  %1691 = add nuw nsw i32 %1690, %1689"
"  %1691 = add nuw nsw i32 %1690, %1689" -> "  %2431 = and i32 %1691, 65535""  %1691 = add nuw nsw i32 %1690, %1689" -> "  %1706 = lshr i32 %1691, 16"
"  %1692 = add i64 %18, -164"
"  %1692 = add i64 %18, -164" -> "  %1693 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1692"
"  %1693 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1692"
"  %1693 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1692" -> "  %1694 = bitcast i8* %1693 to i32*"
"  %1694 = bitcast i8* %1693 to i32*"
"  %1694 = bitcast i8* %1693 to i32*" -> "  store i32 %19431, i32* %1694, align 1, !noalias !59"
"  %1695 = and i32 %1667, 65535"
"  %1695 = and i32 %1667, 65535" -> "  %1697 = add nuw nsw i32 %1696, %1695"
"  %1696 = and i32 %1517, 65535"
"  %1696 = and i32 %1517, 65535" -> "  %1697 = add nuw nsw i32 %1696, %1695"
"  %1697 = add nuw nsw i32 %1696, %1695"
"  %1697 = add nuw nsw i32 %1696, %1695" -> "  %1704 = and i32 %1697, 65535""  %1697 = add nuw nsw i32 %1696, %1695" -> "  %1701 = lshr i32 %1697, 16"
"  %1698 = and i32 %1670, 65535"
"  %1698 = and i32 %1670, 65535" -> "  %1700 = add nuw nsw i32 %1698, %1699"
"  %1699 = lshr i32 %1517, 16"
"  %1699 = lshr i32 %1517, 16" -> "  %1700 = add nuw nsw i32 %1698, %1699"
"  %1700 = add nuw nsw i32 %1698, %1699"
"  %1700 = add nuw nsw i32 %1698, %1699" -> "  %1713 = lshr i32 %1700, 16""  %1700 = add nuw nsw i32 %1698, %1699" -> "  %1702 = and i32 %1700, 65535"
"  %1701 = lshr i32 %1697, 16"
"  %1701 = lshr i32 %1697, 16" -> "  %1703 = add nuw nsw i32 %1702, %1701"
"  %1702 = and i32 %1700, 65535"
"  %1702 = and i32 %1700, 65535" -> "  %1703 = add nuw nsw i32 %1702, %1701"
"  %1703 = add nuw nsw i32 %1702, %1701"
"  %1703 = add nuw nsw i32 %1702, %1701" -> "  %1715 = lshr i32 %1703, 16""  %1703 = add nuw nsw i32 %1702, %1701" -> "  %1710 = and i32 %1703, 65535"
"  %1704 = and i32 %1697, 65535"
"  %1704 = and i32 %1697, 65535" -> "  %1708 = add nuw nsw i32 %1707, %1704"
"  %1705 = lshr i32 %1688, 16"
"  %1705 = lshr i32 %1688, 16" -> "  %1707 = add nuw nsw i32 %1706, %1705"
"  %1706 = lshr i32 %1691, 16"
"  %1706 = lshr i32 %1691, 16" -> "  %1707 = add nuw nsw i32 %1706, %1705"
"  %1707 = add nuw nsw i32 %1706, %1705"
"  %1707 = add nuw nsw i32 %1706, %1705" -> "  %1708 = add nuw nsw i32 %1707, %1704"
"  %1708 = add nuw nsw i32 %1707, %1704"
"  %1708 = add nuw nsw i32 %1707, %1704" -> "  %2440 = and i32 %1708, 65535""  %1708 = add nuw nsw i32 %1707, %1704" -> "  %1709 = lshr i32 %1708, 16"
"  %1709 = lshr i32 %1708, 16"
"  %1709 = lshr i32 %1708, 16" -> "  %1711 = add nuw nsw i32 %1709, %1710"
"  %1710 = and i32 %1703, 65535"
"  %1710 = and i32 %1703, 65535" -> "  %1711 = add nuw nsw i32 %1709, %1710"
"  %1711 = add nuw nsw i32 %1709, %1710"
"  %1711 = add nuw nsw i32 %1709, %1710" -> "  %2443 = and i32 %1711, 65535""  %1711 = add nuw nsw i32 %1709, %1710" -> "  %1717 = lshr i32 %1711, 16"
"  %1712 = and i32 %1677, 65535"
"  %1712 = and i32 %1677, 65535" -> "  %1714 = add nuw nsw i32 %1713, %1712"
"  %1713 = lshr i32 %1700, 16"
"  %1713 = lshr i32 %1700, 16" -> "  %1714 = add nuw nsw i32 %1713, %1712"
"  %1714 = add nuw nsw i32 %1713, %1712"
"  %1714 = add nuw nsw i32 %1713, %1712" -> "  %1716 = add nuw nsw i32 %1714, %1715"
"  %1715 = lshr i32 %1703, 16"
"  %1715 = lshr i32 %1703, 16" -> "  %1716 = add nuw nsw i32 %1714, %1715"
"  %1716 = add nuw nsw i32 %1714, %1715"
"  %1716 = add nuw nsw i32 %1714, %1715" -> "  %1718 = add nuw nsw i32 %1716, %1717"
"  %1717 = lshr i32 %1711, 16"
"  %1717 = lshr i32 %1711, 16" -> "  %1718 = add nuw nsw i32 %1716, %1717"
"  %1718 = add nuw nsw i32 %1716, %1717"
"  %1718 = add nuw nsw i32 %1716, %1717" -> "  %2454 = and i32 %1718, 65535""  %1718 = add nuw nsw i32 %1716, %1717" -> "  %1720 = lshr i32 %1718, 16"
"  %1719 = and i32 %1680, 65535"
"  %1719 = and i32 %1680, 65535" -> "  %1721 = add nuw nsw i32 %1720, %1719"
"  %1720 = lshr i32 %1718, 16"
"  %1720 = lshr i32 %1718, 16" -> "  %1721 = add nuw nsw i32 %1720, %1719"
"  %1721 = add nuw nsw i32 %1720, %1719"
"  %1721 = add nuw nsw i32 %1720, %1719" -> "  %2457 = and i32 %1721, 65535""  %1721 = add nuw nsw i32 %1720, %1719" -> "  %1722 = lshr i32 %1721, 16"
"  %1722 = lshr i32 %1721, 16"
"  %1722 = lshr i32 %1721, 16" -> "  %1723 = add nuw i32 %1682, %1722"
"  %1723 = add nuw i32 %1682, %1722"
"  %1723 = add nuw i32 %1682, %1722" -> "  %2463 = and i32 %1723, 65535""  %1723 = add nuw i32 %1682, %1722" -> "  %2466 = lshr i32 %1723, 16"
"  %1724 = and i32 %1008, 65535"
"  %1724 = and i32 %1008, 65535" -> "  %1725 = mul nuw i32 %1724, 37996""  %1724 = and i32 %1008, 65535" -> "  %1793 = mul nuw i32 %1724, 62728""  %1724 = and i32 %1008, 65535" -> "  %1786 = mul nuw nsw i32 %1724, 1324""  %1724 = and i32 %1008, 65535" -> "  %1736 = mul nuw i32 %1724, 45147""  %1724 = and i32 %1008, 65535" -> "  %2110 = mul nuw i32 %1724, 42170""  %1724 = and i32 %1008, 65535" -> "  %2103 = mul nuw nsw i32 %1724, 31112""  %1724 = and i32 %1008, 65535" -> "  %2061 = mul nuw i32 %1724, 46547""  %1724 = and i32 %1008, 65535" -> "  %2051 = mul nuw nsw i32 %1724, 17857""  %1724 = and i32 %1008, 65535" -> "  %3580 = mul nuw nsw i32 %1724, 4087""  %1724 = and i32 %1008, 65535" -> "  %3587 = mul nuw nsw i32 %1724, 11561""  %1724 = and i32 %1008, 65535" -> "  %3629 = mul nuw nsw i32 %1724, 21884""  %1724 = and i32 %1008, 65535" -> "  %3636 = mul nuw i32 %1724, 36786""  %1724 = and i32 %1008, 65535" -> "  %3347 = mul nuw nsw i32 %1724, 29744""  %1724 = and i32 %1008, 65535" -> "  %3340 = mul nuw nsw i32 %1724, 24315""  %1724 = and i32 %1008, 65535" -> "  %3298 = mul nuw nsw i32 %1724, 9871""  %1724 = and i32 %1008, 65535" -> "  %3291 = mul nuw i32 %1724, 42779"
"  %1725 = mul nuw i32 %1724, 37996"
"  %1725 = mul nuw i32 %1724, 37996" -> "  %2429 = and i32 %1725, 65532""  %1725 = mul nuw i32 %1724, 37996" -> "  %1729 = lshr i32 %1725, 16"
"  %1726 = add i64 %18, -200"
"  %1726 = add i64 %18, -200" -> "  %1727 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1726"
"  %1727 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1726"
"  %1727 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1726" -> "  %1728 = bitcast i8* %1727 to i32*"
"  %1728 = bitcast i8* %1727 to i32*"
"  %1728 = bitcast i8* %1727 to i32*" -> "  store i32 %19499, i32* %1728, align 1, !noalias !62"
"  %1729 = lshr i32 %1725, 16"
"  %1729 = lshr i32 %1725, 16" -> "  %1733 = add nuw nsw i32 %1732, %1729"
"  %1730 = and i32 %1014, 65535"
"  %1730 = and i32 %1014, 65535" -> "  %1731 = mul nuw i32 %1730, 37996""  %1730 = and i32 %1014, 65535" -> "  %1797 = mul nuw i32 %1730, 62728""  %1730 = and i32 %1014, 65535" -> "  %1788 = mul nuw nsw i32 %1730, 1324""  %1730 = and i32 %1014, 65535" -> "  %1743 = mul nuw i32 %1730, 45147""  %1730 = and i32 %1014, 65535" -> "  %2114 = mul nuw i32 %1730, 42170""  %1730 = and i32 %1014, 65535" -> "  %2105 = mul nuw nsw i32 %1730, 31112""  %1730 = and i32 %1014, 65535" -> "  %2065 = mul nuw i32 %1730, 46547""  %1730 = and i32 %1014, 65535" -> "  %2056 = mul nuw nsw i32 %1730, 17857""  %1730 = and i32 %1014, 65535" -> "  %3582 = mul nuw nsw i32 %1730, 4087""  %1730 = and i32 %1014, 65535" -> "  %3591 = mul nuw nsw i32 %1730, 11561""  %1730 = and i32 %1014, 65535" -> "  %3631 = mul nuw nsw i32 %1730, 21884""  %1730 = and i32 %1014, 65535" -> "  %3640 = mul nuw i32 %1730, 36786""  %1730 = and i32 %1014, 65535" -> "  %3351 = mul nuw nsw i32 %1730, 29744""  %1730 = and i32 %1014, 65535" -> "  %3342 = mul nuw nsw i32 %1730, 24315""  %1730 = and i32 %1014, 65535" -> "  %3302 = mul nuw nsw i32 %1730, 9871""  %1730 = and i32 %1014, 65535" -> "  %3293 = mul nuw i32 %1730, 42779"
"  %1731 = mul nuw i32 %1730, 37996"
"  %1731 = mul nuw i32 %1730, 37996" -> "  %1734 = and i32 %1731, -65536""  %1731 = mul nuw i32 %1730, 37996" -> "  %1732 = and i32 %1731, 65532"
"  %1732 = and i32 %1731, 65532"
"  %1732 = and i32 %1731, 65532" -> "  %1733 = add nuw nsw i32 %1732, %1729"
"  %1733 = add nuw nsw i32 %1732, %1729"
"  %1733 = add nuw nsw i32 %1732, %1729" -> "  %1735 = add nuw i32 %1733, %1734"
"  %1734 = and i32 %1731, -65536"
"  %1734 = and i32 %1731, -65536" -> "  %1735 = add nuw i32 %1733, %1734"
"  %1735 = add nuw i32 %1733, %1734"
"  %1735 = add nuw i32 %1733, %1734" -> "  %1742 = lshr i32 %1735, 16""  %1735 = add nuw i32 %1733, %1734" -> "  %1737 = and i32 %1735, 65535"
"  %1736 = mul nuw i32 %1724, 45147"
"  %1736 = mul nuw i32 %1724, 45147" -> "  %1738 = add nuw i32 %1737, %1736"
"  %1737 = and i32 %1735, 65535"
"  %1737 = and i32 %1735, 65535" -> "  %1738 = add nuw i32 %1737, %1736"
"  %1738 = add nuw i32 %1737, %1736"
"  %1738 = add nuw i32 %1737, %1736" -> "  %2432 = and i32 %1738, 65535""  %1738 = add nuw i32 %1737, %1736" -> "  %1745 = lshr i32 %1738, 16"
"  %1739 = add i64 %18, -168"
"  %1739 = add i64 %18, -168" -> "  %1740 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1739"
"  %1740 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1739"
"  %1740 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1739" -> "  %1741 = bitcast i8* %1740 to i32*"
"  %1741 = bitcast i8* %1740 to i32*"
"  %1741 = bitcast i8* %1740 to i32*" -> "  store i32 %20060, i32* %1741, align 1, !noalias !71"
"  %1742 = lshr i32 %1735, 16"
"  %1742 = lshr i32 %1735, 16" -> "  %1744 = add nuw i32 %1742, %1743"
"  %1743 = mul nuw i32 %1730, 45147"
"  %1743 = mul nuw i32 %1730, 45147" -> "  %1744 = add nuw i32 %1742, %1743"
"  %1744 = add nuw i32 %1742, %1743"
"  %1744 = add nuw i32 %1742, %1743" -> "  %1748 = and i32 %1744, -65536""  %1744 = add nuw i32 %1742, %1743" -> "  %1746 = and i32 %1744, 65535"
"  %1745 = lshr i32 %1738, 16"
"  %1745 = lshr i32 %1738, 16" -> "  %1747 = add nuw nsw i32 %1746, %1745"
"  %1746 = and i32 %1744, 65535"
"  %1746 = and i32 %1744, 65535" -> "  %1747 = add nuw nsw i32 %1746, %1745"
"  %1747 = add nuw nsw i32 %1746, %1745"
"  %1747 = add nuw nsw i32 %1746, %1745" -> "  %1749 = add nuw i32 %1747, %1748"
"  %1748 = and i32 %1744, -65536"
"  %1748 = and i32 %1744, -65536" -> "  %1749 = add nuw i32 %1747, %1748"
"  %1749 = add nuw i32 %1747, %1748"
"  %1749 = add nuw i32 %1747, %1748" -> "  %1774 = lshr i32 %1749, 16""  %1749 = add nuw i32 %1747, %1748" -> "  %1770 = and i32 %1749, 65535"
"  %1750 = and i32 %1028, 65535"
"  %1750 = and i32 %1028, 65535" -> "  %2079 = mul nuw i32 %1750, 46547""  %1750 = and i32 %1028, 65535" -> "  %2072 = mul nuw nsw i32 %1750, 17857""  %1750 = and i32 %1028, 65535" -> "  %1752 = mul nuw i32 %1750, 37996""  %1750 = and i32 %1028, 65535" -> "  %1759 = mul nuw i32 %1750, 45147""  %1750 = and i32 %1028, 65535" -> "  %1823 = mul nuw nsw i32 %1750, 1324""  %1750 = and i32 %1028, 65535" -> "  %1830 = mul nuw i32 %1750, 62728""  %1750 = and i32 %1028, 65535" -> "  %2138 = mul nuw i32 %1750, 42170""  %1750 = and i32 %1028, 65535" -> "  %2134 = mul nuw nsw i32 %1750, 31112""  %1750 = and i32 %1028, 65535" -> "  %3598 = mul nuw nsw i32 %1750, 4087""  %1750 = and i32 %1028, 65535" -> "  %3605 = mul nuw nsw i32 %1750, 11561""  %1750 = and i32 %1028, 65535" -> "  %3660 = mul nuw nsw i32 %1750, 21884""  %1750 = and i32 %1028, 65535" -> "  %3667 = mul nuw i32 %1750, 36786""  %1750 = and i32 %1028, 65535" -> "  %3378 = mul nuw nsw i32 %1750, 29744""  %1750 = and i32 %1028, 65535" -> "  %3371 = mul nuw nsw i32 %1750, 24315""  %1750 = and i32 %1028, 65535" -> "  %3316 = mul nuw nsw i32 %1750, 9871""  %1750 = and i32 %1028, 65535" -> "  %3309 = mul nuw i32 %1750, 42779"
"  %1751 = and i32 %1031, 65535"
"  %1751 = and i32 %1031, 65535" -> "  %1754 = mul nuw i32 %1751, 37996""  %1751 = and i32 %1031, 65535" -> "  %1763 = mul nuw i32 %1751, 45147""  %1751 = and i32 %1031, 65535" -> "  %1825 = mul nuw nsw i32 %1751, 1324""  %1751 = and i32 %1031, 65535" -> "  %1834 = mul nuw i32 %1751, 62728""  %1751 = and i32 %1031, 65535" -> "  %2142 = mul nuw i32 %1751, 42170""  %1751 = and i32 %1031, 65535" -> "  %2136 = mul nuw nsw i32 %1751, 31112""  %1751 = and i32 %1031, 65535" -> "  %2083 = mul nuw i32 %1751, 46547""  %1751 = and i32 %1031, 65535" -> "  %2074 = mul nuw nsw i32 %1751, 17857""  %1751 = and i32 %1031, 65535" -> "  %3600 = mul nuw nsw i32 %1751, 4087""  %1751 = and i32 %1031, 65535" -> "  %3609 = mul nuw nsw i32 %1751, 11561""  %1751 = and i32 %1031, 65535" -> "  %3662 = mul nuw nsw i32 %1751, 21884""  %1751 = and i32 %1031, 65535" -> "  %3671 = mul nuw i32 %1751, 36786""  %1751 = and i32 %1031, 65535" -> "  %3382 = mul nuw nsw i32 %1751, 29744""  %1751 = and i32 %1031, 65535" -> "  %3373 = mul nuw nsw i32 %1751, 24315""  %1751 = and i32 %1031, 65535" -> "  %3320 = mul nuw nsw i32 %1751, 9871""  %1751 = and i32 %1031, 65535" -> "  %3311 = mul nuw i32 %1751, 42779"
"  %1752 = mul nuw i32 %1750, 37996"
"  %1752 = mul nuw i32 %1750, 37996" -> "  %1771 = and i32 %1752, 65532""  %1752 = mul nuw i32 %1750, 37996" -> "  %1753 = lshr i32 %1752, 16"
"  %1753 = lshr i32 %1752, 16"
"  %1753 = lshr i32 %1752, 16" -> "  %1756 = add nuw nsw i32 %1755, %1753"
"  %1754 = mul nuw i32 %1751, 37996"
"  %1754 = mul nuw i32 %1751, 37996" -> "  %1757 = and i32 %1754, -65536""  %1754 = mul nuw i32 %1751, 37996" -> "  %1755 = and i32 %1754, 65532"
"  %1755 = and i32 %1754, 65532"
"  %1755 = and i32 %1754, 65532" -> "  %1756 = add nuw nsw i32 %1755, %1753"
"  %1756 = add nuw nsw i32 %1755, %1753"
"  %1756 = add nuw nsw i32 %1755, %1753" -> "  %1758 = add nuw i32 %1756, %1757"
"  %1757 = and i32 %1754, -65536"
"  %1757 = and i32 %1754, -65536" -> "  %1758 = add nuw i32 %1756, %1757"
"  %1758 = add nuw i32 %1756, %1757"
"  %1758 = add nuw i32 %1756, %1757" -> "  %1762 = lshr i32 %1758, 16""  %1758 = add nuw i32 %1756, %1757" -> "  %1760 = and i32 %1758, 65535"
"  %1759 = mul nuw i32 %1750, 45147"
"  %1759 = mul nuw i32 %1750, 45147" -> "  %1761 = add nuw i32 %1760, %1759"
"  %1760 = and i32 %1758, 65535"
"  %1760 = and i32 %1758, 65535" -> "  %1761 = add nuw i32 %1760, %1759"
"  %1761 = add nuw i32 %1760, %1759"
"  %1761 = add nuw i32 %1760, %1759" -> "  %1773 = and i32 %1761, 65535""  %1761 = add nuw i32 %1760, %1759" -> "  %1765 = lshr i32 %1761, 16"
"  %1762 = lshr i32 %1758, 16"
"  %1762 = lshr i32 %1758, 16" -> "  %1764 = add nuw i32 %1762, %1763"
"  %1763 = mul nuw i32 %1751, 45147"
"  %1763 = mul nuw i32 %1751, 45147" -> "  %1764 = add nuw i32 %1762, %1763"
"  %1764 = add nuw i32 %1762, %1763"
"  %1764 = add nuw i32 %1762, %1763" -> "  %1768 = and i32 %1764, -65536""  %1764 = add nuw i32 %1762, %1763" -> "  %1766 = and i32 %1764, 65535"
"  %1765 = lshr i32 %1761, 16"
"  %1765 = lshr i32 %1761, 16" -> "  %1767 = add nuw nsw i32 %1765, %1766"
"  %1766 = and i32 %1764, 65535"
"  %1766 = and i32 %1764, 65535" -> "  %1767 = add nuw nsw i32 %1765, %1766"
"  %1767 = add nuw nsw i32 %1765, %1766"
"  %1767 = add nuw nsw i32 %1765, %1766" -> "  %1769 = add nuw i32 %1767, %1768"
"  %1768 = and i32 %1764, -65536"
"  %1768 = and i32 %1764, -65536" -> "  %1769 = add nuw i32 %1767, %1768"
"  %1769 = add nuw i32 %1767, %1768"
"  %1769 = add nuw i32 %1767, %1768" -> "  %1782 = and i32 %1769, -65536""  %1769 = add nuw i32 %1767, %1768" -> "  %1780 = and i32 %1769, 65535"
"  %1770 = and i32 %1749, 65535"
"  %1770 = and i32 %1749, 65535" -> "  %1772 = add nuw nsw i32 %1770, %1771"
"  %1771 = and i32 %1752, 65532"
"  %1771 = and i32 %1752, 65532" -> "  %1772 = add nuw nsw i32 %1770, %1771"
"  %1772 = add nuw nsw i32 %1770, %1771"
"  %1772 = add nuw nsw i32 %1770, %1771" -> "  %1804 = and i32 %1772, 65535""  %1772 = add nuw nsw i32 %1770, %1771" -> "  %1776 = lshr i32 %1772, 16"
"  %1773 = and i32 %1761, 65535"
"  %1773 = and i32 %1761, 65535" -> "  %1775 = add nuw nsw i32 %1773, %1774"
"  %1774 = lshr i32 %1749, 16"
"  %1774 = lshr i32 %1749, 16" -> "  %1775 = add nuw nsw i32 %1773, %1774"
"  %1775 = add nuw nsw i32 %1773, %1774"
"  %1775 = add nuw nsw i32 %1773, %1774" -> "  %1779 = lshr i32 %1775, 16""  %1775 = add nuw nsw i32 %1773, %1774" -> "  %1777 = and i32 %1775, 65535"
"  %1776 = lshr i32 %1772, 16"
"  %1776 = lshr i32 %1772, 16" -> "  %1778 = add nuw nsw i32 %1777, %1776"
"  %1777 = and i32 %1775, 65535"
"  %1777 = and i32 %1775, 65535" -> "  %1778 = add nuw nsw i32 %1777, %1776"
"  %1778 = add nuw nsw i32 %1777, %1776"
"  %1778 = add nuw nsw i32 %1777, %1776" -> "  %1810 = and i32 %1778, 65535""  %1778 = add nuw nsw i32 %1777, %1776" -> "  %1784 = lshr i32 %1778, 16"
"  %1779 = lshr i32 %1775, 16"
"  %1779 = lshr i32 %1775, 16" -> "  %1781 = add nuw nsw i32 %1780, %1779"
"  %1780 = and i32 %1769, 65535"
"  %1780 = and i32 %1769, 65535" -> "  %1781 = add nuw nsw i32 %1780, %1779"
"  %1781 = add nuw nsw i32 %1780, %1779"
"  %1781 = add nuw nsw i32 %1780, %1779" -> "  %1783 = add nuw i32 %1781, %1782"
"  %1782 = and i32 %1769, -65536"
"  %1782 = and i32 %1769, -65536" -> "  %1783 = add nuw i32 %1781, %1782"
"  %1783 = add nuw i32 %1781, %1782"
"  %1783 = add nuw i32 %1781, %1782" -> "  %1785 = add nuw i32 %1783, %1784"
"  %1784 = lshr i32 %1778, 16"
"  %1784 = lshr i32 %1778, 16" -> "  %1785 = add nuw i32 %1783, %1784"
"  %1785 = add nuw i32 %1783, %1784"
"  %1785 = add nuw i32 %1783, %1784" -> "  %1845 = lshr i32 %1785, 16""  %1785 = add nuw i32 %1783, %1784" -> "  %1841 = and i32 %1785, 65535"
"  %1786 = mul nuw nsw i32 %1724, 1324"
"  %1786 = mul nuw nsw i32 %1724, 1324" -> "  %1805 = and i32 %1786, 65532""  %1786 = mul nuw nsw i32 %1724, 1324" -> "  %1787 = lshr i32 %1786, 16"
"  %1787 = lshr i32 %1786, 16"
"  %1787 = lshr i32 %1786, 16" -> "  %1790 = add nuw nsw i32 %1789, %1787"
"  %1788 = mul nuw nsw i32 %1730, 1324"
"  %1788 = mul nuw nsw i32 %1730, 1324" -> "  %1791 = and i32 %1788, 134152192""  %1788 = mul nuw nsw i32 %1730, 1324" -> "  %1789 = and i32 %1788, 65532"
"  %1789 = and i32 %1788, 65532"
"  %1789 = and i32 %1788, 65532" -> "  %1790 = add nuw nsw i32 %1789, %1787"
"  %1790 = add nuw nsw i32 %1789, %1787"
"  %1790 = add nuw nsw i32 %1789, %1787" -> "  %1792 = add nuw nsw i32 %1790, %1791"
"  %1791 = and i32 %1788, 134152192"
"  %1791 = and i32 %1788, 134152192" -> "  %1792 = add nuw nsw i32 %1790, %1791"
"  %1792 = add nuw nsw i32 %1790, %1791"
"  %1792 = add nuw nsw i32 %1790, %1791" -> "  %1796 = lshr i32 %1792, 16""  %1792 = add nuw nsw i32 %1790, %1791" -> "  %1794 = and i32 %1792, 65535"
"  %1793 = mul nuw i32 %1724, 62728"
"  %1793 = mul nuw i32 %1724, 62728" -> "  %1795 = add nuw i32 %1794, %1793"
"  %1794 = and i32 %1792, 65535"
"  %1794 = and i32 %1792, 65535" -> "  %1795 = add nuw i32 %1794, %1793"
"  %1795 = add nuw i32 %1794, %1793"
"  %1795 = add nuw i32 %1794, %1793" -> "  %1811 = and i32 %1795, 65535""  %1795 = add nuw i32 %1794, %1793" -> "  %1799 = lshr i32 %1795, 16"
"  %1796 = lshr i32 %1792, 16"
"  %1796 = lshr i32 %1792, 16" -> "  %1798 = add nuw i32 %1796, %1797"
"  %1797 = mul nuw i32 %1730, 62728"
"  %1797 = mul nuw i32 %1730, 62728" -> "  %1798 = add nuw i32 %1796, %1797"
"  %1798 = add nuw i32 %1796, %1797"
"  %1798 = add nuw i32 %1796, %1797" -> "  %1802 = and i32 %1798, -65536""  %1798 = add nuw i32 %1796, %1797" -> "  %1800 = and i32 %1798, 65535"
"  %1799 = lshr i32 %1795, 16"
"  %1799 = lshr i32 %1795, 16" -> "  %1801 = add nuw nsw i32 %1799, %1800"
"  %1800 = and i32 %1798, 65535"
"  %1800 = and i32 %1798, 65535" -> "  %1801 = add nuw nsw i32 %1799, %1800"
"  %1801 = add nuw nsw i32 %1799, %1800"
"  %1801 = add nuw nsw i32 %1799, %1800" -> "  %1803 = add nuw i32 %1801, %1802"
"  %1802 = and i32 %1798, -65536"
"  %1802 = and i32 %1798, -65536" -> "  %1803 = add nuw i32 %1801, %1802"
"  %1803 = add nuw i32 %1801, %1802"
"  %1803 = add nuw i32 %1801, %1802" -> "  %1814 = add nuw i32 %1803, %1813"
"  %1804 = and i32 %1772, 65535"
"  %1804 = and i32 %1772, 65535" -> "  %1806 = add nuw nsw i32 %1804, %1805"
"  %1805 = and i32 %1786, 65532"
"  %1805 = and i32 %1786, 65532" -> "  %1806 = add nuw nsw i32 %1804, %1805"
"  %1806 = add nuw nsw i32 %1804, %1805"
"  %1806 = add nuw nsw i32 %1804, %1805" -> "  %2441 = and i32 %1806, 65535""  %1806 = add nuw nsw i32 %1804, %1805" -> "  %1816 = lshr i32 %1806, 16"
"  %1807 = add i64 %18, -172"
"  %1807 = add i64 %18, -172" -> "  %1808 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1807"
"  %1808 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1807"
"  %1808 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1807" -> "  %1809 = bitcast i8* %1808 to i32*"
"  %1809 = bitcast i8* %1808 to i32*"
"  %1809 = bitcast i8* %1808 to i32*" -> "  store i32 %19702, i32* %1809, align 1, !noalias !65"
"  %1810 = and i32 %1778, 65535"
"  %1810 = and i32 %1778, 65535" -> "  %1812 = add nuw nsw i32 %1810, %1811"
"  %1811 = and i32 %1795, 65535"
"  %1811 = and i32 %1795, 65535" -> "  %1812 = add nuw nsw i32 %1810, %1811"
"  %1812 = add nuw nsw i32 %1810, %1811"
"  %1812 = add nuw nsw i32 %1810, %1811" -> "  %1815 = and i32 %1812, 65535""  %1812 = add nuw nsw i32 %1810, %1811" -> "  %1813 = lshr i32 %1812, 16"
"  %1813 = lshr i32 %1812, 16"
"  %1813 = lshr i32 %1812, 16" -> "  %1814 = add nuw i32 %1803, %1813"
"  %1814 = add nuw i32 %1803, %1813"
"  %1814 = add nuw i32 %1803, %1813" -> "  %1822 = add nuw i32 %1814, %1821"
"  %1815 = and i32 %1812, 65535"
"  %1815 = and i32 %1812, 65535" -> "  %1817 = add nuw nsw i32 %1815, %1816"
"  %1816 = lshr i32 %1806, 16"
"  %1816 = lshr i32 %1806, 16" -> "  %1817 = add nuw nsw i32 %1815, %1816"
"  %1817 = add nuw nsw i32 %1815, %1816"
"  %1817 = add nuw nsw i32 %1815, %1816" -> "  %2444 = and i32 %1817, 65535""  %1817 = add nuw nsw i32 %1815, %1816" -> "  %1821 = lshr i32 %1817, 16"
"  %1818 = add i64 %18, -156"
"  %1818 = add i64 %18, -156" -> "  %1819 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1818"
"  %1819 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1818"
"  %1819 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1818" -> "  %1820 = bitcast i8* %1819 to i32*"
"  %1820 = bitcast i8* %1819 to i32*"
"  %1820 = bitcast i8* %1819 to i32*" -> "  store i32 %19705, i32* %1820, align 1, !noalias !65"
"  %1821 = lshr i32 %1817, 16"
"  %1821 = lshr i32 %1817, 16" -> "  %1822 = add nuw i32 %1814, %1821"
"  %1822 = add nuw i32 %1814, %1821"
"  %1822 = add nuw i32 %1814, %1821" -> "  %1861 = lshr i32 %1822, 16""  %1822 = add nuw i32 %1814, %1821" -> "  %1855 = and i32 %1822, 65535"
"  %1823 = mul nuw nsw i32 %1750, 1324"
"  %1823 = mul nuw nsw i32 %1750, 1324" -> "  %1842 = and i32 %1823, 65532""  %1823 = mul nuw nsw i32 %1750, 1324" -> "  %1824 = lshr i32 %1823, 16"
"  %1824 = lshr i32 %1823, 16"
"  %1824 = lshr i32 %1823, 16" -> "  %1827 = add nuw nsw i32 %1826, %1824"
"  %1825 = mul nuw nsw i32 %1751, 1324"
"  %1825 = mul nuw nsw i32 %1751, 1324" -> "  %1828 = and i32 %1825, 134152192""  %1825 = mul nuw nsw i32 %1751, 1324" -> "  %1826 = and i32 %1825, 65532"
"  %1826 = and i32 %1825, 65532"
"  %1826 = and i32 %1825, 65532" -> "  %1827 = add nuw nsw i32 %1826, %1824"
"  %1827 = add nuw nsw i32 %1826, %1824"
"  %1827 = add nuw nsw i32 %1826, %1824" -> "  %1829 = add nuw nsw i32 %1827, %1828"
"  %1828 = and i32 %1825, 134152192"
"  %1828 = and i32 %1825, 134152192" -> "  %1829 = add nuw nsw i32 %1827, %1828"
"  %1829 = add nuw nsw i32 %1827, %1828"
"  %1829 = add nuw nsw i32 %1827, %1828" -> "  %1833 = lshr i32 %1829, 16""  %1829 = add nuw nsw i32 %1827, %1828" -> "  %1831 = and i32 %1829, 65535"
"  %1830 = mul nuw i32 %1750, 62728"
"  %1830 = mul nuw i32 %1750, 62728" -> "  %1832 = add nuw i32 %1831, %1830"
"  %1831 = and i32 %1829, 65535"
"  %1831 = and i32 %1829, 65535" -> "  %1832 = add nuw i32 %1831, %1830"
"  %1832 = add nuw i32 %1831, %1830"
"  %1832 = add nuw i32 %1831, %1830" -> "  %1844 = and i32 %1832, 65535""  %1832 = add nuw i32 %1831, %1830" -> "  %1836 = lshr i32 %1832, 16"
"  %1833 = lshr i32 %1829, 16"
"  %1833 = lshr i32 %1829, 16" -> "  %1835 = add nuw i32 %1833, %1834"
"  %1834 = mul nuw i32 %1751, 62728"
"  %1834 = mul nuw i32 %1751, 62728" -> "  %1835 = add nuw i32 %1833, %1834"
"  %1835 = add nuw i32 %1833, %1834"
"  %1835 = add nuw i32 %1833, %1834" -> "  %1839 = and i32 %1835, -65536""  %1835 = add nuw i32 %1833, %1834" -> "  %1837 = and i32 %1835, 65535"
"  %1836 = lshr i32 %1832, 16"
"  %1836 = lshr i32 %1832, 16" -> "  %1838 = add nuw nsw i32 %1836, %1837"
"  %1837 = and i32 %1835, 65535"
"  %1837 = and i32 %1835, 65535" -> "  %1838 = add nuw nsw i32 %1836, %1837"
"  %1838 = add nuw nsw i32 %1836, %1837"
"  %1838 = add nuw nsw i32 %1836, %1837" -> "  %1840 = add nuw i32 %1838, %1839"
"  %1839 = and i32 %1835, -65536"
"  %1839 = and i32 %1835, -65536" -> "  %1840 = add nuw i32 %1838, %1839"
"  %1840 = add nuw i32 %1838, %1839"
"  %1840 = add nuw i32 %1838, %1839" -> "  %1848 = add nuw i32 %1840, %1847"
"  %1841 = and i32 %1785, 65535"
"  %1841 = and i32 %1785, 65535" -> "  %1843 = add nuw nsw i32 %1841, %1842"
"  %1842 = and i32 %1823, 65532"
"  %1842 = and i32 %1823, 65532" -> "  %1843 = add nuw nsw i32 %1841, %1842"
"  %1843 = add nuw nsw i32 %1841, %1842"
"  %1843 = add nuw nsw i32 %1841, %1842" -> "  %1854 = and i32 %1843, 65535""  %1843 = add nuw nsw i32 %1841, %1842" -> "  %1850 = lshr i32 %1843, 16"
"  %1844 = and i32 %1832, 65535"
"  %1844 = and i32 %1832, 65535" -> "  %1846 = add nuw nsw i32 %1845, %1844"
"  %1845 = lshr i32 %1785, 16"
"  %1845 = lshr i32 %1785, 16" -> "  %1846 = add nuw nsw i32 %1845, %1844"
"  %1846 = add nuw nsw i32 %1845, %1844"
"  %1846 = add nuw nsw i32 %1845, %1844" -> "  %1849 = and i32 %1846, 65535""  %1846 = add nuw nsw i32 %1845, %1844" -> "  %1847 = lshr i32 %1846, 16"
"  %1847 = lshr i32 %1846, 16"
"  %1847 = lshr i32 %1846, 16" -> "  %1848 = add nuw i32 %1840, %1847"
"  %1848 = add nuw i32 %1840, %1847"
"  %1848 = add nuw i32 %1840, %1847" -> "  %1853 = add nuw i32 %1848, %1852"
"  %1849 = and i32 %1846, 65535"
"  %1849 = and i32 %1846, 65535" -> "  %1851 = add nuw nsw i32 %1850, %1849"
"  %1850 = lshr i32 %1843, 16"
"  %1850 = lshr i32 %1843, 16" -> "  %1851 = add nuw nsw i32 %1850, %1849"
"  %1851 = add nuw nsw i32 %1850, %1849"
"  %1851 = add nuw nsw i32 %1850, %1849" -> "  %1860 = and i32 %1851, 65535""  %1851 = add nuw nsw i32 %1850, %1849" -> "  %1852 = lshr i32 %1851, 16"
"  %1852 = lshr i32 %1851, 16"
"  %1852 = lshr i32 %1851, 16" -> "  %1853 = add nuw i32 %1848, %1852"
"  %1853 = add nuw i32 %1848, %1852"
"  %1853 = add nuw i32 %1848, %1852" -> "  %1869 = and i32 %1853, -65536""  %1853 = add nuw i32 %1848, %1852" -> "  %1867 = and i32 %1853, 65535"
"  %1854 = and i32 %1843, 65535"
"  %1854 = and i32 %1843, 65535" -> "  %1856 = add nuw nsw i32 %1855, %1854"
"  %1855 = and i32 %1822, 65535"
"  %1855 = and i32 %1822, 65535" -> "  %1856 = add nuw nsw i32 %1855, %1854"
"  %1856 = add nuw nsw i32 %1855, %1854"
"  %1856 = add nuw nsw i32 %1855, %1854" -> "  %2005 = and i32 %1856, 65535""  %1856 = add nuw nsw i32 %1855, %1854" -> "  %1863 = lshr i32 %1856, 16"
"  %1857 = add i64 %18, -244"
"  %1857 = add i64 %18, -244" -> "  %1858 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1857"
"  %1858 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1857"
"  %1858 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1857" -> "  %1859 = bitcast i8* %1858 to i32*"
"  %1859 = bitcast i8* %1858 to i32*"
"  %1859 = bitcast i8* %1858 to i32*" -> "  store i32 %19491, i32* %1859, align 1, !noalias !62"
"  %1860 = and i32 %1851, 65535"
"  %1860 = and i32 %1851, 65535" -> "  %1862 = add nuw nsw i32 %1860, %1861"
"  %1861 = lshr i32 %1822, 16"
"  %1861 = lshr i32 %1822, 16" -> "  %1862 = add nuw nsw i32 %1860, %1861"
"  %1862 = add nuw nsw i32 %1860, %1861"
"  %1862 = add nuw nsw i32 %1860, %1861" -> "  %1866 = lshr i32 %1862, 16""  %1862 = add nuw nsw i32 %1860, %1861" -> "  %1864 = and i32 %1862, 65535"
"  %1863 = lshr i32 %1856, 16"
"  %1863 = lshr i32 %1856, 16" -> "  %1865 = add nuw nsw i32 %1864, %1863"
"  %1864 = and i32 %1862, 65535"
"  %1864 = and i32 %1862, 65535" -> "  %1865 = add nuw nsw i32 %1864, %1863"
"  %1865 = add nuw nsw i32 %1864, %1863"
"  %1865 = add nuw nsw i32 %1864, %1863" -> "  %2011 = and i32 %1865, 65535""  %1865 = add nuw nsw i32 %1864, %1863" -> "  %1871 = lshr i32 %1865, 16"
"  %1866 = lshr i32 %1862, 16"
"  %1866 = lshr i32 %1862, 16" -> "  %1868 = add nuw nsw i32 %1866, %1867"
"  %1867 = and i32 %1853, 65535"
"  %1867 = and i32 %1853, 65535" -> "  %1868 = add nuw nsw i32 %1866, %1867"
"  %1868 = add nuw nsw i32 %1866, %1867"
"  %1868 = add nuw nsw i32 %1866, %1867" -> "  %1870 = add nuw i32 %1868, %1869"
"  %1869 = and i32 %1853, -65536"
"  %1869 = and i32 %1853, -65536" -> "  %1870 = add nuw i32 %1868, %1869"
"  %1870 = add nuw i32 %1868, %1869"
"  %1870 = add nuw i32 %1868, %1869" -> "  %1872 = add nuw i32 %1870, %1871"
"  %1871 = lshr i32 %1865, 16"
"  %1871 = lshr i32 %1865, 16" -> "  %1872 = add nuw i32 %1870, %1871"
"  %1872 = add nuw i32 %1870, %1871"
"  %1872 = add nuw i32 %1870, %1871" -> "  %2020 = and i32 %1872, 65535""  %1872 = add nuw i32 %1870, %1871" -> "  %2023 = lshr i32 %1872, 16"
"  %1873 = and i32 %1038, 65535"
"  %1873 = and i32 %1038, 65535" -> "  %1874 = mul nuw i32 %1873, 37996""  %1873 = and i32 %1038, 65535" -> "  %1885 = mul nuw i32 %1873, 45147""  %1873 = and i32 %1038, 65535" -> "  %2222 = mul nuw nsw i32 %1873, 17857""  %1873 = and i32 %1038, 65535" -> "  %2229 = mul nuw i32 %1873, 46547""  %1873 = and i32 %1038, 65535" -> "  %1933 = mul nuw i32 %1873, 62728""  %1873 = and i32 %1038, 65535" -> "  %1926 = mul nuw nsw i32 %1873, 1324""  %1873 = and i32 %1038, 65535" -> "  %2268 = mul nuw nsw i32 %1873, 31112""  %1873 = and i32 %1038, 65535" -> "  %2275 = mul nuw i32 %1873, 42170""  %1873 = and i32 %1038, 65535" -> "  %3745 = mul nuw nsw i32 %1873, 4087""  %1873 = and i32 %1038, 65535" -> "  %3752 = mul nuw nsw i32 %1873, 11561""  %1873 = and i32 %1038, 65535" -> "  %3794 = mul nuw nsw i32 %1873, 21884""  %1873 = and i32 %1038, 65535" -> "  %3801 = mul nuw i32 %1873, 36786""  %1873 = and i32 %1038, 65535" -> "  %3471 = mul nuw nsw i32 %1873, 29744""  %1873 = and i32 %1038, 65535" -> "  %3464 = mul nuw nsw i32 %1873, 24315""  %1873 = and i32 %1038, 65535" -> "  %3422 = mul nuw nsw i32 %1873, 9871""  %1873 = and i32 %1038, 65535" -> "  %3415 = mul nuw i32 %1873, 42779"
"  %1874 = mul nuw i32 %1873, 37996"
"  %1874 = mul nuw i32 %1873, 37996" -> "  %2004 = and i32 %1874, 65532""  %1874 = mul nuw i32 %1873, 37996" -> "  %1878 = lshr i32 %1874, 16"
"  %1875 = add i64 %18, -220"
"  %1875 = add i64 %18, -220" -> "  %1876 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1875"
"  %1876 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1875"
"  %1876 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %1875" -> "  %1877 = bitcast i8* %1876 to i32*"
"  %1877 = bitcast i8* %1876 to i32*"
"  %1877 = bitcast i8* %1876 to i32*" -> "  store i32 %19872, i32* %1877, align 1, !noalias !68"
"  %1878 = lshr i32 %1874, 16"
"  %1878 = lshr i32 %1874, 16" -> "  %1882 = add nuw nsw i32 %1881, %1878"
"  %1879 = and i32 %1041, 65535"
"  %1879 = and i32 %1041, 65535" -> "  %1880 = mul nuw i32 %1879, 37996""  %1879 = and i32 %1041, 65535" -> "  %1889 = mul nuw i32 %1879, 45147""  %1879 = and i32 %1041, 65535" -> "  %2224 = mul nuw nsw i32 %1879, 17857""  %1879 = and i32 %1041, 65535" -> "  %2233 = mul nuw i32 %1879, 46547""  %1879 = and i32 %1041, 65535" -> "  %1937 = mul nuw i32 %1879, 62728""  %1879 = and i32 %1041, 65535" -> "  %1928 = mul nuw nsw i32 %1879, 1324""  %1879 = and i32 %1041, 65535" -> "  %2270 = mul nuw nsw i32 %1879, 31112""  %1879 = and i32 %1041, 65535" -> "  %2279 = mul nuw i32 %1879, 42170""  %1879 = and i32 %1041, 65535" -> "  %3747 = mul nuw nsw i32 %1879, 4087""  %1879 = and i32 %1041, 65535" -> "  %3756 = mul nuw nsw i32 %1879, 11561""  %1879 = and i32 %1041, 65535" -> "  %3796 = mul nuw nsw i32 %1879, 21884""  %1879 = and i32 %1041, 65535" -> "  %3805 = mul nuw i32 %1879, 36786""  %1879 = and i32 %1041, 65535" -> "  %3475 = mul nuw nsw i32 %1879, 29744""  %1879 = and i32 %1041, 65535" -> "  %3466 = mul nuw nsw i32 %1879, 24315""  %1879 = and i32 %1041, 65535" -> "  %3426 = mul nuw nsw i32 %1879, 9871""  %1879 = and i32 %1041, 65535" -> "  %3417 = mul nuw i32 %1879, 42779"
"  %1880 = mul nuw i32 %1879, 37996"
"  %1880 = mul nuw i32 %1879, 37996" -> "  %1883 = and i32 %1880, -65536""  %1880 = mul nuw i32 %1879, 37996" -> "  %1881 = and i32 %1880, 65532"
"  %1881 = and i32 %1880, 65532"
"  %1881 = and i32 %1880, 65532" -> "  %1882 = add nuw nsw i32 %1881, %1878"
"  %1882 = add nuw nsw i32 %1881, %1878"
"  %1882 = add nuw nsw i32 %1881, %1878" -> "  %1884 = add nuw i32 %1882, %1883"
"  %1883 = and i32 %1880, -65536"
"  %1883 = and i32 %1880, -65536" -> "  %1884 = add nuw i32 %1882, %1883"
"  %1884 = add nuw i32 %1882, %1883"
"  %1884 = add nuw i32 %1882, %1883" -> "  %1888 = lshr i32 %1884, 16""  %1884 = add nuw i32 %1882, %1883" -> "  %1886 = and i32 %1884, 65535"
"  %1885 = mul nuw i32 %1873, 45147"
"  %1885 = mul nuw i32 %1873, 45147" -> "  %1887 = add nuw i32 %1886, %1885"
"  %1886 = and i32 %1884, 65535"
"  %1886 = and i32 %1884, 65535" -> "  %1887 = add nuw i32 %1886, %1885"
"  %1887 = add nuw i32 %1886, %1885"
"  %1887 = add nuw i32 %1886, %1885" -> "  %2010 = and i32 %1887, 65535""  %1887 = add nuw i32 %1886, %1885" -> "  %1891 = lshr i32 %1887, 16"
"  %1888 = lshr i32 %1884, 16"
"  %1888 = lshr i32 %1884, 16" -> "  %1890 = add nuw i32 %1888, %1889"
"  %1889 = mul nuw i32 %1879, 45147"
"  %1889 = mul nuw i32 %1879, 45147" -> "  %1890 = add nuw i32 %1888, %1889"
"  %1890 = add nuw i32 %1888, %1889"
"  %1890 = add nuw i32 %1888, %1889" -> "  %1894 = and i32 %1890, -65536""  %1890 = add nuw i32 %1888, %1889" -> "  %1892 = and i32 %1890, 65535"
"  %1891 = lshr i32 %1887, 16"
"  %1891 = lshr i32 %1887, 16" -> "  %1893 = add nuw nsw i32 %1891, %1892"
"  %1892 = and i32 %1890, 65535"
"  %1892 = and i32 %1890, 65535" -> "  %1893 = add nuw nsw i32 %1891, %1892"
"  %1893 = add nuw nsw i32 %1891, %1892"
"  %1893 = add nuw nsw i32 %1891, %1892" -> "  %1895 = add nuw i32 %1893, %1894"
"  %1894 = and i32 %1890, -65536"
"  %1894 = and i32 %1890, -65536" -> "  %1895 = add nuw i32 %1893, %1894"
"  %1895 = add nuw i32 %1893, %1894"
"  %1895 = add nuw i32 %1893, %1894" -> "  %1913 = and i32 %1895, 65535""  %1895 = add nuw i32 %1893, %1894" -> "  %1916 = lshr i32 %1895, 16"
"  %1896 = and i32 %1043, 65535"
"  %1896 = and i32 %1043, 65535" -> "  %2244 = mul nuw i32 %1896, 46547""  %1896 = and i32 %1043, 65535" -> "  %2240 = mul nuw nsw i32 %1896, 17857""  %1896 = and i32 %1043, 65535" -> "  %1898 = mul nuw i32 %1896, 37996""  %1896 = and i32 %1043, 65535" -> "  %3433 = mul nuw i32 %1896, 42779""  %1896 = and i32 %1043, 65535" -> "  %3440 = mul nuw nsw i32 %1896, 9871""  %1896 = and i32 %1043, 65535" -> "  %3495 = mul nuw nsw i32 %1896, 24315""  %1896 = and i32 %1043, 65535" -> "  %3502 = mul nuw nsw i32 %1896, 29744""  %1896 = and i32 %1043, 65535" -> "  %3832 = mul nuw i32 %1896, 36786""  %1896 = and i32 %1043, 65535" -> "  %3825 = mul nuw nsw i32 %1896, 21884""  %1896 = and i32 %1043, 65535" -> "  %3770 = mul nuw nsw i32 %1896, 11561""  %1896 = and i32 %1043, 65535" -> "  %3763 = mul nuw nsw i32 %1896, 4087""  %1896 = and i32 %1043, 65535" -> "  %1964 = mul nuw i32 %1896, 62728""  %1896 = and i32 %1043, 65535" -> "  %1957 = mul nuw nsw i32 %1896, 1324""  %1896 = and i32 %1043, 65535" -> "  %2299 = mul nuw nsw i32 %1896, 31112""  %1896 = and i32 %1043, 65535" -> "  %2306 = mul nuw i32 %1896, 42170""  %1896 = and i32 %1043, 65535" -> "  %1902 = mul nuw i32 %1896, 45147"
"  %1897 = lshr i32 %1043, 16"
"  %1897 = lshr i32 %1043, 16" -> "  %3435 = mul nuw i32 %1897, 42779""  %1897 = lshr i32 %1043, 16" -> "  %3444 = mul nuw nsw i32 %1897, 9871""  %1897 = lshr i32 %1043, 16" -> "  %3497 = mul nuw nsw i32 %1897, 24315""  %1897 = lshr i32 %1043, 16" -> "  %3506 = mul nuw nsw i32 %1897, 29744""  %1897 = lshr i32 %1043, 16" -> "  %3836 = mul nuw i32 %1897, 36786""  %1897 = lshr i32 %1043, 16" -> "  %3827 = mul nuw nsw i32 %1897, 21884""  %1897 = lshr i32 %1043, 16" -> "  %3774 = mul nuw nsw i32 %1897, 11561""  %1897 = lshr i32 %1043, 16" -> "  %3765 = mul nuw nsw i32 %1897, 4087""  %1897 = lshr i32 %1043, 16" -> "  %2301 = mul nuw nsw i32 %1897, 31112""  %1897 = lshr i32 %1043, 16" -> "  %2310 = mul nuw i32 %1897, 42170""  %1897 = lshr i32 %1043, 16" -> "  %2242 = mul nuw nsw i32 %1897, 17857""  %1897 = lshr i32 %1043, 16" -> "  %1968 = mul nuw i32 %1897, 62728""  %1897 = lshr i32 %1043, 16" -> "  %1959 = mul nuw nsw i32 %1897, 1324""  %1897 = lshr i32 %1043, 16" -> "  %2248 = mul nuw i32 %1897, 46547""  %1897 = lshr i32 %1043, 16" -> "  %1906 = mul nuw i32 %1897, 45147""  %1897 = lshr i32 %1043, 16" -> "  %1900 = mul nuw i32 %1897, 37996"
"  %1898 = mul nuw i32 %1896, 37996"
"  %1898 = mul nuw i32 %1896, 37996" -> "  %1899 = lshr i32 %1898, 16""  %1898 = mul nuw i32 %1896, 37996" -> "  %1914 = and i32 %1898, 65532"
"  %1899 = lshr i32 %1898, 16"
"  %1899 = lshr i32 %1898, 16" -> "  %1901 = add nuw i32 %1899, %1900"
"  %1900 = mul nuw i32 %1897, 37996"
"  %1900 = mul nuw i32 %1897, 37996" -> "  %1901 = add nuw i32 %1899, %1900"
"  %1901 = add nuw i32 %1899, %1900"
"  %1901 = add nuw i32 %1899, %1900" -> "  %1905 = lshr i32 %1901, 16""  %1901 = add nuw i32 %1899, %1900" -> "  %1903 = and i32 %1901, 65535"
"  %1902 = mul nuw i32 %1896, 45147"
"  %1902 = mul nuw i32 %1896, 45147" -> "  %1904 = add nuw i32 %1903, %1902"
"  %1903 = and i32 %1901, 65535"
"  %1903 = and i32 %1901, 65535" -> "  %1904 = add nuw i32 %1903, %1902"
"  %1904 = add nuw i32 %1903, %1902"
"  %1904 = add nuw i32 %1903, %1902" -> "  %1917 = and i32 %1904, 65535""  %1904 = add nuw i32 %1903, %1902" -> "  %1908 = lshr i32 %1904, 16"
"  %1905 = lshr i32 %1901, 16"
"  %1905 = lshr i32 %1901, 16" -> "  %1907 = add nuw i32 %1905, %1906"
"  %1906 = mul nuw i32 %1897, 45147"
"  %1906 = mul nuw i32 %1897, 45147" -> "  %1907 = add nuw i32 %1905, %1906"
"  %1907 = add nuw i32 %1905, %1906"
"  %1907 = add nuw i32 %1905, %1906" -> "  %1911 = and i32 %1907, -65536""  %1907 = add nuw i32 %1905, %1906" -> "  %1909 = and i32 %1907, 65535"
"  %1908 = lshr i32 %1904, 16"
"  %1908 = lshr i32 %1904, 16" -> "  %1910 = add nuw nsw i32 %1908, %1909"
"  %1909 = and i32 %1907, 65535"
"  %1909 = and i32 %1907, 65535" -> "  %1910 = add nuw nsw i32 %1908, %1909"
"  %1910 = add nuw nsw i32 %1908, %1909"
"  %1910 = add nuw nsw i32 %1908, %1909" -> "  %1912 = add nuw i32 %1910, %1911"
"  %1911 = and i32 %1907, -65536"
"  %1911 = and i32 %1907, -65536" -> "  %1912 = add nuw i32 %1910, %1911"
"  %1912 = add nuw i32 %1910, %1911"
"  %1912 = add nuw i32 %1910, %1911" -> "  %1924 = add nuw i32 %1912, %1922"
"  %1913 = and i32 %1895, 65535"
"  %1913 = and i32 %1895, 65535" -> "  %1915 = add nuw nsw i32 %1913, %1914"
"  %1914 = and i32 %1898, 65532"
"  %1914 = and i32 %1898, 65532" -> "  %1915 = add nuw nsw i32 %1913, %1914"
"  %1915 = add nuw nsw i32 %1913, %1914"
"  %1915 = add nuw nsw i32 %1913, %1914" -> "  %1944 = and i32 %1915, 65535""  %1915 = add nuw nsw i32 %1913, %1914" -> "  %1919 = lshr i32 %1915, 16"
"  %1916 = lshr i32 %1895, 16"
"  %1916 = lshr i32 %1895, 16" -> "  %1918 = add nuw nsw i32 %1916, %1917"
"  %1917 = and i32 %1904, 65535"
"  %1917 = and i32 %1904, 65535" -> "  %1918 = add nuw nsw i32 %1916, %1917"
"  %1918 = add nuw nsw i32 %1916, %1917"
"  %1918 = add nuw nsw i32 %1916, %1917" -> "  %1922 = lshr i32 %1918, 16""  %1918 = add nuw nsw i32 %1916, %1917" -> "  %1920 = and i32 %1918, 65535"
"  %1919 = lshr i32 %1915, 16"
"  %1919 = lshr i32 %1915, 16" -> "  %1921 = add nuw nsw i32 %1920, %1919"
"  %1920 = and i32 %1918, 65535"
"  %1920 = and i32 %1918, 65535" -> "  %1921 = add nuw nsw i32 %1920, %1919"
"  %1921 = add nuw nsw i32 %1920, %1919"
"  %1921 = add nuw nsw i32 %1920, %1919" -> "  %1947 = and i32 %1921, 65535""  %1921 = add nuw nsw i32 %1920, %1919" -> "  %1923 = lshr i32 %1921, 16"
"  %1922 = lshr i32 %1918, 16"
"  %1922 = lshr i32 %1918, 16" -> "  %1924 = add nuw i32 %1912, %1922"
"  %1923 = lshr i32 %1921, 16"
"  %1923 = lshr i32 %1921, 16" -> "  %1925 = add nuw i32 %1924, %1923"
"  %1924 = add nuw i32 %1912, %1922"
"  %1924 = add nuw i32 %1912, %1922" -> "  %1925 = add nuw i32 %1924, %1923"
"  %1925 = add nuw i32 %1924, %1923"
"  %1925 = add nuw i32 %1924, %1923" -> "  %1979 = lshr i32 %1925, 16""  %1925 = add nuw i32 %1924, %1923" -> "  %1975 = and i32 %1925, 65535"
"  %1926 = mul nuw nsw i32 %1873, 1324"
"  %1926 = mul nuw nsw i32 %1873, 1324" -> "  %1945 = and i32 %1926, 65532""  %1926 = mul nuw nsw i32 %1873, 1324" -> "  %1927 = lshr i32 %1926, 16"
"  %1927 = lshr i32 %1926, 16"
"  %1927 = lshr i32 %1926, 16" -> "  %1930 = add nuw nsw i32 %1929, %1927"
"  %1928 = mul nuw nsw i32 %1879, 1324"
"  %1928 = mul nuw nsw i32 %1879, 1324" -> "  %1931 = and i32 %1928, 134152192""  %1928 = mul nuw nsw i32 %1879, 1324" -> "  %1929 = and i32 %1928, 65532"
"  %1929 = and i32 %1928, 65532"
"  %1929 = and i32 %1928, 65532" -> "  %1930 = add nuw nsw i32 %1929, %1927"
"  %1930 = add nuw nsw i32 %1929, %1927"
"  %1930 = add nuw nsw i32 %1929, %1927" -> "  %1932 = add nuw nsw i32 %1930, %1931"
"  %1931 = and i32 %1928, 134152192"
"  %1931 = and i32 %1928, 134152192" -> "  %1932 = add nuw nsw i32 %1930, %1931"
"  %1932 = add nuw nsw i32 %1930, %1931"
"  %1932 = add nuw nsw i32 %1930, %1931" -> "  %1936 = lshr i32 %1932, 16""  %1932 = add nuw nsw i32 %1930, %1931" -> "  %1934 = and i32 %1932, 65535"
"  %1933 = mul nuw i32 %1873, 62728"
"  %1933 = mul nuw i32 %1873, 62728" -> "  %1935 = add nuw i32 %1934, %1933"
"  %1934 = and i32 %1932, 65535"
"  %1934 = and i32 %1932, 65535" -> "  %1935 = add nuw i32 %1934, %1933"
"  %1935 = add nuw i32 %1934, %1933"
"  %1935 = add nuw i32 %1934, %1933" -> "  %1948 = and i32 %1935, 65535""  %1935 = add nuw i32 %1934, %1933" -> "  %1939 = lshr i32 %1935, 16"
"  %1936 = lshr i32 %1932, 16"
"  %1936 = lshr i32 %1932, 16" -> "  %1938 = add nuw i32 %1936, %1937"
"  %1937 = mul nuw i32 %1879, 62728"
"  %1937 = mul nuw i32 %1879, 62728" -> "  %1938 = add nuw i32 %1936, %1937"
"  %1938 = add nuw i32 %1936, %1937"
"  %1938 = add nuw i32 %1936, %1937" -> "  %1942 = and i32 %1938, -65536""  %1938 = add nuw i32 %1936, %1937" -> "  %1940 = and i32 %1938, 65535"
"  %1939 = lshr i32 %1935, 16"
"  %1939 = lshr i32 %1935, 16" -> "  %1941 = add nuw nsw i32 %1939, %1940"
"  %1940 = and i32 %1938, 65535"
"  %1940 = and i32 %1938, 65535" -> "  %1941 = add nuw nsw i32 %1939, %1940"
"  %1941 = add nuw nsw i32 %1939, %1940"
"  %1941 = add nuw nsw i32 %1939, %1940" -> "  %1943 = add nuw i32 %1941, %1942"
"  %1942 = and i32 %1938, -65536"
"  %1942 = and i32 %1938, -65536" -> "  %1943 = add nuw i32 %1941, %1942"
"  %1943 = add nuw i32 %1941, %1942"
"  %1943 = add nuw i32 %1941, %1942" -> "  %1951 = add nuw i32 %1943, %1950"
"  %1944 = and i32 %1915, 65535"
"  %1944 = and i32 %1915, 65535" -> "  %1946 = add nuw nsw i32 %1944, %1945"
"  %1945 = and i32 %1926, 65532"
"  %1945 = and i32 %1926, 65532" -> "  %1946 = add nuw nsw i32 %1944, %1945"
"  %1946 = add nuw nsw i32 %1944, %1945"
"  %1946 = add nuw nsw i32 %1944, %1945" -> "  %2019 = and i32 %1946, 65535""  %1946 = add nuw nsw i32 %1944, %1945" -> "  %1953 = lshr i32 %1946, 16"
"  %1947 = and i32 %1921, 65535"
"  %1947 = and i32 %1921, 65535" -> "  %1949 = add nuw nsw i32 %1947, %1948"
"  %1948 = and i32 %1935, 65535"
"  %1948 = and i32 %1935, 65535" -> "  %1949 = add nuw nsw i32 %1947, %1948"
"  %1949 = add nuw nsw i32 %1947, %1948"
"  %1949 = add nuw nsw i32 %1947, %1948" -> "  %1952 = and i32 %1949, 65535""  %1949 = add nuw nsw i32 %1947, %1948" -> "  %1950 = lshr i32 %1949, 16"
"  %1950 = lshr i32 %1949, 16"
"  %1950 = lshr i32 %1949, 16" -> "  %1951 = add nuw i32 %1943, %1950"
"  %1951 = add nuw i32 %1943, %1950"
"  %1951 = add nuw i32 %1943, %1950" -> "  %1956 = add nuw i32 %1951, %1955"
"  %1952 = and i32 %1949, 65535"
"  %1952 = and i32 %1949, 65535" -> "  %1954 = add nuw nsw i32 %1952, %1953"
"  %1953 = lshr i32 %1946, 16"
"  %1953 = lshr i32 %1946, 16" -> "  %1954 = add nuw nsw i32 %1952, %1953"
"  %1954 = add nuw nsw i32 %1952, %1953"
"  %1954 = add nuw nsw i32 %1952, %1953" -> "  %2022 = and i32 %1954, 65535""  %1954 = add nuw nsw i32 %1952, %1953" -> "  %1955 = lshr i32 %1954, 16"
"  %1955 = lshr i32 %1954, 16"
"  %1955 = lshr i32 %1954, 16" -> "  %1956 = add nuw i32 %1951, %1955"
"  %1956 = add nuw i32 %1951, %1955"
"  %1956 = add nuw i32 %1951, %1955" -> "  %1992 = lshr i32 %1956, 16""  %1956 = add nuw i32 %1951, %1955" -> "  %1989 = and i32 %1956, 65535"
"  %1957 = mul nuw nsw i32 %1896, 1324"
"  %1957 = mul nuw nsw i32 %1896, 1324" -> "  %1976 = and i32 %1957, 65532""  %1957 = mul nuw nsw i32 %1896, 1324" -> "  %1958 = lshr i32 %1957, 16"
"  %1958 = lshr i32 %1957, 16"
"  %1958 = lshr i32 %1957, 16" -> "  %1961 = add nuw nsw i32 %1960, %1958"
"  %1959 = mul nuw nsw i32 %1897, 1324"
"  %1959 = mul nuw nsw i32 %1897, 1324" -> "  %1962 = and i32 %1959, 134152192""  %1959 = mul nuw nsw i32 %1897, 1324" -> "  %1960 = and i32 %1959, 65532"
"  %1960 = and i32 %1959, 65532"
"  %1960 = and i32 %1959, 65532" -> "  %1961 = add nuw nsw i32 %1960, %1958"
"  %1961 = add nuw nsw i32 %1960, %1958"
"  %1961 = add nuw nsw i32 %1960, %1958" -> "  %1963 = add nuw nsw i32 %1961, %1962"
"  %1962 = and i32 %1959, 134152192"
"  %1962 = and i32 %1959, 134152192" -> "  %1963 = add nuw nsw i32 %1961, %1962"
"  %1963 = add nuw nsw i32 %1961, %1962"
"  %1963 = add nuw nsw i32 %1961, %1962" -> "  %1967 = lshr i32 %1963, 16""  %1963 = add nuw nsw i32 %1961, %1962" -> "  %1965 = and i32 %1963, 65535"
"  %1964 = mul nuw i32 %1896, 62728"
"  %1964 = mul nuw i32 %1896, 62728" -> "  %1966 = add nuw i32 %1965, %1964"
"  %1965 = and i32 %1963, 65535"
"  %1965 = and i32 %1963, 65535" -> "  %1966 = add nuw i32 %1965, %1964"
"  %1966 = add nuw i32 %1965, %1964"
"  %1966 = add nuw i32 %1965, %1964" -> "  %1978 = and i32 %1966, 65535""  %1966 = add nuw i32 %1965, %1964" -> "  %1970 = lshr i32 %1966, 16"
"  %1967 = lshr i32 %1963, 16"
"  %1967 = lshr i32 %1963, 16" -> "  %1969 = add nuw i32 %1967, %1968"
"  %1968 = mul nuw i32 %1897, 62728"
"  %1968 = mul nuw i32 %1897, 62728" -> "  %1969 = add nuw i32 %1967, %1968"
"  %1969 = add nuw i32 %1967, %1968"
"  %1969 = add nuw i32 %1967, %1968" -> "  %1973 = and i32 %1969, -65536""  %1969 = add nuw i32 %1967, %1968" -> "  %1971 = and i32 %1969, 65535"
"  %1970 = lshr i32 %1966, 16"
"  %1970 = lshr i32 %1966, 16" -> "  %1972 = add nuw nsw i32 %1970, %1971"
"  %1971 = and i32 %1969, 65535"
"  %1971 = and i32 %1969, 65535" -> "  %1972 = add nuw nsw i32 %1970, %1971"
"  %1972 = add nuw nsw i32 %1970, %1971"
"  %1972 = add nuw nsw i32 %1970, %1971" -> "  %1974 = add nuw i32 %1972, %1973"
"  %1973 = and i32 %1969, -65536"
"  %1973 = and i32 %1969, -65536" -> "  %1974 = add nuw i32 %1972, %1973"
"  %1974 = add nuw i32 %1972, %1973"
"  %1974 = add nuw i32 %1972, %1973" -> "  %1982 = add nuw i32 %1974, %1981"
"  %1975 = and i32 %1925, 65535"
"  %1975 = and i32 %1925, 65535" -> "  %1977 = add nuw nsw i32 %1975, %1976"
"  %1976 = and i32 %1957, 65532"
"  %1976 = and i32 %1957, 65532" -> "  %1977 = add nuw nsw i32 %1975, %1976"
"  %1977 = add nuw nsw i32 %1975, %1976"
"  %1977 = add nuw nsw i32 %1975, %1976" -> "  %1988 = and i32 %1977, 65535""  %1977 = add nuw nsw i32 %1975, %1976" -> "  %1984 = lshr i32 %1977, 16"
"  %1978 = and i32 %1966, 65535"
"  %1978 = and i32 %1966, 65535" -> "  %1980 = add nuw nsw i32 %1979, %1978"
"  %1979 = lshr i32 %1925, 16"
"  %1979 = lshr i32 %1925, 16" -> "  %1980 = add nuw nsw i32 %1979, %1978"
"  %1980 = add nuw nsw i32 %1979, %1978"
"  %1980 = add nuw nsw i32 %1979, %1978" -> "  %1983 = and i32 %1980, 65535""  %1980 = add nuw nsw i32 %1979, %1978" -> "  %1981 = lshr i32 %1980, 16"
"  %1981 = lshr i32 %1980, 16"
"  %1981 = lshr i32 %1980, 16" -> "  %1982 = add nuw i32 %1974, %1981"
"  %1982 = add nuw i32 %1974, %1981"
"  %1982 = add nuw i32 %1974, %1981" -> "  %1987 = add nuw i32 %1982, %1986"
"  %1983 = and i32 %1980, 65535"
"  %1983 = and i32 %1980, 65535" -> "  %1985 = add nuw nsw i32 %1983, %1984"
"  %1984 = lshr i32 %1977, 16"
"  %1984 = lshr i32 %1977, 16" -> "  %1985 = add nuw nsw i32 %1983, %1984"
"  %1985 = add nuw nsw i32 %1983, %1984"
"  %1985 = add nuw nsw i32 %1983, %1984" -> "  %1991 = and i32 %1985, 65535""  %1985 = add nuw nsw i32 %1983, %1984" -> "  %1986 = lshr i32 %1985, 16"
"  %1986 = lshr i32 %1985, 16"
"  %1986 = lshr i32 %1985, 16" -> "  %1987 = add nuw i32 %1982, %1986"
"  %1987 = add nuw i32 %1982, %1986"
"  %1987 = add nuw i32 %1982, %1986" -> "  %2000 = and i32 %1987, -65536""  %1987 = add nuw i32 %1982, %1986" -> "  %1998 = and i32 %1987, 65535"
"  %1988 = and i32 %1977, 65535"
"  %1988 = and i32 %1977, 65535" -> "  %1990 = add nuw nsw i32 %1989, %1988"
"  %1989 = and i32 %1956, 65535"
"  %1989 = and i32 %1956, 65535" -> "  %1990 = add nuw nsw i32 %1989, %1988"
"  %1990 = add nuw nsw i32 %1989, %1988"
"  %1990 = add nuw nsw i32 %1989, %1988" -> "  %2036 = and i32 %1990, 65535""  %1990 = add nuw nsw i32 %1989, %1988" -> "  %1994 = lshr i32 %1990, 16"
"  %1991 = and i32 %1985, 65535"
"  %1991 = and i32 %1985, 65535" -> "  %1993 = add nuw nsw i32 %1991, %1992"
"  %1992 = lshr i32 %1956, 16"
"  %1992 = lshr i32 %1956, 16" -> "  %1993 = add nuw nsw i32 %1991, %1992"
"  %1993 = add nuw nsw i32 %1991, %1992"
"  %1993 = add nuw nsw i32 %1991, %1992" -> "  %1997 = lshr i32 %1993, 16""  %1993 = add nuw nsw i32 %1991, %1992" -> "  %1995 = and i32 %1993, 65535"
"  %1994 = lshr i32 %1990, 16"
"  %1994 = lshr i32 %1990, 16" -> "  %1996 = add nuw nsw i32 %1995, %1994"
"  %1995 = and i32 %1993, 65535"
"  %1995 = and i32 %1993, 65535" -> "  %1996 = add nuw nsw i32 %1995, %1994"
"  %1996 = add nuw nsw i32 %1995, %1994"
"  %1996 = add nuw nsw i32 %1995, %1994" -> "  %2046 = and i32 %1996, 65535""  %1996 = add nuw nsw i32 %1995, %1994" -> "  %2002 = lshr i32 %1996, 16"
"  %1997 = lshr i32 %1993, 16"
"  %1997 = lshr i32 %1993, 16" -> "  %1999 = add nuw nsw i32 %1997, %1998"
"  %1998 = and i32 %1987, 65535"
"  %1998 = and i32 %1987, 65535" -> "  %1999 = add nuw nsw i32 %1997, %1998"
"  %1999 = add nuw nsw i32 %1997, %1998"
"  %1999 = add nuw nsw i32 %1997, %1998" -> "  %2001 = add nuw i32 %1999, %2000"
"  %2000 = and i32 %1987, -65536"
"  %2000 = and i32 %1987, -65536" -> "  %2001 = add nuw i32 %1999, %2000"
"  %2001 = add nuw i32 %1999, %2000"
"  %2001 = add nuw i32 %1999, %2000" -> "  %2003 = add nuw i32 %2001, %2002"
"  %2002 = lshr i32 %1996, 16"
"  %2002 = lshr i32 %1996, 16" -> "  %2003 = add nuw i32 %2001, %2002"
"  %2003 = add nuw i32 %2001, %2002"
"  %2003 = add nuw i32 %2001, %2002" -> "  %2050 = add nuw i32 %2003, %2049"
"  %2004 = and i32 %1874, 65532"
"  %2004 = and i32 %1874, 65532" -> "  %2006 = add nuw nsw i32 %2005, %2004"
"  %2005 = and i32 %1856, 65535"
"  %2005 = and i32 %1856, 65535" -> "  %2006 = add nuw nsw i32 %2005, %2004"
"  %2006 = add nuw nsw i32 %2005, %2004"
"  %2006 = add nuw nsw i32 %2005, %2004" -> "  %2179 = and i32 %2006, 65535""  %2006 = add nuw nsw i32 %2005, %2004" -> "  %2013 = lshr i32 %2006, 16"
"  %2007 = add i64 %18, -204"
"  %2007 = add i64 %18, -204" -> "  %2008 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2007"
"  %2008 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2007"
"  %2008 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2007" -> "  %2009 = bitcast i8* %2008 to i32*"
"  %2009 = bitcast i8* %2008 to i32*"
"  %2009 = bitcast i8* %2008 to i32*" -> "  store i32 %19708, i32* %2009, align 1, !noalias !65"
"  %2010 = and i32 %1887, 65535"
"  %2010 = and i32 %1887, 65535" -> "  %2012 = add nuw nsw i32 %2011, %2010"
"  %2011 = and i32 %1865, 65535"
"  %2011 = and i32 %1865, 65535" -> "  %2012 = add nuw nsw i32 %2011, %2010"
"  %2012 = add nuw nsw i32 %2011, %2010"
"  %2012 = add nuw nsw i32 %2011, %2010" -> "  %2029 = lshr i32 %2012, 16""  %2012 = add nuw nsw i32 %2011, %2010" -> "  %2014 = and i32 %2012, 65535"
"  %2013 = lshr i32 %2006, 16"
"  %2013 = lshr i32 %2006, 16" -> "  %2015 = add nuw nsw i32 %2014, %2013"
"  %2014 = and i32 %2012, 65535"
"  %2014 = and i32 %2012, 65535" -> "  %2015 = add nuw nsw i32 %2014, %2013"
"  %2015 = add nuw nsw i32 %2014, %2013"
"  %2015 = add nuw nsw i32 %2014, %2013" -> "  %2182 = and i32 %2015, 65535""  %2015 = add nuw nsw i32 %2014, %2013" -> "  %2031 = lshr i32 %2015, 16"
"  %2016 = add i64 %18, -180"
"  %2016 = add i64 %18, -180" -> "  %2017 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2016"
"  %2017 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2016"
"  %2017 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2016" -> "  %2018 = bitcast i8* %2017 to i32*"
"  %2018 = bitcast i8* %2017 to i32*"
"  %2018 = bitcast i8* %2017 to i32*" -> "  store i32 %19089, i32* %2018, align 1, !noalias !53"
"  %2019 = and i32 %1946, 65535"
"  %2019 = and i32 %1946, 65535" -> "  %2021 = add nuw nsw i32 %2020, %2019"
"  %2020 = and i32 %1872, 65535"
"  %2020 = and i32 %1872, 65535" -> "  %2021 = add nuw nsw i32 %2020, %2019"
"  %2021 = add nuw nsw i32 %2020, %2019"
"  %2021 = add nuw nsw i32 %2020, %2019" -> "  %2028 = and i32 %2021, 65535""  %2021 = add nuw nsw i32 %2020, %2019" -> "  %2025 = lshr i32 %2021, 16"
"  %2022 = and i32 %1954, 65535"
"  %2022 = and i32 %1954, 65535" -> "  %2024 = add nuw nsw i32 %2023, %2022"
"  %2023 = lshr i32 %1872, 16"
"  %2023 = lshr i32 %1872, 16" -> "  %2024 = add nuw nsw i32 %2023, %2022"
"  %2024 = add nuw nsw i32 %2023, %2022"
"  %2024 = add nuw nsw i32 %2023, %2022" -> "  %2037 = lshr i32 %2024, 16""  %2024 = add nuw nsw i32 %2023, %2022" -> "  %2026 = and i32 %2024, 65535"
"  %2025 = lshr i32 %2021, 16"
"  %2025 = lshr i32 %2021, 16" -> "  %2027 = add nuw nsw i32 %2026, %2025"
"  %2026 = and i32 %2024, 65535"
"  %2026 = and i32 %2024, 65535" -> "  %2027 = add nuw nsw i32 %2026, %2025"
"  %2027 = add nuw nsw i32 %2026, %2025"
"  %2027 = add nuw nsw i32 %2026, %2025" -> "  %2039 = lshr i32 %2027, 16""  %2027 = add nuw nsw i32 %2026, %2025" -> "  %2034 = and i32 %2027, 65535"
"  %2028 = and i32 %2021, 65535"
"  %2028 = and i32 %2021, 65535" -> "  %2030 = add nuw nsw i32 %2028, %2029"
"  %2029 = lshr i32 %2012, 16"
"  %2029 = lshr i32 %2012, 16" -> "  %2030 = add nuw nsw i32 %2028, %2029"
"  %2030 = add nuw nsw i32 %2028, %2029"
"  %2030 = add nuw nsw i32 %2028, %2029" -> "  %2032 = add nuw nsw i32 %2030, %2031"
"  %2031 = lshr i32 %2015, 16"
"  %2031 = lshr i32 %2015, 16" -> "  %2032 = add nuw nsw i32 %2030, %2031"
"  %2032 = add nuw nsw i32 %2030, %2031"
"  %2032 = add nuw nsw i32 %2030, %2031" -> "  %2191 = and i32 %2032, 65535""  %2032 = add nuw nsw i32 %2030, %2031" -> "  %2033 = lshr i32 %2032, 16"
"  %2033 = lshr i32 %2032, 16"
"  %2033 = lshr i32 %2032, 16" -> "  %2035 = add nuw nsw i32 %2033, %2034"
"  %2034 = and i32 %2027, 65535"
"  %2034 = and i32 %2027, 65535" -> "  %2035 = add nuw nsw i32 %2033, %2034"
"  %2035 = add nuw nsw i32 %2033, %2034"
"  %2035 = add nuw nsw i32 %2033, %2034" -> "  %2194 = and i32 %2035, 65535""  %2035 = add nuw nsw i32 %2033, %2034" -> "  %2041 = lshr i32 %2035, 16"
"  %2036 = and i32 %1990, 65535"
"  %2036 = and i32 %1990, 65535" -> "  %2038 = add nuw nsw i32 %2036, %2037"
"  %2037 = lshr i32 %2024, 16"
"  %2037 = lshr i32 %2024, 16" -> "  %2038 = add nuw nsw i32 %2036, %2037"
"  %2038 = add nuw nsw i32 %2036, %2037"
"  %2038 = add nuw nsw i32 %2036, %2037" -> "  %2040 = add nuw nsw i32 %2038, %2039"
"  %2039 = lshr i32 %2027, 16"
"  %2039 = lshr i32 %2027, 16" -> "  %2040 = add nuw nsw i32 %2038, %2039"
"  %2040 = add nuw nsw i32 %2038, %2039"
"  %2040 = add nuw nsw i32 %2038, %2039" -> "  %2042 = add nuw nsw i32 %2040, %2041"
"  %2041 = lshr i32 %2035, 16"
"  %2041 = lshr i32 %2035, 16" -> "  %2042 = add nuw nsw i32 %2040, %2041"
"  %2042 = add nuw nsw i32 %2040, %2041"
"  %2042 = add nuw nsw i32 %2040, %2041" -> "  %2347 = and i32 %2042, 65535""  %2042 = add nuw nsw i32 %2040, %2041" -> "  %2047 = lshr i32 %2042, 16"
"  %2043 = add i64 %18, -160"
"  %2043 = add i64 %18, -160" -> "  %2044 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2043"
"  %2044 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2043"
"  %2044 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2043" -> "  %2045 = bitcast i8* %2044 to i32*"
"  %2045 = bitcast i8* %2044 to i32*"
"  %2045 = bitcast i8* %2044 to i32*" -> "  store i32 %19873, i32* %2045, align 1, !noalias !68"
"  %2046 = and i32 %1996, 65535"
"  %2046 = and i32 %1996, 65535" -> "  %2048 = add nuw nsw i32 %2047, %2046"
"  %2047 = lshr i32 %2042, 16"
"  %2047 = lshr i32 %2042, 16" -> "  %2048 = add nuw nsw i32 %2047, %2046"
"  %2048 = add nuw nsw i32 %2047, %2046"
"  %2048 = add nuw nsw i32 %2047, %2046" -> "  %2350 = and i32 %2048, 65535""  %2048 = add nuw nsw i32 %2047, %2046" -> "  %2049 = lshr i32 %2048, 16"
"  %2049 = lshr i32 %2048, 16"
"  %2049 = lshr i32 %2048, 16" -> "  %2050 = add nuw i32 %2003, %2049"
"  %2050 = add nuw i32 %2003, %2049"
"  %2050 = add nuw i32 %2003, %2049" -> "  %2356 = and i32 %2050, 65535""  %2050 = add nuw i32 %2003, %2049" -> "  %2359 = lshr i32 %2050, 16"
"  %2051 = mul nuw nsw i32 %1724, 17857"
"  %2051 = mul nuw nsw i32 %1724, 17857" -> "  %2178 = and i32 %2051, 65535""  %2051 = mul nuw nsw i32 %1724, 17857" -> "  %2055 = lshr i32 %2051, 16"
"  %2052 = add i64 %18, -184"
"  %2052 = add i64 %18, -184" -> "  %2053 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2052"
"  %2053 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2052"
"  %2053 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2052" -> "  %2054 = bitcast i8* %2053 to i32*"
"  %2054 = bitcast i8* %2053 to i32*"
"  %2054 = bitcast i8* %2053 to i32*" -> "  store i32 %19109, i32* %2054, align 1, !noalias !53"
"  %2055 = lshr i32 %2051, 16"
"  %2055 = lshr i32 %2051, 16" -> "  %2058 = add nuw nsw i32 %2057, %2055"
"  %2056 = mul nuw nsw i32 %1730, 17857"
"  %2056 = mul nuw nsw i32 %1730, 17857" -> "  %2059 = and i32 %2056, 2147418112""  %2056 = mul nuw nsw i32 %1730, 17857" -> "  %2057 = and i32 %2056, 65535"
"  %2057 = and i32 %2056, 65535"
"  %2057 = and i32 %2056, 65535" -> "  %2058 = add nuw nsw i32 %2057, %2055"
"  %2058 = add nuw nsw i32 %2057, %2055"
"  %2058 = add nuw nsw i32 %2057, %2055" -> "  %2060 = add nuw nsw i32 %2058, %2059"
"  %2059 = and i32 %2056, 2147418112"
"  %2059 = and i32 %2056, 2147418112" -> "  %2060 = add nuw nsw i32 %2058, %2059"
"  %2060 = add nuw nsw i32 %2058, %2059"
"  %2060 = add nuw nsw i32 %2058, %2059" -> "  %2064 = lshr i32 %2060, 16""  %2060 = add nuw nsw i32 %2058, %2059" -> "  %2062 = and i32 %2060, 65535"
"  %2061 = mul nuw i32 %1724, 46547"
"  %2061 = mul nuw i32 %1724, 46547" -> "  %2063 = add nuw i32 %2062, %2061"
"  %2062 = and i32 %2060, 65535"
"  %2062 = and i32 %2060, 65535" -> "  %2063 = add nuw i32 %2062, %2061"
"  %2063 = add nuw i32 %2062, %2061"
"  %2063 = add nuw i32 %2062, %2061" -> "  %2181 = and i32 %2063, 65535""  %2063 = add nuw i32 %2062, %2061" -> "  %2067 = lshr i32 %2063, 16"
"  %2064 = lshr i32 %2060, 16"
"  %2064 = lshr i32 %2060, 16" -> "  %2066 = add nuw i32 %2064, %2065"
"  %2065 = mul nuw i32 %1730, 46547"
"  %2065 = mul nuw i32 %1730, 46547" -> "  %2066 = add nuw i32 %2064, %2065"
"  %2066 = add nuw i32 %2064, %2065"
"  %2066 = add nuw i32 %2064, %2065" -> "  %2070 = and i32 %2066, -65536""  %2066 = add nuw i32 %2064, %2065" -> "  %2068 = and i32 %2066, 65535"
"  %2067 = lshr i32 %2063, 16"
"  %2067 = lshr i32 %2063, 16" -> "  %2069 = add nuw nsw i32 %2067, %2068"
"  %2068 = and i32 %2066, 65535"
"  %2068 = and i32 %2066, 65535" -> "  %2069 = add nuw nsw i32 %2067, %2068"
"  %2069 = add nuw nsw i32 %2067, %2068"
"  %2069 = add nuw nsw i32 %2067, %2068" -> "  %2071 = add nuw i32 %2069, %2070"
"  %2070 = and i32 %2066, -65536"
"  %2070 = and i32 %2066, -65536" -> "  %2071 = add nuw i32 %2069, %2070"
"  %2071 = add nuw i32 %2069, %2070"
"  %2071 = add nuw i32 %2069, %2070" -> "  %2090 = and i32 %2071, 65535""  %2071 = add nuw i32 %2069, %2070" -> "  %2094 = lshr i32 %2071, 16"
"  %2072 = mul nuw nsw i32 %1750, 17857"
"  %2072 = mul nuw nsw i32 %1750, 17857" -> "  %2073 = lshr i32 %2072, 16""  %2072 = mul nuw nsw i32 %1750, 17857" -> "  %2091 = and i32 %2072, 65535"
"  %2073 = lshr i32 %2072, 16"
"  %2073 = lshr i32 %2072, 16" -> "  %2076 = add nuw nsw i32 %2075, %2073"
"  %2074 = mul nuw nsw i32 %1751, 17857"
"  %2074 = mul nuw nsw i32 %1751, 17857" -> "  %2077 = and i32 %2074, 2147418112""  %2074 = mul nuw nsw i32 %1751, 17857" -> "  %2075 = and i32 %2074, 65535"
"  %2075 = and i32 %2074, 65535"
"  %2075 = and i32 %2074, 65535" -> "  %2076 = add nuw nsw i32 %2075, %2073"
"  %2076 = add nuw nsw i32 %2075, %2073"
"  %2076 = add nuw nsw i32 %2075, %2073" -> "  %2078 = add nuw nsw i32 %2076, %2077"
"  %2077 = and i32 %2074, 2147418112"
"  %2077 = and i32 %2074, 2147418112" -> "  %2078 = add nuw nsw i32 %2076, %2077"
"  %2078 = add nuw nsw i32 %2076, %2077"
"  %2078 = add nuw nsw i32 %2076, %2077" -> "  %2082 = lshr i32 %2078, 16""  %2078 = add nuw nsw i32 %2076, %2077" -> "  %2080 = and i32 %2078, 65535"
"  %2079 = mul nuw i32 %1750, 46547"
"  %2079 = mul nuw i32 %1750, 46547" -> "  %2081 = add nuw i32 %2080, %2079"
"  %2080 = and i32 %2078, 65535"
"  %2080 = and i32 %2078, 65535" -> "  %2081 = add nuw i32 %2080, %2079"
"  %2081 = add nuw i32 %2080, %2079"
"  %2081 = add nuw i32 %2080, %2079" -> "  %2093 = and i32 %2081, 65535""  %2081 = add nuw i32 %2080, %2079" -> "  %2085 = lshr i32 %2081, 16"
"  %2082 = lshr i32 %2078, 16"
"  %2082 = lshr i32 %2078, 16" -> "  %2084 = add nuw i32 %2082, %2083"
"  %2083 = mul nuw i32 %1751, 46547"
"  %2083 = mul nuw i32 %1751, 46547" -> "  %2084 = add nuw i32 %2082, %2083"
"  %2084 = add nuw i32 %2082, %2083"
"  %2084 = add nuw i32 %2082, %2083" -> "  %2088 = and i32 %2084, -65536""  %2084 = add nuw i32 %2082, %2083" -> "  %2086 = and i32 %2084, 65535"
"  %2085 = lshr i32 %2081, 16"
"  %2085 = lshr i32 %2081, 16" -> "  %2087 = add nuw nsw i32 %2086, %2085"
"  %2086 = and i32 %2084, 65535"
"  %2086 = and i32 %2084, 65535" -> "  %2087 = add nuw nsw i32 %2086, %2085"
"  %2087 = add nuw nsw i32 %2086, %2085"
"  %2087 = add nuw nsw i32 %2086, %2085" -> "  %2089 = add nuw i32 %2087, %2088"
"  %2088 = and i32 %2084, -65536"
"  %2088 = and i32 %2084, -65536" -> "  %2089 = add nuw i32 %2087, %2088"
"  %2089 = add nuw i32 %2087, %2088"
"  %2089 = add nuw i32 %2087, %2088" -> "  %2097 = add nuw i32 %2089, %2096"
"  %2090 = and i32 %2071, 65535"
"  %2090 = and i32 %2071, 65535" -> "  %2092 = add nuw nsw i32 %2090, %2091"
"  %2091 = and i32 %2072, 65535"
"  %2091 = and i32 %2072, 65535" -> "  %2092 = add nuw nsw i32 %2090, %2091"
"  %2092 = add nuw nsw i32 %2090, %2091"
"  %2092 = add nuw nsw i32 %2090, %2091" -> "  %2121 = and i32 %2092, 65535""  %2092 = add nuw nsw i32 %2090, %2091" -> "  %2099 = lshr i32 %2092, 16"
"  %2093 = and i32 %2081, 65535"
"  %2093 = and i32 %2081, 65535" -> "  %2095 = add nuw nsw i32 %2093, %2094"
"  %2094 = lshr i32 %2071, 16"
"  %2094 = lshr i32 %2071, 16" -> "  %2095 = add nuw nsw i32 %2093, %2094"
"  %2095 = add nuw nsw i32 %2093, %2094"
"  %2095 = add nuw nsw i32 %2093, %2094" -> "  %2098 = and i32 %2095, 65535""  %2095 = add nuw nsw i32 %2093, %2094" -> "  %2096 = lshr i32 %2095, 16"
"  %2096 = lshr i32 %2095, 16"
"  %2096 = lshr i32 %2095, 16" -> "  %2097 = add nuw i32 %2089, %2096"
"  %2097 = add nuw i32 %2089, %2096"
"  %2097 = add nuw i32 %2089, %2096" -> "  %2102 = add nuw i32 %2097, %2101"
"  %2098 = and i32 %2095, 65535"
"  %2098 = and i32 %2095, 65535" -> "  %2100 = add nuw nsw i32 %2098, %2099"
"  %2099 = lshr i32 %2092, 16"
"  %2099 = lshr i32 %2092, 16" -> "  %2100 = add nuw nsw i32 %2098, %2099"
"  %2100 = add nuw nsw i32 %2098, %2099"
"  %2100 = add nuw nsw i32 %2098, %2099" -> "  %2124 = and i32 %2100, 65535""  %2100 = add nuw nsw i32 %2098, %2099" -> "  %2101 = lshr i32 %2100, 16"
"  %2101 = lshr i32 %2100, 16"
"  %2101 = lshr i32 %2100, 16" -> "  %2102 = add nuw i32 %2097, %2101"
"  %2102 = add nuw i32 %2097, %2101"
"  %2102 = add nuw i32 %2097, %2101" -> "  %2153 = lshr i32 %2102, 16""  %2102 = add nuw i32 %2097, %2101" -> "  %2149 = and i32 %2102, 65535"
"  %2103 = mul nuw nsw i32 %1724, 31112"
"  %2103 = mul nuw nsw i32 %1724, 31112" -> "  %2122 = and i32 %2103, 65528""  %2103 = mul nuw nsw i32 %1724, 31112" -> "  %2104 = lshr i32 %2103, 16"
"  %2104 = lshr i32 %2103, 16"
"  %2104 = lshr i32 %2103, 16" -> "  %2107 = add nuw nsw i32 %2106, %2104"
"  %2105 = mul nuw nsw i32 %1730, 31112"
"  %2105 = mul nuw nsw i32 %1730, 31112" -> "  %2108 = and i32 %2105, 2147418112""  %2105 = mul nuw nsw i32 %1730, 31112" -> "  %2106 = and i32 %2105, 65528"
"  %2106 = and i32 %2105, 65528"
"  %2106 = and i32 %2105, 65528" -> "  %2107 = add nuw nsw i32 %2106, %2104"
"  %2107 = add nuw nsw i32 %2106, %2104"
"  %2107 = add nuw nsw i32 %2106, %2104" -> "  %2109 = add nuw nsw i32 %2107, %2108"
"  %2108 = and i32 %2105, 2147418112"
"  %2108 = and i32 %2105, 2147418112" -> "  %2109 = add nuw nsw i32 %2107, %2108"
"  %2109 = add nuw nsw i32 %2107, %2108"
"  %2109 = add nuw nsw i32 %2107, %2108" -> "  %2113 = lshr i32 %2109, 16""  %2109 = add nuw nsw i32 %2107, %2108" -> "  %2111 = and i32 %2109, 65535"
"  %2110 = mul nuw i32 %1724, 42170"
"  %2110 = mul nuw i32 %1724, 42170" -> "  %2112 = add nuw i32 %2111, %2110"
"  %2111 = and i32 %2109, 65535"
"  %2111 = and i32 %2109, 65535" -> "  %2112 = add nuw i32 %2111, %2110"
"  %2112 = add nuw i32 %2111, %2110"
"  %2112 = add nuw i32 %2111, %2110" -> "  %2125 = and i32 %2112, 65535""  %2112 = add nuw i32 %2111, %2110" -> "  %2116 = lshr i32 %2112, 16"
"  %2113 = lshr i32 %2109, 16"
"  %2113 = lshr i32 %2109, 16" -> "  %2115 = add nuw i32 %2113, %2114"
"  %2114 = mul nuw i32 %1730, 42170"
"  %2114 = mul nuw i32 %1730, 42170" -> "  %2115 = add nuw i32 %2113, %2114"
"  %2115 = add nuw i32 %2113, %2114"
"  %2115 = add nuw i32 %2113, %2114" -> "  %2119 = and i32 %2115, -65536""  %2115 = add nuw i32 %2113, %2114" -> "  %2117 = and i32 %2115, 65535"
"  %2116 = lshr i32 %2112, 16"
"  %2116 = lshr i32 %2112, 16" -> "  %2118 = add nuw nsw i32 %2116, %2117"
"  %2117 = and i32 %2115, 65535"
"  %2117 = and i32 %2115, 65535" -> "  %2118 = add nuw nsw i32 %2116, %2117"
"  %2118 = add nuw nsw i32 %2116, %2117"
"  %2118 = add nuw nsw i32 %2116, %2117" -> "  %2120 = add nuw i32 %2118, %2119"
"  %2119 = and i32 %2115, -65536"
"  %2119 = and i32 %2115, -65536" -> "  %2120 = add nuw i32 %2118, %2119"
"  %2120 = add nuw i32 %2118, %2119"
"  %2120 = add nuw i32 %2118, %2119" -> "  %2128 = add nuw i32 %2120, %2127"
"  %2121 = and i32 %2092, 65535"
"  %2121 = and i32 %2092, 65535" -> "  %2123 = add nuw nsw i32 %2121, %2122"
"  %2122 = and i32 %2103, 65528"
"  %2122 = and i32 %2103, 65528" -> "  %2123 = add nuw nsw i32 %2121, %2122"
"  %2123 = add nuw nsw i32 %2121, %2122"
"  %2123 = add nuw nsw i32 %2121, %2122" -> "  %2190 = and i32 %2123, 65535""  %2123 = add nuw nsw i32 %2121, %2122" -> "  %2130 = lshr i32 %2123, 16"
"  %2124 = and i32 %2100, 65535"
"  %2124 = and i32 %2100, 65535" -> "  %2126 = add nuw nsw i32 %2124, %2125"
"  %2125 = and i32 %2112, 65535"
"  %2125 = and i32 %2112, 65535" -> "  %2126 = add nuw nsw i32 %2124, %2125"
"  %2126 = add nuw nsw i32 %2124, %2125"
"  %2126 = add nuw nsw i32 %2124, %2125" -> "  %2129 = and i32 %2126, 65535""  %2126 = add nuw nsw i32 %2124, %2125" -> "  %2127 = lshr i32 %2126, 16"
"  %2127 = lshr i32 %2126, 16"
"  %2127 = lshr i32 %2126, 16" -> "  %2128 = add nuw i32 %2120, %2127"
"  %2128 = add nuw i32 %2120, %2127"
"  %2128 = add nuw i32 %2120, %2127" -> "  %2133 = add nuw i32 %2128, %2132"
"  %2129 = and i32 %2126, 65535"
"  %2129 = and i32 %2126, 65535" -> "  %2131 = add nuw nsw i32 %2129, %2130"
"  %2130 = lshr i32 %2123, 16"
"  %2130 = lshr i32 %2123, 16" -> "  %2131 = add nuw nsw i32 %2129, %2130"
"  %2131 = add nuw nsw i32 %2129, %2130"
"  %2131 = add nuw nsw i32 %2129, %2130" -> "  %2193 = and i32 %2131, 65535""  %2131 = add nuw nsw i32 %2129, %2130" -> "  %2132 = lshr i32 %2131, 16"
"  %2132 = lshr i32 %2131, 16"
"  %2132 = lshr i32 %2131, 16" -> "  %2133 = add nuw i32 %2128, %2132"
"  %2133 = add nuw i32 %2128, %2132"
"  %2133 = add nuw i32 %2128, %2132" -> "  %2166 = lshr i32 %2133, 16""  %2133 = add nuw i32 %2128, %2132" -> "  %2163 = and i32 %2133, 65535"
"  %2134 = mul nuw nsw i32 %1750, 31112"
"  %2134 = mul nuw nsw i32 %1750, 31112" -> "  %2150 = and i32 %2134, 65528""  %2134 = mul nuw nsw i32 %1750, 31112" -> "  %2135 = lshr i32 %2134, 16"
"  %2135 = lshr i32 %2134, 16"
"  %2135 = lshr i32 %2134, 16" -> "  %2137 = add nuw nsw i32 %2136, %2135"
"  %2136 = mul nuw nsw i32 %1751, 31112"
"  %2136 = mul nuw nsw i32 %1751, 31112" -> "  %2137 = add nuw nsw i32 %2136, %2135"
"  %2137 = add nuw nsw i32 %2136, %2135"
"  %2137 = add nuw nsw i32 %2136, %2135" -> "  %2141 = lshr i32 %2137, 16""  %2137 = add nuw nsw i32 %2136, %2135" -> "  %2139 = and i32 %2137, 65535"
"  %2138 = mul nuw i32 %1750, 42170"
"  %2138 = mul nuw i32 %1750, 42170" -> "  %2140 = add nuw i32 %2139, %2138"
"  %2139 = and i32 %2137, 65535"
"  %2139 = and i32 %2137, 65535" -> "  %2140 = add nuw i32 %2139, %2138"
"  %2140 = add nuw i32 %2139, %2138"
"  %2140 = add nuw i32 %2139, %2138" -> "  %2152 = and i32 %2140, 65535""  %2140 = add nuw i32 %2139, %2138" -> "  %2144 = lshr i32 %2140, 16"
"  %2141 = lshr i32 %2137, 16"
"  %2141 = lshr i32 %2137, 16" -> "  %2143 = add nuw i32 %2141, %2142"
"  %2142 = mul nuw i32 %1751, 42170"
"  %2142 = mul nuw i32 %1751, 42170" -> "  %2143 = add nuw i32 %2141, %2142"
"  %2143 = add nuw i32 %2141, %2142"
"  %2143 = add nuw i32 %2141, %2142" -> "  %2147 = and i32 %2143, -65536""  %2143 = add nuw i32 %2141, %2142" -> "  %2145 = and i32 %2143, 65535"
"  %2144 = lshr i32 %2140, 16"
"  %2144 = lshr i32 %2140, 16" -> "  %2146 = add nuw nsw i32 %2144, %2145"
"  %2145 = and i32 %2143, 65535"
"  %2145 = and i32 %2143, 65535" -> "  %2146 = add nuw nsw i32 %2144, %2145"
"  %2146 = add nuw nsw i32 %2144, %2145"
"  %2146 = add nuw nsw i32 %2144, %2145" -> "  %2148 = add nuw i32 %2146, %2147"
"  %2147 = and i32 %2143, -65536"
"  %2147 = and i32 %2143, -65536" -> "  %2148 = add nuw i32 %2146, %2147"
"  %2148 = add nuw i32 %2146, %2147"
"  %2148 = add nuw i32 %2146, %2147" -> "  %2156 = add nuw i32 %2148, %2155"
"  %2149 = and i32 %2102, 65535"
"  %2149 = and i32 %2102, 65535" -> "  %2151 = add nuw nsw i32 %2149, %2150"
"  %2150 = and i32 %2134, 65528"
"  %2150 = and i32 %2134, 65528" -> "  %2151 = add nuw nsw i32 %2149, %2150"
"  %2151 = add nuw nsw i32 %2149, %2150"
"  %2151 = add nuw nsw i32 %2149, %2150" -> "  %2162 = and i32 %2151, 65535""  %2151 = add nuw nsw i32 %2149, %2150" -> "  %2158 = lshr i32 %2151, 16"
"  %2152 = and i32 %2140, 65535"
"  %2152 = and i32 %2140, 65535" -> "  %2154 = add nuw nsw i32 %2153, %2152"
"  %2153 = lshr i32 %2102, 16"
"  %2153 = lshr i32 %2102, 16" -> "  %2154 = add nuw nsw i32 %2153, %2152"
"  %2154 = add nuw nsw i32 %2153, %2152"
"  %2154 = add nuw nsw i32 %2153, %2152" -> "  %2157 = and i32 %2154, 65535""  %2154 = add nuw nsw i32 %2153, %2152" -> "  %2155 = lshr i32 %2154, 16"
"  %2155 = lshr i32 %2154, 16"
"  %2155 = lshr i32 %2154, 16" -> "  %2156 = add nuw i32 %2148, %2155"
"  %2156 = add nuw i32 %2148, %2155"
"  %2156 = add nuw i32 %2148, %2155" -> "  %2161 = add nuw i32 %2156, %2160"
"  %2157 = and i32 %2154, 65535"
"  %2157 = and i32 %2154, 65535" -> "  %2159 = add nuw nsw i32 %2157, %2158"
"  %2158 = lshr i32 %2151, 16"
"  %2158 = lshr i32 %2151, 16" -> "  %2159 = add nuw nsw i32 %2157, %2158"
"  %2159 = add nuw nsw i32 %2157, %2158"
"  %2159 = add nuw nsw i32 %2157, %2158" -> "  %2165 = and i32 %2159, 65535""  %2159 = add nuw nsw i32 %2157, %2158" -> "  %2160 = lshr i32 %2159, 16"
"  %2160 = lshr i32 %2159, 16"
"  %2160 = lshr i32 %2159, 16" -> "  %2161 = add nuw i32 %2156, %2160"
"  %2161 = add nuw i32 %2156, %2160"
"  %2161 = add nuw i32 %2156, %2160" -> "  %2174 = and i32 %2161, -65536""  %2161 = add nuw i32 %2156, %2160" -> "  %2172 = and i32 %2161, 65535"
"  %2162 = and i32 %2151, 65535"
"  %2162 = and i32 %2151, 65535" -> "  %2164 = add nuw nsw i32 %2163, %2162"
"  %2163 = and i32 %2133, 65535"
"  %2163 = and i32 %2133, 65535" -> "  %2164 = add nuw nsw i32 %2163, %2162"
"  %2164 = add nuw nsw i32 %2163, %2162"
"  %2164 = add nuw nsw i32 %2163, %2162" -> "  %2210 = and i32 %2164, 65535""  %2164 = add nuw nsw i32 %2163, %2162" -> "  %2168 = lshr i32 %2164, 16"
"  %2165 = and i32 %2159, 65535"
"  %2165 = and i32 %2159, 65535" -> "  %2167 = add nuw nsw i32 %2165, %2166"
"  %2166 = lshr i32 %2133, 16"
"  %2166 = lshr i32 %2133, 16" -> "  %2167 = add nuw nsw i32 %2165, %2166"
"  %2167 = add nuw nsw i32 %2165, %2166"
"  %2167 = add nuw nsw i32 %2165, %2166" -> "  %2171 = lshr i32 %2167, 16""  %2167 = add nuw nsw i32 %2165, %2166" -> "  %2169 = and i32 %2167, 65535"
"  %2168 = lshr i32 %2164, 16"
"  %2168 = lshr i32 %2164, 16" -> "  %2170 = add nuw nsw i32 %2169, %2168"
"  %2169 = and i32 %2167, 65535"
"  %2169 = and i32 %2167, 65535" -> "  %2170 = add nuw nsw i32 %2169, %2168"
"  %2170 = add nuw nsw i32 %2169, %2168"
"  %2170 = add nuw nsw i32 %2169, %2168" -> "  %2217 = and i32 %2170, 65535""  %2170 = add nuw nsw i32 %2169, %2168" -> "  %2176 = lshr i32 %2170, 16"
"  %2171 = lshr i32 %2167, 16"
"  %2171 = lshr i32 %2167, 16" -> "  %2173 = add nuw nsw i32 %2171, %2172"
"  %2172 = and i32 %2161, 65535"
"  %2172 = and i32 %2161, 65535" -> "  %2173 = add nuw nsw i32 %2171, %2172"
"  %2173 = add nuw nsw i32 %2171, %2172"
"  %2173 = add nuw nsw i32 %2171, %2172" -> "  %2175 = add nuw i32 %2173, %2174"
"  %2174 = and i32 %2161, -65536"
"  %2174 = and i32 %2161, -65536" -> "  %2175 = add nuw i32 %2173, %2174"
"  %2175 = add nuw i32 %2173, %2174"
"  %2175 = add nuw i32 %2173, %2174" -> "  %2177 = add nuw i32 %2175, %2176"
"  %2176 = lshr i32 %2170, 16"
"  %2176 = lshr i32 %2170, 16" -> "  %2177 = add nuw i32 %2175, %2176"
"  %2177 = add nuw i32 %2175, %2176"
"  %2177 = add nuw i32 %2175, %2176" -> "  %2221 = add nuw i32 %2177, %2220"
"  %2178 = and i32 %2051, 65535"
"  %2178 = and i32 %2051, 65535" -> "  %2180 = add nuw nsw i32 %2179, %2178"
"  %2179 = and i32 %2006, 65535"
"  %2179 = and i32 %2006, 65535" -> "  %2180 = add nuw nsw i32 %2179, %2178"
"  %2180 = add nuw nsw i32 %2179, %2178"
"  %2180 = add nuw nsw i32 %2179, %2178" -> "  %2455 = and i32 %2180, 65535""  %2180 = add nuw nsw i32 %2179, %2178" -> "  %2184 = lshr i32 %2180, 16"
"  %2181 = and i32 %2063, 65535"
"  %2181 = and i32 %2063, 65535" -> "  %2183 = add nuw nsw i32 %2182, %2181"
"  %2182 = and i32 %2015, 65535"
"  %2182 = and i32 %2015, 65535" -> "  %2183 = add nuw nsw i32 %2182, %2181"
"  %2183 = add nuw nsw i32 %2182, %2181"
"  %2183 = add nuw nsw i32 %2182, %2181" -> "  %2187 = lshr i32 %2183, 16""  %2183 = add nuw nsw i32 %2182, %2181" -> "  %2185 = and i32 %2183, 65535"
"  %2184 = lshr i32 %2180, 16"
"  %2184 = lshr i32 %2180, 16" -> "  %2186 = add nuw nsw i32 %2185, %2184"
"  %2185 = and i32 %2183, 65535"
"  %2185 = and i32 %2183, 65535" -> "  %2186 = add nuw nsw i32 %2185, %2184"
"  %2186 = add nuw nsw i32 %2185, %2184"
"  %2186 = add nuw nsw i32 %2185, %2184" -> "  %2458 = and i32 %2186, 65535""  %2186 = add nuw nsw i32 %2185, %2184" -> "  %2188 = lshr i32 %2186, 16"
"  %2187 = lshr i32 %2183, 16"
"  %2187 = lshr i32 %2183, 16" -> "  %2189 = add nuw nsw i32 %2188, %2187"
"  %2188 = lshr i32 %2186, 16"
"  %2188 = lshr i32 %2186, 16" -> "  %2189 = add nuw nsw i32 %2188, %2187"
"  %2189 = add nuw nsw i32 %2188, %2187"
"  %2189 = add nuw nsw i32 %2188, %2187" -> "  %2200 = add nuw nsw i32 %2189, %2199"
"  %2190 = and i32 %2123, 65535"
"  %2190 = and i32 %2123, 65535" -> "  %2192 = add nuw nsw i32 %2191, %2190"
"  %2191 = and i32 %2032, 65535"
"  %2191 = and i32 %2032, 65535" -> "  %2192 = add nuw nsw i32 %2191, %2190"
"  %2192 = add nuw nsw i32 %2191, %2190"
"  %2192 = add nuw nsw i32 %2191, %2190" -> "  %2199 = and i32 %2192, 65535""  %2192 = add nuw nsw i32 %2191, %2190" -> "  %2196 = lshr i32 %2192, 16"
"  %2193 = and i32 %2131, 65535"
"  %2193 = and i32 %2131, 65535" -> "  %2195 = add nuw nsw i32 %2194, %2193"
"  %2194 = and i32 %2035, 65535"
"  %2194 = and i32 %2035, 65535" -> "  %2195 = add nuw nsw i32 %2194, %2193"
"  %2195 = add nuw nsw i32 %2194, %2193"
"  %2195 = add nuw nsw i32 %2194, %2193" -> "  %2211 = lshr i32 %2195, 16""  %2195 = add nuw nsw i32 %2194, %2193" -> "  %2197 = and i32 %2195, 65535"
"  %2196 = lshr i32 %2192, 16"
"  %2196 = lshr i32 %2192, 16" -> "  %2198 = add nuw nsw i32 %2197, %2196"
"  %2197 = and i32 %2195, 65535"
"  %2197 = and i32 %2195, 65535" -> "  %2198 = add nuw nsw i32 %2197, %2196"
"  %2198 = add nuw nsw i32 %2197, %2196"
"  %2198 = add nuw nsw i32 %2197, %2196" -> "  %2213 = lshr i32 %2198, 16""  %2198 = add nuw nsw i32 %2197, %2196" -> "  %2205 = and i32 %2198, 65535"
"  %2199 = and i32 %2192, 65535"
"  %2199 = and i32 %2192, 65535" -> "  %2200 = add nuw nsw i32 %2189, %2199"
"  %2200 = add nuw nsw i32 %2189, %2199"
"  %2200 = add nuw nsw i32 %2189, %2199" -> "  %2464 = and i32 %2200, 65535""  %2200 = add nuw nsw i32 %2189, %2199" -> "  %2204 = lshr i32 %2200, 16"
"  %2201 = add i64 %18, -208"
"  %2201 = add i64 %18, -208" -> "  %2202 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2201"
"  %2202 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2201"
"  %2202 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2201" -> "  %2203 = bitcast i8* %2202 to i32*"
"  %2203 = bitcast i8* %2202 to i32*"
"  %2203 = bitcast i8* %2202 to i32*" -> "  store i32 %19112, i32* %2203, align 1, !noalias !53"
"  %2204 = lshr i32 %2200, 16"
"  %2204 = lshr i32 %2200, 16" -> "  %2206 = add nuw nsw i32 %2205, %2204"
"  %2205 = and i32 %2198, 65535"
"  %2205 = and i32 %2198, 65535" -> "  %2206 = add nuw nsw i32 %2205, %2204"
"  %2206 = add nuw nsw i32 %2205, %2204"
"  %2206 = add nuw nsw i32 %2205, %2204" -> "  %2467 = and i32 %2206, 65535""  %2206 = add nuw nsw i32 %2205, %2204" -> "  %2215 = lshr i32 %2206, 16"
"  %2207 = add i64 %18, -152"
"  %2207 = add i64 %18, -152" -> "  %2208 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2207"
"  %2208 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2207"
"  %2208 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2207" -> "  %2209 = bitcast i8* %2208 to i32*"
"  %2209 = bitcast i8* %2208 to i32*"
"  %2209 = bitcast i8* %2208 to i32*" -> "  store i32 %19124, i32* %2209, align 1, !noalias !56"
"  %2210 = and i32 %2164, 65535"
"  %2210 = and i32 %2164, 65535" -> "  %2212 = add nuw nsw i32 %2211, %2210"
"  %2211 = lshr i32 %2195, 16"
"  %2211 = lshr i32 %2195, 16" -> "  %2212 = add nuw nsw i32 %2211, %2210"
"  %2212 = add nuw nsw i32 %2211, %2210"
"  %2212 = add nuw nsw i32 %2211, %2210" -> "  %2214 = add nuw nsw i32 %2212, %2213"
"  %2213 = lshr i32 %2198, 16"
"  %2213 = lshr i32 %2198, 16" -> "  %2214 = add nuw nsw i32 %2212, %2213"
"  %2214 = add nuw nsw i32 %2212, %2213"
"  %2214 = add nuw nsw i32 %2212, %2213" -> "  %2216 = add nuw nsw i32 %2214, %2215"
"  %2215 = lshr i32 %2206, 16"
"  %2215 = lshr i32 %2206, 16" -> "  %2216 = add nuw nsw i32 %2214, %2215"
"  %2216 = add nuw nsw i32 %2214, %2215"
"  %2216 = add nuw nsw i32 %2214, %2215" -> "  %2385 = and i32 %2216, 65535""  %2216 = add nuw nsw i32 %2214, %2215" -> "  %2218 = lshr i32 %2216, 16"
"  %2217 = and i32 %2170, 65535"
"  %2217 = and i32 %2170, 65535" -> "  %2219 = add nuw nsw i32 %2218, %2217"
"  %2218 = lshr i32 %2216, 16"
"  %2218 = lshr i32 %2216, 16" -> "  %2219 = add nuw nsw i32 %2218, %2217"
"  %2219 = add nuw nsw i32 %2218, %2217"
"  %2219 = add nuw nsw i32 %2218, %2217" -> "  %2391 = and i32 %2219, 65535""  %2219 = add nuw nsw i32 %2218, %2217" -> "  %2220 = lshr i32 %2219, 16"
"  %2220 = lshr i32 %2219, 16"
"  %2220 = lshr i32 %2219, 16" -> "  %2221 = add nuw i32 %2177, %2220"
"  %2221 = add nuw i32 %2177, %2220"
"  %2221 = add nuw i32 %2177, %2220" -> "  %2400 = and i32 %2221, 65535""  %2221 = add nuw i32 %2177, %2220" -> "  %2403 = lshr i32 %2221, 16"
"  %2222 = mul nuw nsw i32 %1873, 17857"
"  %2222 = mul nuw nsw i32 %1873, 17857" -> "  %2346 = and i32 %2222, 65535""  %2222 = mul nuw nsw i32 %1873, 17857" -> "  %2223 = lshr i32 %2222, 16"
"  %2223 = lshr i32 %2222, 16"
"  %2223 = lshr i32 %2222, 16" -> "  %2226 = add nuw nsw i32 %2225, %2223"
"  %2224 = mul nuw nsw i32 %1879, 17857"
"  %2224 = mul nuw nsw i32 %1879, 17857" -> "  %2227 = and i32 %2224, 2147418112""  %2224 = mul nuw nsw i32 %1879, 17857" -> "  %2225 = and i32 %2224, 65535"
"  %2225 = and i32 %2224, 65535"
"  %2225 = and i32 %2224, 65535" -> "  %2226 = add nuw nsw i32 %2225, %2223"
"  %2226 = add nuw nsw i32 %2225, %2223"
"  %2226 = add nuw nsw i32 %2225, %2223" -> "  %2228 = add nuw nsw i32 %2226, %2227"
"  %2227 = and i32 %2224, 2147418112"
"  %2227 = and i32 %2224, 2147418112" -> "  %2228 = add nuw nsw i32 %2226, %2227"
"  %2228 = add nuw nsw i32 %2226, %2227"
"  %2228 = add nuw nsw i32 %2226, %2227" -> "  %2232 = lshr i32 %2228, 16""  %2228 = add nuw nsw i32 %2226, %2227" -> "  %2230 = and i32 %2228, 65535"
"  %2229 = mul nuw i32 %1873, 46547"
"  %2229 = mul nuw i32 %1873, 46547" -> "  %2231 = add nuw i32 %2230, %2229"
"  %2230 = and i32 %2228, 65535"
"  %2230 = and i32 %2228, 65535" -> "  %2231 = add nuw i32 %2230, %2229"
"  %2231 = add nuw i32 %2230, %2229"
"  %2231 = add nuw i32 %2230, %2229" -> "  %2349 = and i32 %2231, 65535""  %2231 = add nuw i32 %2230, %2229" -> "  %2235 = lshr i32 %2231, 16"
"  %2232 = lshr i32 %2228, 16"
"  %2232 = lshr i32 %2228, 16" -> "  %2234 = add nuw i32 %2232, %2233"
"  %2233 = mul nuw i32 %1879, 46547"
"  %2233 = mul nuw i32 %1879, 46547" -> "  %2234 = add nuw i32 %2232, %2233"
"  %2234 = add nuw i32 %2232, %2233"
"  %2234 = add nuw i32 %2232, %2233" -> "  %2238 = and i32 %2234, -65536""  %2234 = add nuw i32 %2232, %2233" -> "  %2236 = and i32 %2234, 65535"
"  %2235 = lshr i32 %2231, 16"
"  %2235 = lshr i32 %2231, 16" -> "  %2237 = add nuw nsw i32 %2235, %2236"
"  %2236 = and i32 %2234, 65535"
"  %2236 = and i32 %2234, 65535" -> "  %2237 = add nuw nsw i32 %2235, %2236"
"  %2237 = add nuw nsw i32 %2235, %2236"
"  %2237 = add nuw nsw i32 %2235, %2236" -> "  %2239 = add nuw i32 %2237, %2238"
"  %2238 = and i32 %2234, -65536"
"  %2238 = and i32 %2234, -65536" -> "  %2239 = add nuw i32 %2237, %2238"
"  %2239 = add nuw i32 %2237, %2238"
"  %2239 = add nuw i32 %2237, %2238" -> "  %2255 = and i32 %2239, 65535""  %2239 = add nuw i32 %2237, %2238" -> "  %2258 = lshr i32 %2239, 16"
"  %2240 = mul nuw nsw i32 %1896, 17857"
"  %2240 = mul nuw nsw i32 %1896, 17857" -> "  %2241 = lshr i32 %2240, 16""  %2240 = mul nuw nsw i32 %1896, 17857" -> "  %2256 = and i32 %2240, 65535"
"  %2241 = lshr i32 %2240, 16"
"  %2241 = lshr i32 %2240, 16" -> "  %2243 = add nuw nsw i32 %2241, %2242"
"  %2242 = mul nuw nsw i32 %1897, 17857"
"  %2242 = mul nuw nsw i32 %1897, 17857" -> "  %2243 = add nuw nsw i32 %2241, %2242"
"  %2243 = add nuw nsw i32 %2241, %2242"
"  %2243 = add nuw nsw i32 %2241, %2242" -> "  %2247 = lshr i32 %2243, 16""  %2243 = add nuw nsw i32 %2241, %2242" -> "  %2245 = and i32 %2243, 65535"
"  %2244 = mul nuw i32 %1896, 46547"
"  %2244 = mul nuw i32 %1896, 46547" -> "  %2246 = add nuw i32 %2245, %2244"
"  %2245 = and i32 %2243, 65535"
"  %2245 = and i32 %2243, 65535" -> "  %2246 = add nuw i32 %2245, %2244"
"  %2246 = add nuw i32 %2245, %2244"
"  %2246 = add nuw i32 %2245, %2244" -> "  %2259 = and i32 %2246, 65535""  %2246 = add nuw i32 %2245, %2244" -> "  %2250 = lshr i32 %2246, 16"
"  %2247 = lshr i32 %2243, 16"
"  %2247 = lshr i32 %2243, 16" -> "  %2249 = add nuw i32 %2247, %2248"
"  %2248 = mul nuw i32 %1897, 46547"
"  %2248 = mul nuw i32 %1897, 46547" -> "  %2249 = add nuw i32 %2247, %2248"
"  %2249 = add nuw i32 %2247, %2248"
"  %2249 = add nuw i32 %2247, %2248" -> "  %2253 = and i32 %2249, -65536""  %2249 = add nuw i32 %2247, %2248" -> "  %2251 = and i32 %2249, 65535"
"  %2250 = lshr i32 %2246, 16"
"  %2250 = lshr i32 %2246, 16" -> "  %2252 = add nuw nsw i32 %2251, %2250"
"  %2251 = and i32 %2249, 65535"
"  %2251 = and i32 %2249, 65535" -> "  %2252 = add nuw nsw i32 %2251, %2250"
"  %2252 = add nuw nsw i32 %2251, %2250"
"  %2252 = add nuw nsw i32 %2251, %2250" -> "  %2254 = add nuw i32 %2252, %2253"
"  %2253 = and i32 %2249, -65536"
"  %2253 = and i32 %2249, -65536" -> "  %2254 = add nuw i32 %2252, %2253"
"  %2254 = add nuw i32 %2252, %2253"
"  %2254 = add nuw i32 %2252, %2253" -> "  %2262 = add nuw i32 %2254, %2261"
"  %2255 = and i32 %2239, 65535"
"  %2255 = and i32 %2239, 65535" -> "  %2257 = add nuw nsw i32 %2255, %2256"
"  %2256 = and i32 %2240, 65535"
"  %2256 = and i32 %2240, 65535" -> "  %2257 = add nuw nsw i32 %2255, %2256"
"  %2257 = add nuw nsw i32 %2255, %2256"
"  %2257 = add nuw nsw i32 %2255, %2256" -> "  %2286 = and i32 %2257, 65535""  %2257 = add nuw nsw i32 %2255, %2256" -> "  %2264 = lshr i32 %2257, 16"
"  %2258 = lshr i32 %2239, 16"
"  %2258 = lshr i32 %2239, 16" -> "  %2260 = add nuw nsw i32 %2258, %2259"
"  %2259 = and i32 %2246, 65535"
"  %2259 = and i32 %2246, 65535" -> "  %2260 = add nuw nsw i32 %2258, %2259"
"  %2260 = add nuw nsw i32 %2258, %2259"
"  %2260 = add nuw nsw i32 %2258, %2259" -> "  %2263 = and i32 %2260, 65535""  %2260 = add nuw nsw i32 %2258, %2259" -> "  %2261 = lshr i32 %2260, 16"
"  %2261 = lshr i32 %2260, 16"
"  %2261 = lshr i32 %2260, 16" -> "  %2262 = add nuw i32 %2254, %2261"
"  %2262 = add nuw i32 %2254, %2261"
"  %2262 = add nuw i32 %2254, %2261" -> "  %2267 = add nuw i32 %2262, %2266"
"  %2263 = and i32 %2260, 65535"
"  %2263 = and i32 %2260, 65535" -> "  %2265 = add nuw nsw i32 %2263, %2264"
"  %2264 = lshr i32 %2257, 16"
"  %2264 = lshr i32 %2257, 16" -> "  %2265 = add nuw nsw i32 %2263, %2264"
"  %2265 = add nuw nsw i32 %2263, %2264"
"  %2265 = add nuw nsw i32 %2263, %2264" -> "  %2289 = and i32 %2265, 65535""  %2265 = add nuw nsw i32 %2263, %2264" -> "  %2266 = lshr i32 %2265, 16"
"  %2266 = lshr i32 %2265, 16"
"  %2266 = lshr i32 %2265, 16" -> "  %2267 = add nuw i32 %2262, %2266"
"  %2267 = add nuw i32 %2262, %2266"
"  %2267 = add nuw i32 %2262, %2266" -> "  %2321 = lshr i32 %2267, 16""  %2267 = add nuw i32 %2262, %2266" -> "  %2317 = and i32 %2267, 65535"
"  %2268 = mul nuw nsw i32 %1873, 31112"
"  %2268 = mul nuw nsw i32 %1873, 31112" -> "  %2287 = and i32 %2268, 65528""  %2268 = mul nuw nsw i32 %1873, 31112" -> "  %2269 = lshr i32 %2268, 16"
"  %2269 = lshr i32 %2268, 16"
"  %2269 = lshr i32 %2268, 16" -> "  %2272 = add nuw nsw i32 %2271, %2269"
"  %2270 = mul nuw nsw i32 %1879, 31112"
"  %2270 = mul nuw nsw i32 %1879, 31112" -> "  %2273 = and i32 %2270, 2147418112""  %2270 = mul nuw nsw i32 %1879, 31112" -> "  %2271 = and i32 %2270, 65528"
"  %2271 = and i32 %2270, 65528"
"  %2271 = and i32 %2270, 65528" -> "  %2272 = add nuw nsw i32 %2271, %2269"
"  %2272 = add nuw nsw i32 %2271, %2269"
"  %2272 = add nuw nsw i32 %2271, %2269" -> "  %2274 = add nuw nsw i32 %2272, %2273"
"  %2273 = and i32 %2270, 2147418112"
"  %2273 = and i32 %2270, 2147418112" -> "  %2274 = add nuw nsw i32 %2272, %2273"
"  %2274 = add nuw nsw i32 %2272, %2273"
"  %2274 = add nuw nsw i32 %2272, %2273" -> "  %2278 = lshr i32 %2274, 16""  %2274 = add nuw nsw i32 %2272, %2273" -> "  %2276 = and i32 %2274, 65535"
"  %2275 = mul nuw i32 %1873, 42170"
"  %2275 = mul nuw i32 %1873, 42170" -> "  %2277 = add nuw i32 %2276, %2275"
"  %2276 = and i32 %2274, 65535"
"  %2276 = and i32 %2274, 65535" -> "  %2277 = add nuw i32 %2276, %2275"
"  %2277 = add nuw i32 %2276, %2275"
"  %2277 = add nuw i32 %2276, %2275" -> "  %2290 = and i32 %2277, 65535""  %2277 = add nuw i32 %2276, %2275" -> "  %2281 = lshr i32 %2277, 16"
"  %2278 = lshr i32 %2274, 16"
"  %2278 = lshr i32 %2274, 16" -> "  %2280 = add nuw i32 %2278, %2279"
"  %2279 = mul nuw i32 %1879, 42170"
"  %2279 = mul nuw i32 %1879, 42170" -> "  %2280 = add nuw i32 %2278, %2279"
"  %2280 = add nuw i32 %2278, %2279"
"  %2280 = add nuw i32 %2278, %2279" -> "  %2284 = and i32 %2280, -65536""  %2280 = add nuw i32 %2278, %2279" -> "  %2282 = and i32 %2280, 65535"
"  %2281 = lshr i32 %2277, 16"
"  %2281 = lshr i32 %2277, 16" -> "  %2283 = add nuw nsw i32 %2281, %2282"
"  %2282 = and i32 %2280, 65535"
"  %2282 = and i32 %2280, 65535" -> "  %2283 = add nuw nsw i32 %2281, %2282"
"  %2283 = add nuw nsw i32 %2281, %2282"
"  %2283 = add nuw nsw i32 %2281, %2282" -> "  %2285 = add nuw i32 %2283, %2284"
"  %2284 = and i32 %2280, -65536"
"  %2284 = and i32 %2280, -65536" -> "  %2285 = add nuw i32 %2283, %2284"
"  %2285 = add nuw i32 %2283, %2284"
"  %2285 = add nuw i32 %2283, %2284" -> "  %2293 = add nuw i32 %2285, %2292"
"  %2286 = and i32 %2257, 65535"
"  %2286 = and i32 %2257, 65535" -> "  %2288 = add nuw nsw i32 %2286, %2287"
"  %2287 = and i32 %2268, 65528"
"  %2287 = and i32 %2268, 65528" -> "  %2288 = add nuw nsw i32 %2286, %2287"
"  %2288 = add nuw nsw i32 %2286, %2287"
"  %2288 = add nuw nsw i32 %2286, %2287" -> "  %2355 = and i32 %2288, 65535""  %2288 = add nuw nsw i32 %2286, %2287" -> "  %2295 = lshr i32 %2288, 16"
"  %2289 = and i32 %2265, 65535"
"  %2289 = and i32 %2265, 65535" -> "  %2291 = add nuw nsw i32 %2289, %2290"
"  %2290 = and i32 %2277, 65535"
"  %2290 = and i32 %2277, 65535" -> "  %2291 = add nuw nsw i32 %2289, %2290"
"  %2291 = add nuw nsw i32 %2289, %2290"
"  %2291 = add nuw nsw i32 %2289, %2290" -> "  %2294 = and i32 %2291, 65535""  %2291 = add nuw nsw i32 %2289, %2290" -> "  %2292 = lshr i32 %2291, 16"
"  %2292 = lshr i32 %2291, 16"
"  %2292 = lshr i32 %2291, 16" -> "  %2293 = add nuw i32 %2285, %2292"
"  %2293 = add nuw i32 %2285, %2292"
"  %2293 = add nuw i32 %2285, %2292" -> "  %2298 = add nuw i32 %2293, %2297"
"  %2294 = and i32 %2291, 65535"
"  %2294 = and i32 %2291, 65535" -> "  %2296 = add nuw nsw i32 %2294, %2295"
"  %2295 = lshr i32 %2288, 16"
"  %2295 = lshr i32 %2288, 16" -> "  %2296 = add nuw nsw i32 %2294, %2295"
"  %2296 = add nuw nsw i32 %2294, %2295"
"  %2296 = add nuw nsw i32 %2294, %2295" -> "  %2358 = and i32 %2296, 65535""  %2296 = add nuw nsw i32 %2294, %2295" -> "  %2297 = lshr i32 %2296, 16"
"  %2297 = lshr i32 %2296, 16"
"  %2297 = lshr i32 %2296, 16" -> "  %2298 = add nuw i32 %2293, %2297"
"  %2298 = add nuw i32 %2293, %2297"
"  %2298 = add nuw i32 %2293, %2297" -> "  %2334 = lshr i32 %2298, 16""  %2298 = add nuw i32 %2293, %2297" -> "  %2331 = and i32 %2298, 65535"
"  %2299 = mul nuw nsw i32 %1896, 31112"
"  %2299 = mul nuw nsw i32 %1896, 31112" -> "  %2318 = and i32 %2299, 65528""  %2299 = mul nuw nsw i32 %1896, 31112" -> "  %2300 = lshr i32 %2299, 16"
"  %2300 = lshr i32 %2299, 16"
"  %2300 = lshr i32 %2299, 16" -> "  %2303 = add nuw nsw i32 %2302, %2300"
"  %2301 = mul nuw nsw i32 %1897, 31112"
"  %2301 = mul nuw nsw i32 %1897, 31112" -> "  %2304 = and i32 %2301, 2147418112""  %2301 = mul nuw nsw i32 %1897, 31112" -> "  %2302 = and i32 %2301, 65528"
"  %2302 = and i32 %2301, 65528"
"  %2302 = and i32 %2301, 65528" -> "  %2303 = add nuw nsw i32 %2302, %2300"
"  %2303 = add nuw nsw i32 %2302, %2300"
"  %2303 = add nuw nsw i32 %2302, %2300" -> "  %2305 = add nuw nsw i32 %2303, %2304"
"  %2304 = and i32 %2301, 2147418112"
"  %2304 = and i32 %2301, 2147418112" -> "  %2305 = add nuw nsw i32 %2303, %2304"
"  %2305 = add nuw nsw i32 %2303, %2304"
"  %2305 = add nuw nsw i32 %2303, %2304" -> "  %2309 = lshr i32 %2305, 16""  %2305 = add nuw nsw i32 %2303, %2304" -> "  %2307 = and i32 %2305, 65535"
"  %2306 = mul nuw i32 %1896, 42170"
"  %2306 = mul nuw i32 %1896, 42170" -> "  %2308 = add nuw i32 %2307, %2306"
"  %2307 = and i32 %2305, 65535"
"  %2307 = and i32 %2305, 65535" -> "  %2308 = add nuw i32 %2307, %2306"
"  %2308 = add nuw i32 %2307, %2306"
"  %2308 = add nuw i32 %2307, %2306" -> "  %2320 = and i32 %2308, 65535""  %2308 = add nuw i32 %2307, %2306" -> "  %2312 = lshr i32 %2308, 16"
"  %2309 = lshr i32 %2305, 16"
"  %2309 = lshr i32 %2305, 16" -> "  %2311 = add nuw i32 %2309, %2310"
"  %2310 = mul nuw i32 %1897, 42170"
"  %2310 = mul nuw i32 %1897, 42170" -> "  %2311 = add nuw i32 %2309, %2310"
"  %2311 = add nuw i32 %2309, %2310"
"  %2311 = add nuw i32 %2309, %2310" -> "  %2315 = and i32 %2311, -65536""  %2311 = add nuw i32 %2309, %2310" -> "  %2313 = and i32 %2311, 65535"
"  %2312 = lshr i32 %2308, 16"
"  %2312 = lshr i32 %2308, 16" -> "  %2314 = add nuw nsw i32 %2312, %2313"
"  %2313 = and i32 %2311, 65535"
"  %2313 = and i32 %2311, 65535" -> "  %2314 = add nuw nsw i32 %2312, %2313"
"  %2314 = add nuw nsw i32 %2312, %2313"
"  %2314 = add nuw nsw i32 %2312, %2313" -> "  %2316 = add nuw i32 %2314, %2315"
"  %2315 = and i32 %2311, -65536"
"  %2315 = and i32 %2311, -65536" -> "  %2316 = add nuw i32 %2314, %2315"
"  %2316 = add nuw i32 %2314, %2315"
"  %2316 = add nuw i32 %2314, %2315" -> "  %2324 = add nuw i32 %2316, %2323"
"  %2317 = and i32 %2267, 65535"
"  %2317 = and i32 %2267, 65535" -> "  %2319 = add nuw nsw i32 %2317, %2318"
"  %2318 = and i32 %2299, 65528"
"  %2318 = and i32 %2299, 65528" -> "  %2319 = add nuw nsw i32 %2317, %2318"
"  %2319 = add nuw nsw i32 %2317, %2318"
"  %2319 = add nuw nsw i32 %2317, %2318" -> "  %2330 = and i32 %2319, 65535""  %2319 = add nuw nsw i32 %2317, %2318" -> "  %2326 = lshr i32 %2319, 16"
"  %2320 = and i32 %2308, 65535"
"  %2320 = and i32 %2308, 65535" -> "  %2322 = add nuw nsw i32 %2321, %2320"
"  %2321 = lshr i32 %2267, 16"
"  %2321 = lshr i32 %2267, 16" -> "  %2322 = add nuw nsw i32 %2321, %2320"
"  %2322 = add nuw nsw i32 %2321, %2320"
"  %2322 = add nuw nsw i32 %2321, %2320" -> "  %2325 = and i32 %2322, 65535""  %2322 = add nuw nsw i32 %2321, %2320" -> "  %2323 = lshr i32 %2322, 16"
"  %2323 = lshr i32 %2322, 16"
"  %2323 = lshr i32 %2322, 16" -> "  %2324 = add nuw i32 %2316, %2323"
"  %2324 = add nuw i32 %2316, %2323"
"  %2324 = add nuw i32 %2316, %2323" -> "  %2329 = add nuw i32 %2324, %2328"
"  %2325 = and i32 %2322, 65535"
"  %2325 = and i32 %2322, 65535" -> "  %2327 = add nuw nsw i32 %2325, %2326"
"  %2326 = lshr i32 %2319, 16"
"  %2326 = lshr i32 %2319, 16" -> "  %2327 = add nuw nsw i32 %2325, %2326"
"  %2327 = add nuw nsw i32 %2325, %2326"
"  %2327 = add nuw nsw i32 %2325, %2326" -> "  %2333 = and i32 %2327, 65535""  %2327 = add nuw nsw i32 %2325, %2326" -> "  %2328 = lshr i32 %2327, 16"
"  %2328 = lshr i32 %2327, 16"
"  %2328 = lshr i32 %2327, 16" -> "  %2329 = add nuw i32 %2324, %2328"
"  %2329 = add nuw i32 %2324, %2328"
"  %2329 = add nuw i32 %2324, %2328" -> "  %2342 = and i32 %2329, -65536""  %2329 = add nuw i32 %2324, %2328" -> "  %2340 = and i32 %2329, 65535"
"  %2330 = and i32 %2319, 65535"
"  %2330 = and i32 %2319, 65535" -> "  %2332 = add nuw nsw i32 %2331, %2330"
"  %2331 = and i32 %2298, 65535"
"  %2331 = and i32 %2298, 65535" -> "  %2332 = add nuw nsw i32 %2331, %2330"
"  %2332 = add nuw nsw i32 %2331, %2330"
"  %2332 = add nuw nsw i32 %2331, %2330" -> "  %2372 = and i32 %2332, 65535""  %2332 = add nuw nsw i32 %2331, %2330" -> "  %2336 = lshr i32 %2332, 16"
"  %2333 = and i32 %2327, 65535"
"  %2333 = and i32 %2327, 65535" -> "  %2335 = add nuw nsw i32 %2333, %2334"
"  %2334 = lshr i32 %2298, 16"
"  %2334 = lshr i32 %2298, 16" -> "  %2335 = add nuw nsw i32 %2333, %2334"
"  %2335 = add nuw nsw i32 %2333, %2334"
"  %2335 = add nuw nsw i32 %2333, %2334" -> "  %2339 = lshr i32 %2335, 16""  %2335 = add nuw nsw i32 %2333, %2334" -> "  %2337 = and i32 %2335, 65535"
"  %2336 = lshr i32 %2332, 16"
"  %2336 = lshr i32 %2332, 16" -> "  %2338 = add nuw nsw i32 %2337, %2336"
"  %2337 = and i32 %2335, 65535"
"  %2337 = and i32 %2335, 65535" -> "  %2338 = add nuw nsw i32 %2337, %2336"
"  %2338 = add nuw nsw i32 %2337, %2336"
"  %2338 = add nuw nsw i32 %2337, %2336" -> "  %2379 = and i32 %2338, 65535""  %2338 = add nuw nsw i32 %2337, %2336" -> "  %2344 = lshr i32 %2338, 16"
"  %2339 = lshr i32 %2335, 16"
"  %2339 = lshr i32 %2335, 16" -> "  %2341 = add nuw nsw i32 %2339, %2340"
"  %2340 = and i32 %2329, 65535"
"  %2340 = and i32 %2329, 65535" -> "  %2341 = add nuw nsw i32 %2339, %2340"
"  %2341 = add nuw nsw i32 %2339, %2340"
"  %2341 = add nuw nsw i32 %2339, %2340" -> "  %2343 = add nuw i32 %2341, %2342"
"  %2342 = and i32 %2329, -65536"
"  %2342 = and i32 %2329, -65536" -> "  %2343 = add nuw i32 %2341, %2342"
"  %2343 = add nuw i32 %2341, %2342"
"  %2343 = add nuw i32 %2341, %2342" -> "  %2345 = add nuw i32 %2343, %2344"
"  %2344 = lshr i32 %2338, 16"
"  %2344 = lshr i32 %2338, 16" -> "  %2345 = add nuw i32 %2343, %2344"
"  %2345 = add nuw i32 %2343, %2344"
"  %2345 = add nuw i32 %2343, %2344" -> "  %2383 = add nuw i32 %2345, %2382"
"  %2346 = and i32 %2222, 65535"
"  %2346 = and i32 %2222, 65535" -> "  %2348 = add nuw nsw i32 %2347, %2346"
"  %2347 = and i32 %2042, 65535"
"  %2347 = and i32 %2042, 65535" -> "  %2348 = add nuw nsw i32 %2347, %2346"
"  %2348 = add nuw nsw i32 %2347, %2346"
"  %2348 = add nuw nsw i32 %2347, %2346" -> "  %2384 = and i32 %2348, 65535""  %2348 = add nuw nsw i32 %2347, %2346" -> "  %2352 = lshr i32 %2348, 16"
"  %2349 = and i32 %2231, 65535"
"  %2349 = and i32 %2231, 65535" -> "  %2351 = add nuw nsw i32 %2350, %2349"
"  %2350 = and i32 %2048, 65535"
"  %2350 = and i32 %2048, 65535" -> "  %2351 = add nuw nsw i32 %2350, %2349"
"  %2351 = add nuw nsw i32 %2350, %2349"
"  %2351 = add nuw nsw i32 %2350, %2349" -> "  %2365 = lshr i32 %2351, 16""  %2351 = add nuw nsw i32 %2350, %2349" -> "  %2353 = and i32 %2351, 65535"
"  %2352 = lshr i32 %2348, 16"
"  %2352 = lshr i32 %2348, 16" -> "  %2354 = add nuw nsw i32 %2353, %2352"
"  %2353 = and i32 %2351, 65535"
"  %2353 = and i32 %2351, 65535" -> "  %2354 = add nuw nsw i32 %2353, %2352"
"  %2354 = add nuw nsw i32 %2353, %2352"
"  %2354 = add nuw nsw i32 %2353, %2352" -> "  %2390 = and i32 %2354, 65535""  %2354 = add nuw nsw i32 %2353, %2352" -> "  %2367 = lshr i32 %2354, 16"
"  %2355 = and i32 %2288, 65535"
"  %2355 = and i32 %2288, 65535" -> "  %2357 = add nuw nsw i32 %2356, %2355"
"  %2356 = and i32 %2050, 65535"
"  %2356 = and i32 %2050, 65535" -> "  %2357 = add nuw nsw i32 %2356, %2355"
"  %2357 = add nuw nsw i32 %2356, %2355"
"  %2357 = add nuw nsw i32 %2356, %2355" -> "  %2364 = and i32 %2357, 65535""  %2357 = add nuw nsw i32 %2356, %2355" -> "  %2361 = lshr i32 %2357, 16"
"  %2358 = and i32 %2296, 65535"
"  %2358 = and i32 %2296, 65535" -> "  %2360 = add nuw nsw i32 %2359, %2358"
"  %2359 = lshr i32 %2050, 16"
"  %2359 = lshr i32 %2050, 16" -> "  %2360 = add nuw nsw i32 %2359, %2358"
"  %2360 = add nuw nsw i32 %2359, %2358"
"  %2360 = add nuw nsw i32 %2359, %2358" -> "  %2373 = lshr i32 %2360, 16""  %2360 = add nuw nsw i32 %2359, %2358" -> "  %2362 = and i32 %2360, 65535"
"  %2361 = lshr i32 %2357, 16"
"  %2361 = lshr i32 %2357, 16" -> "  %2363 = add nuw nsw i32 %2362, %2361"
"  %2362 = and i32 %2360, 65535"
"  %2362 = and i32 %2360, 65535" -> "  %2363 = add nuw nsw i32 %2362, %2361"
"  %2363 = add nuw nsw i32 %2362, %2361"
"  %2363 = add nuw nsw i32 %2362, %2361" -> "  %2375 = lshr i32 %2363, 16""  %2363 = add nuw nsw i32 %2362, %2361" -> "  %2370 = and i32 %2363, 65535"
"  %2364 = and i32 %2357, 65535"
"  %2364 = and i32 %2357, 65535" -> "  %2366 = add nuw nsw i32 %2364, %2365"
"  %2365 = lshr i32 %2351, 16"
"  %2365 = lshr i32 %2351, 16" -> "  %2366 = add nuw nsw i32 %2364, %2365"
"  %2366 = add nuw nsw i32 %2364, %2365"
"  %2366 = add nuw nsw i32 %2364, %2365" -> "  %2368 = add nuw nsw i32 %2366, %2367"
"  %2367 = lshr i32 %2354, 16"
"  %2367 = lshr i32 %2354, 16" -> "  %2368 = add nuw nsw i32 %2366, %2367"
"  %2368 = add nuw nsw i32 %2366, %2367"
"  %2368 = add nuw nsw i32 %2366, %2367" -> "  %2399 = and i32 %2368, 65535""  %2368 = add nuw nsw i32 %2366, %2367" -> "  %2369 = lshr i32 %2368, 16"
"  %2369 = lshr i32 %2368, 16"
"  %2369 = lshr i32 %2368, 16" -> "  %2371 = add nuw nsw i32 %2369, %2370"
"  %2370 = and i32 %2363, 65535"
"  %2370 = and i32 %2363, 65535" -> "  %2371 = add nuw nsw i32 %2369, %2370"
"  %2371 = add nuw nsw i32 %2369, %2370"
"  %2371 = add nuw nsw i32 %2369, %2370" -> "  %2402 = and i32 %2371, 65535""  %2371 = add nuw nsw i32 %2369, %2370" -> "  %2377 = lshr i32 %2371, 16"
"  %2372 = and i32 %2332, 65535"
"  %2372 = and i32 %2332, 65535" -> "  %2374 = add nuw nsw i32 %2373, %2372"
"  %2373 = lshr i32 %2360, 16"
"  %2373 = lshr i32 %2360, 16" -> "  %2374 = add nuw nsw i32 %2373, %2372"
"  %2374 = add nuw nsw i32 %2373, %2372"
"  %2374 = add nuw nsw i32 %2373, %2372" -> "  %2376 = add nuw nsw i32 %2374, %2375"
"  %2375 = lshr i32 %2363, 16"
"  %2375 = lshr i32 %2363, 16" -> "  %2376 = add nuw nsw i32 %2374, %2375"
"  %2376 = add nuw nsw i32 %2374, %2375"
"  %2376 = add nuw nsw i32 %2374, %2375" -> "  %2378 = add nuw nsw i32 %2376, %2377"
"  %2377 = lshr i32 %2371, 16"
"  %2377 = lshr i32 %2371, 16" -> "  %2378 = add nuw nsw i32 %2376, %2377"
"  %2378 = add nuw nsw i32 %2376, %2377"
"  %2378 = add nuw nsw i32 %2376, %2377" -> "  %2416 = and i32 %2378, 65535""  %2378 = add nuw nsw i32 %2376, %2377" -> "  %2380 = lshr i32 %2378, 16"
"  %2379 = and i32 %2338, 65535"
"  %2379 = and i32 %2338, 65535" -> "  %2381 = add nuw nsw i32 %2380, %2379"
"  %2380 = lshr i32 %2378, 16"
"  %2380 = lshr i32 %2378, 16" -> "  %2381 = add nuw nsw i32 %2380, %2379"
"  %2381 = add nuw nsw i32 %2380, %2379"
"  %2381 = add nuw nsw i32 %2380, %2379" -> "  %2424 = and i32 %2381, 65535""  %2381 = add nuw nsw i32 %2380, %2379" -> "  %2382 = lshr i32 %2381, 16"
"  %2382 = lshr i32 %2381, 16"
"  %2382 = lshr i32 %2381, 16" -> "  %2383 = add nuw i32 %2345, %2382"
"  %2383 = add nuw i32 %2345, %2382"
"  %2383 = add nuw i32 %2345, %2382" -> "  %2427 = add nuw i32 %2383, %2426"
"  %2384 = and i32 %2348, 65535"
"  %2384 = and i32 %2348, 65535" -> "  %2386 = add nuw nsw i32 %2385, %2384"
"  %2385 = and i32 %2216, 65535"
"  %2385 = and i32 %2216, 65535" -> "  %2386 = add nuw nsw i32 %2385, %2384"
"  %2386 = add nuw nsw i32 %2385, %2384"
"  %2386 = add nuw nsw i32 %2385, %2384" -> "  %2501 = and i32 %2386, 65535""  %2386 = add nuw nsw i32 %2385, %2384" -> "  %2393 = lshr i32 %2386, 16"
"  %2387 = add i64 %18, -228"
"  %2387 = add i64 %18, -228" -> "  %2388 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2387"
"  %2388 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2387"
"  %2388 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2387" -> "  %2389 = bitcast i8* %2388 to i32*"
"  %2389 = bitcast i8* %2388 to i32*"
"  %2389 = bitcast i8* %2388 to i32*" -> "  store i32 %19125, i32* %2389, align 1, !noalias !56"
"  %2390 = and i32 %2354, 65535"
"  %2390 = and i32 %2354, 65535" -> "  %2392 = add nuw nsw i32 %2391, %2390"
"  %2391 = and i32 %2219, 65535"
"  %2391 = and i32 %2219, 65535" -> "  %2392 = add nuw nsw i32 %2391, %2390"
"  %2392 = add nuw nsw i32 %2391, %2390"
"  %2392 = add nuw nsw i32 %2391, %2390" -> "  %2409 = lshr i32 %2392, 16""  %2392 = add nuw nsw i32 %2391, %2390" -> "  %2394 = and i32 %2392, 65535"
"  %2393 = lshr i32 %2386, 16"
"  %2393 = lshr i32 %2386, 16" -> "  %2395 = add nuw nsw i32 %2394, %2393"
"  %2394 = and i32 %2392, 65535"
"  %2394 = and i32 %2392, 65535" -> "  %2395 = add nuw nsw i32 %2394, %2393"
"  %2395 = add nuw nsw i32 %2394, %2393"
"  %2395 = add nuw nsw i32 %2394, %2393" -> "  %2505 = and i32 %2395, 65535""  %2395 = add nuw nsw i32 %2394, %2393" -> "  %2410 = lshr i32 %2395, 16"
"  %2396 = add i64 %18, -176"
"  %2396 = add i64 %18, -176" -> "  %2397 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2396"
"  %2397 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2396"
"  %2397 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2396" -> "  %2398 = bitcast i8* %2397 to i32*"
"  %2398 = bitcast i8* %2397 to i32*"
"  %2398 = bitcast i8* %2397 to i32*" -> "  store i32 %15805, i32* %2398, align 1, !noalias !38"
"  %2399 = and i32 %2368, 65535"
"  %2399 = and i32 %2368, 65535" -> "  %2401 = add nuw nsw i32 %2400, %2399"
"  %2400 = and i32 %2221, 65535"
"  %2400 = and i32 %2221, 65535" -> "  %2401 = add nuw nsw i32 %2400, %2399"
"  %2401 = add nuw nsw i32 %2400, %2399"
"  %2401 = add nuw nsw i32 %2400, %2399" -> "  %2408 = and i32 %2401, 65535""  %2401 = add nuw nsw i32 %2400, %2399" -> "  %2405 = lshr i32 %2401, 16"
"  %2402 = and i32 %2371, 65535"
"  %2402 = and i32 %2371, 65535" -> "  %2404 = add nuw nsw i32 %2402, %2403"
"  %2403 = lshr i32 %2221, 16"
"  %2403 = lshr i32 %2221, 16" -> "  %2404 = add nuw nsw i32 %2402, %2403"
"  %2404 = add nuw nsw i32 %2402, %2403"
"  %2404 = add nuw nsw i32 %2402, %2403" -> "  %2417 = lshr i32 %2404, 16""  %2404 = add nuw nsw i32 %2402, %2403" -> "  %2406 = and i32 %2404, 65535"
"  %2405 = lshr i32 %2401, 16"
"  %2405 = lshr i32 %2401, 16" -> "  %2407 = add nuw nsw i32 %2406, %2405"
"  %2406 = and i32 %2404, 65535"
"  %2406 = and i32 %2404, 65535" -> "  %2407 = add nuw nsw i32 %2406, %2405"
"  %2407 = add nuw nsw i32 %2406, %2405"
"  %2407 = add nuw nsw i32 %2406, %2405" -> "  %2419 = lshr i32 %2407, 16""  %2407 = add nuw nsw i32 %2406, %2405" -> "  %2414 = and i32 %2407, 65535"
"  %2408 = and i32 %2401, 65535"
"  %2408 = and i32 %2401, 65535" -> "  %2412 = add nuw nsw i32 %2411, %2408"
"  %2409 = lshr i32 %2392, 16"
"  %2409 = lshr i32 %2392, 16" -> "  %2411 = add nuw nsw i32 %2410, %2409"
"  %2410 = lshr i32 %2395, 16"
"  %2410 = lshr i32 %2395, 16" -> "  %2411 = add nuw nsw i32 %2410, %2409"
"  %2411 = add nuw nsw i32 %2410, %2409"
"  %2411 = add nuw nsw i32 %2410, %2409" -> "  %2412 = add nuw nsw i32 %2411, %2408"
"  %2412 = add nuw nsw i32 %2411, %2408"
"  %2412 = add nuw nsw i32 %2411, %2408" -> "  %2508 = and i32 %2412, 65535""  %2412 = add nuw nsw i32 %2411, %2408" -> "  %2413 = lshr i32 %2412, 16"
"  %2413 = lshr i32 %2412, 16"
"  %2413 = lshr i32 %2412, 16" -> "  %2415 = add nuw nsw i32 %2413, %2414"
"  %2414 = and i32 %2407, 65535"
"  %2414 = and i32 %2407, 65535" -> "  %2415 = add nuw nsw i32 %2413, %2414"
"  %2415 = add nuw nsw i32 %2413, %2414"
"  %2415 = add nuw nsw i32 %2413, %2414" -> "  %2512 = and i32 %2415, 65535""  %2415 = add nuw nsw i32 %2413, %2414" -> "  %2421 = lshr i32 %2415, 16"
"  %2416 = and i32 %2378, 65535"
"  %2416 = and i32 %2378, 65535" -> "  %2418 = add nuw nsw i32 %2417, %2416"
"  %2417 = lshr i32 %2404, 16"
"  %2417 = lshr i32 %2404, 16" -> "  %2418 = add nuw nsw i32 %2417, %2416"
"  %2418 = add nuw nsw i32 %2417, %2416"
"  %2418 = add nuw nsw i32 %2417, %2416" -> "  %2420 = add nuw nsw i32 %2418, %2419"
"  %2419 = lshr i32 %2407, 16"
"  %2419 = lshr i32 %2407, 16" -> "  %2420 = add nuw nsw i32 %2418, %2419"
"  %2420 = add nuw nsw i32 %2418, %2419"
"  %2420 = add nuw nsw i32 %2418, %2419" -> "  %2422 = add nuw nsw i32 %2420, %2421"
"  %2421 = lshr i32 %2415, 16"
"  %2421 = lshr i32 %2415, 16" -> "  %2422 = add nuw nsw i32 %2420, %2421"
"  %2422 = add nuw nsw i32 %2420, %2421"
"  %2422 = add nuw nsw i32 %2420, %2421" -> "  %2514 = and i32 %2422, 65535""  %2422 = add nuw nsw i32 %2420, %2421" -> "  %2423 = lshr i32 %2422, 16"
"  %2423 = lshr i32 %2422, 16"
"  %2423 = lshr i32 %2422, 16" -> "  %2425 = add nuw nsw i32 %2423, %2424"
"  %2424 = and i32 %2381, 65535"
"  %2424 = and i32 %2381, 65535" -> "  %2425 = add nuw nsw i32 %2423, %2424"
"  %2425 = add nuw nsw i32 %2423, %2424"
"  %2425 = add nuw nsw i32 %2423, %2424" -> "  %2517 = and i32 %2425, 65535""  %2425 = add nuw nsw i32 %2423, %2424" -> "  %2426 = lshr i32 %2425, 16"
"  %2426 = lshr i32 %2425, 16"
"  %2426 = lshr i32 %2425, 16" -> "  %2427 = add nuw i32 %2383, %2426"
"  %2427 = add nuw i32 %2383, %2426"
"  %2427 = add nuw i32 %2383, %2426" -> "  %2521 = add nuw i32 %2427, %2520"
"  %2428 = and i32 %1685, 65535"
"  %2428 = and i32 %1685, 65535" -> "  %2430 = add nuw nsw i32 %2428, %2429"
"  %2429 = and i32 %1725, 65532"
"  %2429 = and i32 %1725, 65532" -> "  %2430 = add nuw nsw i32 %2428, %2429"
"  %2430 = add nuw nsw i32 %2428, %2429"
"  %2430 = add nuw nsw i32 %2428, %2429" -> "  %3197 = and i32 %2430, 65535""  %2430 = add nuw nsw i32 %2428, %2429" -> "  %2434 = lshr i32 %2430, 16"
"  %2431 = and i32 %1691, 65535"
"  %2431 = and i32 %1691, 65535" -> "  %2433 = add nuw nsw i32 %2431, %2432"
"  %2432 = and i32 %1738, 65535"
"  %2432 = and i32 %1738, 65535" -> "  %2433 = add nuw nsw i32 %2431, %2432"
"  %2433 = add nuw nsw i32 %2431, %2432"
"  %2433 = add nuw nsw i32 %2431, %2432" -> "  %2437 = lshr i32 %2433, 16""  %2433 = add nuw nsw i32 %2431, %2432" -> "  %2435 = and i32 %2433, 65535"
"  %2434 = lshr i32 %2430, 16"
"  %2434 = lshr i32 %2430, 16" -> "  %2436 = add nuw nsw i32 %2435, %2434"
"  %2435 = and i32 %2433, 65535"
"  %2435 = and i32 %2433, 65535" -> "  %2436 = add nuw nsw i32 %2435, %2434"
"  %2436 = add nuw nsw i32 %2435, %2434"
"  %2436 = add nuw nsw i32 %2435, %2434" -> "  %3200 = and i32 %2436, 65535""  %2436 = add nuw nsw i32 %2435, %2434" -> "  %2438 = lshr i32 %2436, 16"
"  %2437 = lshr i32 %2433, 16"
"  %2437 = lshr i32 %2433, 16" -> "  %2439 = add nuw nsw i32 %2438, %2437"
"  %2438 = lshr i32 %2436, 16"
"  %2438 = lshr i32 %2436, 16" -> "  %2439 = add nuw nsw i32 %2438, %2437"
"  %2439 = add nuw nsw i32 %2438, %2437"
"  %2439 = add nuw nsw i32 %2438, %2437" -> "  %2450 = add nuw nsw i32 %2439, %2449"
"  %2440 = and i32 %1708, 65535"
"  %2440 = and i32 %1708, 65535" -> "  %2442 = add nuw nsw i32 %2440, %2441"
"  %2441 = and i32 %1806, 65535"
"  %2441 = and i32 %1806, 65535" -> "  %2442 = add nuw nsw i32 %2440, %2441"
"  %2442 = add nuw nsw i32 %2440, %2441"
"  %2442 = add nuw nsw i32 %2440, %2441" -> "  %2449 = and i32 %2442, 65535""  %2442 = add nuw nsw i32 %2440, %2441" -> "  %2446 = lshr i32 %2442, 16"
"  %2443 = and i32 %1711, 65535"
"  %2443 = and i32 %1711, 65535" -> "  %2445 = add nuw nsw i32 %2443, %2444"
"  %2444 = and i32 %1817, 65535"
"  %2444 = and i32 %1817, 65535" -> "  %2445 = add nuw nsw i32 %2443, %2444"
"  %2445 = add nuw nsw i32 %2443, %2444"
"  %2445 = add nuw nsw i32 %2443, %2444" -> "  %2485 = lshr i32 %2445, 16""  %2445 = add nuw nsw i32 %2443, %2444" -> "  %2447 = and i32 %2445, 65535"
"  %2446 = lshr i32 %2442, 16"
"  %2446 = lshr i32 %2442, 16" -> "  %2448 = add nuw nsw i32 %2447, %2446"
"  %2447 = and i32 %2445, 65535"
"  %2447 = and i32 %2445, 65535" -> "  %2448 = add nuw nsw i32 %2447, %2446"
"  %2448 = add nuw nsw i32 %2447, %2446"
"  %2448 = add nuw nsw i32 %2447, %2446" -> "  %2486 = lshr i32 %2448, 16""  %2448 = add nuw nsw i32 %2447, %2446" -> "  %2452 = and i32 %2448, 65535"
"  %2449 = and i32 %2442, 65535"
"  %2449 = and i32 %2442, 65535" -> "  %2450 = add nuw nsw i32 %2439, %2449"
"  %2450 = add nuw nsw i32 %2439, %2449"
"  %2450 = add nuw nsw i32 %2439, %2449" -> "  %3208 = and i32 %2450, 65535""  %2450 = add nuw nsw i32 %2439, %2449" -> "  %2451 = lshr i32 %2450, 16"
"  %2451 = lshr i32 %2450, 16"
"  %2451 = lshr i32 %2450, 16" -> "  %2453 = add nuw nsw i32 %2452, %2451"
"  %2452 = and i32 %2448, 65535"
"  %2452 = and i32 %2448, 65535" -> "  %2453 = add nuw nsw i32 %2452, %2451"
"  %2453 = add nuw nsw i32 %2452, %2451"
"  %2453 = add nuw nsw i32 %2452, %2451" -> "  %3211 = and i32 %2453, 65535""  %2453 = add nuw nsw i32 %2452, %2451" -> "  %2487 = lshr i32 %2453, 16"
"  %2454 = and i32 %1718, 65535"
"  %2454 = and i32 %1718, 65535" -> "  %2456 = add nuw nsw i32 %2454, %2455"
"  %2455 = and i32 %2180, 65535"
"  %2455 = and i32 %2180, 65535" -> "  %2456 = add nuw nsw i32 %2454, %2455"
"  %2456 = add nuw nsw i32 %2454, %2455"
"  %2456 = add nuw nsw i32 %2454, %2455" -> "  %2484 = and i32 %2456, 65535""  %2456 = add nuw nsw i32 %2454, %2455" -> "  %2460 = lshr i32 %2456, 16"
"  %2457 = and i32 %1721, 65535"
"  %2457 = and i32 %1721, 65535" -> "  %2459 = add nuw nsw i32 %2457, %2458"
"  %2458 = and i32 %2186, 65535"
"  %2458 = and i32 %2186, 65535" -> "  %2459 = add nuw nsw i32 %2457, %2458"
"  %2459 = add nuw nsw i32 %2457, %2458"
"  %2459 = add nuw nsw i32 %2457, %2458" -> "  %2476 = lshr i32 %2459, 16""  %2459 = add nuw nsw i32 %2457, %2458" -> "  %2461 = and i32 %2459, 65535"
"  %2460 = lshr i32 %2456, 16"
"  %2460 = lshr i32 %2456, 16" -> "  %2462 = add nuw nsw i32 %2461, %2460"
"  %2461 = and i32 %2459, 65535"
"  %2461 = and i32 %2459, 65535" -> "  %2462 = add nuw nsw i32 %2461, %2460"
"  %2462 = add nuw nsw i32 %2461, %2460"
"  %2462 = add nuw nsw i32 %2461, %2460" -> "  %2491 = and i32 %2462, 65535""  %2462 = add nuw nsw i32 %2461, %2460" -> "  %2478 = lshr i32 %2462, 16"
"  %2463 = and i32 %1723, 65535"
"  %2463 = and i32 %1723, 65535" -> "  %2465 = add nuw nsw i32 %2463, %2464"
"  %2464 = and i32 %2200, 65535"
"  %2464 = and i32 %2200, 65535" -> "  %2465 = add nuw nsw i32 %2463, %2464"
"  %2465 = add nuw nsw i32 %2463, %2464"
"  %2465 = add nuw nsw i32 %2463, %2464" -> "  %2475 = and i32 %2465, 65535""  %2465 = add nuw nsw i32 %2463, %2464" -> "  %2469 = lshr i32 %2465, 16"
"  %2466 = lshr i32 %1723, 16"
"  %2466 = lshr i32 %1723, 16" -> "  %2468 = add nuw nsw i32 %2467, %2466"
"  %2467 = and i32 %2206, 65535"
"  %2467 = and i32 %2206, 65535" -> "  %2468 = add nuw nsw i32 %2467, %2466"
"  %2468 = add nuw nsw i32 %2467, %2466"
"  %2468 = add nuw nsw i32 %2467, %2466" -> "  %2472 = lshr i32 %2468, 16""  %2468 = add nuw nsw i32 %2467, %2466" -> "  %2470 = and i32 %2468, 65535"
"  %2469 = lshr i32 %2465, 16"
"  %2469 = lshr i32 %2465, 16" -> "  %2471 = add nuw nsw i32 %2470, %2469"
"  %2470 = and i32 %2468, 65535"
"  %2470 = and i32 %2468, 65535" -> "  %2471 = add nuw nsw i32 %2470, %2469"
"  %2471 = add nuw nsw i32 %2470, %2469"
"  %2471 = add nuw nsw i32 %2470, %2469" -> "  %2480 = and i32 %2471, 65535""  %2471 = add nuw nsw i32 %2470, %2469" -> "  %2473 = lshr i32 %2471, 16"
"  %2472 = lshr i32 %2468, 16"
"  %2472 = lshr i32 %2468, 16" -> "  %2474 = add nuw nsw i32 %2473, %2472"
"  %2473 = lshr i32 %2471, 16"
"  %2473 = lshr i32 %2471, 16" -> "  %2474 = add nuw nsw i32 %2473, %2472"
"  %2474 = add nuw nsw i32 %2473, %2472"
"  %2474 = add nuw nsw i32 %2473, %2472" -> "  %2502 = add nuw nsw i32 %2474, %2501"
"  %2475 = and i32 %2465, 65535"
"  %2475 = and i32 %2465, 65535" -> "  %2477 = add nuw nsw i32 %2475, %2476"
"  %2476 = lshr i32 %2459, 16"
"  %2476 = lshr i32 %2459, 16" -> "  %2477 = add nuw nsw i32 %2475, %2476"
"  %2477 = add nuw nsw i32 %2475, %2476"
"  %2477 = add nuw nsw i32 %2475, %2476" -> "  %2479 = add nuw nsw i32 %2477, %2478"
"  %2478 = lshr i32 %2462, 16"
"  %2478 = lshr i32 %2462, 16" -> "  %2479 = add nuw nsw i32 %2477, %2478"
"  %2479 = add nuw nsw i32 %2477, %2478"
"  %2479 = add nuw nsw i32 %2477, %2478" -> "  %2494 = and i32 %2479, 65535""  %2479 = add nuw nsw i32 %2477, %2478" -> "  %2481 = lshr i32 %2479, 16"
"  %2480 = and i32 %2471, 65535"
"  %2480 = and i32 %2471, 65535" -> "  %2482 = add nuw nsw i32 %2480, %2481"
"  %2481 = lshr i32 %2479, 16"
"  %2481 = lshr i32 %2479, 16" -> "  %2482 = add nuw nsw i32 %2480, %2481"
"  %2482 = add nuw nsw i32 %2480, %2481"
"  %2482 = add nuw nsw i32 %2480, %2481" -> "  %2497 = and i32 %2482, 65535""  %2482 = add nuw nsw i32 %2480, %2481" -> "  %2483 = lshr i32 %2482, 16"
"  %2483 = lshr i32 %2482, 16"
"  %2483 = lshr i32 %2482, 16" -> "  %2503 = add nuw nsw i32 %2502, %2483"
"  %2484 = and i32 %2456, 65535"
"  %2484 = and i32 %2456, 65535" -> "  %2489 = add nuw nsw i32 %2488, %2484"
"  %2485 = lshr i32 %2445, 16"
"  %2485 = lshr i32 %2445, 16" -> "  %2488 = add nuw nsw i32 %2486, %2485"
"  %2486 = lshr i32 %2448, 16"
"  %2486 = lshr i32 %2448, 16" -> "  %2488 = add nuw nsw i32 %2486, %2485"
"  %2487 = lshr i32 %2453, 16"
"  %2487 = lshr i32 %2453, 16" -> "  %2490 = add nuw nsw i32 %2489, %2487"
"  %2488 = add nuw nsw i32 %2486, %2485"
"  %2488 = add nuw nsw i32 %2486, %2485" -> "  %2489 = add nuw nsw i32 %2488, %2484"
"  %2489 = add nuw nsw i32 %2488, %2484"
"  %2489 = add nuw nsw i32 %2488, %2484" -> "  %2490 = add nuw nsw i32 %2489, %2487"
"  %2490 = add nuw nsw i32 %2489, %2487"
"  %2490 = add nuw nsw i32 %2489, %2487" -> "  %3223 = and i32 %2490, 65535""  %2490 = add nuw nsw i32 %2489, %2487" -> "  %2492 = lshr i32 %2490, 16"
"  %2491 = and i32 %2462, 65535"
"  %2491 = and i32 %2462, 65535" -> "  %2493 = add nuw nsw i32 %2491, %2492"
"  %2492 = lshr i32 %2490, 16"
"  %2492 = lshr i32 %2490, 16" -> "  %2493 = add nuw nsw i32 %2491, %2492"
"  %2493 = add nuw nsw i32 %2491, %2492"
"  %2493 = add nuw nsw i32 %2491, %2492" -> "  %3226 = and i32 %2493, 65535""  %2493 = add nuw nsw i32 %2491, %2492" -> "  %2495 = lshr i32 %2493, 16"
"  %2494 = and i32 %2479, 65535"
"  %2494 = and i32 %2479, 65535" -> "  %2496 = add nuw nsw i32 %2494, %2495"
"  %2495 = lshr i32 %2493, 16"
"  %2495 = lshr i32 %2493, 16" -> "  %2496 = add nuw nsw i32 %2494, %2495"
"  %2496 = add nuw nsw i32 %2494, %2495"
"  %2496 = add nuw nsw i32 %2494, %2495" -> "  %3235 = and i32 %2496, 65535""  %2496 = add nuw nsw i32 %2494, %2495" -> "  %2498 = lshr i32 %2496, 16"
"  %2497 = and i32 %2482, 65535"
"  %2497 = and i32 %2482, 65535" -> "  %2499 = add nuw nsw i32 %2497, %2498"
"  %2498 = lshr i32 %2496, 16"
"  %2498 = lshr i32 %2496, 16" -> "  %2499 = add nuw nsw i32 %2497, %2498"
"  %2499 = add nuw nsw i32 %2497, %2498"
"  %2499 = add nuw nsw i32 %2497, %2498" -> "  %3238 = and i32 %2499, 65535""  %2499 = add nuw nsw i32 %2497, %2498" -> "  %2500 = lshr i32 %2499, 16"
"  %2500 = lshr i32 %2499, 16"
"  %2500 = lshr i32 %2499, 16" -> "  %2504 = add nuw nsw i32 %2503, %2500"
"  %2501 = and i32 %2386, 65535"
"  %2501 = and i32 %2386, 65535" -> "  %2502 = add nuw nsw i32 %2474, %2501"
"  %2502 = add nuw nsw i32 %2474, %2501"
"  %2502 = add nuw nsw i32 %2474, %2501" -> "  %2503 = add nuw nsw i32 %2502, %2483"
"  %2503 = add nuw nsw i32 %2502, %2483"
"  %2503 = add nuw nsw i32 %2502, %2483" -> "  %2504 = add nuw nsw i32 %2503, %2500"
"  %2504 = add nuw nsw i32 %2503, %2500"
"  %2504 = add nuw nsw i32 %2503, %2500" -> "  %3948 = and i32 %2504, 65535""  %2504 = add nuw nsw i32 %2503, %2500" -> "  %2506 = lshr i32 %2504, 16"
"  %2505 = and i32 %2395, 65535"
"  %2505 = and i32 %2395, 65535" -> "  %2507 = add nuw nsw i32 %2506, %2505"
"  %2506 = lshr i32 %2504, 16"
"  %2506 = lshr i32 %2504, 16" -> "  %2507 = add nuw nsw i32 %2506, %2505"
"  %2507 = add nuw nsw i32 %2506, %2505"
"  %2507 = add nuw nsw i32 %2506, %2505" -> "  %3951 = and i32 %2507, 65535""  %2507 = add nuw nsw i32 %2506, %2505" -> "  %2509 = lshr i32 %2507, 16"
"  %2508 = and i32 %2412, 65535"
"  %2508 = and i32 %2412, 65535" -> "  %2510 = add nuw nsw i32 %2509, %2508"
"  %2509 = lshr i32 %2507, 16"
"  %2509 = lshr i32 %2507, 16" -> "  %2510 = add nuw nsw i32 %2509, %2508"
"  %2510 = add nuw nsw i32 %2509, %2508"
"  %2510 = add nuw nsw i32 %2509, %2508" -> "  %3957 = and i32 %2510, 65535""  %2510 = add nuw nsw i32 %2509, %2508" -> "  %2511 = lshr i32 %2510, 16"
"  %2511 = lshr i32 %2510, 16"
"  %2511 = lshr i32 %2510, 16" -> "  %2513 = add nuw nsw i32 %2511, %2512"
"  %2512 = and i32 %2415, 65535"
"  %2512 = and i32 %2415, 65535" -> "  %2513 = add nuw nsw i32 %2511, %2512"
"  %2513 = add nuw nsw i32 %2511, %2512"
"  %2513 = add nuw nsw i32 %2511, %2512" -> "  %3960 = and i32 %2513, 65535""  %2513 = add nuw nsw i32 %2511, %2512" -> "  %2515 = lshr i32 %2513, 16"
"  %2514 = and i32 %2422, 65535"
"  %2514 = and i32 %2422, 65535" -> "  %2516 = add nuw nsw i32 %2515, %2514"
"  %2515 = lshr i32 %2513, 16"
"  %2515 = lshr i32 %2513, 16" -> "  %2516 = add nuw nsw i32 %2515, %2514"
"  %2516 = add nuw nsw i32 %2515, %2514"
"  %2516 = add nuw nsw i32 %2515, %2514" -> "  %3974 = and i32 %2516, 65535""  %2516 = add nuw nsw i32 %2515, %2514" -> "  %2518 = lshr i32 %2516, 16"
"  %2517 = and i32 %2425, 65535"
"  %2517 = and i32 %2425, 65535" -> "  %2519 = add nuw nsw i32 %2518, %2517"
"  %2518 = lshr i32 %2516, 16"
"  %2518 = lshr i32 %2516, 16" -> "  %2519 = add nuw nsw i32 %2518, %2517"
"  %2519 = add nuw nsw i32 %2518, %2517"
"  %2519 = add nuw nsw i32 %2518, %2517" -> "  %3977 = and i32 %2519, 65535""  %2519 = add nuw nsw i32 %2518, %2517" -> "  %2520 = lshr i32 %2519, 16"
"  %2520 = lshr i32 %2519, 16"
"  %2520 = lshr i32 %2519, 16" -> "  %2521 = add nuw i32 %2427, %2520"
"  %2521 = add nuw i32 %2427, %2520"
"  %2521 = add nuw i32 %2427, %2520" -> "  %3983 = and i32 %2521, 65535""  %2521 = add nuw i32 %2427, %2520" -> "  %3986 = lshr i32 %2521, 16"
"  %2522 = mul nuw i32 %1044, 42779"
"  %2522 = mul nuw i32 %1044, 42779" -> "  %3198 = and i32 %2522, 65535""  %2522 = mul nuw i32 %1044, 42779" -> "  %2523 = lshr i32 %2522, 16"
"  %2523 = lshr i32 %2522, 16"
"  %2523 = lshr i32 %2522, 16" -> "  %2526 = add nuw nsw i32 %2525, %2523"
"  %2524 = mul nuw i32 %1047, 42779"
"  %2524 = mul nuw i32 %1047, 42779" -> "  %2527 = and i32 %2524, -65536""  %2524 = mul nuw i32 %1047, 42779" -> "  %2525 = and i32 %2524, 65535"
"  %2525 = and i32 %2524, 65535"
"  %2525 = and i32 %2524, 65535" -> "  %2526 = add nuw nsw i32 %2525, %2523"
"  %2526 = add nuw nsw i32 %2525, %2523"
"  %2526 = add nuw nsw i32 %2525, %2523" -> "  %2528 = add nuw i32 %2526, %2527"
"  %2527 = and i32 %2524, -65536"
"  %2527 = and i32 %2524, -65536" -> "  %2528 = add nuw i32 %2526, %2527"
"  %2528 = add nuw i32 %2526, %2527"
"  %2528 = add nuw i32 %2526, %2527" -> "  %2532 = lshr i32 %2528, 16""  %2528 = add nuw i32 %2526, %2527" -> "  %2530 = and i32 %2528, 65535"
"  %2529 = mul nuw nsw i32 %1044, 9871"
"  %2529 = mul nuw nsw i32 %1044, 9871" -> "  %2531 = add nuw nsw i32 %2530, %2529"
"  %2530 = and i32 %2528, 65535"
"  %2530 = and i32 %2528, 65535" -> "  %2531 = add nuw nsw i32 %2530, %2529"
"  %2531 = add nuw nsw i32 %2530, %2529"
"  %2531 = add nuw nsw i32 %2530, %2529" -> "  %3201 = and i32 %2531, 65535""  %2531 = add nuw nsw i32 %2530, %2529" -> "  %2535 = lshr i32 %2531, 16"
"  %2532 = lshr i32 %2528, 16"
"  %2532 = lshr i32 %2528, 16" -> "  %2534 = add nuw nsw i32 %2532, %2533"
"  %2533 = mul nuw nsw i32 %1047, 9871"
"  %2533 = mul nuw nsw i32 %1047, 9871" -> "  %2534 = add nuw nsw i32 %2532, %2533"
"  %2534 = add nuw nsw i32 %2532, %2533"
"  %2534 = add nuw nsw i32 %2532, %2533" -> "  %2538 = and i32 %2534, 2147418112""  %2534 = add nuw nsw i32 %2532, %2533" -> "  %2536 = and i32 %2534, 65535"
"  %2535 = lshr i32 %2531, 16"
"  %2535 = lshr i32 %2531, 16" -> "  %2537 = add nuw nsw i32 %2535, %2536"
"  %2536 = and i32 %2534, 65535"
"  %2536 = and i32 %2534, 65535" -> "  %2537 = add nuw nsw i32 %2535, %2536"
"  %2537 = add nuw nsw i32 %2535, %2536"
"  %2537 = add nuw nsw i32 %2535, %2536" -> "  %2539 = add nuw nsw i32 %2537, %2538"
"  %2538 = and i32 %2534, 2147418112"
"  %2538 = and i32 %2534, 2147418112" -> "  %2539 = add nuw nsw i32 %2537, %2538"
"  %2539 = add nuw nsw i32 %2537, %2538"
"  %2539 = add nuw nsw i32 %2537, %2538" -> "  %2562 = lshr i32 %2539, 16""  %2539 = add nuw nsw i32 %2537, %2538" -> "  %2558 = and i32 %2539, 65535"
"  %2540 = mul nuw i32 %1064, 42779"
"  %2540 = mul nuw i32 %1064, 42779" -> "  %2559 = and i32 %2540, 65535""  %2540 = mul nuw i32 %1064, 42779" -> "  %2541 = lshr i32 %2540, 16"
"  %2541 = lshr i32 %2540, 16"
"  %2541 = lshr i32 %2540, 16" -> "  %2544 = add nuw nsw i32 %2543, %2541"
"  %2542 = mul nuw i32 %1065, 42779"
"  %2542 = mul nuw i32 %1065, 42779" -> "  %2545 = and i32 %2542, -65536""  %2542 = mul nuw i32 %1065, 42779" -> "  %2543 = and i32 %2542, 65535"
"  %2543 = and i32 %2542, 65535"
"  %2543 = and i32 %2542, 65535" -> "  %2544 = add nuw nsw i32 %2543, %2541"
"  %2544 = add nuw nsw i32 %2543, %2541"
"  %2544 = add nuw nsw i32 %2543, %2541" -> "  %2546 = add nuw i32 %2544, %2545"
"  %2545 = and i32 %2542, -65536"
"  %2545 = and i32 %2542, -65536" -> "  %2546 = add nuw i32 %2544, %2545"
"  %2546 = add nuw i32 %2544, %2545"
"  %2546 = add nuw i32 %2544, %2545" -> "  %2550 = lshr i32 %2546, 16""  %2546 = add nuw i32 %2544, %2545" -> "  %2548 = and i32 %2546, 65535"
"  %2547 = mul nuw nsw i32 %1064, 9871"
"  %2547 = mul nuw nsw i32 %1064, 9871" -> "  %2549 = add nuw nsw i32 %2548, %2547"
"  %2548 = and i32 %2546, 65535"
"  %2548 = and i32 %2546, 65535" -> "  %2549 = add nuw nsw i32 %2548, %2547"
"  %2549 = add nuw nsw i32 %2548, %2547"
"  %2549 = add nuw nsw i32 %2548, %2547" -> "  %2561 = and i32 %2549, 65535""  %2549 = add nuw nsw i32 %2548, %2547" -> "  %2553 = lshr i32 %2549, 16"
"  %2550 = lshr i32 %2546, 16"
"  %2550 = lshr i32 %2546, 16" -> "  %2552 = add nuw nsw i32 %2550, %2551"
"  %2551 = mul nuw nsw i32 %1065, 9871"
"  %2551 = mul nuw nsw i32 %1065, 9871" -> "  %2552 = add nuw nsw i32 %2550, %2551"
"  %2552 = add nuw nsw i32 %2550, %2551"
"  %2552 = add nuw nsw i32 %2550, %2551" -> "  %2556 = and i32 %2552, 2147418112""  %2552 = add nuw nsw i32 %2550, %2551" -> "  %2554 = and i32 %2552, 65535"
"  %2553 = lshr i32 %2549, 16"
"  %2553 = lshr i32 %2549, 16" -> "  %2555 = add nuw nsw i32 %2553, %2554"
"  %2554 = and i32 %2552, 65535"
"  %2554 = and i32 %2552, 65535" -> "  %2555 = add nuw nsw i32 %2553, %2554"
"  %2555 = add nuw nsw i32 %2553, %2554"
"  %2555 = add nuw nsw i32 %2553, %2554" -> "  %2557 = add nuw nsw i32 %2555, %2556"
"  %2556 = and i32 %2552, 2147418112"
"  %2556 = and i32 %2552, 2147418112" -> "  %2557 = add nuw nsw i32 %2555, %2556"
"  %2557 = add nuw nsw i32 %2555, %2556"
"  %2557 = add nuw nsw i32 %2555, %2556" -> "  %2565 = add nuw nsw i32 %2557, %2564"
"  %2558 = and i32 %2539, 65535"
"  %2558 = and i32 %2539, 65535" -> "  %2560 = add nuw nsw i32 %2558, %2559"
"  %2559 = and i32 %2540, 65535"
"  %2559 = and i32 %2540, 65535" -> "  %2560 = add nuw nsw i32 %2558, %2559"
"  %2560 = add nuw nsw i32 %2558, %2559"
"  %2560 = add nuw nsw i32 %2558, %2559" -> "  %2589 = and i32 %2560, 65535""  %2560 = add nuw nsw i32 %2558, %2559" -> "  %2567 = lshr i32 %2560, 16"
"  %2561 = and i32 %2549, 65535"
"  %2561 = and i32 %2549, 65535" -> "  %2563 = add nuw nsw i32 %2561, %2562"
"  %2562 = lshr i32 %2539, 16"
"  %2562 = lshr i32 %2539, 16" -> "  %2563 = add nuw nsw i32 %2561, %2562"
"  %2563 = add nuw nsw i32 %2561, %2562"
"  %2563 = add nuw nsw i32 %2561, %2562" -> "  %2566 = and i32 %2563, 65535""  %2563 = add nuw nsw i32 %2561, %2562" -> "  %2564 = lshr i32 %2563, 16"
"  %2564 = lshr i32 %2563, 16"
"  %2564 = lshr i32 %2563, 16" -> "  %2565 = add nuw nsw i32 %2557, %2564"
"  %2565 = add nuw nsw i32 %2557, %2564"
"  %2565 = add nuw nsw i32 %2557, %2564" -> "  %2570 = add nuw nsw i32 %2565, %2569"
"  %2566 = and i32 %2563, 65535"
"  %2566 = and i32 %2563, 65535" -> "  %2568 = add nuw nsw i32 %2566, %2567"
"  %2567 = lshr i32 %2560, 16"
"  %2567 = lshr i32 %2560, 16" -> "  %2568 = add nuw nsw i32 %2566, %2567"
"  %2568 = add nuw nsw i32 %2566, %2567"
"  %2568 = add nuw nsw i32 %2566, %2567" -> "  %2592 = and i32 %2568, 65535""  %2568 = add nuw nsw i32 %2566, %2567" -> "  %2569 = lshr i32 %2568, 16"
"  %2569 = lshr i32 %2568, 16"
"  %2569 = lshr i32 %2568, 16" -> "  %2570 = add nuw nsw i32 %2565, %2569"
"  %2570 = add nuw nsw i32 %2565, %2569"
"  %2570 = add nuw nsw i32 %2565, %2569" -> "  %2624 = lshr i32 %2570, 16""  %2570 = add nuw nsw i32 %2565, %2569" -> "  %2620 = and i32 %2570, 65535"
"  %2571 = mul nuw nsw i32 %1044, 24315"
"  %2571 = mul nuw nsw i32 %1044, 24315" -> "  %2590 = and i32 %2571, 65535""  %2571 = mul nuw nsw i32 %1044, 24315" -> "  %2572 = lshr i32 %2571, 16"
"  %2572 = lshr i32 %2571, 16"
"  %2572 = lshr i32 %2571, 16" -> "  %2575 = add nuw nsw i32 %2574, %2572"
"  %2573 = mul nuw nsw i32 %1047, 24315"
"  %2573 = mul nuw nsw i32 %1047, 24315" -> "  %2576 = and i32 %2573, 2147418112""  %2573 = mul nuw nsw i32 %1047, 24315" -> "  %2574 = and i32 %2573, 65535"
"  %2574 = and i32 %2573, 65535"
"  %2574 = and i32 %2573, 65535" -> "  %2575 = add nuw nsw i32 %2574, %2572"
"  %2575 = add nuw nsw i32 %2574, %2572"
"  %2575 = add nuw nsw i32 %2574, %2572" -> "  %2577 = add nuw nsw i32 %2575, %2576"
"  %2576 = and i32 %2573, 2147418112"
"  %2576 = and i32 %2573, 2147418112" -> "  %2577 = add nuw nsw i32 %2575, %2576"
"  %2577 = add nuw nsw i32 %2575, %2576"
"  %2577 = add nuw nsw i32 %2575, %2576" -> "  %2581 = lshr i32 %2577, 16""  %2577 = add nuw nsw i32 %2575, %2576" -> "  %2579 = and i32 %2577, 65535"
"  %2578 = mul nuw nsw i32 %1044, 29744"
"  %2578 = mul nuw nsw i32 %1044, 29744" -> "  %2580 = add nuw nsw i32 %2579, %2578"
"  %2579 = and i32 %2577, 65535"
"  %2579 = and i32 %2577, 65535" -> "  %2580 = add nuw nsw i32 %2579, %2578"
"  %2580 = add nuw nsw i32 %2579, %2578"
"  %2580 = add nuw nsw i32 %2579, %2578" -> "  %2593 = and i32 %2580, 65535""  %2580 = add nuw nsw i32 %2579, %2578" -> "  %2584 = lshr i32 %2580, 16"
"  %2581 = lshr i32 %2577, 16"
"  %2581 = lshr i32 %2577, 16" -> "  %2583 = add nuw nsw i32 %2581, %2582"
"  %2582 = mul nuw nsw i32 %1047, 29744"
"  %2582 = mul nuw nsw i32 %1047, 29744" -> "  %2583 = add nuw nsw i32 %2581, %2582"
"  %2583 = add nuw nsw i32 %2581, %2582"
"  %2583 = add nuw nsw i32 %2581, %2582" -> "  %2587 = and i32 %2583, 2147418112""  %2583 = add nuw nsw i32 %2581, %2582" -> "  %2585 = and i32 %2583, 65535"
"  %2584 = lshr i32 %2580, 16"
"  %2584 = lshr i32 %2580, 16" -> "  %2586 = add nuw nsw i32 %2584, %2585"
"  %2585 = and i32 %2583, 65535"
"  %2585 = and i32 %2583, 65535" -> "  %2586 = add nuw nsw i32 %2584, %2585"
"  %2586 = add nuw nsw i32 %2584, %2585"
"  %2586 = add nuw nsw i32 %2584, %2585" -> "  %2588 = add nuw nsw i32 %2586, %2587"
"  %2587 = and i32 %2583, 2147418112"
"  %2587 = and i32 %2583, 2147418112" -> "  %2588 = add nuw nsw i32 %2586, %2587"
"  %2588 = add nuw nsw i32 %2586, %2587"
"  %2588 = add nuw nsw i32 %2586, %2587" -> "  %2596 = add nuw nsw i32 %2588, %2595"
"  %2589 = and i32 %2560, 65535"
"  %2589 = and i32 %2560, 65535" -> "  %2591 = add nuw nsw i32 %2589, %2590"
"  %2590 = and i32 %2571, 65535"
"  %2590 = and i32 %2571, 65535" -> "  %2591 = add nuw nsw i32 %2589, %2590"
"  %2591 = add nuw nsw i32 %2589, %2590"
"  %2591 = add nuw nsw i32 %2589, %2590" -> "  %3209 = and i32 %2591, 65535""  %2591 = add nuw nsw i32 %2589, %2590" -> "  %2598 = lshr i32 %2591, 16"
"  %2592 = and i32 %2568, 65535"
"  %2592 = and i32 %2568, 65535" -> "  %2594 = add nuw nsw i32 %2592, %2593"
"  %2593 = and i32 %2580, 65535"
"  %2593 = and i32 %2580, 65535" -> "  %2594 = add nuw nsw i32 %2592, %2593"
"  %2594 = add nuw nsw i32 %2592, %2593"
"  %2594 = add nuw nsw i32 %2592, %2593" -> "  %2597 = and i32 %2594, 65535""  %2594 = add nuw nsw i32 %2592, %2593" -> "  %2595 = lshr i32 %2594, 16"
"  %2595 = lshr i32 %2594, 16"
"  %2595 = lshr i32 %2594, 16" -> "  %2596 = add nuw nsw i32 %2588, %2595"
"  %2596 = add nuw nsw i32 %2588, %2595"
"  %2596 = add nuw nsw i32 %2588, %2595" -> "  %2601 = add nuw nsw i32 %2596, %2600"
"  %2597 = and i32 %2594, 65535"
"  %2597 = and i32 %2594, 65535" -> "  %2599 = add nuw nsw i32 %2597, %2598"
"  %2598 = lshr i32 %2591, 16"
"  %2598 = lshr i32 %2591, 16" -> "  %2599 = add nuw nsw i32 %2597, %2598"
"  %2599 = add nuw nsw i32 %2597, %2598"
"  %2599 = add nuw nsw i32 %2597, %2598" -> "  %3212 = and i32 %2599, 65535""  %2599 = add nuw nsw i32 %2597, %2598" -> "  %2600 = lshr i32 %2599, 16"
"  %2600 = lshr i32 %2599, 16"
"  %2600 = lshr i32 %2599, 16" -> "  %2601 = add nuw nsw i32 %2596, %2600"
"  %2601 = add nuw nsw i32 %2596, %2600"
"  %2601 = add nuw nsw i32 %2596, %2600" -> "  %2637 = lshr i32 %2601, 16""  %2601 = add nuw nsw i32 %2596, %2600" -> "  %2634 = and i32 %2601, 65535"
"  %2602 = mul nuw nsw i32 %1064, 24315"
"  %2602 = mul nuw nsw i32 %1064, 24315" -> "  %2621 = and i32 %2602, 65535""  %2602 = mul nuw nsw i32 %1064, 24315" -> "  %2603 = lshr i32 %2602, 16"
"  %2603 = lshr i32 %2602, 16"
"  %2603 = lshr i32 %2602, 16" -> "  %2606 = add nuw nsw i32 %2605, %2603"
"  %2604 = mul nuw nsw i32 %1065, 24315"
"  %2604 = mul nuw nsw i32 %1065, 24315" -> "  %2607 = and i32 %2604, 2147418112""  %2604 = mul nuw nsw i32 %1065, 24315" -> "  %2605 = and i32 %2604, 65535"
"  %2605 = and i32 %2604, 65535"
"  %2605 = and i32 %2604, 65535" -> "  %2606 = add nuw nsw i32 %2605, %2603"
"  %2606 = add nuw nsw i32 %2605, %2603"
"  %2606 = add nuw nsw i32 %2605, %2603" -> "  %2608 = add nuw nsw i32 %2606, %2607"
"  %2607 = and i32 %2604, 2147418112"
"  %2607 = and i32 %2604, 2147418112" -> "  %2608 = add nuw nsw i32 %2606, %2607"
"  %2608 = add nuw nsw i32 %2606, %2607"
"  %2608 = add nuw nsw i32 %2606, %2607" -> "  %2612 = lshr i32 %2608, 16""  %2608 = add nuw nsw i32 %2606, %2607" -> "  %2610 = and i32 %2608, 65535"
"  %2609 = mul nuw nsw i32 %1064, 29744"
"  %2609 = mul nuw nsw i32 %1064, 29744" -> "  %2611 = add nuw nsw i32 %2610, %2609"
"  %2610 = and i32 %2608, 65535"
"  %2610 = and i32 %2608, 65535" -> "  %2611 = add nuw nsw i32 %2610, %2609"
"  %2611 = add nuw nsw i32 %2610, %2609"
"  %2611 = add nuw nsw i32 %2610, %2609" -> "  %2623 = and i32 %2611, 65535""  %2611 = add nuw nsw i32 %2610, %2609" -> "  %2615 = lshr i32 %2611, 16"
"  %2612 = lshr i32 %2608, 16"
"  %2612 = lshr i32 %2608, 16" -> "  %2614 = add nuw nsw i32 %2612, %2613"
"  %2613 = mul nuw nsw i32 %1065, 29744"
"  %2613 = mul nuw nsw i32 %1065, 29744" -> "  %2614 = add nuw nsw i32 %2612, %2613"
"  %2614 = add nuw nsw i32 %2612, %2613"
"  %2614 = add nuw nsw i32 %2612, %2613" -> "  %2618 = and i32 %2614, 2147418112""  %2614 = add nuw nsw i32 %2612, %2613" -> "  %2616 = and i32 %2614, 65535"
"  %2615 = lshr i32 %2611, 16"
"  %2615 = lshr i32 %2611, 16" -> "  %2617 = add nuw nsw i32 %2615, %2616"
"  %2616 = and i32 %2614, 65535"
"  %2616 = and i32 %2614, 65535" -> "  %2617 = add nuw nsw i32 %2615, %2616"
"  %2617 = add nuw nsw i32 %2615, %2616"
"  %2617 = add nuw nsw i32 %2615, %2616" -> "  %2619 = add nuw nsw i32 %2617, %2618"
"  %2618 = and i32 %2614, 2147418112"
"  %2618 = and i32 %2614, 2147418112" -> "  %2619 = add nuw nsw i32 %2617, %2618"
"  %2619 = add nuw nsw i32 %2617, %2618"
"  %2619 = add nuw nsw i32 %2617, %2618" -> "  %2627 = add nuw nsw i32 %2619, %2626"
"  %2620 = and i32 %2570, 65535"
"  %2620 = and i32 %2570, 65535" -> "  %2622 = add nuw nsw i32 %2620, %2621"
"  %2621 = and i32 %2602, 65535"
"  %2621 = and i32 %2602, 65535" -> "  %2622 = add nuw nsw i32 %2620, %2621"
"  %2622 = add nuw nsw i32 %2620, %2621"
"  %2622 = add nuw nsw i32 %2620, %2621" -> "  %2633 = and i32 %2622, 65535""  %2622 = add nuw nsw i32 %2620, %2621" -> "  %2629 = lshr i32 %2622, 16"
"  %2623 = and i32 %2611, 65535"
"  %2623 = and i32 %2611, 65535" -> "  %2625 = add nuw nsw i32 %2624, %2623"
"  %2624 = lshr i32 %2570, 16"
"  %2624 = lshr i32 %2570, 16" -> "  %2625 = add nuw nsw i32 %2624, %2623"
"  %2625 = add nuw nsw i32 %2624, %2623"
"  %2625 = add nuw nsw i32 %2624, %2623" -> "  %2628 = and i32 %2625, 65535""  %2625 = add nuw nsw i32 %2624, %2623" -> "  %2626 = lshr i32 %2625, 16"
"  %2626 = lshr i32 %2625, 16"
"  %2626 = lshr i32 %2625, 16" -> "  %2627 = add nuw nsw i32 %2619, %2626"
"  %2627 = add nuw nsw i32 %2619, %2626"
"  %2627 = add nuw nsw i32 %2619, %2626" -> "  %2632 = add nuw nsw i32 %2627, %2631"
"  %2628 = and i32 %2625, 65535"
"  %2628 = and i32 %2625, 65535" -> "  %2630 = add nuw nsw i32 %2628, %2629"
"  %2629 = lshr i32 %2622, 16"
"  %2629 = lshr i32 %2622, 16" -> "  %2630 = add nuw nsw i32 %2628, %2629"
"  %2630 = add nuw nsw i32 %2628, %2629"
"  %2630 = add nuw nsw i32 %2628, %2629" -> "  %2636 = and i32 %2630, 65535""  %2630 = add nuw nsw i32 %2628, %2629" -> "  %2631 = lshr i32 %2630, 16"
"  %2631 = lshr i32 %2630, 16"
"  %2631 = lshr i32 %2630, 16" -> "  %2632 = add nuw nsw i32 %2627, %2631"
"  %2632 = add nuw nsw i32 %2627, %2631"
"  %2632 = add nuw nsw i32 %2627, %2631" -> "  %2645 = and i32 %2632, 2147418112""  %2632 = add nuw nsw i32 %2627, %2631" -> "  %2643 = and i32 %2632, 65535"
"  %2633 = and i32 %2622, 65535"
"  %2633 = and i32 %2622, 65535" -> "  %2635 = add nuw nsw i32 %2634, %2633"
"  %2634 = and i32 %2601, 65535"
"  %2634 = and i32 %2601, 65535" -> "  %2635 = add nuw nsw i32 %2634, %2633"
"  %2635 = add nuw nsw i32 %2634, %2633"
"  %2635 = add nuw nsw i32 %2634, %2633" -> "  %2777 = and i32 %2635, 65535""  %2635 = add nuw nsw i32 %2634, %2633" -> "  %2639 = lshr i32 %2635, 16"
"  %2636 = and i32 %2630, 65535"
"  %2636 = and i32 %2630, 65535" -> "  %2638 = add nuw nsw i32 %2636, %2637"
"  %2637 = lshr i32 %2601, 16"
"  %2637 = lshr i32 %2601, 16" -> "  %2638 = add nuw nsw i32 %2636, %2637"
"  %2638 = add nuw nsw i32 %2636, %2637"
"  %2638 = add nuw nsw i32 %2636, %2637" -> "  %2642 = lshr i32 %2638, 16""  %2638 = add nuw nsw i32 %2636, %2637" -> "  %2640 = and i32 %2638, 65535"
"  %2639 = lshr i32 %2635, 16"
"  %2639 = lshr i32 %2635, 16" -> "  %2641 = add nuw nsw i32 %2640, %2639"
"  %2640 = and i32 %2638, 65535"
"  %2640 = and i32 %2638, 65535" -> "  %2641 = add nuw nsw i32 %2640, %2639"
"  %2641 = add nuw nsw i32 %2640, %2639"
"  %2641 = add nuw nsw i32 %2640, %2639" -> "  %2783 = and i32 %2641, 65535""  %2641 = add nuw nsw i32 %2640, %2639" -> "  %2647 = lshr i32 %2641, 16"
"  %2642 = lshr i32 %2638, 16"
"  %2642 = lshr i32 %2638, 16" -> "  %2644 = add nuw nsw i32 %2642, %2643"
"  %2643 = and i32 %2632, 65535"
"  %2643 = and i32 %2632, 65535" -> "  %2644 = add nuw nsw i32 %2642, %2643"
"  %2644 = add nuw nsw i32 %2642, %2643"
"  %2644 = add nuw nsw i32 %2642, %2643" -> "  %2646 = add nuw nsw i32 %2644, %2645"
"  %2645 = and i32 %2632, 2147418112"
"  %2645 = and i32 %2632, 2147418112" -> "  %2646 = add nuw nsw i32 %2644, %2645"
"  %2646 = add nuw nsw i32 %2644, %2645"
"  %2646 = add nuw nsw i32 %2644, %2645" -> "  %2648 = add nuw nsw i32 %2646, %2647"
"  %2647 = lshr i32 %2641, 16"
"  %2647 = lshr i32 %2641, 16" -> "  %2648 = add nuw nsw i32 %2646, %2647"
"  %2648 = add nuw nsw i32 %2646, %2647"
"  %2648 = add nuw nsw i32 %2646, %2647" -> "  %2794 = and i32 %2648, 65535""  %2648 = add nuw nsw i32 %2646, %2647" -> "  %2797 = lshr i32 %2648, 16"
"  %2649 = mul nuw i32 %1178, 42779"
"  %2649 = mul nuw i32 %1178, 42779" -> "  %2776 = and i32 %2649, 65535""  %2649 = mul nuw i32 %1178, 42779" -> "  %2650 = lshr i32 %2649, 16"
"  %2650 = lshr i32 %2649, 16"
"  %2650 = lshr i32 %2649, 16" -> "  %2653 = add nuw nsw i32 %2652, %2650"
"  %2651 = mul nuw i32 %1179, 42779"
"  %2651 = mul nuw i32 %1179, 42779" -> "  %2654 = and i32 %2651, -65536""  %2651 = mul nuw i32 %1179, 42779" -> "  %2652 = and i32 %2651, 65535"
"  %2652 = and i32 %2651, 65535"
"  %2652 = and i32 %2651, 65535" -> "  %2653 = add nuw nsw i32 %2652, %2650"
"  %2653 = add nuw nsw i32 %2652, %2650"
"  %2653 = add nuw nsw i32 %2652, %2650" -> "  %2655 = add nuw i32 %2653, %2654"
"  %2654 = and i32 %2651, -65536"
"  %2654 = and i32 %2651, -65536" -> "  %2655 = add nuw i32 %2653, %2654"
"  %2655 = add nuw i32 %2653, %2654"
"  %2655 = add nuw i32 %2653, %2654" -> "  %2659 = lshr i32 %2655, 16""  %2655 = add nuw i32 %2653, %2654" -> "  %2657 = and i32 %2655, 65535"
"  %2656 = mul nuw nsw i32 %1178, 9871"
"  %2656 = mul nuw nsw i32 %1178, 9871" -> "  %2658 = add nuw nsw i32 %2657, %2656"
"  %2657 = and i32 %2655, 65535"
"  %2657 = and i32 %2655, 65535" -> "  %2658 = add nuw nsw i32 %2657, %2656"
"  %2658 = add nuw nsw i32 %2657, %2656"
"  %2658 = add nuw nsw i32 %2657, %2656" -> "  %2782 = and i32 %2658, 65535""  %2658 = add nuw nsw i32 %2657, %2656" -> "  %2662 = lshr i32 %2658, 16"
"  %2659 = lshr i32 %2655, 16"
"  %2659 = lshr i32 %2655, 16" -> "  %2661 = add nuw nsw i32 %2659, %2660"
"  %2660 = mul nuw nsw i32 %1179, 9871"
"  %2660 = mul nuw nsw i32 %1179, 9871" -> "  %2661 = add nuw nsw i32 %2659, %2660"
"  %2661 = add nuw nsw i32 %2659, %2660"
"  %2661 = add nuw nsw i32 %2659, %2660" -> "  %2665 = and i32 %2661, 2147418112""  %2661 = add nuw nsw i32 %2659, %2660" -> "  %2663 = and i32 %2661, 65535"
"  %2662 = lshr i32 %2658, 16"
"  %2662 = lshr i32 %2658, 16" -> "  %2664 = add nuw nsw i32 %2662, %2663"
"  %2663 = and i32 %2661, 65535"
"  %2663 = and i32 %2661, 65535" -> "  %2664 = add nuw nsw i32 %2662, %2663"
"  %2664 = add nuw nsw i32 %2662, %2663"
"  %2664 = add nuw nsw i32 %2662, %2663" -> "  %2666 = add nuw nsw i32 %2664, %2665"
"  %2665 = and i32 %2661, 2147418112"
"  %2665 = and i32 %2661, 2147418112" -> "  %2666 = add nuw nsw i32 %2664, %2665"
"  %2666 = add nuw nsw i32 %2664, %2665"
"  %2666 = add nuw nsw i32 %2664, %2665" -> "  %2689 = lshr i32 %2666, 16""  %2666 = add nuw nsw i32 %2664, %2665" -> "  %2685 = and i32 %2666, 65535"
"  %2667 = mul nuw i32 %1198, 42779"
"  %2667 = mul nuw i32 %1198, 42779" -> "  %2686 = and i32 %2667, 65535""  %2667 = mul nuw i32 %1198, 42779" -> "  %2668 = lshr i32 %2667, 16"
"  %2668 = lshr i32 %2667, 16"
"  %2668 = lshr i32 %2667, 16" -> "  %2671 = add nuw nsw i32 %2670, %2668"
"  %2669 = mul nuw i32 %1201, 42779"
"  %2669 = mul nuw i32 %1201, 42779" -> "  %2672 = and i32 %2669, -65536""  %2669 = mul nuw i32 %1201, 42779" -> "  %2670 = and i32 %2669, 65535"
"  %2670 = and i32 %2669, 65535"
"  %2670 = and i32 %2669, 65535" -> "  %2671 = add nuw nsw i32 %2670, %2668"
"  %2671 = add nuw nsw i32 %2670, %2668"
"  %2671 = add nuw nsw i32 %2670, %2668" -> "  %2673 = add nuw i32 %2671, %2672"
"  %2672 = and i32 %2669, -65536"
"  %2672 = and i32 %2669, -65536" -> "  %2673 = add nuw i32 %2671, %2672"
"  %2673 = add nuw i32 %2671, %2672"
"  %2673 = add nuw i32 %2671, %2672" -> "  %2677 = lshr i32 %2673, 16""  %2673 = add nuw i32 %2671, %2672" -> "  %2675 = and i32 %2673, 65535"
"  %2674 = mul nuw nsw i32 %1198, 9871"
"  %2674 = mul nuw nsw i32 %1198, 9871" -> "  %2676 = add nuw nsw i32 %2675, %2674"
"  %2675 = and i32 %2673, 65535"
"  %2675 = and i32 %2673, 65535" -> "  %2676 = add nuw nsw i32 %2675, %2674"
"  %2676 = add nuw nsw i32 %2675, %2674"
"  %2676 = add nuw nsw i32 %2675, %2674" -> "  %2688 = and i32 %2676, 65535""  %2676 = add nuw nsw i32 %2675, %2674" -> "  %2680 = lshr i32 %2676, 16"
"  %2677 = lshr i32 %2673, 16"
"  %2677 = lshr i32 %2673, 16" -> "  %2679 = add nuw nsw i32 %2677, %2678"
"  %2678 = mul nuw nsw i32 %1201, 9871"
"  %2678 = mul nuw nsw i32 %1201, 9871" -> "  %2679 = add nuw nsw i32 %2677, %2678"
"  %2679 = add nuw nsw i32 %2677, %2678"
"  %2679 = add nuw nsw i32 %2677, %2678" -> "  %2683 = and i32 %2679, 2147418112""  %2679 = add nuw nsw i32 %2677, %2678" -> "  %2681 = and i32 %2679, 65535"
"  %2680 = lshr i32 %2676, 16"
"  %2680 = lshr i32 %2676, 16" -> "  %2682 = add nuw nsw i32 %2680, %2681"
"  %2681 = and i32 %2679, 65535"
"  %2681 = and i32 %2679, 65535" -> "  %2682 = add nuw nsw i32 %2680, %2681"
"  %2682 = add nuw nsw i32 %2680, %2681"
"  %2682 = add nuw nsw i32 %2680, %2681" -> "  %2684 = add nuw nsw i32 %2682, %2683"
"  %2683 = and i32 %2679, 2147418112"
"  %2683 = and i32 %2679, 2147418112" -> "  %2684 = add nuw nsw i32 %2682, %2683"
"  %2684 = add nuw nsw i32 %2682, %2683"
"  %2684 = add nuw nsw i32 %2682, %2683" -> "  %2692 = add nuw nsw i32 %2684, %2691"
"  %2685 = and i32 %2666, 65535"
"  %2685 = and i32 %2666, 65535" -> "  %2687 = add nuw nsw i32 %2685, %2686"
"  %2686 = and i32 %2667, 65535"
"  %2686 = and i32 %2667, 65535" -> "  %2687 = add nuw nsw i32 %2685, %2686"
"  %2687 = add nuw nsw i32 %2685, %2686"
"  %2687 = add nuw nsw i32 %2685, %2686" -> "  %2716 = and i32 %2687, 65535""  %2687 = add nuw nsw i32 %2685, %2686" -> "  %2694 = lshr i32 %2687, 16"
"  %2688 = and i32 %2676, 65535"
"  %2688 = and i32 %2676, 65535" -> "  %2690 = add nuw nsw i32 %2688, %2689"
"  %2689 = lshr i32 %2666, 16"
"  %2689 = lshr i32 %2666, 16" -> "  %2690 = add nuw nsw i32 %2688, %2689"
"  %2690 = add nuw nsw i32 %2688, %2689"
"  %2690 = add nuw nsw i32 %2688, %2689" -> "  %2693 = and i32 %2690, 65535""  %2690 = add nuw nsw i32 %2688, %2689" -> "  %2691 = lshr i32 %2690, 16"
"  %2691 = lshr i32 %2690, 16"
"  %2691 = lshr i32 %2690, 16" -> "  %2692 = add nuw nsw i32 %2684, %2691"
"  %2692 = add nuw nsw i32 %2684, %2691"
"  %2692 = add nuw nsw i32 %2684, %2691" -> "  %2697 = add nuw nsw i32 %2692, %2696"
"  %2693 = and i32 %2690, 65535"
"  %2693 = and i32 %2690, 65535" -> "  %2695 = add nuw nsw i32 %2693, %2694"
"  %2694 = lshr i32 %2687, 16"
"  %2694 = lshr i32 %2687, 16" -> "  %2695 = add nuw nsw i32 %2693, %2694"
"  %2695 = add nuw nsw i32 %2693, %2694"
"  %2695 = add nuw nsw i32 %2693, %2694" -> "  %2719 = and i32 %2695, 65535""  %2695 = add nuw nsw i32 %2693, %2694" -> "  %2696 = lshr i32 %2695, 16"
"  %2696 = lshr i32 %2695, 16"
"  %2696 = lshr i32 %2695, 16" -> "  %2697 = add nuw nsw i32 %2692, %2696"
"  %2697 = add nuw nsw i32 %2692, %2696"
"  %2697 = add nuw nsw i32 %2692, %2696" -> "  %2747 = and i32 %2697, 65535""  %2697 = add nuw nsw i32 %2692, %2696" -> "  %2751 = lshr i32 %2697, 16"
"  %2698 = mul nuw nsw i32 %1178, 24315"
"  %2698 = mul nuw nsw i32 %1178, 24315" -> "  %2717 = and i32 %2698, 65535""  %2698 = mul nuw nsw i32 %1178, 24315" -> "  %2699 = lshr i32 %2698, 16"
"  %2699 = lshr i32 %2698, 16"
"  %2699 = lshr i32 %2698, 16" -> "  %2702 = add nuw nsw i32 %2701, %2699"
"  %2700 = mul nuw nsw i32 %1179, 24315"
"  %2700 = mul nuw nsw i32 %1179, 24315" -> "  %2703 = and i32 %2700, 2147418112""  %2700 = mul nuw nsw i32 %1179, 24315" -> "  %2701 = and i32 %2700, 65535"
"  %2701 = and i32 %2700, 65535"
"  %2701 = and i32 %2700, 65535" -> "  %2702 = add nuw nsw i32 %2701, %2699"
"  %2702 = add nuw nsw i32 %2701, %2699"
"  %2702 = add nuw nsw i32 %2701, %2699" -> "  %2704 = add nuw nsw i32 %2702, %2703"
"  %2703 = and i32 %2700, 2147418112"
"  %2703 = and i32 %2700, 2147418112" -> "  %2704 = add nuw nsw i32 %2702, %2703"
"  %2704 = add nuw nsw i32 %2702, %2703"
"  %2704 = add nuw nsw i32 %2702, %2703" -> "  %2708 = lshr i32 %2704, 16""  %2704 = add nuw nsw i32 %2702, %2703" -> "  %2706 = and i32 %2704, 65535"
"  %2705 = mul nuw nsw i32 %1178, 29744"
"  %2705 = mul nuw nsw i32 %1178, 29744" -> "  %2707 = add nuw nsw i32 %2706, %2705"
"  %2706 = and i32 %2704, 65535"
"  %2706 = and i32 %2704, 65535" -> "  %2707 = add nuw nsw i32 %2706, %2705"
"  %2707 = add nuw nsw i32 %2706, %2705"
"  %2707 = add nuw nsw i32 %2706, %2705" -> "  %2720 = and i32 %2707, 65535""  %2707 = add nuw nsw i32 %2706, %2705" -> "  %2711 = lshr i32 %2707, 16"
"  %2708 = lshr i32 %2704, 16"
"  %2708 = lshr i32 %2704, 16" -> "  %2710 = add nuw nsw i32 %2708, %2709"
"  %2709 = mul nuw nsw i32 %1179, 29744"
"  %2709 = mul nuw nsw i32 %1179, 29744" -> "  %2710 = add nuw nsw i32 %2708, %2709"
"  %2710 = add nuw nsw i32 %2708, %2709"
"  %2710 = add nuw nsw i32 %2708, %2709" -> "  %2714 = and i32 %2710, 2147418112""  %2710 = add nuw nsw i32 %2708, %2709" -> "  %2712 = and i32 %2710, 65535"
"  %2711 = lshr i32 %2707, 16"
"  %2711 = lshr i32 %2707, 16" -> "  %2713 = add nuw nsw i32 %2711, %2712"
"  %2712 = and i32 %2710, 65535"
"  %2712 = and i32 %2710, 65535" -> "  %2713 = add nuw nsw i32 %2711, %2712"
"  %2713 = add nuw nsw i32 %2711, %2712"
"  %2713 = add nuw nsw i32 %2711, %2712" -> "  %2715 = add nuw nsw i32 %2713, %2714"
"  %2714 = and i32 %2710, 2147418112"
"  %2714 = and i32 %2710, 2147418112" -> "  %2715 = add nuw nsw i32 %2713, %2714"
"  %2715 = add nuw nsw i32 %2713, %2714"
"  %2715 = add nuw nsw i32 %2713, %2714" -> "  %2723 = add nuw nsw i32 %2715, %2722"
"  %2716 = and i32 %2687, 65535"
"  %2716 = and i32 %2687, 65535" -> "  %2718 = add nuw nsw i32 %2716, %2717"
"  %2717 = and i32 %2698, 65535"
"  %2717 = and i32 %2698, 65535" -> "  %2718 = add nuw nsw i32 %2716, %2717"
"  %2718 = add nuw nsw i32 %2716, %2717"
"  %2718 = add nuw nsw i32 %2716, %2717" -> "  %2795 = and i32 %2718, 65535""  %2718 = add nuw nsw i32 %2716, %2717" -> "  %2725 = lshr i32 %2718, 16"
"  %2719 = and i32 %2695, 65535"
"  %2719 = and i32 %2695, 65535" -> "  %2721 = add nuw nsw i32 %2719, %2720"
"  %2720 = and i32 %2707, 65535"
"  %2720 = and i32 %2707, 65535" -> "  %2721 = add nuw nsw i32 %2719, %2720"
"  %2721 = add nuw nsw i32 %2719, %2720"
"  %2721 = add nuw nsw i32 %2719, %2720" -> "  %2724 = and i32 %2721, 65535""  %2721 = add nuw nsw i32 %2719, %2720" -> "  %2722 = lshr i32 %2721, 16"
"  %2722 = lshr i32 %2721, 16"
"  %2722 = lshr i32 %2721, 16" -> "  %2723 = add nuw nsw i32 %2715, %2722"
"  %2723 = add nuw nsw i32 %2715, %2722"
"  %2723 = add nuw nsw i32 %2715, %2722" -> "  %2728 = add nuw nsw i32 %2723, %2727"
"  %2724 = and i32 %2721, 65535"
"  %2724 = and i32 %2721, 65535" -> "  %2726 = add nuw nsw i32 %2724, %2725"
"  %2725 = lshr i32 %2718, 16"
"  %2725 = lshr i32 %2718, 16" -> "  %2726 = add nuw nsw i32 %2724, %2725"
"  %2726 = add nuw nsw i32 %2724, %2725"
"  %2726 = add nuw nsw i32 %2724, %2725" -> "  %2798 = and i32 %2726, 65535""  %2726 = add nuw nsw i32 %2724, %2725" -> "  %2727 = lshr i32 %2726, 16"
"  %2727 = lshr i32 %2726, 16"
"  %2727 = lshr i32 %2726, 16" -> "  %2728 = add nuw nsw i32 %2723, %2727"
"  %2728 = add nuw nsw i32 %2723, %2727"
"  %2728 = add nuw nsw i32 %2723, %2727" -> "  %2761 = and i32 %2728, 65535""  %2728 = add nuw nsw i32 %2723, %2727" -> "  %2764 = lshr i32 %2728, 16"
"  %2729 = mul nuw nsw i32 %1198, 24315"
"  %2729 = mul nuw nsw i32 %1198, 24315" -> "  %2748 = and i32 %2729, 65535""  %2729 = mul nuw nsw i32 %1198, 24315" -> "  %2730 = lshr i32 %2729, 16"
"  %2730 = lshr i32 %2729, 16"
"  %2730 = lshr i32 %2729, 16" -> "  %2733 = add nuw nsw i32 %2732, %2730"
"  %2731 = mul nuw nsw i32 %1201, 24315"
"  %2731 = mul nuw nsw i32 %1201, 24315" -> "  %2732 = and i32 %2731, 65535""  %2731 = mul nuw nsw i32 %1201, 24315" -> "  %2734 = and i32 %2731, 2147418112"
"  %2732 = and i32 %2731, 65535"
"  %2732 = and i32 %2731, 65535" -> "  %2733 = add nuw nsw i32 %2732, %2730"
"  %2733 = add nuw nsw i32 %2732, %2730"
"  %2733 = add nuw nsw i32 %2732, %2730" -> "  %2735 = add nuw nsw i32 %2733, %2734"
"  %2734 = and i32 %2731, 2147418112"
"  %2734 = and i32 %2731, 2147418112" -> "  %2735 = add nuw nsw i32 %2733, %2734"
"  %2735 = add nuw nsw i32 %2733, %2734"
"  %2735 = add nuw nsw i32 %2733, %2734" -> "  %2739 = lshr i32 %2735, 16""  %2735 = add nuw nsw i32 %2733, %2734" -> "  %2737 = and i32 %2735, 65535"
"  %2736 = mul nuw nsw i32 %1198, 29744"
"  %2736 = mul nuw nsw i32 %1198, 29744" -> "  %2738 = add nuw nsw i32 %2737, %2736"
"  %2737 = and i32 %2735, 65535"
"  %2737 = and i32 %2735, 65535" -> "  %2738 = add nuw nsw i32 %2737, %2736"
"  %2738 = add nuw nsw i32 %2737, %2736"
"  %2738 = add nuw nsw i32 %2737, %2736" -> "  %2750 = and i32 %2738, 65535""  %2738 = add nuw nsw i32 %2737, %2736" -> "  %2742 = lshr i32 %2738, 16"
"  %2739 = lshr i32 %2735, 16"
"  %2739 = lshr i32 %2735, 16" -> "  %2741 = add nuw nsw i32 %2739, %2740"
"  %2740 = mul nuw nsw i32 %1201, 29744"
"  %2740 = mul nuw nsw i32 %1201, 29744" -> "  %2741 = add nuw nsw i32 %2739, %2740"
"  %2741 = add nuw nsw i32 %2739, %2740"
"  %2741 = add nuw nsw i32 %2739, %2740" -> "  %2745 = and i32 %2741, 2147418112""  %2741 = add nuw nsw i32 %2739, %2740" -> "  %2743 = and i32 %2741, 65535"
"  %2742 = lshr i32 %2738, 16"
"  %2742 = lshr i32 %2738, 16" -> "  %2744 = add nuw nsw i32 %2743, %2742"
"  %2743 = and i32 %2741, 65535"
"  %2743 = and i32 %2741, 65535" -> "  %2744 = add nuw nsw i32 %2743, %2742"
"  %2744 = add nuw nsw i32 %2743, %2742"
"  %2744 = add nuw nsw i32 %2743, %2742" -> "  %2746 = add nuw nsw i32 %2744, %2745"
"  %2745 = and i32 %2741, 2147418112"
"  %2745 = and i32 %2741, 2147418112" -> "  %2746 = add nuw nsw i32 %2744, %2745"
"  %2746 = add nuw nsw i32 %2744, %2745"
"  %2746 = add nuw nsw i32 %2744, %2745" -> "  %2754 = add nuw nsw i32 %2746, %2753"
"  %2747 = and i32 %2697, 65535"
"  %2747 = and i32 %2697, 65535" -> "  %2749 = add nuw nsw i32 %2747, %2748"
"  %2748 = and i32 %2729, 65535"
"  %2748 = and i32 %2729, 65535" -> "  %2749 = add nuw nsw i32 %2747, %2748"
"  %2749 = add nuw nsw i32 %2747, %2748"
"  %2749 = add nuw nsw i32 %2747, %2748" -> "  %2760 = and i32 %2749, 65535""  %2749 = add nuw nsw i32 %2747, %2748" -> "  %2756 = lshr i32 %2749, 16"
"  %2750 = and i32 %2738, 65535"
"  %2750 = and i32 %2738, 65535" -> "  %2752 = add nuw nsw i32 %2751, %2750"
"  %2751 = lshr i32 %2697, 16"
"  %2751 = lshr i32 %2697, 16" -> "  %2752 = add nuw nsw i32 %2751, %2750"
"  %2752 = add nuw nsw i32 %2751, %2750"
"  %2752 = add nuw nsw i32 %2751, %2750" -> "  %2755 = and i32 %2752, 65535""  %2752 = add nuw nsw i32 %2751, %2750" -> "  %2753 = lshr i32 %2752, 16"
"  %2753 = lshr i32 %2752, 16"
"  %2753 = lshr i32 %2752, 16" -> "  %2754 = add nuw nsw i32 %2746, %2753"
"  %2754 = add nuw nsw i32 %2746, %2753"
"  %2754 = add nuw nsw i32 %2746, %2753" -> "  %2759 = add nuw nsw i32 %2754, %2758"
"  %2755 = and i32 %2752, 65535"
"  %2755 = and i32 %2752, 65535" -> "  %2757 = add nuw nsw i32 %2755, %2756"
"  %2756 = lshr i32 %2749, 16"
"  %2756 = lshr i32 %2749, 16" -> "  %2757 = add nuw nsw i32 %2755, %2756"
"  %2757 = add nuw nsw i32 %2755, %2756"
"  %2757 = add nuw nsw i32 %2755, %2756" -> "  %2763 = and i32 %2757, 65535""  %2757 = add nuw nsw i32 %2755, %2756" -> "  %2758 = lshr i32 %2757, 16"
"  %2758 = lshr i32 %2757, 16"
"  %2758 = lshr i32 %2757, 16" -> "  %2759 = add nuw nsw i32 %2754, %2758"
"  %2759 = add nuw nsw i32 %2754, %2758"
"  %2759 = add nuw nsw i32 %2754, %2758" -> "  %2772 = and i32 %2759, 2147418112""  %2759 = add nuw nsw i32 %2754, %2758" -> "  %2770 = and i32 %2759, 65535"
"  %2760 = and i32 %2749, 65535"
"  %2760 = and i32 %2749, 65535" -> "  %2762 = add nuw nsw i32 %2761, %2760"
"  %2761 = and i32 %2728, 65535"
"  %2761 = and i32 %2728, 65535" -> "  %2762 = add nuw nsw i32 %2761, %2760"
"  %2762 = add nuw nsw i32 %2761, %2760"
"  %2762 = add nuw nsw i32 %2761, %2760" -> "  %2808 = and i32 %2762, 65535""  %2762 = add nuw nsw i32 %2761, %2760" -> "  %2766 = lshr i32 %2762, 16"
"  %2763 = and i32 %2757, 65535"
"  %2763 = and i32 %2757, 65535" -> "  %2765 = add nuw nsw i32 %2763, %2764"
"  %2764 = lshr i32 %2728, 16"
"  %2764 = lshr i32 %2728, 16" -> "  %2765 = add nuw nsw i32 %2763, %2764"
"  %2765 = add nuw nsw i32 %2763, %2764"
"  %2765 = add nuw nsw i32 %2763, %2764" -> "  %2769 = lshr i32 %2765, 16""  %2765 = add nuw nsw i32 %2763, %2764" -> "  %2767 = and i32 %2765, 65535"
"  %2766 = lshr i32 %2762, 16"
"  %2766 = lshr i32 %2762, 16" -> "  %2768 = add nuw nsw i32 %2767, %2766"
"  %2767 = and i32 %2765, 65535"
"  %2767 = and i32 %2765, 65535" -> "  %2768 = add nuw nsw i32 %2767, %2766"
"  %2768 = add nuw nsw i32 %2767, %2766"
"  %2768 = add nuw nsw i32 %2767, %2766" -> "  %2818 = and i32 %2768, 65535""  %2768 = add nuw nsw i32 %2767, %2766" -> "  %2774 = lshr i32 %2768, 16"
"  %2769 = lshr i32 %2765, 16"
"  %2769 = lshr i32 %2765, 16" -> "  %2771 = add nuw nsw i32 %2769, %2770"
"  %2770 = and i32 %2759, 65535"
"  %2770 = and i32 %2759, 65535" -> "  %2771 = add nuw nsw i32 %2769, %2770"
"  %2771 = add nuw nsw i32 %2769, %2770"
"  %2771 = add nuw nsw i32 %2769, %2770" -> "  %2773 = add nuw nsw i32 %2771, %2772"
"  %2772 = and i32 %2759, 2147418112"
"  %2772 = and i32 %2759, 2147418112" -> "  %2773 = add nuw nsw i32 %2771, %2772"
"  %2773 = add nuw nsw i32 %2771, %2772"
"  %2773 = add nuw nsw i32 %2771, %2772" -> "  %2775 = add nuw nsw i32 %2773, %2774"
"  %2774 = lshr i32 %2768, 16"
"  %2774 = lshr i32 %2768, 16" -> "  %2775 = add nuw nsw i32 %2773, %2774"
"  %2775 = add nuw nsw i32 %2773, %2774"
"  %2775 = add nuw nsw i32 %2773, %2774" -> "  %2822 = add nuw nsw i32 %2775, %2821"
"  %2776 = and i32 %2649, 65535"
"  %2776 = and i32 %2649, 65535" -> "  %2778 = add nuw nsw i32 %2777, %2776"
"  %2777 = and i32 %2635, 65535"
"  %2777 = and i32 %2635, 65535" -> "  %2778 = add nuw nsw i32 %2777, %2776"
"  %2778 = add nuw nsw i32 %2777, %2776"
"  %2778 = add nuw nsw i32 %2777, %2776" -> "  %2951 = and i32 %2778, 65535""  %2778 = add nuw nsw i32 %2777, %2776" -> "  %2785 = lshr i32 %2778, 16"
"  %2779 = add i64 %18, -124"
"  %2779 = add i64 %18, -124" -> "  %2780 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2779"
"  %2780 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2779"
"  %2780 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2779" -> "  %2781 = bitcast i8* %2780 to i32*"
"  %2781 = bitcast i8* %2780 to i32*"
"  %2781 = bitcast i8* %2780 to i32*" -> "  store i32 %15016, i32* %2781, align 1, !noalias !32"
"  %2782 = and i32 %2658, 65535"
"  %2782 = and i32 %2658, 65535" -> "  %2784 = add nuw nsw i32 %2782, %2783"
"  %2783 = and i32 %2641, 65535"
"  %2783 = and i32 %2641, 65535" -> "  %2784 = add nuw nsw i32 %2782, %2783"
"  %2784 = add nuw nsw i32 %2782, %2783"
"  %2784 = add nuw nsw i32 %2782, %2783" -> "  %2791 = lshr i32 %2784, 16""  %2784 = add nuw nsw i32 %2782, %2783" -> "  %2786 = and i32 %2784, 65535"
"  %2785 = lshr i32 %2778, 16"
"  %2785 = lshr i32 %2778, 16" -> "  %2787 = add nuw nsw i32 %2786, %2785"
"  %2786 = and i32 %2784, 65535"
"  %2786 = and i32 %2784, 65535" -> "  %2787 = add nuw nsw i32 %2786, %2785"
"  %2787 = add nuw nsw i32 %2786, %2785"
"  %2787 = add nuw nsw i32 %2786, %2785" -> "  %2954 = and i32 %2787, 65535""  %2787 = add nuw nsw i32 %2786, %2785" -> "  %2792 = lshr i32 %2787, 16"
"  %2788 = add i64 %18, -144"
"  %2788 = add i64 %18, -144" -> "  %2789 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2788"
"  %2789 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2788"
"  %2789 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2788" -> "  %2790 = bitcast i8* %2789 to i32*"
"  %2790 = bitcast i8* %2789 to i32*"
"  %2790 = bitcast i8* %2789 to i32*" -> "  store i32 %15641, i32* %2790, align 1, !noalias !35"
"  %2791 = lshr i32 %2784, 16"
"  %2791 = lshr i32 %2784, 16" -> "  %2793 = add nuw nsw i32 %2792, %2791"
"  %2792 = lshr i32 %2787, 16"
"  %2792 = lshr i32 %2787, 16" -> "  %2793 = add nuw nsw i32 %2792, %2791"
"  %2793 = add nuw nsw i32 %2792, %2791"
"  %2793 = add nuw nsw i32 %2792, %2791" -> "  %2804 = add nuw nsw i32 %2793, %2803"
"  %2794 = and i32 %2648, 65535"
"  %2794 = and i32 %2648, 65535" -> "  %2796 = add nuw nsw i32 %2795, %2794"
"  %2795 = and i32 %2718, 65535"
"  %2795 = and i32 %2718, 65535" -> "  %2796 = add nuw nsw i32 %2795, %2794"
"  %2796 = add nuw nsw i32 %2795, %2794"
"  %2796 = add nuw nsw i32 %2795, %2794" -> "  %2803 = and i32 %2796, 65535""  %2796 = add nuw nsw i32 %2795, %2794" -> "  %2800 = lshr i32 %2796, 16"
"  %2797 = lshr i32 %2648, 16"
"  %2797 = lshr i32 %2648, 16" -> "  %2799 = add nuw nsw i32 %2798, %2797"
"  %2798 = and i32 %2726, 65535"
"  %2798 = and i32 %2726, 65535" -> "  %2799 = add nuw nsw i32 %2798, %2797"
"  %2799 = add nuw nsw i32 %2798, %2797"
"  %2799 = add nuw nsw i32 %2798, %2797" -> "  %2809 = lshr i32 %2799, 16""  %2799 = add nuw nsw i32 %2798, %2797" -> "  %2801 = and i32 %2799, 65535"
"  %2800 = lshr i32 %2796, 16"
"  %2800 = lshr i32 %2796, 16" -> "  %2802 = add nuw nsw i32 %2801, %2800"
"  %2801 = and i32 %2799, 65535"
"  %2801 = and i32 %2799, 65535" -> "  %2802 = add nuw nsw i32 %2801, %2800"
"  %2802 = add nuw nsw i32 %2801, %2800"
"  %2802 = add nuw nsw i32 %2801, %2800" -> "  %2811 = lshr i32 %2802, 16""  %2802 = add nuw nsw i32 %2801, %2800" -> "  %2806 = and i32 %2802, 65535"
"  %2803 = and i32 %2796, 65535"
"  %2803 = and i32 %2796, 65535" -> "  %2804 = add nuw nsw i32 %2793, %2803"
"  %2804 = add nuw nsw i32 %2793, %2803"
"  %2804 = add nuw nsw i32 %2793, %2803" -> "  %2962 = and i32 %2804, 65535""  %2804 = add nuw nsw i32 %2793, %2803" -> "  %2805 = lshr i32 %2804, 16"
"  %2805 = lshr i32 %2804, 16"
"  %2805 = lshr i32 %2804, 16" -> "  %2807 = add nuw nsw i32 %2806, %2805"
"  %2806 = and i32 %2802, 65535"
"  %2806 = and i32 %2802, 65535" -> "  %2807 = add nuw nsw i32 %2806, %2805"
"  %2807 = add nuw nsw i32 %2806, %2805"
"  %2807 = add nuw nsw i32 %2806, %2805" -> "  %2966 = and i32 %2807, 65535""  %2807 = add nuw nsw i32 %2806, %2805" -> "  %2813 = lshr i32 %2807, 16"
"  %2808 = and i32 %2762, 65535"
"  %2808 = and i32 %2762, 65535" -> "  %2810 = add nuw nsw i32 %2808, %2809"
"  %2809 = lshr i32 %2799, 16"
"  %2809 = lshr i32 %2799, 16" -> "  %2810 = add nuw nsw i32 %2808, %2809"
"  %2810 = add nuw nsw i32 %2808, %2809"
"  %2810 = add nuw nsw i32 %2808, %2809" -> "  %2812 = add nuw nsw i32 %2810, %2811"
"  %2811 = lshr i32 %2802, 16"
"  %2811 = lshr i32 %2802, 16" -> "  %2812 = add nuw nsw i32 %2810, %2811"
"  %2812 = add nuw nsw i32 %2810, %2811"
"  %2812 = add nuw nsw i32 %2810, %2811" -> "  %2814 = add nuw nsw i32 %2812, %2813"
"  %2813 = lshr i32 %2807, 16"
"  %2813 = lshr i32 %2807, 16" -> "  %2814 = add nuw nsw i32 %2812, %2813"
"  %2814 = add nuw nsw i32 %2812, %2813"
"  %2814 = add nuw nsw i32 %2812, %2813" -> "  %3122 = and i32 %2814, 65535""  %2814 = add nuw nsw i32 %2812, %2813" -> "  %2819 = lshr i32 %2814, 16"
"  %2815 = add i64 %18, -140"
"  %2815 = add i64 %18, -140" -> "  %2816 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2815"
"  %2816 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2815"
"  %2816 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2815" -> "  %2817 = bitcast i8* %2816 to i32*"
"  %2817 = bitcast i8* %2816 to i32*"
"  %2817 = bitcast i8* %2816 to i32*" -> "  store i32 %15806, i32* %2817, align 1, !noalias !38"
"  %2818 = and i32 %2768, 65535"
"  %2818 = and i32 %2768, 65535" -> "  %2820 = add nuw nsw i32 %2819, %2818"
"  %2819 = lshr i32 %2814, 16"
"  %2819 = lshr i32 %2814, 16" -> "  %2820 = add nuw nsw i32 %2819, %2818"
"  %2820 = add nuw nsw i32 %2819, %2818"
"  %2820 = add nuw nsw i32 %2819, %2818" -> "  %3125 = and i32 %2820, 65535""  %2820 = add nuw nsw i32 %2819, %2818" -> "  %2821 = lshr i32 %2820, 16"
"  %2821 = lshr i32 %2820, 16"
"  %2821 = lshr i32 %2820, 16" -> "  %2822 = add nuw nsw i32 %2775, %2821"
"  %2822 = add nuw nsw i32 %2775, %2821"
"  %2822 = add nuw nsw i32 %2775, %2821" -> "  %3130 = and i32 %2822, 65535""  %2822 = add nuw nsw i32 %2775, %2821" -> "  %3133 = lshr i32 %2822, 16"
"  %2823 = mul nuw nsw i32 %1044, 4087"
"  %2823 = mul nuw nsw i32 %1044, 4087" -> "  %2950 = and i32 %2823, 65535""  %2823 = mul nuw nsw i32 %1044, 4087" -> "  %2824 = lshr i32 %2823, 16"
"  %2824 = lshr i32 %2823, 16"
"  %2824 = lshr i32 %2823, 16" -> "  %2827 = add nuw nsw i32 %2826, %2824"
"  %2825 = mul nuw nsw i32 %1047, 4087"
"  %2825 = mul nuw nsw i32 %1047, 4087" -> "  %2828 = and i32 %2825, 268369920""  %2825 = mul nuw nsw i32 %1047, 4087" -> "  %2826 = and i32 %2825, 65535"
"  %2826 = and i32 %2825, 65535"
"  %2826 = and i32 %2825, 65535" -> "  %2827 = add nuw nsw i32 %2826, %2824"
"  %2827 = add nuw nsw i32 %2826, %2824"
"  %2827 = add nuw nsw i32 %2826, %2824" -> "  %2829 = add nuw nsw i32 %2827, %2828"
"  %2828 = and i32 %2825, 268369920"
"  %2828 = and i32 %2825, 268369920" -> "  %2829 = add nuw nsw i32 %2827, %2828"
"  %2829 = add nuw nsw i32 %2827, %2828"
"  %2829 = add nuw nsw i32 %2827, %2828" -> "  %2833 = lshr i32 %2829, 16""  %2829 = add nuw nsw i32 %2827, %2828" -> "  %2831 = and i32 %2829, 65535"
"  %2830 = mul nuw nsw i32 %1044, 11561"
"  %2830 = mul nuw nsw i32 %1044, 11561" -> "  %2832 = add nuw nsw i32 %2831, %2830"
"  %2831 = and i32 %2829, 65535"
"  %2831 = and i32 %2829, 65535" -> "  %2832 = add nuw nsw i32 %2831, %2830"
"  %2832 = add nuw nsw i32 %2831, %2830"
"  %2832 = add nuw nsw i32 %2831, %2830" -> "  %2953 = and i32 %2832, 65535""  %2832 = add nuw nsw i32 %2831, %2830" -> "  %2836 = lshr i32 %2832, 16"
"  %2833 = lshr i32 %2829, 16"
"  %2833 = lshr i32 %2829, 16" -> "  %2835 = add nuw nsw i32 %2833, %2834"
"  %2834 = mul nuw nsw i32 %1047, 11561"
"  %2834 = mul nuw nsw i32 %1047, 11561" -> "  %2835 = add nuw nsw i32 %2833, %2834"
"  %2835 = add nuw nsw i32 %2833, %2834"
"  %2835 = add nuw nsw i32 %2833, %2834" -> "  %2839 = and i32 %2835, 2147418112""  %2835 = add nuw nsw i32 %2833, %2834" -> "  %2837 = and i32 %2835, 65535"
"  %2836 = lshr i32 %2832, 16"
"  %2836 = lshr i32 %2832, 16" -> "  %2838 = add nuw nsw i32 %2836, %2837"
"  %2837 = and i32 %2835, 65535"
"  %2837 = and i32 %2835, 65535" -> "  %2838 = add nuw nsw i32 %2836, %2837"
"  %2838 = add nuw nsw i32 %2836, %2837"
"  %2838 = add nuw nsw i32 %2836, %2837" -> "  %2840 = add nuw nsw i32 %2838, %2839"
"  %2839 = and i32 %2835, 2147418112"
"  %2839 = and i32 %2835, 2147418112" -> "  %2840 = add nuw nsw i32 %2838, %2839"
"  %2840 = add nuw nsw i32 %2838, %2839"
"  %2840 = add nuw nsw i32 %2838, %2839" -> "  %2863 = lshr i32 %2840, 16""  %2840 = add nuw nsw i32 %2838, %2839" -> "  %2859 = and i32 %2840, 65535"
"  %2841 = mul nuw nsw i32 %1064, 4087"
"  %2841 = mul nuw nsw i32 %1064, 4087" -> "  %2860 = and i32 %2841, 65535""  %2841 = mul nuw nsw i32 %1064, 4087" -> "  %2842 = lshr i32 %2841, 16"
"  %2842 = lshr i32 %2841, 16"
"  %2842 = lshr i32 %2841, 16" -> "  %2845 = add nuw nsw i32 %2844, %2842"
"  %2843 = mul nuw nsw i32 %1065, 4087"
"  %2843 = mul nuw nsw i32 %1065, 4087" -> "  %2846 = and i32 %2843, 268369920""  %2843 = mul nuw nsw i32 %1065, 4087" -> "  %2844 = and i32 %2843, 65535"
"  %2844 = and i32 %2843, 65535"
"  %2844 = and i32 %2843, 65535" -> "  %2845 = add nuw nsw i32 %2844, %2842"
"  %2845 = add nuw nsw i32 %2844, %2842"
"  %2845 = add nuw nsw i32 %2844, %2842" -> "  %2847 = add nuw nsw i32 %2845, %2846"
"  %2846 = and i32 %2843, 268369920"
"  %2846 = and i32 %2843, 268369920" -> "  %2847 = add nuw nsw i32 %2845, %2846"
"  %2847 = add nuw nsw i32 %2845, %2846"
"  %2847 = add nuw nsw i32 %2845, %2846" -> "  %2851 = lshr i32 %2847, 16""  %2847 = add nuw nsw i32 %2845, %2846" -> "  %2849 = and i32 %2847, 65535"
"  %2848 = mul nuw nsw i32 %1064, 11561"
"  %2848 = mul nuw nsw i32 %1064, 11561" -> "  %2850 = add nuw nsw i32 %2849, %2848"
"  %2849 = and i32 %2847, 65535"
"  %2849 = and i32 %2847, 65535" -> "  %2850 = add nuw nsw i32 %2849, %2848"
"  %2850 = add nuw nsw i32 %2849, %2848"
"  %2850 = add nuw nsw i32 %2849, %2848" -> "  %2862 = and i32 %2850, 65535""  %2850 = add nuw nsw i32 %2849, %2848" -> "  %2854 = lshr i32 %2850, 16"
"  %2851 = lshr i32 %2847, 16"
"  %2851 = lshr i32 %2847, 16" -> "  %2853 = add nuw nsw i32 %2851, %2852"
"  %2852 = mul nuw nsw i32 %1065, 11561"
"  %2852 = mul nuw nsw i32 %1065, 11561" -> "  %2853 = add nuw nsw i32 %2851, %2852"
"  %2853 = add nuw nsw i32 %2851, %2852"
"  %2853 = add nuw nsw i32 %2851, %2852" -> "  %2857 = and i32 %2853, 2147418112""  %2853 = add nuw nsw i32 %2851, %2852" -> "  %2855 = and i32 %2853, 65535"
"  %2854 = lshr i32 %2850, 16"
"  %2854 = lshr i32 %2850, 16" -> "  %2856 = add nuw nsw i32 %2854, %2855"
"  %2855 = and i32 %2853, 65535"
"  %2855 = and i32 %2853, 65535" -> "  %2856 = add nuw nsw i32 %2854, %2855"
"  %2856 = add nuw nsw i32 %2854, %2855"
"  %2856 = add nuw nsw i32 %2854, %2855" -> "  %2858 = add nuw nsw i32 %2856, %2857"
"  %2857 = and i32 %2853, 2147418112"
"  %2857 = and i32 %2853, 2147418112" -> "  %2858 = add nuw nsw i32 %2856, %2857"
"  %2858 = add nuw nsw i32 %2856, %2857"
"  %2858 = add nuw nsw i32 %2856, %2857" -> "  %2866 = add nuw nsw i32 %2858, %2865"
"  %2859 = and i32 %2840, 65535"
"  %2859 = and i32 %2840, 65535" -> "  %2861 = add nuw nsw i32 %2859, %2860"
"  %2860 = and i32 %2841, 65535"
"  %2860 = and i32 %2841, 65535" -> "  %2861 = add nuw nsw i32 %2859, %2860"
"  %2861 = add nuw nsw i32 %2859, %2860"
"  %2861 = add nuw nsw i32 %2859, %2860" -> "  %2890 = and i32 %2861, 65535""  %2861 = add nuw nsw i32 %2859, %2860" -> "  %2868 = lshr i32 %2861, 16"
"  %2862 = and i32 %2850, 65535"
"  %2862 = and i32 %2850, 65535" -> "  %2864 = add nuw nsw i32 %2862, %2863"
"  %2863 = lshr i32 %2840, 16"
"  %2863 = lshr i32 %2840, 16" -> "  %2864 = add nuw nsw i32 %2862, %2863"
"  %2864 = add nuw nsw i32 %2862, %2863"
"  %2864 = add nuw nsw i32 %2862, %2863" -> "  %2867 = and i32 %2864, 65535""  %2864 = add nuw nsw i32 %2862, %2863" -> "  %2865 = lshr i32 %2864, 16"
"  %2865 = lshr i32 %2864, 16"
"  %2865 = lshr i32 %2864, 16" -> "  %2866 = add nuw nsw i32 %2858, %2865"
"  %2866 = add nuw nsw i32 %2858, %2865"
"  %2866 = add nuw nsw i32 %2858, %2865" -> "  %2871 = add nuw nsw i32 %2866, %2870"
"  %2867 = and i32 %2864, 65535"
"  %2867 = and i32 %2864, 65535" -> "  %2869 = add nuw nsw i32 %2867, %2868"
"  %2868 = lshr i32 %2861, 16"
"  %2868 = lshr i32 %2861, 16" -> "  %2869 = add nuw nsw i32 %2867, %2868"
"  %2869 = add nuw nsw i32 %2867, %2868"
"  %2869 = add nuw nsw i32 %2867, %2868" -> "  %2893 = and i32 %2869, 65535""  %2869 = add nuw nsw i32 %2867, %2868" -> "  %2870 = lshr i32 %2869, 16"
"  %2870 = lshr i32 %2869, 16"
"  %2870 = lshr i32 %2869, 16" -> "  %2871 = add nuw nsw i32 %2866, %2870"
"  %2871 = add nuw nsw i32 %2866, %2870"
"  %2871 = add nuw nsw i32 %2866, %2870" -> "  %2921 = and i32 %2871, 65535""  %2871 = add nuw nsw i32 %2866, %2870" -> "  %2925 = lshr i32 %2871, 16"
"  %2872 = mul nuw nsw i32 %1044, 21884"
"  %2872 = mul nuw nsw i32 %1044, 21884" -> "  %2891 = and i32 %2872, 65532""  %2872 = mul nuw nsw i32 %1044, 21884" -> "  %2873 = lshr i32 %2872, 16"
"  %2873 = lshr i32 %2872, 16"
"  %2873 = lshr i32 %2872, 16" -> "  %2876 = add nuw nsw i32 %2875, %2873"
"  %2874 = mul nuw nsw i32 %1047, 21884"
"  %2874 = mul nuw nsw i32 %1047, 21884" -> "  %2877 = and i32 %2874, 2147418112""  %2874 = mul nuw nsw i32 %1047, 21884" -> "  %2875 = and i32 %2874, 65532"
"  %2875 = and i32 %2874, 65532"
"  %2875 = and i32 %2874, 65532" -> "  %2876 = add nuw nsw i32 %2875, %2873"
"  %2876 = add nuw nsw i32 %2875, %2873"
"  %2876 = add nuw nsw i32 %2875, %2873" -> "  %2878 = add nuw nsw i32 %2876, %2877"
"  %2877 = and i32 %2874, 2147418112"
"  %2877 = and i32 %2874, 2147418112" -> "  %2878 = add nuw nsw i32 %2876, %2877"
"  %2878 = add nuw nsw i32 %2876, %2877"
"  %2878 = add nuw nsw i32 %2876, %2877" -> "  %2882 = lshr i32 %2878, 16""  %2878 = add nuw nsw i32 %2876, %2877" -> "  %2880 = and i32 %2878, 65535"
"  %2879 = mul nuw i32 %1044, 36786"
"  %2879 = mul nuw i32 %1044, 36786" -> "  %2881 = add nuw i32 %2880, %2879"
"  %2880 = and i32 %2878, 65535"
"  %2880 = and i32 %2878, 65535" -> "  %2881 = add nuw i32 %2880, %2879"
"  %2881 = add nuw i32 %2880, %2879"
"  %2881 = add nuw i32 %2880, %2879" -> "  %2894 = and i32 %2881, 65535""  %2881 = add nuw i32 %2880, %2879" -> "  %2885 = lshr i32 %2881, 16"
"  %2882 = lshr i32 %2878, 16"
"  %2882 = lshr i32 %2878, 16" -> "  %2884 = add nuw i32 %2882, %2883"
"  %2883 = mul nuw i32 %1047, 36786"
"  %2883 = mul nuw i32 %1047, 36786" -> "  %2884 = add nuw i32 %2882, %2883"
"  %2884 = add nuw i32 %2882, %2883"
"  %2884 = add nuw i32 %2882, %2883" -> "  %2888 = and i32 %2884, -65536""  %2884 = add nuw i32 %2882, %2883" -> "  %2886 = and i32 %2884, 65535"
"  %2885 = lshr i32 %2881, 16"
"  %2885 = lshr i32 %2881, 16" -> "  %2887 = add nuw nsw i32 %2885, %2886"
"  %2886 = and i32 %2884, 65535"
"  %2886 = and i32 %2884, 65535" -> "  %2887 = add nuw nsw i32 %2885, %2886"
"  %2887 = add nuw nsw i32 %2885, %2886"
"  %2887 = add nuw nsw i32 %2885, %2886" -> "  %2889 = add nuw i32 %2887, %2888"
"  %2888 = and i32 %2884, -65536"
"  %2888 = and i32 %2884, -65536" -> "  %2889 = add nuw i32 %2887, %2888"
"  %2889 = add nuw i32 %2887, %2888"
"  %2889 = add nuw i32 %2887, %2888" -> "  %2897 = add nuw i32 %2889, %2896"
"  %2890 = and i32 %2861, 65535"
"  %2890 = and i32 %2861, 65535" -> "  %2892 = add nuw nsw i32 %2890, %2891"
"  %2891 = and i32 %2872, 65532"
"  %2891 = and i32 %2872, 65532" -> "  %2892 = add nuw nsw i32 %2890, %2891"
"  %2892 = add nuw nsw i32 %2890, %2891"
"  %2892 = add nuw nsw i32 %2890, %2891" -> "  %2963 = and i32 %2892, 65535""  %2892 = add nuw nsw i32 %2890, %2891" -> "  %2899 = lshr i32 %2892, 16"
"  %2893 = and i32 %2869, 65535"
"  %2893 = and i32 %2869, 65535" -> "  %2895 = add nuw nsw i32 %2893, %2894"
"  %2894 = and i32 %2881, 65535"
"  %2894 = and i32 %2881, 65535" -> "  %2895 = add nuw nsw i32 %2893, %2894"
"  %2895 = add nuw nsw i32 %2893, %2894"
"  %2895 = add nuw nsw i32 %2893, %2894" -> "  %2898 = and i32 %2895, 65535""  %2895 = add nuw nsw i32 %2893, %2894" -> "  %2896 = lshr i32 %2895, 16"
"  %2896 = lshr i32 %2895, 16"
"  %2896 = lshr i32 %2895, 16" -> "  %2897 = add nuw i32 %2889, %2896"
"  %2897 = add nuw i32 %2889, %2896"
"  %2897 = add nuw i32 %2889, %2896" -> "  %2902 = add nuw i32 %2897, %2901"
"  %2898 = and i32 %2895, 65535"
"  %2898 = and i32 %2895, 65535" -> "  %2900 = add nuw nsw i32 %2898, %2899"
"  %2899 = lshr i32 %2892, 16"
"  %2899 = lshr i32 %2892, 16" -> "  %2900 = add nuw nsw i32 %2898, %2899"
"  %2900 = add nuw nsw i32 %2898, %2899"
"  %2900 = add nuw nsw i32 %2898, %2899" -> "  %2965 = and i32 %2900, 65535""  %2900 = add nuw nsw i32 %2898, %2899" -> "  %2901 = lshr i32 %2900, 16"
"  %2901 = lshr i32 %2900, 16"
"  %2901 = lshr i32 %2900, 16" -> "  %2902 = add nuw i32 %2897, %2901"
"  %2902 = add nuw i32 %2897, %2901"
"  %2902 = add nuw i32 %2897, %2901" -> "  %2935 = and i32 %2902, 65535""  %2902 = add nuw i32 %2897, %2901" -> "  %2938 = lshr i32 %2902, 16"
"  %2903 = mul nuw nsw i32 %1064, 21884"
"  %2903 = mul nuw nsw i32 %1064, 21884" -> "  %2922 = and i32 %2903, 65532""  %2903 = mul nuw nsw i32 %1064, 21884" -> "  %2904 = lshr i32 %2903, 16"
"  %2904 = lshr i32 %2903, 16"
"  %2904 = lshr i32 %2903, 16" -> "  %2907 = add nuw nsw i32 %2906, %2904"
"  %2905 = mul nuw nsw i32 %1065, 21884"
"  %2905 = mul nuw nsw i32 %1065, 21884" -> "  %2908 = and i32 %2905, 2147418112""  %2905 = mul nuw nsw i32 %1065, 21884" -> "  %2906 = and i32 %2905, 65532"
"  %2906 = and i32 %2905, 65532"
"  %2906 = and i32 %2905, 65532" -> "  %2907 = add nuw nsw i32 %2906, %2904"
"  %2907 = add nuw nsw i32 %2906, %2904"
"  %2907 = add nuw nsw i32 %2906, %2904" -> "  %2909 = add nuw nsw i32 %2907, %2908"
"  %2908 = and i32 %2905, 2147418112"
"  %2908 = and i32 %2905, 2147418112" -> "  %2909 = add nuw nsw i32 %2907, %2908"
"  %2909 = add nuw nsw i32 %2907, %2908"
"  %2909 = add nuw nsw i32 %2907, %2908" -> "  %2913 = lshr i32 %2909, 16""  %2909 = add nuw nsw i32 %2907, %2908" -> "  %2911 = and i32 %2909, 65535"
"  %2910 = mul nuw i32 %1064, 36786"
"  %2910 = mul nuw i32 %1064, 36786" -> "  %2912 = add nuw i32 %2911, %2910"
"  %2911 = and i32 %2909, 65535"
"  %2911 = and i32 %2909, 65535" -> "  %2912 = add nuw i32 %2911, %2910"
"  %2912 = add nuw i32 %2911, %2910"
"  %2912 = add nuw i32 %2911, %2910" -> "  %2924 = and i32 %2912, 65535""  %2912 = add nuw i32 %2911, %2910" -> "  %2916 = lshr i32 %2912, 16"
"  %2913 = lshr i32 %2909, 16"
"  %2913 = lshr i32 %2909, 16" -> "  %2915 = add nuw i32 %2913, %2914"
"  %2914 = mul nuw i32 %1065, 36786"
"  %2914 = mul nuw i32 %1065, 36786" -> "  %2915 = add nuw i32 %2913, %2914"
"  %2915 = add nuw i32 %2913, %2914"
"  %2915 = add nuw i32 %2913, %2914" -> "  %2919 = and i32 %2915, -65536""  %2915 = add nuw i32 %2913, %2914" -> "  %2917 = and i32 %2915, 65535"
"  %2916 = lshr i32 %2912, 16"
"  %2916 = lshr i32 %2912, 16" -> "  %2918 = add nuw nsw i32 %2916, %2917"
"  %2917 = and i32 %2915, 65535"
"  %2917 = and i32 %2915, 65535" -> "  %2918 = add nuw nsw i32 %2916, %2917"
"  %2918 = add nuw nsw i32 %2916, %2917"
"  %2918 = add nuw nsw i32 %2916, %2917" -> "  %2920 = add nuw i32 %2918, %2919"
"  %2919 = and i32 %2915, -65536"
"  %2919 = and i32 %2915, -65536" -> "  %2920 = add nuw i32 %2918, %2919"
"  %2920 = add nuw i32 %2918, %2919"
"  %2920 = add nuw i32 %2918, %2919" -> "  %2928 = add nuw i32 %2920, %2927"
"  %2921 = and i32 %2871, 65535"
"  %2921 = and i32 %2871, 65535" -> "  %2923 = add nuw nsw i32 %2921, %2922"
"  %2922 = and i32 %2903, 65532"
"  %2922 = and i32 %2903, 65532" -> "  %2923 = add nuw nsw i32 %2921, %2922"
"  %2923 = add nuw nsw i32 %2921, %2922"
"  %2923 = add nuw nsw i32 %2921, %2922" -> "  %2934 = and i32 %2923, 65535""  %2923 = add nuw nsw i32 %2921, %2922" -> "  %2930 = lshr i32 %2923, 16"
"  %2924 = and i32 %2912, 65535"
"  %2924 = and i32 %2912, 65535" -> "  %2926 = add nuw nsw i32 %2925, %2924"
"  %2925 = lshr i32 %2871, 16"
"  %2925 = lshr i32 %2871, 16" -> "  %2926 = add nuw nsw i32 %2925, %2924"
"  %2926 = add nuw nsw i32 %2925, %2924"
"  %2926 = add nuw nsw i32 %2925, %2924" -> "  %2929 = and i32 %2926, 65535""  %2926 = add nuw nsw i32 %2925, %2924" -> "  %2927 = lshr i32 %2926, 16"
"  %2927 = lshr i32 %2926, 16"
"  %2927 = lshr i32 %2926, 16" -> "  %2928 = add nuw i32 %2920, %2927"
"  %2928 = add nuw i32 %2920, %2927"
"  %2928 = add nuw i32 %2920, %2927" -> "  %2933 = add nuw i32 %2928, %2932"
"  %2929 = and i32 %2926, 65535"
"  %2929 = and i32 %2926, 65535" -> "  %2931 = add nuw nsw i32 %2929, %2930"
"  %2930 = lshr i32 %2923, 16"
"  %2930 = lshr i32 %2923, 16" -> "  %2931 = add nuw nsw i32 %2929, %2930"
"  %2931 = add nuw nsw i32 %2929, %2930"
"  %2931 = add nuw nsw i32 %2929, %2930" -> "  %2937 = and i32 %2931, 65535""  %2931 = add nuw nsw i32 %2929, %2930" -> "  %2932 = lshr i32 %2931, 16"
"  %2932 = lshr i32 %2931, 16"
"  %2932 = lshr i32 %2931, 16" -> "  %2933 = add nuw i32 %2928, %2932"
"  %2933 = add nuw i32 %2928, %2932"
"  %2933 = add nuw i32 %2928, %2932" -> "  %2946 = and i32 %2933, -65536""  %2933 = add nuw i32 %2928, %2932" -> "  %2944 = and i32 %2933, 65535"
"  %2934 = and i32 %2923, 65535"
"  %2934 = and i32 %2923, 65535" -> "  %2936 = add nuw nsw i32 %2935, %2934"
"  %2935 = and i32 %2902, 65535"
"  %2935 = and i32 %2902, 65535" -> "  %2936 = add nuw nsw i32 %2935, %2934"
"  %2936 = add nuw nsw i32 %2935, %2934"
"  %2936 = add nuw nsw i32 %2935, %2934" -> "  %2982 = and i32 %2936, 65535""  %2936 = add nuw nsw i32 %2935, %2934" -> "  %2940 = lshr i32 %2936, 16"
"  %2937 = and i32 %2931, 65535"
"  %2937 = and i32 %2931, 65535" -> "  %2939 = add nuw nsw i32 %2937, %2938"
"  %2938 = lshr i32 %2902, 16"
"  %2938 = lshr i32 %2902, 16" -> "  %2939 = add nuw nsw i32 %2937, %2938"
"  %2939 = add nuw nsw i32 %2937, %2938"
"  %2939 = add nuw nsw i32 %2937, %2938" -> "  %2943 = lshr i32 %2939, 16""  %2939 = add nuw nsw i32 %2937, %2938" -> "  %2941 = and i32 %2939, 65535"
"  %2940 = lshr i32 %2936, 16"
"  %2940 = lshr i32 %2936, 16" -> "  %2942 = add nuw nsw i32 %2941, %2940"
"  %2941 = and i32 %2939, 65535"
"  %2941 = and i32 %2939, 65535" -> "  %2942 = add nuw nsw i32 %2941, %2940"
"  %2942 = add nuw nsw i32 %2941, %2940"
"  %2942 = add nuw nsw i32 %2941, %2940" -> "  %2989 = and i32 %2942, 65535""  %2942 = add nuw nsw i32 %2941, %2940" -> "  %2948 = lshr i32 %2942, 16"
"  %2943 = lshr i32 %2939, 16"
"  %2943 = lshr i32 %2939, 16" -> "  %2945 = add nuw nsw i32 %2943, %2944"
"  %2944 = and i32 %2933, 65535"
"  %2944 = and i32 %2933, 65535" -> "  %2945 = add nuw nsw i32 %2943, %2944"
"  %2945 = add nuw nsw i32 %2943, %2944"
"  %2945 = add nuw nsw i32 %2943, %2944" -> "  %2947 = add nuw i32 %2945, %2946"
"  %2946 = and i32 %2933, -65536"
"  %2946 = and i32 %2933, -65536" -> "  %2947 = add nuw i32 %2945, %2946"
"  %2947 = add nuw i32 %2945, %2946"
"  %2947 = add nuw i32 %2945, %2946" -> "  %2949 = add nuw i32 %2947, %2948"
"  %2948 = lshr i32 %2942, 16"
"  %2948 = lshr i32 %2942, 16" -> "  %2949 = add nuw i32 %2947, %2948"
"  %2949 = add nuw i32 %2947, %2948"
"  %2949 = add nuw i32 %2947, %2948" -> "  %2993 = add nuw i32 %2949, %2992"
"  %2950 = and i32 %2823, 65535"
"  %2950 = and i32 %2823, 65535" -> "  %2952 = add nuw nsw i32 %2951, %2950"
"  %2951 = and i32 %2778, 65535"
"  %2951 = and i32 %2778, 65535" -> "  %2952 = add nuw nsw i32 %2951, %2950"
"  %2952 = add nuw nsw i32 %2951, %2950"
"  %2952 = add nuw nsw i32 %2951, %2950" -> "  %3224 = and i32 %2952, 65535""  %2952 = add nuw nsw i32 %2951, %2950" -> "  %2956 = lshr i32 %2952, 16"
"  %2953 = and i32 %2832, 65535"
"  %2953 = and i32 %2832, 65535" -> "  %2955 = add nuw nsw i32 %2954, %2953"
"  %2954 = and i32 %2787, 65535"
"  %2954 = and i32 %2787, 65535" -> "  %2955 = add nuw nsw i32 %2954, %2953"
"  %2955 = add nuw nsw i32 %2954, %2953"
"  %2955 = add nuw nsw i32 %2954, %2953" -> "  %2959 = lshr i32 %2955, 16""  %2955 = add nuw nsw i32 %2954, %2953" -> "  %2957 = and i32 %2955, 65535"
"  %2956 = lshr i32 %2952, 16"
"  %2956 = lshr i32 %2952, 16" -> "  %2958 = add nuw nsw i32 %2957, %2956"
"  %2957 = and i32 %2955, 65535"
"  %2957 = and i32 %2955, 65535" -> "  %2958 = add nuw nsw i32 %2957, %2956"
"  %2958 = add nuw nsw i32 %2957, %2956"
"  %2958 = add nuw nsw i32 %2957, %2956" -> "  %3227 = and i32 %2958, 65535""  %2958 = add nuw nsw i32 %2957, %2956" -> "  %2960 = lshr i32 %2958, 16"
"  %2959 = lshr i32 %2955, 16"
"  %2959 = lshr i32 %2955, 16" -> "  %2961 = add nuw nsw i32 %2960, %2959"
"  %2960 = lshr i32 %2958, 16"
"  %2960 = lshr i32 %2958, 16" -> "  %2961 = add nuw nsw i32 %2960, %2959"
"  %2961 = add nuw nsw i32 %2960, %2959"
"  %2961 = add nuw nsw i32 %2960, %2959" -> "  %2972 = add nuw nsw i32 %2961, %2971"
"  %2962 = and i32 %2804, 65535"
"  %2962 = and i32 %2804, 65535" -> "  %2964 = add nuw nsw i32 %2962, %2963"
"  %2963 = and i32 %2892, 65535"
"  %2963 = and i32 %2892, 65535" -> "  %2964 = add nuw nsw i32 %2962, %2963"
"  %2964 = add nuw nsw i32 %2962, %2963"
"  %2964 = add nuw nsw i32 %2962, %2963" -> "  %2971 = and i32 %2964, 65535""  %2964 = add nuw nsw i32 %2962, %2963" -> "  %2968 = lshr i32 %2964, 16"
"  %2965 = and i32 %2900, 65535"
"  %2965 = and i32 %2900, 65535" -> "  %2967 = add nuw nsw i32 %2966, %2965"
"  %2966 = and i32 %2807, 65535"
"  %2966 = and i32 %2807, 65535" -> "  %2967 = add nuw nsw i32 %2966, %2965"
"  %2967 = add nuw nsw i32 %2966, %2965"
"  %2967 = add nuw nsw i32 %2966, %2965" -> "  %2983 = lshr i32 %2967, 16""  %2967 = add nuw nsw i32 %2966, %2965" -> "  %2969 = and i32 %2967, 65535"
"  %2968 = lshr i32 %2964, 16"
"  %2968 = lshr i32 %2964, 16" -> "  %2970 = add nuw nsw i32 %2969, %2968"
"  %2969 = and i32 %2967, 65535"
"  %2969 = and i32 %2967, 65535" -> "  %2970 = add nuw nsw i32 %2969, %2968"
"  %2970 = add nuw nsw i32 %2969, %2968"
"  %2970 = add nuw nsw i32 %2969, %2968" -> "  %2985 = lshr i32 %2970, 16""  %2970 = add nuw nsw i32 %2969, %2968" -> "  %2977 = and i32 %2970, 65535"
"  %2971 = and i32 %2964, 65535"
"  %2971 = and i32 %2964, 65535" -> "  %2972 = add nuw nsw i32 %2961, %2971"
"  %2972 = add nuw nsw i32 %2961, %2971"
"  %2972 = add nuw nsw i32 %2961, %2971" -> "  %3236 = and i32 %2972, 65535""  %2972 = add nuw nsw i32 %2961, %2971" -> "  %2976 = lshr i32 %2972, 16"
"  %2973 = add i64 %18, -112"
"  %2973 = add i64 %18, -112" -> "  %2974 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2973"
"  %2974 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2973"
"  %2974 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2973" -> "  %2975 = bitcast i8* %2974 to i32*"
"  %2975 = bitcast i8* %2974 to i32*"
"  %2975 = bitcast i8* %2974 to i32*" -> "  store i32 %15036, i32* %2975, align 1, !noalias !32"
"  %2976 = lshr i32 %2972, 16"
"  %2976 = lshr i32 %2972, 16" -> "  %2978 = add nuw nsw i32 %2977, %2976"
"  %2977 = and i32 %2970, 65535"
"  %2977 = and i32 %2970, 65535" -> "  %2978 = add nuw nsw i32 %2977, %2976"
"  %2978 = add nuw nsw i32 %2977, %2976"
"  %2978 = add nuw nsw i32 %2977, %2976" -> "  %3239 = and i32 %2978, 65535""  %2978 = add nuw nsw i32 %2977, %2976" -> "  %2987 = lshr i32 %2978, 16"
"  %2979 = add i64 %18, -84"
"  %2979 = add i64 %18, -84" -> "  %2980 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2979"
"  %2980 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2979"
"  %2980 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2979" -> "  %2981 = bitcast i8* %2980 to i32*"
"  %2981 = bitcast i8* %2980 to i32*"
"  %2981 = bitcast i8* %2980 to i32*" -> "  store i32 %15039, i32* %2981, align 1, !noalias !32"
"  %2982 = and i32 %2936, 65535"
"  %2982 = and i32 %2936, 65535" -> "  %2984 = add nuw nsw i32 %2983, %2982"
"  %2983 = lshr i32 %2967, 16"
"  %2983 = lshr i32 %2967, 16" -> "  %2984 = add nuw nsw i32 %2983, %2982"
"  %2984 = add nuw nsw i32 %2983, %2982"
"  %2984 = add nuw nsw i32 %2983, %2982" -> "  %2986 = add nuw nsw i32 %2984, %2985"
"  %2985 = lshr i32 %2970, 16"
"  %2985 = lshr i32 %2970, 16" -> "  %2986 = add nuw nsw i32 %2984, %2985"
"  %2986 = add nuw nsw i32 %2984, %2985"
"  %2986 = add nuw nsw i32 %2984, %2985" -> "  %2988 = add nuw nsw i32 %2986, %2987"
"  %2987 = lshr i32 %2978, 16"
"  %2987 = lshr i32 %2978, 16" -> "  %2988 = add nuw nsw i32 %2986, %2987"
"  %2988 = add nuw nsw i32 %2986, %2987"
"  %2988 = add nuw nsw i32 %2986, %2987" -> "  %3160 = and i32 %2988, 65535""  %2988 = add nuw nsw i32 %2986, %2987" -> "  %2990 = lshr i32 %2988, 16"
"  %2989 = and i32 %2942, 65535"
"  %2989 = and i32 %2942, 65535" -> "  %2991 = add nuw nsw i32 %2990, %2989"
"  %2990 = lshr i32 %2988, 16"
"  %2990 = lshr i32 %2988, 16" -> "  %2991 = add nuw nsw i32 %2990, %2989"
"  %2991 = add nuw nsw i32 %2990, %2989"
"  %2991 = add nuw nsw i32 %2990, %2989" -> "  %3163 = and i32 %2991, 65535""  %2991 = add nuw nsw i32 %2990, %2989" -> "  %2992 = lshr i32 %2991, 16"
"  %2992 = lshr i32 %2991, 16"
"  %2992 = lshr i32 %2991, 16" -> "  %2993 = add nuw i32 %2949, %2992"
"  %2993 = add nuw i32 %2949, %2992"
"  %2993 = add nuw i32 %2949, %2992" -> "  %3169 = and i32 %2993, 65535""  %2993 = add nuw i32 %2949, %2992" -> "  %3172 = lshr i32 %2993, 16"
"  %2994 = mul nuw nsw i32 %1178, 4087"
"  %2994 = mul nuw nsw i32 %1178, 4087" -> "  %3121 = and i32 %2994, 65535""  %2994 = mul nuw nsw i32 %1178, 4087" -> "  %2998 = lshr i32 %2994, 16"
"  %2995 = add i64 %18, -88"
"  %2995 = add i64 %18, -88" -> "  %2996 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2995"
"  %2996 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2995"
"  %2996 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %2995" -> "  %2997 = bitcast i8* %2996 to i32*"
"  %2997 = bitcast i8* %2996 to i32*"
"  %2997 = bitcast i8* %2996 to i32*" -> "  store i32 %15051, i32* %2997, align 1, !noalias !32"
"  %2998 = lshr i32 %2994, 16"
"  %2998 = lshr i32 %2994, 16" -> "  %3001 = add nuw nsw i32 %3000, %2998"
"  %2999 = mul nuw nsw i32 %1179, 4087"
"  %2999 = mul nuw nsw i32 %1179, 4087" -> "  %3002 = and i32 %2999, 268369920""  %2999 = mul nuw nsw i32 %1179, 4087" -> "  %3000 = and i32 %2999, 65535"
"  %3000 = and i32 %2999, 65535"
"  %3000 = and i32 %2999, 65535" -> "  %3001 = add nuw nsw i32 %3000, %2998"
"  %3001 = add nuw nsw i32 %3000, %2998"
"  %3001 = add nuw nsw i32 %3000, %2998" -> "  %3003 = add nuw nsw i32 %3001, %3002"
"  %3002 = and i32 %2999, 268369920"
"  %3002 = and i32 %2999, 268369920" -> "  %3003 = add nuw nsw i32 %3001, %3002"
"  %3003 = add nuw nsw i32 %3001, %3002"
"  %3003 = add nuw nsw i32 %3001, %3002" -> "  %3007 = lshr i32 %3003, 16""  %3003 = add nuw nsw i32 %3001, %3002" -> "  %3005 = and i32 %3003, 65535"
"  %3004 = mul nuw nsw i32 %1178, 11561"
"  %3004 = mul nuw nsw i32 %1178, 11561" -> "  %3006 = add nuw nsw i32 %3005, %3004"
"  %3005 = and i32 %3003, 65535"
"  %3005 = and i32 %3003, 65535" -> "  %3006 = add nuw nsw i32 %3005, %3004"
"  %3006 = add nuw nsw i32 %3005, %3004"
"  %3006 = add nuw nsw i32 %3005, %3004" -> "  %3124 = and i32 %3006, 65535""  %3006 = add nuw nsw i32 %3005, %3004" -> "  %3010 = lshr i32 %3006, 16"
"  %3007 = lshr i32 %3003, 16"
"  %3007 = lshr i32 %3003, 16" -> "  %3009 = add nuw nsw i32 %3007, %3008"
"  %3008 = mul nuw nsw i32 %1179, 11561"
"  %3008 = mul nuw nsw i32 %1179, 11561" -> "  %3009 = add nuw nsw i32 %3007, %3008"
"  %3009 = add nuw nsw i32 %3007, %3008"
"  %3009 = add nuw nsw i32 %3007, %3008" -> "  %3013 = and i32 %3009, 2147418112""  %3009 = add nuw nsw i32 %3007, %3008" -> "  %3011 = and i32 %3009, 65535"
"  %3010 = lshr i32 %3006, 16"
"  %3010 = lshr i32 %3006, 16" -> "  %3012 = add nuw nsw i32 %3010, %3011"
"  %3011 = and i32 %3009, 65535"
"  %3011 = and i32 %3009, 65535" -> "  %3012 = add nuw nsw i32 %3010, %3011"
"  %3012 = add nuw nsw i32 %3010, %3011"
"  %3012 = add nuw nsw i32 %3010, %3011" -> "  %3014 = add nuw nsw i32 %3012, %3013"
"  %3013 = and i32 %3009, 2147418112"
"  %3013 = and i32 %3009, 2147418112" -> "  %3014 = add nuw nsw i32 %3012, %3013"
"  %3014 = add nuw nsw i32 %3012, %3013"
"  %3014 = add nuw nsw i32 %3012, %3013" -> "  %3037 = lshr i32 %3014, 16""  %3014 = add nuw nsw i32 %3012, %3013" -> "  %3033 = and i32 %3014, 65535"
"  %3015 = mul nuw nsw i32 %1198, 4087"
"  %3015 = mul nuw nsw i32 %1198, 4087" -> "  %3034 = and i32 %3015, 65535""  %3015 = mul nuw nsw i32 %1198, 4087" -> "  %3016 = lshr i32 %3015, 16"
"  %3016 = lshr i32 %3015, 16"
"  %3016 = lshr i32 %3015, 16" -> "  %3019 = add nuw nsw i32 %3018, %3016"
"  %3017 = mul nuw nsw i32 %1201, 4087"
"  %3017 = mul nuw nsw i32 %1201, 4087" -> "  %3020 = and i32 %3017, 268369920""  %3017 = mul nuw nsw i32 %1201, 4087" -> "  %3018 = and i32 %3017, 65535"
"  %3018 = and i32 %3017, 65535"
"  %3018 = and i32 %3017, 65535" -> "  %3019 = add nuw nsw i32 %3018, %3016"
"  %3019 = add nuw nsw i32 %3018, %3016"
"  %3019 = add nuw nsw i32 %3018, %3016" -> "  %3021 = add nuw nsw i32 %3019, %3020"
"  %3020 = and i32 %3017, 268369920"
"  %3020 = and i32 %3017, 268369920" -> "  %3021 = add nuw nsw i32 %3019, %3020"
"  %3021 = add nuw nsw i32 %3019, %3020"
"  %3021 = add nuw nsw i32 %3019, %3020" -> "  %3025 = lshr i32 %3021, 16""  %3021 = add nuw nsw i32 %3019, %3020" -> "  %3023 = and i32 %3021, 65535"
"  %3022 = mul nuw nsw i32 %1198, 11561"
"  %3022 = mul nuw nsw i32 %1198, 11561" -> "  %3024 = add nuw nsw i32 %3023, %3022"
"  %3023 = and i32 %3021, 65535"
"  %3023 = and i32 %3021, 65535" -> "  %3024 = add nuw nsw i32 %3023, %3022"
"  %3024 = add nuw nsw i32 %3023, %3022"
"  %3024 = add nuw nsw i32 %3023, %3022" -> "  %3036 = and i32 %3024, 65535""  %3024 = add nuw nsw i32 %3023, %3022" -> "  %3028 = lshr i32 %3024, 16"
"  %3025 = lshr i32 %3021, 16"
"  %3025 = lshr i32 %3021, 16" -> "  %3027 = add nuw nsw i32 %3025, %3026"
"  %3026 = mul nuw nsw i32 %1201, 11561"
"  %3026 = mul nuw nsw i32 %1201, 11561" -> "  %3027 = add nuw nsw i32 %3025, %3026"
"  %3027 = add nuw nsw i32 %3025, %3026"
"  %3027 = add nuw nsw i32 %3025, %3026" -> "  %3031 = and i32 %3027, 2147418112""  %3027 = add nuw nsw i32 %3025, %3026" -> "  %3029 = and i32 %3027, 65535"
"  %3028 = lshr i32 %3024, 16"
"  %3028 = lshr i32 %3024, 16" -> "  %3030 = add nuw nsw i32 %3028, %3029"
"  %3029 = and i32 %3027, 65535"
"  %3029 = and i32 %3027, 65535" -> "  %3030 = add nuw nsw i32 %3028, %3029"
"  %3030 = add nuw nsw i32 %3028, %3029"
"  %3030 = add nuw nsw i32 %3028, %3029" -> "  %3032 = add nuw nsw i32 %3030, %3031"
"  %3031 = and i32 %3027, 2147418112"
"  %3031 = and i32 %3027, 2147418112" -> "  %3032 = add nuw nsw i32 %3030, %3031"
"  %3032 = add nuw nsw i32 %3030, %3031"
"  %3032 = add nuw nsw i32 %3030, %3031" -> "  %3040 = add nuw nsw i32 %3032, %3039"
"  %3033 = and i32 %3014, 65535"
"  %3033 = and i32 %3014, 65535" -> "  %3035 = add nuw nsw i32 %3033, %3034"
"  %3034 = and i32 %3015, 65535"
"  %3034 = and i32 %3015, 65535" -> "  %3035 = add nuw nsw i32 %3033, %3034"
"  %3035 = add nuw nsw i32 %3033, %3034"
"  %3035 = add nuw nsw i32 %3033, %3034" -> "  %3064 = and i32 %3035, 65535""  %3035 = add nuw nsw i32 %3033, %3034" -> "  %3042 = lshr i32 %3035, 16"
"  %3036 = and i32 %3024, 65535"
"  %3036 = and i32 %3024, 65535" -> "  %3038 = add nuw nsw i32 %3036, %3037"
"  %3037 = lshr i32 %3014, 16"
"  %3037 = lshr i32 %3014, 16" -> "  %3038 = add nuw nsw i32 %3036, %3037"
"  %3038 = add nuw nsw i32 %3036, %3037"
"  %3038 = add nuw nsw i32 %3036, %3037" -> "  %3041 = and i32 %3038, 65535""  %3038 = add nuw nsw i32 %3036, %3037" -> "  %3039 = lshr i32 %3038, 16"
"  %3039 = lshr i32 %3038, 16"
"  %3039 = lshr i32 %3038, 16" -> "  %3040 = add nuw nsw i32 %3032, %3039"
"  %3040 = add nuw nsw i32 %3032, %3039"
"  %3040 = add nuw nsw i32 %3032, %3039" -> "  %3045 = add nuw nsw i32 %3040, %3044"
"  %3041 = and i32 %3038, 65535"
"  %3041 = and i32 %3038, 65535" -> "  %3043 = add nuw nsw i32 %3041, %3042"
"  %3042 = lshr i32 %3035, 16"
"  %3042 = lshr i32 %3035, 16" -> "  %3043 = add nuw nsw i32 %3041, %3042"
"  %3043 = add nuw nsw i32 %3041, %3042"
"  %3043 = add nuw nsw i32 %3041, %3042" -> "  %3067 = and i32 %3043, 65535""  %3043 = add nuw nsw i32 %3041, %3042" -> "  %3044 = lshr i32 %3043, 16"
"  %3044 = lshr i32 %3043, 16"
"  %3044 = lshr i32 %3043, 16" -> "  %3045 = add nuw nsw i32 %3040, %3044"
"  %3045 = add nuw nsw i32 %3040, %3044"
"  %3045 = add nuw nsw i32 %3040, %3044" -> "  %3092 = and i32 %3045, 65535""  %3045 = add nuw nsw i32 %3040, %3044" -> "  %3096 = lshr i32 %3045, 16"
"  %3046 = mul nuw nsw i32 %1178, 21884"
"  %3046 = mul nuw nsw i32 %1178, 21884" -> "  %3065 = and i32 %3046, 65532""  %3046 = mul nuw nsw i32 %1178, 21884" -> "  %3047 = lshr i32 %3046, 16"
"  %3047 = lshr i32 %3046, 16"
"  %3047 = lshr i32 %3046, 16" -> "  %3050 = add nuw nsw i32 %3049, %3047"
"  %3048 = mul nuw nsw i32 %1179, 21884"
"  %3048 = mul nuw nsw i32 %1179, 21884" -> "  %3051 = and i32 %3048, 2147418112""  %3048 = mul nuw nsw i32 %1179, 21884" -> "  %3049 = and i32 %3048, 65532"
"  %3049 = and i32 %3048, 65532"
"  %3049 = and i32 %3048, 65532" -> "  %3050 = add nuw nsw i32 %3049, %3047"
"  %3050 = add nuw nsw i32 %3049, %3047"
"  %3050 = add nuw nsw i32 %3049, %3047" -> "  %3052 = add nuw nsw i32 %3050, %3051"
"  %3051 = and i32 %3048, 2147418112"
"  %3051 = and i32 %3048, 2147418112" -> "  %3052 = add nuw nsw i32 %3050, %3051"
"  %3052 = add nuw nsw i32 %3050, %3051"
"  %3052 = add nuw nsw i32 %3050, %3051" -> "  %3056 = lshr i32 %3052, 16""  %3052 = add nuw nsw i32 %3050, %3051" -> "  %3054 = and i32 %3052, 65535"
"  %3053 = mul nuw i32 %1178, 36786"
"  %3053 = mul nuw i32 %1178, 36786" -> "  %3055 = add nuw i32 %3054, %3053"
"  %3054 = and i32 %3052, 65535"
"  %3054 = and i32 %3052, 65535" -> "  %3055 = add nuw i32 %3054, %3053"
"  %3055 = add nuw i32 %3054, %3053"
"  %3055 = add nuw i32 %3054, %3053" -> "  %3068 = and i32 %3055, 65535""  %3055 = add nuw i32 %3054, %3053" -> "  %3059 = lshr i32 %3055, 16"
"  %3056 = lshr i32 %3052, 16"
"  %3056 = lshr i32 %3052, 16" -> "  %3058 = add nuw i32 %3056, %3057"
"  %3057 = mul nuw i32 %1179, 36786"
"  %3057 = mul nuw i32 %1179, 36786" -> "  %3058 = add nuw i32 %3056, %3057"
"  %3058 = add nuw i32 %3056, %3057"
"  %3058 = add nuw i32 %3056, %3057" -> "  %3062 = and i32 %3058, -65536""  %3058 = add nuw i32 %3056, %3057" -> "  %3060 = and i32 %3058, 65535"
"  %3059 = lshr i32 %3055, 16"
"  %3059 = lshr i32 %3055, 16" -> "  %3061 = add nuw nsw i32 %3059, %3060"
"  %3060 = and i32 %3058, 65535"
"  %3060 = and i32 %3058, 65535" -> "  %3061 = add nuw nsw i32 %3059, %3060"
"  %3061 = add nuw nsw i32 %3059, %3060"
"  %3061 = add nuw nsw i32 %3059, %3060" -> "  %3063 = add nuw i32 %3061, %3062"
"  %3062 = and i32 %3058, -65536"
"  %3062 = and i32 %3058, -65536" -> "  %3063 = add nuw i32 %3061, %3062"
"  %3063 = add nuw i32 %3061, %3062"
"  %3063 = add nuw i32 %3061, %3062" -> "  %3071 = add nuw i32 %3063, %3070"
"  %3064 = and i32 %3035, 65535"
"  %3064 = and i32 %3035, 65535" -> "  %3066 = add nuw nsw i32 %3064, %3065"
"  %3065 = and i32 %3046, 65532"
"  %3065 = and i32 %3046, 65532" -> "  %3066 = add nuw nsw i32 %3064, %3065"
"  %3066 = add nuw nsw i32 %3064, %3065"
"  %3066 = add nuw nsw i32 %3064, %3065" -> "  %3131 = and i32 %3066, 65535""  %3066 = add nuw nsw i32 %3064, %3065" -> "  %3073 = lshr i32 %3066, 16"
"  %3067 = and i32 %3043, 65535"
"  %3067 = and i32 %3043, 65535" -> "  %3069 = add nuw nsw i32 %3067, %3068"
"  %3068 = and i32 %3055, 65535"
"  %3068 = and i32 %3055, 65535" -> "  %3069 = add nuw nsw i32 %3067, %3068"
"  %3069 = add nuw nsw i32 %3067, %3068"
"  %3069 = add nuw nsw i32 %3067, %3068" -> "  %3072 = and i32 %3069, 65535""  %3069 = add nuw nsw i32 %3067, %3068" -> "  %3070 = lshr i32 %3069, 16"
"  %3070 = lshr i32 %3069, 16"
"  %3070 = lshr i32 %3069, 16" -> "  %3071 = add nuw i32 %3063, %3070"
"  %3071 = add nuw i32 %3063, %3070"
"  %3071 = add nuw i32 %3063, %3070" -> "  %3076 = add nuw i32 %3071, %3075"
"  %3072 = and i32 %3069, 65535"
"  %3072 = and i32 %3069, 65535" -> "  %3074 = add nuw nsw i32 %3072, %3073"
"  %3073 = lshr i32 %3066, 16"
"  %3073 = lshr i32 %3066, 16" -> "  %3074 = add nuw nsw i32 %3072, %3073"
"  %3074 = add nuw nsw i32 %3072, %3073"
"  %3074 = add nuw nsw i32 %3072, %3073" -> "  %3134 = and i32 %3074, 65535""  %3074 = add nuw nsw i32 %3072, %3073" -> "  %3075 = lshr i32 %3074, 16"
"  %3075 = lshr i32 %3074, 16"
"  %3075 = lshr i32 %3074, 16" -> "  %3076 = add nuw i32 %3071, %3075"
"  %3076 = add nuw i32 %3071, %3075"
"  %3076 = add nuw i32 %3071, %3075" -> "  %3106 = and i32 %3076, 65535""  %3076 = add nuw i32 %3071, %3075" -> "  %3109 = lshr i32 %3076, 16"
"  %3077 = mul nuw nsw i32 %1198, 21884"
"  %3077 = mul nuw nsw i32 %1198, 21884" -> "  %3093 = and i32 %3077, 65532""  %3077 = mul nuw nsw i32 %1198, 21884" -> "  %3078 = lshr i32 %3077, 16"
"  %3078 = lshr i32 %3077, 16"
"  %3078 = lshr i32 %3077, 16" -> "  %3080 = add nuw nsw i32 %3079, %3078"
"  %3079 = mul nuw nsw i32 %1201, 21884"
"  %3079 = mul nuw nsw i32 %1201, 21884" -> "  %3080 = add nuw nsw i32 %3079, %3078"
"  %3080 = add nuw nsw i32 %3079, %3078"
"  %3080 = add nuw nsw i32 %3079, %3078" -> "  %3084 = lshr i32 %3080, 16""  %3080 = add nuw nsw i32 %3079, %3078" -> "  %3082 = and i32 %3080, 65535"
"  %3081 = mul nuw i32 %1198, 36786"
"  %3081 = mul nuw i32 %1198, 36786" -> "  %3083 = add nuw i32 %3082, %3081"
"  %3082 = and i32 %3080, 65535"
"  %3082 = and i32 %3080, 65535" -> "  %3083 = add nuw i32 %3082, %3081"
"  %3083 = add nuw i32 %3082, %3081"
"  %3083 = add nuw i32 %3082, %3081" -> "  %3095 = and i32 %3083, 65535""  %3083 = add nuw i32 %3082, %3081" -> "  %3087 = lshr i32 %3083, 16"
"  %3084 = lshr i32 %3080, 16"
"  %3084 = lshr i32 %3080, 16" -> "  %3086 = add nuw i32 %3084, %3085"
"  %3085 = mul nuw i32 %1201, 36786"
"  %3085 = mul nuw i32 %1201, 36786" -> "  %3086 = add nuw i32 %3084, %3085"
"  %3086 = add nuw i32 %3084, %3085"
"  %3086 = add nuw i32 %3084, %3085" -> "  %3090 = and i32 %3086, -65536""  %3086 = add nuw i32 %3084, %3085" -> "  %3088 = and i32 %3086, 65535"
"  %3087 = lshr i32 %3083, 16"
"  %3087 = lshr i32 %3083, 16" -> "  %3089 = add nuw nsw i32 %3087, %3088"
"  %3088 = and i32 %3086, 65535"
"  %3088 = and i32 %3086, 65535" -> "  %3089 = add nuw nsw i32 %3087, %3088"
"  %3089 = add nuw nsw i32 %3087, %3088"
"  %3089 = add nuw nsw i32 %3087, %3088" -> "  %3091 = add nuw i32 %3089, %3090"
"  %3090 = and i32 %3086, -65536"
"  %3090 = and i32 %3086, -65536" -> "  %3091 = add nuw i32 %3089, %3090"
"  %3091 = add nuw i32 %3089, %3090"
"  %3091 = add nuw i32 %3089, %3090" -> "  %3099 = add nuw i32 %3091, %3098"
"  %3092 = and i32 %3045, 65535"
"  %3092 = and i32 %3045, 65535" -> "  %3094 = add nuw nsw i32 %3092, %3093"
"  %3093 = and i32 %3077, 65532"
"  %3093 = and i32 %3077, 65532" -> "  %3094 = add nuw nsw i32 %3092, %3093"
"  %3094 = add nuw nsw i32 %3092, %3093"
"  %3094 = add nuw nsw i32 %3092, %3093" -> "  %3105 = and i32 %3094, 65535""  %3094 = add nuw nsw i32 %3092, %3093" -> "  %3101 = lshr i32 %3094, 16"
"  %3095 = and i32 %3083, 65535"
"  %3095 = and i32 %3083, 65535" -> "  %3097 = add nuw nsw i32 %3096, %3095"
"  %3096 = lshr i32 %3045, 16"
"  %3096 = lshr i32 %3045, 16" -> "  %3097 = add nuw nsw i32 %3096, %3095"
"  %3097 = add nuw nsw i32 %3096, %3095"
"  %3097 = add nuw nsw i32 %3096, %3095" -> "  %3100 = and i32 %3097, 65535""  %3097 = add nuw nsw i32 %3096, %3095" -> "  %3098 = lshr i32 %3097, 16"
"  %3098 = lshr i32 %3097, 16"
"  %3098 = lshr i32 %3097, 16" -> "  %3099 = add nuw i32 %3091, %3098"
"  %3099 = add nuw i32 %3091, %3098"
"  %3099 = add nuw i32 %3091, %3098" -> "  %3104 = add nuw i32 %3099, %3103"
"  %3100 = and i32 %3097, 65535"
"  %3100 = and i32 %3097, 65535" -> "  %3102 = add nuw nsw i32 %3100, %3101"
"  %3101 = lshr i32 %3094, 16"
"  %3101 = lshr i32 %3094, 16" -> "  %3102 = add nuw nsw i32 %3100, %3101"
"  %3102 = add nuw nsw i32 %3100, %3101"
"  %3102 = add nuw nsw i32 %3100, %3101" -> "  %3108 = and i32 %3102, 65535""  %3102 = add nuw nsw i32 %3100, %3101" -> "  %3103 = lshr i32 %3102, 16"
"  %3103 = lshr i32 %3102, 16"
"  %3103 = lshr i32 %3102, 16" -> "  %3104 = add nuw i32 %3099, %3103"
"  %3104 = add nuw i32 %3099, %3103"
"  %3104 = add nuw i32 %3099, %3103" -> "  %3117 = and i32 %3104, -65536""  %3104 = add nuw i32 %3099, %3103" -> "  %3115 = and i32 %3104, 65535"
"  %3105 = and i32 %3094, 65535"
"  %3105 = and i32 %3094, 65535" -> "  %3107 = add nuw nsw i32 %3106, %3105"
"  %3106 = and i32 %3076, 65535"
"  %3106 = and i32 %3076, 65535" -> "  %3107 = add nuw nsw i32 %3106, %3105"
"  %3107 = add nuw nsw i32 %3106, %3105"
"  %3107 = add nuw nsw i32 %3106, %3105" -> "  %3147 = and i32 %3107, 65535""  %3107 = add nuw nsw i32 %3106, %3105" -> "  %3111 = lshr i32 %3107, 16"
"  %3108 = and i32 %3102, 65535"
"  %3108 = and i32 %3102, 65535" -> "  %3110 = add nuw nsw i32 %3108, %3109"
"  %3109 = lshr i32 %3076, 16"
"  %3109 = lshr i32 %3076, 16" -> "  %3110 = add nuw nsw i32 %3108, %3109"
"  %3110 = add nuw nsw i32 %3108, %3109"
"  %3110 = add nuw nsw i32 %3108, %3109" -> "  %3114 = lshr i32 %3110, 16""  %3110 = add nuw nsw i32 %3108, %3109" -> "  %3112 = and i32 %3110, 65535"
"  %3111 = lshr i32 %3107, 16"
"  %3111 = lshr i32 %3107, 16" -> "  %3113 = add nuw nsw i32 %3112, %3111"
"  %3112 = and i32 %3110, 65535"
"  %3112 = and i32 %3110, 65535" -> "  %3113 = add nuw nsw i32 %3112, %3111"
"  %3113 = add nuw nsw i32 %3112, %3111"
"  %3113 = add nuw nsw i32 %3112, %3111" -> "  %3154 = and i32 %3113, 65535""  %3113 = add nuw nsw i32 %3112, %3111" -> "  %3119 = lshr i32 %3113, 16"
"  %3114 = lshr i32 %3110, 16"
"  %3114 = lshr i32 %3110, 16" -> "  %3116 = add nuw nsw i32 %3114, %3115"
"  %3115 = and i32 %3104, 65535"
"  %3115 = and i32 %3104, 65535" -> "  %3116 = add nuw nsw i32 %3114, %3115"
"  %3116 = add nuw nsw i32 %3114, %3115"
"  %3116 = add nuw nsw i32 %3114, %3115" -> "  %3118 = add nuw i32 %3116, %3117"
"  %3117 = and i32 %3104, -65536"
"  %3117 = and i32 %3104, -65536" -> "  %3118 = add nuw i32 %3116, %3117"
"  %3118 = add nuw i32 %3116, %3117"
"  %3118 = add nuw i32 %3116, %3117" -> "  %3120 = add nuw i32 %3118, %3119"
"  %3119 = lshr i32 %3113, 16"
"  %3119 = lshr i32 %3113, 16" -> "  %3120 = add nuw i32 %3118, %3119"
"  %3120 = add nuw i32 %3118, %3119"
"  %3120 = add nuw i32 %3118, %3119" -> "  %3158 = add nuw i32 %3120, %3157"
"  %3121 = and i32 %2994, 65535"
"  %3121 = and i32 %2994, 65535" -> "  %3123 = add nuw nsw i32 %3122, %3121"
"  %3122 = and i32 %2814, 65535"
"  %3122 = and i32 %2814, 65535" -> "  %3123 = add nuw nsw i32 %3122, %3121"
"  %3123 = add nuw nsw i32 %3122, %3121"
"  %3123 = add nuw nsw i32 %3122, %3121" -> "  %3159 = and i32 %3123, 65535""  %3123 = add nuw nsw i32 %3122, %3121" -> "  %3127 = lshr i32 %3123, 16"
"  %3124 = and i32 %3006, 65535"
"  %3124 = and i32 %3006, 65535" -> "  %3126 = add nuw nsw i32 %3125, %3124"
"  %3125 = and i32 %2820, 65535"
"  %3125 = and i32 %2820, 65535" -> "  %3126 = add nuw nsw i32 %3125, %3124"
"  %3126 = add nuw nsw i32 %3125, %3124"
"  %3126 = add nuw nsw i32 %3125, %3124" -> "  %3140 = lshr i32 %3126, 16""  %3126 = add nuw nsw i32 %3125, %3124" -> "  %3128 = and i32 %3126, 65535"
"  %3127 = lshr i32 %3123, 16"
"  %3127 = lshr i32 %3123, 16" -> "  %3129 = add nuw nsw i32 %3128, %3127"
"  %3128 = and i32 %3126, 65535"
"  %3128 = and i32 %3126, 65535" -> "  %3129 = add nuw nsw i32 %3128, %3127"
"  %3129 = add nuw nsw i32 %3128, %3127"
"  %3129 = add nuw nsw i32 %3128, %3127" -> "  %3162 = and i32 %3129, 65535""  %3129 = add nuw nsw i32 %3128, %3127" -> "  %3142 = lshr i32 %3129, 16"
"  %3130 = and i32 %2822, 65535"
"  %3130 = and i32 %2822, 65535" -> "  %3132 = add nuw nsw i32 %3130, %3131"
"  %3131 = and i32 %3066, 65535"
"  %3131 = and i32 %3066, 65535" -> "  %3132 = add nuw nsw i32 %3130, %3131"
"  %3132 = add nuw nsw i32 %3130, %3131"
"  %3132 = add nuw nsw i32 %3130, %3131" -> "  %3139 = and i32 %3132, 65535""  %3132 = add nuw nsw i32 %3130, %3131" -> "  %3136 = lshr i32 %3132, 16"
"  %3133 = lshr i32 %2822, 16"
"  %3133 = lshr i32 %2822, 16" -> "  %3135 = add nuw nsw i32 %3133, %3134"
"  %3134 = and i32 %3074, 65535"
"  %3134 = and i32 %3074, 65535" -> "  %3135 = add nuw nsw i32 %3133, %3134"
"  %3135 = add nuw nsw i32 %3133, %3134"
"  %3135 = add nuw nsw i32 %3133, %3134" -> "  %3148 = lshr i32 %3135, 16""  %3135 = add nuw nsw i32 %3133, %3134" -> "  %3137 = and i32 %3135, 65535"
"  %3136 = lshr i32 %3132, 16"
"  %3136 = lshr i32 %3132, 16" -> "  %3138 = add nuw nsw i32 %3137, %3136"
"  %3137 = and i32 %3135, 65535"
"  %3137 = and i32 %3135, 65535" -> "  %3138 = add nuw nsw i32 %3137, %3136"
"  %3138 = add nuw nsw i32 %3137, %3136"
"  %3138 = add nuw nsw i32 %3137, %3136" -> "  %3150 = lshr i32 %3138, 16""  %3138 = add nuw nsw i32 %3137, %3136" -> "  %3145 = and i32 %3138, 65535"
"  %3139 = and i32 %3132, 65535"
"  %3139 = and i32 %3132, 65535" -> "  %3141 = add nuw nsw i32 %3139, %3140"
"  %3140 = lshr i32 %3126, 16"
"  %3140 = lshr i32 %3126, 16" -> "  %3141 = add nuw nsw i32 %3139, %3140"
"  %3141 = add nuw nsw i32 %3139, %3140"
"  %3141 = add nuw nsw i32 %3139, %3140" -> "  %3143 = add nuw nsw i32 %3141, %3142"
"  %3142 = lshr i32 %3129, 16"
"  %3142 = lshr i32 %3129, 16" -> "  %3143 = add nuw nsw i32 %3141, %3142"
"  %3143 = add nuw nsw i32 %3141, %3142"
"  %3143 = add nuw nsw i32 %3141, %3142" -> "  %3168 = and i32 %3143, 65535""  %3143 = add nuw nsw i32 %3141, %3142" -> "  %3144 = lshr i32 %3143, 16"
"  %3144 = lshr i32 %3143, 16"
"  %3144 = lshr i32 %3143, 16" -> "  %3146 = add nuw nsw i32 %3144, %3145"
"  %3145 = and i32 %3138, 65535"
"  %3145 = and i32 %3138, 65535" -> "  %3146 = add nuw nsw i32 %3144, %3145"
"  %3146 = add nuw nsw i32 %3144, %3145"
"  %3146 = add nuw nsw i32 %3144, %3145" -> "  %3171 = and i32 %3146, 65535""  %3146 = add nuw nsw i32 %3144, %3145" -> "  %3152 = lshr i32 %3146, 16"
"  %3147 = and i32 %3107, 65535"
"  %3147 = and i32 %3107, 65535" -> "  %3149 = add nuw nsw i32 %3148, %3147"
"  %3148 = lshr i32 %3135, 16"
"  %3148 = lshr i32 %3135, 16" -> "  %3149 = add nuw nsw i32 %3148, %3147"
"  %3149 = add nuw nsw i32 %3148, %3147"
"  %3149 = add nuw nsw i32 %3148, %3147" -> "  %3151 = add nuw nsw i32 %3149, %3150"
"  %3150 = lshr i32 %3138, 16"
"  %3150 = lshr i32 %3138, 16" -> "  %3151 = add nuw nsw i32 %3149, %3150"
"  %3151 = add nuw nsw i32 %3149, %3150"
"  %3151 = add nuw nsw i32 %3149, %3150" -> "  %3153 = add nuw nsw i32 %3151, %3152"
"  %3152 = lshr i32 %3146, 16"
"  %3152 = lshr i32 %3146, 16" -> "  %3153 = add nuw nsw i32 %3151, %3152"
"  %3153 = add nuw nsw i32 %3151, %3152"
"  %3153 = add nuw nsw i32 %3151, %3152" -> "  %3185 = and i32 %3153, 65535""  %3153 = add nuw nsw i32 %3151, %3152" -> "  %3155 = lshr i32 %3153, 16"
"  %3154 = and i32 %3113, 65535"
"  %3154 = and i32 %3113, 65535" -> "  %3156 = add nuw nsw i32 %3155, %3154"
"  %3155 = lshr i32 %3153, 16"
"  %3155 = lshr i32 %3153, 16" -> "  %3156 = add nuw nsw i32 %3155, %3154"
"  %3156 = add nuw nsw i32 %3155, %3154"
"  %3156 = add nuw nsw i32 %3155, %3154" -> "  %3192 = and i32 %3156, 65535""  %3156 = add nuw nsw i32 %3155, %3154" -> "  %3157 = lshr i32 %3156, 16"
"  %3157 = lshr i32 %3156, 16"
"  %3157 = lshr i32 %3156, 16" -> "  %3158 = add nuw i32 %3120, %3157"
"  %3158 = add nuw i32 %3120, %3157"
"  %3158 = add nuw i32 %3120, %3157" -> "  %3196 = add nuw i32 %3158, %3195"
"  %3159 = and i32 %3123, 65535"
"  %3159 = and i32 %3123, 65535" -> "  %3161 = add nuw nsw i32 %3160, %3159"
"  %3160 = and i32 %2988, 65535"
"  %3160 = and i32 %2988, 65535" -> "  %3161 = add nuw nsw i32 %3160, %3159"
"  %3161 = add nuw nsw i32 %3160, %3159"
"  %3161 = add nuw nsw i32 %3160, %3159" -> "  %3269 = and i32 %3161, 65535""  %3161 = add nuw nsw i32 %3160, %3159" -> "  %3165 = lshr i32 %3161, 16"
"  %3162 = and i32 %3129, 65535"
"  %3162 = and i32 %3129, 65535" -> "  %3164 = add nuw nsw i32 %3163, %3162"
"  %3163 = and i32 %2991, 65535"
"  %3163 = and i32 %2991, 65535" -> "  %3164 = add nuw nsw i32 %3163, %3162"
"  %3164 = add nuw nsw i32 %3163, %3162"
"  %3164 = add nuw nsw i32 %3163, %3162" -> "  %3178 = lshr i32 %3164, 16""  %3164 = add nuw nsw i32 %3163, %3162" -> "  %3166 = and i32 %3164, 65535"
"  %3165 = lshr i32 %3161, 16"
"  %3165 = lshr i32 %3161, 16" -> "  %3167 = add nuw nsw i32 %3166, %3165"
"  %3166 = and i32 %3164, 65535"
"  %3166 = and i32 %3164, 65535" -> "  %3167 = add nuw nsw i32 %3166, %3165"
"  %3167 = add nuw nsw i32 %3166, %3165"
"  %3167 = add nuw nsw i32 %3166, %3165" -> "  %3274 = and i32 %3167, 65535""  %3167 = add nuw nsw i32 %3166, %3165" -> "  %3180 = lshr i32 %3167, 16"
"  %3168 = and i32 %3143, 65535"
"  %3168 = and i32 %3143, 65535" -> "  %3170 = add nuw nsw i32 %3169, %3168"
"  %3169 = and i32 %2993, 65535"
"  %3169 = and i32 %2993, 65535" -> "  %3170 = add nuw nsw i32 %3169, %3168"
"  %3170 = add nuw nsw i32 %3169, %3168"
"  %3170 = add nuw nsw i32 %3169, %3168" -> "  %3177 = and i32 %3170, 65535""  %3170 = add nuw nsw i32 %3169, %3168" -> "  %3174 = lshr i32 %3170, 16"
"  %3171 = and i32 %3146, 65535"
"  %3171 = and i32 %3146, 65535" -> "  %3173 = add nuw nsw i32 %3171, %3172"
"  %3172 = lshr i32 %2993, 16"
"  %3172 = lshr i32 %2993, 16" -> "  %3173 = add nuw nsw i32 %3171, %3172"
"  %3173 = add nuw nsw i32 %3171, %3172"
"  %3173 = add nuw nsw i32 %3171, %3172" -> "  %3186 = lshr i32 %3173, 16""  %3173 = add nuw nsw i32 %3171, %3172" -> "  %3175 = and i32 %3173, 65535"
"  %3174 = lshr i32 %3170, 16"
"  %3174 = lshr i32 %3170, 16" -> "  %3176 = add nuw nsw i32 %3175, %3174"
"  %3175 = and i32 %3173, 65535"
"  %3175 = and i32 %3173, 65535" -> "  %3176 = add nuw nsw i32 %3175, %3174"
"  %3176 = add nuw nsw i32 %3175, %3174"
"  %3176 = add nuw nsw i32 %3175, %3174" -> "  %3188 = lshr i32 %3176, 16""  %3176 = add nuw nsw i32 %3175, %3174" -> "  %3183 = and i32 %3176, 65535"
"  %3177 = and i32 %3170, 65535"
"  %3177 = and i32 %3170, 65535" -> "  %3179 = add nuw nsw i32 %3177, %3178"
"  %3178 = lshr i32 %3164, 16"
"  %3178 = lshr i32 %3164, 16" -> "  %3179 = add nuw nsw i32 %3177, %3178"
"  %3179 = add nuw nsw i32 %3177, %3178"
"  %3179 = add nuw nsw i32 %3177, %3178" -> "  %3181 = add nuw nsw i32 %3179, %3180"
"  %3180 = lshr i32 %3167, 16"
"  %3180 = lshr i32 %3167, 16" -> "  %3181 = add nuw nsw i32 %3179, %3180"
"  %3181 = add nuw nsw i32 %3179, %3180"
"  %3181 = add nuw nsw i32 %3179, %3180" -> "  %3277 = and i32 %3181, 65535""  %3181 = add nuw nsw i32 %3179, %3180" -> "  %3182 = lshr i32 %3181, 16"
"  %3182 = lshr i32 %3181, 16"
"  %3182 = lshr i32 %3181, 16" -> "  %3184 = add nuw nsw i32 %3182, %3183"
"  %3183 = and i32 %3176, 65535"
"  %3183 = and i32 %3176, 65535" -> "  %3184 = add nuw nsw i32 %3182, %3183"
"  %3184 = add nuw nsw i32 %3182, %3183"
"  %3184 = add nuw nsw i32 %3182, %3183" -> "  %3281 = and i32 %3184, 65535""  %3184 = add nuw nsw i32 %3182, %3183" -> "  %3190 = lshr i32 %3184, 16"
"  %3185 = and i32 %3153, 65535"
"  %3185 = and i32 %3153, 65535" -> "  %3187 = add nuw nsw i32 %3186, %3185"
"  %3186 = lshr i32 %3173, 16"
"  %3186 = lshr i32 %3173, 16" -> "  %3187 = add nuw nsw i32 %3186, %3185"
"  %3187 = add nuw nsw i32 %3186, %3185"
"  %3187 = add nuw nsw i32 %3186, %3185" -> "  %3189 = add nuw nsw i32 %3187, %3188"
"  %3188 = lshr i32 %3176, 16"
"  %3188 = lshr i32 %3176, 16" -> "  %3189 = add nuw nsw i32 %3187, %3188"
"  %3189 = add nuw nsw i32 %3187, %3188"
"  %3189 = add nuw nsw i32 %3187, %3188" -> "  %3191 = add nuw nsw i32 %3189, %3190"
"  %3190 = lshr i32 %3184, 16"
"  %3190 = lshr i32 %3184, 16" -> "  %3191 = add nuw nsw i32 %3189, %3190"
"  %3191 = add nuw nsw i32 %3189, %3190"
"  %3191 = add nuw nsw i32 %3189, %3190" -> "  %3284 = and i32 %3191, 65535""  %3191 = add nuw nsw i32 %3189, %3190" -> "  %3193 = lshr i32 %3191, 16"
"  %3192 = and i32 %3156, 65535"
"  %3192 = and i32 %3156, 65535" -> "  %3194 = add nuw nsw i32 %3193, %3192"
"  %3193 = lshr i32 %3191, 16"
"  %3193 = lshr i32 %3191, 16" -> "  %3194 = add nuw nsw i32 %3193, %3192"
"  %3194 = add nuw nsw i32 %3193, %3192"
"  %3194 = add nuw nsw i32 %3193, %3192" -> "  %3287 = and i32 %3194, 65535""  %3194 = add nuw nsw i32 %3193, %3192" -> "  %3195 = lshr i32 %3194, 16"
"  %3195 = lshr i32 %3194, 16"
"  %3195 = lshr i32 %3194, 16" -> "  %3196 = add nuw i32 %3158, %3195"
"  %3196 = add nuw i32 %3158, %3195"
"  %3196 = add nuw i32 %3158, %3195" -> "  %3290 = add nuw i32 %3196, %3289"
"  %3197 = and i32 %2430, 65535"
"  %3197 = and i32 %2430, 65535" -> "  %3199 = add nuw nsw i32 %3197, %3198"
"  %3198 = and i32 %2522, 65535"
"  %3198 = and i32 %2522, 65535" -> "  %3199 = add nuw nsw i32 %3197, %3198"
"  %3199 = add nuw nsw i32 %3197, %3198"
"  %3199 = add nuw nsw i32 %3197, %3198" -> "  %3203 = lshr i32 %3199, 16"
"  %3200 = and i32 %2436, 65535"
"  %3200 = and i32 %2436, 65535" -> "  %3202 = add nuw nsw i32 %3200, %3201"
"  %3201 = and i32 %2531, 65535"
"  %3201 = and i32 %2531, 65535" -> "  %3202 = add nuw nsw i32 %3200, %3201"
"  %3202 = add nuw nsw i32 %3200, %3201"
"  %3202 = add nuw nsw i32 %3200, %3201" -> "  %3206 = lshr i32 %3202, 16""  %3202 = add nuw nsw i32 %3200, %3201" -> "  %3204 = and i32 %3202, 65535"
"  %3203 = lshr i32 %3199, 16"
"  %3203 = lshr i32 %3199, 16" -> "  %3205 = add nuw nsw i32 %3204, %3203"
"  %3204 = and i32 %3202, 65535"
"  %3204 = and i32 %3202, 65535" -> "  %3205 = add nuw nsw i32 %3204, %3203"
"  %3205 = add nuw nsw i32 %3204, %3203"
"  %3205 = add nuw nsw i32 %3204, %3203" -> "  %3207 = lshr i32 %3205, 16"
"  %3206 = lshr i32 %3202, 16"
"  %3206 = lshr i32 %3202, 16" -> "  %3218 = add nuw nsw i32 %3207, %3206"
"  %3207 = lshr i32 %3205, 16"
"  %3207 = lshr i32 %3205, 16" -> "  %3218 = add nuw nsw i32 %3207, %3206"
"  %3208 = and i32 %2450, 65535"
"  %3208 = and i32 %2450, 65535" -> "  %3210 = add nuw nsw i32 %3208, %3209"
"  %3209 = and i32 %2591, 65535"
"  %3209 = and i32 %2591, 65535" -> "  %3210 = add nuw nsw i32 %3208, %3209"
"  %3210 = add nuw nsw i32 %3208, %3209"
"  %3210 = add nuw nsw i32 %3208, %3209" -> "  %3217 = and i32 %3210, 65535""  %3210 = add nuw nsw i32 %3208, %3209" -> "  %3214 = lshr i32 %3210, 16"
"  %3211 = and i32 %2453, 65535"
"  %3211 = and i32 %2453, 65535" -> "  %3213 = add nuw nsw i32 %3211, %3212"
"  %3212 = and i32 %2599, 65535"
"  %3212 = and i32 %2599, 65535" -> "  %3213 = add nuw nsw i32 %3211, %3212"
"  %3213 = add nuw nsw i32 %3211, %3212"
"  %3213 = add nuw nsw i32 %3211, %3212" -> "  %3252 = lshr i32 %3213, 16""  %3213 = add nuw nsw i32 %3211, %3212" -> "  %3215 = and i32 %3213, 65535"
"  %3214 = lshr i32 %3210, 16"
"  %3214 = lshr i32 %3210, 16" -> "  %3216 = add nuw nsw i32 %3215, %3214"
"  %3215 = and i32 %3213, 65535"
"  %3215 = and i32 %3213, 65535" -> "  %3216 = add nuw nsw i32 %3215, %3214"
"  %3216 = add nuw nsw i32 %3215, %3214"
"  %3216 = add nuw nsw i32 %3215, %3214" -> "  %3254 = lshr i32 %3216, 16""  %3216 = add nuw nsw i32 %3215, %3214" -> "  %3221 = and i32 %3216, 65535"
"  %3217 = and i32 %3210, 65535"
"  %3217 = and i32 %3210, 65535" -> "  %3219 = add nuw nsw i32 %3218, %3217"
"  %3218 = add nuw nsw i32 %3207, %3206"
"  %3218 = add nuw nsw i32 %3207, %3206" -> "  %3219 = add nuw nsw i32 %3218, %3217"
"  %3219 = add nuw nsw i32 %3218, %3217"
"  %3219 = add nuw nsw i32 %3218, %3217" -> "  %3220 = lshr i32 %3219, 16"
"  %3220 = lshr i32 %3219, 16"
"  %3220 = lshr i32 %3219, 16" -> "  %3222 = add nuw nsw i32 %3221, %3220"
"  %3221 = and i32 %3216, 65535"
"  %3221 = and i32 %3216, 65535" -> "  %3222 = add nuw nsw i32 %3221, %3220"
"  %3222 = add nuw nsw i32 %3221, %3220"
"  %3222 = add nuw nsw i32 %3221, %3220" -> "  %3255 = lshr i32 %3222, 16"
"  %3223 = and i32 %2490, 65535"
"  %3223 = and i32 %2490, 65535" -> "  %3225 = add nuw nsw i32 %3223, %3224"
"  %3224 = and i32 %2952, 65535"
"  %3224 = and i32 %2952, 65535" -> "  %3225 = add nuw nsw i32 %3223, %3224"
"  %3225 = add nuw nsw i32 %3223, %3224"
"  %3225 = add nuw nsw i32 %3223, %3224" -> "  %3253 = and i32 %3225, 65535""  %3225 = add nuw nsw i32 %3223, %3224" -> "  %3229 = lshr i32 %3225, 16"
"  %3226 = and i32 %2493, 65535"
"  %3226 = and i32 %2493, 65535" -> "  %3228 = add nuw nsw i32 %3226, %3227"
"  %3227 = and i32 %2958, 65535"
"  %3227 = and i32 %2958, 65535" -> "  %3228 = add nuw nsw i32 %3226, %3227"
"  %3228 = add nuw nsw i32 %3226, %3227"
"  %3228 = add nuw nsw i32 %3226, %3227" -> "  %3232 = lshr i32 %3228, 16""  %3228 = add nuw nsw i32 %3226, %3227" -> "  %3230 = and i32 %3228, 65535"
"  %3229 = lshr i32 %3225, 16"
"  %3229 = lshr i32 %3225, 16" -> "  %3231 = add nuw nsw i32 %3230, %3229"
"  %3230 = and i32 %3228, 65535"
"  %3230 = and i32 %3228, 65535" -> "  %3231 = add nuw nsw i32 %3230, %3229"
"  %3231 = add nuw nsw i32 %3230, %3229"
"  %3231 = add nuw nsw i32 %3230, %3229" -> "  %3260 = and i32 %3231, 65535""  %3231 = add nuw nsw i32 %3230, %3229" -> "  %3233 = lshr i32 %3231, 16"
"  %3232 = lshr i32 %3228, 16"
"  %3232 = lshr i32 %3228, 16" -> "  %3234 = add nuw nsw i32 %3233, %3232"
"  %3233 = lshr i32 %3231, 16"
"  %3233 = lshr i32 %3231, 16" -> "  %3234 = add nuw nsw i32 %3233, %3232"
"  %3234 = add nuw nsw i32 %3233, %3232"
"  %3234 = add nuw nsw i32 %3233, %3232" -> "  %3247 = add nuw nsw i32 %3234, %3246"
"  %3235 = and i32 %2496, 65535"
"  %3235 = and i32 %2496, 65535" -> "  %3237 = add nuw nsw i32 %3235, %3236"
"  %3236 = and i32 %2972, 65535"
"  %3236 = and i32 %2972, 65535" -> "  %3237 = add nuw nsw i32 %3235, %3236"
"  %3237 = add nuw nsw i32 %3235, %3236"
"  %3237 = add nuw nsw i32 %3235, %3236" -> "  %3246 = and i32 %3237, 65535""  %3237 = add nuw nsw i32 %3235, %3236" -> "  %3241 = lshr i32 %3237, 16"
"  %3238 = and i32 %2499, 65535"
"  %3238 = and i32 %2499, 65535" -> "  %3240 = add nuw nsw i32 %3238, %3239"
"  %3239 = and i32 %2978, 65535"
"  %3239 = and i32 %2978, 65535" -> "  %3240 = add nuw nsw i32 %3238, %3239"
"  %3240 = add nuw nsw i32 %3238, %3239"
"  %3240 = add nuw nsw i32 %3238, %3239" -> "  %3244 = lshr i32 %3240, 16""  %3240 = add nuw nsw i32 %3238, %3239" -> "  %3242 = and i32 %3240, 65535"
"  %3241 = lshr i32 %3237, 16"
"  %3241 = lshr i32 %3237, 16" -> "  %3243 = add nuw nsw i32 %3242, %3241"
"  %3242 = and i32 %3240, 65535"
"  %3242 = and i32 %3240, 65535" -> "  %3243 = add nuw nsw i32 %3242, %3241"
"  %3243 = add nuw nsw i32 %3242, %3241"
"  %3243 = add nuw nsw i32 %3242, %3241" -> "  %3249 = and i32 %3243, 65535""  %3243 = add nuw nsw i32 %3242, %3241" -> "  %3245 = lshr i32 %3243, 16"
"  %3244 = lshr i32 %3240, 16"
"  %3244 = lshr i32 %3240, 16" -> "  %3270 = add nuw nsw i32 %3244, %3269"
"  %3245 = lshr i32 %3243, 16"
"  %3245 = lshr i32 %3243, 16" -> "  %3271 = add nuw nsw i32 %3270, %3245"
"  %3246 = and i32 %3237, 65535"
"  %3246 = and i32 %3237, 65535" -> "  %3247 = add nuw nsw i32 %3234, %3246"
"  %3247 = add nuw nsw i32 %3234, %3246"
"  %3247 = add nuw nsw i32 %3234, %3246" -> "  %3262 = and i32 %3247, 65535""  %3247 = add nuw nsw i32 %3234, %3246" -> "  %3248 = lshr i32 %3247, 16"
"  %3248 = lshr i32 %3247, 16"
"  %3248 = lshr i32 %3247, 16" -> "  %3250 = add nuw nsw i32 %3249, %3248"
"  %3249 = and i32 %3243, 65535"
"  %3249 = and i32 %3243, 65535" -> "  %3250 = add nuw nsw i32 %3249, %3248"
"  %3250 = add nuw nsw i32 %3249, %3248"
"  %3250 = add nuw nsw i32 %3249, %3248" -> "  %3265 = and i32 %3250, 65535""  %3250 = add nuw nsw i32 %3249, %3248" -> "  %3251 = lshr i32 %3250, 16"
"  %3251 = lshr i32 %3250, 16"
"  %3251 = lshr i32 %3250, 16" -> "  %3272 = add nuw nsw i32 %3271, %3251"
"  %3252 = lshr i32 %3213, 16"
"  %3252 = lshr i32 %3213, 16" -> "  %3256 = add nuw nsw i32 %3254, %3252"
"  %3253 = and i32 %3225, 65535"
"  %3253 = and i32 %3225, 65535" -> "  %3257 = add nuw nsw i32 %3256, %3253"
"  %3254 = lshr i32 %3216, 16"
"  %3254 = lshr i32 %3216, 16" -> "  %3256 = add nuw nsw i32 %3254, %3252"
"  %3255 = lshr i32 %3222, 16"
"  %3255 = lshr i32 %3222, 16" -> "  %3258 = add nuw nsw i32 %3257, %3255"
"  %3256 = add nuw nsw i32 %3254, %3252"
"  %3256 = add nuw nsw i32 %3254, %3252" -> "  %3257 = add nuw nsw i32 %3256, %3253"
"  %3257 = add nuw nsw i32 %3256, %3253"
"  %3257 = add nuw nsw i32 %3256, %3253" -> "  %3258 = add nuw nsw i32 %3257, %3255"
"  %3258 = add nuw nsw i32 %3257, %3255"
"  %3258 = add nuw nsw i32 %3257, %3255" -> "  %3259 = lshr i32 %3258, 16"
"  %3259 = lshr i32 %3258, 16"
"  %3259 = lshr i32 %3258, 16" -> "  %3261 = add nuw nsw i32 %3259, %3260"
"  %3260 = and i32 %3231, 65535"
"  %3260 = and i32 %3231, 65535" -> "  %3261 = add nuw nsw i32 %3259, %3260"
"  %3261 = add nuw nsw i32 %3259, %3260"
"  %3261 = add nuw nsw i32 %3259, %3260" -> "  %3263 = lshr i32 %3261, 16"
"  %3262 = and i32 %3247, 65535"
"  %3262 = and i32 %3247, 65535" -> "  %3264 = add nuw nsw i32 %3262, %3263"
"  %3263 = lshr i32 %3261, 16"
"  %3263 = lshr i32 %3261, 16" -> "  %3264 = add nuw nsw i32 %3262, %3263"
"  %3264 = add nuw nsw i32 %3262, %3263"
"  %3264 = add nuw nsw i32 %3262, %3263" -> "  %3266 = lshr i32 %3264, 16"
"  %3265 = and i32 %3250, 65535"
"  %3265 = and i32 %3250, 65535" -> "  %3267 = add nuw nsw i32 %3265, %3266"
"  %3266 = lshr i32 %3264, 16"
"  %3266 = lshr i32 %3264, 16" -> "  %3267 = add nuw nsw i32 %3265, %3266"
"  %3267 = add nuw nsw i32 %3265, %3266"
"  %3267 = add nuw nsw i32 %3265, %3266" -> "  %3268 = lshr i32 %3267, 16"
"  %3268 = lshr i32 %3267, 16"
"  %3268 = lshr i32 %3267, 16" -> "  %3273 = add nuw nsw i32 %3272, %3268"
"  %3269 = and i32 %3161, 65535"
"  %3269 = and i32 %3161, 65535" -> "  %3270 = add nuw nsw i32 %3244, %3269"
"  %3270 = add nuw nsw i32 %3244, %3269"
"  %3270 = add nuw nsw i32 %3244, %3269" -> "  %3271 = add nuw nsw i32 %3270, %3245"
"  %3271 = add nuw nsw i32 %3270, %3245"
"  %3271 = add nuw nsw i32 %3270, %3245" -> "  %3272 = add nuw nsw i32 %3271, %3251"
"  %3272 = add nuw nsw i32 %3271, %3251"
"  %3272 = add nuw nsw i32 %3271, %3251" -> "  %3273 = add nuw nsw i32 %3272, %3268"
"  %3273 = add nuw nsw i32 %3272, %3268"
"  %3273 = add nuw nsw i32 %3272, %3268" -> "  %4042 = and i32 %3273, 65535""  %3273 = add nuw nsw i32 %3272, %3268" -> "  %3275 = lshr i32 %3273, 16"
"  %3274 = and i32 %3167, 65535"
"  %3274 = and i32 %3167, 65535" -> "  %3276 = add nuw nsw i32 %3275, %3274"
"  %3275 = lshr i32 %3273, 16"
"  %3275 = lshr i32 %3273, 16" -> "  %3276 = add nuw nsw i32 %3275, %3274"
"  %3276 = add nuw nsw i32 %3275, %3274"
"  %3276 = add nuw nsw i32 %3275, %3274" -> "  %4046 = and i32 %3276, 65535""  %3276 = add nuw nsw i32 %3275, %3274" -> "  %3278 = lshr i32 %3276, 16"
"  %3277 = and i32 %3181, 65535"
"  %3277 = and i32 %3181, 65535" -> "  %3279 = add nuw nsw i32 %3278, %3277"
"  %3278 = lshr i32 %3276, 16"
"  %3278 = lshr i32 %3276, 16" -> "  %3279 = add nuw nsw i32 %3278, %3277"
"  %3279 = add nuw nsw i32 %3278, %3277"
"  %3279 = add nuw nsw i32 %3278, %3277" -> "  %4051 = and i32 %3279, 65535""  %3279 = add nuw nsw i32 %3278, %3277" -> "  %3280 = lshr i32 %3279, 16"
"  %3280 = lshr i32 %3279, 16"
"  %3280 = lshr i32 %3279, 16" -> "  %3282 = add nuw nsw i32 %3280, %3281"
"  %3281 = and i32 %3184, 65535"
"  %3281 = and i32 %3184, 65535" -> "  %3282 = add nuw nsw i32 %3280, %3281"
"  %3282 = add nuw nsw i32 %3280, %3281"
"  %3282 = add nuw nsw i32 %3280, %3281" -> "  %4054 = and i32 %3282, 65535""  %3282 = add nuw nsw i32 %3280, %3281" -> "  %3283 = lshr i32 %3282, 16"
"  %3283 = lshr i32 %3282, 16"
"  %3283 = lshr i32 %3282, 16" -> "  %3285 = add nuw nsw i32 %3283, %3284"
"  %3284 = and i32 %3191, 65535"
"  %3284 = and i32 %3191, 65535" -> "  %3285 = add nuw nsw i32 %3283, %3284"
"  %3285 = add nuw nsw i32 %3283, %3284"
"  %3285 = add nuw nsw i32 %3283, %3284" -> "  %4068 = and i32 %3285, 65535""  %3285 = add nuw nsw i32 %3283, %3284" -> "  %3286 = lshr i32 %3285, 16"
"  %3286 = lshr i32 %3285, 16"
"  %3286 = lshr i32 %3285, 16" -> "  %3288 = add nuw nsw i32 %3286, %3287"
"  %3287 = and i32 %3194, 65535"
"  %3287 = and i32 %3194, 65535" -> "  %3288 = add nuw nsw i32 %3286, %3287"
"  %3288 = add nuw nsw i32 %3286, %3287"
"  %3288 = add nuw nsw i32 %3286, %3287" -> "  %4071 = and i32 %3288, 65535""  %3288 = add nuw nsw i32 %3286, %3287" -> "  %3289 = lshr i32 %3288, 16"
"  %3289 = lshr i32 %3288, 16"
"  %3289 = lshr i32 %3288, 16" -> "  %3290 = add nuw i32 %3196, %3289"
"  %3290 = add nuw i32 %3196, %3289"
"  %3290 = add nuw i32 %3196, %3289" -> "  %4077 = and i32 %3290, 65535""  %3290 = add nuw i32 %3196, %3289" -> "  %4080 = lshr i32 %3290, 16"
"  %3291 = mul nuw i32 %1724, 42779"
"  %3291 = mul nuw i32 %1724, 42779" -> "  %3949 = and i32 %3291, 65535""  %3291 = mul nuw i32 %1724, 42779" -> "  %3292 = lshr i32 %3291, 16"
"  %3292 = lshr i32 %3291, 16"
"  %3292 = lshr i32 %3291, 16" -> "  %3295 = add nuw nsw i32 %3294, %3292"
"  %3293 = mul nuw i32 %1730, 42779"
"  %3293 = mul nuw i32 %1730, 42779" -> "  %3296 = and i32 %3293, -65536""  %3293 = mul nuw i32 %1730, 42779" -> "  %3294 = and i32 %3293, 65535"
"  %3294 = and i32 %3293, 65535"
"  %3294 = and i32 %3293, 65535" -> "  %3295 = add nuw nsw i32 %3294, %3292"
"  %3295 = add nuw nsw i32 %3294, %3292"
"  %3295 = add nuw nsw i32 %3294, %3292" -> "  %3297 = add nuw i32 %3295, %3296"
"  %3296 = and i32 %3293, -65536"
"  %3296 = and i32 %3293, -65536" -> "  %3297 = add nuw i32 %3295, %3296"
"  %3297 = add nuw i32 %3295, %3296"
"  %3297 = add nuw i32 %3295, %3296" -> "  %3301 = lshr i32 %3297, 16""  %3297 = add nuw i32 %3295, %3296" -> "  %3299 = and i32 %3297, 65535"
"  %3298 = mul nuw nsw i32 %1724, 9871"
"  %3298 = mul nuw nsw i32 %1724, 9871" -> "  %3300 = add nuw nsw i32 %3299, %3298"
"  %3299 = and i32 %3297, 65535"
"  %3299 = and i32 %3297, 65535" -> "  %3300 = add nuw nsw i32 %3299, %3298"
"  %3300 = add nuw nsw i32 %3299, %3298"
"  %3300 = add nuw nsw i32 %3299, %3298" -> "  %3952 = and i32 %3300, 65535""  %3300 = add nuw nsw i32 %3299, %3298" -> "  %3304 = lshr i32 %3300, 16"
"  %3301 = lshr i32 %3297, 16"
"  %3301 = lshr i32 %3297, 16" -> "  %3303 = add nuw nsw i32 %3301, %3302"
"  %3302 = mul nuw nsw i32 %1730, 9871"
"  %3302 = mul nuw nsw i32 %1730, 9871" -> "  %3303 = add nuw nsw i32 %3301, %3302"
"  %3303 = add nuw nsw i32 %3301, %3302"
"  %3303 = add nuw nsw i32 %3301, %3302" -> "  %3307 = and i32 %3303, 2147418112""  %3303 = add nuw nsw i32 %3301, %3302" -> "  %3305 = and i32 %3303, 65535"
"  %3304 = lshr i32 %3300, 16"
"  %3304 = lshr i32 %3300, 16" -> "  %3306 = add nuw nsw i32 %3304, %3305"
"  %3305 = and i32 %3303, 65535"
"  %3305 = and i32 %3303, 65535" -> "  %3306 = add nuw nsw i32 %3304, %3305"
"  %3306 = add nuw nsw i32 %3304, %3305"
"  %3306 = add nuw nsw i32 %3304, %3305" -> "  %3308 = add nuw nsw i32 %3306, %3307"
"  %3307 = and i32 %3303, 2147418112"
"  %3307 = and i32 %3303, 2147418112" -> "  %3308 = add nuw nsw i32 %3306, %3307"
"  %3308 = add nuw nsw i32 %3306, %3307"
"  %3308 = add nuw nsw i32 %3306, %3307" -> "  %3331 = lshr i32 %3308, 16""  %3308 = add nuw nsw i32 %3306, %3307" -> "  %3327 = and i32 %3308, 65535"
"  %3309 = mul nuw i32 %1750, 42779"
"  %3309 = mul nuw i32 %1750, 42779" -> "  %3328 = and i32 %3309, 65535""  %3309 = mul nuw i32 %1750, 42779" -> "  %3310 = lshr i32 %3309, 16"
"  %3310 = lshr i32 %3309, 16"
"  %3310 = lshr i32 %3309, 16" -> "  %3313 = add nuw nsw i32 %3312, %3310"
"  %3311 = mul nuw i32 %1751, 42779"
"  %3311 = mul nuw i32 %1751, 42779" -> "  %3314 = and i32 %3311, -65536""  %3311 = mul nuw i32 %1751, 42779" -> "  %3312 = and i32 %3311, 65535"
"  %3312 = and i32 %3311, 65535"
"  %3312 = and i32 %3311, 65535" -> "  %3313 = add nuw nsw i32 %3312, %3310"
"  %3313 = add nuw nsw i32 %3312, %3310"
"  %3313 = add nuw nsw i32 %3312, %3310" -> "  %3315 = add nuw i32 %3313, %3314"
"  %3314 = and i32 %3311, -65536"
"  %3314 = and i32 %3311, -65536" -> "  %3315 = add nuw i32 %3313, %3314"
"  %3315 = add nuw i32 %3313, %3314"
"  %3315 = add nuw i32 %3313, %3314" -> "  %3319 = lshr i32 %3315, 16""  %3315 = add nuw i32 %3313, %3314" -> "  %3317 = and i32 %3315, 65535"
"  %3316 = mul nuw nsw i32 %1750, 9871"
"  %3316 = mul nuw nsw i32 %1750, 9871" -> "  %3318 = add nuw nsw i32 %3317, %3316"
"  %3317 = and i32 %3315, 65535"
"  %3317 = and i32 %3315, 65535" -> "  %3318 = add nuw nsw i32 %3317, %3316"
"  %3318 = add nuw nsw i32 %3317, %3316"
"  %3318 = add nuw nsw i32 %3317, %3316" -> "  %3330 = and i32 %3318, 65535""  %3318 = add nuw nsw i32 %3317, %3316" -> "  %3322 = lshr i32 %3318, 16"
"  %3319 = lshr i32 %3315, 16"
"  %3319 = lshr i32 %3315, 16" -> "  %3321 = add nuw nsw i32 %3319, %3320"
"  %3320 = mul nuw nsw i32 %1751, 9871"
"  %3320 = mul nuw nsw i32 %1751, 9871" -> "  %3321 = add nuw nsw i32 %3319, %3320"
"  %3321 = add nuw nsw i32 %3319, %3320"
"  %3321 = add nuw nsw i32 %3319, %3320" -> "  %3325 = and i32 %3321, 2147418112""  %3321 = add nuw nsw i32 %3319, %3320" -> "  %3323 = and i32 %3321, 65535"
"  %3322 = lshr i32 %3318, 16"
"  %3322 = lshr i32 %3318, 16" -> "  %3324 = add nuw nsw i32 %3322, %3323"
"  %3323 = and i32 %3321, 65535"
"  %3323 = and i32 %3321, 65535" -> "  %3324 = add nuw nsw i32 %3322, %3323"
"  %3324 = add nuw nsw i32 %3322, %3323"
"  %3324 = add nuw nsw i32 %3322, %3323" -> "  %3326 = add nuw nsw i32 %3324, %3325"
"  %3325 = and i32 %3321, 2147418112"
"  %3325 = and i32 %3321, 2147418112" -> "  %3326 = add nuw nsw i32 %3324, %3325"
"  %3326 = add nuw nsw i32 %3324, %3325"
"  %3326 = add nuw nsw i32 %3324, %3325" -> "  %3334 = add nuw nsw i32 %3326, %3333"
"  %3327 = and i32 %3308, 65535"
"  %3327 = and i32 %3308, 65535" -> "  %3329 = add nuw nsw i32 %3327, %3328"
"  %3328 = and i32 %3309, 65535"
"  %3328 = and i32 %3309, 65535" -> "  %3329 = add nuw nsw i32 %3327, %3328"
"  %3329 = add nuw nsw i32 %3327, %3328"
"  %3329 = add nuw nsw i32 %3327, %3328" -> "  %3358 = and i32 %3329, 65535""  %3329 = add nuw nsw i32 %3327, %3328" -> "  %3336 = lshr i32 %3329, 16"
"  %3330 = and i32 %3318, 65535"
"  %3330 = and i32 %3318, 65535" -> "  %3332 = add nuw nsw i32 %3330, %3331"
"  %3331 = lshr i32 %3308, 16"
"  %3331 = lshr i32 %3308, 16" -> "  %3332 = add nuw nsw i32 %3330, %3331"
"  %3332 = add nuw nsw i32 %3330, %3331"
"  %3332 = add nuw nsw i32 %3330, %3331" -> "  %3335 = and i32 %3332, 65535""  %3332 = add nuw nsw i32 %3330, %3331" -> "  %3333 = lshr i32 %3332, 16"
"  %3333 = lshr i32 %3332, 16"
"  %3333 = lshr i32 %3332, 16" -> "  %3334 = add nuw nsw i32 %3326, %3333"
"  %3334 = add nuw nsw i32 %3326, %3333"
"  %3334 = add nuw nsw i32 %3326, %3333" -> "  %3339 = add nuw nsw i32 %3334, %3338"
"  %3335 = and i32 %3332, 65535"
"  %3335 = and i32 %3332, 65535" -> "  %3337 = add nuw nsw i32 %3335, %3336"
"  %3336 = lshr i32 %3329, 16"
"  %3336 = lshr i32 %3329, 16" -> "  %3337 = add nuw nsw i32 %3335, %3336"
"  %3337 = add nuw nsw i32 %3335, %3336"
"  %3337 = add nuw nsw i32 %3335, %3336" -> "  %3361 = and i32 %3337, 65535""  %3337 = add nuw nsw i32 %3335, %3336" -> "  %3338 = lshr i32 %3337, 16"
"  %3338 = lshr i32 %3337, 16"
"  %3338 = lshr i32 %3337, 16" -> "  %3339 = add nuw nsw i32 %3334, %3338"
"  %3339 = add nuw nsw i32 %3334, %3338"
"  %3339 = add nuw nsw i32 %3334, %3338" -> "  %3393 = lshr i32 %3339, 16""  %3339 = add nuw nsw i32 %3334, %3338" -> "  %3389 = and i32 %3339, 65535"
"  %3340 = mul nuw nsw i32 %1724, 24315"
"  %3340 = mul nuw nsw i32 %1724, 24315" -> "  %3359 = and i32 %3340, 65535""  %3340 = mul nuw nsw i32 %1724, 24315" -> "  %3341 = lshr i32 %3340, 16"
"  %3341 = lshr i32 %3340, 16"
"  %3341 = lshr i32 %3340, 16" -> "  %3344 = add nuw nsw i32 %3343, %3341"
"  %3342 = mul nuw nsw i32 %1730, 24315"
"  %3342 = mul nuw nsw i32 %1730, 24315" -> "  %3345 = and i32 %3342, 2147418112""  %3342 = mul nuw nsw i32 %1730, 24315" -> "  %3343 = and i32 %3342, 65535"
"  %3343 = and i32 %3342, 65535"
"  %3343 = and i32 %3342, 65535" -> "  %3344 = add nuw nsw i32 %3343, %3341"
"  %3344 = add nuw nsw i32 %3343, %3341"
"  %3344 = add nuw nsw i32 %3343, %3341" -> "  %3346 = add nuw nsw i32 %3344, %3345"
"  %3345 = and i32 %3342, 2147418112"
"  %3345 = and i32 %3342, 2147418112" -> "  %3346 = add nuw nsw i32 %3344, %3345"
"  %3346 = add nuw nsw i32 %3344, %3345"
"  %3346 = add nuw nsw i32 %3344, %3345" -> "  %3350 = lshr i32 %3346, 16""  %3346 = add nuw nsw i32 %3344, %3345" -> "  %3348 = and i32 %3346, 65535"
"  %3347 = mul nuw nsw i32 %1724, 29744"
"  %3347 = mul nuw nsw i32 %1724, 29744" -> "  %3349 = add nuw nsw i32 %3348, %3347"
"  %3348 = and i32 %3346, 65535"
"  %3348 = and i32 %3346, 65535" -> "  %3349 = add nuw nsw i32 %3348, %3347"
"  %3349 = add nuw nsw i32 %3348, %3347"
"  %3349 = add nuw nsw i32 %3348, %3347" -> "  %3362 = and i32 %3349, 65535""  %3349 = add nuw nsw i32 %3348, %3347" -> "  %3353 = lshr i32 %3349, 16"
"  %3350 = lshr i32 %3346, 16"
"  %3350 = lshr i32 %3346, 16" -> "  %3352 = add nuw nsw i32 %3350, %3351"
"  %3351 = mul nuw nsw i32 %1730, 29744"
"  %3351 = mul nuw nsw i32 %1730, 29744" -> "  %3352 = add nuw nsw i32 %3350, %3351"
"  %3352 = add nuw nsw i32 %3350, %3351"
"  %3352 = add nuw nsw i32 %3350, %3351" -> "  %3356 = and i32 %3352, 2147418112""  %3352 = add nuw nsw i32 %3350, %3351" -> "  %3354 = and i32 %3352, 65535"
"  %3353 = lshr i32 %3349, 16"
"  %3353 = lshr i32 %3349, 16" -> "  %3355 = add nuw nsw i32 %3353, %3354"
"  %3354 = and i32 %3352, 65535"
"  %3354 = and i32 %3352, 65535" -> "  %3355 = add nuw nsw i32 %3353, %3354"
"  %3355 = add nuw nsw i32 %3353, %3354"
"  %3355 = add nuw nsw i32 %3353, %3354" -> "  %3357 = add nuw nsw i32 %3355, %3356"
"  %3356 = and i32 %3352, 2147418112"
"  %3356 = and i32 %3352, 2147418112" -> "  %3357 = add nuw nsw i32 %3355, %3356"
"  %3357 = add nuw nsw i32 %3355, %3356"
"  %3357 = add nuw nsw i32 %3355, %3356" -> "  %3365 = add nuw nsw i32 %3357, %3364"
"  %3358 = and i32 %3329, 65535"
"  %3358 = and i32 %3329, 65535" -> "  %3360 = add nuw nsw i32 %3358, %3359"
"  %3359 = and i32 %3340, 65535"
"  %3359 = and i32 %3340, 65535" -> "  %3360 = add nuw nsw i32 %3358, %3359"
"  %3360 = add nuw nsw i32 %3358, %3359"
"  %3360 = add nuw nsw i32 %3358, %3359" -> "  %3958 = and i32 %3360, 65535""  %3360 = add nuw nsw i32 %3358, %3359" -> "  %3367 = lshr i32 %3360, 16"
"  %3361 = and i32 %3337, 65535"
"  %3361 = and i32 %3337, 65535" -> "  %3363 = add nuw nsw i32 %3361, %3362"
"  %3362 = and i32 %3349, 65535"
"  %3362 = and i32 %3349, 65535" -> "  %3363 = add nuw nsw i32 %3361, %3362"
"  %3363 = add nuw nsw i32 %3361, %3362"
"  %3363 = add nuw nsw i32 %3361, %3362" -> "  %3366 = and i32 %3363, 65535""  %3363 = add nuw nsw i32 %3361, %3362" -> "  %3364 = lshr i32 %3363, 16"
"  %3364 = lshr i32 %3363, 16"
"  %3364 = lshr i32 %3363, 16" -> "  %3365 = add nuw nsw i32 %3357, %3364"
"  %3365 = add nuw nsw i32 %3357, %3364"
"  %3365 = add nuw nsw i32 %3357, %3364" -> "  %3370 = add nuw nsw i32 %3365, %3369"
"  %3366 = and i32 %3363, 65535"
"  %3366 = and i32 %3363, 65535" -> "  %3368 = add nuw nsw i32 %3366, %3367"
"  %3367 = lshr i32 %3360, 16"
"  %3367 = lshr i32 %3360, 16" -> "  %3368 = add nuw nsw i32 %3366, %3367"
"  %3368 = add nuw nsw i32 %3366, %3367"
"  %3368 = add nuw nsw i32 %3366, %3367" -> "  %3961 = and i32 %3368, 65535""  %3368 = add nuw nsw i32 %3366, %3367" -> "  %3369 = lshr i32 %3368, 16"
"  %3369 = lshr i32 %3368, 16"
"  %3369 = lshr i32 %3368, 16" -> "  %3370 = add nuw nsw i32 %3365, %3369"
"  %3370 = add nuw nsw i32 %3365, %3369"
"  %3370 = add nuw nsw i32 %3365, %3369" -> "  %3402 = and i32 %3370, 65535""  %3370 = add nuw nsw i32 %3365, %3369" -> "  %3405 = lshr i32 %3370, 16"
"  %3371 = mul nuw nsw i32 %1750, 24315"
"  %3371 = mul nuw nsw i32 %1750, 24315" -> "  %3390 = and i32 %3371, 65535""  %3371 = mul nuw nsw i32 %1750, 24315" -> "  %3372 = lshr i32 %3371, 16"
"  %3372 = lshr i32 %3371, 16"
"  %3372 = lshr i32 %3371, 16" -> "  %3375 = add nuw nsw i32 %3374, %3372"
"  %3373 = mul nuw nsw i32 %1751, 24315"
"  %3373 = mul nuw nsw i32 %1751, 24315" -> "  %3376 = and i32 %3373, 2147418112""  %3373 = mul nuw nsw i32 %1751, 24315" -> "  %3374 = and i32 %3373, 65535"
"  %3374 = and i32 %3373, 65535"
"  %3374 = and i32 %3373, 65535" -> "  %3375 = add nuw nsw i32 %3374, %3372"
"  %3375 = add nuw nsw i32 %3374, %3372"
"  %3375 = add nuw nsw i32 %3374, %3372" -> "  %3377 = add nuw nsw i32 %3375, %3376"
"  %3376 = and i32 %3373, 2147418112"
"  %3376 = and i32 %3373, 2147418112" -> "  %3377 = add nuw nsw i32 %3375, %3376"
"  %3377 = add nuw nsw i32 %3375, %3376"
"  %3377 = add nuw nsw i32 %3375, %3376" -> "  %3381 = lshr i32 %3377, 16""  %3377 = add nuw nsw i32 %3375, %3376" -> "  %3379 = and i32 %3377, 65535"
"  %3378 = mul nuw nsw i32 %1750, 29744"
"  %3378 = mul nuw nsw i32 %1750, 29744" -> "  %3380 = add nuw nsw i32 %3379, %3378"
"  %3379 = and i32 %3377, 65535"
"  %3379 = and i32 %3377, 65535" -> "  %3380 = add nuw nsw i32 %3379, %3378"
"  %3380 = add nuw nsw i32 %3379, %3378"
"  %3380 = add nuw nsw i32 %3379, %3378" -> "  %3392 = and i32 %3380, 65535""  %3380 = add nuw nsw i32 %3379, %3378" -> "  %3384 = lshr i32 %3380, 16"
"  %3381 = lshr i32 %3377, 16"
"  %3381 = lshr i32 %3377, 16" -> "  %3383 = add nuw nsw i32 %3381, %3382"
"  %3382 = mul nuw nsw i32 %1751, 29744"
"  %3382 = mul nuw nsw i32 %1751, 29744" -> "  %3383 = add nuw nsw i32 %3381, %3382"
"  %3383 = add nuw nsw i32 %3381, %3382"
"  %3383 = add nuw nsw i32 %3381, %3382" -> "  %3387 = and i32 %3383, 2147418112""  %3383 = add nuw nsw i32 %3381, %3382" -> "  %3385 = and i32 %3383, 65535"
"  %3384 = lshr i32 %3380, 16"
"  %3384 = lshr i32 %3380, 16" -> "  %3386 = add nuw nsw i32 %3384, %3385"
"  %3385 = and i32 %3383, 65535"
"  %3385 = and i32 %3383, 65535" -> "  %3386 = add nuw nsw i32 %3384, %3385"
"  %3386 = add nuw nsw i32 %3384, %3385"
"  %3386 = add nuw nsw i32 %3384, %3385" -> "  %3388 = add nuw nsw i32 %3386, %3387"
"  %3387 = and i32 %3383, 2147418112"
"  %3387 = and i32 %3383, 2147418112" -> "  %3388 = add nuw nsw i32 %3386, %3387"
"  %3388 = add nuw nsw i32 %3386, %3387"
"  %3388 = add nuw nsw i32 %3386, %3387" -> "  %3396 = add nuw nsw i32 %3388, %3395"
"  %3389 = and i32 %3339, 65535"
"  %3389 = and i32 %3339, 65535" -> "  %3391 = add nuw nsw i32 %3389, %3390"
"  %3390 = and i32 %3371, 65535"
"  %3390 = and i32 %3371, 65535" -> "  %3391 = add nuw nsw i32 %3389, %3390"
"  %3391 = add nuw nsw i32 %3389, %3390"
"  %3391 = add nuw nsw i32 %3389, %3390" -> "  %3403 = and i32 %3391, 65535""  %3391 = add nuw nsw i32 %3389, %3390" -> "  %3398 = lshr i32 %3391, 16"
"  %3392 = and i32 %3380, 65535"
"  %3392 = and i32 %3380, 65535" -> "  %3394 = add nuw nsw i32 %3393, %3392"
"  %3393 = lshr i32 %3339, 16"
"  %3393 = lshr i32 %3339, 16" -> "  %3394 = add nuw nsw i32 %3393, %3392"
"  %3394 = add nuw nsw i32 %3393, %3392"
"  %3394 = add nuw nsw i32 %3393, %3392" -> "  %3397 = and i32 %3394, 65535""  %3394 = add nuw nsw i32 %3393, %3392" -> "  %3395 = lshr i32 %3394, 16"
"  %3395 = lshr i32 %3394, 16"
"  %3395 = lshr i32 %3394, 16" -> "  %3396 = add nuw nsw i32 %3388, %3395"
"  %3396 = add nuw nsw i32 %3388, %3395"
"  %3396 = add nuw nsw i32 %3388, %3395" -> "  %3401 = add nuw nsw i32 %3396, %3400"
"  %3397 = and i32 %3394, 65535"
"  %3397 = and i32 %3394, 65535" -> "  %3399 = add nuw nsw i32 %3398, %3397"
"  %3398 = lshr i32 %3391, 16"
"  %3398 = lshr i32 %3391, 16" -> "  %3399 = add nuw nsw i32 %3398, %3397"
"  %3399 = add nuw nsw i32 %3398, %3397"
"  %3399 = add nuw nsw i32 %3398, %3397" -> "  %3406 = and i32 %3399, 65535""  %3399 = add nuw nsw i32 %3398, %3397" -> "  %3400 = lshr i32 %3399, 16"
"  %3400 = lshr i32 %3399, 16"
"  %3400 = lshr i32 %3399, 16" -> "  %3401 = add nuw nsw i32 %3396, %3400"
"  %3401 = add nuw nsw i32 %3396, %3400"
"  %3401 = add nuw nsw i32 %3396, %3400" -> "  %3413 = add nuw nsw i32 %3401, %3411"
"  %3402 = and i32 %3370, 65535"
"  %3402 = and i32 %3370, 65535" -> "  %3404 = add nuw nsw i32 %3402, %3403"
"  %3403 = and i32 %3391, 65535"
"  %3403 = and i32 %3391, 65535" -> "  %3404 = add nuw nsw i32 %3402, %3403"
"  %3404 = add nuw nsw i32 %3402, %3403"
"  %3404 = add nuw nsw i32 %3402, %3403" -> "  %3542 = and i32 %3404, 65535""  %3404 = add nuw nsw i32 %3402, %3403" -> "  %3408 = lshr i32 %3404, 16"
"  %3405 = lshr i32 %3370, 16"
"  %3405 = lshr i32 %3370, 16" -> "  %3407 = add nuw nsw i32 %3405, %3406"
"  %3406 = and i32 %3399, 65535"
"  %3406 = and i32 %3399, 65535" -> "  %3407 = add nuw nsw i32 %3405, %3406"
"  %3407 = add nuw nsw i32 %3405, %3406"
"  %3407 = add nuw nsw i32 %3405, %3406" -> "  %3411 = lshr i32 %3407, 16""  %3407 = add nuw nsw i32 %3405, %3406" -> "  %3409 = and i32 %3407, 65535"
"  %3408 = lshr i32 %3404, 16"
"  %3408 = lshr i32 %3404, 16" -> "  %3410 = add nuw nsw i32 %3409, %3408"
"  %3409 = and i32 %3407, 65535"
"  %3409 = and i32 %3407, 65535" -> "  %3410 = add nuw nsw i32 %3409, %3408"
"  %3410 = add nuw nsw i32 %3409, %3408"
"  %3410 = add nuw nsw i32 %3409, %3408" -> "  %3545 = and i32 %3410, 65535""  %3410 = add nuw nsw i32 %3409, %3408" -> "  %3412 = lshr i32 %3410, 16"
"  %3411 = lshr i32 %3407, 16"
"  %3411 = lshr i32 %3407, 16" -> "  %3413 = add nuw nsw i32 %3401, %3411"
"  %3412 = lshr i32 %3410, 16"
"  %3412 = lshr i32 %3410, 16" -> "  %3414 = add nuw nsw i32 %3413, %3412"
"  %3413 = add nuw nsw i32 %3401, %3411"
"  %3413 = add nuw nsw i32 %3401, %3411" -> "  %3414 = add nuw nsw i32 %3413, %3412"
"  %3414 = add nuw nsw i32 %3413, %3412"
"  %3414 = add nuw nsw i32 %3413, %3412" -> "  %3555 = lshr i32 %3414, 16""  %3414 = add nuw nsw i32 %3413, %3412" -> "  %3552 = and i32 %3414, 65535"
"  %3415 = mul nuw i32 %1873, 42779"
"  %3415 = mul nuw i32 %1873, 42779" -> "  %3543 = and i32 %3415, 65535""  %3415 = mul nuw i32 %1873, 42779" -> "  %3416 = lshr i32 %3415, 16"
"  %3416 = lshr i32 %3415, 16"
"  %3416 = lshr i32 %3415, 16" -> "  %3419 = add nuw nsw i32 %3418, %3416"
"  %3417 = mul nuw i32 %1879, 42779"
"  %3417 = mul nuw i32 %1879, 42779" -> "  %3420 = and i32 %3417, -65536""  %3417 = mul nuw i32 %1879, 42779" -> "  %3418 = and i32 %3417, 65535"
"  %3418 = and i32 %3417, 65535"
"  %3418 = and i32 %3417, 65535" -> "  %3419 = add nuw nsw i32 %3418, %3416"
"  %3419 = add nuw nsw i32 %3418, %3416"
"  %3419 = add nuw nsw i32 %3418, %3416" -> "  %3421 = add nuw i32 %3419, %3420"
"  %3420 = and i32 %3417, -65536"
"  %3420 = and i32 %3417, -65536" -> "  %3421 = add nuw i32 %3419, %3420"
"  %3421 = add nuw i32 %3419, %3420"
"  %3421 = add nuw i32 %3419, %3420" -> "  %3425 = lshr i32 %3421, 16""  %3421 = add nuw i32 %3419, %3420" -> "  %3423 = and i32 %3421, 65535"
"  %3422 = mul nuw nsw i32 %1873, 9871"
"  %3422 = mul nuw nsw i32 %1873, 9871" -> "  %3424 = add nuw nsw i32 %3423, %3422"
"  %3423 = and i32 %3421, 65535"
"  %3423 = and i32 %3421, 65535" -> "  %3424 = add nuw nsw i32 %3423, %3422"
"  %3424 = add nuw nsw i32 %3423, %3422"
"  %3424 = add nuw nsw i32 %3423, %3422" -> "  %3546 = and i32 %3424, 65535""  %3424 = add nuw nsw i32 %3423, %3422" -> "  %3428 = lshr i32 %3424, 16"
"  %3425 = lshr i32 %3421, 16"
"  %3425 = lshr i32 %3421, 16" -> "  %3427 = add nuw nsw i32 %3425, %3426"
"  %3426 = mul nuw nsw i32 %1879, 9871"
"  %3426 = mul nuw nsw i32 %1879, 9871" -> "  %3427 = add nuw nsw i32 %3425, %3426"
"  %3427 = add nuw nsw i32 %3425, %3426"
"  %3427 = add nuw nsw i32 %3425, %3426" -> "  %3431 = and i32 %3427, 2147418112""  %3427 = add nuw nsw i32 %3425, %3426" -> "  %3429 = and i32 %3427, 65535"
"  %3428 = lshr i32 %3424, 16"
"  %3428 = lshr i32 %3424, 16" -> "  %3430 = add nuw nsw i32 %3428, %3429"
"  %3429 = and i32 %3427, 65535"
"  %3429 = and i32 %3427, 65535" -> "  %3430 = add nuw nsw i32 %3428, %3429"
"  %3430 = add nuw nsw i32 %3428, %3429"
"  %3430 = add nuw nsw i32 %3428, %3429" -> "  %3432 = add nuw nsw i32 %3430, %3431"
"  %3431 = and i32 %3427, 2147418112"
"  %3431 = and i32 %3427, 2147418112" -> "  %3432 = add nuw nsw i32 %3430, %3431"
"  %3432 = add nuw nsw i32 %3430, %3431"
"  %3432 = add nuw nsw i32 %3430, %3431" -> "  %3455 = lshr i32 %3432, 16""  %3432 = add nuw nsw i32 %3430, %3431" -> "  %3451 = and i32 %3432, 65535"
"  %3433 = mul nuw i32 %1896, 42779"
"  %3433 = mul nuw i32 %1896, 42779" -> "  %3452 = and i32 %3433, 65535""  %3433 = mul nuw i32 %1896, 42779" -> "  %3434 = lshr i32 %3433, 16"
"  %3434 = lshr i32 %3433, 16"
"  %3434 = lshr i32 %3433, 16" -> "  %3437 = add nuw nsw i32 %3436, %3434"
"  %3435 = mul nuw i32 %1897, 42779"
"  %3435 = mul nuw i32 %1897, 42779" -> "  %3438 = and i32 %3435, -65536""  %3435 = mul nuw i32 %1897, 42779" -> "  %3436 = and i32 %3435, 65535"
"  %3436 = and i32 %3435, 65535"
"  %3436 = and i32 %3435, 65535" -> "  %3437 = add nuw nsw i32 %3436, %3434"
"  %3437 = add nuw nsw i32 %3436, %3434"
"  %3437 = add nuw nsw i32 %3436, %3434" -> "  %3439 = add nuw i32 %3437, %3438"
"  %3438 = and i32 %3435, -65536"
"  %3438 = and i32 %3435, -65536" -> "  %3439 = add nuw i32 %3437, %3438"
"  %3439 = add nuw i32 %3437, %3438"
"  %3439 = add nuw i32 %3437, %3438" -> "  %3443 = lshr i32 %3439, 16""  %3439 = add nuw i32 %3437, %3438" -> "  %3441 = and i32 %3439, 65535"
"  %3440 = mul nuw nsw i32 %1896, 9871"
"  %3440 = mul nuw nsw i32 %1896, 9871" -> "  %3442 = add nuw nsw i32 %3441, %3440"
"  %3441 = and i32 %3439, 65535"
"  %3441 = and i32 %3439, 65535" -> "  %3442 = add nuw nsw i32 %3441, %3440"
"  %3442 = add nuw nsw i32 %3441, %3440"
"  %3442 = add nuw nsw i32 %3441, %3440" -> "  %3454 = and i32 %3442, 65535""  %3442 = add nuw nsw i32 %3441, %3440" -> "  %3446 = lshr i32 %3442, 16"
"  %3443 = lshr i32 %3439, 16"
"  %3443 = lshr i32 %3439, 16" -> "  %3445 = add nuw nsw i32 %3443, %3444"
"  %3444 = mul nuw nsw i32 %1897, 9871"
"  %3444 = mul nuw nsw i32 %1897, 9871" -> "  %3445 = add nuw nsw i32 %3443, %3444"
"  %3445 = add nuw nsw i32 %3443, %3444"
"  %3445 = add nuw nsw i32 %3443, %3444" -> "  %3449 = and i32 %3445, 2147418112""  %3445 = add nuw nsw i32 %3443, %3444" -> "  %3447 = and i32 %3445, 65535"
"  %3446 = lshr i32 %3442, 16"
"  %3446 = lshr i32 %3442, 16" -> "  %3448 = add nuw nsw i32 %3446, %3447"
"  %3447 = and i32 %3445, 65535"
"  %3447 = and i32 %3445, 65535" -> "  %3448 = add nuw nsw i32 %3446, %3447"
"  %3448 = add nuw nsw i32 %3446, %3447"
"  %3448 = add nuw nsw i32 %3446, %3447" -> "  %3450 = add nuw nsw i32 %3448, %3449"
"  %3449 = and i32 %3445, 2147418112"
"  %3449 = and i32 %3445, 2147418112" -> "  %3450 = add nuw nsw i32 %3448, %3449"
"  %3450 = add nuw nsw i32 %3448, %3449"
"  %3450 = add nuw nsw i32 %3448, %3449" -> "  %3458 = add nuw nsw i32 %3450, %3457"
"  %3451 = and i32 %3432, 65535"
"  %3451 = and i32 %3432, 65535" -> "  %3453 = add nuw nsw i32 %3451, %3452"
"  %3452 = and i32 %3433, 65535"
"  %3452 = and i32 %3433, 65535" -> "  %3453 = add nuw nsw i32 %3451, %3452"
"  %3453 = add nuw nsw i32 %3451, %3452"
"  %3453 = add nuw nsw i32 %3451, %3452" -> "  %3482 = and i32 %3453, 65535""  %3453 = add nuw nsw i32 %3451, %3452" -> "  %3460 = lshr i32 %3453, 16"
"  %3454 = and i32 %3442, 65535"
"  %3454 = and i32 %3442, 65535" -> "  %3456 = add nuw nsw i32 %3455, %3454"
"  %3455 = lshr i32 %3432, 16"
"  %3455 = lshr i32 %3432, 16" -> "  %3456 = add nuw nsw i32 %3455, %3454"
"  %3456 = add nuw nsw i32 %3455, %3454"
"  %3456 = add nuw nsw i32 %3455, %3454" -> "  %3459 = and i32 %3456, 65535""  %3456 = add nuw nsw i32 %3455, %3454" -> "  %3457 = lshr i32 %3456, 16"
"  %3457 = lshr i32 %3456, 16"
"  %3457 = lshr i32 %3456, 16" -> "  %3458 = add nuw nsw i32 %3450, %3457"
"  %3458 = add nuw nsw i32 %3450, %3457"
"  %3458 = add nuw nsw i32 %3450, %3457" -> "  %3463 = add nuw nsw i32 %3458, %3462"
"  %3459 = and i32 %3456, 65535"
"  %3459 = and i32 %3456, 65535" -> "  %3461 = add nuw nsw i32 %3459, %3460"
"  %3460 = lshr i32 %3453, 16"
"  %3460 = lshr i32 %3453, 16" -> "  %3461 = add nuw nsw i32 %3459, %3460"
"  %3461 = add nuw nsw i32 %3459, %3460"
"  %3461 = add nuw nsw i32 %3459, %3460" -> "  %3485 = and i32 %3461, 65535""  %3461 = add nuw nsw i32 %3459, %3460" -> "  %3462 = lshr i32 %3461, 16"
"  %3462 = lshr i32 %3461, 16"
"  %3462 = lshr i32 %3461, 16" -> "  %3463 = add nuw nsw i32 %3458, %3462"
"  %3463 = add nuw nsw i32 %3458, %3462"
"  %3463 = add nuw nsw i32 %3458, %3462" -> "  %3517 = lshr i32 %3463, 16""  %3463 = add nuw nsw i32 %3458, %3462" -> "  %3513 = and i32 %3463, 65535"
"  %3464 = mul nuw nsw i32 %1873, 24315"
"  %3464 = mul nuw nsw i32 %1873, 24315" -> "  %3483 = and i32 %3464, 65535""  %3464 = mul nuw nsw i32 %1873, 24315" -> "  %3465 = lshr i32 %3464, 16"
"  %3465 = lshr i32 %3464, 16"
"  %3465 = lshr i32 %3464, 16" -> "  %3468 = add nuw nsw i32 %3467, %3465"
"  %3466 = mul nuw nsw i32 %1879, 24315"
"  %3466 = mul nuw nsw i32 %1879, 24315" -> "  %3469 = and i32 %3466, 2147418112""  %3466 = mul nuw nsw i32 %1879, 24315" -> "  %3467 = and i32 %3466, 65535"
"  %3467 = and i32 %3466, 65535"
"  %3467 = and i32 %3466, 65535" -> "  %3468 = add nuw nsw i32 %3467, %3465"
"  %3468 = add nuw nsw i32 %3467, %3465"
"  %3468 = add nuw nsw i32 %3467, %3465" -> "  %3470 = add nuw nsw i32 %3468, %3469"
"  %3469 = and i32 %3466, 2147418112"
"  %3469 = and i32 %3466, 2147418112" -> "  %3470 = add nuw nsw i32 %3468, %3469"
"  %3470 = add nuw nsw i32 %3468, %3469"
"  %3470 = add nuw nsw i32 %3468, %3469" -> "  %3474 = lshr i32 %3470, 16""  %3470 = add nuw nsw i32 %3468, %3469" -> "  %3472 = and i32 %3470, 65535"
"  %3471 = mul nuw nsw i32 %1873, 29744"
"  %3471 = mul nuw nsw i32 %1873, 29744" -> "  %3473 = add nuw nsw i32 %3472, %3471"
"  %3472 = and i32 %3470, 65535"
"  %3472 = and i32 %3470, 65535" -> "  %3473 = add nuw nsw i32 %3472, %3471"
"  %3473 = add nuw nsw i32 %3472, %3471"
"  %3473 = add nuw nsw i32 %3472, %3471" -> "  %3486 = and i32 %3473, 65535""  %3473 = add nuw nsw i32 %3472, %3471" -> "  %3477 = lshr i32 %3473, 16"
"  %3474 = lshr i32 %3470, 16"
"  %3474 = lshr i32 %3470, 16" -> "  %3476 = add nuw nsw i32 %3474, %3475"
"  %3475 = mul nuw nsw i32 %1879, 29744"
"  %3475 = mul nuw nsw i32 %1879, 29744" -> "  %3476 = add nuw nsw i32 %3474, %3475"
"  %3476 = add nuw nsw i32 %3474, %3475"
"  %3476 = add nuw nsw i32 %3474, %3475" -> "  %3480 = and i32 %3476, 2147418112""  %3476 = add nuw nsw i32 %3474, %3475" -> "  %3478 = and i32 %3476, 65535"
"  %3477 = lshr i32 %3473, 16"
"  %3477 = lshr i32 %3473, 16" -> "  %3479 = add nuw nsw i32 %3477, %3478"
"  %3478 = and i32 %3476, 65535"
"  %3478 = and i32 %3476, 65535" -> "  %3479 = add nuw nsw i32 %3477, %3478"
"  %3479 = add nuw nsw i32 %3477, %3478"
"  %3479 = add nuw nsw i32 %3477, %3478" -> "  %3481 = add nuw nsw i32 %3479, %3480"
"  %3480 = and i32 %3476, 2147418112"
"  %3480 = and i32 %3476, 2147418112" -> "  %3481 = add nuw nsw i32 %3479, %3480"
"  %3481 = add nuw nsw i32 %3479, %3480"
"  %3481 = add nuw nsw i32 %3479, %3480" -> "  %3489 = add nuw nsw i32 %3481, %3488"
"  %3482 = and i32 %3453, 65535"
"  %3482 = and i32 %3453, 65535" -> "  %3484 = add nuw nsw i32 %3482, %3483"
"  %3483 = and i32 %3464, 65535"
"  %3483 = and i32 %3464, 65535" -> "  %3484 = add nuw nsw i32 %3482, %3483"
"  %3484 = add nuw nsw i32 %3482, %3483"
"  %3484 = add nuw nsw i32 %3482, %3483" -> "  %3551 = and i32 %3484, 65535""  %3484 = add nuw nsw i32 %3482, %3483" -> "  %3491 = lshr i32 %3484, 16"
"  %3485 = and i32 %3461, 65535"
"  %3485 = and i32 %3461, 65535" -> "  %3487 = add nuw nsw i32 %3485, %3486"
"  %3486 = and i32 %3473, 65535"
"  %3486 = and i32 %3473, 65535" -> "  %3487 = add nuw nsw i32 %3485, %3486"
"  %3487 = add nuw nsw i32 %3485, %3486"
"  %3487 = add nuw nsw i32 %3485, %3486" -> "  %3490 = and i32 %3487, 65535""  %3487 = add nuw nsw i32 %3485, %3486" -> "  %3488 = lshr i32 %3487, 16"
"  %3488 = lshr i32 %3487, 16"
"  %3488 = lshr i32 %3487, 16" -> "  %3489 = add nuw nsw i32 %3481, %3488"
"  %3489 = add nuw nsw i32 %3481, %3488"
"  %3489 = add nuw nsw i32 %3481, %3488" -> "  %3494 = add nuw nsw i32 %3489, %3493"
"  %3490 = and i32 %3487, 65535"
"  %3490 = and i32 %3487, 65535" -> "  %3492 = add nuw nsw i32 %3490, %3491"
"  %3491 = lshr i32 %3484, 16"
"  %3491 = lshr i32 %3484, 16" -> "  %3492 = add nuw nsw i32 %3490, %3491"
"  %3492 = add nuw nsw i32 %3490, %3491"
"  %3492 = add nuw nsw i32 %3490, %3491" -> "  %3554 = and i32 %3492, 65535""  %3492 = add nuw nsw i32 %3490, %3491" -> "  %3493 = lshr i32 %3492, 16"
"  %3493 = lshr i32 %3492, 16"
"  %3493 = lshr i32 %3492, 16" -> "  %3494 = add nuw nsw i32 %3489, %3493"
"  %3494 = add nuw nsw i32 %3489, %3493"
"  %3494 = add nuw nsw i32 %3489, %3493" -> "  %3530 = lshr i32 %3494, 16""  %3494 = add nuw nsw i32 %3489, %3493" -> "  %3527 = and i32 %3494, 65535"
"  %3495 = mul nuw nsw i32 %1896, 24315"
"  %3495 = mul nuw nsw i32 %1896, 24315" -> "  %3514 = and i32 %3495, 65535""  %3495 = mul nuw nsw i32 %1896, 24315" -> "  %3496 = lshr i32 %3495, 16"
"  %3496 = lshr i32 %3495, 16"
"  %3496 = lshr i32 %3495, 16" -> "  %3499 = add nuw nsw i32 %3498, %3496"
"  %3497 = mul nuw nsw i32 %1897, 24315"
"  %3497 = mul nuw nsw i32 %1897, 24315" -> "  %3500 = and i32 %3497, 2147418112""  %3497 = mul nuw nsw i32 %1897, 24315" -> "  %3498 = and i32 %3497, 65535"
"  %3498 = and i32 %3497, 65535"
"  %3498 = and i32 %3497, 65535" -> "  %3499 = add nuw nsw i32 %3498, %3496"
"  %3499 = add nuw nsw i32 %3498, %3496"
"  %3499 = add nuw nsw i32 %3498, %3496" -> "  %3501 = add nuw nsw i32 %3499, %3500"
"  %3500 = and i32 %3497, 2147418112"
"  %3500 = and i32 %3497, 2147418112" -> "  %3501 = add nuw nsw i32 %3499, %3500"
"  %3501 = add nuw nsw i32 %3499, %3500"
"  %3501 = add nuw nsw i32 %3499, %3500" -> "  %3505 = lshr i32 %3501, 16""  %3501 = add nuw nsw i32 %3499, %3500" -> "  %3503 = and i32 %3501, 65535"
"  %3502 = mul nuw nsw i32 %1896, 29744"
"  %3502 = mul nuw nsw i32 %1896, 29744" -> "  %3504 = add nuw nsw i32 %3503, %3502"
"  %3503 = and i32 %3501, 65535"
"  %3503 = and i32 %3501, 65535" -> "  %3504 = add nuw nsw i32 %3503, %3502"
"  %3504 = add nuw nsw i32 %3503, %3502"
"  %3504 = add nuw nsw i32 %3503, %3502" -> "  %3516 = and i32 %3504, 65535""  %3504 = add nuw nsw i32 %3503, %3502" -> "  %3508 = lshr i32 %3504, 16"
"  %3505 = lshr i32 %3501, 16"
"  %3505 = lshr i32 %3501, 16" -> "  %3507 = add nuw nsw i32 %3505, %3506"
"  %3506 = mul nuw nsw i32 %1897, 29744"
"  %3506 = mul nuw nsw i32 %1897, 29744" -> "  %3507 = add nuw nsw i32 %3505, %3506"
"  %3507 = add nuw nsw i32 %3505, %3506"
"  %3507 = add nuw nsw i32 %3505, %3506" -> "  %3511 = and i32 %3507, 2147418112""  %3507 = add nuw nsw i32 %3505, %3506" -> "  %3509 = and i32 %3507, 65535"
"  %3508 = lshr i32 %3504, 16"
"  %3508 = lshr i32 %3504, 16" -> "  %3510 = add nuw nsw i32 %3508, %3509"
"  %3509 = and i32 %3507, 65535"
"  %3509 = and i32 %3507, 65535" -> "  %3510 = add nuw nsw i32 %3508, %3509"
"  %3510 = add nuw nsw i32 %3508, %3509"
"  %3510 = add nuw nsw i32 %3508, %3509" -> "  %3512 = add nuw nsw i32 %3510, %3511"
"  %3511 = and i32 %3507, 2147418112"
"  %3511 = and i32 %3507, 2147418112" -> "  %3512 = add nuw nsw i32 %3510, %3511"
"  %3512 = add nuw nsw i32 %3510, %3511"
"  %3512 = add nuw nsw i32 %3510, %3511" -> "  %3520 = add nuw nsw i32 %3512, %3519"
"  %3513 = and i32 %3463, 65535"
"  %3513 = and i32 %3463, 65535" -> "  %3515 = add nuw nsw i32 %3513, %3514"
"  %3514 = and i32 %3495, 65535"
"  %3514 = and i32 %3495, 65535" -> "  %3515 = add nuw nsw i32 %3513, %3514"
"  %3515 = add nuw nsw i32 %3513, %3514"
"  %3515 = add nuw nsw i32 %3513, %3514" -> "  %3526 = and i32 %3515, 65535""  %3515 = add nuw nsw i32 %3513, %3514" -> "  %3522 = lshr i32 %3515, 16"
"  %3516 = and i32 %3504, 65535"
"  %3516 = and i32 %3504, 65535" -> "  %3518 = add nuw nsw i32 %3517, %3516"
"  %3517 = lshr i32 %3463, 16"
"  %3517 = lshr i32 %3463, 16" -> "  %3518 = add nuw nsw i32 %3517, %3516"
"  %3518 = add nuw nsw i32 %3517, %3516"
"  %3518 = add nuw nsw i32 %3517, %3516" -> "  %3521 = and i32 %3518, 65535""  %3518 = add nuw nsw i32 %3517, %3516" -> "  %3519 = lshr i32 %3518, 16"
"  %3519 = lshr i32 %3518, 16"
"  %3519 = lshr i32 %3518, 16" -> "  %3520 = add nuw nsw i32 %3512, %3519"
"  %3520 = add nuw nsw i32 %3512, %3519"
"  %3520 = add nuw nsw i32 %3512, %3519" -> "  %3525 = add nuw nsw i32 %3520, %3524"
"  %3521 = and i32 %3518, 65535"
"  %3521 = and i32 %3518, 65535" -> "  %3523 = add nuw nsw i32 %3522, %3521"
"  %3522 = lshr i32 %3515, 16"
"  %3522 = lshr i32 %3515, 16" -> "  %3523 = add nuw nsw i32 %3522, %3521"
"  %3523 = add nuw nsw i32 %3522, %3521"
"  %3523 = add nuw nsw i32 %3522, %3521" -> "  %3529 = and i32 %3523, 65535""  %3523 = add nuw nsw i32 %3522, %3521" -> "  %3524 = lshr i32 %3523, 16"
"  %3524 = lshr i32 %3523, 16"
"  %3524 = lshr i32 %3523, 16" -> "  %3525 = add nuw nsw i32 %3520, %3524"
"  %3525 = add nuw nsw i32 %3520, %3524"
"  %3525 = add nuw nsw i32 %3520, %3524" -> "  %3538 = and i32 %3525, 2147418112""  %3525 = add nuw nsw i32 %3520, %3524" -> "  %3536 = and i32 %3525, 65535"
"  %3526 = and i32 %3515, 65535"
"  %3526 = and i32 %3515, 65535" -> "  %3528 = add nuw nsw i32 %3527, %3526"
"  %3527 = and i32 %3494, 65535"
"  %3527 = and i32 %3494, 65535" -> "  %3528 = add nuw nsw i32 %3527, %3526"
"  %3528 = add nuw nsw i32 %3527, %3526"
"  %3528 = add nuw nsw i32 %3527, %3526" -> "  %3569 = and i32 %3528, 65535""  %3528 = add nuw nsw i32 %3527, %3526" -> "  %3532 = lshr i32 %3528, 16"
"  %3529 = and i32 %3523, 65535"
"  %3529 = and i32 %3523, 65535" -> "  %3531 = add nuw nsw i32 %3530, %3529"
"  %3530 = lshr i32 %3494, 16"
"  %3530 = lshr i32 %3494, 16" -> "  %3531 = add nuw nsw i32 %3530, %3529"
"  %3531 = add nuw nsw i32 %3530, %3529"
"  %3531 = add nuw nsw i32 %3530, %3529" -> "  %3535 = lshr i32 %3531, 16""  %3531 = add nuw nsw i32 %3530, %3529" -> "  %3533 = and i32 %3531, 65535"
"  %3532 = lshr i32 %3528, 16"
"  %3532 = lshr i32 %3528, 16" -> "  %3534 = add nuw nsw i32 %3532, %3533"
"  %3533 = and i32 %3531, 65535"
"  %3533 = and i32 %3531, 65535" -> "  %3534 = add nuw nsw i32 %3532, %3533"
"  %3534 = add nuw nsw i32 %3532, %3533"
"  %3534 = add nuw nsw i32 %3532, %3533" -> "  %3576 = and i32 %3534, 65535""  %3534 = add nuw nsw i32 %3532, %3533" -> "  %3540 = lshr i32 %3534, 16"
"  %3535 = lshr i32 %3531, 16"
"  %3535 = lshr i32 %3531, 16" -> "  %3537 = add nuw nsw i32 %3535, %3536"
"  %3536 = and i32 %3525, 65535"
"  %3536 = and i32 %3525, 65535" -> "  %3537 = add nuw nsw i32 %3535, %3536"
"  %3537 = add nuw nsw i32 %3535, %3536"
"  %3537 = add nuw nsw i32 %3535, %3536" -> "  %3539 = add nuw nsw i32 %3537, %3538"
"  %3538 = and i32 %3525, 2147418112"
"  %3538 = and i32 %3525, 2147418112" -> "  %3539 = add nuw nsw i32 %3537, %3538"
"  %3539 = add nuw nsw i32 %3537, %3538"
"  %3539 = add nuw nsw i32 %3537, %3538" -> "  %3541 = add nuw nsw i32 %3539, %3540"
"  %3540 = lshr i32 %3534, 16"
"  %3540 = lshr i32 %3534, 16" -> "  %3541 = add nuw nsw i32 %3539, %3540"
"  %3541 = add nuw nsw i32 %3539, %3540"
"  %3541 = add nuw nsw i32 %3539, %3540" -> "  %3579 = add nuw nsw i32 %3541, %3578"
"  %3542 = and i32 %3404, 65535"
"  %3542 = and i32 %3404, 65535" -> "  %3544 = add nuw nsw i32 %3542, %3543"
"  %3543 = and i32 %3415, 65535"
"  %3543 = and i32 %3415, 65535" -> "  %3544 = add nuw nsw i32 %3542, %3543"
"  %3544 = add nuw nsw i32 %3542, %3543"
"  %3544 = add nuw nsw i32 %3542, %3543" -> "  %3708 = and i32 %3544, 65535""  %3544 = add nuw nsw i32 %3542, %3543" -> "  %3548 = lshr i32 %3544, 16"
"  %3545 = and i32 %3410, 65535"
"  %3545 = and i32 %3410, 65535" -> "  %3547 = add nuw nsw i32 %3545, %3546"
"  %3546 = and i32 %3424, 65535"
"  %3546 = and i32 %3424, 65535" -> "  %3547 = add nuw nsw i32 %3545, %3546"
"  %3547 = add nuw nsw i32 %3545, %3546"
"  %3547 = add nuw nsw i32 %3545, %3546" -> "  %3561 = lshr i32 %3547, 16""  %3547 = add nuw nsw i32 %3545, %3546" -> "  %3549 = and i32 %3547, 65535"
"  %3548 = lshr i32 %3544, 16"
"  %3548 = lshr i32 %3544, 16" -> "  %3550 = add nuw nsw i32 %3549, %3548"
"  %3549 = and i32 %3547, 65535"
"  %3549 = and i32 %3547, 65535" -> "  %3550 = add nuw nsw i32 %3549, %3548"
"  %3550 = add nuw nsw i32 %3549, %3548"
"  %3550 = add nuw nsw i32 %3549, %3548" -> "  %3711 = and i32 %3550, 65535""  %3550 = add nuw nsw i32 %3549, %3548" -> "  %3563 = lshr i32 %3550, 16"
"  %3551 = and i32 %3484, 65535"
"  %3551 = and i32 %3484, 65535" -> "  %3553 = add nuw nsw i32 %3552, %3551"
"  %3552 = and i32 %3414, 65535"
"  %3552 = and i32 %3414, 65535" -> "  %3553 = add nuw nsw i32 %3552, %3551"
"  %3553 = add nuw nsw i32 %3552, %3551"
"  %3553 = add nuw nsw i32 %3552, %3551" -> "  %3560 = and i32 %3553, 65535""  %3553 = add nuw nsw i32 %3552, %3551" -> "  %3557 = lshr i32 %3553, 16"
"  %3554 = and i32 %3492, 65535"
"  %3554 = and i32 %3492, 65535" -> "  %3556 = add nuw nsw i32 %3555, %3554"
"  %3555 = lshr i32 %3414, 16"
"  %3555 = lshr i32 %3414, 16" -> "  %3556 = add nuw nsw i32 %3555, %3554"
"  %3556 = add nuw nsw i32 %3555, %3554"
"  %3556 = add nuw nsw i32 %3555, %3554" -> "  %3568 = lshr i32 %3556, 16""  %3556 = add nuw nsw i32 %3555, %3554" -> "  %3558 = and i32 %3556, 65535"
"  %3557 = lshr i32 %3553, 16"
"  %3557 = lshr i32 %3553, 16" -> "  %3559 = add nuw nsw i32 %3558, %3557"
"  %3558 = and i32 %3556, 65535"
"  %3558 = and i32 %3556, 65535" -> "  %3559 = add nuw nsw i32 %3558, %3557"
"  %3559 = add nuw nsw i32 %3558, %3557"
"  %3559 = add nuw nsw i32 %3558, %3557" -> "  %3566 = and i32 %3559, 65535""  %3559 = add nuw nsw i32 %3558, %3557" -> "  %3570 = lshr i32 %3559, 16"
"  %3560 = and i32 %3553, 65535"
"  %3560 = and i32 %3553, 65535" -> "  %3562 = add nuw nsw i32 %3560, %3561"
"  %3561 = lshr i32 %3547, 16"
"  %3561 = lshr i32 %3547, 16" -> "  %3562 = add nuw nsw i32 %3560, %3561"
"  %3562 = add nuw nsw i32 %3560, %3561"
"  %3562 = add nuw nsw i32 %3560, %3561" -> "  %3564 = add nuw nsw i32 %3562, %3563"
"  %3563 = lshr i32 %3550, 16"
"  %3563 = lshr i32 %3550, 16" -> "  %3564 = add nuw nsw i32 %3562, %3563"
"  %3564 = add nuw nsw i32 %3562, %3563"
"  %3564 = add nuw nsw i32 %3562, %3563" -> "  %3720 = and i32 %3564, 65535""  %3564 = add nuw nsw i32 %3562, %3563" -> "  %3565 = lshr i32 %3564, 16"
"  %3565 = lshr i32 %3564, 16"
"  %3565 = lshr i32 %3564, 16" -> "  %3567 = add nuw nsw i32 %3565, %3566"
"  %3566 = and i32 %3559, 65535"
"  %3566 = and i32 %3559, 65535" -> "  %3567 = add nuw nsw i32 %3565, %3566"
"  %3567 = add nuw nsw i32 %3565, %3566"
"  %3567 = add nuw nsw i32 %3565, %3566" -> "  %3722 = and i32 %3567, 65535""  %3567 = add nuw nsw i32 %3565, %3566" -> "  %3571 = lshr i32 %3567, 16"
"  %3568 = lshr i32 %3556, 16"
"  %3568 = lshr i32 %3556, 16" -> "  %3572 = add nuw nsw i32 %3569, %3568"
"  %3569 = and i32 %3528, 65535"
"  %3569 = and i32 %3528, 65535" -> "  %3572 = add nuw nsw i32 %3569, %3568"
"  %3570 = lshr i32 %3559, 16"
"  %3570 = lshr i32 %3559, 16" -> "  %3573 = add nuw nsw i32 %3572, %3570"
"  %3571 = lshr i32 %3567, 16"
"  %3571 = lshr i32 %3567, 16" -> "  %3574 = add nuw nsw i32 %3573, %3571"
"  %3572 = add nuw nsw i32 %3569, %3568"
"  %3572 = add nuw nsw i32 %3569, %3568" -> "  %3573 = add nuw nsw i32 %3572, %3570"
"  %3573 = add nuw nsw i32 %3572, %3570"
"  %3573 = add nuw nsw i32 %3572, %3570" -> "  %3574 = add nuw nsw i32 %3573, %3571"
"  %3574 = add nuw nsw i32 %3573, %3571"
"  %3574 = add nuw nsw i32 %3573, %3571" -> "  %3873 = and i32 %3574, 65535""  %3574 = add nuw nsw i32 %3573, %3571" -> "  %3575 = lshr i32 %3574, 16"
"  %3575 = lshr i32 %3574, 16"
"  %3575 = lshr i32 %3574, 16" -> "  %3577 = add nuw nsw i32 %3575, %3576"
"  %3576 = and i32 %3534, 65535"
"  %3576 = and i32 %3534, 65535" -> "  %3577 = add nuw nsw i32 %3575, %3576"
"  %3577 = add nuw nsw i32 %3575, %3576"
"  %3577 = add nuw nsw i32 %3575, %3576" -> "  %3876 = and i32 %3577, 65535""  %3577 = add nuw nsw i32 %3575, %3576" -> "  %3578 = lshr i32 %3577, 16"
"  %3578 = lshr i32 %3577, 16"
"  %3578 = lshr i32 %3577, 16" -> "  %3579 = add nuw nsw i32 %3541, %3578"
"  %3579 = add nuw nsw i32 %3541, %3578"
"  %3579 = add nuw nsw i32 %3541, %3578" -> "  %3882 = and i32 %3579, 65535""  %3579 = add nuw nsw i32 %3541, %3578" -> "  %3885 = lshr i32 %3579, 16"
"  %3580 = mul nuw nsw i32 %1724, 4087"
"  %3580 = mul nuw nsw i32 %1724, 4087" -> "  %3707 = and i32 %3580, 65535""  %3580 = mul nuw nsw i32 %1724, 4087" -> "  %3581 = lshr i32 %3580, 16"
"  %3581 = lshr i32 %3580, 16"
"  %3581 = lshr i32 %3580, 16" -> "  %3584 = add nuw nsw i32 %3583, %3581"
"  %3582 = mul nuw nsw i32 %1730, 4087"
"  %3582 = mul nuw nsw i32 %1730, 4087" -> "  %3585 = and i32 %3582, 268369920""  %3582 = mul nuw nsw i32 %1730, 4087" -> "  %3583 = and i32 %3582, 65535"
"  %3583 = and i32 %3582, 65535"
"  %3583 = and i32 %3582, 65535" -> "  %3584 = add nuw nsw i32 %3583, %3581"
"  %3584 = add nuw nsw i32 %3583, %3581"
"  %3584 = add nuw nsw i32 %3583, %3581" -> "  %3586 = add nuw nsw i32 %3584, %3585"
"  %3585 = and i32 %3582, 268369920"
"  %3585 = and i32 %3582, 268369920" -> "  %3586 = add nuw nsw i32 %3584, %3585"
"  %3586 = add nuw nsw i32 %3584, %3585"
"  %3586 = add nuw nsw i32 %3584, %3585" -> "  %3590 = lshr i32 %3586, 16""  %3586 = add nuw nsw i32 %3584, %3585" -> "  %3588 = and i32 %3586, 65535"
"  %3587 = mul nuw nsw i32 %1724, 11561"
"  %3587 = mul nuw nsw i32 %1724, 11561" -> "  %3589 = add nuw nsw i32 %3588, %3587"
"  %3588 = and i32 %3586, 65535"
"  %3588 = and i32 %3586, 65535" -> "  %3589 = add nuw nsw i32 %3588, %3587"
"  %3589 = add nuw nsw i32 %3588, %3587"
"  %3589 = add nuw nsw i32 %3588, %3587" -> "  %3710 = and i32 %3589, 65535""  %3589 = add nuw nsw i32 %3588, %3587" -> "  %3593 = lshr i32 %3589, 16"
"  %3590 = lshr i32 %3586, 16"
"  %3590 = lshr i32 %3586, 16" -> "  %3592 = add nuw nsw i32 %3590, %3591"
"  %3591 = mul nuw nsw i32 %1730, 11561"
"  %3591 = mul nuw nsw i32 %1730, 11561" -> "  %3592 = add nuw nsw i32 %3590, %3591"
"  %3592 = add nuw nsw i32 %3590, %3591"
"  %3592 = add nuw nsw i32 %3590, %3591" -> "  %3596 = and i32 %3592, 2147418112""  %3592 = add nuw nsw i32 %3590, %3591" -> "  %3594 = and i32 %3592, 65535"
"  %3593 = lshr i32 %3589, 16"
"  %3593 = lshr i32 %3589, 16" -> "  %3595 = add nuw nsw i32 %3593, %3594"
"  %3594 = and i32 %3592, 65535"
"  %3594 = and i32 %3592, 65535" -> "  %3595 = add nuw nsw i32 %3593, %3594"
"  %3595 = add nuw nsw i32 %3593, %3594"
"  %3595 = add nuw nsw i32 %3593, %3594" -> "  %3597 = add nuw nsw i32 %3595, %3596"
"  %3596 = and i32 %3592, 2147418112"
"  %3596 = and i32 %3592, 2147418112" -> "  %3597 = add nuw nsw i32 %3595, %3596"
"  %3597 = add nuw nsw i32 %3595, %3596"
"  %3597 = add nuw nsw i32 %3595, %3596" -> "  %3620 = lshr i32 %3597, 16""  %3597 = add nuw nsw i32 %3595, %3596" -> "  %3616 = and i32 %3597, 65535"
"  %3598 = mul nuw nsw i32 %1750, 4087"
"  %3598 = mul nuw nsw i32 %1750, 4087" -> "  %3617 = and i32 %3598, 65535""  %3598 = mul nuw nsw i32 %1750, 4087" -> "  %3599 = lshr i32 %3598, 16"
"  %3599 = lshr i32 %3598, 16"
"  %3599 = lshr i32 %3598, 16" -> "  %3602 = add nuw nsw i32 %3601, %3599"
"  %3600 = mul nuw nsw i32 %1751, 4087"
"  %3600 = mul nuw nsw i32 %1751, 4087" -> "  %3603 = and i32 %3600, 268369920""  %3600 = mul nuw nsw i32 %1751, 4087" -> "  %3601 = and i32 %3600, 65535"
"  %3601 = and i32 %3600, 65535"
"  %3601 = and i32 %3600, 65535" -> "  %3602 = add nuw nsw i32 %3601, %3599"
"  %3602 = add nuw nsw i32 %3601, %3599"
"  %3602 = add nuw nsw i32 %3601, %3599" -> "  %3604 = add nuw nsw i32 %3602, %3603"
"  %3603 = and i32 %3600, 268369920"
"  %3603 = and i32 %3600, 268369920" -> "  %3604 = add nuw nsw i32 %3602, %3603"
"  %3604 = add nuw nsw i32 %3602, %3603"
"  %3604 = add nuw nsw i32 %3602, %3603" -> "  %3608 = lshr i32 %3604, 16""  %3604 = add nuw nsw i32 %3602, %3603" -> "  %3606 = and i32 %3604, 65535"
"  %3605 = mul nuw nsw i32 %1750, 11561"
"  %3605 = mul nuw nsw i32 %1750, 11561" -> "  %3607 = add nuw nsw i32 %3606, %3605"
"  %3606 = and i32 %3604, 65535"
"  %3606 = and i32 %3604, 65535" -> "  %3607 = add nuw nsw i32 %3606, %3605"
"  %3607 = add nuw nsw i32 %3606, %3605"
"  %3607 = add nuw nsw i32 %3606, %3605" -> "  %3619 = and i32 %3607, 65535""  %3607 = add nuw nsw i32 %3606, %3605" -> "  %3611 = lshr i32 %3607, 16"
"  %3608 = lshr i32 %3604, 16"
"  %3608 = lshr i32 %3604, 16" -> "  %3610 = add nuw nsw i32 %3608, %3609"
"  %3609 = mul nuw nsw i32 %1751, 11561"
"  %3609 = mul nuw nsw i32 %1751, 11561" -> "  %3610 = add nuw nsw i32 %3608, %3609"
"  %3610 = add nuw nsw i32 %3608, %3609"
"  %3610 = add nuw nsw i32 %3608, %3609" -> "  %3614 = and i32 %3610, 2147418112""  %3610 = add nuw nsw i32 %3608, %3609" -> "  %3612 = and i32 %3610, 65535"
"  %3611 = lshr i32 %3607, 16"
"  %3611 = lshr i32 %3607, 16" -> "  %3613 = add nuw nsw i32 %3611, %3612"
"  %3612 = and i32 %3610, 65535"
"  %3612 = and i32 %3610, 65535" -> "  %3613 = add nuw nsw i32 %3611, %3612"
"  %3613 = add nuw nsw i32 %3611, %3612"
"  %3613 = add nuw nsw i32 %3611, %3612" -> "  %3615 = add nuw nsw i32 %3613, %3614"
"  %3614 = and i32 %3610, 2147418112"
"  %3614 = and i32 %3610, 2147418112" -> "  %3615 = add nuw nsw i32 %3613, %3614"
"  %3615 = add nuw nsw i32 %3613, %3614"
"  %3615 = add nuw nsw i32 %3613, %3614" -> "  %3623 = add nuw nsw i32 %3615, %3622"
"  %3616 = and i32 %3597, 65535"
"  %3616 = and i32 %3597, 65535" -> "  %3618 = add nuw nsw i32 %3616, %3617"
"  %3617 = and i32 %3598, 65535"
"  %3617 = and i32 %3598, 65535" -> "  %3618 = add nuw nsw i32 %3616, %3617"
"  %3618 = add nuw nsw i32 %3616, %3617"
"  %3618 = add nuw nsw i32 %3616, %3617" -> "  %3647 = and i32 %3618, 65535""  %3618 = add nuw nsw i32 %3616, %3617" -> "  %3625 = lshr i32 %3618, 16"
"  %3619 = and i32 %3607, 65535"
"  %3619 = and i32 %3607, 65535" -> "  %3621 = add nuw nsw i32 %3619, %3620"
"  %3620 = lshr i32 %3597, 16"
"  %3620 = lshr i32 %3597, 16" -> "  %3621 = add nuw nsw i32 %3619, %3620"
"  %3621 = add nuw nsw i32 %3619, %3620"
"  %3621 = add nuw nsw i32 %3619, %3620" -> "  %3624 = and i32 %3621, 65535""  %3621 = add nuw nsw i32 %3619, %3620" -> "  %3622 = lshr i32 %3621, 16"
"  %3622 = lshr i32 %3621, 16"
"  %3622 = lshr i32 %3621, 16" -> "  %3623 = add nuw nsw i32 %3615, %3622"
"  %3623 = add nuw nsw i32 %3615, %3622"
"  %3623 = add nuw nsw i32 %3615, %3622" -> "  %3628 = add nuw nsw i32 %3623, %3627"
"  %3624 = and i32 %3621, 65535"
"  %3624 = and i32 %3621, 65535" -> "  %3626 = add nuw nsw i32 %3624, %3625"
"  %3625 = lshr i32 %3618, 16"
"  %3625 = lshr i32 %3618, 16" -> "  %3626 = add nuw nsw i32 %3624, %3625"
"  %3626 = add nuw nsw i32 %3624, %3625"
"  %3626 = add nuw nsw i32 %3624, %3625" -> "  %3650 = and i32 %3626, 65535""  %3626 = add nuw nsw i32 %3624, %3625" -> "  %3627 = lshr i32 %3626, 16"
"  %3627 = lshr i32 %3626, 16"
"  %3627 = lshr i32 %3626, 16" -> "  %3628 = add nuw nsw i32 %3623, %3627"
"  %3628 = add nuw nsw i32 %3623, %3627"
"  %3628 = add nuw nsw i32 %3623, %3627" -> "  %3682 = lshr i32 %3628, 16""  %3628 = add nuw nsw i32 %3623, %3627" -> "  %3678 = and i32 %3628, 65535"
"  %3629 = mul nuw nsw i32 %1724, 21884"
"  %3629 = mul nuw nsw i32 %1724, 21884" -> "  %3648 = and i32 %3629, 65532""  %3629 = mul nuw nsw i32 %1724, 21884" -> "  %3630 = lshr i32 %3629, 16"
"  %3630 = lshr i32 %3629, 16"
"  %3630 = lshr i32 %3629, 16" -> "  %3633 = add nuw nsw i32 %3632, %3630"
"  %3631 = mul nuw nsw i32 %1730, 21884"
"  %3631 = mul nuw nsw i32 %1730, 21884" -> "  %3634 = and i32 %3631, 2147418112""  %3631 = mul nuw nsw i32 %1730, 21884" -> "  %3632 = and i32 %3631, 65532"
"  %3632 = and i32 %3631, 65532"
"  %3632 = and i32 %3631, 65532" -> "  %3633 = add nuw nsw i32 %3632, %3630"
"  %3633 = add nuw nsw i32 %3632, %3630"
"  %3633 = add nuw nsw i32 %3632, %3630" -> "  %3635 = add nuw nsw i32 %3633, %3634"
"  %3634 = and i32 %3631, 2147418112"
"  %3634 = and i32 %3631, 2147418112" -> "  %3635 = add nuw nsw i32 %3633, %3634"
"  %3635 = add nuw nsw i32 %3633, %3634"
"  %3635 = add nuw nsw i32 %3633, %3634" -> "  %3639 = lshr i32 %3635, 16""  %3635 = add nuw nsw i32 %3633, %3634" -> "  %3637 = and i32 %3635, 65535"
"  %3636 = mul nuw i32 %1724, 36786"
"  %3636 = mul nuw i32 %1724, 36786" -> "  %3638 = add nuw i32 %3637, %3636"
"  %3637 = and i32 %3635, 65535"
"  %3637 = and i32 %3635, 65535" -> "  %3638 = add nuw i32 %3637, %3636"
"  %3638 = add nuw i32 %3637, %3636"
"  %3638 = add nuw i32 %3637, %3636" -> "  %3651 = and i32 %3638, 65535""  %3638 = add nuw i32 %3637, %3636" -> "  %3642 = lshr i32 %3638, 16"
"  %3639 = lshr i32 %3635, 16"
"  %3639 = lshr i32 %3635, 16" -> "  %3641 = add nuw i32 %3639, %3640"
"  %3640 = mul nuw i32 %1730, 36786"
"  %3640 = mul nuw i32 %1730, 36786" -> "  %3641 = add nuw i32 %3639, %3640"
"  %3641 = add nuw i32 %3639, %3640"
"  %3641 = add nuw i32 %3639, %3640" -> "  %3645 = and i32 %3641, -65536""  %3641 = add nuw i32 %3639, %3640" -> "  %3643 = and i32 %3641, 65535"
"  %3642 = lshr i32 %3638, 16"
"  %3642 = lshr i32 %3638, 16" -> "  %3644 = add nuw nsw i32 %3642, %3643"
"  %3643 = and i32 %3641, 65535"
"  %3643 = and i32 %3641, 65535" -> "  %3644 = add nuw nsw i32 %3642, %3643"
"  %3644 = add nuw nsw i32 %3642, %3643"
"  %3644 = add nuw nsw i32 %3642, %3643" -> "  %3646 = add nuw i32 %3644, %3645"
"  %3645 = and i32 %3641, -65536"
"  %3645 = and i32 %3641, -65536" -> "  %3646 = add nuw i32 %3644, %3645"
"  %3646 = add nuw i32 %3644, %3645"
"  %3646 = add nuw i32 %3644, %3645" -> "  %3654 = add nuw i32 %3646, %3653"
"  %3647 = and i32 %3618, 65535"
"  %3647 = and i32 %3618, 65535" -> "  %3649 = add nuw nsw i32 %3647, %3648"
"  %3648 = and i32 %3629, 65532"
"  %3648 = and i32 %3629, 65532" -> "  %3649 = add nuw nsw i32 %3647, %3648"
"  %3649 = add nuw nsw i32 %3647, %3648"
"  %3649 = add nuw nsw i32 %3647, %3648" -> "  %3719 = and i32 %3649, 65535""  %3649 = add nuw nsw i32 %3647, %3648" -> "  %3656 = lshr i32 %3649, 16"
"  %3650 = and i32 %3626, 65535"
"  %3650 = and i32 %3626, 65535" -> "  %3652 = add nuw nsw i32 %3650, %3651"
"  %3651 = and i32 %3638, 65535"
"  %3651 = and i32 %3638, 65535" -> "  %3652 = add nuw nsw i32 %3650, %3651"
"  %3652 = add nuw nsw i32 %3650, %3651"
"  %3652 = add nuw nsw i32 %3650, %3651" -> "  %3655 = and i32 %3652, 65535""  %3652 = add nuw nsw i32 %3650, %3651" -> "  %3653 = lshr i32 %3652, 16"
"  %3653 = lshr i32 %3652, 16"
"  %3653 = lshr i32 %3652, 16" -> "  %3654 = add nuw i32 %3646, %3653"
"  %3654 = add nuw i32 %3646, %3653"
"  %3654 = add nuw i32 %3646, %3653" -> "  %3659 = add nuw i32 %3654, %3658"
"  %3655 = and i32 %3652, 65535"
"  %3655 = and i32 %3652, 65535" -> "  %3657 = add nuw nsw i32 %3655, %3656"
"  %3656 = lshr i32 %3649, 16"
"  %3656 = lshr i32 %3649, 16" -> "  %3657 = add nuw nsw i32 %3655, %3656"
"  %3657 = add nuw nsw i32 %3655, %3656"
"  %3657 = add nuw nsw i32 %3655, %3656" -> "  %3723 = and i32 %3657, 65535""  %3657 = add nuw nsw i32 %3655, %3656" -> "  %3658 = lshr i32 %3657, 16"
"  %3658 = lshr i32 %3657, 16"
"  %3658 = lshr i32 %3657, 16" -> "  %3659 = add nuw i32 %3654, %3658"
"  %3659 = add nuw i32 %3654, %3658"
"  %3659 = add nuw i32 %3654, %3658" -> "  %3695 = lshr i32 %3659, 16""  %3659 = add nuw i32 %3654, %3658" -> "  %3692 = and i32 %3659, 65535"
"  %3660 = mul nuw nsw i32 %1750, 21884"
"  %3660 = mul nuw nsw i32 %1750, 21884" -> "  %3679 = and i32 %3660, 65532""  %3660 = mul nuw nsw i32 %1750, 21884" -> "  %3661 = lshr i32 %3660, 16"
"  %3661 = lshr i32 %3660, 16"
"  %3661 = lshr i32 %3660, 16" -> "  %3664 = add nuw nsw i32 %3663, %3661"
"  %3662 = mul nuw nsw i32 %1751, 21884"
"  %3662 = mul nuw nsw i32 %1751, 21884" -> "  %3665 = and i32 %3662, 2147418112""  %3662 = mul nuw nsw i32 %1751, 21884" -> "  %3663 = and i32 %3662, 65532"
"  %3663 = and i32 %3662, 65532"
"  %3663 = and i32 %3662, 65532" -> "  %3664 = add nuw nsw i32 %3663, %3661"
"  %3664 = add nuw nsw i32 %3663, %3661"
"  %3664 = add nuw nsw i32 %3663, %3661" -> "  %3666 = add nuw nsw i32 %3664, %3665"
"  %3665 = and i32 %3662, 2147418112"
"  %3665 = and i32 %3662, 2147418112" -> "  %3666 = add nuw nsw i32 %3664, %3665"
"  %3666 = add nuw nsw i32 %3664, %3665"
"  %3666 = add nuw nsw i32 %3664, %3665" -> "  %3670 = lshr i32 %3666, 16""  %3666 = add nuw nsw i32 %3664, %3665" -> "  %3668 = and i32 %3666, 65535"
"  %3667 = mul nuw i32 %1750, 36786"
"  %3667 = mul nuw i32 %1750, 36786" -> "  %3669 = add nuw i32 %3668, %3667"
"  %3668 = and i32 %3666, 65535"
"  %3668 = and i32 %3666, 65535" -> "  %3669 = add nuw i32 %3668, %3667"
"  %3669 = add nuw i32 %3668, %3667"
"  %3669 = add nuw i32 %3668, %3667" -> "  %3681 = and i32 %3669, 65535""  %3669 = add nuw i32 %3668, %3667" -> "  %3673 = lshr i32 %3669, 16"
"  %3670 = lshr i32 %3666, 16"
"  %3670 = lshr i32 %3666, 16" -> "  %3672 = add nuw i32 %3670, %3671"
"  %3671 = mul nuw i32 %1751, 36786"
"  %3671 = mul nuw i32 %1751, 36786" -> "  %3672 = add nuw i32 %3670, %3671"
"  %3672 = add nuw i32 %3670, %3671"
"  %3672 = add nuw i32 %3670, %3671" -> "  %3676 = and i32 %3672, -65536""  %3672 = add nuw i32 %3670, %3671" -> "  %3674 = and i32 %3672, 65535"
"  %3673 = lshr i32 %3669, 16"
"  %3673 = lshr i32 %3669, 16" -> "  %3675 = add nuw nsw i32 %3673, %3674"
"  %3674 = and i32 %3672, 65535"
"  %3674 = and i32 %3672, 65535" -> "  %3675 = add nuw nsw i32 %3673, %3674"
"  %3675 = add nuw nsw i32 %3673, %3674"
"  %3675 = add nuw nsw i32 %3673, %3674" -> "  %3677 = add nuw i32 %3675, %3676"
"  %3676 = and i32 %3672, -65536"
"  %3676 = and i32 %3672, -65536" -> "  %3677 = add nuw i32 %3675, %3676"
"  %3677 = add nuw i32 %3675, %3676"
"  %3677 = add nuw i32 %3675, %3676" -> "  %3685 = add nuw i32 %3677, %3684"
"  %3678 = and i32 %3628, 65535"
"  %3678 = and i32 %3628, 65535" -> "  %3680 = add nuw nsw i32 %3678, %3679"
"  %3679 = and i32 %3660, 65532"
"  %3679 = and i32 %3660, 65532" -> "  %3680 = add nuw nsw i32 %3678, %3679"
"  %3680 = add nuw nsw i32 %3678, %3679"
"  %3680 = add nuw nsw i32 %3678, %3679" -> "  %3691 = and i32 %3680, 65535""  %3680 = add nuw nsw i32 %3678, %3679" -> "  %3687 = lshr i32 %3680, 16"
"  %3681 = and i32 %3669, 65535"
"  %3681 = and i32 %3669, 65535" -> "  %3683 = add nuw nsw i32 %3682, %3681"
"  %3682 = lshr i32 %3628, 16"
"  %3682 = lshr i32 %3628, 16" -> "  %3683 = add nuw nsw i32 %3682, %3681"
"  %3683 = add nuw nsw i32 %3682, %3681"
"  %3683 = add nuw nsw i32 %3682, %3681" -> "  %3686 = and i32 %3683, 65535""  %3683 = add nuw nsw i32 %3682, %3681" -> "  %3684 = lshr i32 %3683, 16"
"  %3684 = lshr i32 %3683, 16"
"  %3684 = lshr i32 %3683, 16" -> "  %3685 = add nuw i32 %3677, %3684"
"  %3685 = add nuw i32 %3677, %3684"
"  %3685 = add nuw i32 %3677, %3684" -> "  %3690 = add nuw i32 %3685, %3689"
"  %3686 = and i32 %3683, 65535"
"  %3686 = and i32 %3683, 65535" -> "  %3688 = add nuw nsw i32 %3687, %3686"
"  %3687 = lshr i32 %3680, 16"
"  %3687 = lshr i32 %3680, 16" -> "  %3688 = add nuw nsw i32 %3687, %3686"
"  %3688 = add nuw nsw i32 %3687, %3686"
"  %3688 = add nuw nsw i32 %3687, %3686" -> "  %3694 = and i32 %3688, 65535""  %3688 = add nuw nsw i32 %3687, %3686" -> "  %3689 = lshr i32 %3688, 16"
"  %3689 = lshr i32 %3688, 16"
"  %3689 = lshr i32 %3688, 16" -> "  %3690 = add nuw i32 %3685, %3689"
"  %3690 = add nuw i32 %3685, %3689"
"  %3690 = add nuw i32 %3685, %3689" -> "  %3703 = and i32 %3690, -65536""  %3690 = add nuw i32 %3685, %3689" -> "  %3701 = and i32 %3690, 65535"
"  %3691 = and i32 %3680, 65535"
"  %3691 = and i32 %3680, 65535" -> "  %3693 = add nuw nsw i32 %3692, %3691"
"  %3692 = and i32 %3659, 65535"
"  %3692 = and i32 %3659, 65535" -> "  %3693 = add nuw nsw i32 %3692, %3691"
"  %3693 = add nuw nsw i32 %3692, %3691"
"  %3693 = add nuw nsw i32 %3692, %3691" -> "  %3734 = and i32 %3693, 65535""  %3693 = add nuw nsw i32 %3692, %3691" -> "  %3697 = lshr i32 %3693, 16"
"  %3694 = and i32 %3688, 65535"
"  %3694 = and i32 %3688, 65535" -> "  %3696 = add nuw nsw i32 %3695, %3694"
"  %3695 = lshr i32 %3659, 16"
"  %3695 = lshr i32 %3659, 16" -> "  %3696 = add nuw nsw i32 %3695, %3694"
"  %3696 = add nuw nsw i32 %3695, %3694"
"  %3696 = add nuw nsw i32 %3695, %3694" -> "  %3700 = lshr i32 %3696, 16""  %3696 = add nuw nsw i32 %3695, %3694" -> "  %3698 = and i32 %3696, 65535"
"  %3697 = lshr i32 %3693, 16"
"  %3697 = lshr i32 %3693, 16" -> "  %3699 = add nuw nsw i32 %3697, %3698"
"  %3698 = and i32 %3696, 65535"
"  %3698 = and i32 %3696, 65535" -> "  %3699 = add nuw nsw i32 %3697, %3698"
"  %3699 = add nuw nsw i32 %3697, %3698"
"  %3699 = add nuw nsw i32 %3697, %3698" -> "  %3741 = and i32 %3699, 65535""  %3699 = add nuw nsw i32 %3697, %3698" -> "  %3705 = lshr i32 %3699, 16"
"  %3700 = lshr i32 %3696, 16"
"  %3700 = lshr i32 %3696, 16" -> "  %3702 = add nuw nsw i32 %3700, %3701"
"  %3701 = and i32 %3690, 65535"
"  %3701 = and i32 %3690, 65535" -> "  %3702 = add nuw nsw i32 %3700, %3701"
"  %3702 = add nuw nsw i32 %3700, %3701"
"  %3702 = add nuw nsw i32 %3700, %3701" -> "  %3704 = add nuw i32 %3702, %3703"
"  %3703 = and i32 %3690, -65536"
"  %3703 = and i32 %3690, -65536" -> "  %3704 = add nuw i32 %3702, %3703"
"  %3704 = add nuw i32 %3702, %3703"
"  %3704 = add nuw i32 %3702, %3703" -> "  %3706 = add nuw i32 %3704, %3705"
"  %3705 = lshr i32 %3699, 16"
"  %3705 = lshr i32 %3699, 16" -> "  %3706 = add nuw i32 %3704, %3705"
"  %3706 = add nuw i32 %3704, %3705"
"  %3706 = add nuw i32 %3704, %3705" -> "  %3744 = add nuw i32 %3706, %3743"
"  %3707 = and i32 %3580, 65535"
"  %3707 = and i32 %3580, 65535" -> "  %3709 = add nuw nsw i32 %3708, %3707"
"  %3708 = and i32 %3544, 65535"
"  %3708 = and i32 %3544, 65535" -> "  %3709 = add nuw nsw i32 %3708, %3707"
"  %3709 = add nuw nsw i32 %3708, %3707"
"  %3709 = add nuw nsw i32 %3708, %3707" -> "  %3975 = and i32 %3709, 65535""  %3709 = add nuw nsw i32 %3708, %3707" -> "  %3713 = lshr i32 %3709, 16"
"  %3710 = and i32 %3589, 65535"
"  %3710 = and i32 %3589, 65535" -> "  %3712 = add nuw nsw i32 %3711, %3710"
"  %3711 = and i32 %3550, 65535"
"  %3711 = and i32 %3550, 65535" -> "  %3712 = add nuw nsw i32 %3711, %3710"
"  %3712 = add nuw nsw i32 %3711, %3710"
"  %3712 = add nuw nsw i32 %3711, %3710" -> "  %3716 = lshr i32 %3712, 16""  %3712 = add nuw nsw i32 %3711, %3710" -> "  %3714 = and i32 %3712, 65535"
"  %3713 = lshr i32 %3709, 16"
"  %3713 = lshr i32 %3709, 16" -> "  %3715 = add nuw nsw i32 %3714, %3713"
"  %3714 = and i32 %3712, 65535"
"  %3714 = and i32 %3712, 65535" -> "  %3715 = add nuw nsw i32 %3714, %3713"
"  %3715 = add nuw nsw i32 %3714, %3713"
"  %3715 = add nuw nsw i32 %3714, %3713" -> "  %3978 = and i32 %3715, 65535""  %3715 = add nuw nsw i32 %3714, %3713" -> "  %3717 = lshr i32 %3715, 16"
"  %3716 = lshr i32 %3712, 16"
"  %3716 = lshr i32 %3712, 16" -> "  %3718 = add nuw nsw i32 %3717, %3716"
"  %3717 = lshr i32 %3715, 16"
"  %3717 = lshr i32 %3715, 16" -> "  %3718 = add nuw nsw i32 %3717, %3716"
"  %3718 = add nuw nsw i32 %3717, %3716"
"  %3718 = add nuw nsw i32 %3717, %3716" -> "  %3729 = add nuw nsw i32 %3718, %3728"
"  %3719 = and i32 %3649, 65535"
"  %3719 = and i32 %3649, 65535" -> "  %3721 = add nuw nsw i32 %3720, %3719"
"  %3720 = and i32 %3564, 65535"
"  %3720 = and i32 %3564, 65535" -> "  %3721 = add nuw nsw i32 %3720, %3719"
"  %3721 = add nuw nsw i32 %3720, %3719"
"  %3721 = add nuw nsw i32 %3720, %3719" -> "  %3728 = and i32 %3721, 65535""  %3721 = add nuw nsw i32 %3720, %3719" -> "  %3725 = lshr i32 %3721, 16"
"  %3722 = and i32 %3567, 65535"
"  %3722 = and i32 %3567, 65535" -> "  %3724 = add nuw nsw i32 %3722, %3723"
"  %3723 = and i32 %3657, 65535"
"  %3723 = and i32 %3657, 65535" -> "  %3724 = add nuw nsw i32 %3722, %3723"
"  %3724 = add nuw nsw i32 %3722, %3723"
"  %3724 = add nuw nsw i32 %3722, %3723" -> "  %3733 = lshr i32 %3724, 16""  %3724 = add nuw nsw i32 %3722, %3723" -> "  %3726 = and i32 %3724, 65535"
"  %3725 = lshr i32 %3721, 16"
"  %3725 = lshr i32 %3721, 16" -> "  %3727 = add nuw nsw i32 %3726, %3725"
"  %3726 = and i32 %3724, 65535"
"  %3726 = and i32 %3724, 65535" -> "  %3727 = add nuw nsw i32 %3726, %3725"
"  %3727 = add nuw nsw i32 %3726, %3725"
"  %3727 = add nuw nsw i32 %3726, %3725" -> "  %3735 = lshr i32 %3727, 16""  %3727 = add nuw nsw i32 %3726, %3725" -> "  %3731 = and i32 %3727, 65535"
"  %3728 = and i32 %3721, 65535"
"  %3728 = and i32 %3721, 65535" -> "  %3729 = add nuw nsw i32 %3718, %3728"
"  %3729 = add nuw nsw i32 %3718, %3728"
"  %3729 = add nuw nsw i32 %3718, %3728" -> "  %3984 = and i32 %3729, 65535""  %3729 = add nuw nsw i32 %3718, %3728" -> "  %3730 = lshr i32 %3729, 16"
"  %3730 = lshr i32 %3729, 16"
"  %3730 = lshr i32 %3729, 16" -> "  %3732 = add nuw nsw i32 %3731, %3730"
"  %3731 = and i32 %3727, 65535"
"  %3731 = and i32 %3727, 65535" -> "  %3732 = add nuw nsw i32 %3731, %3730"
"  %3732 = add nuw nsw i32 %3731, %3730"
"  %3732 = add nuw nsw i32 %3731, %3730" -> "  %3987 = and i32 %3732, 65535""  %3732 = add nuw nsw i32 %3731, %3730" -> "  %3736 = lshr i32 %3732, 16"
"  %3733 = lshr i32 %3724, 16"
"  %3733 = lshr i32 %3724, 16" -> "  %3737 = add nuw nsw i32 %3733, %3734"
"  %3734 = and i32 %3693, 65535"
"  %3734 = and i32 %3693, 65535" -> "  %3737 = add nuw nsw i32 %3733, %3734"
"  %3735 = lshr i32 %3727, 16"
"  %3735 = lshr i32 %3727, 16" -> "  %3738 = add nuw nsw i32 %3737, %3735"
"  %3736 = lshr i32 %3732, 16"
"  %3736 = lshr i32 %3732, 16" -> "  %3739 = add nuw nsw i32 %3738, %3736"
"  %3737 = add nuw nsw i32 %3733, %3734"
"  %3737 = add nuw nsw i32 %3733, %3734" -> "  %3738 = add nuw nsw i32 %3737, %3735"
"  %3738 = add nuw nsw i32 %3737, %3735"
"  %3738 = add nuw nsw i32 %3737, %3735" -> "  %3739 = add nuw nsw i32 %3738, %3736"
"  %3739 = add nuw nsw i32 %3738, %3736"
"  %3739 = add nuw nsw i32 %3738, %3736" -> "  %3911 = and i32 %3739, 65535""  %3739 = add nuw nsw i32 %3738, %3736" -> "  %3740 = lshr i32 %3739, 16"
"  %3740 = lshr i32 %3739, 16"
"  %3740 = lshr i32 %3739, 16" -> "  %3742 = add nuw nsw i32 %3740, %3741"
"  %3741 = and i32 %3699, 65535"
"  %3741 = and i32 %3699, 65535" -> "  %3742 = add nuw nsw i32 %3740, %3741"
"  %3742 = add nuw nsw i32 %3740, %3741"
"  %3742 = add nuw nsw i32 %3740, %3741" -> "  %3914 = and i32 %3742, 65535""  %3742 = add nuw nsw i32 %3740, %3741" -> "  %3743 = lshr i32 %3742, 16"
"  %3743 = lshr i32 %3742, 16"
"  %3743 = lshr i32 %3742, 16" -> "  %3744 = add nuw i32 %3706, %3743"
"  %3744 = add nuw i32 %3706, %3743"
"  %3744 = add nuw i32 %3706, %3743" -> "  %3920 = and i32 %3744, 65535""  %3744 = add nuw i32 %3706, %3743" -> "  %3923 = lshr i32 %3744, 16"
"  %3745 = mul nuw nsw i32 %1873, 4087"
"  %3745 = mul nuw nsw i32 %1873, 4087" -> "  %3872 = and i32 %3745, 65535""  %3745 = mul nuw nsw i32 %1873, 4087" -> "  %3746 = lshr i32 %3745, 16"
"  %3746 = lshr i32 %3745, 16"
"  %3746 = lshr i32 %3745, 16" -> "  %3749 = add nuw nsw i32 %3748, %3746"
"  %3747 = mul nuw nsw i32 %1879, 4087"
"  %3747 = mul nuw nsw i32 %1879, 4087" -> "  %3750 = and i32 %3747, 268369920""  %3747 = mul nuw nsw i32 %1879, 4087" -> "  %3748 = and i32 %3747, 65535"
"  %3748 = and i32 %3747, 65535"
"  %3748 = and i32 %3747, 65535" -> "  %3749 = add nuw nsw i32 %3748, %3746"
"  %3749 = add nuw nsw i32 %3748, %3746"
"  %3749 = add nuw nsw i32 %3748, %3746" -> "  %3751 = add nuw nsw i32 %3749, %3750"
"  %3750 = and i32 %3747, 268369920"
"  %3750 = and i32 %3747, 268369920" -> "  %3751 = add nuw nsw i32 %3749, %3750"
"  %3751 = add nuw nsw i32 %3749, %3750"
"  %3751 = add nuw nsw i32 %3749, %3750" -> "  %3755 = lshr i32 %3751, 16""  %3751 = add nuw nsw i32 %3749, %3750" -> "  %3753 = and i32 %3751, 65535"
"  %3752 = mul nuw nsw i32 %1873, 11561"
"  %3752 = mul nuw nsw i32 %1873, 11561" -> "  %3754 = add nuw nsw i32 %3753, %3752"
"  %3753 = and i32 %3751, 65535"
"  %3753 = and i32 %3751, 65535" -> "  %3754 = add nuw nsw i32 %3753, %3752"
"  %3754 = add nuw nsw i32 %3753, %3752"
"  %3754 = add nuw nsw i32 %3753, %3752" -> "  %3875 = and i32 %3754, 65535""  %3754 = add nuw nsw i32 %3753, %3752" -> "  %3758 = lshr i32 %3754, 16"
"  %3755 = lshr i32 %3751, 16"
"  %3755 = lshr i32 %3751, 16" -> "  %3757 = add nuw nsw i32 %3755, %3756"
"  %3756 = mul nuw nsw i32 %1879, 11561"
"  %3756 = mul nuw nsw i32 %1879, 11561" -> "  %3757 = add nuw nsw i32 %3755, %3756"
"  %3757 = add nuw nsw i32 %3755, %3756"
"  %3757 = add nuw nsw i32 %3755, %3756" -> "  %3761 = and i32 %3757, 2147418112""  %3757 = add nuw nsw i32 %3755, %3756" -> "  %3759 = and i32 %3757, 65535"
"  %3758 = lshr i32 %3754, 16"
"  %3758 = lshr i32 %3754, 16" -> "  %3760 = add nuw nsw i32 %3758, %3759"
"  %3759 = and i32 %3757, 65535"
"  %3759 = and i32 %3757, 65535" -> "  %3760 = add nuw nsw i32 %3758, %3759"
"  %3760 = add nuw nsw i32 %3758, %3759"
"  %3760 = add nuw nsw i32 %3758, %3759" -> "  %3762 = add nuw nsw i32 %3760, %3761"
"  %3761 = and i32 %3757, 2147418112"
"  %3761 = and i32 %3757, 2147418112" -> "  %3762 = add nuw nsw i32 %3760, %3761"
"  %3762 = add nuw nsw i32 %3760, %3761"
"  %3762 = add nuw nsw i32 %3760, %3761" -> "  %3785 = lshr i32 %3762, 16""  %3762 = add nuw nsw i32 %3760, %3761" -> "  %3781 = and i32 %3762, 65535"
"  %3763 = mul nuw nsw i32 %1896, 4087"
"  %3763 = mul nuw nsw i32 %1896, 4087" -> "  %3782 = and i32 %3763, 65535""  %3763 = mul nuw nsw i32 %1896, 4087" -> "  %3764 = lshr i32 %3763, 16"
"  %3764 = lshr i32 %3763, 16"
"  %3764 = lshr i32 %3763, 16" -> "  %3767 = add nuw nsw i32 %3766, %3764"
"  %3765 = mul nuw nsw i32 %1897, 4087"
"  %3765 = mul nuw nsw i32 %1897, 4087" -> "  %3768 = and i32 %3765, 268369920""  %3765 = mul nuw nsw i32 %1897, 4087" -> "  %3766 = and i32 %3765, 65535"
"  %3766 = and i32 %3765, 65535"
"  %3766 = and i32 %3765, 65535" -> "  %3767 = add nuw nsw i32 %3766, %3764"
"  %3767 = add nuw nsw i32 %3766, %3764"
"  %3767 = add nuw nsw i32 %3766, %3764" -> "  %3769 = add nuw nsw i32 %3767, %3768"
"  %3768 = and i32 %3765, 268369920"
"  %3768 = and i32 %3765, 268369920" -> "  %3769 = add nuw nsw i32 %3767, %3768"
"  %3769 = add nuw nsw i32 %3767, %3768"
"  %3769 = add nuw nsw i32 %3767, %3768" -> "  %3773 = lshr i32 %3769, 16""  %3769 = add nuw nsw i32 %3767, %3768" -> "  %3771 = and i32 %3769, 65535"
"  %3770 = mul nuw nsw i32 %1896, 11561"
"  %3770 = mul nuw nsw i32 %1896, 11561" -> "  %3772 = add nuw nsw i32 %3771, %3770"
"  %3771 = and i32 %3769, 65535"
"  %3771 = and i32 %3769, 65535" -> "  %3772 = add nuw nsw i32 %3771, %3770"
"  %3772 = add nuw nsw i32 %3771, %3770"
"  %3772 = add nuw nsw i32 %3771, %3770" -> "  %3784 = and i32 %3772, 65535""  %3772 = add nuw nsw i32 %3771, %3770" -> "  %3776 = lshr i32 %3772, 16"
"  %3773 = lshr i32 %3769, 16"
"  %3773 = lshr i32 %3769, 16" -> "  %3775 = add nuw nsw i32 %3773, %3774"
"  %3774 = mul nuw nsw i32 %1897, 11561"
"  %3774 = mul nuw nsw i32 %1897, 11561" -> "  %3775 = add nuw nsw i32 %3773, %3774"
"  %3775 = add nuw nsw i32 %3773, %3774"
"  %3775 = add nuw nsw i32 %3773, %3774" -> "  %3779 = and i32 %3775, 2147418112""  %3775 = add nuw nsw i32 %3773, %3774" -> "  %3777 = and i32 %3775, 65535"
"  %3776 = lshr i32 %3772, 16"
"  %3776 = lshr i32 %3772, 16" -> "  %3778 = add nuw nsw i32 %3776, %3777"
"  %3777 = and i32 %3775, 65535"
"  %3777 = and i32 %3775, 65535" -> "  %3778 = add nuw nsw i32 %3776, %3777"
"  %3778 = add nuw nsw i32 %3776, %3777"
"  %3778 = add nuw nsw i32 %3776, %3777" -> "  %3780 = add nuw nsw i32 %3778, %3779"
"  %3779 = and i32 %3775, 2147418112"
"  %3779 = and i32 %3775, 2147418112" -> "  %3780 = add nuw nsw i32 %3778, %3779"
"  %3780 = add nuw nsw i32 %3778, %3779"
"  %3780 = add nuw nsw i32 %3778, %3779" -> "  %3788 = add nuw nsw i32 %3780, %3787"
"  %3781 = and i32 %3762, 65535"
"  %3781 = and i32 %3762, 65535" -> "  %3783 = add nuw nsw i32 %3781, %3782"
"  %3782 = and i32 %3763, 65535"
"  %3782 = and i32 %3763, 65535" -> "  %3783 = add nuw nsw i32 %3781, %3782"
"  %3783 = add nuw nsw i32 %3781, %3782"
"  %3783 = add nuw nsw i32 %3781, %3782" -> "  %3812 = and i32 %3783, 65535""  %3783 = add nuw nsw i32 %3781, %3782" -> "  %3790 = lshr i32 %3783, 16"
"  %3784 = and i32 %3772, 65535"
"  %3784 = and i32 %3772, 65535" -> "  %3786 = add nuw nsw i32 %3785, %3784"
"  %3785 = lshr i32 %3762, 16"
"  %3785 = lshr i32 %3762, 16" -> "  %3786 = add nuw nsw i32 %3785, %3784"
"  %3786 = add nuw nsw i32 %3785, %3784"
"  %3786 = add nuw nsw i32 %3785, %3784" -> "  %3789 = and i32 %3786, 65535""  %3786 = add nuw nsw i32 %3785, %3784" -> "  %3787 = lshr i32 %3786, 16"
"  %3787 = lshr i32 %3786, 16"
"  %3787 = lshr i32 %3786, 16" -> "  %3788 = add nuw nsw i32 %3780, %3787"
"  %3788 = add nuw nsw i32 %3780, %3787"
"  %3788 = add nuw nsw i32 %3780, %3787" -> "  %3793 = add nuw nsw i32 %3788, %3792"
"  %3789 = and i32 %3786, 65535"
"  %3789 = and i32 %3786, 65535" -> "  %3791 = add nuw nsw i32 %3789, %3790"
"  %3790 = lshr i32 %3783, 16"
"  %3790 = lshr i32 %3783, 16" -> "  %3791 = add nuw nsw i32 %3789, %3790"
"  %3791 = add nuw nsw i32 %3789, %3790"
"  %3791 = add nuw nsw i32 %3789, %3790" -> "  %3815 = and i32 %3791, 65535""  %3791 = add nuw nsw i32 %3789, %3790" -> "  %3792 = lshr i32 %3791, 16"
"  %3792 = lshr i32 %3791, 16"
"  %3792 = lshr i32 %3791, 16" -> "  %3793 = add nuw nsw i32 %3788, %3792"
"  %3793 = add nuw nsw i32 %3788, %3792"
"  %3793 = add nuw nsw i32 %3788, %3792" -> "  %3847 = lshr i32 %3793, 16""  %3793 = add nuw nsw i32 %3788, %3792" -> "  %3843 = and i32 %3793, 65535"
"  %3794 = mul nuw nsw i32 %1873, 21884"
"  %3794 = mul nuw nsw i32 %1873, 21884" -> "  %3813 = and i32 %3794, 65532""  %3794 = mul nuw nsw i32 %1873, 21884" -> "  %3795 = lshr i32 %3794, 16"
"  %3795 = lshr i32 %3794, 16"
"  %3795 = lshr i32 %3794, 16" -> "  %3798 = add nuw nsw i32 %3797, %3795"
"  %3796 = mul nuw nsw i32 %1879, 21884"
"  %3796 = mul nuw nsw i32 %1879, 21884" -> "  %3799 = and i32 %3796, 2147418112""  %3796 = mul nuw nsw i32 %1879, 21884" -> "  %3797 = and i32 %3796, 65532"
"  %3797 = and i32 %3796, 65532"
"  %3797 = and i32 %3796, 65532" -> "  %3798 = add nuw nsw i32 %3797, %3795"
"  %3798 = add nuw nsw i32 %3797, %3795"
"  %3798 = add nuw nsw i32 %3797, %3795" -> "  %3800 = add nuw nsw i32 %3798, %3799"
"  %3799 = and i32 %3796, 2147418112"
"  %3799 = and i32 %3796, 2147418112" -> "  %3800 = add nuw nsw i32 %3798, %3799"
"  %3800 = add nuw nsw i32 %3798, %3799"
"  %3800 = add nuw nsw i32 %3798, %3799" -> "  %3804 = lshr i32 %3800, 16""  %3800 = add nuw nsw i32 %3798, %3799" -> "  %3802 = and i32 %3800, 65535"
"  %3801 = mul nuw i32 %1873, 36786"
"  %3801 = mul nuw i32 %1873, 36786" -> "  %3803 = add nuw i32 %3802, %3801"
"  %3802 = and i32 %3800, 65535"
"  %3802 = and i32 %3800, 65535" -> "  %3803 = add nuw i32 %3802, %3801"
"  %3803 = add nuw i32 %3802, %3801"
"  %3803 = add nuw i32 %3802, %3801" -> "  %3816 = and i32 %3803, 65535""  %3803 = add nuw i32 %3802, %3801" -> "  %3807 = lshr i32 %3803, 16"
"  %3804 = lshr i32 %3800, 16"
"  %3804 = lshr i32 %3800, 16" -> "  %3806 = add nuw i32 %3804, %3805"
"  %3805 = mul nuw i32 %1879, 36786"
"  %3805 = mul nuw i32 %1879, 36786" -> "  %3806 = add nuw i32 %3804, %3805"
"  %3806 = add nuw i32 %3804, %3805"
"  %3806 = add nuw i32 %3804, %3805" -> "  %3810 = and i32 %3806, -65536""  %3806 = add nuw i32 %3804, %3805" -> "  %3808 = and i32 %3806, 65535"
"  %3807 = lshr i32 %3803, 16"
"  %3807 = lshr i32 %3803, 16" -> "  %3809 = add nuw nsw i32 %3807, %3808"
"  %3808 = and i32 %3806, 65535"
"  %3808 = and i32 %3806, 65535" -> "  %3809 = add nuw nsw i32 %3807, %3808"
"  %3809 = add nuw nsw i32 %3807, %3808"
"  %3809 = add nuw nsw i32 %3807, %3808" -> "  %3811 = add nuw i32 %3809, %3810"
"  %3810 = and i32 %3806, -65536"
"  %3810 = and i32 %3806, -65536" -> "  %3811 = add nuw i32 %3809, %3810"
"  %3811 = add nuw i32 %3809, %3810"
"  %3811 = add nuw i32 %3809, %3810" -> "  %3819 = add nuw i32 %3811, %3818"
"  %3812 = and i32 %3783, 65535"
"  %3812 = and i32 %3783, 65535" -> "  %3814 = add nuw nsw i32 %3812, %3813"
"  %3813 = and i32 %3794, 65532"
"  %3813 = and i32 %3794, 65532" -> "  %3814 = add nuw nsw i32 %3812, %3813"
"  %3814 = add nuw nsw i32 %3812, %3813"
"  %3814 = add nuw nsw i32 %3812, %3813" -> "  %3881 = and i32 %3814, 65535""  %3814 = add nuw nsw i32 %3812, %3813" -> "  %3821 = lshr i32 %3814, 16"
"  %3815 = and i32 %3791, 65535"
"  %3815 = and i32 %3791, 65535" -> "  %3817 = add nuw nsw i32 %3815, %3816"
"  %3816 = and i32 %3803, 65535"
"  %3816 = and i32 %3803, 65535" -> "  %3817 = add nuw nsw i32 %3815, %3816"
"  %3817 = add nuw nsw i32 %3815, %3816"
"  %3817 = add nuw nsw i32 %3815, %3816" -> "  %3820 = and i32 %3817, 65535""  %3817 = add nuw nsw i32 %3815, %3816" -> "  %3818 = lshr i32 %3817, 16"
"  %3818 = lshr i32 %3817, 16"
"  %3818 = lshr i32 %3817, 16" -> "  %3819 = add nuw i32 %3811, %3818"
"  %3819 = add nuw i32 %3811, %3818"
"  %3819 = add nuw i32 %3811, %3818" -> "  %3824 = add nuw i32 %3819, %3823"
"  %3820 = and i32 %3817, 65535"
"  %3820 = and i32 %3817, 65535" -> "  %3822 = add nuw nsw i32 %3820, %3821"
"  %3821 = lshr i32 %3814, 16"
"  %3821 = lshr i32 %3814, 16" -> "  %3822 = add nuw nsw i32 %3820, %3821"
"  %3822 = add nuw nsw i32 %3820, %3821"
"  %3822 = add nuw nsw i32 %3820, %3821" -> "  %3884 = and i32 %3822, 65535""  %3822 = add nuw nsw i32 %3820, %3821" -> "  %3823 = lshr i32 %3822, 16"
"  %3823 = lshr i32 %3822, 16"
"  %3823 = lshr i32 %3822, 16" -> "  %3824 = add nuw i32 %3819, %3823"
"  %3824 = add nuw i32 %3819, %3823"
"  %3824 = add nuw i32 %3819, %3823" -> "  %3860 = lshr i32 %3824, 16""  %3824 = add nuw i32 %3819, %3823" -> "  %3857 = and i32 %3824, 65535"
"  %3825 = mul nuw nsw i32 %1896, 21884"
"  %3825 = mul nuw nsw i32 %1896, 21884" -> "  %3844 = and i32 %3825, 65532""  %3825 = mul nuw nsw i32 %1896, 21884" -> "  %3826 = lshr i32 %3825, 16"
"  %3826 = lshr i32 %3825, 16"
"  %3826 = lshr i32 %3825, 16" -> "  %3829 = add nuw nsw i32 %3828, %3826"
"  %3827 = mul nuw nsw i32 %1897, 21884"
"  %3827 = mul nuw nsw i32 %1897, 21884" -> "  %3830 = and i32 %3827, 2147418112""  %3827 = mul nuw nsw i32 %1897, 21884" -> "  %3828 = and i32 %3827, 65532"
"  %3828 = and i32 %3827, 65532"
"  %3828 = and i32 %3827, 65532" -> "  %3829 = add nuw nsw i32 %3828, %3826"
"  %3829 = add nuw nsw i32 %3828, %3826"
"  %3829 = add nuw nsw i32 %3828, %3826" -> "  %3831 = add nuw nsw i32 %3829, %3830"
"  %3830 = and i32 %3827, 2147418112"
"  %3830 = and i32 %3827, 2147418112" -> "  %3831 = add nuw nsw i32 %3829, %3830"
"  %3831 = add nuw nsw i32 %3829, %3830"
"  %3831 = add nuw nsw i32 %3829, %3830" -> "  %3835 = lshr i32 %3831, 16""  %3831 = add nuw nsw i32 %3829, %3830" -> "  %3833 = and i32 %3831, 65535"
"  %3832 = mul nuw i32 %1896, 36786"
"  %3832 = mul nuw i32 %1896, 36786" -> "  %3834 = add nuw i32 %3833, %3832"
"  %3833 = and i32 %3831, 65535"
"  %3833 = and i32 %3831, 65535" -> "  %3834 = add nuw i32 %3833, %3832"
"  %3834 = add nuw i32 %3833, %3832"
"  %3834 = add nuw i32 %3833, %3832" -> "  %3846 = and i32 %3834, 65535""  %3834 = add nuw i32 %3833, %3832" -> "  %3838 = lshr i32 %3834, 16"
"  %3835 = lshr i32 %3831, 16"
"  %3835 = lshr i32 %3831, 16" -> "  %3837 = add nuw i32 %3835, %3836"
"  %3836 = mul nuw i32 %1897, 36786"
"  %3836 = mul nuw i32 %1897, 36786" -> "  %3837 = add nuw i32 %3835, %3836"
"  %3837 = add nuw i32 %3835, %3836"
"  %3837 = add nuw i32 %3835, %3836" -> "  %3841 = and i32 %3837, -65536""  %3837 = add nuw i32 %3835, %3836" -> "  %3839 = and i32 %3837, 65535"
"  %3838 = lshr i32 %3834, 16"
"  %3838 = lshr i32 %3834, 16" -> "  %3840 = add nuw nsw i32 %3838, %3839"
"  %3839 = and i32 %3837, 65535"
"  %3839 = and i32 %3837, 65535" -> "  %3840 = add nuw nsw i32 %3838, %3839"
"  %3840 = add nuw nsw i32 %3838, %3839"
"  %3840 = add nuw nsw i32 %3838, %3839" -> "  %3842 = add nuw i32 %3840, %3841"
"  %3841 = and i32 %3837, -65536"
"  %3841 = and i32 %3837, -65536" -> "  %3842 = add nuw i32 %3840, %3841"
"  %3842 = add nuw i32 %3840, %3841"
"  %3842 = add nuw i32 %3840, %3841" -> "  %3850 = add nuw i32 %3842, %3849"
"  %3843 = and i32 %3793, 65535"
"  %3843 = and i32 %3793, 65535" -> "  %3845 = add nuw nsw i32 %3843, %3844"
"  %3844 = and i32 %3825, 65532"
"  %3844 = and i32 %3825, 65532" -> "  %3845 = add nuw nsw i32 %3843, %3844"
"  %3845 = add nuw nsw i32 %3843, %3844"
"  %3845 = add nuw nsw i32 %3843, %3844" -> "  %3856 = and i32 %3845, 65535""  %3845 = add nuw nsw i32 %3843, %3844" -> "  %3852 = lshr i32 %3845, 16"
"  %3846 = and i32 %3834, 65535"
"  %3846 = and i32 %3834, 65535" -> "  %3848 = add nuw nsw i32 %3847, %3846"
"  %3847 = lshr i32 %3793, 16"
"  %3847 = lshr i32 %3793, 16" -> "  %3848 = add nuw nsw i32 %3847, %3846"
"  %3848 = add nuw nsw i32 %3847, %3846"
"  %3848 = add nuw nsw i32 %3847, %3846" -> "  %3851 = and i32 %3848, 65535""  %3848 = add nuw nsw i32 %3847, %3846" -> "  %3849 = lshr i32 %3848, 16"
"  %3849 = lshr i32 %3848, 16"
"  %3849 = lshr i32 %3848, 16" -> "  %3850 = add nuw i32 %3842, %3849"
"  %3850 = add nuw i32 %3842, %3849"
"  %3850 = add nuw i32 %3842, %3849" -> "  %3855 = add nuw i32 %3850, %3854"
"  %3851 = and i32 %3848, 65535"
"  %3851 = and i32 %3848, 65535" -> "  %3853 = add nuw nsw i32 %3852, %3851"
"  %3852 = lshr i32 %3845, 16"
"  %3852 = lshr i32 %3845, 16" -> "  %3853 = add nuw nsw i32 %3852, %3851"
"  %3853 = add nuw nsw i32 %3852, %3851"
"  %3853 = add nuw nsw i32 %3852, %3851" -> "  %3859 = and i32 %3853, 65535""  %3853 = add nuw nsw i32 %3852, %3851" -> "  %3854 = lshr i32 %3853, 16"
"  %3854 = lshr i32 %3853, 16"
"  %3854 = lshr i32 %3853, 16" -> "  %3855 = add nuw i32 %3850, %3854"
"  %3855 = add nuw i32 %3850, %3854"
"  %3855 = add nuw i32 %3850, %3854" -> "  %3868 = and i32 %3855, -65536""  %3855 = add nuw i32 %3850, %3854" -> "  %3866 = and i32 %3855, 65535"
"  %3856 = and i32 %3845, 65535"
"  %3856 = and i32 %3845, 65535" -> "  %3858 = add nuw nsw i32 %3857, %3856"
"  %3857 = and i32 %3824, 65535"
"  %3857 = and i32 %3824, 65535" -> "  %3858 = add nuw nsw i32 %3857, %3856"
"  %3858 = add nuw nsw i32 %3857, %3856"
"  %3858 = add nuw nsw i32 %3857, %3856" -> "  %3899 = and i32 %3858, 65535""  %3858 = add nuw nsw i32 %3857, %3856" -> "  %3862 = lshr i32 %3858, 16"
"  %3859 = and i32 %3853, 65535"
"  %3859 = and i32 %3853, 65535" -> "  %3861 = add nuw nsw i32 %3860, %3859"
"  %3860 = lshr i32 %3824, 16"
"  %3860 = lshr i32 %3824, 16" -> "  %3861 = add nuw nsw i32 %3860, %3859"
"  %3861 = add nuw nsw i32 %3860, %3859"
"  %3861 = add nuw nsw i32 %3860, %3859" -> "  %3865 = lshr i32 %3861, 16""  %3861 = add nuw nsw i32 %3860, %3859" -> "  %3863 = and i32 %3861, 65535"
"  %3862 = lshr i32 %3858, 16"
"  %3862 = lshr i32 %3858, 16" -> "  %3864 = add nuw nsw i32 %3862, %3863"
"  %3863 = and i32 %3861, 65535"
"  %3863 = and i32 %3861, 65535" -> "  %3864 = add nuw nsw i32 %3862, %3863"
"  %3864 = add nuw nsw i32 %3862, %3863"
"  %3864 = add nuw nsw i32 %3862, %3863" -> "  %3906 = and i32 %3864, 65535""  %3864 = add nuw nsw i32 %3862, %3863" -> "  %3870 = lshr i32 %3864, 16"
"  %3865 = lshr i32 %3861, 16"
"  %3865 = lshr i32 %3861, 16" -> "  %3867 = add nuw nsw i32 %3865, %3866"
"  %3866 = and i32 %3855, 65535"
"  %3866 = and i32 %3855, 65535" -> "  %3867 = add nuw nsw i32 %3865, %3866"
"  %3867 = add nuw nsw i32 %3865, %3866"
"  %3867 = add nuw nsw i32 %3865, %3866" -> "  %3869 = add nuw i32 %3867, %3868"
"  %3868 = and i32 %3855, -65536"
"  %3868 = and i32 %3855, -65536" -> "  %3869 = add nuw i32 %3867, %3868"
"  %3869 = add nuw i32 %3867, %3868"
"  %3869 = add nuw i32 %3867, %3868" -> "  %3871 = add nuw i32 %3869, %3870"
"  %3870 = lshr i32 %3864, 16"
"  %3870 = lshr i32 %3864, 16" -> "  %3871 = add nuw i32 %3869, %3870"
"  %3871 = add nuw i32 %3869, %3870"
"  %3871 = add nuw i32 %3869, %3870" -> "  %3909 = add nuw i32 %3871, %3908"
"  %3872 = and i32 %3745, 65535"
"  %3872 = and i32 %3745, 65535" -> "  %3874 = add nuw nsw i32 %3873, %3872"
"  %3873 = and i32 %3574, 65535"
"  %3873 = and i32 %3574, 65535" -> "  %3874 = add nuw nsw i32 %3873, %3872"
"  %3874 = add nuw nsw i32 %3873, %3872"
"  %3874 = add nuw nsw i32 %3873, %3872" -> "  %3910 = and i32 %3874, 65535""  %3874 = add nuw nsw i32 %3873, %3872" -> "  %3878 = lshr i32 %3874, 16"
"  %3875 = and i32 %3754, 65535"
"  %3875 = and i32 %3754, 65535" -> "  %3877 = add nuw nsw i32 %3876, %3875"
"  %3876 = and i32 %3577, 65535"
"  %3876 = and i32 %3577, 65535" -> "  %3877 = add nuw nsw i32 %3876, %3875"
"  %3877 = add nuw nsw i32 %3876, %3875"
"  %3877 = add nuw nsw i32 %3876, %3875" -> "  %3891 = lshr i32 %3877, 16""  %3877 = add nuw nsw i32 %3876, %3875" -> "  %3879 = and i32 %3877, 65535"
"  %3878 = lshr i32 %3874, 16"
"  %3878 = lshr i32 %3874, 16" -> "  %3880 = add nuw nsw i32 %3879, %3878"
"  %3879 = and i32 %3877, 65535"
"  %3879 = and i32 %3877, 65535" -> "  %3880 = add nuw nsw i32 %3879, %3878"
"  %3880 = add nuw nsw i32 %3879, %3878"
"  %3880 = add nuw nsw i32 %3879, %3878" -> "  %3913 = and i32 %3880, 65535""  %3880 = add nuw nsw i32 %3879, %3878" -> "  %3893 = lshr i32 %3880, 16"
"  %3881 = and i32 %3814, 65535"
"  %3881 = and i32 %3814, 65535" -> "  %3883 = add nuw nsw i32 %3882, %3881"
"  %3882 = and i32 %3579, 65535"
"  %3882 = and i32 %3579, 65535" -> "  %3883 = add nuw nsw i32 %3882, %3881"
"  %3883 = add nuw nsw i32 %3882, %3881"
"  %3883 = add nuw nsw i32 %3882, %3881" -> "  %3890 = and i32 %3883, 65535""  %3883 = add nuw nsw i32 %3882, %3881" -> "  %3887 = lshr i32 %3883, 16"
"  %3884 = and i32 %3822, 65535"
"  %3884 = and i32 %3822, 65535" -> "  %3886 = add nuw nsw i32 %3885, %3884"
"  %3885 = lshr i32 %3579, 16"
"  %3885 = lshr i32 %3579, 16" -> "  %3886 = add nuw nsw i32 %3885, %3884"
"  %3886 = add nuw nsw i32 %3885, %3884"
"  %3886 = add nuw nsw i32 %3885, %3884" -> "  %3898 = lshr i32 %3886, 16""  %3886 = add nuw nsw i32 %3885, %3884" -> "  %3888 = and i32 %3886, 65535"
"  %3887 = lshr i32 %3883, 16"
"  %3887 = lshr i32 %3883, 16" -> "  %3889 = add nuw nsw i32 %3888, %3887"
"  %3888 = and i32 %3886, 65535"
"  %3888 = and i32 %3886, 65535" -> "  %3889 = add nuw nsw i32 %3888, %3887"
"  %3889 = add nuw nsw i32 %3888, %3887"
"  %3889 = add nuw nsw i32 %3888, %3887" -> "  %3896 = and i32 %3889, 65535""  %3889 = add nuw nsw i32 %3888, %3887" -> "  %3901 = lshr i32 %3889, 16"
"  %3890 = and i32 %3883, 65535"
"  %3890 = and i32 %3883, 65535" -> "  %3892 = add nuw nsw i32 %3890, %3891"
"  %3891 = lshr i32 %3877, 16"
"  %3891 = lshr i32 %3877, 16" -> "  %3892 = add nuw nsw i32 %3890, %3891"
"  %3892 = add nuw nsw i32 %3890, %3891"
"  %3892 = add nuw nsw i32 %3890, %3891" -> "  %3894 = add nuw nsw i32 %3892, %3893"
"  %3893 = lshr i32 %3880, 16"
"  %3893 = lshr i32 %3880, 16" -> "  %3894 = add nuw nsw i32 %3892, %3893"
"  %3894 = add nuw nsw i32 %3892, %3893"
"  %3894 = add nuw nsw i32 %3892, %3893" -> "  %3919 = and i32 %3894, 65535""  %3894 = add nuw nsw i32 %3892, %3893" -> "  %3895 = lshr i32 %3894, 16"
"  %3895 = lshr i32 %3894, 16"
"  %3895 = lshr i32 %3894, 16" -> "  %3897 = add nuw nsw i32 %3895, %3896"
"  %3896 = and i32 %3889, 65535"
"  %3896 = and i32 %3889, 65535" -> "  %3897 = add nuw nsw i32 %3895, %3896"
"  %3897 = add nuw nsw i32 %3895, %3896"
"  %3897 = add nuw nsw i32 %3895, %3896" -> "  %3922 = and i32 %3897, 65535""  %3897 = add nuw nsw i32 %3895, %3896" -> "  %3902 = lshr i32 %3897, 16"
"  %3898 = lshr i32 %3886, 16"
"  %3898 = lshr i32 %3886, 16" -> "  %3900 = add nuw nsw i32 %3898, %3899"
"  %3899 = and i32 %3858, 65535"
"  %3899 = and i32 %3858, 65535" -> "  %3900 = add nuw nsw i32 %3898, %3899"
"  %3900 = add nuw nsw i32 %3898, %3899"
"  %3900 = add nuw nsw i32 %3898, %3899" -> "  %3903 = add nuw nsw i32 %3900, %3901"
"  %3901 = lshr i32 %3889, 16"
"  %3901 = lshr i32 %3889, 16" -> "  %3903 = add nuw nsw i32 %3900, %3901"
"  %3902 = lshr i32 %3897, 16"
"  %3902 = lshr i32 %3897, 16" -> "  %3904 = add nuw nsw i32 %3903, %3902"
"  %3903 = add nuw nsw i32 %3900, %3901"
"  %3903 = add nuw nsw i32 %3900, %3901" -> "  %3904 = add nuw nsw i32 %3903, %3902"
"  %3904 = add nuw nsw i32 %3903, %3902"
"  %3904 = add nuw nsw i32 %3903, %3902" -> "  %3936 = and i32 %3904, 65535""  %3904 = add nuw nsw i32 %3903, %3902" -> "  %3905 = lshr i32 %3904, 16"
"  %3905 = lshr i32 %3904, 16"
"  %3905 = lshr i32 %3904, 16" -> "  %3907 = add nuw nsw i32 %3905, %3906"
"  %3906 = and i32 %3864, 65535"
"  %3906 = and i32 %3864, 65535" -> "  %3907 = add nuw nsw i32 %3905, %3906"
"  %3907 = add nuw nsw i32 %3905, %3906"
"  %3907 = add nuw nsw i32 %3905, %3906" -> "  %3943 = and i32 %3907, 65535""  %3907 = add nuw nsw i32 %3905, %3906" -> "  %3908 = lshr i32 %3907, 16"
"  %3908 = lshr i32 %3907, 16"
"  %3908 = lshr i32 %3907, 16" -> "  %3909 = add nuw i32 %3871, %3908"
"  %3909 = add nuw i32 %3871, %3908"
"  %3909 = add nuw i32 %3871, %3908" -> "  %3947 = add nuw i32 %3909, %3946"
"  %3910 = and i32 %3874, 65535"
"  %3910 = and i32 %3874, 65535" -> "  %3912 = add nuw nsw i32 %3911, %3910"
"  %3911 = and i32 %3739, 65535"
"  %3911 = and i32 %3739, 65535" -> "  %3912 = add nuw nsw i32 %3911, %3910"
"  %3912 = add nuw nsw i32 %3911, %3910"
"  %3912 = add nuw nsw i32 %3911, %3910" -> "  %4020 = and i32 %3912, 65535""  %3912 = add nuw nsw i32 %3911, %3910" -> "  %3916 = lshr i32 %3912, 16"
"  %3913 = and i32 %3880, 65535"
"  %3913 = and i32 %3880, 65535" -> "  %3915 = add nuw nsw i32 %3914, %3913"
"  %3914 = and i32 %3742, 65535"
"  %3914 = and i32 %3742, 65535" -> "  %3915 = add nuw nsw i32 %3914, %3913"
"  %3915 = add nuw nsw i32 %3914, %3913"
"  %3915 = add nuw nsw i32 %3914, %3913" -> "  %3929 = lshr i32 %3915, 16""  %3915 = add nuw nsw i32 %3914, %3913" -> "  %3917 = and i32 %3915, 65535"
"  %3916 = lshr i32 %3912, 16"
"  %3916 = lshr i32 %3912, 16" -> "  %3918 = add nuw nsw i32 %3917, %3916"
"  %3917 = and i32 %3915, 65535"
"  %3917 = and i32 %3915, 65535" -> "  %3918 = add nuw nsw i32 %3917, %3916"
"  %3918 = add nuw nsw i32 %3917, %3916"
"  %3918 = add nuw nsw i32 %3917, %3916" -> "  %4025 = and i32 %3918, 65535""  %3918 = add nuw nsw i32 %3917, %3916" -> "  %3930 = lshr i32 %3918, 16"
"  %3919 = and i32 %3894, 65535"
"  %3919 = and i32 %3894, 65535" -> "  %3921 = add nuw nsw i32 %3920, %3919"
"  %3920 = and i32 %3744, 65535"
"  %3920 = and i32 %3744, 65535" -> "  %3921 = add nuw nsw i32 %3920, %3919"
"  %3921 = add nuw nsw i32 %3920, %3919"
"  %3921 = add nuw nsw i32 %3920, %3919" -> "  %3928 = and i32 %3921, 65535""  %3921 = add nuw nsw i32 %3920, %3919" -> "  %3925 = lshr i32 %3921, 16"
"  %3922 = and i32 %3897, 65535"
"  %3922 = and i32 %3897, 65535" -> "  %3924 = add nuw nsw i32 %3922, %3923"
"  %3923 = lshr i32 %3744, 16"
"  %3923 = lshr i32 %3744, 16" -> "  %3924 = add nuw nsw i32 %3922, %3923"
"  %3924 = add nuw nsw i32 %3922, %3923"
"  %3924 = add nuw nsw i32 %3922, %3923" -> "  %3937 = lshr i32 %3924, 16""  %3924 = add nuw nsw i32 %3922, %3923" -> "  %3926 = and i32 %3924, 65535"
"  %3925 = lshr i32 %3921, 16"
"  %3925 = lshr i32 %3921, 16" -> "  %3927 = add nuw nsw i32 %3926, %3925"
"  %3926 = and i32 %3924, 65535"
"  %3926 = and i32 %3924, 65535" -> "  %3927 = add nuw nsw i32 %3926, %3925"
"  %3927 = add nuw nsw i32 %3926, %3925"
"  %3927 = add nuw nsw i32 %3926, %3925" -> "  %3939 = lshr i32 %3927, 16""  %3927 = add nuw nsw i32 %3926, %3925" -> "  %3934 = and i32 %3927, 65535"
"  %3928 = and i32 %3921, 65535"
"  %3928 = and i32 %3921, 65535" -> "  %3932 = add nuw nsw i32 %3931, %3928"
"  %3929 = lshr i32 %3915, 16"
"  %3929 = lshr i32 %3915, 16" -> "  %3931 = add nuw nsw i32 %3930, %3929"
"  %3930 = lshr i32 %3918, 16"
"  %3930 = lshr i32 %3918, 16" -> "  %3931 = add nuw nsw i32 %3930, %3929"
"  %3931 = add nuw nsw i32 %3930, %3929"
"  %3931 = add nuw nsw i32 %3930, %3929" -> "  %3932 = add nuw nsw i32 %3931, %3928"
"  %3932 = add nuw nsw i32 %3931, %3928"
"  %3932 = add nuw nsw i32 %3931, %3928" -> "  %4026 = and i32 %3932, 65535""  %3932 = add nuw nsw i32 %3931, %3928" -> "  %3933 = lshr i32 %3932, 16"
"  %3933 = lshr i32 %3932, 16"
"  %3933 = lshr i32 %3932, 16" -> "  %3935 = add nuw nsw i32 %3933, %3934"
"  %3934 = and i32 %3927, 65535"
"  %3934 = and i32 %3927, 65535" -> "  %3935 = add nuw nsw i32 %3933, %3934"
"  %3935 = add nuw nsw i32 %3933, %3934"
"  %3935 = add nuw nsw i32 %3933, %3934" -> "  %4032 = and i32 %3935, 65535""  %3935 = add nuw nsw i32 %3933, %3934" -> "  %3941 = lshr i32 %3935, 16"
"  %3936 = and i32 %3904, 65535"
"  %3936 = and i32 %3904, 65535" -> "  %3938 = add nuw nsw i32 %3937, %3936"
"  %3937 = lshr i32 %3924, 16"
"  %3937 = lshr i32 %3924, 16" -> "  %3938 = add nuw nsw i32 %3937, %3936"
"  %3938 = add nuw nsw i32 %3937, %3936"
"  %3938 = add nuw nsw i32 %3937, %3936" -> "  %3940 = add nuw nsw i32 %3938, %3939"
"  %3939 = lshr i32 %3927, 16"
"  %3939 = lshr i32 %3927, 16" -> "  %3940 = add nuw nsw i32 %3938, %3939"
"  %3940 = add nuw nsw i32 %3938, %3939"
"  %3940 = add nuw nsw i32 %3938, %3939" -> "  %3942 = add nuw nsw i32 %3940, %3941"
"  %3941 = lshr i32 %3935, 16"
"  %3941 = lshr i32 %3935, 16" -> "  %3942 = add nuw nsw i32 %3940, %3941"
"  %3942 = add nuw nsw i32 %3940, %3941"
"  %3942 = add nuw nsw i32 %3940, %3941" -> "  %4034 = and i32 %3942, 65535""  %3942 = add nuw nsw i32 %3940, %3941" -> "  %3944 = lshr i32 %3942, 16"
"  %3943 = and i32 %3907, 65535"
"  %3943 = and i32 %3907, 65535" -> "  %3945 = add nuw nsw i32 %3944, %3943"
"  %3944 = lshr i32 %3942, 16"
"  %3944 = lshr i32 %3942, 16" -> "  %3945 = add nuw nsw i32 %3944, %3943"
"  %3945 = add nuw nsw i32 %3944, %3943"
"  %3945 = add nuw nsw i32 %3944, %3943" -> "  %4037 = and i32 %3945, 65535""  %3945 = add nuw nsw i32 %3944, %3943" -> "  %3946 = lshr i32 %3945, 16"
"  %3946 = lshr i32 %3945, 16"
"  %3946 = lshr i32 %3945, 16" -> "  %3947 = add nuw i32 %3909, %3946"
"  %3947 = add nuw i32 %3909, %3946"
"  %3947 = add nuw i32 %3909, %3946" -> "  %4041 = add nuw i32 %3947, %4040"
"  %3948 = and i32 %2504, 65535"
"  %3948 = and i32 %2504, 65535" -> "  %3950 = add nuw nsw i32 %3948, %3949"
"  %3949 = and i32 %3291, 65535"
"  %3949 = and i32 %3291, 65535" -> "  %3950 = add nuw nsw i32 %3948, %3949"
"  %3950 = add nuw nsw i32 %3948, %3949"
"  %3950 = add nuw nsw i32 %3948, %3949" -> "  %4043 = and i32 %3950, 65535""  %3950 = add nuw nsw i32 %3948, %3949" -> "  %3954 = lshr i32 %3950, 16"
"  %3951 = and i32 %2507, 65535"
"  %3951 = and i32 %2507, 65535" -> "  %3953 = add nuw nsw i32 %3951, %3952"
"  %3952 = and i32 %3300, 65535"
"  %3952 = and i32 %3300, 65535" -> "  %3953 = add nuw nsw i32 %3951, %3952"
"  %3953 = add nuw nsw i32 %3951, %3952"
"  %3953 = add nuw nsw i32 %3951, %3952" -> "  %3967 = lshr i32 %3953, 16""  %3953 = add nuw nsw i32 %3951, %3952" -> "  %3955 = and i32 %3953, 65535"
"  %3954 = lshr i32 %3950, 16"
"  %3954 = lshr i32 %3950, 16" -> "  %3956 = add nuw nsw i32 %3955, %3954"
"  %3955 = and i32 %3953, 65535"
"  %3955 = and i32 %3953, 65535" -> "  %3956 = add nuw nsw i32 %3955, %3954"
"  %3956 = add nuw nsw i32 %3955, %3954"
"  %3956 = add nuw nsw i32 %3955, %3954" -> "  %4045 = and i32 %3956, 65535""  %3956 = add nuw nsw i32 %3955, %3954" -> "  %3968 = lshr i32 %3956, 16"
"  %3957 = and i32 %2510, 65535"
"  %3957 = and i32 %2510, 65535" -> "  %3959 = add nuw nsw i32 %3957, %3958"
"  %3958 = and i32 %3360, 65535"
"  %3958 = and i32 %3360, 65535" -> "  %3959 = add nuw nsw i32 %3957, %3958"
"  %3959 = add nuw nsw i32 %3957, %3958"
"  %3959 = add nuw nsw i32 %3957, %3958" -> "  %3966 = and i32 %3959, 65535""  %3959 = add nuw nsw i32 %3957, %3958" -> "  %3963 = lshr i32 %3959, 16"
"  %3960 = and i32 %2513, 65535"
"  %3960 = and i32 %2513, 65535" -> "  %3962 = add nuw nsw i32 %3960, %3961"
"  %3961 = and i32 %3368, 65535"
"  %3961 = and i32 %3368, 65535" -> "  %3962 = add nuw nsw i32 %3960, %3961"
"  %3962 = add nuw nsw i32 %3960, %3961"
"  %3962 = add nuw nsw i32 %3960, %3961" -> "  %4004 = lshr i32 %3962, 16""  %3962 = add nuw nsw i32 %3960, %3961" -> "  %3964 = and i32 %3962, 65535"
"  %3963 = lshr i32 %3959, 16"
"  %3963 = lshr i32 %3959, 16" -> "  %3965 = add nuw nsw i32 %3964, %3963"
"  %3964 = and i32 %3962, 65535"
"  %3964 = and i32 %3962, 65535" -> "  %3965 = add nuw nsw i32 %3964, %3963"
"  %3965 = add nuw nsw i32 %3964, %3963"
"  %3965 = add nuw nsw i32 %3964, %3963" -> "  %4005 = lshr i32 %3965, 16""  %3965 = add nuw nsw i32 %3964, %3963" -> "  %3972 = and i32 %3965, 65535"
"  %3966 = and i32 %3959, 65535"
"  %3966 = and i32 %3959, 65535" -> "  %3970 = add nuw nsw i32 %3969, %3966"
"  %3967 = lshr i32 %3953, 16"
"  %3967 = lshr i32 %3953, 16" -> "  %3969 = add nuw nsw i32 %3968, %3967"
"  %3968 = lshr i32 %3956, 16"
"  %3968 = lshr i32 %3956, 16" -> "  %3969 = add nuw nsw i32 %3968, %3967"
"  %3969 = add nuw nsw i32 %3968, %3967"
"  %3969 = add nuw nsw i32 %3968, %3967" -> "  %3970 = add nuw nsw i32 %3969, %3966"
"  %3970 = add nuw nsw i32 %3969, %3966"
"  %3970 = add nuw nsw i32 %3969, %3966" -> "  %4052 = and i32 %3970, 65535""  %3970 = add nuw nsw i32 %3969, %3966" -> "  %3971 = lshr i32 %3970, 16"
"  %3971 = lshr i32 %3970, 16"
"  %3971 = lshr i32 %3970, 16" -> "  %3973 = add nuw nsw i32 %3972, %3971"
"  %3972 = and i32 %3965, 65535"
"  %3972 = and i32 %3965, 65535" -> "  %3973 = add nuw nsw i32 %3972, %3971"
"  %3973 = add nuw nsw i32 %3972, %3971"
"  %3973 = add nuw nsw i32 %3972, %3971" -> "  %4055 = and i32 %3973, 65535""  %3973 = add nuw nsw i32 %3972, %3971" -> "  %4006 = lshr i32 %3973, 16"
"  %3974 = and i32 %2516, 65535"
"  %3974 = and i32 %2516, 65535" -> "  %3976 = add nuw nsw i32 %3974, %3975"
"  %3975 = and i32 %3709, 65535"
"  %3975 = and i32 %3709, 65535" -> "  %3976 = add nuw nsw i32 %3974, %3975"
"  %3976 = add nuw nsw i32 %3974, %3975"
"  %3976 = add nuw nsw i32 %3974, %3975" -> "  %4003 = and i32 %3976, 65535""  %3976 = add nuw nsw i32 %3974, %3975" -> "  %3980 = lshr i32 %3976, 16"
"  %3977 = and i32 %2519, 65535"
"  %3977 = and i32 %2519, 65535" -> "  %3979 = add nuw nsw i32 %3977, %3978"
"  %3978 = and i32 %3715, 65535"
"  %3978 = and i32 %3715, 65535" -> "  %3979 = add nuw nsw i32 %3977, %3978"
"  %3979 = add nuw nsw i32 %3977, %3978"
"  %3979 = add nuw nsw i32 %3977, %3978" -> "  %3995 = lshr i32 %3979, 16""  %3979 = add nuw nsw i32 %3977, %3978" -> "  %3981 = and i32 %3979, 65535"
"  %3980 = lshr i32 %3976, 16"
"  %3980 = lshr i32 %3976, 16" -> "  %3982 = add nuw nsw i32 %3981, %3980"
"  %3981 = and i32 %3979, 65535"
"  %3981 = and i32 %3979, 65535" -> "  %3982 = add nuw nsw i32 %3981, %3980"
"  %3982 = add nuw nsw i32 %3981, %3980"
"  %3982 = add nuw nsw i32 %3981, %3980" -> "  %4010 = and i32 %3982, 65535""  %3982 = add nuw nsw i32 %3981, %3980" -> "  %3996 = lshr i32 %3982, 16"
"  %3983 = and i32 %2521, 65535"
"  %3983 = and i32 %2521, 65535" -> "  %3985 = add nuw nsw i32 %3983, %3984"
"  %3984 = and i32 %3729, 65535"
"  %3984 = and i32 %3729, 65535" -> "  %3985 = add nuw nsw i32 %3983, %3984"
"  %3985 = add nuw nsw i32 %3983, %3984"
"  %3985 = add nuw nsw i32 %3983, %3984" -> "  %3994 = and i32 %3985, 65535""  %3985 = add nuw nsw i32 %3983, %3984" -> "  %3989 = lshr i32 %3985, 16"
"  %3986 = lshr i32 %2521, 16"
"  %3986 = lshr i32 %2521, 16" -> "  %3988 = add nuw nsw i32 %3986, %3987"
"  %3987 = and i32 %3732, 65535"
"  %3987 = and i32 %3732, 65535" -> "  %3988 = add nuw nsw i32 %3986, %3987"
"  %3988 = add nuw nsw i32 %3986, %3987"
"  %3988 = add nuw nsw i32 %3986, %3987" -> "  %3992 = lshr i32 %3988, 16""  %3988 = add nuw nsw i32 %3986, %3987" -> "  %3990 = and i32 %3988, 65535"
"  %3989 = lshr i32 %3985, 16"
"  %3989 = lshr i32 %3985, 16" -> "  %3991 = add nuw nsw i32 %3990, %3989"
"  %3990 = and i32 %3988, 65535"
"  %3990 = and i32 %3988, 65535" -> "  %3991 = add nuw nsw i32 %3990, %3989"
"  %3991 = add nuw nsw i32 %3990, %3989"
"  %3991 = add nuw nsw i32 %3990, %3989" -> "  %3999 = and i32 %3991, 65535""  %3991 = add nuw nsw i32 %3990, %3989" -> "  %3993 = lshr i32 %3991, 16"
"  %3992 = lshr i32 %3988, 16"
"  %3992 = lshr i32 %3988, 16" -> "  %4021 = add nuw nsw i32 %3992, %4020"
"  %3993 = lshr i32 %3991, 16"
"  %3993 = lshr i32 %3991, 16" -> "  %4022 = add nuw nsw i32 %4021, %3993"
"  %3994 = and i32 %3985, 65535"
"  %3994 = and i32 %3985, 65535" -> "  %3998 = add nuw nsw i32 %3997, %3994"
"  %3995 = lshr i32 %3979, 16"
"  %3995 = lshr i32 %3979, 16" -> "  %3997 = add nuw nsw i32 %3996, %3995"
"  %3996 = lshr i32 %3982, 16"
"  %3996 = lshr i32 %3982, 16" -> "  %3997 = add nuw nsw i32 %3996, %3995"
"  %3997 = add nuw nsw i32 %3996, %3995"
"  %3997 = add nuw nsw i32 %3996, %3995" -> "  %3998 = add nuw nsw i32 %3997, %3994"
"  %3998 = add nuw nsw i32 %3997, %3994"
"  %3998 = add nuw nsw i32 %3997, %3994" -> "  %4013 = and i32 %3998, 65535""  %3998 = add nuw nsw i32 %3997, %3994" -> "  %4000 = lshr i32 %3998, 16"
"  %3999 = and i32 %3991, 65535"
"  %3999 = and i32 %3991, 65535" -> "  %4001 = add nuw nsw i32 %4000, %3999"
"  %4000 = lshr i32 %3998, 16"
"  %4000 = lshr i32 %3998, 16" -> "  %4001 = add nuw nsw i32 %4000, %3999"
"  %4001 = add nuw nsw i32 %4000, %3999"
"  %4001 = add nuw nsw i32 %4000, %3999" -> "  %4016 = and i32 %4001, 65535""  %4001 = add nuw nsw i32 %4000, %3999" -> "  %4002 = lshr i32 %4001, 16"
"  %4002 = lshr i32 %4001, 16"
"  %4002 = lshr i32 %4001, 16" -> "  %4023 = add nuw nsw i32 %4022, %4002"
"  %4003 = and i32 %3976, 65535"
"  %4003 = and i32 %3976, 65535" -> "  %4008 = add nuw nsw i32 %4007, %4003"
"  %4004 = lshr i32 %3962, 16"
"  %4004 = lshr i32 %3962, 16" -> "  %4007 = add nuw nsw i32 %4005, %4004"
"  %4005 = lshr i32 %3965, 16"
"  %4005 = lshr i32 %3965, 16" -> "  %4007 = add nuw nsw i32 %4005, %4004"
"  %4006 = lshr i32 %3973, 16"
"  %4006 = lshr i32 %3973, 16" -> "  %4009 = add nuw nsw i32 %4008, %4006"
"  %4007 = add nuw nsw i32 %4005, %4004"
"  %4007 = add nuw nsw i32 %4005, %4004" -> "  %4008 = add nuw nsw i32 %4007, %4003"
"  %4008 = add nuw nsw i32 %4007, %4003"
"  %4008 = add nuw nsw i32 %4007, %4003" -> "  %4009 = add nuw nsw i32 %4008, %4006"
"  %4009 = add nuw nsw i32 %4008, %4006"
"  %4009 = add nuw nsw i32 %4008, %4006" -> "  %4069 = and i32 %4009, 65535""  %4009 = add nuw nsw i32 %4008, %4006" -> "  %4011 = lshr i32 %4009, 16"
"  %4010 = and i32 %3982, 65535"
"  %4010 = and i32 %3982, 65535" -> "  %4012 = add nuw nsw i32 %4010, %4011"
"  %4011 = lshr i32 %4009, 16"
"  %4011 = lshr i32 %4009, 16" -> "  %4012 = add nuw nsw i32 %4010, %4011"
"  %4012 = add nuw nsw i32 %4010, %4011"
"  %4012 = add nuw nsw i32 %4010, %4011" -> "  %4072 = and i32 %4012, 65535""  %4012 = add nuw nsw i32 %4010, %4011" -> "  %4014 = lshr i32 %4012, 16"
"  %4013 = and i32 %3998, 65535"
"  %4013 = and i32 %3998, 65535" -> "  %4015 = add nuw nsw i32 %4013, %4014"
"  %4014 = lshr i32 %4012, 16"
"  %4014 = lshr i32 %4012, 16" -> "  %4015 = add nuw nsw i32 %4013, %4014"
"  %4015 = add nuw nsw i32 %4013, %4014"
"  %4015 = add nuw nsw i32 %4013, %4014" -> "  %4078 = and i32 %4015, 65535""  %4015 = add nuw nsw i32 %4013, %4014" -> "  %4017 = lshr i32 %4015, 16"
"  %4016 = and i32 %4001, 65535"
"  %4016 = and i32 %4001, 65535" -> "  %4018 = add nuw nsw i32 %4016, %4017"
"  %4017 = lshr i32 %4015, 16"
"  %4017 = lshr i32 %4015, 16" -> "  %4018 = add nuw nsw i32 %4016, %4017"
"  %4018 = add nuw nsw i32 %4016, %4017"
"  %4018 = add nuw nsw i32 %4016, %4017" -> "  %4081 = and i32 %4018, 65535""  %4018 = add nuw nsw i32 %4016, %4017" -> "  %4019 = lshr i32 %4018, 16"
"  %4019 = lshr i32 %4018, 16"
"  %4019 = lshr i32 %4018, 16" -> "  %4024 = add nuw nsw i32 %4023, %4019"
"  %4020 = and i32 %3912, 65535"
"  %4020 = and i32 %3912, 65535" -> "  %4021 = add nuw nsw i32 %3992, %4020"
"  %4021 = add nuw nsw i32 %3992, %4020"
"  %4021 = add nuw nsw i32 %3992, %4020" -> "  %4022 = add nuw nsw i32 %4021, %3993"
"  %4022 = add nuw nsw i32 %4021, %3993"
"  %4022 = add nuw nsw i32 %4021, %3993" -> "  %4023 = add nuw nsw i32 %4022, %4002"
"  %4023 = add nuw nsw i32 %4022, %4002"
"  %4023 = add nuw nsw i32 %4022, %4002" -> "  %4024 = add nuw nsw i32 %4023, %4019"
"  %4024 = add nuw nsw i32 %4023, %4019"
"  %4024 = add nuw nsw i32 %4023, %4019" -> "  %4115 = and i32 %4024, 65535""  %4024 = add nuw nsw i32 %4023, %4019" -> "  %4027 = lshr i32 %4024, 16"
"  %4025 = and i32 %3918, 65535"
"  %4025 = and i32 %3918, 65535" -> "  %4028 = add nuw nsw i32 %4027, %4025"
"  %4026 = and i32 %3932, 65535"
"  %4026 = and i32 %3932, 65535" -> "  %4030 = add nuw nsw i32 %4029, %4026"
"  %4027 = lshr i32 %4024, 16"
"  %4027 = lshr i32 %4024, 16" -> "  %4028 = add nuw nsw i32 %4027, %4025"
"  %4028 = add nuw nsw i32 %4027, %4025"
"  %4028 = add nuw nsw i32 %4027, %4025" -> "  %4120 = and i32 %4028, 65535""  %4028 = add nuw nsw i32 %4027, %4025" -> "  %4029 = lshr i32 %4028, 16"
"  %4029 = lshr i32 %4028, 16"
"  %4029 = lshr i32 %4028, 16" -> "  %4030 = add nuw nsw i32 %4029, %4026"
"  %4030 = add nuw nsw i32 %4029, %4026"
"  %4030 = add nuw nsw i32 %4029, %4026" -> "  %4123 = and i32 %4030, 65535""  %4030 = add nuw nsw i32 %4029, %4026" -> "  %4031 = lshr i32 %4030, 16"
"  %4031 = lshr i32 %4030, 16"
"  %4031 = lshr i32 %4030, 16" -> "  %4033 = add nuw nsw i32 %4031, %4032"
"  %4032 = and i32 %3935, 65535"
"  %4032 = and i32 %3935, 65535" -> "  %4033 = add nuw nsw i32 %4031, %4032"
"  %4033 = add nuw nsw i32 %4031, %4032"
"  %4033 = add nuw nsw i32 %4031, %4032" -> "  %4129 = and i32 %4033, 65535""  %4033 = add nuw nsw i32 %4031, %4032" -> "  %4035 = lshr i32 %4033, 16"
"  %4034 = and i32 %3942, 65535"
"  %4034 = and i32 %3942, 65535" -> "  %4036 = add nuw nsw i32 %4035, %4034"
"  %4035 = lshr i32 %4033, 16"
"  %4035 = lshr i32 %4033, 16" -> "  %4036 = add nuw nsw i32 %4035, %4034"
"  %4036 = add nuw nsw i32 %4035, %4034"
"  %4036 = add nuw nsw i32 %4035, %4034" -> "  %4133 = and i32 %4036, 65535""  %4036 = add nuw nsw i32 %4035, %4034" -> "  %4038 = lshr i32 %4036, 16"
"  %4037 = and i32 %3945, 65535"
"  %4037 = and i32 %3945, 65535" -> "  %4039 = add nuw nsw i32 %4038, %4037"
"  %4038 = lshr i32 %4036, 16"
"  %4038 = lshr i32 %4036, 16" -> "  %4039 = add nuw nsw i32 %4038, %4037"
"  %4039 = add nuw nsw i32 %4038, %4037"
"  %4039 = add nuw nsw i32 %4038, %4037" -> "  %4136 = and i32 %4039, 65535""  %4039 = add nuw nsw i32 %4038, %4037" -> "  %4040 = lshr i32 %4039, 16"
"  %4040 = lshr i32 %4039, 16"
"  %4040 = lshr i32 %4039, 16" -> "  %4041 = add nuw i32 %3947, %4040"
"  %4041 = add nuw i32 %3947, %4040"
"  %4041 = add nuw i32 %3947, %4040" -> "  %4140 = add nuw i32 %4041, %4139"
"  %4042 = and i32 %3273, 65535"
"  %4042 = and i32 %3273, 65535" -> "  %4044 = add nuw nsw i32 %4042, %4043"
"  %4043 = and i32 %3950, 65535"
"  %4043 = and i32 %3950, 65535" -> "  %4044 = add nuw nsw i32 %4042, %4043"
"  %4044 = add nuw nsw i32 %4042, %4043"
"  %4044 = add nuw nsw i32 %4042, %4043" -> "  %4048 = lshr i32 %4044, 16"
"  %4045 = and i32 %3956, 65535"
"  %4045 = and i32 %3956, 65535" -> "  %4047 = add nuw nsw i32 %4046, %4045"
"  %4046 = and i32 %3276, 65535"
"  %4046 = and i32 %3276, 65535" -> "  %4047 = add nuw nsw i32 %4046, %4045"
"  %4047 = add nuw nsw i32 %4046, %4045"
"  %4047 = add nuw nsw i32 %4046, %4045" -> "  %4061 = lshr i32 %4047, 16""  %4047 = add nuw nsw i32 %4046, %4045" -> "  %4049 = and i32 %4047, 65535"
"  %4048 = lshr i32 %4044, 16"
"  %4048 = lshr i32 %4044, 16" -> "  %4050 = add nuw nsw i32 %4049, %4048"
"  %4049 = and i32 %4047, 65535"
"  %4049 = and i32 %4047, 65535" -> "  %4050 = add nuw nsw i32 %4049, %4048"
"  %4050 = add nuw nsw i32 %4049, %4048"
"  %4050 = add nuw nsw i32 %4049, %4048" -> "  %4062 = lshr i32 %4050, 16"
"  %4051 = and i32 %3279, 65535"
"  %4051 = and i32 %3279, 65535" -> "  %4053 = add nuw nsw i32 %4051, %4052"
"  %4052 = and i32 %3970, 65535"
"  %4052 = and i32 %3970, 65535" -> "  %4053 = add nuw nsw i32 %4051, %4052"
"  %4053 = add nuw nsw i32 %4051, %4052"
"  %4053 = add nuw nsw i32 %4051, %4052" -> "  %4060 = and i32 %4053, 65535""  %4053 = add nuw nsw i32 %4051, %4052" -> "  %4057 = lshr i32 %4053, 16"
"  %4054 = and i32 %3282, 65535"
"  %4054 = and i32 %3282, 65535" -> "  %4056 = add nuw nsw i32 %4054, %4055"
"  %4055 = and i32 %3973, 65535"
"  %4055 = and i32 %3973, 65535" -> "  %4056 = add nuw nsw i32 %4054, %4055"
"  %4056 = add nuw nsw i32 %4054, %4055"
"  %4056 = add nuw nsw i32 %4054, %4055" -> "  %4098 = lshr i32 %4056, 16""  %4056 = add nuw nsw i32 %4054, %4055" -> "  %4058 = and i32 %4056, 65535"
"  %4057 = lshr i32 %4053, 16"
"  %4057 = lshr i32 %4053, 16" -> "  %4059 = add nuw nsw i32 %4058, %4057"
"  %4058 = and i32 %4056, 65535"
"  %4058 = and i32 %4056, 65535" -> "  %4059 = add nuw nsw i32 %4058, %4057"
"  %4059 = add nuw nsw i32 %4058, %4057"
"  %4059 = add nuw nsw i32 %4058, %4057" -> "  %4100 = lshr i32 %4059, 16""  %4059 = add nuw nsw i32 %4058, %4057" -> "  %4066 = and i32 %4059, 65535"
"  %4060 = and i32 %4053, 65535"
"  %4060 = and i32 %4053, 65535" -> "  %4064 = add nuw nsw i32 %4063, %4060"
"  %4061 = lshr i32 %4047, 16"
"  %4061 = lshr i32 %4047, 16" -> "  %4063 = add nuw nsw i32 %4062, %4061"
"  %4062 = lshr i32 %4050, 16"
"  %4062 = lshr i32 %4050, 16" -> "  %4063 = add nuw nsw i32 %4062, %4061"
"  %4063 = add nuw nsw i32 %4062, %4061"
"  %4063 = add nuw nsw i32 %4062, %4061" -> "  %4064 = add nuw nsw i32 %4063, %4060"
"  %4064 = add nuw nsw i32 %4063, %4060"
"  %4064 = add nuw nsw i32 %4063, %4060" -> "  %4065 = lshr i32 %4064, 16"
"  %4065 = lshr i32 %4064, 16"
"  %4065 = lshr i32 %4064, 16" -> "  %4067 = add nuw nsw i32 %4066, %4065"
"  %4066 = and i32 %4059, 65535"
"  %4066 = and i32 %4059, 65535" -> "  %4067 = add nuw nsw i32 %4066, %4065"
"  %4067 = add nuw nsw i32 %4066, %4065"
"  %4067 = add nuw nsw i32 %4066, %4065" -> "  %4102 = lshr i32 %4067, 16"
"  %4068 = and i32 %3285, 65535"
"  %4068 = and i32 %3285, 65535" -> "  %4070 = add nuw nsw i32 %4068, %4069"
"  %4069 = and i32 %4009, 65535"
"  %4069 = and i32 %4009, 65535" -> "  %4070 = add nuw nsw i32 %4068, %4069"
"  %4070 = add nuw nsw i32 %4068, %4069"
"  %4070 = add nuw nsw i32 %4068, %4069" -> "  %4097 = and i32 %4070, 65535""  %4070 = add nuw nsw i32 %4068, %4069" -> "  %4074 = lshr i32 %4070, 16"
"  %4071 = and i32 %3288, 65535"
"  %4071 = and i32 %3288, 65535" -> "  %4073 = add nuw nsw i32 %4071, %4072"
"  %4072 = and i32 %4012, 65535"
"  %4072 = and i32 %4012, 65535" -> "  %4073 = add nuw nsw i32 %4071, %4072"
"  %4073 = add nuw nsw i32 %4071, %4072"
"  %4073 = add nuw nsw i32 %4071, %4072" -> "  %4089 = lshr i32 %4073, 16""  %4073 = add nuw nsw i32 %4071, %4072" -> "  %4075 = and i32 %4073, 65535"
"  %4074 = lshr i32 %4070, 16"
"  %4074 = lshr i32 %4070, 16" -> "  %4076 = add nuw nsw i32 %4075, %4074"
"  %4075 = and i32 %4073, 65535"
"  %4075 = and i32 %4073, 65535" -> "  %4076 = add nuw nsw i32 %4075, %4074"
"  %4076 = add nuw nsw i32 %4075, %4074"
"  %4076 = add nuw nsw i32 %4075, %4074" -> "  %4104 = and i32 %4076, 65535""  %4076 = add nuw nsw i32 %4075, %4074" -> "  %4091 = lshr i32 %4076, 16"
"  %4077 = and i32 %3290, 65535"
"  %4077 = and i32 %3290, 65535" -> "  %4079 = add nuw nsw i32 %4077, %4078"
"  %4078 = and i32 %4015, 65535"
"  %4078 = and i32 %4015, 65535" -> "  %4079 = add nuw nsw i32 %4077, %4078"
"  %4079 = add nuw nsw i32 %4077, %4078"
"  %4079 = add nuw nsw i32 %4077, %4078" -> "  %4088 = and i32 %4079, 65535""  %4079 = add nuw nsw i32 %4077, %4078" -> "  %4083 = lshr i32 %4079, 16"
"  %4080 = lshr i32 %3290, 16"
"  %4080 = lshr i32 %3290, 16" -> "  %4082 = add nuw nsw i32 %4081, %4080"
"  %4081 = and i32 %4018, 65535"
"  %4081 = and i32 %4018, 65535" -> "  %4082 = add nuw nsw i32 %4081, %4080"
"  %4082 = add nuw nsw i32 %4081, %4080"
"  %4082 = add nuw nsw i32 %4081, %4080" -> "  %4086 = lshr i32 %4082, 16""  %4082 = add nuw nsw i32 %4081, %4080" -> "  %4084 = and i32 %4082, 65535"
"  %4083 = lshr i32 %4079, 16"
"  %4083 = lshr i32 %4079, 16" -> "  %4085 = add nuw nsw i32 %4084, %4083"
"  %4084 = and i32 %4082, 65535"
"  %4084 = and i32 %4082, 65535" -> "  %4085 = add nuw nsw i32 %4084, %4083"
"  %4085 = add nuw nsw i32 %4084, %4083"
"  %4085 = add nuw nsw i32 %4084, %4083" -> "  %4093 = and i32 %4085, 65535""  %4085 = add nuw nsw i32 %4084, %4083" -> "  %4087 = lshr i32 %4085, 16"
"  %4086 = lshr i32 %4082, 16"
"  %4086 = lshr i32 %4082, 16" -> "  %4116 = add nuw nsw i32 %4115, %4086"
"  %4087 = lshr i32 %4085, 16"
"  %4087 = lshr i32 %4085, 16" -> "  %4117 = add nuw nsw i32 %4116, %4087"
"  %4088 = and i32 %4079, 65535"
"  %4088 = and i32 %4079, 65535" -> "  %4090 = add nuw nsw i32 %4088, %4089"
"  %4089 = lshr i32 %4073, 16"
"  %4089 = lshr i32 %4073, 16" -> "  %4090 = add nuw nsw i32 %4088, %4089"
"  %4090 = add nuw nsw i32 %4088, %4089"
"  %4090 = add nuw nsw i32 %4088, %4089" -> "  %4092 = add nuw nsw i32 %4090, %4091"
"  %4091 = lshr i32 %4076, 16"
"  %4091 = lshr i32 %4076, 16" -> "  %4092 = add nuw nsw i32 %4090, %4091"
"  %4092 = add nuw nsw i32 %4090, %4091"
"  %4092 = add nuw nsw i32 %4090, %4091" -> "  %4107 = and i32 %4092, 65535""  %4092 = add nuw nsw i32 %4090, %4091" -> "  %4094 = lshr i32 %4092, 16"
"  %4093 = and i32 %4085, 65535"
"  %4093 = and i32 %4085, 65535" -> "  %4095 = add nuw nsw i32 %4094, %4093"
"  %4094 = lshr i32 %4092, 16"
"  %4094 = lshr i32 %4092, 16" -> "  %4095 = add nuw nsw i32 %4094, %4093"
"  %4095 = add nuw nsw i32 %4094, %4093"
"  %4095 = add nuw nsw i32 %4094, %4093" -> "  %4110 = and i32 %4095, 65535""  %4095 = add nuw nsw i32 %4094, %4093" -> "  %4096 = lshr i32 %4095, 16"
"  %4096 = lshr i32 %4095, 16"
"  %4096 = lshr i32 %4095, 16" -> "  %4118 = add nuw nsw i32 %4117, %4096"
"  %4097 = and i32 %4070, 65535"
"  %4097 = and i32 %4070, 65535" -> "  %4099 = add nuw nsw i32 %4097, %4098"
"  %4098 = lshr i32 %4056, 16"
"  %4098 = lshr i32 %4056, 16" -> "  %4099 = add nuw nsw i32 %4097, %4098"
"  %4099 = add nuw nsw i32 %4097, %4098"
"  %4099 = add nuw nsw i32 %4097, %4098" -> "  %4101 = add nuw nsw i32 %4099, %4100"
"  %4100 = lshr i32 %4059, 16"
"  %4100 = lshr i32 %4059, 16" -> "  %4101 = add nuw nsw i32 %4099, %4100"
"  %4101 = add nuw nsw i32 %4099, %4100"
"  %4101 = add nuw nsw i32 %4099, %4100" -> "  %4103 = add nuw nsw i32 %4101, %4102"
"  %4102 = lshr i32 %4067, 16"
"  %4102 = lshr i32 %4067, 16" -> "  %4103 = add nuw nsw i32 %4101, %4102"
"  %4103 = add nuw nsw i32 %4101, %4102"
"  %4103 = add nuw nsw i32 %4101, %4102" -> "  %4105 = lshr i32 %4103, 16"
"  %4104 = and i32 %4076, 65535"
"  %4104 = and i32 %4076, 65535" -> "  %4106 = add nuw nsw i32 %4105, %4104"
"  %4105 = lshr i32 %4103, 16"
"  %4105 = lshr i32 %4103, 16" -> "  %4106 = add nuw nsw i32 %4105, %4104"
"  %4106 = add nuw nsw i32 %4105, %4104"
"  %4106 = add nuw nsw i32 %4105, %4104" -> "  %4108 = lshr i32 %4106, 16"
"  %4107 = and i32 %4092, 65535"
"  %4107 = and i32 %4092, 65535" -> "  %4109 = add nuw nsw i32 %4107, %4108"
"  %4108 = lshr i32 %4106, 16"
"  %4108 = lshr i32 %4106, 16" -> "  %4109 = add nuw nsw i32 %4107, %4108"
"  %4109 = add nuw nsw i32 %4107, %4108"
"  %4109 = add nuw nsw i32 %4107, %4108" -> "  %4111 = lshr i32 %4109, 16"
"  %4110 = and i32 %4095, 65535"
"  %4110 = and i32 %4095, 65535" -> "  %4112 = add nuw nsw i32 %4111, %4110"
"  %4111 = lshr i32 %4109, 16"
"  %4111 = lshr i32 %4109, 16" -> "  %4112 = add nuw nsw i32 %4111, %4110"
"  %4112 = add nuw nsw i32 %4111, %4110"
"  %4112 = add nuw nsw i32 %4111, %4110" -> "  %4114 = lshr i32 %4112, 16""  %4112 = add nuw nsw i32 %4111, %4110" -> "  %4113 = lshr i32 %4112, 15"
"  %4113 = lshr i32 %4112, 15"
"  %4113 = lshr i32 %4112, 15" -> "  %4162 = and i32 %4113, 1"
"  %4114 = lshr i32 %4112, 16"
"  %4114 = lshr i32 %4112, 16" -> "  %4119 = add nuw nsw i32 %4118, %4114"
"  %4115 = and i32 %4024, 65535"
"  %4115 = and i32 %4024, 65535" -> "  %4116 = add nuw nsw i32 %4115, %4086"
"  %4116 = add nuw nsw i32 %4115, %4086"
"  %4116 = add nuw nsw i32 %4115, %4086" -> "  %4117 = add nuw nsw i32 %4116, %4087"
"  %4117 = add nuw nsw i32 %4116, %4087"
"  %4117 = add nuw nsw i32 %4116, %4087" -> "  %4118 = add nuw nsw i32 %4117, %4096"
"  %4118 = add nuw nsw i32 %4117, %4096"
"  %4118 = add nuw nsw i32 %4117, %4096" -> "  %4119 = add nuw nsw i32 %4118, %4114"
"  %4119 = add nuw nsw i32 %4118, %4114"
"  %4119 = add nuw nsw i32 %4118, %4114" -> "  %4163 = shl nuw nsw i32 %4119, 1""  %4119 = add nuw nsw i32 %4118, %4114" -> "  %4149 = lshr i32 %4119, 15""  %4119 = add nuw nsw i32 %4118, %4114" -> "  %4121 = lshr i32 %4119, 16"
"  %4120 = and i32 %4028, 65535"
"  %4120 = and i32 %4028, 65535" -> "  %4122 = add nuw nsw i32 %4121, %4120"
"  %4121 = lshr i32 %4119, 16"
"  %4121 = lshr i32 %4119, 16" -> "  %4122 = add nuw nsw i32 %4121, %4120"
"  %4122 = add nuw nsw i32 %4121, %4120"
"  %4122 = add nuw nsw i32 %4121, %4120" -> "  %4151 = shl nuw nsw i32 %4122, 1""  %4122 = add nuw nsw i32 %4121, %4120" -> "  %4125 = lshr i32 %4122, 16""  %4122 = add nuw nsw i32 %4121, %4120" -> "  %4124 = lshr i32 %4122, 15"
"  %4123 = and i32 %4030, 65535"
"  %4123 = and i32 %4030, 65535" -> "  %4126 = add nuw nsw i32 %4125, %4123"
"  %4124 = lshr i32 %4122, 15"
"  %4124 = lshr i32 %4122, 15" -> "  %4145 = and i32 %4124, 1"
"  %4125 = lshr i32 %4122, 16"
"  %4125 = lshr i32 %4122, 16" -> "  %4126 = add nuw nsw i32 %4125, %4123"
"  %4126 = add nuw nsw i32 %4125, %4123"
"  %4126 = add nuw nsw i32 %4125, %4123" -> "  %4146 = shl nuw nsw i32 %4126, 1""  %4126 = add nuw nsw i32 %4125, %4123" -> "  %4128 = lshr i32 %4126, 16""  %4126 = add nuw nsw i32 %4125, %4123" -> "  %4127 = lshr i32 %4126, 15"
"  %4127 = lshr i32 %4126, 15"
"  %4127 = lshr i32 %4126, 15" -> "  %4141 = and i32 %4127, 1"
"  %4128 = lshr i32 %4126, 16"
"  %4128 = lshr i32 %4126, 16" -> "  %4130 = add nuw nsw i32 %4128, %4129"
"  %4129 = and i32 %4033, 65535"
"  %4129 = and i32 %4033, 65535" -> "  %4130 = add nuw nsw i32 %4128, %4129"
"  %4130 = add nuw nsw i32 %4128, %4129"
"  %4130 = add nuw nsw i32 %4128, %4129" -> "  %4142 = shl nuw nsw i32 %4130, 1""  %4130 = add nuw nsw i32 %4128, %4129" -> "  %4132 = lshr i32 %4130, 16""  %4130 = add nuw nsw i32 %4128, %4129" -> "  %4131 = lshr i32 %4130, 15"
"  %4131 = lshr i32 %4130, 15"
"  %4131 = lshr i32 %4130, 15" -> "  %4158 = and i32 %4131, 1"
"  %4132 = lshr i32 %4130, 16"
"  %4132 = lshr i32 %4130, 16" -> "  %4134 = add nuw nsw i32 %4132, %4133"
"  %4133 = and i32 %4036, 65535"
"  %4133 = and i32 %4036, 65535" -> "  %4134 = add nuw nsw i32 %4132, %4133"
"  %4134 = add nuw nsw i32 %4132, %4133"
"  %4134 = add nuw nsw i32 %4132, %4133" -> "  %4360 = lshr i32 %4134, 15""  %4134 = add nuw nsw i32 %4132, %4133" -> "  %4159 = shl nuw nsw i32 %4134, 1""  %4134 = add nuw nsw i32 %4132, %4133" -> "  %4135 = lshr i32 %4134, 16"
"  %4135 = lshr i32 %4134, 16"
"  %4135 = lshr i32 %4134, 16" -> "  %4137 = add nuw nsw i32 %4135, %4136"
"  %4136 = and i32 %4039, 65535"
"  %4136 = and i32 %4039, 65535" -> "  %4137 = add nuw nsw i32 %4135, %4136"
"  %4137 = add nuw nsw i32 %4135, %4136"
"  %4137 = add nuw nsw i32 %4135, %4136" -> "  %4362 = shl nuw nsw i32 %4137, 1""  %4137 = add nuw nsw i32 %4135, %4136" -> "  %4139 = lshr i32 %4137, 16""  %4137 = add nuw nsw i32 %4135, %4136" -> "  %4138 = lshr i32 %4137, 15"
"  %4138 = lshr i32 %4137, 15"
"  %4138 = lshr i32 %4137, 15" -> "  %4154 = and i32 %4138, 1"
"  %4139 = lshr i32 %4137, 16"
"  %4139 = lshr i32 %4137, 16" -> "  %4140 = add nuw i32 %4041, %4139"
"  %4140 = add nuw i32 %4041, %4139"
"  %4140 = add nuw i32 %4041, %4139" -> "  %4385 = lshr i32 %4140, 15""  %4140 = add nuw i32 %4041, %4139" -> "  %4155 = shl i32 %4140, 1"
"  %4141 = and i32 %4127, 1"
"  %4141 = and i32 %4127, 1" -> "  %4144 = or i32 %4143, %4141"
"  %4142 = shl nuw nsw i32 %4130, 1"
"  %4142 = shl nuw nsw i32 %4130, 1" -> "  %4143 = and i32 %4142, 65534"
"  %4143 = and i32 %4142, 65534"
"  %4143 = and i32 %4142, 65534" -> "  %4144 = or i32 %4143, %4141"
"  %4144 = or i32 %4143, %4141"
"  %4144 = or i32 %4143, %4141" -> "  %4318 = mul nuw nsw i32 %4144, 1146""  %4144 = or i32 %4143, %4141" -> "  %4254 = mul nuw i32 %4144, 63663""  %4144 = or i32 %4143, %4141" -> "  %4250 = mul nuw nsw i32 %4144, 7935""  %4144 = or i32 %4143, %4141" -> "  %4223 = mul nuw i32 %4144, 34017""  %4144 = or i32 %4143, %4141" -> "  %4219 = mul nuw nsw i32 %4144, 17399"
"  %4145 = and i32 %4124, 1"
"  %4145 = and i32 %4124, 1" -> "  %4148 = or i32 %4147, %4145"
"  %4146 = shl nuw nsw i32 %4126, 1"
"  %4146 = shl nuw nsw i32 %4126, 1" -> "  %4147 = and i32 %4146, 65534"
"  %4147 = and i32 %4146, 65534"
"  %4147 = and i32 %4146, 65534" -> "  %4148 = or i32 %4147, %4145"
"  %4148 = or i32 %4147, %4145"
"  %4148 = or i32 %4147, %4145" -> "  %4215 = mul nuw nsw i32 %4148, 17399""  %4148 = or i32 %4147, %4145" -> "  %4316 = mul nuw nsw i32 %4148, 1146""  %4148 = or i32 %4147, %4145" -> "  %4315 = mul nuw i32 %4148, 43563""  %4148 = or i32 %4147, %4145" -> "  %4245 = mul nuw i32 %4148, 63663""  %4148 = or i32 %4147, %4145" -> "  %4243 = mul nuw nsw i32 %4148, 7935""  %4148 = or i32 %4147, %4145" -> "  %4217 = mul nuw i32 %4148, 34017"
"  %4149 = lshr i32 %4119, 15"
"  %4149 = lshr i32 %4119, 15" -> "  %4150 = and i32 %4149, 1"
"  %4150 = and i32 %4149, 1"
"  %4150 = and i32 %4149, 1" -> "  %4153 = or i32 %4152, %4150"
"  %4151 = shl nuw nsw i32 %4122, 1"
"  %4151 = shl nuw nsw i32 %4122, 1" -> "  %4152 = and i32 %4151, 65534"
"  %4152 = and i32 %4151, 65534"
"  %4152 = and i32 %4151, 65534" -> "  %4153 = or i32 %4152, %4150"
"  %4153 = or i32 %4152, %4150"
"  %4153 = or i32 %4152, %4150" -> "  %4311 = mul nuw nsw i32 %4153, 13953""  %4153 = or i32 %4152, %4150" -> "  %4301 = mul nuw i32 %4153, 43563""  %4153 = or i32 %4152, %4150" -> "  %4297 = mul nuw nsw i32 %4153, 1146""  %4153 = or i32 %4152, %4150" -> "  %4195 = mul nuw i32 %4153, 63663""  %4153 = or i32 %4152, %4150" -> "  %4191 = mul nuw nsw i32 %4153, 7935""  %4153 = or i32 %4152, %4150" -> "  %4177 = mul nuw i32 %4153, 34017""  %4153 = or i32 %4152, %4150" -> "  %4173 = mul nuw nsw i32 %4153, 17399"
"  %4154 = and i32 %4138, 1"
"  %4154 = and i32 %4138, 1" -> "  %4157 = or i32 %4156, %4154"
"  %4155 = shl i32 %4140, 1"
"  %4155 = shl i32 %4140, 1" -> "  %4156 = and i32 %4155, 65534"
"  %4156 = and i32 %4155, 65534"
"  %4156 = and i32 %4155, 65534" -> "  %4157 = or i32 %4156, %4154"
"  %4157 = or i32 %4156, %4154"
"  %4157 = or i32 %4156, %4154" -> "  %4389 = mul nuw i32 %4157, 34017""  %4157 = or i32 %4156, %4154" -> "  %4391 = mul nuw nsw i32 %4157, 17399"
"  %4158 = and i32 %4131, 1"
"  %4158 = and i32 %4131, 1" -> "  %4161 = or i32 %4160, %4158"
"  %4159 = shl nuw nsw i32 %4134, 1"
"  %4159 = shl nuw nsw i32 %4134, 1" -> "  %4160 = and i32 %4159, 65534"
"  %4160 = and i32 %4159, 65534"
"  %4160 = and i32 %4159, 65534" -> "  %4161 = or i32 %4160, %4158"
"  %4161 = or i32 %4160, %4158"
"  %4161 = or i32 %4160, %4158" -> "  %4356 = mul nuw nsw i32 %4161, 17399""  %4161 = or i32 %4160, %4158" -> "  %4358 = mul nuw i32 %4161, 34017""  %4161 = or i32 %4160, %4158" -> "  %4376 = mul nuw nsw i32 %4161, 7935""  %4161 = or i32 %4160, %4158" -> "  %4378 = mul nuw i32 %4161, 63663"
"  %4162 = and i32 %4113, 1"
"  %4162 = and i32 %4113, 1" -> "  %4165 = or i32 %4164, %4162"
"  %4163 = shl nuw nsw i32 %4119, 1"
"  %4163 = shl nuw nsw i32 %4119, 1" -> "  %4164 = and i32 %4163, 65534"
"  %4164 = and i32 %4163, 65534"
"  %4164 = and i32 %4163, 65534" -> "  %4165 = or i32 %4164, %4162"
"  %4165 = or i32 %4164, %4162"
"  %4165 = or i32 %4164, %4162" -> "  %4310 = mul nuw i32 %4165, 58377""  %4165 = or i32 %4164, %4162" -> "  %4308 = mul nuw nsw i32 %4165, 13953""  %4165 = or i32 %4164, %4162" -> "  %4292 = mul nuw i32 %4165, 43563""  %4165 = or i32 %4164, %4162" -> "  %4290 = mul nuw nsw i32 %4165, 1146""  %4165 = or i32 %4164, %4162" -> "  %4186 = mul nuw i32 %4165, 63663""  %4165 = or i32 %4164, %4162" -> "  %4184 = mul nuw nsw i32 %4165, 7935""  %4165 = or i32 %4164, %4162" -> "  %4168 = mul nuw i32 %4165, 34017""  %4165 = or i32 %4164, %4162" -> "  %4166 = mul nuw nsw i32 %4165, 17399"
"  %4166 = mul nuw nsw i32 %4165, 17399"
"  %4166 = mul nuw nsw i32 %4165, 17399" -> "  %4427 = and i32 %4166, 65535""  %4166 = mul nuw nsw i32 %4165, 17399" -> "  %4167 = lshr i32 %4166, 16"
"  %4167 = lshr i32 %4166, 16"
"  %4167 = lshr i32 %4166, 16" -> "  %4170 = add nuw nsw i32 %4167, %4169"
"  %4168 = mul nuw i32 %4165, 34017"
"  %4168 = mul nuw i32 %4165, 34017" -> "  %4171 = and i32 %4168, -65536""  %4168 = mul nuw i32 %4165, 34017" -> "  %4169 = and i32 %4168, 65535"
"  %4169 = and i32 %4168, 65535"
"  %4169 = and i32 %4168, 65535" -> "  %4170 = add nuw nsw i32 %4167, %4169"
"  %4170 = add nuw nsw i32 %4167, %4169"
"  %4170 = add nuw nsw i32 %4167, %4169" -> "  %4172 = add nuw i32 %4170, %4171"
"  %4171 = and i32 %4168, -65536"
"  %4171 = and i32 %4168, -65536" -> "  %4172 = add nuw i32 %4170, %4171"
"  %4172 = add nuw i32 %4170, %4171"
"  %4172 = add nuw i32 %4170, %4171" -> "  %4176 = lshr i32 %4172, 16""  %4172 = add nuw i32 %4170, %4171" -> "  %4174 = and i32 %4172, 65535"
"  %4173 = mul nuw nsw i32 %4153, 17399"
"  %4173 = mul nuw nsw i32 %4153, 17399" -> "  %4175 = add nuw nsw i32 %4174, %4173"
"  %4174 = and i32 %4172, 65535"
"  %4174 = and i32 %4172, 65535" -> "  %4175 = add nuw nsw i32 %4174, %4173"
"  %4175 = add nuw nsw i32 %4174, %4173"
"  %4175 = add nuw nsw i32 %4174, %4173" -> "  %4429 = and i32 %4175, 65535""  %4175 = add nuw nsw i32 %4174, %4173" -> "  %4179 = lshr i32 %4175, 16"
"  %4176 = lshr i32 %4172, 16"
"  %4176 = lshr i32 %4172, 16" -> "  %4178 = add nuw i32 %4176, %4177"
"  %4177 = mul nuw i32 %4153, 34017"
"  %4177 = mul nuw i32 %4153, 34017" -> "  %4178 = add nuw i32 %4176, %4177"
"  %4178 = add nuw i32 %4176, %4177"
"  %4178 = add nuw i32 %4176, %4177" -> "  %4182 = and i32 %4178, -65536""  %4178 = add nuw i32 %4176, %4177" -> "  %4180 = and i32 %4178, 65535"
"  %4179 = lshr i32 %4175, 16"
"  %4179 = lshr i32 %4175, 16" -> "  %4181 = add nuw nsw i32 %4179, %4180"
"  %4180 = and i32 %4178, 65535"
"  %4180 = and i32 %4178, 65535" -> "  %4181 = add nuw nsw i32 %4179, %4180"
"  %4181 = add nuw nsw i32 %4179, %4180"
"  %4181 = add nuw nsw i32 %4179, %4180" -> "  %4183 = add nuw i32 %4181, %4182"
"  %4182 = and i32 %4178, -65536"
"  %4182 = and i32 %4178, -65536" -> "  %4183 = add nuw i32 %4181, %4182"
"  %4183 = add nuw i32 %4181, %4182"
"  %4183 = add nuw i32 %4181, %4182" -> "  %4206 = lshr i32 %4183, 16""  %4183 = add nuw i32 %4181, %4182" -> "  %4202 = and i32 %4183, 65535"
"  %4184 = mul nuw nsw i32 %4165, 7935"
"  %4184 = mul nuw nsw i32 %4165, 7935" -> "  %4203 = and i32 %4184, 65535""  %4184 = mul nuw nsw i32 %4165, 7935" -> "  %4185 = lshr i32 %4184, 16"
"  %4185 = lshr i32 %4184, 16"
"  %4185 = lshr i32 %4184, 16" -> "  %4188 = add nuw nsw i32 %4185, %4187"
"  %4186 = mul nuw i32 %4165, 63663"
"  %4186 = mul nuw i32 %4165, 63663" -> "  %4189 = and i32 %4186, -65536""  %4186 = mul nuw i32 %4165, 63663" -> "  %4187 = and i32 %4186, 65535"
"  %4187 = and i32 %4186, 65535"
"  %4187 = and i32 %4186, 65535" -> "  %4188 = add nuw nsw i32 %4185, %4187"
"  %4188 = add nuw nsw i32 %4185, %4187"
"  %4188 = add nuw nsw i32 %4185, %4187" -> "  %4190 = add nuw i32 %4188, %4189"
"  %4189 = and i32 %4186, -65536"
"  %4189 = and i32 %4186, -65536" -> "  %4190 = add nuw i32 %4188, %4189"
"  %4190 = add nuw i32 %4188, %4189"
"  %4190 = add nuw i32 %4188, %4189" -> "  %4194 = lshr i32 %4190, 16""  %4190 = add nuw i32 %4188, %4189" -> "  %4192 = and i32 %4190, 65535"
"  %4191 = mul nuw nsw i32 %4153, 7935"
"  %4191 = mul nuw nsw i32 %4153, 7935" -> "  %4193 = add nuw nsw i32 %4192, %4191"
"  %4192 = and i32 %4190, 65535"
"  %4192 = and i32 %4190, 65535" -> "  %4193 = add nuw nsw i32 %4192, %4191"
"  %4193 = add nuw nsw i32 %4192, %4191"
"  %4193 = add nuw nsw i32 %4192, %4191" -> "  %4205 = and i32 %4193, 65535""  %4193 = add nuw nsw i32 %4192, %4191" -> "  %4197 = lshr i32 %4193, 16"
"  %4194 = lshr i32 %4190, 16"
"  %4194 = lshr i32 %4190, 16" -> "  %4196 = add nuw i32 %4194, %4195"
"  %4195 = mul nuw i32 %4153, 63663"
"  %4195 = mul nuw i32 %4153, 63663" -> "  %4196 = add nuw i32 %4194, %4195"
"  %4196 = add nuw i32 %4194, %4195"
"  %4196 = add nuw i32 %4194, %4195" -> "  %4200 = and i32 %4196, -65536""  %4196 = add nuw i32 %4194, %4195" -> "  %4198 = and i32 %4196, 65535"
"  %4197 = lshr i32 %4193, 16"
"  %4197 = lshr i32 %4193, 16" -> "  %4199 = add nuw nsw i32 %4197, %4198"
"  %4198 = and i32 %4196, 65535"
"  %4198 = and i32 %4196, 65535" -> "  %4199 = add nuw nsw i32 %4197, %4198"
"  %4199 = add nuw nsw i32 %4197, %4198"
"  %4199 = add nuw nsw i32 %4197, %4198" -> "  %4201 = add nuw i32 %4199, %4200"
"  %4200 = and i32 %4196, -65536"
"  %4200 = and i32 %4196, -65536" -> "  %4201 = add nuw i32 %4199, %4200"
"  %4201 = add nuw i32 %4199, %4200"
"  %4201 = add nuw i32 %4199, %4200" -> "  %4209 = add nuw i32 %4201, %4208"
"  %4202 = and i32 %4183, 65535"
"  %4202 = and i32 %4183, 65535" -> "  %4204 = add nuw nsw i32 %4202, %4203"
"  %4203 = and i32 %4184, 65535"
"  %4203 = and i32 %4184, 65535" -> "  %4204 = add nuw nsw i32 %4202, %4203"
"  %4204 = add nuw nsw i32 %4202, %4203"
"  %4204 = add nuw nsw i32 %4202, %4203" -> "  %4230 = and i32 %4204, 65535""  %4204 = add nuw nsw i32 %4202, %4203" -> "  %4211 = lshr i32 %4204, 16"
"  %4205 = and i32 %4193, 65535"
"  %4205 = and i32 %4193, 65535" -> "  %4207 = add nuw nsw i32 %4206, %4205"
"  %4206 = lshr i32 %4183, 16"
"  %4206 = lshr i32 %4183, 16" -> "  %4207 = add nuw nsw i32 %4206, %4205"
"  %4207 = add nuw nsw i32 %4206, %4205"
"  %4207 = add nuw nsw i32 %4206, %4205" -> "  %4210 = and i32 %4207, 65535""  %4207 = add nuw nsw i32 %4206, %4205" -> "  %4208 = lshr i32 %4207, 16"
"  %4208 = lshr i32 %4207, 16"
"  %4208 = lshr i32 %4207, 16" -> "  %4209 = add nuw i32 %4201, %4208"
"  %4209 = add nuw i32 %4201, %4208"
"  %4209 = add nuw i32 %4201, %4208" -> "  %4214 = add nuw i32 %4209, %4213"
"  %4210 = and i32 %4207, 65535"
"  %4210 = and i32 %4207, 65535" -> "  %4212 = add nuw nsw i32 %4211, %4210"
"  %4211 = lshr i32 %4204, 16"
"  %4211 = lshr i32 %4204, 16" -> "  %4212 = add nuw nsw i32 %4211, %4210"
"  %4212 = add nuw nsw i32 %4211, %4210"
"  %4212 = add nuw nsw i32 %4211, %4210" -> "  %4234 = and i32 %4212, 65535""  %4212 = add nuw nsw i32 %4211, %4210" -> "  %4213 = lshr i32 %4212, 16"
"  %4213 = lshr i32 %4212, 16"
"  %4213 = lshr i32 %4212, 16" -> "  %4214 = add nuw i32 %4209, %4213"
"  %4214 = add nuw i32 %4209, %4213"
"  %4214 = add nuw i32 %4209, %4213" -> "  %4261 = and i32 %4214, 65535""  %4214 = add nuw i32 %4209, %4213" -> "  %4265 = lshr i32 %4214, 16"
"  %4215 = mul nuw nsw i32 %4148, 17399"
"  %4215 = mul nuw nsw i32 %4148, 17399" -> "  %4231 = and i32 %4215, 65535""  %4215 = mul nuw nsw i32 %4148, 17399" -> "  %4216 = lshr i32 %4215, 16"
"  %4216 = lshr i32 %4215, 16"
"  %4216 = lshr i32 %4215, 16" -> "  %4218 = add i32 %4216, %4217"
"  %4217 = mul nuw i32 %4148, 34017"
"  %4217 = mul nuw i32 %4148, 34017" -> "  %4218 = add i32 %4216, %4217"
"  %4218 = add i32 %4216, %4217"
"  %4218 = add i32 %4216, %4217" -> "  %4222 = lshr i32 %4218, 16""  %4218 = add i32 %4216, %4217" -> "  %4220 = and i32 %4218, 65535"
"  %4219 = mul nuw nsw i32 %4144, 17399"
"  %4219 = mul nuw nsw i32 %4144, 17399" -> "  %4221 = add nuw i32 %4220, %4219"
"  %4220 = and i32 %4218, 65535"
"  %4220 = and i32 %4218, 65535" -> "  %4221 = add nuw i32 %4220, %4219"
"  %4221 = add nuw i32 %4220, %4219"
"  %4221 = add nuw i32 %4220, %4219" -> "  %4233 = and i32 %4221, 65535""  %4221 = add nuw i32 %4220, %4219" -> "  %4225 = lshr i32 %4221, 16"
"  %4222 = lshr i32 %4218, 16"
"  %4222 = lshr i32 %4218, 16" -> "  %4224 = add i32 %4222, %4223"
"  %4223 = mul nuw i32 %4144, 34017"
"  %4223 = mul nuw i32 %4144, 34017" -> "  %4224 = add i32 %4222, %4223"
"  %4224 = add i32 %4222, %4223"
"  %4224 = add i32 %4222, %4223" -> "  %4228 = and i32 %4224, -65536""  %4224 = add i32 %4222, %4223" -> "  %4226 = and i32 %4224, 65535"
"  %4225 = lshr i32 %4221, 16"
"  %4225 = lshr i32 %4221, 16" -> "  %4227 = add nuw nsw i32 %4225, %4226"
"  %4226 = and i32 %4224, 65535"
"  %4226 = and i32 %4224, 65535" -> "  %4227 = add nuw nsw i32 %4225, %4226"
"  %4227 = add nuw nsw i32 %4225, %4226"
"  %4227 = add nuw nsw i32 %4225, %4226" -> "  %4229 = add i32 %4227, %4228"
"  %4228 = and i32 %4224, -65536"
"  %4228 = and i32 %4224, -65536" -> "  %4229 = add i32 %4227, %4228"
"  %4229 = add i32 %4227, %4228"
"  %4229 = add i32 %4227, %4228" -> "  %4237 = add i32 %4229, %4236"
"  %4230 = and i32 %4204, 65535"
"  %4230 = and i32 %4204, 65535" -> "  %4232 = add nuw nsw i32 %4230, %4231"
"  %4231 = and i32 %4215, 65535"
"  %4231 = and i32 %4215, 65535" -> "  %4232 = add nuw nsw i32 %4230, %4231"
"  %4232 = add nuw nsw i32 %4230, %4231"
"  %4232 = add nuw nsw i32 %4230, %4231" -> "  %4433 = and i32 %4232, 65535""  %4232 = add nuw nsw i32 %4230, %4231" -> "  %4239 = lshr i32 %4232, 16"
"  %4233 = and i32 %4221, 65535"
"  %4233 = and i32 %4221, 65535" -> "  %4235 = add nuw nsw i32 %4234, %4233"
"  %4234 = and i32 %4212, 65535"
"  %4234 = and i32 %4212, 65535" -> "  %4235 = add nuw nsw i32 %4234, %4233"
"  %4235 = add nuw nsw i32 %4234, %4233"
"  %4235 = add nuw nsw i32 %4234, %4233" -> "  %4238 = and i32 %4235, 65535""  %4235 = add nuw nsw i32 %4234, %4233" -> "  %4236 = lshr i32 %4235, 16"
"  %4236 = lshr i32 %4235, 16"
"  %4236 = lshr i32 %4235, 16" -> "  %4237 = add i32 %4229, %4236"
"  %4237 = add i32 %4229, %4236"
"  %4237 = add i32 %4229, %4236" -> "  %4242 = add i32 %4237, %4241"
"  %4238 = and i32 %4235, 65535"
"  %4238 = and i32 %4235, 65535" -> "  %4240 = add nuw nsw i32 %4238, %4239"
"  %4239 = lshr i32 %4232, 16"
"  %4239 = lshr i32 %4232, 16" -> "  %4240 = add nuw nsw i32 %4238, %4239"
"  %4240 = add nuw nsw i32 %4238, %4239"
"  %4240 = add nuw nsw i32 %4238, %4239" -> "  %4437 = and i32 %4240, 65535""  %4240 = add nuw nsw i32 %4238, %4239" -> "  %4241 = lshr i32 %4240, 16"
"  %4241 = lshr i32 %4240, 16"
"  %4241 = lshr i32 %4240, 16" -> "  %4242 = add i32 %4237, %4241"
"  %4242 = add i32 %4237, %4241"
"  %4242 = add i32 %4237, %4241" -> "  %4278 = lshr i32 %4242, 16""  %4242 = add i32 %4237, %4241" -> "  %4275 = and i32 %4242, 65535"
"  %4243 = mul nuw nsw i32 %4148, 7935"
"  %4243 = mul nuw nsw i32 %4148, 7935" -> "  %4262 = and i32 %4243, 65535""  %4243 = mul nuw nsw i32 %4148, 7935" -> "  %4244 = lshr i32 %4243, 16"
"  %4244 = lshr i32 %4243, 16"
"  %4244 = lshr i32 %4243, 16" -> "  %4247 = add nuw nsw i32 %4244, %4246"
"  %4245 = mul nuw i32 %4148, 63663"
"  %4245 = mul nuw i32 %4148, 63663" -> "  %4248 = and i32 %4245, -65536""  %4245 = mul nuw i32 %4148, 63663" -> "  %4246 = and i32 %4245, 65535"
"  %4246 = and i32 %4245, 65535"
"  %4246 = and i32 %4245, 65535" -> "  %4247 = add nuw nsw i32 %4244, %4246"
"  %4247 = add nuw nsw i32 %4244, %4246"
"  %4247 = add nuw nsw i32 %4244, %4246" -> "  %4249 = add i32 %4247, %4248"
"  %4248 = and i32 %4245, -65536"
"  %4248 = and i32 %4245, -65536" -> "  %4249 = add i32 %4247, %4248"
"  %4249 = add i32 %4247, %4248"
"  %4249 = add i32 %4247, %4248" -> "  %4253 = lshr i32 %4249, 16""  %4249 = add i32 %4247, %4248" -> "  %4251 = and i32 %4249, 65535"
"  %4250 = mul nuw nsw i32 %4144, 7935"
"  %4250 = mul nuw nsw i32 %4144, 7935" -> "  %4252 = add nuw nsw i32 %4251, %4250"
"  %4251 = and i32 %4249, 65535"
"  %4251 = and i32 %4249, 65535" -> "  %4252 = add nuw nsw i32 %4251, %4250"
"  %4252 = add nuw nsw i32 %4251, %4250"
"  %4252 = add nuw nsw i32 %4251, %4250" -> "  %4264 = and i32 %4252, 65535""  %4252 = add nuw nsw i32 %4251, %4250" -> "  %4256 = lshr i32 %4252, 16"
"  %4253 = lshr i32 %4249, 16"
"  %4253 = lshr i32 %4249, 16" -> "  %4255 = add i32 %4253, %4254"
"  %4254 = mul nuw i32 %4144, 63663"
"  %4254 = mul nuw i32 %4144, 63663" -> "  %4255 = add i32 %4253, %4254"
"  %4255 = add i32 %4253, %4254"
"  %4255 = add i32 %4253, %4254" -> "  %4259 = and i32 %4255, -65536""  %4255 = add i32 %4253, %4254" -> "  %4257 = and i32 %4255, 65535"
"  %4256 = lshr i32 %4252, 16"
"  %4256 = lshr i32 %4252, 16" -> "  %4258 = add nuw nsw i32 %4256, %4257"
"  %4257 = and i32 %4255, 65535"
"  %4257 = and i32 %4255, 65535" -> "  %4258 = add nuw nsw i32 %4256, %4257"
"  %4258 = add nuw nsw i32 %4256, %4257"
"  %4258 = add nuw nsw i32 %4256, %4257" -> "  %4260 = add i32 %4258, %4259"
"  %4259 = and i32 %4255, -65536"
"  %4259 = and i32 %4255, -65536" -> "  %4260 = add i32 %4258, %4259"
"  %4260 = add i32 %4258, %4259"
"  %4260 = add i32 %4258, %4259" -> "  %4268 = add i32 %4260, %4267"
"  %4261 = and i32 %4214, 65535"
"  %4261 = and i32 %4214, 65535" -> "  %4263 = add nuw nsw i32 %4261, %4262"
"  %4262 = and i32 %4243, 65535"
"  %4262 = and i32 %4243, 65535" -> "  %4263 = add nuw nsw i32 %4261, %4262"
"  %4263 = add nuw nsw i32 %4261, %4262"
"  %4263 = add nuw nsw i32 %4261, %4262" -> "  %4274 = and i32 %4263, 65535""  %4263 = add nuw nsw i32 %4261, %4262" -> "  %4270 = lshr i32 %4263, 16"
"  %4264 = and i32 %4252, 65535"
"  %4264 = and i32 %4252, 65535" -> "  %4266 = add nuw nsw i32 %4265, %4264"
"  %4265 = lshr i32 %4214, 16"
"  %4265 = lshr i32 %4214, 16" -> "  %4266 = add nuw nsw i32 %4265, %4264"
"  %4266 = add nuw nsw i32 %4265, %4264"
"  %4266 = add nuw nsw i32 %4265, %4264" -> "  %4269 = and i32 %4266, 65535""  %4266 = add nuw nsw i32 %4265, %4264" -> "  %4267 = lshr i32 %4266, 16"
"  %4267 = lshr i32 %4266, 16"
"  %4267 = lshr i32 %4266, 16" -> "  %4268 = add i32 %4260, %4267"
"  %4268 = add i32 %4260, %4267"
"  %4268 = add i32 %4260, %4267" -> "  %4273 = add i32 %4268, %4272"
"  %4269 = and i32 %4266, 65535"
"  %4269 = and i32 %4266, 65535" -> "  %4271 = add nuw nsw i32 %4269, %4270"
"  %4270 = lshr i32 %4263, 16"
"  %4270 = lshr i32 %4263, 16" -> "  %4271 = add nuw nsw i32 %4269, %4270"
"  %4271 = add nuw nsw i32 %4269, %4270"
"  %4271 = add nuw nsw i32 %4269, %4270" -> "  %4277 = and i32 %4271, 65535""  %4271 = add nuw nsw i32 %4269, %4270" -> "  %4272 = lshr i32 %4271, 16"
"  %4272 = lshr i32 %4271, 16"
"  %4272 = lshr i32 %4271, 16" -> "  %4273 = add i32 %4268, %4272"
"  %4273 = add i32 %4268, %4272"
"  %4273 = add i32 %4268, %4272" -> "  %4286 = and i32 %4273, -65536""  %4273 = add i32 %4268, %4272" -> "  %4284 = and i32 %4273, 65535"
"  %4274 = and i32 %4263, 65535"
"  %4274 = and i32 %4263, 65535" -> "  %4276 = add nuw nsw i32 %4275, %4274"
"  %4275 = and i32 %4242, 65535"
"  %4275 = and i32 %4242, 65535" -> "  %4276 = add nuw nsw i32 %4275, %4274"
"  %4276 = add nuw nsw i32 %4275, %4274"
"  %4276 = add nuw nsw i32 %4275, %4274" -> "  %4326 = and i32 %4276, 65535""  %4276 = add nuw nsw i32 %4275, %4274" -> "  %4280 = lshr i32 %4276, 16"
"  %4277 = and i32 %4271, 65535"
"  %4277 = and i32 %4271, 65535" -> "  %4279 = add nuw nsw i32 %4277, %4278"
"  %4278 = lshr i32 %4242, 16"
"  %4278 = lshr i32 %4242, 16" -> "  %4279 = add nuw nsw i32 %4277, %4278"
"  %4279 = add nuw nsw i32 %4277, %4278"
"  %4279 = add nuw nsw i32 %4277, %4278" -> "  %4283 = lshr i32 %4279, 16""  %4279 = add nuw nsw i32 %4277, %4278" -> "  %4281 = and i32 %4279, 65535"
"  %4280 = lshr i32 %4276, 16"
"  %4280 = lshr i32 %4276, 16" -> "  %4282 = add nuw nsw i32 %4281, %4280"
"  %4281 = and i32 %4279, 65535"
"  %4281 = and i32 %4279, 65535" -> "  %4282 = add nuw nsw i32 %4281, %4280"
"  %4282 = add nuw nsw i32 %4281, %4280"
"  %4282 = add nuw nsw i32 %4281, %4280" -> "  %4329 = and i32 %4282, 65535""  %4282 = add nuw nsw i32 %4281, %4280" -> "  %4288 = lshr i32 %4282, 16"
"  %4283 = lshr i32 %4279, 16"
"  %4283 = lshr i32 %4279, 16" -> "  %4285 = add nuw nsw i32 %4283, %4284"
"  %4284 = and i32 %4273, 65535"
"  %4284 = and i32 %4273, 65535" -> "  %4285 = add nuw nsw i32 %4283, %4284"
"  %4285 = add nuw nsw i32 %4283, %4284"
"  %4285 = add nuw nsw i32 %4283, %4284" -> "  %4287 = add i32 %4285, %4286"
"  %4286 = and i32 %4273, -65536"
"  %4286 = and i32 %4273, -65536" -> "  %4287 = add i32 %4285, %4286"
"  %4287 = add i32 %4285, %4286"
"  %4287 = add i32 %4285, %4286" -> "  %4289 = add i32 %4287, %4288"
"  %4288 = lshr i32 %4282, 16"
"  %4288 = lshr i32 %4282, 16" -> "  %4289 = add i32 %4287, %4288"
"  %4289 = add i32 %4287, %4288"
"  %4289 = add i32 %4287, %4288" -> "  %4336 = and i32 %4289, 65535""  %4289 = add i32 %4287, %4288" -> "  %4325 = lshr i32 %4289, 16"
"  %4290 = mul nuw nsw i32 %4165, 1146"
"  %4290 = mul nuw nsw i32 %4165, 1146" -> "  %4327 = and i32 %4290, 65534""  %4290 = mul nuw nsw i32 %4165, 1146" -> "  %4291 = lshr i32 %4290, 16"
"  %4291 = lshr i32 %4290, 16"
"  %4291 = lshr i32 %4290, 16" -> "  %4294 = add nuw nsw i32 %4291, %4293"
"  %4292 = mul nuw i32 %4165, 43563"
"  %4292 = mul nuw i32 %4165, 43563" -> "  %4295 = and i32 %4292, -65536""  %4292 = mul nuw i32 %4165, 43563" -> "  %4293 = and i32 %4292, 65535"
"  %4293 = and i32 %4292, 65535"
"  %4293 = and i32 %4292, 65535" -> "  %4294 = add nuw nsw i32 %4291, %4293"
"  %4294 = add nuw nsw i32 %4291, %4293"
"  %4294 = add nuw nsw i32 %4291, %4293" -> "  %4296 = add i32 %4294, %4295"
"  %4295 = and i32 %4292, -65536"
"  %4295 = and i32 %4292, -65536" -> "  %4296 = add i32 %4294, %4295"
"  %4296 = add i32 %4294, %4295"
"  %4296 = add i32 %4294, %4295" -> "  %4300 = lshr i32 %4296, 16""  %4296 = add i32 %4294, %4295" -> "  %4298 = and i32 %4296, 65535"
"  %4297 = mul nuw nsw i32 %4153, 1146"
"  %4297 = mul nuw nsw i32 %4153, 1146" -> "  %4299 = add nuw nsw i32 %4298, %4297"
"  %4298 = and i32 %4296, 65535"
"  %4298 = and i32 %4296, 65535" -> "  %4299 = add nuw nsw i32 %4298, %4297"
"  %4299 = add nuw nsw i32 %4298, %4297"
"  %4299 = add nuw nsw i32 %4298, %4297" -> "  %4330 = and i32 %4299, 65535""  %4299 = add nuw nsw i32 %4298, %4297" -> "  %4303 = lshr i32 %4299, 16"
"  %4300 = lshr i32 %4296, 16"
"  %4300 = lshr i32 %4296, 16" -> "  %4302 = add i32 %4300, %4301"
"  %4301 = mul nuw i32 %4153, 43563"
"  %4301 = mul nuw i32 %4153, 43563" -> "  %4302 = add i32 %4300, %4301"
"  %4302 = add i32 %4300, %4301"
"  %4302 = add i32 %4300, %4301" -> "  %4306 = and i32 %4302, -65536""  %4302 = add i32 %4300, %4301" -> "  %4304 = and i32 %4302, 65535"
"  %4303 = lshr i32 %4299, 16"
"  %4303 = lshr i32 %4299, 16" -> "  %4305 = add nuw nsw i32 %4303, %4304"
"  %4304 = and i32 %4302, 65535"
"  %4304 = and i32 %4302, 65535" -> "  %4305 = add nuw nsw i32 %4303, %4304"
"  %4305 = add nuw nsw i32 %4303, %4304"
"  %4305 = add nuw nsw i32 %4303, %4304" -> "  %4307 = add i32 %4305, %4306"
"  %4306 = and i32 %4302, -65536"
"  %4306 = and i32 %4302, -65536" -> "  %4307 = add i32 %4305, %4306"
"  %4307 = add i32 %4305, %4306"
"  %4307 = add i32 %4305, %4306" -> "  %4319 = lshr i32 %4307, 16""  %4307 = add i32 %4305, %4306" -> "  %4312 = and i32 %4307, 65535"
"  %4308 = mul nuw nsw i32 %4165, 13953"
"  %4308 = mul nuw nsw i32 %4165, 13953" -> "  %4313 = and i32 %4308, 65535""  %4308 = mul nuw nsw i32 %4165, 13953" -> "  %4309 = lshr i32 %4308, 16"
"  %4309 = lshr i32 %4308, 16"
"  %4309 = lshr i32 %4308, 16" -> "  %4345 = add i32 %4309, %4310"
"  %4310 = mul nuw i32 %4165, 58377"
"  %4310 = mul nuw i32 %4165, 58377" -> "  %4345 = add i32 %4309, %4310"
"  %4311 = mul nuw nsw i32 %4153, 13953"
"  %4311 = mul nuw nsw i32 %4153, 13953" -> "  %4346 = add i32 %4345, %4311"
"  %4312 = and i32 %4307, 65535"
"  %4312 = and i32 %4307, 65535" -> "  %4314 = add nuw nsw i32 %4312, %4313"
"  %4313 = and i32 %4308, 65535"
"  %4313 = and i32 %4308, 65535" -> "  %4314 = add nuw nsw i32 %4312, %4313"
"  %4314 = add nuw nsw i32 %4312, %4313"
"  %4314 = add nuw nsw i32 %4312, %4313" -> "  %4321 = and i32 %4314, 65535""  %4314 = add nuw nsw i32 %4312, %4313" -> "  %4320 = lshr i32 %4314, 16"
"  %4315 = mul nuw i32 %4148, 43563"
"  %4315 = mul nuw i32 %4148, 43563" -> "  %4347 = add i32 %4346, %4315"
"  %4316 = mul nuw nsw i32 %4148, 1146"
"  %4316 = mul nuw nsw i32 %4148, 1146" -> "  %4322 = and i32 %4316, 65534""  %4316 = mul nuw nsw i32 %4148, 1146" -> "  %4317 = lshr i32 %4316, 16"
"  %4317 = lshr i32 %4316, 16"
"  %4317 = lshr i32 %4316, 16" -> "  %4348 = add i32 %4347, %4317"
"  %4318 = mul nuw nsw i32 %4144, 1146"
"  %4318 = mul nuw nsw i32 %4144, 1146" -> "  %4349 = add i32 %4348, %4318"
"  %4319 = lshr i32 %4307, 16"
"  %4319 = lshr i32 %4307, 16" -> "  %4350 = add i32 %4349, %4319"
"  %4320 = lshr i32 %4314, 16"
"  %4320 = lshr i32 %4314, 16" -> "  %4351 = add i32 %4350, %4320"
"  %4321 = and i32 %4314, 65535"
"  %4321 = and i32 %4314, 65535" -> "  %4323 = add nuw nsw i32 %4321, %4322"
"  %4322 = and i32 %4316, 65534"
"  %4322 = and i32 %4316, 65534" -> "  %4323 = add nuw nsw i32 %4321, %4322"
"  %4323 = add nuw nsw i32 %4321, %4322"
"  %4323 = add nuw nsw i32 %4321, %4322" -> "  %4335 = and i32 %4323, 65535""  %4323 = add nuw nsw i32 %4321, %4322" -> "  %4324 = lshr i32 %4323, 16"
"  %4324 = lshr i32 %4323, 16"
"  %4324 = lshr i32 %4323, 16" -> "  %4352 = add i32 %4351, %4324"
"  %4325 = lshr i32 %4289, 16"
"  %4325 = lshr i32 %4289, 16" -> "  %4353 = add i32 %4352, %4325"
"  %4326 = and i32 %4276, 65535"
"  %4326 = and i32 %4276, 65535" -> "  %4328 = add nuw nsw i32 %4326, %4327"
"  %4327 = and i32 %4290, 65534"
"  %4327 = and i32 %4290, 65534" -> "  %4328 = add nuw nsw i32 %4326, %4327"
"  %4328 = add nuw nsw i32 %4326, %4327"
"  %4328 = add nuw nsw i32 %4326, %4327" -> "  %4404 = and i32 %4328, 65535""  %4328 = add nuw nsw i32 %4326, %4327" -> "  %4332 = lshr i32 %4328, 16"
"  %4329 = and i32 %4282, 65535"
"  %4329 = and i32 %4282, 65535" -> "  %4331 = add nuw nsw i32 %4329, %4330"
"  %4330 = and i32 %4299, 65535"
"  %4330 = and i32 %4299, 65535" -> "  %4331 = add nuw nsw i32 %4329, %4330"
"  %4331 = add nuw nsw i32 %4329, %4330"
"  %4331 = add nuw nsw i32 %4329, %4330" -> "  %4340 = lshr i32 %4331, 16""  %4331 = add nuw nsw i32 %4329, %4330" -> "  %4333 = and i32 %4331, 65535"
"  %4332 = lshr i32 %4328, 16"
"  %4332 = lshr i32 %4328, 16" -> "  %4334 = add nuw nsw i32 %4333, %4332"
"  %4333 = and i32 %4331, 65535"
"  %4333 = and i32 %4331, 65535" -> "  %4334 = add nuw nsw i32 %4333, %4332"
"  %4334 = add nuw nsw i32 %4333, %4332"
"  %4334 = add nuw nsw i32 %4333, %4332" -> "  %4407 = and i32 %4334, 65535""  %4334 = add nuw nsw i32 %4333, %4332" -> "  %4341 = lshr i32 %4334, 16"
"  %4335 = and i32 %4323, 65535"
"  %4335 = and i32 %4323, 65535" -> "  %4337 = add nuw nsw i32 %4336, %4335"
"  %4336 = and i32 %4289, 65535"
"  %4336 = and i32 %4289, 65535" -> "  %4337 = add nuw nsw i32 %4336, %4335"
"  %4337 = add nuw nsw i32 %4336, %4335"
"  %4337 = add nuw nsw i32 %4336, %4335" -> "  %4339 = and i32 %4337, 65535""  %4337 = add nuw nsw i32 %4336, %4335" -> "  %4338 = lshr i32 %4337, 16"
"  %4338 = lshr i32 %4337, 16"
"  %4338 = lshr i32 %4337, 16" -> "  %4354 = add i32 %4353, %4338"
"  %4339 = and i32 %4337, 65535"
"  %4339 = and i32 %4337, 65535" -> "  %4343 = add nuw nsw i32 %4342, %4339"
"  %4340 = lshr i32 %4331, 16"
"  %4340 = lshr i32 %4331, 16" -> "  %4342 = add nuw nsw i32 %4341, %4340"
"  %4341 = lshr i32 %4334, 16"
"  %4341 = lshr i32 %4334, 16" -> "  %4342 = add nuw nsw i32 %4341, %4340"
"  %4342 = add nuw nsw i32 %4341, %4340"
"  %4342 = add nuw nsw i32 %4341, %4340" -> "  %4343 = add nuw nsw i32 %4342, %4339"
"  %4343 = add nuw nsw i32 %4342, %4339"
"  %4343 = add nuw nsw i32 %4342, %4339" -> "  %4415 = and i32 %4343, 65535""  %4343 = add nuw nsw i32 %4342, %4339" -> "  %4344 = lshr i32 %4343, 16"
"  %4344 = lshr i32 %4343, 16"
"  %4344 = lshr i32 %4343, 16" -> "  %4355 = add i32 %4354, %4344"
"  %4345 = add i32 %4309, %4310"
"  %4345 = add i32 %4309, %4310" -> "  %4346 = add i32 %4345, %4311"
"  %4346 = add i32 %4345, %4311"
"  %4346 = add i32 %4345, %4311" -> "  %4347 = add i32 %4346, %4315"
"  %4347 = add i32 %4346, %4315"
"  %4347 = add i32 %4346, %4315" -> "  %4348 = add i32 %4347, %4317"
"  %4348 = add i32 %4347, %4317"
"  %4348 = add i32 %4347, %4317" -> "  %4349 = add i32 %4348, %4318"
"  %4349 = add i32 %4348, %4318"
"  %4349 = add i32 %4348, %4318" -> "  %4350 = add i32 %4349, %4319"
"  %4350 = add i32 %4349, %4319"
"  %4350 = add i32 %4349, %4319" -> "  %4351 = add i32 %4350, %4320"
"  %4351 = add i32 %4350, %4320"
"  %4351 = add i32 %4350, %4320" -> "  %4352 = add i32 %4351, %4324"
"  %4352 = add i32 %4351, %4324"
"  %4352 = add i32 %4351, %4324" -> "  %4353 = add i32 %4352, %4325"
"  %4353 = add i32 %4352, %4325"
"  %4353 = add i32 %4352, %4325" -> "  %4354 = add i32 %4353, %4338"
"  %4354 = add i32 %4353, %4338"
"  %4354 = add i32 %4353, %4338" -> "  %4355 = add i32 %4354, %4344"
"  %4355 = add i32 %4354, %4344"
"  %4355 = add i32 %4354, %4344" -> "  %4418 = and i32 %4355, 65535"
"  %4356 = mul nuw nsw i32 %4161, 17399"
"  %4356 = mul nuw nsw i32 %4161, 17399" -> "  %4403 = and i32 %4356, 65535""  %4356 = mul nuw nsw i32 %4161, 17399" -> "  %4357 = lshr i32 %4356, 16"
"  %4357 = lshr i32 %4356, 16"
"  %4357 = lshr i32 %4356, 16" -> "  %4359 = add i32 %4357, %4358"
"  %4358 = mul nuw i32 %4161, 34017"
"  %4358 = mul nuw i32 %4161, 34017" -> "  %4359 = add i32 %4357, %4358"
"  %4359 = add i32 %4357, %4358"
"  %4359 = add i32 %4357, %4358" -> "  %4368 = lshr i32 %4359, 16""  %4359 = add i32 %4357, %4358" -> "  %4366 = and i32 %4359, 65535"
"  %4360 = lshr i32 %4134, 15"
"  %4360 = lshr i32 %4134, 15" -> "  %4361 = and i32 %4360, 1"
"  %4361 = and i32 %4360, 1"
"  %4361 = and i32 %4360, 1" -> "  %4364 = or i32 %4363, %4361"
"  %4362 = shl nuw nsw i32 %4137, 1"
"  %4362 = shl nuw nsw i32 %4137, 1" -> "  %4363 = and i32 %4362, 65534"
"  %4363 = and i32 %4362, 65534"
"  %4363 = and i32 %4362, 65534" -> "  %4364 = or i32 %4363, %4361"
"  %4364 = or i32 %4363, %4361"
"  %4364 = or i32 %4363, %4361" -> "  %4380 = mul nuw nsw i32 %4364, 7935""  %4364 = or i32 %4363, %4361" -> "  %4369 = mul nuw i32 %4364, 34017""  %4364 = or i32 %4363, %4361" -> "  %4365 = mul nuw nsw i32 %4364, 17399"
"  %4365 = mul nuw nsw i32 %4364, 17399"
"  %4365 = mul nuw nsw i32 %4364, 17399" -> "  %4367 = add nuw nsw i32 %4366, %4365"
"  %4366 = and i32 %4359, 65535"
"  %4366 = and i32 %4359, 65535" -> "  %4367 = add nuw nsw i32 %4366, %4365"
"  %4367 = add nuw nsw i32 %4366, %4365"
"  %4367 = add nuw nsw i32 %4366, %4365" -> "  %4406 = and i32 %4367, 65535""  %4367 = add nuw nsw i32 %4366, %4365" -> "  %4371 = lshr i32 %4367, 16"
"  %4368 = lshr i32 %4359, 16"
"  %4368 = lshr i32 %4359, 16" -> "  %4370 = add nuw i32 %4368, %4369"
"  %4369 = mul nuw i32 %4364, 34017"
"  %4369 = mul nuw i32 %4364, 34017" -> "  %4370 = add nuw i32 %4368, %4369"
"  %4370 = add nuw i32 %4368, %4369"
"  %4370 = add nuw i32 %4368, %4369" -> "  %4374 = and i32 %4370, -65536""  %4370 = add nuw i32 %4368, %4369" -> "  %4372 = and i32 %4370, 65535"
"  %4371 = lshr i32 %4367, 16"
"  %4371 = lshr i32 %4367, 16" -> "  %4373 = add nuw nsw i32 %4371, %4372"
"  %4372 = and i32 %4370, 65535"
"  %4372 = and i32 %4370, 65535" -> "  %4373 = add nuw nsw i32 %4371, %4372"
"  %4373 = add nuw nsw i32 %4371, %4372"
"  %4373 = add nuw nsw i32 %4371, %4372" -> "  %4375 = add nuw i32 %4373, %4374"
"  %4374 = and i32 %4370, -65536"
"  %4374 = and i32 %4370, -65536" -> "  %4375 = add nuw i32 %4373, %4374"
"  %4375 = add nuw i32 %4373, %4374"
"  %4375 = add nuw i32 %4373, %4374" -> "  %4394 = lshr i32 %4375, 16""  %4375 = add nuw i32 %4373, %4374" -> "  %4382 = and i32 %4375, 65535"
"  %4376 = mul nuw nsw i32 %4161, 7935"
"  %4376 = mul nuw nsw i32 %4161, 7935" -> "  %4383 = and i32 %4376, 65535""  %4376 = mul nuw nsw i32 %4161, 7935" -> "  %4377 = lshr i32 %4376, 16"
"  %4377 = lshr i32 %4376, 16"
"  %4377 = lshr i32 %4376, 16" -> "  %4379 = add i32 %4377, %4378"
"  %4378 = mul nuw i32 %4161, 63663"
"  %4378 = mul nuw i32 %4161, 63663" -> "  %4379 = add i32 %4377, %4378"
"  %4379 = add i32 %4377, %4378"
"  %4379 = add i32 %4377, %4378" -> "  %4381 = add i32 %4379, %4380"
"  %4380 = mul nuw nsw i32 %4364, 7935"
"  %4380 = mul nuw nsw i32 %4364, 7935" -> "  %4381 = add i32 %4379, %4380"
"  %4381 = add i32 %4379, %4380"
"  %4381 = add i32 %4379, %4380" -> "  %4388 = add i32 %4381, %4387"
"  %4382 = and i32 %4375, 65535"
"  %4382 = and i32 %4375, 65535" -> "  %4384 = add nuw nsw i32 %4382, %4383"
"  %4383 = and i32 %4376, 65535"
"  %4383 = and i32 %4376, 65535" -> "  %4384 = add nuw nsw i32 %4382, %4383"
"  %4384 = add nuw nsw i32 %4382, %4383"
"  %4384 = add nuw nsw i32 %4382, %4383" -> "  %4398 = and i32 %4384, 65535""  %4384 = add nuw nsw i32 %4382, %4383" -> "  %4396 = lshr i32 %4384, 16"
"  %4385 = lshr i32 %4140, 15"
"  %4385 = lshr i32 %4140, 15" -> "  %4386 = and i32 %4385, 65535"
"  %4386 = and i32 %4385, 65535"
"  %4386 = and i32 %4385, 65535" -> "  %4387 = mul nuw nsw i32 %4386, 17399"
"  %4387 = mul nuw nsw i32 %4386, 17399"
"  %4387 = mul nuw nsw i32 %4386, 17399" -> "  %4388 = add i32 %4381, %4387"
"  %4388 = add i32 %4381, %4387"
"  %4388 = add i32 %4381, %4387" -> "  %4390 = add i32 %4388, %4389"
"  %4389 = mul nuw i32 %4157, 34017"
"  %4389 = mul nuw i32 %4157, 34017" -> "  %4390 = add i32 %4388, %4389"
"  %4390 = add i32 %4388, %4389"
"  %4390 = add i32 %4388, %4389" -> "  %4393 = add i32 %4390, %4392"
"  %4391 = mul nuw nsw i32 %4157, 17399"
"  %4391 = mul nuw nsw i32 %4157, 17399" -> "  %4399 = and i32 %4391, 65535""  %4391 = mul nuw nsw i32 %4157, 17399" -> "  %4392 = lshr i32 %4391, 16"
"  %4392 = lshr i32 %4391, 16"
"  %4392 = lshr i32 %4391, 16" -> "  %4393 = add i32 %4390, %4392"
"  %4393 = add i32 %4390, %4392"
"  %4393 = add i32 %4390, %4392" -> "  %4395 = add i32 %4393, %4394"
"  %4394 = lshr i32 %4375, 16"
"  %4394 = lshr i32 %4375, 16" -> "  %4395 = add i32 %4393, %4394"
"  %4395 = add i32 %4393, %4394"
"  %4395 = add i32 %4393, %4394" -> "  %4397 = add i32 %4395, %4396"
"  %4396 = lshr i32 %4384, 16"
"  %4396 = lshr i32 %4384, 16" -> "  %4397 = add i32 %4395, %4396"
"  %4397 = add i32 %4395, %4396"
"  %4397 = add i32 %4395, %4396" -> "  %4402 = add i32 %4397, %4401"
"  %4398 = and i32 %4384, 65535"
"  %4398 = and i32 %4384, 65535" -> "  %4400 = add nuw nsw i32 %4398, %4399"
"  %4399 = and i32 %4391, 65535"
"  %4399 = and i32 %4391, 65535" -> "  %4400 = add nuw nsw i32 %4398, %4399"
"  %4400 = add nuw nsw i32 %4398, %4399"
"  %4400 = add nuw nsw i32 %4398, %4399" -> "  %4414 = and i32 %4400, 65535""  %4400 = add nuw nsw i32 %4398, %4399" -> "  %4401 = lshr i32 %4400, 16"
"  %4401 = lshr i32 %4400, 16"
"  %4401 = lshr i32 %4400, 16" -> "  %4402 = add i32 %4397, %4401"
"  %4402 = add i32 %4397, %4401"
"  %4402 = add i32 %4397, %4401" -> "  %4417 = and i32 %4402, 65535"
"  %4403 = and i32 %4356, 65535"
"  %4403 = and i32 %4356, 65535" -> "  %4405 = add nuw nsw i32 %4404, %4403"
"  %4404 = and i32 %4328, 65535"
"  %4404 = and i32 %4328, 65535" -> "  %4405 = add nuw nsw i32 %4404, %4403"
"  %4405 = add nuw nsw i32 %4404, %4403"
"  %4405 = add nuw nsw i32 %4404, %4403" -> "  %4442 = and i32 %4405, 65535""  %4405 = add nuw nsw i32 %4404, %4403" -> "  %4409 = lshr i32 %4405, 16"
"  %4406 = and i32 %4367, 65535"
"  %4406 = and i32 %4367, 65535" -> "  %4408 = add nuw nsw i32 %4407, %4406"
"  %4407 = and i32 %4334, 65535"
"  %4407 = and i32 %4334, 65535" -> "  %4408 = add nuw nsw i32 %4407, %4406"
"  %4408 = add nuw nsw i32 %4407, %4406"
"  %4408 = add nuw nsw i32 %4407, %4406" -> "  %4412 = lshr i32 %4408, 16""  %4408 = add nuw nsw i32 %4407, %4406" -> "  %4410 = and i32 %4408, 65535"
"  %4409 = lshr i32 %4405, 16"
"  %4409 = lshr i32 %4405, 16" -> "  %4411 = add nuw nsw i32 %4410, %4409"
"  %4410 = and i32 %4408, 65535"
"  %4410 = and i32 %4408, 65535" -> "  %4411 = add nuw nsw i32 %4410, %4409"
"  %4411 = add nuw nsw i32 %4410, %4409"
"  %4411 = add nuw nsw i32 %4410, %4409" -> "  %4445 = and i32 %4411, 65535""  %4411 = add nuw nsw i32 %4410, %4409" -> "  %4413 = lshr i32 %4411, 16"
"  %4412 = lshr i32 %4408, 16"
"  %4412 = lshr i32 %4408, 16" -> "  %4423 = add nuw nsw i32 %4413, %4412"
"  %4413 = lshr i32 %4411, 16"
"  %4413 = lshr i32 %4411, 16" -> "  %4423 = add nuw nsw i32 %4413, %4412"
"  %4414 = and i32 %4400, 65535"
"  %4414 = and i32 %4400, 65535" -> "  %4416 = add nuw nsw i32 %4415, %4414"
"  %4415 = and i32 %4343, 65535"
"  %4415 = and i32 %4343, 65535" -> "  %4416 = add nuw nsw i32 %4415, %4414"
"  %4416 = add nuw nsw i32 %4415, %4414"
"  %4416 = add nuw nsw i32 %4415, %4414" -> "  %4422 = and i32 %4416, 65535""  %4416 = add nuw nsw i32 %4415, %4414" -> "  %4420 = lshr i32 %4416, 16"
"  %4417 = and i32 %4402, 65535"
"  %4417 = and i32 %4402, 65535" -> "  %4419 = add nuw nsw i32 %4418, %4417"
"  %4418 = and i32 %4355, 65535"
"  %4418 = and i32 %4355, 65535" -> "  %4419 = add nuw nsw i32 %4418, %4417"
"  %4419 = add nuw nsw i32 %4418, %4417"
"  %4419 = add nuw nsw i32 %4418, %4417" -> "  %4421 = add nuw nsw i32 %4419, %4420"
"  %4420 = lshr i32 %4416, 16"
"  %4420 = lshr i32 %4416, 16" -> "  %4421 = add nuw nsw i32 %4419, %4420"
"  %4421 = add nuw nsw i32 %4419, %4420"
"  %4421 = add nuw nsw i32 %4419, %4420" -> "  %4426 = add nuw nsw i32 %4421, %4425"
"  %4422 = and i32 %4416, 65535"
"  %4422 = and i32 %4416, 65535" -> "  %4424 = add nuw nsw i32 %4423, %4422"
"  %4423 = add nuw nsw i32 %4413, %4412"
"  %4423 = add nuw nsw i32 %4413, %4412" -> "  %4424 = add nuw nsw i32 %4423, %4422"
"  %4424 = add nuw nsw i32 %4423, %4422"
"  %4424 = add nuw nsw i32 %4423, %4422" -> "  %4449 = and i32 %4424, 65535""  %4424 = add nuw nsw i32 %4423, %4422" -> "  %4425 = lshr i32 %4424, 16"
"  %4425 = lshr i32 %4424, 16"
"  %4425 = lshr i32 %4424, 16" -> "  %4426 = add nuw nsw i32 %4421, %4425"
"  %4426 = add nuw nsw i32 %4421, %4425"
"  %4426 = add nuw nsw i32 %4421, %4425" -> "  %4489 = xor i32 %4426, 65535"
"  %4427 = and i32 %4166, 65535"
"  %4427 = and i32 %4166, 65535" -> "  %4428 = sub nuw nsw i32 65536, %4427"
"  %4428 = sub nuw nsw i32 65536, %4427"
"  %4428 = sub nuw nsw i32 65536, %4427" -> "  %4453 = and i32 %4428, 65535""  %4428 = sub nuw nsw i32 65536, %4427" -> "  %4431 = lshr i32 %4428, 16"
"  %4429 = and i32 %4175, 65535"
"  %4429 = and i32 %4175, 65535" -> "  %4430 = xor i32 %4429, 65535"
"  %4430 = xor i32 %4429, 65535"
"  %4430 = xor i32 %4429, 65535" -> "  %4432 = add nuw nsw i32 %4430, %4431"
"  %4431 = lshr i32 %4428, 16"
"  %4431 = lshr i32 %4428, 16" -> "  %4432 = add nuw nsw i32 %4430, %4431"
"  %4432 = add nuw nsw i32 %4430, %4431"
"  %4432 = add nuw nsw i32 %4430, %4431" -> "  %4455 = and i32 %4432, 65535""  %4432 = add nuw nsw i32 %4430, %4431" -> "  %4435 = lshr i32 %4432, 16"
"  %4433 = and i32 %4232, 65535"
"  %4433 = and i32 %4232, 65535" -> "  %4434 = xor i32 %4433, 65535"
"  %4434 = xor i32 %4433, 65535"
"  %4434 = xor i32 %4433, 65535" -> "  %4436 = add nuw nsw i32 %4434, %4435"
"  %4435 = lshr i32 %4432, 16"
"  %4435 = lshr i32 %4432, 16" -> "  %4436 = add nuw nsw i32 %4434, %4435"
"  %4436 = add nuw nsw i32 %4434, %4435"
"  %4436 = add nuw nsw i32 %4434, %4435" -> "  %4462 = and i32 %4436, 65535""  %4436 = add nuw nsw i32 %4434, %4435" -> "  %4439 = lshr i32 %4436, 16"
"  %4437 = and i32 %4240, 65535"
"  %4437 = and i32 %4240, 65535" -> "  %4438 = xor i32 %4437, 65535"
"  %4438 = xor i32 %4437, 65535"
"  %4438 = xor i32 %4437, 65535" -> "  %4440 = add nuw nsw i32 %4438, %4439"
"  %4439 = lshr i32 %4436, 16"
"  %4439 = lshr i32 %4436, 16" -> "  %4440 = add nuw nsw i32 %4438, %4439"
"  %4440 = add nuw nsw i32 %4438, %4439"
"  %4440 = add nuw nsw i32 %4438, %4439" -> "  %4464 = and i32 %4440, 65535""  %4440 = add nuw nsw i32 %4438, %4439" -> "  %4441 = lshr i32 %4440, 16"
"  %4441 = lshr i32 %4440, 16"
"  %4441 = lshr i32 %4440, 16" -> "  %4444 = add nuw nsw i32 %4443, %4441"
"  %4442 = and i32 %4405, 65535"
"  %4442 = and i32 %4405, 65535" -> "  %4443 = xor i32 %4442, 65535"
"  %4443 = xor i32 %4442, 65535"
"  %4443 = xor i32 %4442, 65535" -> "  %4444 = add nuw nsw i32 %4443, %4441"
"  %4444 = add nuw nsw i32 %4443, %4441"
"  %4444 = add nuw nsw i32 %4443, %4441" -> "  %4478 = and i32 %4444, 65535""  %4444 = add nuw nsw i32 %4443, %4441" -> "  %4447 = lshr i32 %4444, 16"
"  %4445 = and i32 %4411, 65535"
"  %4445 = and i32 %4411, 65535" -> "  %4446 = xor i32 %4445, 65535"
"  %4446 = xor i32 %4445, 65535"
"  %4446 = xor i32 %4445, 65535" -> "  %4448 = add nuw nsw i32 %4446, %4447"
"  %4447 = lshr i32 %4444, 16"
"  %4447 = lshr i32 %4444, 16" -> "  %4448 = add nuw nsw i32 %4446, %4447"
"  %4448 = add nuw nsw i32 %4446, %4447"
"  %4448 = add nuw nsw i32 %4446, %4447" -> "  %4480 = and i32 %4448, 65535""  %4448 = add nuw nsw i32 %4446, %4447" -> "  %4451 = lshr i32 %4448, 16"
"  %4449 = and i32 %4424, 65535"
"  %4449 = and i32 %4424, 65535" -> "  %4450 = xor i32 %4449, 65535"
"  %4450 = xor i32 %4449, 65535"
"  %4450 = xor i32 %4449, 65535" -> "  %4452 = add nuw nsw i32 %4450, %4451"
"  %4451 = lshr i32 %4448, 16"
"  %4451 = lshr i32 %4448, 16" -> "  %4452 = add nuw nsw i32 %4450, %4451"
"  %4452 = add nuw nsw i32 %4450, %4451"
"  %4452 = add nuw nsw i32 %4450, %4451" -> "  %4505 = add i32 %4504, %4452""  %4452 = add nuw nsw i32 %4450, %4451" -> "  %4487 = and i32 %4452, 65535"
"  %4453 = and i32 %4428, 65535"
"  %4453 = and i32 %4428, 65535" -> "  %4454 = add nuw nsw i32 %4453, %1044"
"  %4454 = add nuw nsw i32 %4453, %1044"
"  %4454 = add nuw nsw i32 %4453, %1044" -> "  %4512 = and i32 %4454, 65535""  %4454 = add nuw nsw i32 %4453, %1044" -> "  %4457 = lshr i32 %4454, 16"
"  %4455 = and i32 %4432, 65535"
"  %4455 = and i32 %4432, 65535" -> "  %4456 = add nuw nsw i32 %4455, %1047"
"  %4456 = add nuw nsw i32 %4455, %1047"
"  %4456 = add nuw nsw i32 %4455, %1047" -> "  %4460 = lshr i32 %4456, 16""  %4456 = add nuw nsw i32 %4455, %1047" -> "  %4458 = and i32 %4456, 65535"
"  %4457 = lshr i32 %4454, 16"
"  %4457 = lshr i32 %4454, 16" -> "  %4459 = add nuw nsw i32 %4458, %4457"
"  %4458 = and i32 %4456, 65535"
"  %4458 = and i32 %4456, 65535" -> "  %4459 = add nuw nsw i32 %4458, %4457"
"  %4459 = add nuw nsw i32 %4458, %4457"
"  %4459 = add nuw nsw i32 %4458, %4457" -> "  %4513 = and i32 %4459, 65535""  %4459 = add nuw nsw i32 %4458, %4457" -> "  %4461 = lshr i32 %4459, 16"
"  %4460 = lshr i32 %4456, 16"
"  %4460 = lshr i32 %4456, 16" -> "  %4472 = add nuw nsw i32 %4461, %4460"
"  %4461 = lshr i32 %4459, 16"
"  %4461 = lshr i32 %4459, 16" -> "  %4472 = add nuw nsw i32 %4461, %4460"
"  %4462 = and i32 %4436, 65535"
"  %4462 = and i32 %4436, 65535" -> "  %4463 = add nuw nsw i32 %4462, %1064"
"  %4463 = add nuw nsw i32 %4462, %1064"
"  %4463 = add nuw nsw i32 %4462, %1064" -> "  %4471 = and i32 %4463, 65535""  %4463 = add nuw nsw i32 %4462, %1064" -> "  %4466 = lshr i32 %4463, 16"
"  %4464 = and i32 %4440, 65535"
"  %4464 = and i32 %4440, 65535" -> "  %4465 = add nuw nsw i32 %4464, %1065"
"  %4465 = add nuw nsw i32 %4464, %1065"
"  %4465 = add nuw nsw i32 %4464, %1065" -> "  %4469 = lshr i32 %4465, 16""  %4465 = add nuw nsw i32 %4464, %1065" -> "  %4467 = and i32 %4465, 65535"
"  %4466 = lshr i32 %4463, 16"
"  %4466 = lshr i32 %4463, 16" -> "  %4468 = add nuw nsw i32 %4467, %4466"
"  %4467 = and i32 %4465, 65535"
"  %4467 = and i32 %4465, 65535" -> "  %4468 = add nuw nsw i32 %4467, %4466"
"  %4468 = add nuw nsw i32 %4467, %4466"
"  %4468 = add nuw nsw i32 %4467, %4466" -> "  %4474 = and i32 %4468, 65535""  %4468 = add nuw nsw i32 %4467, %4466" -> "  %4470 = lshr i32 %4468, 16"
"  %4469 = lshr i32 %4465, 16"
"  %4469 = lshr i32 %4465, 16" -> "  %4495 = add nuw nsw i32 %4470, %4469"
"  %4470 = lshr i32 %4468, 16"
"  %4470 = lshr i32 %4468, 16" -> "  %4495 = add nuw nsw i32 %4470, %4469"
"  %4471 = and i32 %4463, 65535"
"  %4471 = and i32 %4463, 65535" -> "  %4473 = add nuw nsw i32 %4472, %4471"
"  %4472 = add nuw nsw i32 %4461, %4460"
"  %4472 = add nuw nsw i32 %4461, %4460" -> "  %4473 = add nuw nsw i32 %4472, %4471"
"  %4473 = add nuw nsw i32 %4472, %4471"
"  %4473 = add nuw nsw i32 %4472, %4471" -> "  %4531 = and i32 %4473, 65535""  %4473 = add nuw nsw i32 %4472, %4471" -> "  %4475 = lshr i32 %4473, 16"
"  %4474 = and i32 %4468, 65535"
"  %4474 = and i32 %4468, 65535" -> "  %4476 = add nuw nsw i32 %4474, %4475"
"  %4475 = lshr i32 %4473, 16"
"  %4475 = lshr i32 %4473, 16" -> "  %4476 = add nuw nsw i32 %4474, %4475"
"  %4476 = add nuw nsw i32 %4474, %4475"
"  %4476 = add nuw nsw i32 %4474, %4475" -> "  %4532 = and i32 %4476, 65535""  %4476 = add nuw nsw i32 %4474, %4475" -> "  %4477 = lshr i32 %4476, 16"
"  %4477 = lshr i32 %4476, 16"
"  %4477 = lshr i32 %4476, 16" -> "  %4496 = add nuw nsw i32 %4495, %4477"
"  %4478 = and i32 %4444, 65535"
"  %4478 = and i32 %4444, 65535" -> "  %4479 = add nuw nsw i32 %4478, %1178"
"  %4479 = add nuw nsw i32 %4478, %1178"
"  %4479 = add nuw nsw i32 %4478, %1178" -> "  %4494 = and i32 %4479, 65535""  %4479 = add nuw nsw i32 %4478, %1178" -> "  %4482 = lshr i32 %4479, 16"
"  %4480 = and i32 %4448, 65535"
"  %4480 = and i32 %4448, 65535" -> "  %4481 = add nuw nsw i32 %4480, %1179"
"  %4481 = add nuw nsw i32 %4480, %1179"
"  %4481 = add nuw nsw i32 %4480, %1179" -> "  %4485 = lshr i32 %4481, 16""  %4481 = add nuw nsw i32 %4480, %1179" -> "  %4483 = and i32 %4481, 65535"
"  %4482 = lshr i32 %4479, 16"
"  %4482 = lshr i32 %4479, 16" -> "  %4484 = add nuw nsw i32 %4483, %4482"
"  %4483 = and i32 %4481, 65535"
"  %4483 = and i32 %4481, 65535" -> "  %4484 = add nuw nsw i32 %4483, %4482"
"  %4484 = add nuw nsw i32 %4483, %4482"
"  %4484 = add nuw nsw i32 %4483, %4482" -> "  %4498 = and i32 %4484, 65535""  %4484 = add nuw nsw i32 %4483, %4482" -> "  %4486 = lshr i32 %4484, 16"
"  %4485 = lshr i32 %4481, 16"
"  %4485 = lshr i32 %4481, 16" -> "  %4492 = add nuw nsw i32 %4486, %4485"
"  %4486 = lshr i32 %4484, 16"
"  %4486 = lshr i32 %4484, 16" -> "  %4492 = add nuw nsw i32 %4486, %4485"
"  %4487 = and i32 %4452, 65535"
"  %4487 = and i32 %4452, 65535" -> "  %4488 = add nuw nsw i32 %4487, %1198"
"  %4488 = add nuw nsw i32 %4487, %1198"
"  %4488 = add nuw nsw i32 %4487, %1198" -> "  %4507 = add i32 %4506, %4488""  %4488 = add nuw nsw i32 %4487, %1198" -> "  %4491 = and i32 %4488, 65535"
"  %4489 = xor i32 %4426, 65535"
"  %4489 = xor i32 %4426, 65535" -> "  %4490 = add nuw nsw i32 %4489, %843"
"  %4490 = add nuw nsw i32 %4489, %843"
"  %4490 = add nuw nsw i32 %4489, %843" -> "  %4504 = shl i32 %4490, 16"
"  %4491 = and i32 %4488, 65535"
"  %4491 = and i32 %4488, 65535" -> "  %4493 = add nuw nsw i32 %4492, %4491"
"  %4492 = add nuw nsw i32 %4486, %4485"
"  %4492 = add nuw nsw i32 %4486, %4485" -> "  %4493 = add nuw nsw i32 %4492, %4491"
"  %4493 = add nuw nsw i32 %4492, %4491"
"  %4493 = add nuw nsw i32 %4492, %4491" -> "  %4509 = add i32 %4508, %4493""  %4493 = add nuw nsw i32 %4492, %4491" -> "  %4502 = and i32 %4493, 65535"
"  %4494 = and i32 %4479, 65535"
"  %4494 = and i32 %4479, 65535" -> "  %4497 = add nuw nsw i32 %4496, %4494"
"  %4495 = add nuw nsw i32 %4470, %4469"
"  %4495 = add nuw nsw i32 %4470, %4469" -> "  %4496 = add nuw nsw i32 %4495, %4477"
"  %4496 = add nuw nsw i32 %4495, %4477"
"  %4496 = add nuw nsw i32 %4495, %4477" -> "  %4497 = add nuw nsw i32 %4496, %4494"
"  %4497 = add nuw nsw i32 %4496, %4494"
"  %4497 = add nuw nsw i32 %4496, %4494" -> "  %4638 = and i32 %4497, 65535""  %4497 = add nuw nsw i32 %4496, %4494" -> "  %4499 = lshr i32 %4497, 16"
"  %4498 = and i32 %4484, 65535"
"  %4498 = and i32 %4484, 65535" -> "  %4500 = add nuw nsw i32 %4498, %4499"
"  %4499 = lshr i32 %4497, 16"
"  %4499 = lshr i32 %4497, 16" -> "  %4500 = add nuw nsw i32 %4498, %4499"
"  %4500 = add nuw nsw i32 %4498, %4499"
"  %4500 = add nuw nsw i32 %4498, %4499" -> "  %4639 = and i32 %4500, 65535""  %4500 = add nuw nsw i32 %4498, %4499" -> "  %4501 = lshr i32 %4500, 16"
"  %4501 = lshr i32 %4500, 16"
"  %4501 = lshr i32 %4500, 16" -> "  %4503 = add nuw nsw i32 %4502, %4501"
"  %4502 = and i32 %4493, 65535"
"  %4502 = and i32 %4493, 65535" -> "  %4503 = add nuw nsw i32 %4502, %4501"
"  %4503 = add nuw nsw i32 %4502, %4501"
"  %4503 = add nuw nsw i32 %4502, %4501" -> "  %4511 = add i32 %4503, %4510"
"  %4504 = shl i32 %4490, 16"
"  %4504 = shl i32 %4490, 16" -> "  %4505 = add i32 %4504, %4452"
"  %4505 = add i32 %4504, %4452"
"  %4505 = add i32 %4504, %4452" -> "  %4506 = and i32 %4505, -65536"
"  %4506 = and i32 %4505, -65536"
"  %4506 = and i32 %4505, -65536" -> "  %4507 = add i32 %4506, %4488"
"  %4507 = add i32 %4506, %4488"
"  %4507 = add i32 %4506, %4488" -> "  %4508 = and i32 %4507, -65536"
"  %4508 = and i32 %4507, -65536"
"  %4508 = and i32 %4507, -65536" -> "  %4509 = add i32 %4508, %4493"
"  %4509 = add i32 %4508, %4493"
"  %4509 = add i32 %4508, %4493" -> "  %4510 = and i32 %4509, -65536"
"  %4510 = and i32 %4509, -65536"
"  %4510 = and i32 %4509, -65536" -> "  %4511 = add i32 %4503, %4510"
"  %4511 = add i32 %4503, %4510"
"  %4511 = add i32 %4503, %4510" -> "  %4661 = and i32 %4511, 65535""  %4511 = add i32 %4503, %4510" -> "  %4664 = lshr i32 %4511, 16"
"  %4512 = and i32 %4454, 65535"
"  %4512 = and i32 %4454, 65535" -> "  %4665 = mul nuw i32 %4664, %4512""  %4512 = and i32 %4454, 65535" -> "  %4662 = mul nuw i32 %4661, %4512""  %4512 = and i32 %4454, 65535" -> "  %4642 = mul nuw i32 %4639, %4512""  %4512 = and i32 %4454, 65535" -> "  %4640 = mul nuw i32 %4638, %4512""  %4512 = and i32 %4454, 65535" -> "  %4535 = mul nuw i32 %4532, %4512""  %4512 = and i32 %4454, 65535" -> "  %4533 = mul nuw i32 %4531, %4512""  %4512 = and i32 %4454, 65535" -> "  %4516 = mul nuw i32 %4513, %4512""  %4512 = and i32 %4454, 65535" -> "  %4514 = mul nuw i32 %4512, %4512""  %4512 = and i32 %4454, 65535" -> "  %4514 = mul nuw i32 %4512, %4512"
"  %4513 = and i32 %4459, 65535"
"  %4513 = and i32 %4459, 65535" -> "  %4678 = mul nuw i32 %4664, %4513""  %4513 = and i32 %4459, 65535" -> "  %4666 = mul nuw i32 %4661, %4513""  %4513 = and i32 %4459, 65535" -> "  %4655 = mul nuw i32 %4639, %4513""  %4513 = and i32 %4459, 65535" -> "  %4645 = mul nuw i32 %4638, %4513""  %4513 = and i32 %4459, 65535" -> "  %4551 = mul nuw i32 %4532, %4513""  %4513 = and i32 %4459, 65535" -> "  %4538 = mul nuw i32 %4531, %4513""  %4513 = and i32 %4459, 65535" -> "  %4516 = mul nuw i32 %4513, %4512""  %4513 = and i32 %4459, 65535" -> "  %4524 = mul nuw i32 %4513, %4513""  %4513 = and i32 %4459, 65535" -> "  %4524 = mul nuw i32 %4513, %4513"
"  %4514 = mul nuw i32 %4512, %4512"
"  %4514 = mul nuw i32 %4512, %4512" -> "  %5131 = and i32 %4514, 65535""  %4514 = mul nuw i32 %4512, %4512" -> "  %4515 = lshr i32 %4514, 16"
"  %4515 = lshr i32 %4514, 16"
"  %4515 = lshr i32 %4514, 16" -> "  %4518 = add nuw nsw i32 %4517, %4515"
"  %4516 = mul nuw i32 %4513, %4512"
"  %4516 = mul nuw i32 %4513, %4512" -> "  %4522 = add nuw i32 %4521, %4516""  %4516 = mul nuw i32 %4513, %4512" -> "  %4519 = and i32 %4516, -65536""  %4516 = mul nuw i32 %4513, %4512" -> "  %4517 = and i32 %4516, 65535"
"  %4517 = and i32 %4516, 65535"
"  %4517 = and i32 %4516, 65535" -> "  %4518 = add nuw nsw i32 %4517, %4515"
"  %4518 = add nuw nsw i32 %4517, %4515"
"  %4518 = add nuw nsw i32 %4517, %4515" -> "  %4520 = add nuw i32 %4518, %4519"
"  %4519 = and i32 %4516, -65536"
"  %4519 = and i32 %4516, -65536" -> "  %4520 = add nuw i32 %4518, %4519"
"  %4520 = add nuw i32 %4518, %4519"
"  %4520 = add nuw i32 %4518, %4519" -> "  %4523 = lshr i32 %4520, 16""  %4520 = add nuw i32 %4518, %4519" -> "  %4521 = and i32 %4520, 65535"
"  %4521 = and i32 %4520, 65535"
"  %4521 = and i32 %4520, 65535" -> "  %4522 = add nuw i32 %4521, %4516"
"  %4522 = add nuw i32 %4521, %4516"
"  %4522 = add nuw i32 %4521, %4516" -> "  %5134 = and i32 %4522, 65535""  %4522 = add nuw i32 %4521, %4516" -> "  %4526 = lshr i32 %4522, 16"
"  %4523 = lshr i32 %4520, 16"
"  %4523 = lshr i32 %4520, 16" -> "  %4525 = add nuw i32 %4523, %4524"
"  %4524 = mul nuw i32 %4513, %4513"
"  %4524 = mul nuw i32 %4513, %4513" -> "  %4525 = add nuw i32 %4523, %4524"
"  %4525 = add nuw i32 %4523, %4524"
"  %4525 = add nuw i32 %4523, %4524" -> "  %4529 = and i32 %4525, -65536""  %4525 = add nuw i32 %4523, %4524" -> "  %4527 = and i32 %4525, 65535"
"  %4526 = lshr i32 %4522, 16"
"  %4526 = lshr i32 %4522, 16" -> "  %4528 = add nuw nsw i32 %4526, %4527"
"  %4527 = and i32 %4525, 65535"
"  %4527 = and i32 %4525, 65535" -> "  %4528 = add nuw nsw i32 %4526, %4527"
"  %4528 = add nuw nsw i32 %4526, %4527"
"  %4528 = add nuw nsw i32 %4526, %4527" -> "  %4530 = add i32 %4528, %4529"
"  %4529 = and i32 %4525, -65536"
"  %4529 = and i32 %4525, -65536" -> "  %4530 = add i32 %4528, %4529"
"  %4530 = add i32 %4528, %4529"
"  %4530 = add i32 %4528, %4529" -> "  %4560 = and i32 %4530, 65535""  %4530 = add i32 %4528, %4529" -> "  %4558 = lshr i32 %4530, 16"
"  %4531 = and i32 %4473, 65535"
"  %4531 = and i32 %4473, 65535" -> "  %4739 = mul nuw i32 %4664, %4531""  %4531 = and i32 %4473, 65535" -> "  %4737 = mul nuw i32 %4661, %4531""  %4531 = and i32 %4473, 65535" -> "  %4702 = mul nuw i32 %4639, %4531""  %4531 = and i32 %4473, 65535" -> "  %4700 = mul nuw i32 %4638, %4531""  %4531 = and i32 %4473, 65535" -> "  %4594 = mul nuw i32 %4532, %4531""  %4531 = and i32 %4473, 65535" -> "  %4538 = mul nuw i32 %4531, %4513""  %4531 = and i32 %4473, 65535" -> "  %4533 = mul nuw i32 %4531, %4512""  %4531 = and i32 %4473, 65535" -> "  %4592 = mul nuw i32 %4531, %4531""  %4531 = and i32 %4473, 65535" -> "  %4592 = mul nuw i32 %4531, %4531"
"  %4532 = and i32 %4476, 65535"
"  %4532 = and i32 %4476, 65535" -> "  %4755 = mul nuw i32 %4664, %4532""  %4532 = and i32 %4476, 65535" -> "  %4742 = mul nuw i32 %4661, %4532""  %4532 = and i32 %4476, 65535" -> "  %4718 = mul nuw i32 %4639, %4532""  %4532 = and i32 %4476, 65535" -> "  %4705 = mul nuw i32 %4638, %4532""  %4532 = and i32 %4476, 65535" -> "  %4594 = mul nuw i32 %4532, %4531""  %4532 = and i32 %4476, 65535" -> "  %4551 = mul nuw i32 %4532, %4513""  %4532 = and i32 %4476, 65535" -> "  %4535 = mul nuw i32 %4532, %4512""  %4532 = and i32 %4476, 65535" -> "  %4602 = mul nuw i32 %4532, %4532""  %4532 = and i32 %4476, 65535" -> "  %4602 = mul nuw i32 %4532, %4532"
"  %4533 = mul nuw i32 %4531, %4512"
"  %4533 = mul nuw i32 %4531, %4512" -> "  %4561 = and i32 %4533, 65535""  %4533 = mul nuw i32 %4531, %4512" -> "  %4534 = lshr i32 %4533, 16"
"  %4534 = lshr i32 %4533, 16"
"  %4534 = lshr i32 %4533, 16" -> "  %4537 = add nuw nsw i32 %4536, %4534""  %4534 = lshr i32 %4533, 16" -> "  %4540 = add nuw nsw i32 %4534, %4539"
"  %4535 = mul nuw i32 %4532, %4512"
"  %4535 = mul nuw i32 %4532, %4512" -> "  %4544 = add nuw i32 %4535, %4543""  %4535 = mul nuw i32 %4532, %4512" -> "  %4545 = and i32 %4535, -65536""  %4535 = mul nuw i32 %4532, %4512" -> "  %4536 = and i32 %4535, 65535"
"  %4536 = and i32 %4535, 65535"
"  %4536 = and i32 %4535, 65535" -> "  %4537 = add nuw nsw i32 %4536, %4534"
"  %4537 = add nuw nsw i32 %4536, %4534"
"  %4537 = add nuw nsw i32 %4536, %4534" -> "  %4546 = add nuw i32 %4537, %4545"
"  %4538 = mul nuw i32 %4531, %4513"
"  %4538 = mul nuw i32 %4531, %4513" -> "  %4548 = add nuw i32 %4547, %4538""  %4538 = mul nuw i32 %4531, %4513" -> "  %4541 = and i32 %4538, -65536""  %4538 = mul nuw i32 %4531, %4513" -> "  %4539 = and i32 %4538, 65535"
"  %4539 = and i32 %4538, 65535"
"  %4539 = and i32 %4538, 65535" -> "  %4540 = add nuw nsw i32 %4534, %4539"
"  %4540 = add nuw nsw i32 %4534, %4539"
"  %4540 = add nuw nsw i32 %4534, %4539" -> "  %4542 = add nuw i32 %4540, %4541"
"  %4541 = and i32 %4538, -65536"
"  %4541 = and i32 %4538, -65536" -> "  %4542 = add nuw i32 %4540, %4541"
"  %4542 = add nuw i32 %4540, %4541"
"  %4542 = add nuw i32 %4540, %4541" -> "  %4573 = lshr i32 %4542, 16""  %4542 = add nuw i32 %4540, %4541" -> "  %4543 = and i32 %4542, 65535"
"  %4543 = and i32 %4542, 65535"
"  %4543 = and i32 %4542, 65535" -> "  %4544 = add nuw i32 %4535, %4543"
"  %4544 = add nuw i32 %4535, %4543"
"  %4544 = add nuw i32 %4535, %4543" -> "  %4583 = and i32 %4544, 65535""  %4544 = add nuw i32 %4535, %4543" -> "  %4575 = lshr i32 %4544, 16"
"  %4545 = and i32 %4535, -65536"
"  %4545 = and i32 %4535, -65536" -> "  %4546 = add nuw i32 %4537, %4545"
"  %4546 = add nuw i32 %4537, %4545"
"  %4546 = add nuw i32 %4537, %4545" -> "  %4549 = lshr i32 %4546, 16""  %4546 = add nuw i32 %4537, %4545" -> "  %4547 = and i32 %4546, 65535"
"  %4547 = and i32 %4546, 65535"
"  %4547 = and i32 %4546, 65535" -> "  %4548 = add nuw i32 %4547, %4538"
"  %4548 = add nuw i32 %4547, %4538"
"  %4548 = add nuw i32 %4547, %4538" -> "  %4557 = and i32 %4548, 65535""  %4548 = add nuw i32 %4547, %4538" -> "  %4550 = lshr i32 %4548, 16"
"  %4549 = lshr i32 %4546, 16"
"  %4549 = lshr i32 %4546, 16" -> "  %4552 = add nuw i32 %4549, %4551"
"  %4550 = lshr i32 %4548, 16"
"  %4550 = lshr i32 %4548, 16" -> "  %4554 = add nuw nsw i32 %4553, %4550"
"  %4551 = mul nuw i32 %4532, %4513"
"  %4551 = mul nuw i32 %4532, %4513" -> "  %4574 = add nuw i32 %4551, %4573""  %4551 = mul nuw i32 %4532, %4513" -> "  %4552 = add nuw i32 %4549, %4551"
"  %4552 = add nuw i32 %4549, %4551"
"  %4552 = add nuw i32 %4549, %4551" -> "  %4555 = and i32 %4552, -65536""  %4552 = add nuw i32 %4549, %4551" -> "  %4553 = and i32 %4552, 65535"
"  %4553 = and i32 %4552, 65535"
"  %4553 = and i32 %4552, 65535" -> "  %4554 = add nuw nsw i32 %4553, %4550"
"  %4554 = add nuw nsw i32 %4553, %4550"
"  %4554 = add nuw nsw i32 %4553, %4550" -> "  %4556 = add i32 %4554, %4555"
"  %4555 = and i32 %4552, -65536"
"  %4555 = and i32 %4552, -65536" -> "  %4556 = add i32 %4554, %4555"
"  %4556 = add i32 %4554, %4555"
"  %4556 = add i32 %4554, %4555" -> "  %4569 = and i32 %4556, -65536""  %4556 = add i32 %4554, %4555" -> "  %4567 = and i32 %4556, 65535"
"  %4557 = and i32 %4548, 65535"
"  %4557 = and i32 %4548, 65535" -> "  %4559 = add nuw nsw i32 %4557, %4558"
"  %4558 = lshr i32 %4530, 16"
"  %4558 = lshr i32 %4530, 16" -> "  %4559 = add nuw nsw i32 %4557, %4558"
"  %4559 = add nuw nsw i32 %4557, %4558"
"  %4559 = add nuw nsw i32 %4557, %4558" -> "  %4566 = lshr i32 %4559, 16""  %4559 = add nuw nsw i32 %4557, %4558" -> "  %4564 = and i32 %4559, 65535"
"  %4560 = and i32 %4530, 65535"
"  %4560 = and i32 %4530, 65535" -> "  %4562 = add nuw nsw i32 %4560, %4561"
"  %4561 = and i32 %4533, 65535"
"  %4561 = and i32 %4533, 65535" -> "  %4581 = add nuw nsw i32 %4580, %4561""  %4561 = and i32 %4533, 65535" -> "  %4562 = add nuw nsw i32 %4560, %4561"
"  %4562 = add nuw nsw i32 %4560, %4561"
"  %4562 = add nuw nsw i32 %4560, %4561" -> "  %4580 = and i32 %4562, 65535""  %4562 = add nuw nsw i32 %4560, %4561" -> "  %4563 = lshr i32 %4562, 16"
"  %4563 = lshr i32 %4562, 16"
"  %4563 = lshr i32 %4562, 16" -> "  %4565 = add nuw nsw i32 %4564, %4563"
"  %4564 = and i32 %4559, 65535"
"  %4564 = and i32 %4559, 65535" -> "  %4565 = add nuw nsw i32 %4564, %4563"
"  %4565 = add nuw nsw i32 %4564, %4563"
"  %4565 = add nuw nsw i32 %4564, %4563" -> "  %4582 = and i32 %4565, 65535""  %4565 = add nuw nsw i32 %4564, %4563" -> "  %4571 = lshr i32 %4565, 16"
"  %4566 = lshr i32 %4559, 16"
"  %4566 = lshr i32 %4559, 16" -> "  %4568 = add nuw nsw i32 %4567, %4566"
"  %4567 = and i32 %4556, 65535"
"  %4567 = and i32 %4556, 65535" -> "  %4568 = add nuw nsw i32 %4567, %4566"
"  %4568 = add nuw nsw i32 %4567, %4566"
"  %4568 = add nuw nsw i32 %4567, %4566" -> "  %4570 = add i32 %4568, %4569"
"  %4569 = and i32 %4556, -65536"
"  %4569 = and i32 %4556, -65536" -> "  %4570 = add i32 %4568, %4569"
"  %4570 = add i32 %4568, %4569"
"  %4570 = add i32 %4568, %4569" -> "  %4572 = add i32 %4570, %4571"
"  %4571 = lshr i32 %4565, 16"
"  %4571 = lshr i32 %4565, 16" -> "  %4572 = add i32 %4570, %4571"
"  %4572 = add i32 %4570, %4571"
"  %4572 = add i32 %4570, %4571" -> "  %4613 = lshr i32 %4572, 16""  %4572 = add i32 %4570, %4571" -> "  %4609 = and i32 %4572, 65535"
"  %4573 = lshr i32 %4542, 16"
"  %4573 = lshr i32 %4542, 16" -> "  %4574 = add nuw i32 %4551, %4573"
"  %4574 = add nuw i32 %4551, %4573"
"  %4574 = add nuw i32 %4551, %4573" -> "  %4578 = and i32 %4574, -65536""  %4574 = add nuw i32 %4551, %4573" -> "  %4576 = and i32 %4574, 65535"
"  %4575 = lshr i32 %4544, 16"
"  %4575 = lshr i32 %4544, 16" -> "  %4577 = add nuw nsw i32 %4576, %4575"
"  %4576 = and i32 %4574, 65535"
"  %4576 = and i32 %4574, 65535" -> "  %4577 = add nuw nsw i32 %4576, %4575"
"  %4577 = add nuw nsw i32 %4576, %4575"
"  %4577 = add nuw nsw i32 %4576, %4575" -> "  %4579 = add i32 %4577, %4578"
"  %4578 = and i32 %4574, -65536"
"  %4578 = and i32 %4574, -65536" -> "  %4579 = add i32 %4577, %4578"
"  %4579 = add i32 %4577, %4578"
"  %4579 = add i32 %4577, %4578" -> "  %4586 = add i32 %4579, %4585"
"  %4580 = and i32 %4562, 65535"
"  %4580 = and i32 %4562, 65535" -> "  %4581 = add nuw nsw i32 %4580, %4561"
"  %4581 = add nuw nsw i32 %4580, %4561"
"  %4581 = add nuw nsw i32 %4580, %4561" -> "  %5151 = and i32 %4581, 65535""  %4581 = add nuw nsw i32 %4580, %4561" -> "  %4588 = lshr i32 %4581, 16"
"  %4582 = and i32 %4565, 65535"
"  %4582 = and i32 %4565, 65535" -> "  %4584 = add nuw nsw i32 %4582, %4583"
"  %4583 = and i32 %4544, 65535"
"  %4583 = and i32 %4544, 65535" -> "  %4584 = add nuw nsw i32 %4582, %4583"
"  %4584 = add nuw nsw i32 %4582, %4583"
"  %4584 = add nuw nsw i32 %4582, %4583" -> "  %4587 = and i32 %4584, 65535""  %4584 = add nuw nsw i32 %4582, %4583" -> "  %4585 = lshr i32 %4584, 16"
"  %4585 = lshr i32 %4584, 16"
"  %4585 = lshr i32 %4584, 16" -> "  %4586 = add i32 %4579, %4585"
"  %4586 = add i32 %4579, %4585"
"  %4586 = add i32 %4579, %4585" -> "  %4591 = add i32 %4586, %4590"
"  %4587 = and i32 %4584, 65535"
"  %4587 = and i32 %4584, 65535" -> "  %4589 = add nuw nsw i32 %4587, %4588"
"  %4588 = lshr i32 %4581, 16"
"  %4588 = lshr i32 %4581, 16" -> "  %4589 = add nuw nsw i32 %4587, %4588"
"  %4589 = add nuw nsw i32 %4587, %4588"
"  %4589 = add nuw nsw i32 %4587, %4588" -> "  %5152 = and i32 %4589, 65535""  %4589 = add nuw nsw i32 %4587, %4588" -> "  %4590 = lshr i32 %4589, 16"
"  %4590 = lshr i32 %4589, 16"
"  %4590 = lshr i32 %4589, 16" -> "  %4591 = add i32 %4586, %4590"
"  %4591 = add i32 %4586, %4590"
"  %4591 = add i32 %4586, %4590" -> "  %4626 = lshr i32 %4591, 16""  %4591 = add i32 %4586, %4590" -> "  %4623 = and i32 %4591, 65535"
"  %4592 = mul nuw i32 %4531, %4531"
"  %4592 = mul nuw i32 %4531, %4531" -> "  %4610 = and i32 %4592, 65535""  %4592 = mul nuw i32 %4531, %4531" -> "  %4593 = lshr i32 %4592, 16"
"  %4593 = lshr i32 %4592, 16"
"  %4593 = lshr i32 %4592, 16" -> "  %4596 = add nuw nsw i32 %4595, %4593"
"  %4594 = mul nuw i32 %4532, %4531"
"  %4594 = mul nuw i32 %4532, %4531" -> "  %4600 = add nuw i32 %4599, %4594""  %4594 = mul nuw i32 %4532, %4531" -> "  %4597 = and i32 %4594, -65536""  %4594 = mul nuw i32 %4532, %4531" -> "  %4595 = and i32 %4594, 65535"
"  %4595 = and i32 %4594, 65535"
"  %4595 = and i32 %4594, 65535" -> "  %4596 = add nuw nsw i32 %4595, %4593"
"  %4596 = add nuw nsw i32 %4595, %4593"
"  %4596 = add nuw nsw i32 %4595, %4593" -> "  %4598 = add nuw i32 %4596, %4597"
"  %4597 = and i32 %4594, -65536"
"  %4597 = and i32 %4594, -65536" -> "  %4598 = add nuw i32 %4596, %4597"
"  %4598 = add nuw i32 %4596, %4597"
"  %4598 = add nuw i32 %4596, %4597" -> "  %4601 = lshr i32 %4598, 16""  %4598 = add nuw i32 %4596, %4597" -> "  %4599 = and i32 %4598, 65535"
"  %4599 = and i32 %4598, 65535"
"  %4599 = and i32 %4598, 65535" -> "  %4600 = add nuw i32 %4599, %4594"
"  %4600 = add nuw i32 %4599, %4594"
"  %4600 = add nuw i32 %4599, %4594" -> "  %4612 = and i32 %4600, 65535""  %4600 = add nuw i32 %4599, %4594" -> "  %4604 = lshr i32 %4600, 16"
"  %4601 = lshr i32 %4598, 16"
"  %4601 = lshr i32 %4598, 16" -> "  %4603 = add nuw i32 %4601, %4602"
"  %4602 = mul nuw i32 %4532, %4532"
"  %4602 = mul nuw i32 %4532, %4532" -> "  %4603 = add nuw i32 %4601, %4602"
"  %4603 = add nuw i32 %4601, %4602"
"  %4603 = add nuw i32 %4601, %4602" -> "  %4607 = and i32 %4603, -65536""  %4603 = add nuw i32 %4601, %4602" -> "  %4605 = and i32 %4603, 65535"
"  %4604 = lshr i32 %4600, 16"
"  %4604 = lshr i32 %4600, 16" -> "  %4606 = add nuw nsw i32 %4604, %4605"
"  %4605 = and i32 %4603, 65535"
"  %4605 = and i32 %4603, 65535" -> "  %4606 = add nuw nsw i32 %4604, %4605"
"  %4606 = add nuw nsw i32 %4604, %4605"
"  %4606 = add nuw nsw i32 %4604, %4605" -> "  %4608 = add i32 %4606, %4607"
"  %4607 = and i32 %4603, -65536"
"  %4607 = and i32 %4603, -65536" -> "  %4608 = add i32 %4606, %4607"
"  %4608 = add i32 %4606, %4607"
"  %4608 = add i32 %4606, %4607" -> "  %4616 = add i32 %4608, %4615"
"  %4609 = and i32 %4572, 65535"
"  %4609 = and i32 %4572, 65535" -> "  %4611 = add nuw nsw i32 %4609, %4610"
"  %4610 = and i32 %4592, 65535"
"  %4610 = and i32 %4592, 65535" -> "  %4611 = add nuw nsw i32 %4609, %4610"
"  %4611 = add nuw nsw i32 %4609, %4610"
"  %4611 = add nuw nsw i32 %4609, %4610" -> "  %4622 = and i32 %4611, 65535""  %4611 = add nuw nsw i32 %4609, %4610" -> "  %4618 = lshr i32 %4611, 16"
"  %4612 = and i32 %4600, 65535"
"  %4612 = and i32 %4600, 65535" -> "  %4614 = add nuw nsw i32 %4613, %4612"
"  %4613 = lshr i32 %4572, 16"
"  %4613 = lshr i32 %4572, 16" -> "  %4614 = add nuw nsw i32 %4613, %4612"
"  %4614 = add nuw nsw i32 %4613, %4612"
"  %4614 = add nuw nsw i32 %4613, %4612" -> "  %4617 = and i32 %4614, 65535""  %4614 = add nuw nsw i32 %4613, %4612" -> "  %4615 = lshr i32 %4614, 16"
"  %4615 = lshr i32 %4614, 16"
"  %4615 = lshr i32 %4614, 16" -> "  %4616 = add i32 %4608, %4615"
"  %4616 = add i32 %4608, %4615"
"  %4616 = add i32 %4608, %4615" -> "  %4621 = add i32 %4616, %4620"
"  %4617 = and i32 %4614, 65535"
"  %4617 = and i32 %4614, 65535" -> "  %4619 = add nuw nsw i32 %4617, %4618"
"  %4618 = lshr i32 %4611, 16"
"  %4618 = lshr i32 %4611, 16" -> "  %4619 = add nuw nsw i32 %4617, %4618"
"  %4619 = add nuw nsw i32 %4617, %4618"
"  %4619 = add nuw nsw i32 %4617, %4618" -> "  %4625 = and i32 %4619, 65535""  %4619 = add nuw nsw i32 %4617, %4618" -> "  %4620 = lshr i32 %4619, 16"
"  %4620 = lshr i32 %4619, 16"
"  %4620 = lshr i32 %4619, 16" -> "  %4621 = add i32 %4616, %4620"
"  %4621 = add i32 %4616, %4620"
"  %4621 = add i32 %4616, %4620" -> "  %4634 = and i32 %4621, -65536""  %4621 = add i32 %4616, %4620" -> "  %4632 = and i32 %4621, 65535"
"  %4622 = and i32 %4611, 65535"
"  %4622 = and i32 %4611, 65535" -> "  %4624 = add nuw nsw i32 %4623, %4622"
"  %4623 = and i32 %4591, 65535"
"  %4623 = and i32 %4591, 65535" -> "  %4624 = add nuw nsw i32 %4623, %4622"
"  %4624 = add nuw nsw i32 %4623, %4622"
"  %4624 = add nuw nsw i32 %4623, %4622" -> "  %4794 = and i32 %4624, 65535""  %4624 = add nuw nsw i32 %4623, %4622" -> "  %4628 = lshr i32 %4624, 16"
"  %4625 = and i32 %4619, 65535"
"  %4625 = and i32 %4619, 65535" -> "  %4627 = add nuw nsw i32 %4625, %4626"
"  %4626 = lshr i32 %4591, 16"
"  %4626 = lshr i32 %4591, 16" -> "  %4627 = add nuw nsw i32 %4625, %4626"
"  %4627 = add nuw nsw i32 %4625, %4626"
"  %4627 = add nuw nsw i32 %4625, %4626" -> "  %4631 = lshr i32 %4627, 16""  %4627 = add nuw nsw i32 %4625, %4626" -> "  %4629 = and i32 %4627, 65535"
"  %4628 = lshr i32 %4624, 16"
"  %4628 = lshr i32 %4624, 16" -> "  %4630 = add nuw nsw i32 %4629, %4628"
"  %4629 = and i32 %4627, 65535"
"  %4629 = and i32 %4627, 65535" -> "  %4630 = add nuw nsw i32 %4629, %4628"
"  %4630 = add nuw nsw i32 %4629, %4628"
"  %4630 = add nuw nsw i32 %4629, %4628" -> "  %4791 = and i32 %4630, 65535""  %4630 = add nuw nsw i32 %4629, %4628" -> "  %4636 = lshr i32 %4630, 16"
"  %4631 = lshr i32 %4627, 16"
"  %4631 = lshr i32 %4627, 16" -> "  %4633 = add nuw nsw i32 %4631, %4632"
"  %4632 = and i32 %4621, 65535"
"  %4632 = and i32 %4621, 65535" -> "  %4633 = add nuw nsw i32 %4631, %4632"
"  %4633 = add nuw nsw i32 %4631, %4632"
"  %4633 = add nuw nsw i32 %4631, %4632" -> "  %4635 = add i32 %4633, %4634"
"  %4634 = and i32 %4621, -65536"
"  %4634 = and i32 %4621, -65536" -> "  %4635 = add i32 %4633, %4634"
"  %4635 = add i32 %4633, %4634"
"  %4635 = add i32 %4633, %4634" -> "  %4637 = add i32 %4635, %4636"
"  %4636 = lshr i32 %4630, 16"
"  %4636 = lshr i32 %4630, 16" -> "  %4637 = add i32 %4635, %4636"
"  %4637 = add i32 %4635, %4636"
"  %4637 = add i32 %4635, %4636" -> "  %4803 = and i32 %4637, 65535""  %4637 = add i32 %4635, %4636" -> "  %4806 = lshr i32 %4637, 16"
"  %4638 = and i32 %4497, 65535"
"  %4638 = and i32 %4497, 65535" -> "  %4961 = mul nuw i32 %4664, %4638""  %4638 = and i32 %4497, 65535" -> "  %4959 = mul nuw i32 %4661, %4638""  %4638 = and i32 %4497, 65535" -> "  %4944 = mul nuw i32 %4639, %4638""  %4638 = and i32 %4497, 65535" -> "  %4705 = mul nuw i32 %4638, %4532""  %4638 = and i32 %4497, 65535" -> "  %4700 = mul nuw i32 %4638, %4531""  %4638 = and i32 %4497, 65535" -> "  %4645 = mul nuw i32 %4638, %4513""  %4638 = and i32 %4497, 65535" -> "  %4640 = mul nuw i32 %4638, %4512""  %4638 = and i32 %4497, 65535" -> "  %4942 = mul nuw i32 %4638, %4638""  %4638 = and i32 %4497, 65535" -> "  %4942 = mul nuw i32 %4638, %4638"
"  %4639 = and i32 %4500, 65535"
"  %4639 = and i32 %4500, 65535" -> "  %4971 = mul nuw i32 %4664, %4639""  %4639 = and i32 %4500, 65535" -> "  %4962 = mul nuw i32 %4661, %4639""  %4639 = and i32 %4500, 65535" -> "  %4944 = mul nuw i32 %4639, %4638""  %4639 = and i32 %4500, 65535" -> "  %4718 = mul nuw i32 %4639, %4532""  %4639 = and i32 %4500, 65535" -> "  %4702 = mul nuw i32 %4639, %4531""  %4639 = and i32 %4500, 65535" -> "  %4655 = mul nuw i32 %4639, %4513""  %4639 = and i32 %4500, 65535" -> "  %4642 = mul nuw i32 %4639, %4512""  %4639 = and i32 %4500, 65535" -> "  %4952 = mul nuw i32 %4639, %4639""  %4639 = and i32 %4500, 65535" -> "  %4952 = mul nuw i32 %4639, %4639"
"  %4640 = mul nuw i32 %4638, %4512"
"  %4640 = mul nuw i32 %4638, %4512" -> "  %4793 = and i32 %4640, 65535""  %4640 = mul nuw i32 %4638, %4512" -> "  %4641 = lshr i32 %4640, 16"
"  %4641 = lshr i32 %4640, 16"
"  %4641 = lshr i32 %4640, 16" -> "  %4644 = add nuw nsw i32 %4643, %4641""  %4641 = lshr i32 %4640, 16" -> "  %4646 = add nuw i32 %4641, %4645"
"  %4642 = mul nuw i32 %4639, %4512"
"  %4642 = mul nuw i32 %4639, %4512" -> "  %4648 = add nuw i32 %4642, %4647""  %4642 = mul nuw i32 %4639, %4512" -> "  %4649 = and i32 %4642, -65536""  %4642 = mul nuw i32 %4639, %4512" -> "  %4643 = and i32 %4642, 65535"
"  %4643 = and i32 %4642, 65535"
"  %4643 = and i32 %4642, 65535" -> "  %4644 = add nuw nsw i32 %4643, %4641"
"  %4644 = add nuw nsw i32 %4643, %4641"
"  %4644 = add nuw nsw i32 %4643, %4641" -> "  %4650 = add nuw i32 %4644, %4649"
"  %4645 = mul nuw i32 %4638, %4513"
"  %4645 = mul nuw i32 %4638, %4513" -> "  %4652 = add nuw i32 %4651, %4645""  %4645 = mul nuw i32 %4638, %4513" -> "  %4646 = add nuw i32 %4641, %4645"
"  %4646 = add nuw i32 %4641, %4645"
"  %4646 = add nuw i32 %4641, %4645" -> "  %4828 = lshr i32 %4646, 16""  %4646 = add nuw i32 %4641, %4645" -> "  %4647 = and i32 %4646, 65535"
"  %4647 = and i32 %4646, 65535"
"  %4647 = and i32 %4646, 65535" -> "  %4648 = add nuw i32 %4642, %4647"
"  %4648 = add nuw i32 %4642, %4647"
"  %4648 = add nuw i32 %4642, %4647" -> "  %4907 = and i32 %4648, 65535""  %4648 = add nuw i32 %4642, %4647" -> "  %4830 = lshr i32 %4648, 16"
"  %4649 = and i32 %4642, -65536"
"  %4649 = and i32 %4642, -65536" -> "  %4650 = add nuw i32 %4644, %4649"
"  %4650 = add nuw i32 %4644, %4649"
"  %4650 = add nuw i32 %4644, %4649" -> "  %4653 = lshr i32 %4650, 16""  %4650 = add nuw i32 %4644, %4649" -> "  %4651 = and i32 %4650, 65535"
"  %4651 = and i32 %4650, 65535"
"  %4651 = and i32 %4650, 65535" -> "  %4652 = add nuw i32 %4651, %4645"
"  %4652 = add nuw i32 %4651, %4645"
"  %4652 = add nuw i32 %4651, %4645" -> "  %4790 = and i32 %4652, 65535""  %4652 = add nuw i32 %4651, %4645" -> "  %4654 = lshr i32 %4652, 16"
"  %4653 = lshr i32 %4650, 16"
"  %4653 = lshr i32 %4650, 16" -> "  %4656 = add nuw i32 %4653, %4655"
"  %4654 = lshr i32 %4652, 16"
"  %4654 = lshr i32 %4652, 16" -> "  %4658 = add nuw nsw i32 %4654, %4657"
"  %4655 = mul nuw i32 %4639, %4513"
"  %4655 = mul nuw i32 %4639, %4513" -> "  %4829 = add nuw i32 %4655, %4828""  %4655 = mul nuw i32 %4639, %4513" -> "  %4656 = add nuw i32 %4653, %4655"
"  %4656 = add nuw i32 %4653, %4655"
"  %4656 = add nuw i32 %4653, %4655" -> "  %4659 = and i32 %4656, -65536""  %4656 = add nuw i32 %4653, %4655" -> "  %4657 = and i32 %4656, 65535"
"  %4657 = and i32 %4656, 65535"
"  %4657 = and i32 %4656, 65535" -> "  %4658 = add nuw nsw i32 %4654, %4657"
"  %4658 = add nuw nsw i32 %4654, %4657"
"  %4658 = add nuw nsw i32 %4654, %4657" -> "  %4660 = add i32 %4658, %4659"
"  %4659 = and i32 %4656, -65536"
"  %4659 = and i32 %4656, -65536" -> "  %4660 = add i32 %4658, %4659"
"  %4660 = add i32 %4658, %4659"
"  %4660 = add i32 %4658, %4659" -> "  %4688 = and i32 %4660, 65535""  %4660 = add i32 %4658, %4659" -> "  %4685 = lshr i32 %4660, 16"
"  %4661 = and i32 %4511, 65535"
"  %4661 = and i32 %4511, 65535" -> "  %4962 = mul nuw i32 %4661, %4639""  %4661 = and i32 %4511, 65535" -> "  %4959 = mul nuw i32 %4661, %4638""  %4661 = and i32 %4511, 65535" -> "  %4742 = mul nuw i32 %4661, %4532""  %4661 = and i32 %4511, 65535" -> "  %4737 = mul nuw i32 %4661, %4531""  %4661 = and i32 %4511, 65535" -> "  %4666 = mul nuw i32 %4661, %4513""  %4661 = and i32 %4511, 65535" -> "  %4662 = mul nuw i32 %4661, %4512""  %4661 = and i32 %4511, 65535" -> "  %5011 = mul nuw i32 %4664, %4661""  %4661 = and i32 %4511, 65535" -> "  %5009 = mul nuw i32 %4661, %4661""  %4661 = and i32 %4511, 65535" -> "  %5009 = mul nuw i32 %4661, %4661"
"  %4662 = mul nuw i32 %4661, %4512"
"  %4662 = mul nuw i32 %4661, %4512" -> "  %4687 = and i32 %4662, 65535""  %4662 = mul nuw i32 %4661, %4512" -> "  %4663 = lshr i32 %4662, 16"
"  %4663 = lshr i32 %4662, 16"
"  %4663 = lshr i32 %4662, 16" -> "  %4673 = add nuw i32 %4663, %4665""  %4663 = lshr i32 %4662, 16" -> "  %4668 = add nuw nsw i32 %4663, %4667"
"  %4664 = lshr i32 %4511, 16"
"  %4664 = lshr i32 %4511, 16" -> "  %4971 = mul nuw i32 %4664, %4639""  %4664 = lshr i32 %4511, 16" -> "  %4961 = mul nuw i32 %4664, %4638""  %4664 = lshr i32 %4511, 16" -> "  %4755 = mul nuw i32 %4664, %4532""  %4664 = lshr i32 %4511, 16" -> "  %4739 = mul nuw i32 %4664, %4531""  %4664 = lshr i32 %4511, 16" -> "  %4678 = mul nuw i32 %4664, %4513""  %4664 = lshr i32 %4511, 16" -> "  %4665 = mul nuw i32 %4664, %4512""  %4664 = lshr i32 %4511, 16" -> "  %5011 = mul nuw i32 %4664, %4661""  %4664 = lshr i32 %4511, 16" -> "  %5019 = mul nuw i32 %4664, %4664""  %4664 = lshr i32 %4511, 16" -> "  %5019 = mul nuw i32 %4664, %4664"
"  %4665 = mul nuw i32 %4664, %4512"
"  %4665 = mul nuw i32 %4664, %4512" -> "  %4673 = add nuw i32 %4663, %4665""  %4665 = mul nuw i32 %4664, %4512" -> "  %4672 = add nuw i32 %4671, %4665"
"  %4666 = mul nuw i32 %4661, %4513"
"  %4666 = mul nuw i32 %4661, %4513" -> "  %4675 = add nuw i32 %4674, %4666""  %4666 = mul nuw i32 %4661, %4513" -> "  %4669 = and i32 %4666, -65536""  %4666 = mul nuw i32 %4661, %4513" -> "  %4667 = and i32 %4666, 65535"
"  %4667 = and i32 %4666, 65535"
"  %4667 = and i32 %4666, 65535" -> "  %4668 = add nuw nsw i32 %4663, %4667"
"  %4668 = add nuw nsw i32 %4663, %4667"
"  %4668 = add nuw nsw i32 %4663, %4667" -> "  %4670 = add nuw i32 %4668, %4669"
"  %4669 = and i32 %4666, -65536"
"  %4669 = and i32 %4666, -65536" -> "  %4670 = add nuw i32 %4668, %4669"
"  %4670 = add nuw i32 %4668, %4669"
"  %4670 = add nuw i32 %4668, %4669" -> "  %4854 = lshr i32 %4670, 16""  %4670 = add nuw i32 %4668, %4669" -> "  %4671 = and i32 %4670, 65535"
"  %4671 = and i32 %4670, 65535"
"  %4671 = and i32 %4670, 65535" -> "  %4672 = add nuw i32 %4671, %4665"
"  %4672 = add nuw i32 %4671, %4665"
"  %4672 = add nuw i32 %4671, %4665" -> "  %4856 = lshr i32 %4672, 16""  %4672 = add nuw i32 %4671, %4665" -> "  %4864 = and i32 %4672, 65535"
"  %4673 = add nuw i32 %4663, %4665"
"  %4673 = add nuw i32 %4663, %4665" -> "  %4676 = lshr i32 %4673, 16""  %4673 = add nuw i32 %4663, %4665" -> "  %4674 = and i32 %4673, 65535"
"  %4674 = and i32 %4673, 65535"
"  %4674 = and i32 %4673, 65535" -> "  %4675 = add nuw i32 %4674, %4666"
"  %4675 = add nuw i32 %4674, %4666"
"  %4675 = add nuw i32 %4674, %4666" -> "  %4684 = and i32 %4675, 65535""  %4675 = add nuw i32 %4674, %4666" -> "  %4677 = lshr i32 %4675, 16"
"  %4676 = lshr i32 %4673, 16"
"  %4676 = lshr i32 %4673, 16" -> "  %4679 = add nuw i32 %4676, %4678"
"  %4677 = lshr i32 %4675, 16"
"  %4677 = lshr i32 %4675, 16" -> "  %4681 = add nuw nsw i32 %4677, %4680"
"  %4678 = mul nuw i32 %4664, %4513"
"  %4678 = mul nuw i32 %4664, %4513" -> "  %4855 = add nuw i32 %4854, %4678""  %4678 = mul nuw i32 %4664, %4513" -> "  %4679 = add nuw i32 %4676, %4678"
"  %4679 = add nuw i32 %4676, %4678"
"  %4679 = add nuw i32 %4676, %4678" -> "  %4682 = and i32 %4679, -65536""  %4679 = add nuw i32 %4676, %4678" -> "  %4680 = and i32 %4679, 65535"
"  %4680 = and i32 %4679, 65535"
"  %4680 = and i32 %4679, 65535" -> "  %4681 = add nuw nsw i32 %4677, %4680"
"  %4681 = add nuw nsw i32 %4677, %4680"
"  %4681 = add nuw nsw i32 %4677, %4680" -> "  %4683 = add i32 %4681, %4682"
"  %4682 = and i32 %4679, -65536"
"  %4682 = and i32 %4679, -65536" -> "  %4683 = add i32 %4681, %4682"
"  %4683 = add i32 %4681, %4682"
"  %4683 = add i32 %4681, %4682" -> "  %4694 = and i32 %4683, 65535""  %4683 = add i32 %4681, %4682" -> "  %4696 = and i32 %4683, -65536"
"  %4684 = and i32 %4675, 65535"
"  %4684 = and i32 %4675, 65535" -> "  %4686 = add nuw nsw i32 %4684, %4685"
"  %4685 = lshr i32 %4660, 16"
"  %4685 = lshr i32 %4660, 16" -> "  %4686 = add nuw nsw i32 %4684, %4685"
"  %4686 = add nuw nsw i32 %4684, %4685"
"  %4686 = add nuw nsw i32 %4684, %4685" -> "  %4691 = and i32 %4686, 65535""  %4686 = add nuw nsw i32 %4684, %4685" -> "  %4693 = lshr i32 %4686, 16"
"  %4687 = and i32 %4662, 65535"
"  %4687 = and i32 %4662, 65535" -> "  %4689 = add nuw nsw i32 %4688, %4687""  %4687 = and i32 %4662, 65535" -> "  %4862 = add nuw nsw i32 %4687, %4861"
"  %4688 = and i32 %4660, 65535"
"  %4688 = and i32 %4660, 65535" -> "  %4689 = add nuw nsw i32 %4688, %4687"
"  %4689 = add nuw nsw i32 %4688, %4687"
"  %4689 = add nuw nsw i32 %4688, %4687" -> "  %4731 = and i32 %4689, 65535""  %4689 = add nuw nsw i32 %4688, %4687" -> "  %4690 = lshr i32 %4689, 16"
"  %4690 = lshr i32 %4689, 16"
"  %4690 = lshr i32 %4689, 16" -> "  %4692 = add nuw nsw i32 %4691, %4690"
"  %4691 = and i32 %4686, 65535"
"  %4691 = and i32 %4686, 65535" -> "  %4692 = add nuw nsw i32 %4691, %4690"
"  %4692 = add nuw nsw i32 %4691, %4690"
"  %4692 = add nuw nsw i32 %4691, %4690" -> "  %4724 = and i32 %4692, 65535""  %4692 = add nuw nsw i32 %4691, %4690" -> "  %4697 = lshr i32 %4692, 16"
"  %4693 = lshr i32 %4686, 16"
"  %4693 = lshr i32 %4686, 16" -> "  %4695 = add nuw nsw i32 %4694, %4693"
"  %4694 = and i32 %4683, 65535"
"  %4694 = and i32 %4683, 65535" -> "  %4695 = add nuw nsw i32 %4694, %4693"
"  %4695 = add nuw nsw i32 %4694, %4693"
"  %4695 = add nuw nsw i32 %4694, %4693" -> "  %4698 = add i32 %4695, %4696"
"  %4696 = and i32 %4683, -65536"
"  %4696 = and i32 %4683, -65536" -> "  %4698 = add i32 %4695, %4696"
"  %4697 = lshr i32 %4692, 16"
"  %4697 = lshr i32 %4692, 16" -> "  %4699 = add i32 %4698, %4697"
"  %4698 = add i32 %4695, %4696"
"  %4698 = add i32 %4695, %4696" -> "  %4699 = add i32 %4698, %4697"
"  %4699 = add i32 %4698, %4697"
"  %4699 = add i32 %4698, %4697" -> "  %4767 = and i32 %4699, 65535""  %4699 = add i32 %4698, %4697" -> "  %4762 = lshr i32 %4699, 16"
"  %4700 = mul nuw i32 %4638, %4531"
"  %4700 = mul nuw i32 %4638, %4531" -> "  %4729 = and i32 %4700, 65535""  %4700 = mul nuw i32 %4638, %4531" -> "  %4701 = lshr i32 %4700, 16"
"  %4701 = lshr i32 %4700, 16"
"  %4701 = lshr i32 %4700, 16" -> "  %4704 = add nuw nsw i32 %4703, %4701""  %4701 = lshr i32 %4700, 16" -> "  %4707 = add nuw nsw i32 %4706, %4701"
"  %4702 = mul nuw i32 %4639, %4531"
"  %4702 = mul nuw i32 %4639, %4531" -> "  %4711 = add nuw i32 %4702, %4710""  %4702 = mul nuw i32 %4639, %4531" -> "  %4712 = and i32 %4702, -65536""  %4702 = mul nuw i32 %4639, %4531" -> "  %4703 = and i32 %4702, 65535"
"  %4703 = and i32 %4702, 65535"
"  %4703 = and i32 %4702, 65535" -> "  %4704 = add nuw nsw i32 %4703, %4701"
"  %4704 = add nuw nsw i32 %4703, %4701"
"  %4704 = add nuw nsw i32 %4703, %4701" -> "  %4713 = add nuw i32 %4704, %4712"
"  %4705 = mul nuw i32 %4638, %4532"
"  %4705 = mul nuw i32 %4638, %4532" -> "  %4715 = add nuw i32 %4714, %4705""  %4705 = mul nuw i32 %4638, %4532" -> "  %4708 = and i32 %4705, -65536""  %4705 = mul nuw i32 %4638, %4532" -> "  %4706 = and i32 %4705, 65535"
"  %4706 = and i32 %4705, 65535"
"  %4706 = and i32 %4705, 65535" -> "  %4707 = add nuw nsw i32 %4706, %4701"
"  %4707 = add nuw nsw i32 %4706, %4701"
"  %4707 = add nuw nsw i32 %4706, %4701" -> "  %4709 = add nuw i32 %4707, %4708"
"  %4708 = and i32 %4705, -65536"
"  %4708 = and i32 %4705, -65536" -> "  %4709 = add nuw i32 %4707, %4708"
"  %4709 = add nuw i32 %4707, %4708"
"  %4709 = add nuw i32 %4707, %4708" -> "  %4835 = lshr i32 %4709, 16""  %4709 = add nuw i32 %4707, %4708" -> "  %4710 = and i32 %4709, 65535"
"  %4710 = and i32 %4709, 65535"
"  %4710 = and i32 %4709, 65535" -> "  %4711 = add nuw i32 %4702, %4710"
"  %4711 = add nuw i32 %4702, %4710"
"  %4711 = add nuw i32 %4702, %4710" -> "  %4837 = lshr i32 %4711, 16""  %4711 = add nuw i32 %4702, %4710" -> "  %4844 = and i32 %4711, 65535"
"  %4712 = and i32 %4702, -65536"
"  %4712 = and i32 %4702, -65536" -> "  %4713 = add nuw i32 %4704, %4712"
"  %4713 = add nuw i32 %4704, %4712"
"  %4713 = add nuw i32 %4704, %4712" -> "  %4716 = lshr i32 %4713, 16""  %4713 = add nuw i32 %4704, %4712" -> "  %4714 = and i32 %4713, 65535"
"  %4714 = and i32 %4713, 65535"
"  %4714 = and i32 %4713, 65535" -> "  %4715 = add nuw i32 %4714, %4705"
"  %4715 = add nuw i32 %4714, %4705"
"  %4715 = add nuw i32 %4714, %4705" -> "  %4725 = and i32 %4715, 65535""  %4715 = add nuw i32 %4714, %4705" -> "  %4717 = lshr i32 %4715, 16"
"  %4716 = lshr i32 %4713, 16"
"  %4716 = lshr i32 %4713, 16" -> "  %4719 = add nuw i32 %4716, %4718"
"  %4717 = lshr i32 %4715, 16"
"  %4717 = lshr i32 %4715, 16" -> "  %4721 = add nuw nsw i32 %4717, %4720"
"  %4718 = mul nuw i32 %4639, %4532"
"  %4718 = mul nuw i32 %4639, %4532" -> "  %4836 = add nuw i32 %4718, %4835""  %4718 = mul nuw i32 %4639, %4532" -> "  %4719 = add nuw i32 %4716, %4718"
"  %4719 = add nuw i32 %4716, %4718"
"  %4719 = add nuw i32 %4716, %4718" -> "  %4722 = and i32 %4719, -65536""  %4719 = add nuw i32 %4716, %4718" -> "  %4720 = and i32 %4719, 65535"
"  %4720 = and i32 %4719, 65535"
"  %4720 = and i32 %4719, 65535" -> "  %4721 = add nuw nsw i32 %4717, %4720"
"  %4721 = add nuw nsw i32 %4717, %4720"
"  %4721 = add nuw nsw i32 %4717, %4720" -> "  %4723 = add i32 %4721, %4722"
"  %4722 = and i32 %4719, -65536"
"  %4722 = and i32 %4719, -65536" -> "  %4723 = add i32 %4721, %4722"
"  %4723 = add i32 %4721, %4722"
"  %4723 = add i32 %4721, %4722" -> "  %4728 = add i32 %4723, %4727"
"  %4724 = and i32 %4692, 65535"
"  %4724 = and i32 %4692, 65535" -> "  %4726 = add nuw nsw i32 %4724, %4725"
"  %4725 = and i32 %4715, 65535"
"  %4725 = and i32 %4715, 65535" -> "  %4726 = add nuw nsw i32 %4724, %4725"
"  %4726 = add nuw nsw i32 %4724, %4725"
"  %4726 = add nuw nsw i32 %4724, %4725" -> "  %4730 = and i32 %4726, 65535""  %4726 = add nuw nsw i32 %4724, %4725" -> "  %4727 = lshr i32 %4726, 16"
"  %4727 = lshr i32 %4726, 16"
"  %4727 = lshr i32 %4726, 16" -> "  %4728 = add i32 %4723, %4727"
"  %4728 = add i32 %4723, %4727"
"  %4728 = add i32 %4723, %4727" -> "  %4736 = add i32 %4728, %4735"
"  %4729 = and i32 %4700, 65535"
"  %4729 = and i32 %4700, 65535" -> "  %4843 = add nuw nsw i32 %4842, %4729""  %4729 = and i32 %4700, 65535" -> "  %4732 = add nuw nsw i32 %4731, %4729"
"  %4730 = and i32 %4726, 65535"
"  %4730 = and i32 %4726, 65535" -> "  %4734 = add nuw nsw i32 %4730, %4733"
"  %4731 = and i32 %4689, 65535"
"  %4731 = and i32 %4689, 65535" -> "  %4732 = add nuw nsw i32 %4731, %4729"
"  %4732 = add nuw nsw i32 %4731, %4729"
"  %4732 = add nuw nsw i32 %4731, %4729" -> "  %4802 = and i32 %4732, 65535""  %4732 = add nuw nsw i32 %4731, %4729" -> "  %4733 = lshr i32 %4732, 16"
"  %4733 = lshr i32 %4732, 16"
"  %4733 = lshr i32 %4732, 16" -> "  %4734 = add nuw nsw i32 %4730, %4733"
"  %4734 = add nuw nsw i32 %4730, %4733"
"  %4734 = add nuw nsw i32 %4730, %4733" -> "  %4805 = and i32 %4734, 65535""  %4734 = add nuw nsw i32 %4730, %4733" -> "  %4735 = lshr i32 %4734, 16"
"  %4735 = lshr i32 %4734, 16"
"  %4735 = lshr i32 %4734, 16" -> "  %4736 = add i32 %4728, %4735"
"  %4736 = add i32 %4728, %4735"
"  %4736 = add i32 %4728, %4735" -> "  %4778 = lshr i32 %4736, 16""  %4736 = add i32 %4728, %4735" -> "  %4775 = and i32 %4736, 65535"
"  %4737 = mul nuw i32 %4661, %4531"
"  %4737 = mul nuw i32 %4661, %4531" -> "  %4766 = and i32 %4737, 65535""  %4737 = mul nuw i32 %4661, %4531" -> "  %4738 = lshr i32 %4737, 16"
"  %4738 = lshr i32 %4737, 16"
"  %4738 = lshr i32 %4737, 16" -> "  %4744 = add nuw nsw i32 %4738, %4743""  %4738 = lshr i32 %4737, 16" -> "  %4741 = add nuw nsw i32 %4740, %4738"
"  %4739 = mul nuw i32 %4664, %4531"
"  %4739 = mul nuw i32 %4664, %4531" -> "  %4748 = add nuw i32 %4747, %4739""  %4739 = mul nuw i32 %4664, %4531" -> "  %4749 = and i32 %4739, -65536""  %4739 = mul nuw i32 %4664, %4531" -> "  %4740 = and i32 %4739, 65535"
"  %4740 = and i32 %4739, 65535"
"  %4740 = and i32 %4739, 65535" -> "  %4741 = add nuw nsw i32 %4740, %4738"
"  %4741 = add nuw nsw i32 %4740, %4738"
"  %4741 = add nuw nsw i32 %4740, %4738" -> "  %4750 = add nuw i32 %4741, %4749"
"  %4742 = mul nuw i32 %4661, %4532"
"  %4742 = mul nuw i32 %4661, %4532" -> "  %4752 = add nuw i32 %4751, %4742""  %4742 = mul nuw i32 %4661, %4532" -> "  %4745 = and i32 %4742, -65536""  %4742 = mul nuw i32 %4661, %4532" -> "  %4743 = and i32 %4742, 65535"
"  %4743 = and i32 %4742, 65535"
"  %4743 = and i32 %4742, 65535" -> "  %4744 = add nuw nsw i32 %4738, %4743"
"  %4744 = add nuw nsw i32 %4738, %4743"
"  %4744 = add nuw nsw i32 %4738, %4743" -> "  %4746 = add nuw i32 %4744, %4745"
"  %4745 = and i32 %4742, -65536"
"  %4745 = and i32 %4742, -65536" -> "  %4746 = add nuw i32 %4744, %4745"
"  %4746 = add nuw i32 %4744, %4745"
"  %4746 = add nuw i32 %4744, %4745" -> "  %4873 = lshr i32 %4746, 16""  %4746 = add nuw i32 %4744, %4745" -> "  %4747 = and i32 %4746, 65535"
"  %4747 = and i32 %4746, 65535"
"  %4747 = and i32 %4746, 65535" -> "  %4748 = add nuw i32 %4747, %4739"
"  %4748 = add nuw i32 %4747, %4739"
"  %4748 = add nuw i32 %4747, %4739" -> "  %4883 = and i32 %4748, 65535""  %4748 = add nuw i32 %4747, %4739" -> "  %4875 = lshr i32 %4748, 16"
"  %4749 = and i32 %4739, -65536"
"  %4749 = and i32 %4739, -65536" -> "  %4750 = add nuw i32 %4741, %4749"
"  %4750 = add nuw i32 %4741, %4749"
"  %4750 = add nuw i32 %4741, %4749" -> "  %4753 = lshr i32 %4750, 16""  %4750 = add nuw i32 %4741, %4749" -> "  %4751 = and i32 %4750, 65535"
"  %4751 = and i32 %4750, 65535"
"  %4751 = and i32 %4750, 65535" -> "  %4752 = add nuw i32 %4751, %4742"
"  %4752 = add nuw i32 %4751, %4742"
"  %4752 = add nuw i32 %4751, %4742" -> "  %4761 = and i32 %4752, 65535""  %4752 = add nuw i32 %4751, %4742" -> "  %4754 = lshr i32 %4752, 16"
"  %4753 = lshr i32 %4750, 16"
"  %4753 = lshr i32 %4750, 16" -> "  %4756 = add nuw i32 %4753, %4755"
"  %4754 = lshr i32 %4752, 16"
"  %4754 = lshr i32 %4752, 16" -> "  %4758 = add nuw nsw i32 %4754, %4757"
"  %4755 = mul nuw i32 %4664, %4532"
"  %4755 = mul nuw i32 %4664, %4532" -> "  %4874 = add nuw i32 %4873, %4755""  %4755 = mul nuw i32 %4664, %4532" -> "  %4756 = add nuw i32 %4753, %4755"
"  %4756 = add nuw i32 %4753, %4755"
"  %4756 = add nuw i32 %4753, %4755" -> "  %4759 = and i32 %4756, -65536""  %4756 = add nuw i32 %4753, %4755" -> "  %4757 = and i32 %4756, 65535"
"  %4757 = and i32 %4756, 65535"
"  %4757 = and i32 %4756, 65535" -> "  %4758 = add nuw nsw i32 %4754, %4757"
"  %4758 = add nuw nsw i32 %4754, %4757"
"  %4758 = add nuw nsw i32 %4754, %4757" -> "  %4760 = add i32 %4758, %4759"
"  %4759 = and i32 %4756, -65536"
"  %4759 = and i32 %4756, -65536" -> "  %4760 = add i32 %4758, %4759"
"  %4760 = add i32 %4758, %4759"
"  %4760 = add i32 %4758, %4759" -> "  %4765 = add i32 %4760, %4764"
"  %4761 = and i32 %4752, 65535"
"  %4761 = and i32 %4752, 65535" -> "  %4763 = add nuw nsw i32 %4762, %4761"
"  %4762 = lshr i32 %4699, 16"
"  %4762 = lshr i32 %4699, 16" -> "  %4763 = add nuw nsw i32 %4762, %4761"
"  %4763 = add nuw nsw i32 %4762, %4761"
"  %4763 = add nuw nsw i32 %4762, %4761" -> "  %4768 = and i32 %4763, 65535""  %4763 = add nuw nsw i32 %4762, %4761" -> "  %4764 = lshr i32 %4763, 16"
"  %4764 = lshr i32 %4763, 16"
"  %4764 = lshr i32 %4763, 16" -> "  %4765 = add i32 %4760, %4764"
"  %4765 = add i32 %4760, %4764"
"  %4765 = add i32 %4760, %4764" -> "  %4773 = add i32 %4765, %4772"
"  %4766 = and i32 %4737, 65535"
"  %4766 = and i32 %4737, 65535" -> "  %4881 = add nuw nsw i32 %4880, %4766""  %4766 = and i32 %4737, 65535" -> "  %4769 = add nuw nsw i32 %4767, %4766"
"  %4767 = and i32 %4699, 65535"
"  %4767 = and i32 %4699, 65535" -> "  %4769 = add nuw nsw i32 %4767, %4766"
"  %4768 = and i32 %4763, 65535"
"  %4768 = and i32 %4763, 65535" -> "  %4771 = add nuw nsw i32 %4768, %4770"
"  %4769 = add nuw nsw i32 %4767, %4766"
"  %4769 = add nuw nsw i32 %4767, %4766" -> "  %4774 = and i32 %4769, 65535""  %4769 = add nuw nsw i32 %4767, %4766" -> "  %4770 = lshr i32 %4769, 16"
"  %4770 = lshr i32 %4769, 16"
"  %4770 = lshr i32 %4769, 16" -> "  %4771 = add nuw nsw i32 %4768, %4770"
"  %4771 = add nuw nsw i32 %4768, %4770"
"  %4771 = add nuw nsw i32 %4768, %4770" -> "  %4777 = and i32 %4771, 65535""  %4771 = add nuw nsw i32 %4768, %4770" -> "  %4772 = lshr i32 %4771, 16"
"  %4772 = lshr i32 %4771, 16"
"  %4772 = lshr i32 %4771, 16" -> "  %4773 = add i32 %4765, %4772"
"  %4773 = add i32 %4765, %4772"
"  %4773 = add i32 %4765, %4772" -> "  %4786 = and i32 %4773, -65536""  %4773 = add i32 %4765, %4772" -> "  %4784 = and i32 %4773, 65535"
"  %4774 = and i32 %4769, 65535"
"  %4774 = and i32 %4769, 65535" -> "  %4776 = add nuw nsw i32 %4775, %4774"
"  %4775 = and i32 %4736, 65535"
"  %4775 = and i32 %4736, 65535" -> "  %4776 = add nuw nsw i32 %4775, %4774"
"  %4776 = add nuw nsw i32 %4775, %4774"
"  %4776 = add nuw nsw i32 %4775, %4774" -> "  %4816 = and i32 %4776, 65535""  %4776 = add nuw nsw i32 %4775, %4774" -> "  %4780 = lshr i32 %4776, 16"
"  %4777 = and i32 %4771, 65535"
"  %4777 = and i32 %4771, 65535" -> "  %4779 = add nuw nsw i32 %4777, %4778"
"  %4778 = lshr i32 %4736, 16"
"  %4778 = lshr i32 %4736, 16" -> "  %4779 = add nuw nsw i32 %4777, %4778"
"  %4779 = add nuw nsw i32 %4777, %4778"
"  %4779 = add nuw nsw i32 %4777, %4778" -> "  %4783 = lshr i32 %4779, 16""  %4779 = add nuw nsw i32 %4777, %4778" -> "  %4781 = and i32 %4779, 65535"
"  %4780 = lshr i32 %4776, 16"
"  %4780 = lshr i32 %4776, 16" -> "  %4782 = add nuw nsw i32 %4781, %4780"
"  %4781 = and i32 %4779, 65535"
"  %4781 = and i32 %4779, 65535" -> "  %4782 = add nuw nsw i32 %4781, %4780"
"  %4782 = add nuw nsw i32 %4781, %4780"
"  %4782 = add nuw nsw i32 %4781, %4780" -> "  %4823 = and i32 %4782, 65535""  %4782 = add nuw nsw i32 %4781, %4780" -> "  %4788 = lshr i32 %4782, 16"
"  %4783 = lshr i32 %4779, 16"
"  %4783 = lshr i32 %4779, 16" -> "  %4785 = add nuw nsw i32 %4783, %4784"
"  %4784 = and i32 %4773, 65535"
"  %4784 = and i32 %4773, 65535" -> "  %4785 = add nuw nsw i32 %4783, %4784"
"  %4785 = add nuw nsw i32 %4783, %4784"
"  %4785 = add nuw nsw i32 %4783, %4784" -> "  %4787 = add i32 %4785, %4786"
"  %4786 = and i32 %4773, -65536"
"  %4786 = and i32 %4773, -65536" -> "  %4787 = add i32 %4785, %4786"
"  %4787 = add i32 %4785, %4786"
"  %4787 = add i32 %4785, %4786" -> "  %4789 = add i32 %4787, %4788"
"  %4788 = lshr i32 %4782, 16"
"  %4788 = lshr i32 %4782, 16" -> "  %4789 = add i32 %4787, %4788"
"  %4789 = add i32 %4787, %4788"
"  %4789 = add i32 %4787, %4788" -> "  %4827 = add i32 %4789, %4826"
"  %4790 = and i32 %4652, 65535"
"  %4790 = and i32 %4652, 65535" -> "  %4792 = add nuw nsw i32 %4791, %4790"
"  %4791 = and i32 %4630, 65535"
"  %4791 = and i32 %4630, 65535" -> "  %4792 = add nuw nsw i32 %4791, %4790"
"  %4792 = add nuw nsw i32 %4791, %4790"
"  %4792 = add nuw nsw i32 %4791, %4790" -> "  %4799 = lshr i32 %4792, 16""  %4792 = add nuw nsw i32 %4791, %4790" -> "  %4797 = and i32 %4792, 65535"
"  %4793 = and i32 %4640, 65535"
"  %4793 = and i32 %4640, 65535" -> "  %4906 = add nuw nsw i32 %4905, %4793""  %4793 = and i32 %4640, 65535" -> "  %4795 = add nuw nsw i32 %4794, %4793"
"  %4794 = and i32 %4624, 65535"
"  %4794 = and i32 %4624, 65535" -> "  %4795 = add nuw nsw i32 %4794, %4793"
"  %4795 = add nuw nsw i32 %4794, %4793"
"  %4795 = add nuw nsw i32 %4794, %4793" -> "  %4905 = and i32 %4795, 65535""  %4795 = add nuw nsw i32 %4794, %4793" -> "  %4796 = lshr i32 %4795, 16"
"  %4796 = lshr i32 %4795, 16"
"  %4796 = lshr i32 %4795, 16" -> "  %4798 = add nuw nsw i32 %4797, %4796"
"  %4797 = and i32 %4792, 65535"
"  %4797 = and i32 %4792, 65535" -> "  %4798 = add nuw nsw i32 %4797, %4796"
"  %4798 = add nuw nsw i32 %4797, %4796"
"  %4798 = add nuw nsw i32 %4797, %4796" -> "  %4908 = and i32 %4798, 65535""  %4798 = add nuw nsw i32 %4797, %4796" -> "  %4800 = lshr i32 %4798, 16"
"  %4799 = lshr i32 %4792, 16"
"  %4799 = lshr i32 %4792, 16" -> "  %4801 = add nuw nsw i32 %4800, %4799"
"  %4800 = lshr i32 %4798, 16"
"  %4800 = lshr i32 %4798, 16" -> "  %4801 = add nuw nsw i32 %4800, %4799"
"  %4801 = add nuw nsw i32 %4800, %4799"
"  %4801 = add nuw nsw i32 %4800, %4799" -> "  %4812 = add nuw nsw i32 %4801, %4811"
"  %4802 = and i32 %4732, 65535"
"  %4802 = and i32 %4732, 65535" -> "  %4804 = add nuw nsw i32 %4802, %4803"
"  %4803 = and i32 %4637, 65535"
"  %4803 = and i32 %4637, 65535" -> "  %4804 = add nuw nsw i32 %4802, %4803"
"  %4804 = add nuw nsw i32 %4802, %4803"
"  %4804 = add nuw nsw i32 %4802, %4803" -> "  %4811 = and i32 %4804, 65535""  %4804 = add nuw nsw i32 %4802, %4803" -> "  %4808 = lshr i32 %4804, 16"
"  %4805 = and i32 %4734, 65535"
"  %4805 = and i32 %4734, 65535" -> "  %4807 = add nuw nsw i32 %4805, %4806"
"  %4806 = lshr i32 %4637, 16"
"  %4806 = lshr i32 %4637, 16" -> "  %4807 = add nuw nsw i32 %4805, %4806"
"  %4807 = add nuw nsw i32 %4805, %4806"
"  %4807 = add nuw nsw i32 %4805, %4806" -> "  %4817 = lshr i32 %4807, 16""  %4807 = add nuw nsw i32 %4805, %4806" -> "  %4809 = and i32 %4807, 65535"
"  %4808 = lshr i32 %4804, 16"
"  %4808 = lshr i32 %4804, 16" -> "  %4810 = add nuw nsw i32 %4809, %4808"
"  %4809 = and i32 %4807, 65535"
"  %4809 = and i32 %4807, 65535" -> "  %4810 = add nuw nsw i32 %4809, %4808"
"  %4810 = add nuw nsw i32 %4809, %4808"
"  %4810 = add nuw nsw i32 %4809, %4808" -> "  %4819 = lshr i32 %4810, 16""  %4810 = add nuw nsw i32 %4809, %4808" -> "  %4814 = and i32 %4810, 65535"
"  %4811 = and i32 %4804, 65535"
"  %4811 = and i32 %4804, 65535" -> "  %4812 = add nuw nsw i32 %4801, %4811"
"  %4812 = add nuw nsw i32 %4801, %4811"
"  %4812 = add nuw nsw i32 %4801, %4811" -> "  %4917 = and i32 %4812, 65535""  %4812 = add nuw nsw i32 %4801, %4811" -> "  %4813 = lshr i32 %4812, 16"
"  %4813 = lshr i32 %4812, 16"
"  %4813 = lshr i32 %4812, 16" -> "  %4815 = add nuw nsw i32 %4814, %4813"
"  %4814 = and i32 %4810, 65535"
"  %4814 = and i32 %4810, 65535" -> "  %4815 = add nuw nsw i32 %4814, %4813"
"  %4815 = add nuw nsw i32 %4814, %4813"
"  %4815 = add nuw nsw i32 %4814, %4813" -> "  %4920 = and i32 %4815, 65535""  %4815 = add nuw nsw i32 %4814, %4813" -> "  %4821 = lshr i32 %4815, 16"
"  %4816 = and i32 %4776, 65535"
"  %4816 = and i32 %4776, 65535" -> "  %4818 = add nuw nsw i32 %4816, %4817"
"  %4817 = lshr i32 %4807, 16"
"  %4817 = lshr i32 %4807, 16" -> "  %4818 = add nuw nsw i32 %4816, %4817"
"  %4818 = add nuw nsw i32 %4816, %4817"
"  %4818 = add nuw nsw i32 %4816, %4817" -> "  %4820 = add nuw nsw i32 %4818, %4819"
"  %4819 = lshr i32 %4810, 16"
"  %4819 = lshr i32 %4810, 16" -> "  %4820 = add nuw nsw i32 %4818, %4819"
"  %4820 = add nuw nsw i32 %4818, %4819"
"  %4820 = add nuw nsw i32 %4818, %4819" -> "  %4822 = add nuw nsw i32 %4820, %4821"
"  %4821 = lshr i32 %4815, 16"
"  %4821 = lshr i32 %4815, 16" -> "  %4822 = add nuw nsw i32 %4820, %4821"
"  %4822 = add nuw nsw i32 %4820, %4821"
"  %4822 = add nuw nsw i32 %4820, %4821" -> "  %5056 = and i32 %4822, 65535""  %4822 = add nuw nsw i32 %4820, %4821" -> "  %4824 = lshr i32 %4822, 16"
"  %4823 = and i32 %4782, 65535"
"  %4823 = and i32 %4782, 65535" -> "  %4825 = add nuw nsw i32 %4824, %4823"
"  %4824 = lshr i32 %4822, 16"
"  %4824 = lshr i32 %4822, 16" -> "  %4825 = add nuw nsw i32 %4824, %4823"
"  %4825 = add nuw nsw i32 %4824, %4823"
"  %4825 = add nuw nsw i32 %4824, %4823" -> "  %5059 = and i32 %4825, 65535""  %4825 = add nuw nsw i32 %4824, %4823" -> "  %4826 = lshr i32 %4825, 16"
"  %4826 = lshr i32 %4825, 16"
"  %4826 = lshr i32 %4825, 16" -> "  %4827 = add i32 %4789, %4826"
"  %4827 = add i32 %4789, %4826"
"  %4827 = add i32 %4789, %4826" -> "  %5065 = and i32 %4827, 65535""  %4827 = add i32 %4789, %4826" -> "  %5068 = lshr i32 %4827, 16"
"  %4828 = lshr i32 %4646, 16"
"  %4828 = lshr i32 %4646, 16" -> "  %4829 = add nuw i32 %4655, %4828"
"  %4829 = add nuw i32 %4655, %4828"
"  %4829 = add nuw i32 %4655, %4828" -> "  %4833 = and i32 %4829, -65536""  %4829 = add nuw i32 %4655, %4828" -> "  %4831 = and i32 %4829, 65535"
"  %4830 = lshr i32 %4648, 16"
"  %4830 = lshr i32 %4648, 16" -> "  %4832 = add nuw nsw i32 %4830, %4831"
"  %4831 = and i32 %4829, 65535"
"  %4831 = and i32 %4829, 65535" -> "  %4832 = add nuw nsw i32 %4830, %4831"
"  %4832 = add nuw nsw i32 %4830, %4831"
"  %4832 = add nuw nsw i32 %4830, %4831" -> "  %4834 = add i32 %4832, %4833"
"  %4833 = and i32 %4829, -65536"
"  %4833 = and i32 %4829, -65536" -> "  %4834 = add i32 %4832, %4833"
"  %4834 = add i32 %4832, %4833"
"  %4834 = add i32 %4832, %4833" -> "  %4842 = and i32 %4834, 65535""  %4834 = add i32 %4832, %4833" -> "  %4845 = lshr i32 %4834, 16"
"  %4835 = lshr i32 %4709, 16"
"  %4835 = lshr i32 %4709, 16" -> "  %4836 = add nuw i32 %4718, %4835"
"  %4836 = add nuw i32 %4718, %4835"
"  %4836 = add nuw i32 %4718, %4835" -> "  %4840 = and i32 %4836, -65536""  %4836 = add nuw i32 %4718, %4835" -> "  %4838 = and i32 %4836, 65535"
"  %4837 = lshr i32 %4711, 16"
"  %4837 = lshr i32 %4711, 16" -> "  %4839 = add nuw nsw i32 %4837, %4838"
"  %4838 = and i32 %4836, 65535"
"  %4838 = and i32 %4836, 65535" -> "  %4839 = add nuw nsw i32 %4837, %4838"
"  %4839 = add nuw nsw i32 %4837, %4838"
"  %4839 = add nuw nsw i32 %4837, %4838" -> "  %4841 = add i32 %4839, %4840"
"  %4840 = and i32 %4836, -65536"
"  %4840 = and i32 %4836, -65536" -> "  %4841 = add i32 %4839, %4840"
"  %4841 = add i32 %4839, %4840"
"  %4841 = add i32 %4839, %4840" -> "  %4848 = add i32 %4841, %4847"
"  %4842 = and i32 %4834, 65535"
"  %4842 = and i32 %4834, 65535" -> "  %4843 = add nuw nsw i32 %4842, %4729"
"  %4843 = add nuw nsw i32 %4842, %4729"
"  %4843 = add nuw nsw i32 %4842, %4729" -> "  %4861 = and i32 %4843, 65535""  %4843 = add nuw nsw i32 %4842, %4729" -> "  %4850 = lshr i32 %4843, 16"
"  %4844 = and i32 %4711, 65535"
"  %4844 = and i32 %4711, 65535" -> "  %4846 = add nuw nsw i32 %4845, %4844"
"  %4845 = lshr i32 %4834, 16"
"  %4845 = lshr i32 %4834, 16" -> "  %4846 = add nuw nsw i32 %4845, %4844"
"  %4846 = add nuw nsw i32 %4845, %4844"
"  %4846 = add nuw nsw i32 %4845, %4844" -> "  %4849 = and i32 %4846, 65535""  %4846 = add nuw nsw i32 %4845, %4844" -> "  %4847 = lshr i32 %4846, 16"
"  %4847 = lshr i32 %4846, 16"
"  %4847 = lshr i32 %4846, 16" -> "  %4848 = add i32 %4841, %4847"
"  %4848 = add i32 %4841, %4847"
"  %4848 = add i32 %4841, %4847" -> "  %4853 = add i32 %4848, %4852"
"  %4849 = and i32 %4846, 65535"
"  %4849 = and i32 %4846, 65535" -> "  %4851 = add nuw nsw i32 %4849, %4850"
"  %4850 = lshr i32 %4843, 16"
"  %4850 = lshr i32 %4843, 16" -> "  %4851 = add nuw nsw i32 %4849, %4850"
"  %4851 = add nuw nsw i32 %4849, %4850"
"  %4851 = add nuw nsw i32 %4849, %4850" -> "  %4863 = and i32 %4851, 65535""  %4851 = add nuw nsw i32 %4849, %4850" -> "  %4852 = lshr i32 %4851, 16"
"  %4852 = lshr i32 %4851, 16"
"  %4852 = lshr i32 %4851, 16" -> "  %4853 = add i32 %4848, %4852"
"  %4853 = add i32 %4848, %4852"
"  %4853 = add i32 %4848, %4852" -> "  %4882 = lshr i32 %4853, 16""  %4853 = add i32 %4848, %4852" -> "  %4880 = and i32 %4853, 65535"
"  %4854 = lshr i32 %4670, 16"
"  %4854 = lshr i32 %4670, 16" -> "  %4855 = add nuw i32 %4854, %4678"
"  %4855 = add nuw i32 %4854, %4678"
"  %4855 = add nuw i32 %4854, %4678" -> "  %4859 = and i32 %4855, -65536""  %4855 = add nuw i32 %4854, %4678" -> "  %4857 = and i32 %4855, 65535"
"  %4856 = lshr i32 %4672, 16"
"  %4856 = lshr i32 %4672, 16" -> "  %4858 = add nuw nsw i32 %4856, %4857"
"  %4857 = and i32 %4855, 65535"
"  %4857 = and i32 %4855, 65535" -> "  %4858 = add nuw nsw i32 %4856, %4857"
"  %4858 = add nuw nsw i32 %4856, %4857"
"  %4858 = add nuw nsw i32 %4856, %4857" -> "  %4860 = add i32 %4858, %4859"
"  %4859 = and i32 %4855, -65536"
"  %4859 = and i32 %4855, -65536" -> "  %4860 = add i32 %4858, %4859"
"  %4860 = add i32 %4858, %4859"
"  %4860 = add i32 %4858, %4859" -> "  %4867 = add i32 %4860, %4866"
"  %4861 = and i32 %4843, 65535"
"  %4861 = and i32 %4843, 65535" -> "  %4862 = add nuw nsw i32 %4687, %4861"
"  %4862 = add nuw nsw i32 %4687, %4861"
"  %4862 = add nuw nsw i32 %4687, %4861" -> "  %4916 = and i32 %4862, 65535""  %4862 = add nuw nsw i32 %4687, %4861" -> "  %4869 = lshr i32 %4862, 16"
"  %4863 = and i32 %4851, 65535"
"  %4863 = and i32 %4851, 65535" -> "  %4865 = add nuw nsw i32 %4864, %4863"
"  %4864 = and i32 %4672, 65535"
"  %4864 = and i32 %4672, 65535" -> "  %4865 = add nuw nsw i32 %4864, %4863"
"  %4865 = add nuw nsw i32 %4864, %4863"
"  %4865 = add nuw nsw i32 %4864, %4863" -> "  %4868 = and i32 %4865, 65535""  %4865 = add nuw nsw i32 %4864, %4863" -> "  %4866 = lshr i32 %4865, 16"
"  %4866 = lshr i32 %4865, 16"
"  %4866 = lshr i32 %4865, 16" -> "  %4867 = add i32 %4860, %4866"
"  %4867 = add i32 %4860, %4866"
"  %4867 = add i32 %4860, %4866" -> "  %4872 = add i32 %4867, %4871"
"  %4868 = and i32 %4865, 65535"
"  %4868 = and i32 %4865, 65535" -> "  %4870 = add nuw nsw i32 %4868, %4869"
"  %4869 = lshr i32 %4862, 16"
"  %4869 = lshr i32 %4862, 16" -> "  %4870 = add nuw nsw i32 %4868, %4869"
"  %4870 = add nuw nsw i32 %4868, %4869"
"  %4870 = add nuw nsw i32 %4868, %4869" -> "  %4919 = and i32 %4870, 65535""  %4870 = add nuw nsw i32 %4868, %4869" -> "  %4871 = lshr i32 %4870, 16"
"  %4871 = lshr i32 %4870, 16"
"  %4871 = lshr i32 %4870, 16" -> "  %4872 = add i32 %4867, %4871"
"  %4872 = add i32 %4867, %4871"
"  %4872 = add i32 %4867, %4871" -> "  %4896 = lshr i32 %4872, 16""  %4872 = add i32 %4867, %4871" -> "  %4893 = and i32 %4872, 65535"
"  %4873 = lshr i32 %4746, 16"
"  %4873 = lshr i32 %4746, 16" -> "  %4874 = add nuw i32 %4873, %4755"
"  %4874 = add nuw i32 %4873, %4755"
"  %4874 = add nuw i32 %4873, %4755" -> "  %4878 = and i32 %4874, -65536""  %4874 = add nuw i32 %4873, %4755" -> "  %4876 = and i32 %4874, 65535"
"  %4875 = lshr i32 %4748, 16"
"  %4875 = lshr i32 %4748, 16" -> "  %4877 = add nuw nsw i32 %4875, %4876"
"  %4876 = and i32 %4874, 65535"
"  %4876 = and i32 %4874, 65535" -> "  %4877 = add nuw nsw i32 %4875, %4876"
"  %4877 = add nuw nsw i32 %4875, %4876"
"  %4877 = add nuw nsw i32 %4875, %4876" -> "  %4879 = add i32 %4877, %4878"
"  %4878 = and i32 %4874, -65536"
"  %4878 = and i32 %4874, -65536" -> "  %4879 = add i32 %4877, %4878"
"  %4879 = add i32 %4877, %4878"
"  %4879 = add i32 %4877, %4878" -> "  %4886 = add i32 %4879, %4885"
"  %4880 = and i32 %4853, 65535"
"  %4880 = and i32 %4853, 65535" -> "  %4881 = add nuw nsw i32 %4880, %4766"
"  %4881 = add nuw nsw i32 %4880, %4766"
"  %4881 = add nuw nsw i32 %4880, %4766" -> "  %4892 = and i32 %4881, 65535""  %4881 = add nuw nsw i32 %4880, %4766" -> "  %4888 = lshr i32 %4881, 16"
"  %4882 = lshr i32 %4853, 16"
"  %4882 = lshr i32 %4853, 16" -> "  %4884 = add nuw nsw i32 %4883, %4882"
"  %4883 = and i32 %4748, 65535"
"  %4883 = and i32 %4748, 65535" -> "  %4884 = add nuw nsw i32 %4883, %4882"
"  %4884 = add nuw nsw i32 %4883, %4882"
"  %4884 = add nuw nsw i32 %4883, %4882" -> "  %4887 = and i32 %4884, 65535""  %4884 = add nuw nsw i32 %4883, %4882" -> "  %4885 = lshr i32 %4884, 16"
"  %4885 = lshr i32 %4884, 16"
"  %4885 = lshr i32 %4884, 16" -> "  %4886 = add i32 %4879, %4885"
"  %4886 = add i32 %4879, %4885"
"  %4886 = add i32 %4879, %4885" -> "  %4891 = add i32 %4886, %4890"
"  %4887 = and i32 %4884, 65535"
"  %4887 = and i32 %4884, 65535" -> "  %4889 = add nuw nsw i32 %4887, %4888"
"  %4888 = lshr i32 %4881, 16"
"  %4888 = lshr i32 %4881, 16" -> "  %4889 = add nuw nsw i32 %4887, %4888"
"  %4889 = add nuw nsw i32 %4887, %4888"
"  %4889 = add nuw nsw i32 %4887, %4888" -> "  %4895 = and i32 %4889, 65535""  %4889 = add nuw nsw i32 %4887, %4888" -> "  %4890 = lshr i32 %4889, 16"
"  %4890 = lshr i32 %4889, 16"
"  %4890 = lshr i32 %4889, 16" -> "  %4891 = add i32 %4886, %4890"
"  %4891 = add i32 %4886, %4890"
"  %4891 = add i32 %4886, %4890" -> "  %4899 = add i32 %4891, %4898"
"  %4892 = and i32 %4881, 65535"
"  %4892 = and i32 %4881, 65535" -> "  %4894 = add nuw nsw i32 %4893, %4892"
"  %4893 = and i32 %4872, 65535"
"  %4893 = and i32 %4872, 65535" -> "  %4894 = add nuw nsw i32 %4893, %4892"
"  %4894 = add nuw nsw i32 %4893, %4892"
"  %4894 = add nuw nsw i32 %4893, %4892" -> "  %4930 = and i32 %4894, 65535""  %4894 = add nuw nsw i32 %4893, %4892" -> "  %4901 = lshr i32 %4894, 16"
"  %4895 = and i32 %4889, 65535"
"  %4895 = and i32 %4889, 65535" -> "  %4897 = add nuw nsw i32 %4896, %4895"
"  %4896 = lshr i32 %4872, 16"
"  %4896 = lshr i32 %4872, 16" -> "  %4897 = add nuw nsw i32 %4896, %4895"
"  %4897 = add nuw nsw i32 %4896, %4895"
"  %4897 = add nuw nsw i32 %4896, %4895" -> "  %4900 = and i32 %4897, 65535""  %4897 = add nuw nsw i32 %4896, %4895" -> "  %4898 = lshr i32 %4897, 16"
"  %4898 = lshr i32 %4897, 16"
"  %4898 = lshr i32 %4897, 16" -> "  %4899 = add i32 %4891, %4898"
"  %4899 = add i32 %4891, %4898"
"  %4899 = add i32 %4891, %4898" -> "  %4904 = add i32 %4899, %4903"
"  %4900 = and i32 %4897, 65535"
"  %4900 = and i32 %4897, 65535" -> "  %4902 = add nuw nsw i32 %4900, %4901"
"  %4901 = lshr i32 %4894, 16"
"  %4901 = lshr i32 %4894, 16" -> "  %4902 = add nuw nsw i32 %4900, %4901"
"  %4902 = add nuw nsw i32 %4900, %4901"
"  %4902 = add nuw nsw i32 %4900, %4901" -> "  %4937 = and i32 %4902, 65535""  %4902 = add nuw nsw i32 %4900, %4901" -> "  %4903 = lshr i32 %4902, 16"
"  %4903 = lshr i32 %4902, 16"
"  %4903 = lshr i32 %4902, 16" -> "  %4904 = add i32 %4899, %4903"
"  %4904 = add i32 %4899, %4903"
"  %4904 = add i32 %4899, %4903" -> "  %4941 = add i32 %4904, %4940"
"  %4905 = and i32 %4795, 65535"
"  %4905 = and i32 %4795, 65535" -> "  %4906 = add nuw nsw i32 %4905, %4793"
"  %4906 = add nuw nsw i32 %4905, %4793"
"  %4906 = add nuw nsw i32 %4905, %4793" -> "  %5262 = and i32 %4906, 65535""  %4906 = add nuw nsw i32 %4905, %4793" -> "  %4910 = lshr i32 %4906, 16"
"  %4907 = and i32 %4648, 65535"
"  %4907 = and i32 %4648, 65535" -> "  %4909 = add nuw nsw i32 %4908, %4907"
"  %4908 = and i32 %4798, 65535"
"  %4908 = and i32 %4798, 65535" -> "  %4909 = add nuw nsw i32 %4908, %4907"
"  %4909 = add nuw nsw i32 %4908, %4907"
"  %4909 = add nuw nsw i32 %4908, %4907" -> "  %4913 = lshr i32 %4909, 16""  %4909 = add nuw nsw i32 %4908, %4907" -> "  %4911 = and i32 %4909, 65535"
"  %4910 = lshr i32 %4906, 16"
"  %4910 = lshr i32 %4906, 16" -> "  %4912 = add nuw nsw i32 %4911, %4910"
"  %4911 = and i32 %4909, 65535"
"  %4911 = and i32 %4909, 65535" -> "  %4912 = add nuw nsw i32 %4911, %4910"
"  %4912 = add nuw nsw i32 %4911, %4910"
"  %4912 = add nuw nsw i32 %4911, %4910" -> "  %5265 = and i32 %4912, 65535""  %4912 = add nuw nsw i32 %4911, %4910" -> "  %4914 = lshr i32 %4912, 16"
"  %4913 = lshr i32 %4909, 16"
"  %4913 = lshr i32 %4909, 16" -> "  %4915 = add nuw nsw i32 %4914, %4913"
"  %4914 = lshr i32 %4912, 16"
"  %4914 = lshr i32 %4912, 16" -> "  %4915 = add nuw nsw i32 %4914, %4913"
"  %4915 = add nuw nsw i32 %4914, %4913"
"  %4915 = add nuw nsw i32 %4914, %4913" -> "  %4926 = add nuw nsw i32 %4915, %4925"
"  %4916 = and i32 %4862, 65535"
"  %4916 = and i32 %4862, 65535" -> "  %4918 = add nuw nsw i32 %4917, %4916"
"  %4917 = and i32 %4812, 65535"
"  %4917 = and i32 %4812, 65535" -> "  %4918 = add nuw nsw i32 %4917, %4916"
"  %4918 = add nuw nsw i32 %4917, %4916"
"  %4918 = add nuw nsw i32 %4917, %4916" -> "  %4925 = and i32 %4918, 65535""  %4918 = add nuw nsw i32 %4917, %4916" -> "  %4922 = lshr i32 %4918, 16"
"  %4919 = and i32 %4870, 65535"
"  %4919 = and i32 %4870, 65535" -> "  %4921 = add nuw nsw i32 %4920, %4919"
"  %4920 = and i32 %4815, 65535"
"  %4920 = and i32 %4815, 65535" -> "  %4921 = add nuw nsw i32 %4920, %4919"
"  %4921 = add nuw nsw i32 %4920, %4919"
"  %4921 = add nuw nsw i32 %4920, %4919" -> "  %4931 = lshr i32 %4921, 16""  %4921 = add nuw nsw i32 %4920, %4919" -> "  %4923 = and i32 %4921, 65535"
"  %4922 = lshr i32 %4918, 16"
"  %4922 = lshr i32 %4918, 16" -> "  %4924 = add nuw nsw i32 %4923, %4922"
"  %4923 = and i32 %4921, 65535"
"  %4923 = and i32 %4921, 65535" -> "  %4924 = add nuw nsw i32 %4923, %4922"
"  %4924 = add nuw nsw i32 %4923, %4922"
"  %4924 = add nuw nsw i32 %4923, %4922" -> "  %4933 = lshr i32 %4924, 16""  %4924 = add nuw nsw i32 %4923, %4922" -> "  %4928 = and i32 %4924, 65535"
"  %4925 = and i32 %4918, 65535"
"  %4925 = and i32 %4918, 65535" -> "  %4926 = add nuw nsw i32 %4915, %4925"
"  %4926 = add nuw nsw i32 %4915, %4925"
"  %4926 = add nuw nsw i32 %4915, %4925" -> "  %5282 = and i32 %4926, 65535""  %4926 = add nuw nsw i32 %4915, %4925" -> "  %4927 = lshr i32 %4926, 16"
"  %4927 = lshr i32 %4926, 16"
"  %4927 = lshr i32 %4926, 16" -> "  %4929 = add nuw nsw i32 %4928, %4927"
"  %4928 = and i32 %4924, 65535"
"  %4928 = and i32 %4924, 65535" -> "  %4929 = add nuw nsw i32 %4928, %4927"
"  %4929 = add nuw nsw i32 %4928, %4927"
"  %4929 = add nuw nsw i32 %4928, %4927" -> "  %8504 = add i32 %8503, %4929""  %4929 = add nuw nsw i32 %4928, %4927" -> "  %5285 = and i32 %4929, 65535""  %4929 = add nuw nsw i32 %4928, %4927" -> "  %4935 = lshr i32 %4929, 16"
"  %4930 = and i32 %4894, 65535"
"  %4930 = and i32 %4894, 65535" -> "  %4932 = add nuw nsw i32 %4931, %4930"
"  %4931 = lshr i32 %4921, 16"
"  %4931 = lshr i32 %4921, 16" -> "  %4932 = add nuw nsw i32 %4931, %4930"
"  %4932 = add nuw nsw i32 %4931, %4930"
"  %4932 = add nuw nsw i32 %4931, %4930" -> "  %4934 = add nuw nsw i32 %4932, %4933"
"  %4933 = lshr i32 %4924, 16"
"  %4933 = lshr i32 %4924, 16" -> "  %4934 = add nuw nsw i32 %4932, %4933"
"  %4934 = add nuw nsw i32 %4932, %4933"
"  %4934 = add nuw nsw i32 %4932, %4933" -> "  %4936 = add nuw nsw i32 %4934, %4935"
"  %4935 = lshr i32 %4929, 16"
"  %4935 = lshr i32 %4929, 16" -> "  %4936 = add nuw nsw i32 %4934, %4935"
"  %4936 = add nuw nsw i32 %4934, %4935"
"  %4936 = add nuw nsw i32 %4934, %4935" -> "  %5094 = and i32 %4936, 65535""  %4936 = add nuw nsw i32 %4934, %4935" -> "  %4938 = lshr i32 %4936, 16"
"  %4937 = and i32 %4902, 65535"
"  %4937 = and i32 %4902, 65535" -> "  %4939 = add nuw nsw i32 %4938, %4937"
"  %4938 = lshr i32 %4936, 16"
"  %4938 = lshr i32 %4936, 16" -> "  %4939 = add nuw nsw i32 %4938, %4937"
"  %4939 = add nuw nsw i32 %4938, %4937"
"  %4939 = add nuw nsw i32 %4938, %4937" -> "  %5097 = and i32 %4939, 65535""  %4939 = add nuw nsw i32 %4938, %4937" -> "  %4940 = lshr i32 %4939, 16"
"  %4940 = lshr i32 %4939, 16"
"  %4940 = lshr i32 %4939, 16" -> "  %4941 = add i32 %4904, %4940"
"  %4941 = add i32 %4904, %4940"
"  %4941 = add i32 %4904, %4940" -> "  %5103 = and i32 %4941, 65535""  %4941 = add i32 %4904, %4940" -> "  %5106 = lshr i32 %4941, 16"
"  %4942 = mul nuw i32 %4638, %4638"
"  %4942 = mul nuw i32 %4638, %4638" -> "  %4943 = lshr i32 %4942, 16""  %4942 = mul nuw i32 %4638, %4638" -> "  %5055 = and i32 %4942, 65535"
"  %4943 = lshr i32 %4942, 16"
"  %4943 = lshr i32 %4942, 16" -> "  %4946 = add nuw nsw i32 %4945, %4943"
"  %4944 = mul nuw i32 %4639, %4638"
"  %4944 = mul nuw i32 %4639, %4638" -> "  %4950 = add nuw i32 %4949, %4944""  %4944 = mul nuw i32 %4639, %4638" -> "  %4947 = and i32 %4944, -65536""  %4944 = mul nuw i32 %4639, %4638" -> "  %4945 = and i32 %4944, 65535"
"  %4945 = and i32 %4944, 65535"
"  %4945 = and i32 %4944, 65535" -> "  %4946 = add nuw nsw i32 %4945, %4943"
"  %4946 = add nuw nsw i32 %4945, %4943"
"  %4946 = add nuw nsw i32 %4945, %4943" -> "  %4948 = add nuw i32 %4946, %4947"
"  %4947 = and i32 %4944, -65536"
"  %4947 = and i32 %4944, -65536" -> "  %4948 = add nuw i32 %4946, %4947"
"  %4948 = add nuw i32 %4946, %4947"
"  %4948 = add nuw i32 %4946, %4947" -> "  %4951 = lshr i32 %4948, 16""  %4948 = add nuw i32 %4946, %4947" -> "  %4949 = and i32 %4948, 65535"
"  %4949 = and i32 %4948, 65535"
"  %4949 = and i32 %4948, 65535" -> "  %4950 = add nuw i32 %4949, %4944"
"  %4950 = add nuw i32 %4949, %4944"
"  %4950 = add nuw i32 %4949, %4944" -> "  %5058 = and i32 %4950, 65535""  %4950 = add nuw i32 %4949, %4944" -> "  %4954 = lshr i32 %4950, 16"
"  %4951 = lshr i32 %4948, 16"
"  %4951 = lshr i32 %4948, 16" -> "  %4953 = add nuw i32 %4951, %4952"
"  %4952 = mul nuw i32 %4639, %4639"
"  %4952 = mul nuw i32 %4639, %4639" -> "  %4953 = add nuw i32 %4951, %4952"
"  %4953 = add nuw i32 %4951, %4952"
"  %4953 = add nuw i32 %4951, %4952" -> "  %4957 = and i32 %4953, -65536""  %4953 = add nuw i32 %4951, %4952" -> "  %4955 = and i32 %4953, 65535"
"  %4954 = lshr i32 %4950, 16"
"  %4954 = lshr i32 %4950, 16" -> "  %4956 = add nuw nsw i32 %4954, %4955"
"  %4955 = and i32 %4953, 65535"
"  %4955 = and i32 %4953, 65535" -> "  %4956 = add nuw nsw i32 %4954, %4955"
"  %4956 = add nuw nsw i32 %4954, %4955"
"  %4956 = add nuw nsw i32 %4954, %4955" -> "  %4958 = add i32 %4956, %4957"
"  %4957 = and i32 %4953, -65536"
"  %4957 = and i32 %4953, -65536" -> "  %4958 = add i32 %4956, %4957"
"  %4958 = add i32 %4956, %4957"
"  %4958 = add i32 %4956, %4957" -> "  %4983 = and i32 %4958, 65535""  %4958 = add i32 %4956, %4957" -> "  %4978 = lshr i32 %4958, 16"
"  %4959 = mul nuw i32 %4661, %4638"
"  %4959 = mul nuw i32 %4661, %4638" -> "  %4982 = and i32 %4959, 65535""  %4959 = mul nuw i32 %4661, %4638" -> "  %4960 = lshr i32 %4959, 16"
"  %4960 = lshr i32 %4959, 16"
"  %4960 = lshr i32 %4959, 16" -> "  %4966 = add nuw i32 %4960, %4961""  %4960 = lshr i32 %4959, 16" -> "  %4963 = add nuw i32 %4960, %4962"
"  %4961 = mul nuw i32 %4664, %4638"
"  %4961 = mul nuw i32 %4664, %4638" -> "  %4966 = add nuw i32 %4960, %4961""  %4961 = mul nuw i32 %4664, %4638" -> "  %4965 = add nuw i32 %4964, %4961"
"  %4962 = mul nuw i32 %4661, %4639"
"  %4962 = mul nuw i32 %4661, %4639" -> "  %4968 = add nuw i32 %4967, %4962""  %4962 = mul nuw i32 %4661, %4639" -> "  %4963 = add nuw i32 %4960, %4962"
"  %4963 = add nuw i32 %4960, %4962"
"  %4963 = add nuw i32 %4960, %4962" -> "  %4990 = lshr i32 %4963, 16""  %4963 = add nuw i32 %4960, %4962" -> "  %4964 = and i32 %4963, 65535"
"  %4964 = and i32 %4963, 65535"
"  %4964 = and i32 %4963, 65535" -> "  %4965 = add nuw i32 %4964, %4961"
"  %4965 = add nuw i32 %4964, %4961"
"  %4965 = add nuw i32 %4964, %4961" -> "  %5000 = and i32 %4965, 65535""  %4965 = add nuw i32 %4964, %4961" -> "  %4992 = lshr i32 %4965, 16"
"  %4966 = add nuw i32 %4960, %4961"
"  %4966 = add nuw i32 %4960, %4961" -> "  %4969 = lshr i32 %4966, 16""  %4966 = add nuw i32 %4960, %4961" -> "  %4967 = and i32 %4966, 65535"
"  %4967 = and i32 %4966, 65535"
"  %4967 = and i32 %4966, 65535" -> "  %4968 = add nuw i32 %4967, %4962"
"  %4968 = add nuw i32 %4967, %4962"
"  %4968 = add nuw i32 %4967, %4962" -> "  %4977 = and i32 %4968, 65535""  %4968 = add nuw i32 %4967, %4962" -> "  %4970 = lshr i32 %4968, 16"
"  %4969 = lshr i32 %4966, 16"
"  %4969 = lshr i32 %4966, 16" -> "  %4972 = add nuw i32 %4969, %4971"
"  %4970 = lshr i32 %4968, 16"
"  %4970 = lshr i32 %4968, 16" -> "  %4974 = add nuw nsw i32 %4970, %4973"
"  %4971 = mul nuw i32 %4664, %4639"
"  %4971 = mul nuw i32 %4664, %4639" -> "  %4991 = add nuw i32 %4990, %4971""  %4971 = mul nuw i32 %4664, %4639" -> "  %4972 = add nuw i32 %4969, %4971"
"  %4972 = add nuw i32 %4969, %4971"
"  %4972 = add nuw i32 %4969, %4971" -> "  %4975 = and i32 %4972, -65536""  %4972 = add nuw i32 %4969, %4971" -> "  %4973 = and i32 %4972, 65535"
"  %4973 = and i32 %4972, 65535"
"  %4973 = and i32 %4972, 65535" -> "  %4974 = add nuw nsw i32 %4970, %4973"
"  %4974 = add nuw nsw i32 %4970, %4973"
"  %4974 = add nuw nsw i32 %4970, %4973" -> "  %4976 = add i32 %4974, %4975"
"  %4975 = and i32 %4972, -65536"
"  %4975 = and i32 %4972, -65536" -> "  %4976 = add i32 %4974, %4975"
"  %4976 = add i32 %4974, %4975"
"  %4976 = add i32 %4974, %4975" -> "  %4981 = add i32 %4976, %4980"
"  %4977 = and i32 %4968, 65535"
"  %4977 = and i32 %4968, 65535" -> "  %4979 = add nuw nsw i32 %4977, %4978"
"  %4978 = lshr i32 %4958, 16"
"  %4978 = lshr i32 %4958, 16" -> "  %4979 = add nuw nsw i32 %4977, %4978"
"  %4979 = add nuw nsw i32 %4977, %4978"
"  %4979 = add nuw nsw i32 %4977, %4978" -> "  %4986 = and i32 %4979, 65535""  %4979 = add nuw nsw i32 %4977, %4978" -> "  %4980 = lshr i32 %4979, 16"
"  %4980 = lshr i32 %4979, 16"
"  %4980 = lshr i32 %4979, 16" -> "  %4981 = add i32 %4976, %4980"
"  %4981 = add i32 %4976, %4980"
"  %4981 = add i32 %4976, %4980" -> "  %4989 = add i32 %4981, %4988"
"  %4982 = and i32 %4959, 65535"
"  %4982 = and i32 %4959, 65535" -> "  %4998 = add nuw nsw i32 %4997, %4982""  %4982 = and i32 %4959, 65535" -> "  %4984 = add nuw nsw i32 %4983, %4982"
"  %4983 = and i32 %4958, 65535"
"  %4983 = and i32 %4958, 65535" -> "  %4984 = add nuw nsw i32 %4983, %4982"
"  %4984 = add nuw nsw i32 %4983, %4982"
"  %4984 = add nuw nsw i32 %4983, %4982" -> "  %4997 = and i32 %4984, 65535""  %4984 = add nuw nsw i32 %4983, %4982" -> "  %4985 = lshr i32 %4984, 16"
"  %4985 = lshr i32 %4984, 16"
"  %4985 = lshr i32 %4984, 16" -> "  %4987 = add nuw nsw i32 %4986, %4985"
"  %4986 = and i32 %4979, 65535"
"  %4986 = and i32 %4979, 65535" -> "  %4987 = add nuw nsw i32 %4986, %4985"
"  %4987 = add nuw nsw i32 %4986, %4985"
"  %4987 = add nuw nsw i32 %4986, %4985" -> "  %4999 = and i32 %4987, 65535""  %4987 = add nuw nsw i32 %4986, %4985" -> "  %4988 = lshr i32 %4987, 16"
"  %4988 = lshr i32 %4987, 16"
"  %4988 = lshr i32 %4987, 16" -> "  %4989 = add i32 %4981, %4988"
"  %4989 = add i32 %4981, %4988"
"  %4989 = add i32 %4981, %4988" -> "  %5030 = lshr i32 %4989, 16""  %4989 = add i32 %4981, %4988" -> "  %5026 = and i32 %4989, 65535"
"  %4990 = lshr i32 %4963, 16"
"  %4990 = lshr i32 %4963, 16" -> "  %4991 = add nuw i32 %4990, %4971"
"  %4991 = add nuw i32 %4990, %4971"
"  %4991 = add nuw i32 %4990, %4971" -> "  %4995 = and i32 %4991, -65536""  %4991 = add nuw i32 %4990, %4971" -> "  %4993 = and i32 %4991, 65535"
"  %4992 = lshr i32 %4965, 16"
"  %4992 = lshr i32 %4965, 16" -> "  %4994 = add nuw nsw i32 %4992, %4993"
"  %4993 = and i32 %4991, 65535"
"  %4993 = and i32 %4991, 65535" -> "  %4994 = add nuw nsw i32 %4992, %4993"
"  %4994 = add nuw nsw i32 %4992, %4993"
"  %4994 = add nuw nsw i32 %4992, %4993" -> "  %4996 = add i32 %4994, %4995"
"  %4995 = and i32 %4991, -65536"
"  %4995 = and i32 %4991, -65536" -> "  %4996 = add i32 %4994, %4995"
"  %4996 = add i32 %4994, %4995"
"  %4996 = add i32 %4994, %4995" -> "  %5003 = add i32 %4996, %5002"
"  %4997 = and i32 %4984, 65535"
"  %4997 = and i32 %4984, 65535" -> "  %4998 = add nuw nsw i32 %4997, %4982"
"  %4998 = add nuw nsw i32 %4997, %4982"
"  %4998 = add nuw nsw i32 %4997, %4982" -> "  %5064 = and i32 %4998, 65535""  %4998 = add nuw nsw i32 %4997, %4982" -> "  %5005 = lshr i32 %4998, 16"
"  %4999 = and i32 %4987, 65535"
"  %4999 = and i32 %4987, 65535" -> "  %5001 = add nuw nsw i32 %4999, %5000"
"  %5000 = and i32 %4965, 65535"
"  %5000 = and i32 %4965, 65535" -> "  %5001 = add nuw nsw i32 %4999, %5000"
"  %5001 = add nuw nsw i32 %4999, %5000"
"  %5001 = add nuw nsw i32 %4999, %5000" -> "  %5004 = and i32 %5001, 65535""  %5001 = add nuw nsw i32 %4999, %5000" -> "  %5002 = lshr i32 %5001, 16"
"  %5002 = lshr i32 %5001, 16"
"  %5002 = lshr i32 %5001, 16" -> "  %5003 = add i32 %4996, %5002"
"  %5003 = add i32 %4996, %5002"
"  %5003 = add i32 %4996, %5002" -> "  %5008 = add i32 %5003, %5007"
"  %5004 = and i32 %5001, 65535"
"  %5004 = and i32 %5001, 65535" -> "  %5006 = add nuw nsw i32 %5004, %5005"
"  %5005 = lshr i32 %4998, 16"
"  %5005 = lshr i32 %4998, 16" -> "  %5006 = add nuw nsw i32 %5004, %5005"
"  %5006 = add nuw nsw i32 %5004, %5005"
"  %5006 = add nuw nsw i32 %5004, %5005" -> "  %5067 = and i32 %5006, 65535""  %5006 = add nuw nsw i32 %5004, %5005" -> "  %5007 = lshr i32 %5006, 16"
"  %5007 = lshr i32 %5006, 16"
"  %5007 = lshr i32 %5006, 16" -> "  %5008 = add i32 %5003, %5007"
"  %5008 = add i32 %5003, %5007"
"  %5008 = add i32 %5003, %5007" -> "  %5043 = lshr i32 %5008, 16""  %5008 = add i32 %5003, %5007" -> "  %5040 = and i32 %5008, 65535"
"  %5009 = mul nuw i32 %4661, %4661"
"  %5009 = mul nuw i32 %4661, %4661" -> "  %5027 = and i32 %5009, 65535""  %5009 = mul nuw i32 %4661, %4661" -> "  %5010 = lshr i32 %5009, 16"
"  %5010 = lshr i32 %5009, 16"
"  %5010 = lshr i32 %5009, 16" -> "  %5013 = add nuw nsw i32 %5012, %5010"
"  %5011 = mul nuw i32 %4664, %4661"
"  %5011 = mul nuw i32 %4664, %4661" -> "  %5017 = add nuw i32 %5016, %5011""  %5011 = mul nuw i32 %4664, %4661" -> "  %5014 = and i32 %5011, -65536""  %5011 = mul nuw i32 %4664, %4661" -> "  %5012 = and i32 %5011, 65535"
"  %5012 = and i32 %5011, 65535"
"  %5012 = and i32 %5011, 65535" -> "  %5013 = add nuw nsw i32 %5012, %5010"
"  %5013 = add nuw nsw i32 %5012, %5010"
"  %5013 = add nuw nsw i32 %5012, %5010" -> "  %5015 = add nuw i32 %5013, %5014"
"  %5014 = and i32 %5011, -65536"
"  %5014 = and i32 %5011, -65536" -> "  %5015 = add nuw i32 %5013, %5014"
"  %5015 = add nuw i32 %5013, %5014"
"  %5015 = add nuw i32 %5013, %5014" -> "  %5018 = lshr i32 %5015, 16""  %5015 = add nuw i32 %5013, %5014" -> "  %5016 = and i32 %5015, 65535"
"  %5016 = and i32 %5015, 65535"
"  %5016 = and i32 %5015, 65535" -> "  %5017 = add nuw i32 %5016, %5011"
"  %5017 = add nuw i32 %5016, %5011"
"  %5017 = add nuw i32 %5016, %5011" -> "  %5029 = and i32 %5017, 65535""  %5017 = add nuw i32 %5016, %5011" -> "  %5021 = lshr i32 %5017, 16"
"  %5018 = lshr i32 %5015, 16"
"  %5018 = lshr i32 %5015, 16" -> "  %5020 = add nuw i32 %5018, %5019"
"  %5019 = mul nuw i32 %4664, %4664"
"  %5019 = mul nuw i32 %4664, %4664" -> "  %5020 = add nuw i32 %5018, %5019"
"  %5020 = add nuw i32 %5018, %5019"
"  %5020 = add nuw i32 %5018, %5019" -> "  %5024 = and i32 %5020, -65536""  %5020 = add nuw i32 %5018, %5019" -> "  %5022 = and i32 %5020, 65535"
"  %5021 = lshr i32 %5017, 16"
"  %5021 = lshr i32 %5017, 16" -> "  %5023 = add nuw nsw i32 %5021, %5022"
"  %5022 = and i32 %5020, 65535"
"  %5022 = and i32 %5020, 65535" -> "  %5023 = add nuw nsw i32 %5021, %5022"
"  %5023 = add nuw nsw i32 %5021, %5022"
"  %5023 = add nuw nsw i32 %5021, %5022" -> "  %5025 = add i32 %5023, %5024"
"  %5024 = and i32 %5020, -65536"
"  %5024 = and i32 %5020, -65536" -> "  %5025 = add i32 %5023, %5024"
"  %5025 = add i32 %5023, %5024"
"  %5025 = add i32 %5023, %5024" -> "  %5033 = add i32 %5025, %5032"
"  %5026 = and i32 %4989, 65535"
"  %5026 = and i32 %4989, 65535" -> "  %5028 = add nuw nsw i32 %5026, %5027"
"  %5027 = and i32 %5009, 65535"
"  %5027 = and i32 %5009, 65535" -> "  %5028 = add nuw nsw i32 %5026, %5027"
"  %5028 = add nuw nsw i32 %5026, %5027"
"  %5028 = add nuw nsw i32 %5026, %5027" -> "  %5039 = and i32 %5028, 65535""  %5028 = add nuw nsw i32 %5026, %5027" -> "  %5035 = lshr i32 %5028, 16"
"  %5029 = and i32 %5017, 65535"
"  %5029 = and i32 %5017, 65535" -> "  %5031 = add nuw nsw i32 %5030, %5029"
"  %5030 = lshr i32 %4989, 16"
"  %5030 = lshr i32 %4989, 16" -> "  %5031 = add nuw nsw i32 %5030, %5029"
"  %5031 = add nuw nsw i32 %5030, %5029"
"  %5031 = add nuw nsw i32 %5030, %5029" -> "  %5034 = and i32 %5031, 65535""  %5031 = add nuw nsw i32 %5030, %5029" -> "  %5032 = lshr i32 %5031, 16"
"  %5032 = lshr i32 %5031, 16"
"  %5032 = lshr i32 %5031, 16" -> "  %5033 = add i32 %5025, %5032"
"  %5033 = add i32 %5025, %5032"
"  %5033 = add i32 %5025, %5032" -> "  %5038 = add i32 %5033, %5037"
"  %5034 = and i32 %5031, 65535"
"  %5034 = and i32 %5031, 65535" -> "  %5036 = add nuw nsw i32 %5034, %5035"
"  %5035 = lshr i32 %5028, 16"
"  %5035 = lshr i32 %5028, 16" -> "  %5036 = add nuw nsw i32 %5034, %5035"
"  %5036 = add nuw nsw i32 %5034, %5035"
"  %5036 = add nuw nsw i32 %5034, %5035" -> "  %5042 = and i32 %5036, 65535""  %5036 = add nuw nsw i32 %5034, %5035" -> "  %5037 = lshr i32 %5036, 16"
"  %5037 = lshr i32 %5036, 16"
"  %5037 = lshr i32 %5036, 16" -> "  %5038 = add i32 %5033, %5037"
"  %5038 = add i32 %5033, %5037"
"  %5038 = add i32 %5033, %5037" -> "  %5051 = and i32 %5038, -65536""  %5038 = add i32 %5033, %5037" -> "  %5049 = and i32 %5038, 65535"
"  %5039 = and i32 %5028, 65535"
"  %5039 = and i32 %5028, 65535" -> "  %5041 = add nuw nsw i32 %5040, %5039"
"  %5040 = and i32 %5008, 65535"
"  %5040 = and i32 %5008, 65535" -> "  %5041 = add nuw nsw i32 %5040, %5039"
"  %5041 = add nuw nsw i32 %5040, %5039"
"  %5041 = add nuw nsw i32 %5040, %5039" -> "  %5081 = and i32 %5041, 65535""  %5041 = add nuw nsw i32 %5040, %5039" -> "  %5045 = lshr i32 %5041, 16"
"  %5042 = and i32 %5036, 65535"
"  %5042 = and i32 %5036, 65535" -> "  %5044 = add nuw nsw i32 %5042, %5043"
"  %5043 = lshr i32 %5008, 16"
"  %5043 = lshr i32 %5008, 16" -> "  %5044 = add nuw nsw i32 %5042, %5043"
"  %5044 = add nuw nsw i32 %5042, %5043"
"  %5044 = add nuw nsw i32 %5042, %5043" -> "  %5048 = lshr i32 %5044, 16""  %5044 = add nuw nsw i32 %5042, %5043" -> "  %5046 = and i32 %5044, 65535"
"  %5045 = lshr i32 %5041, 16"
"  %5045 = lshr i32 %5041, 16" -> "  %5047 = add nuw nsw i32 %5046, %5045"
"  %5046 = and i32 %5044, 65535"
"  %5046 = and i32 %5044, 65535" -> "  %5047 = add nuw nsw i32 %5046, %5045"
"  %5047 = add nuw nsw i32 %5046, %5045"
"  %5047 = add nuw nsw i32 %5046, %5045" -> "  %5088 = and i32 %5047, 65535""  %5047 = add nuw nsw i32 %5046, %5045" -> "  %5053 = lshr i32 %5047, 16"
"  %5048 = lshr i32 %5044, 16"
"  %5048 = lshr i32 %5044, 16" -> "  %5050 = add nuw nsw i32 %5048, %5049"
"  %5049 = and i32 %5038, 65535"
"  %5049 = and i32 %5038, 65535" -> "  %5050 = add nuw nsw i32 %5048, %5049"
"  %5050 = add nuw nsw i32 %5048, %5049"
"  %5050 = add nuw nsw i32 %5048, %5049" -> "  %5052 = add i32 %5050, %5051"
"  %5051 = and i32 %5038, -65536"
"  %5051 = and i32 %5038, -65536" -> "  %5052 = add i32 %5050, %5051"
"  %5052 = add i32 %5050, %5051"
"  %5052 = add i32 %5050, %5051" -> "  %5054 = add i32 %5052, %5053"
"  %5053 = lshr i32 %5047, 16"
"  %5053 = lshr i32 %5047, 16" -> "  %5054 = add i32 %5052, %5053"
"  %5054 = add i32 %5052, %5053"
"  %5054 = add i32 %5052, %5053" -> "  %5092 = add i32 %5054, %5091"
"  %5055 = and i32 %4942, 65535"
"  %5055 = and i32 %4942, 65535" -> "  %5057 = add nuw nsw i32 %5056, %5055"
"  %5056 = and i32 %4822, 65535"
"  %5056 = and i32 %4822, 65535" -> "  %5057 = add nuw nsw i32 %5056, %5055"
"  %5057 = add nuw nsw i32 %5056, %5055"
"  %5057 = add nuw nsw i32 %5056, %5055" -> "  %5093 = and i32 %5057, 65535""  %5057 = add nuw nsw i32 %5056, %5055" -> "  %5061 = lshr i32 %5057, 16"
"  %5058 = and i32 %4950, 65535"
"  %5058 = and i32 %4950, 65535" -> "  %5060 = add nuw nsw i32 %5059, %5058"
"  %5059 = and i32 %4825, 65535"
"  %5059 = and i32 %4825, 65535" -> "  %5060 = add nuw nsw i32 %5059, %5058"
"  %5060 = add nuw nsw i32 %5059, %5058"
"  %5060 = add nuw nsw i32 %5059, %5058" -> "  %5074 = lshr i32 %5060, 16""  %5060 = add nuw nsw i32 %5059, %5058" -> "  %5062 = and i32 %5060, 65535"
"  %5061 = lshr i32 %5057, 16"
"  %5061 = lshr i32 %5057, 16" -> "  %5063 = add nuw nsw i32 %5062, %5061"
"  %5062 = and i32 %5060, 65535"
"  %5062 = and i32 %5060, 65535" -> "  %5063 = add nuw nsw i32 %5062, %5061"
"  %5063 = add nuw nsw i32 %5062, %5061"
"  %5063 = add nuw nsw i32 %5062, %5061" -> "  %5096 = and i32 %5063, 65535""  %5063 = add nuw nsw i32 %5062, %5061" -> "  %5076 = lshr i32 %5063, 16"
"  %5064 = and i32 %4998, 65535"
"  %5064 = and i32 %4998, 65535" -> "  %5066 = add nuw nsw i32 %5065, %5064"
"  %5065 = and i32 %4827, 65535"
"  %5065 = and i32 %4827, 65535" -> "  %5066 = add nuw nsw i32 %5065, %5064"
"  %5066 = add nuw nsw i32 %5065, %5064"
"  %5066 = add nuw nsw i32 %5065, %5064" -> "  %5073 = and i32 %5066, 65535""  %5066 = add nuw nsw i32 %5065, %5064" -> "  %5070 = lshr i32 %5066, 16"
"  %5067 = and i32 %5006, 65535"
"  %5067 = and i32 %5006, 65535" -> "  %5069 = add nuw nsw i32 %5068, %5067"
"  %5068 = lshr i32 %4827, 16"
"  %5068 = lshr i32 %4827, 16" -> "  %5069 = add nuw nsw i32 %5068, %5067"
"  %5069 = add nuw nsw i32 %5068, %5067"
"  %5069 = add nuw nsw i32 %5068, %5067" -> "  %5082 = lshr i32 %5069, 16""  %5069 = add nuw nsw i32 %5068, %5067" -> "  %5071 = and i32 %5069, 65535"
"  %5070 = lshr i32 %5066, 16"
"  %5070 = lshr i32 %5066, 16" -> "  %5072 = add nuw nsw i32 %5070, %5071"
"  %5071 = and i32 %5069, 65535"
"  %5071 = and i32 %5069, 65535" -> "  %5072 = add nuw nsw i32 %5070, %5071"
"  %5072 = add nuw nsw i32 %5070, %5071"
"  %5072 = add nuw nsw i32 %5070, %5071" -> "  %5084 = lshr i32 %5072, 16""  %5072 = add nuw nsw i32 %5070, %5071" -> "  %5079 = and i32 %5072, 65535"
"  %5073 = and i32 %5066, 65535"
"  %5073 = and i32 %5066, 65535" -> "  %5075 = add nuw nsw i32 %5073, %5074"
"  %5074 = lshr i32 %5060, 16"
"  %5074 = lshr i32 %5060, 16" -> "  %5075 = add nuw nsw i32 %5073, %5074"
"  %5075 = add nuw nsw i32 %5073, %5074"
"  %5075 = add nuw nsw i32 %5073, %5074" -> "  %5077 = add nuw nsw i32 %5075, %5076"
"  %5076 = lshr i32 %5063, 16"
"  %5076 = lshr i32 %5063, 16" -> "  %5077 = add nuw nsw i32 %5075, %5076"
"  %5077 = add nuw nsw i32 %5075, %5076"
"  %5077 = add nuw nsw i32 %5075, %5076" -> "  %5102 = and i32 %5077, 65535""  %5077 = add nuw nsw i32 %5075, %5076" -> "  %5078 = lshr i32 %5077, 16"
"  %5078 = lshr i32 %5077, 16"
"  %5078 = lshr i32 %5077, 16" -> "  %5080 = add nuw nsw i32 %5078, %5079"
"  %5079 = and i32 %5072, 65535"
"  %5079 = and i32 %5072, 65535" -> "  %5080 = add nuw nsw i32 %5078, %5079"
"  %5080 = add nuw nsw i32 %5078, %5079"
"  %5080 = add nuw nsw i32 %5078, %5079" -> "  %5105 = and i32 %5080, 65535""  %5080 = add nuw nsw i32 %5078, %5079" -> "  %5086 = lshr i32 %5080, 16"
"  %5081 = and i32 %5041, 65535"
"  %5081 = and i32 %5041, 65535" -> "  %5083 = add nuw nsw i32 %5082, %5081"
"  %5082 = lshr i32 %5069, 16"
"  %5082 = lshr i32 %5069, 16" -> "  %5083 = add nuw nsw i32 %5082, %5081"
"  %5083 = add nuw nsw i32 %5082, %5081"
"  %5083 = add nuw nsw i32 %5082, %5081" -> "  %5085 = add nuw nsw i32 %5083, %5084"
"  %5084 = lshr i32 %5072, 16"
"  %5084 = lshr i32 %5072, 16" -> "  %5085 = add nuw nsw i32 %5083, %5084"
"  %5085 = add nuw nsw i32 %5083, %5084"
"  %5085 = add nuw nsw i32 %5083, %5084" -> "  %5087 = add nuw nsw i32 %5085, %5086"
"  %5086 = lshr i32 %5080, 16"
"  %5086 = lshr i32 %5080, 16" -> "  %5087 = add nuw nsw i32 %5085, %5086"
"  %5087 = add nuw nsw i32 %5085, %5086"
"  %5087 = add nuw nsw i32 %5085, %5086" -> "  %5119 = and i32 %5087, 65535""  %5087 = add nuw nsw i32 %5085, %5086" -> "  %5089 = lshr i32 %5087, 16"
"  %5088 = and i32 %5047, 65535"
"  %5088 = and i32 %5047, 65535" -> "  %5090 = add nuw nsw i32 %5089, %5088"
"  %5089 = lshr i32 %5087, 16"
"  %5089 = lshr i32 %5087, 16" -> "  %5090 = add nuw nsw i32 %5089, %5088"
"  %5090 = add nuw nsw i32 %5089, %5088"
"  %5090 = add nuw nsw i32 %5089, %5088" -> "  %5126 = and i32 %5090, 65535""  %5090 = add nuw nsw i32 %5089, %5088" -> "  %5091 = lshr i32 %5090, 16"
"  %5091 = lshr i32 %5090, 16"
"  %5091 = lshr i32 %5090, 16" -> "  %5092 = add i32 %5054, %5091"
"  %5092 = add i32 %5054, %5091"
"  %5092 = add i32 %5054, %5091" -> "  %5130 = add i32 %5092, %5129"
"  %5093 = and i32 %5057, 65535"
"  %5093 = and i32 %5057, 65535" -> "  %5095 = add nuw nsw i32 %5094, %5093"
"  %5094 = and i32 %4936, 65535"
"  %5094 = and i32 %4936, 65535" -> "  %5095 = add nuw nsw i32 %5094, %5093"
"  %5095 = add nuw nsw i32 %5094, %5093"
"  %5095 = add nuw nsw i32 %5094, %5093" -> "  %5802 = and i32 %5095, 65535""  %5095 = add nuw nsw i32 %5094, %5093" -> "  %5099 = lshr i32 %5095, 16"
"  %5096 = and i32 %5063, 65535"
"  %5096 = and i32 %5063, 65535" -> "  %5098 = add nuw nsw i32 %5097, %5096"
"  %5097 = and i32 %4939, 65535"
"  %5097 = and i32 %4939, 65535" -> "  %5098 = add nuw nsw i32 %5097, %5096"
"  %5098 = add nuw nsw i32 %5097, %5096"
"  %5098 = add nuw nsw i32 %5097, %5096" -> "  %5112 = lshr i32 %5098, 16""  %5098 = add nuw nsw i32 %5097, %5096" -> "  %5100 = and i32 %5098, 65535"
"  %5099 = lshr i32 %5095, 16"
"  %5099 = lshr i32 %5095, 16" -> "  %5101 = add nuw nsw i32 %5100, %5099"
"  %5100 = and i32 %5098, 65535"
"  %5100 = and i32 %5098, 65535" -> "  %5101 = add nuw nsw i32 %5100, %5099"
"  %5101 = add nuw nsw i32 %5100, %5099"
"  %5101 = add nuw nsw i32 %5100, %5099" -> "  %5803 = and i32 %5101, 65535""  %5101 = add nuw nsw i32 %5100, %5099" -> "  %5113 = lshr i32 %5101, 16"
"  %5102 = and i32 %5077, 65535"
"  %5102 = and i32 %5077, 65535" -> "  %5104 = add nuw nsw i32 %5103, %5102"
"  %5103 = and i32 %4941, 65535"
"  %5103 = and i32 %4941, 65535" -> "  %5104 = add nuw nsw i32 %5103, %5102"
"  %5104 = add nuw nsw i32 %5103, %5102"
"  %5104 = add nuw nsw i32 %5103, %5102" -> "  %5111 = and i32 %5104, 65535""  %5104 = add nuw nsw i32 %5103, %5102" -> "  %5108 = lshr i32 %5104, 16"
"  %5105 = and i32 %5080, 65535"
"  %5105 = and i32 %5080, 65535" -> "  %5107 = add nuw nsw i32 %5105, %5106"
"  %5106 = lshr i32 %4941, 16"
"  %5106 = lshr i32 %4941, 16" -> "  %5107 = add nuw nsw i32 %5105, %5106"
"  %5107 = add nuw nsw i32 %5105, %5106"
"  %5107 = add nuw nsw i32 %5105, %5106" -> "  %5120 = lshr i32 %5107, 16""  %5107 = add nuw nsw i32 %5105, %5106" -> "  %5109 = and i32 %5107, 65535"
"  %5108 = lshr i32 %5104, 16"
"  %5108 = lshr i32 %5104, 16" -> "  %5110 = add nuw nsw i32 %5109, %5108"
"  %5109 = and i32 %5107, 65535"
"  %5109 = and i32 %5107, 65535" -> "  %5110 = add nuw nsw i32 %5109, %5108"
"  %5110 = add nuw nsw i32 %5109, %5108"
"  %5110 = add nuw nsw i32 %5109, %5108" -> "  %5122 = lshr i32 %5110, 16""  %5110 = add nuw nsw i32 %5109, %5108" -> "  %5117 = and i32 %5110, 65535"
"  %5111 = and i32 %5104, 65535"
"  %5111 = and i32 %5104, 65535" -> "  %5115 = add nuw nsw i32 %5114, %5111"
"  %5112 = lshr i32 %5098, 16"
"  %5112 = lshr i32 %5098, 16" -> "  %5114 = add nuw nsw i32 %5113, %5112"
"  %5113 = lshr i32 %5101, 16"
"  %5113 = lshr i32 %5101, 16" -> "  %5114 = add nuw nsw i32 %5113, %5112"
"  %5114 = add nuw nsw i32 %5113, %5112"
"  %5114 = add nuw nsw i32 %5113, %5112" -> "  %5115 = add nuw nsw i32 %5114, %5111"
"  %5115 = add nuw nsw i32 %5114, %5111"
"  %5115 = add nuw nsw i32 %5114, %5111" -> "  %5822 = and i32 %5115, 65535""  %5115 = add nuw nsw i32 %5114, %5111" -> "  %5116 = lshr i32 %5115, 16"
"  %5116 = lshr i32 %5115, 16"
"  %5116 = lshr i32 %5115, 16" -> "  %5118 = add nuw nsw i32 %5116, %5117"
"  %5117 = and i32 %5110, 65535"
"  %5117 = and i32 %5110, 65535" -> "  %5118 = add nuw nsw i32 %5116, %5117"
"  %5118 = add nuw nsw i32 %5116, %5117"
"  %5118 = add nuw nsw i32 %5116, %5117" -> "  %5823 = and i32 %5118, 65535""  %5118 = add nuw nsw i32 %5116, %5117" -> "  %5124 = lshr i32 %5118, 16"
"  %5119 = and i32 %5087, 65535"
"  %5119 = and i32 %5087, 65535" -> "  %5121 = add nuw nsw i32 %5120, %5119"
"  %5120 = lshr i32 %5107, 16"
"  %5120 = lshr i32 %5107, 16" -> "  %5121 = add nuw nsw i32 %5120, %5119"
"  %5121 = add nuw nsw i32 %5120, %5119"
"  %5121 = add nuw nsw i32 %5120, %5119" -> "  %5123 = add nuw nsw i32 %5121, %5122"
"  %5122 = lshr i32 %5110, 16"
"  %5122 = lshr i32 %5110, 16" -> "  %5123 = add nuw nsw i32 %5121, %5122"
"  %5123 = add nuw nsw i32 %5121, %5122"
"  %5123 = add nuw nsw i32 %5121, %5122" -> "  %5125 = add nuw nsw i32 %5123, %5124"
"  %5124 = lshr i32 %5118, 16"
"  %5124 = lshr i32 %5118, 16" -> "  %5125 = add nuw nsw i32 %5123, %5124"
"  %5125 = add nuw nsw i32 %5123, %5124"
"  %5125 = add nuw nsw i32 %5123, %5124" -> "  %5936 = and i32 %5125, 65535""  %5125 = add nuw nsw i32 %5123, %5124" -> "  %5127 = lshr i32 %5125, 16"
"  %5126 = and i32 %5090, 65535"
"  %5126 = and i32 %5090, 65535" -> "  %5128 = add nuw nsw i32 %5127, %5126"
"  %5127 = lshr i32 %5125, 16"
"  %5127 = lshr i32 %5125, 16" -> "  %5128 = add nuw nsw i32 %5127, %5126"
"  %5128 = add nuw nsw i32 %5127, %5126"
"  %5128 = add nuw nsw i32 %5127, %5126" -> "  %5939 = and i32 %5128, 65535""  %5128 = add nuw nsw i32 %5127, %5126" -> "  %5129 = lshr i32 %5128, 16"
"  %5129 = lshr i32 %5128, 16"
"  %5129 = lshr i32 %5128, 16" -> "  %5130 = add i32 %5092, %5129"
"  %5130 = add i32 %5092, %5129"
"  %5130 = add i32 %5092, %5129" -> "  %5956 = and i32 %5130, 65535""  %5130 = add i32 %5092, %5129" -> "  %5957 = lshr i32 %5130, 16"
"  %5131 = and i32 %4514, 65535"
"  %5131 = and i32 %4514, 65535" -> "  %8465 = add nuw nsw i32 %8464, %5131""  %5131 = and i32 %4514, 65535" -> "  %6841 = mul nuw nsw i32 %5131, 4087""  %5131 = and i32 %4514, 65535" -> "  %6848 = mul nuw nsw i32 %5131, 11561""  %5131 = and i32 %4514, 65535" -> "  %6890 = mul nuw nsw i32 %5131, 21884""  %5131 = and i32 %4514, 65535" -> "  %6897 = mul nuw i32 %5131, 36786""  %5131 = and i32 %4514, 65535" -> "  %6549 = mul nuw i32 %5131, 42779""  %5131 = and i32 %4514, 65535" -> "  %6556 = mul nuw nsw i32 %5131, 9871""  %5131 = and i32 %4514, 65535" -> "  %6598 = mul nuw nsw i32 %5131, 24315""  %5131 = and i32 %4514, 65535" -> "  %6605 = mul nuw nsw i32 %5131, 29744""  %5131 = and i32 %4514, 65535" -> "  %5490 = mul nuw i32 %5131, 42170""  %5131 = and i32 %4514, 65535" -> "  %5483 = mul nuw nsw i32 %5131, 31112""  %5131 = and i32 %4514, 65535" -> "  %5187 = mul nuw nsw i32 %5131, 1324""  %5131 = and i32 %4514, 65535" -> "  %5191 = mul nuw i32 %5131, 62728""  %5131 = and i32 %4514, 65535" -> "  %5441 = mul nuw i32 %5131, 46547""  %5131 = and i32 %4514, 65535" -> "  %5132 = mul nuw i32 %5131, 37996""  %5131 = and i32 %4514, 65535" -> "  %5434 = mul nuw nsw i32 %5131, 17857""  %5131 = and i32 %4514, 65535" -> "  %5140 = mul nuw i32 %5131, 45147"
"  %5132 = mul nuw i32 %5131, 37996"
"  %5132 = mul nuw i32 %5131, 37996" -> "  %5133 = lshr i32 %5132, 16"
"  %5133 = lshr i32 %5132, 16"
"  %5133 = lshr i32 %5132, 16" -> "  %5137 = add nuw nsw i32 %5136, %5133"
"  %5134 = and i32 %4522, 65535"
"  %5134 = and i32 %4522, 65535" -> "  %8467 = add nuw nsw i32 %8466, %5134""  %5134 = and i32 %4522, 65535" -> "  %5135 = mul nuw i32 %5134, 37996""  %5134 = and i32 %4522, 65535" -> "  %5436 = mul nuw nsw i32 %5134, 17857""  %5134 = and i32 %4522, 65535" -> "  %5445 = mul nuw i32 %5134, 46547""  %5134 = and i32 %4522, 65535" -> "  %5195 = mul nuw i32 %5134, 62728""  %5134 = and i32 %4522, 65535" -> "  %5189 = mul nuw nsw i32 %5134, 1324""  %5134 = and i32 %4522, 65535" -> "  %5144 = mul nuw i32 %5134, 45147""  %5134 = and i32 %4522, 65535" -> "  %5485 = mul nuw nsw i32 %5134, 31112""  %5134 = and i32 %4522, 65535" -> "  %5494 = mul nuw i32 %5134, 42170""  %5134 = and i32 %4522, 65535" -> "  %6609 = mul nuw nsw i32 %5134, 29744""  %5134 = and i32 %4522, 65535" -> "  %6600 = mul nuw nsw i32 %5134, 24315""  %5134 = and i32 %4522, 65535" -> "  %6560 = mul nuw nsw i32 %5134, 9871""  %5134 = and i32 %4522, 65535" -> "  %6551 = mul nuw i32 %5134, 42779""  %5134 = and i32 %4522, 65535" -> "  %6901 = mul nuw i32 %5134, 36786""  %5134 = and i32 %4522, 65535" -> "  %6892 = mul nuw nsw i32 %5134, 21884""  %5134 = and i32 %4522, 65535" -> "  %6852 = mul nuw nsw i32 %5134, 11561""  %5134 = and i32 %4522, 65535" -> "  %6843 = mul nuw nsw i32 %5134, 4087"
"  %5135 = mul nuw i32 %5134, 37996"
"  %5135 = mul nuw i32 %5134, 37996" -> "  %5138 = and i32 %5135, -65536""  %5135 = mul nuw i32 %5134, 37996" -> "  %5136 = and i32 %5135, 65532"
"  %5136 = and i32 %5135, 65532"
"  %5136 = and i32 %5135, 65532" -> "  %5137 = add nuw nsw i32 %5136, %5133"
"  %5137 = add nuw nsw i32 %5136, %5133"
"  %5137 = add nuw nsw i32 %5136, %5133" -> "  %5139 = add nuw i32 %5137, %5138"
"  %5138 = and i32 %5135, -65536"
"  %5138 = and i32 %5135, -65536" -> "  %5139 = add nuw i32 %5137, %5138"
"  %5139 = add nuw i32 %5137, %5138"
"  %5139 = add nuw i32 %5137, %5138" -> "  %5141 = and i32 %5139, 65535""  %5139 = add nuw i32 %5137, %5138" -> "  %5143 = lshr i32 %5139, 16"
"  %5140 = mul nuw i32 %5131, 45147"
"  %5140 = mul nuw i32 %5131, 45147" -> "  %5142 = add nuw i32 %5141, %5140"
"  %5141 = and i32 %5139, 65535"
"  %5141 = and i32 %5139, 65535" -> "  %5142 = add nuw i32 %5141, %5140"
"  %5142 = add nuw i32 %5141, %5140"
"  %5142 = add nuw i32 %5141, %5140" -> "  %5146 = lshr i32 %5142, 16"
"  %5143 = lshr i32 %5139, 16"
"  %5143 = lshr i32 %5139, 16" -> "  %5145 = add nuw i32 %5143, %5144"
"  %5144 = mul nuw i32 %5134, 45147"
"  %5144 = mul nuw i32 %5134, 45147" -> "  %5145 = add nuw i32 %5143, %5144"
"  %5145 = add nuw i32 %5143, %5144"
"  %5145 = add nuw i32 %5143, %5144" -> "  %5149 = and i32 %5145, -65536""  %5145 = add nuw i32 %5143, %5144" -> "  %5147 = and i32 %5145, 65535"
"  %5146 = lshr i32 %5142, 16"
"  %5146 = lshr i32 %5142, 16" -> "  %5148 = add nuw nsw i32 %5147, %5146"
"  %5147 = and i32 %5145, 65535"
"  %5147 = and i32 %5145, 65535" -> "  %5148 = add nuw nsw i32 %5147, %5146"
"  %5148 = add nuw nsw i32 %5147, %5146"
"  %5148 = add nuw nsw i32 %5147, %5146" -> "  %5150 = add nuw i32 %5148, %5149"
"  %5149 = and i32 %5145, -65536"
"  %5149 = and i32 %5145, -65536" -> "  %5150 = add nuw i32 %5148, %5149"
"  %5150 = add nuw i32 %5148, %5149"
"  %5150 = add nuw i32 %5148, %5149" -> "  %5175 = lshr i32 %5150, 16""  %5150 = add nuw i32 %5148, %5149" -> "  %5171 = and i32 %5150, 65535"
"  %5151 = and i32 %4581, 65535"
"  %5151 = and i32 %4581, 65535" -> "  %8475 = add nuw nsw i32 %8474, %5151""  %5151 = and i32 %4581, 65535" -> "  %5452 = mul nuw nsw i32 %5151, 17857""  %5151 = and i32 %4581, 65535" -> "  %6567 = mul nuw i32 %5151, 42779""  %5151 = and i32 %4581, 65535" -> "  %5153 = mul nuw i32 %5151, 37996""  %5151 = and i32 %4581, 65535" -> "  %5160 = mul nuw i32 %5151, 45147""  %5151 = and i32 %4581, 65535" -> "  %5215 = mul nuw nsw i32 %5151, 1324""  %5151 = and i32 %4581, 65535" -> "  %5222 = mul nuw i32 %5151, 62728""  %5151 = and i32 %4581, 65535" -> "  %5459 = mul nuw i32 %5151, 46547""  %5151 = and i32 %4581, 65535" -> "  %5514 = mul nuw nsw i32 %5151, 31112""  %5151 = and i32 %4581, 65535" -> "  %5521 = mul nuw i32 %5151, 42170""  %5151 = and i32 %4581, 65535" -> "  %6636 = mul nuw nsw i32 %5151, 29744""  %5151 = and i32 %4581, 65535" -> "  %6629 = mul nuw nsw i32 %5151, 24315""  %5151 = and i32 %4581, 65535" -> "  %6574 = mul nuw nsw i32 %5151, 9871""  %5151 = and i32 %4581, 65535" -> "  %6928 = mul nuw i32 %5151, 36786""  %5151 = and i32 %4581, 65535" -> "  %6921 = mul nuw nsw i32 %5151, 21884""  %5151 = and i32 %4581, 65535" -> "  %6866 = mul nuw nsw i32 %5151, 11561""  %5151 = and i32 %4581, 65535" -> "  %6859 = mul nuw nsw i32 %5151, 4087"
"  %5152 = and i32 %4589, 65535"
"  %5152 = and i32 %4589, 65535" -> "  %8477 = add nuw nsw i32 %8476, %5152""  %5152 = and i32 %4589, 65535" -> "  %5155 = mul nuw i32 %5152, 37996""  %5152 = and i32 %4589, 65535" -> "  %5164 = mul nuw i32 %5152, 45147""  %5152 = and i32 %4589, 65535" -> "  %5217 = mul nuw nsw i32 %5152, 1324""  %5152 = and i32 %4589, 65535" -> "  %5226 = mul nuw i32 %5152, 62728""  %5152 = and i32 %4589, 65535" -> "  %5463 = mul nuw i32 %5152, 46547""  %5152 = and i32 %4589, 65535" -> "  %5454 = mul nuw nsw i32 %5152, 17857""  %5152 = and i32 %4589, 65535" -> "  %5516 = mul nuw nsw i32 %5152, 31112""  %5152 = and i32 %4589, 65535" -> "  %5525 = mul nuw i32 %5152, 42170""  %5152 = and i32 %4589, 65535" -> "  %6640 = mul nuw nsw i32 %5152, 29744""  %5152 = and i32 %4589, 65535" -> "  %6631 = mul nuw nsw i32 %5152, 24315""  %5152 = and i32 %4589, 65535" -> "  %6578 = mul nuw nsw i32 %5152, 9871""  %5152 = and i32 %4589, 65535" -> "  %6569 = mul nuw i32 %5152, 42779""  %5152 = and i32 %4589, 65535" -> "  %6932 = mul nuw i32 %5152, 36786""  %5152 = and i32 %4589, 65535" -> "  %6923 = mul nuw nsw i32 %5152, 21884""  %5152 = and i32 %4589, 65535" -> "  %6870 = mul nuw nsw i32 %5152, 11561""  %5152 = and i32 %4589, 65535" -> "  %6861 = mul nuw nsw i32 %5152, 4087"
"  %5153 = mul nuw i32 %5151, 37996"
"  %5153 = mul nuw i32 %5151, 37996" -> "  %5172 = and i32 %5153, 65532""  %5153 = mul nuw i32 %5151, 37996" -> "  %5154 = lshr i32 %5153, 16"
"  %5154 = lshr i32 %5153, 16"
"  %5154 = lshr i32 %5153, 16" -> "  %5157 = add nuw nsw i32 %5156, %5154"
"  %5155 = mul nuw i32 %5152, 37996"
"  %5155 = mul nuw i32 %5152, 37996" -> "  %5158 = and i32 %5155, -65536""  %5155 = mul nuw i32 %5152, 37996" -> "  %5156 = and i32 %5155, 65532"
"  %5156 = and i32 %5155, 65532"
"  %5156 = and i32 %5155, 65532" -> "  %5157 = add nuw nsw i32 %5156, %5154"
"  %5157 = add nuw nsw i32 %5156, %5154"
"  %5157 = add nuw nsw i32 %5156, %5154" -> "  %5159 = add nuw i32 %5157, %5158"
"  %5158 = and i32 %5155, -65536"
"  %5158 = and i32 %5155, -65536" -> "  %5159 = add nuw i32 %5157, %5158"
"  %5159 = add nuw i32 %5157, %5158"
"  %5159 = add nuw i32 %5157, %5158" -> "  %5163 = lshr i32 %5159, 16""  %5159 = add nuw i32 %5157, %5158" -> "  %5161 = and i32 %5159, 65535"
"  %5160 = mul nuw i32 %5151, 45147"
"  %5160 = mul nuw i32 %5151, 45147" -> "  %5162 = add nuw i32 %5161, %5160"
"  %5161 = and i32 %5159, 65535"
"  %5161 = and i32 %5159, 65535" -> "  %5162 = add nuw i32 %5161, %5160"
"  %5162 = add nuw i32 %5161, %5160"
"  %5162 = add nuw i32 %5161, %5160" -> "  %5174 = and i32 %5162, 65535""  %5162 = add nuw i32 %5161, %5160" -> "  %5166 = lshr i32 %5162, 16"
"  %5163 = lshr i32 %5159, 16"
"  %5163 = lshr i32 %5159, 16" -> "  %5165 = add nuw i32 %5163, %5164"
"  %5164 = mul nuw i32 %5152, 45147"
"  %5164 = mul nuw i32 %5152, 45147" -> "  %5165 = add nuw i32 %5163, %5164"
"  %5165 = add nuw i32 %5163, %5164"
"  %5165 = add nuw i32 %5163, %5164" -> "  %5169 = and i32 %5165, -65536""  %5165 = add nuw i32 %5163, %5164" -> "  %5167 = and i32 %5165, 65535"
"  %5166 = lshr i32 %5162, 16"
"  %5166 = lshr i32 %5162, 16" -> "  %5168 = add nuw nsw i32 %5166, %5167"
"  %5167 = and i32 %5165, 65535"
"  %5167 = and i32 %5165, 65535" -> "  %5168 = add nuw nsw i32 %5166, %5167"
"  %5168 = add nuw nsw i32 %5166, %5167"
"  %5168 = add nuw nsw i32 %5166, %5167" -> "  %5170 = add nuw i32 %5168, %5169"
"  %5169 = and i32 %5165, -65536"
"  %5169 = and i32 %5165, -65536" -> "  %5170 = add nuw i32 %5168, %5169"
"  %5170 = add nuw i32 %5168, %5169"
"  %5170 = add nuw i32 %5168, %5169" -> "  %5183 = and i32 %5170, -65536""  %5170 = add nuw i32 %5168, %5169" -> "  %5181 = and i32 %5170, 65535"
"  %5171 = and i32 %5150, 65535"
"  %5171 = and i32 %5150, 65535" -> "  %5173 = add nuw nsw i32 %5171, %5172"
"  %5172 = and i32 %5153, 65532"
"  %5172 = and i32 %5153, 65532" -> "  %5173 = add nuw nsw i32 %5171, %5172"
"  %5173 = add nuw nsw i32 %5171, %5172"
"  %5173 = add nuw nsw i32 %5171, %5172" -> "  %5202 = and i32 %5173, 65535""  %5173 = add nuw nsw i32 %5171, %5172" -> "  %5177 = lshr i32 %5173, 16"
"  %5174 = and i32 %5162, 65535"
"  %5174 = and i32 %5162, 65535" -> "  %5176 = add nuw nsw i32 %5174, %5175"
"  %5175 = lshr i32 %5150, 16"
"  %5175 = lshr i32 %5150, 16" -> "  %5176 = add nuw nsw i32 %5174, %5175"
"  %5176 = add nuw nsw i32 %5174, %5175"
"  %5176 = add nuw nsw i32 %5174, %5175" -> "  %5180 = lshr i32 %5176, 16""  %5176 = add nuw nsw i32 %5174, %5175" -> "  %5178 = and i32 %5176, 65535"
"  %5177 = lshr i32 %5173, 16"
"  %5177 = lshr i32 %5173, 16" -> "  %5179 = add nuw nsw i32 %5178, %5177"
"  %5178 = and i32 %5176, 65535"
"  %5178 = and i32 %5176, 65535" -> "  %5179 = add nuw nsw i32 %5178, %5177"
"  %5179 = add nuw nsw i32 %5178, %5177"
"  %5179 = add nuw nsw i32 %5178, %5177" -> "  %5205 = and i32 %5179, 65535""  %5179 = add nuw nsw i32 %5178, %5177" -> "  %5185 = lshr i32 %5179, 16"
"  %5180 = lshr i32 %5176, 16"
"  %5180 = lshr i32 %5176, 16" -> "  %5182 = add nuw nsw i32 %5181, %5180"
"  %5181 = and i32 %5170, 65535"
"  %5181 = and i32 %5170, 65535" -> "  %5182 = add nuw nsw i32 %5181, %5180"
"  %5182 = add nuw nsw i32 %5181, %5180"
"  %5182 = add nuw nsw i32 %5181, %5180" -> "  %5184 = add nuw i32 %5182, %5183"
"  %5183 = and i32 %5170, -65536"
"  %5183 = and i32 %5170, -65536" -> "  %5184 = add nuw i32 %5182, %5183"
"  %5184 = add nuw i32 %5182, %5183"
"  %5184 = add nuw i32 %5182, %5183" -> "  %5186 = add nuw i32 %5184, %5185"
"  %5185 = lshr i32 %5179, 16"
"  %5185 = lshr i32 %5179, 16" -> "  %5186 = add nuw i32 %5184, %5185"
"  %5186 = add nuw i32 %5184, %5185"
"  %5186 = add nuw i32 %5184, %5185" -> "  %5237 = lshr i32 %5186, 16""  %5186 = add nuw i32 %5184, %5185" -> "  %5233 = and i32 %5186, 65535"
"  %5187 = mul nuw nsw i32 %5131, 1324"
"  %5187 = mul nuw nsw i32 %5131, 1324" -> "  %5203 = and i32 %5187, 65532""  %5187 = mul nuw nsw i32 %5131, 1324" -> "  %5188 = lshr i32 %5187, 16"
"  %5188 = lshr i32 %5187, 16"
"  %5188 = lshr i32 %5187, 16" -> "  %5190 = add nuw nsw i32 %5189, %5188"
"  %5189 = mul nuw nsw i32 %5134, 1324"
"  %5189 = mul nuw nsw i32 %5134, 1324" -> "  %5190 = add nuw nsw i32 %5189, %5188"
"  %5190 = add nuw nsw i32 %5189, %5188"
"  %5190 = add nuw nsw i32 %5189, %5188" -> "  %5194 = lshr i32 %5190, 16""  %5190 = add nuw nsw i32 %5189, %5188" -> "  %5192 = and i32 %5190, 65535"
"  %5191 = mul nuw i32 %5131, 62728"
"  %5191 = mul nuw i32 %5131, 62728" -> "  %5193 = add nuw i32 %5192, %5191"
"  %5192 = and i32 %5190, 65535"
"  %5192 = and i32 %5190, 65535" -> "  %5193 = add nuw i32 %5192, %5191"
"  %5193 = add nuw i32 %5192, %5191"
"  %5193 = add nuw i32 %5192, %5191" -> "  %5206 = and i32 %5193, 65535""  %5193 = add nuw i32 %5192, %5191" -> "  %5197 = lshr i32 %5193, 16"
"  %5194 = lshr i32 %5190, 16"
"  %5194 = lshr i32 %5190, 16" -> "  %5196 = add nuw i32 %5194, %5195"
"  %5195 = mul nuw i32 %5134, 62728"
"  %5195 = mul nuw i32 %5134, 62728" -> "  %5196 = add nuw i32 %5194, %5195"
"  %5196 = add nuw i32 %5194, %5195"
"  %5196 = add nuw i32 %5194, %5195" -> "  %5200 = and i32 %5196, -65536""  %5196 = add nuw i32 %5194, %5195" -> "  %5198 = and i32 %5196, 65535"
"  %5197 = lshr i32 %5193, 16"
"  %5197 = lshr i32 %5193, 16" -> "  %5199 = add nuw nsw i32 %5197, %5198"
"  %5198 = and i32 %5196, 65535"
"  %5198 = and i32 %5196, 65535" -> "  %5199 = add nuw nsw i32 %5197, %5198"
"  %5199 = add nuw nsw i32 %5197, %5198"
"  %5199 = add nuw nsw i32 %5197, %5198" -> "  %5201 = add nuw i32 %5199, %5200"
"  %5200 = and i32 %5196, -65536"
"  %5200 = and i32 %5196, -65536" -> "  %5201 = add nuw i32 %5199, %5200"
"  %5201 = add nuw i32 %5199, %5200"
"  %5201 = add nuw i32 %5199, %5200" -> "  %5209 = add nuw i32 %5201, %5208"
"  %5202 = and i32 %5173, 65535"
"  %5202 = and i32 %5173, 65535" -> "  %5204 = add nuw nsw i32 %5202, %5203"
"  %5203 = and i32 %5187, 65532"
"  %5203 = and i32 %5187, 65532" -> "  %5204 = add nuw nsw i32 %5202, %5203"
"  %5204 = add nuw nsw i32 %5202, %5203"
"  %5204 = add nuw nsw i32 %5202, %5203" -> "  %5211 = lshr i32 %5204, 16"
"  %5205 = and i32 %5179, 65535"
"  %5205 = and i32 %5179, 65535" -> "  %5207 = add nuw nsw i32 %5205, %5206"
"  %5206 = and i32 %5193, 65535"
"  %5206 = and i32 %5193, 65535" -> "  %5207 = add nuw nsw i32 %5205, %5206"
"  %5207 = add nuw nsw i32 %5205, %5206"
"  %5207 = add nuw nsw i32 %5205, %5206" -> "  %5210 = and i32 %5207, 65535""  %5207 = add nuw nsw i32 %5205, %5206" -> "  %5208 = lshr i32 %5207, 16"
"  %5208 = lshr i32 %5207, 16"
"  %5208 = lshr i32 %5207, 16" -> "  %5209 = add nuw i32 %5201, %5208"
"  %5209 = add nuw i32 %5201, %5208"
"  %5209 = add nuw i32 %5201, %5208" -> "  %5214 = add nuw i32 %5209, %5213"
"  %5210 = and i32 %5207, 65535"
"  %5210 = and i32 %5207, 65535" -> "  %5212 = add nuw nsw i32 %5210, %5211"
"  %5211 = lshr i32 %5204, 16"
"  %5211 = lshr i32 %5204, 16" -> "  %5212 = add nuw nsw i32 %5210, %5211"
"  %5212 = add nuw nsw i32 %5210, %5211"
"  %5212 = add nuw nsw i32 %5210, %5211" -> "  %5213 = lshr i32 %5212, 16"
"  %5213 = lshr i32 %5212, 16"
"  %5213 = lshr i32 %5212, 16" -> "  %5214 = add nuw i32 %5209, %5213"
"  %5214 = add nuw i32 %5209, %5213"
"  %5214 = add nuw i32 %5209, %5213" -> "  %5250 = lshr i32 %5214, 16""  %5214 = add nuw i32 %5209, %5213" -> "  %5247 = and i32 %5214, 65535"
"  %5215 = mul nuw nsw i32 %5151, 1324"
"  %5215 = mul nuw nsw i32 %5151, 1324" -> "  %5234 = and i32 %5215, 65532""  %5215 = mul nuw nsw i32 %5151, 1324" -> "  %5216 = lshr i32 %5215, 16"
"  %5216 = lshr i32 %5215, 16"
"  %5216 = lshr i32 %5215, 16" -> "  %5219 = add nuw nsw i32 %5218, %5216"
"  %5217 = mul nuw nsw i32 %5152, 1324"
"  %5217 = mul nuw nsw i32 %5152, 1324" -> "  %5220 = and i32 %5217, 134152192""  %5217 = mul nuw nsw i32 %5152, 1324" -> "  %5218 = and i32 %5217, 65532"
"  %5218 = and i32 %5217, 65532"
"  %5218 = and i32 %5217, 65532" -> "  %5219 = add nuw nsw i32 %5218, %5216"
"  %5219 = add nuw nsw i32 %5218, %5216"
"  %5219 = add nuw nsw i32 %5218, %5216" -> "  %5221 = add nuw nsw i32 %5219, %5220"
"  %5220 = and i32 %5217, 134152192"
"  %5220 = and i32 %5217, 134152192" -> "  %5221 = add nuw nsw i32 %5219, %5220"
"  %5221 = add nuw nsw i32 %5219, %5220"
"  %5221 = add nuw nsw i32 %5219, %5220" -> "  %5225 = lshr i32 %5221, 16""  %5221 = add nuw nsw i32 %5219, %5220" -> "  %5223 = and i32 %5221, 65535"
"  %5222 = mul nuw i32 %5151, 62728"
"  %5222 = mul nuw i32 %5151, 62728" -> "  %5224 = add nuw i32 %5223, %5222"
"  %5223 = and i32 %5221, 65535"
"  %5223 = and i32 %5221, 65535" -> "  %5224 = add nuw i32 %5223, %5222"
"  %5224 = add nuw i32 %5223, %5222"
"  %5224 = add nuw i32 %5223, %5222" -> "  %5236 = and i32 %5224, 65535""  %5224 = add nuw i32 %5223, %5222" -> "  %5228 = lshr i32 %5224, 16"
"  %5225 = lshr i32 %5221, 16"
"  %5225 = lshr i32 %5221, 16" -> "  %5227 = add nuw i32 %5225, %5226"
"  %5226 = mul nuw i32 %5152, 62728"
"  %5226 = mul nuw i32 %5152, 62728" -> "  %5227 = add nuw i32 %5225, %5226"
"  %5227 = add nuw i32 %5225, %5226"
"  %5227 = add nuw i32 %5225, %5226" -> "  %5231 = and i32 %5227, -65536""  %5227 = add nuw i32 %5225, %5226" -> "  %5229 = and i32 %5227, 65535"
"  %5228 = lshr i32 %5224, 16"
"  %5228 = lshr i32 %5224, 16" -> "  %5230 = add nuw nsw i32 %5228, %5229"
"  %5229 = and i32 %5227, 65535"
"  %5229 = and i32 %5227, 65535" -> "  %5230 = add nuw nsw i32 %5228, %5229"
"  %5230 = add nuw nsw i32 %5228, %5229"
"  %5230 = add nuw nsw i32 %5228, %5229" -> "  %5232 = add nuw i32 %5230, %5231"
"  %5231 = and i32 %5227, -65536"
"  %5231 = and i32 %5227, -65536" -> "  %5232 = add nuw i32 %5230, %5231"
"  %5232 = add nuw i32 %5230, %5231"
"  %5232 = add nuw i32 %5230, %5231" -> "  %5240 = add nuw i32 %5232, %5239"
"  %5233 = and i32 %5186, 65535"
"  %5233 = and i32 %5186, 65535" -> "  %5235 = add nuw nsw i32 %5233, %5234"
"  %5234 = and i32 %5215, 65532"
"  %5234 = and i32 %5215, 65532" -> "  %5235 = add nuw nsw i32 %5233, %5234"
"  %5235 = add nuw nsw i32 %5233, %5234"
"  %5235 = add nuw nsw i32 %5233, %5234" -> "  %5246 = and i32 %5235, 65535""  %5235 = add nuw nsw i32 %5233, %5234" -> "  %5242 = lshr i32 %5235, 16"
"  %5236 = and i32 %5224, 65535"
"  %5236 = and i32 %5224, 65535" -> "  %5238 = add nuw nsw i32 %5237, %5236"
"  %5237 = lshr i32 %5186, 16"
"  %5237 = lshr i32 %5186, 16" -> "  %5238 = add nuw nsw i32 %5237, %5236"
"  %5238 = add nuw nsw i32 %5237, %5236"
"  %5238 = add nuw nsw i32 %5237, %5236" -> "  %5241 = and i32 %5238, 65535""  %5238 = add nuw nsw i32 %5237, %5236" -> "  %5239 = lshr i32 %5238, 16"
"  %5239 = lshr i32 %5238, 16"
"  %5239 = lshr i32 %5238, 16" -> "  %5240 = add nuw i32 %5232, %5239"
"  %5240 = add nuw i32 %5232, %5239"
"  %5240 = add nuw i32 %5232, %5239" -> "  %5245 = add nuw i32 %5240, %5244"
"  %5241 = and i32 %5238, 65535"
"  %5241 = and i32 %5238, 65535" -> "  %5243 = add nuw nsw i32 %5242, %5241"
"  %5242 = lshr i32 %5235, 16"
"  %5242 = lshr i32 %5235, 16" -> "  %5243 = add nuw nsw i32 %5242, %5241"
"  %5243 = add nuw nsw i32 %5242, %5241"
"  %5243 = add nuw nsw i32 %5242, %5241" -> "  %5249 = and i32 %5243, 65535""  %5243 = add nuw nsw i32 %5242, %5241" -> "  %5244 = lshr i32 %5243, 16"
"  %5244 = lshr i32 %5243, 16"
"  %5244 = lshr i32 %5243, 16" -> "  %5245 = add nuw i32 %5240, %5244"
"  %5245 = add nuw i32 %5240, %5244"
"  %5245 = add nuw i32 %5240, %5244" -> "  %5258 = and i32 %5245, -65536""  %5245 = add nuw i32 %5240, %5244" -> "  %5256 = and i32 %5245, 65535"
"  %5246 = and i32 %5235, 65535"
"  %5246 = and i32 %5235, 65535" -> "  %5248 = add nuw nsw i32 %5247, %5246"
"  %5247 = and i32 %5214, 65535"
"  %5247 = and i32 %5214, 65535" -> "  %5248 = add nuw nsw i32 %5247, %5246"
"  %5248 = add nuw nsw i32 %5247, %5246"
"  %5248 = add nuw nsw i32 %5247, %5246" -> "  %5397 = and i32 %5248, 65535""  %5248 = add nuw nsw i32 %5247, %5246" -> "  %5252 = lshr i32 %5248, 16"
"  %5249 = and i32 %5243, 65535"
"  %5249 = and i32 %5243, 65535" -> "  %5251 = add nuw nsw i32 %5249, %5250"
"  %5250 = lshr i32 %5214, 16"
"  %5250 = lshr i32 %5214, 16" -> "  %5251 = add nuw nsw i32 %5249, %5250"
"  %5251 = add nuw nsw i32 %5249, %5250"
"  %5251 = add nuw nsw i32 %5249, %5250" -> "  %5255 = lshr i32 %5251, 16""  %5251 = add nuw nsw i32 %5249, %5250" -> "  %5253 = and i32 %5251, 65535"
"  %5252 = lshr i32 %5248, 16"
"  %5252 = lshr i32 %5248, 16" -> "  %5254 = add nuw nsw i32 %5253, %5252"
"  %5253 = and i32 %5251, 65535"
"  %5253 = and i32 %5251, 65535" -> "  %5254 = add nuw nsw i32 %5253, %5252"
"  %5254 = add nuw nsw i32 %5253, %5252"
"  %5254 = add nuw nsw i32 %5253, %5252" -> "  %5400 = and i32 %5254, 65535""  %5254 = add nuw nsw i32 %5253, %5252" -> "  %5260 = lshr i32 %5254, 16"
"  %5255 = lshr i32 %5251, 16"
"  %5255 = lshr i32 %5251, 16" -> "  %5257 = add nuw nsw i32 %5255, %5256"
"  %5256 = and i32 %5245, 65535"
"  %5256 = and i32 %5245, 65535" -> "  %5257 = add nuw nsw i32 %5255, %5256"
"  %5257 = add nuw nsw i32 %5255, %5256"
"  %5257 = add nuw nsw i32 %5255, %5256" -> "  %5259 = add nuw i32 %5257, %5258"
"  %5258 = and i32 %5245, -65536"
"  %5258 = and i32 %5245, -65536" -> "  %5259 = add nuw i32 %5257, %5258"
"  %5259 = add nuw i32 %5257, %5258"
"  %5259 = add nuw i32 %5257, %5258" -> "  %5261 = add nuw i32 %5259, %5260"
"  %5260 = lshr i32 %5254, 16"
"  %5260 = lshr i32 %5254, 16" -> "  %5261 = add nuw i32 %5259, %5260"
"  %5261 = add nuw i32 %5259, %5260"
"  %5261 = add nuw i32 %5259, %5260" -> "  %5409 = and i32 %5261, 65535""  %5261 = add nuw i32 %5259, %5260" -> "  %5412 = lshr i32 %5261, 16"
"  %5262 = and i32 %4906, 65535"
"  %5262 = and i32 %4906, 65535" -> "  %8492 = add nuw nsw i32 %8491, %5262""  %5262 = and i32 %4906, 65535" -> "  %7058 = mul nuw nsw i32 %5262, 21884""  %5262 = and i32 %4906, 65535" -> "  %6725 = mul nuw nsw i32 %5262, 24315""  %5262 = and i32 %4906, 65535" -> "  %5263 = mul nuw i32 %5262, 37996""  %5262 = and i32 %4906, 65535" -> "  %5271 = mul nuw i32 %5262, 45147""  %5262 = and i32 %4906, 65535" -> "  %5599 = mul nuw nsw i32 %5262, 17857""  %5262 = and i32 %4906, 65535" -> "  %5606 = mul nuw i32 %5262, 46547""  %5262 = and i32 %4906, 65535" -> "  %5325 = mul nuw i32 %5262, 62728""  %5262 = and i32 %4906, 65535" -> "  %5318 = mul nuw nsw i32 %5262, 1324""  %5262 = and i32 %4906, 65535" -> "  %5648 = mul nuw nsw i32 %5262, 31112""  %5262 = and i32 %4906, 65535" -> "  %5655 = mul nuw i32 %5262, 42170""  %5262 = and i32 %4906, 65535" -> "  %6732 = mul nuw nsw i32 %5262, 29744""  %5262 = and i32 %4906, 65535" -> "  %6683 = mul nuw nsw i32 %5262, 9871""  %5262 = and i32 %4906, 65535" -> "  %6676 = mul nuw i32 %5262, 42779""  %5262 = and i32 %4906, 65535" -> "  %7065 = mul nuw i32 %5262, 36786""  %5262 = and i32 %4906, 65535" -> "  %7016 = mul nuw nsw i32 %5262, 11561""  %5262 = and i32 %4906, 65535" -> "  %7006 = mul nuw nsw i32 %5262, 4087"
"  %5263 = mul nuw i32 %5262, 37996"
"  %5263 = mul nuw i32 %5262, 37996" -> "  %5396 = and i32 %5263, 65532""  %5263 = mul nuw i32 %5262, 37996" -> "  %5264 = lshr i32 %5263, 16"
"  %5264 = lshr i32 %5263, 16"
"  %5264 = lshr i32 %5263, 16" -> "  %5268 = add nuw nsw i32 %5267, %5264"
"  %5265 = and i32 %4912, 65535"
"  %5265 = and i32 %4912, 65535" -> "  %8494 = add nuw nsw i32 %8493, %5265""  %5265 = and i32 %4912, 65535" -> "  %5266 = mul nuw i32 %5265, 37996""  %5265 = and i32 %4912, 65535" -> "  %5275 = mul nuw i32 %5265, 45147""  %5265 = and i32 %4912, 65535" -> "  %5601 = mul nuw nsw i32 %5265, 17857""  %5265 = and i32 %4912, 65535" -> "  %5610 = mul nuw i32 %5265, 46547""  %5265 = and i32 %4912, 65535" -> "  %5329 = mul nuw i32 %5265, 62728""  %5265 = and i32 %4912, 65535" -> "  %5320 = mul nuw nsw i32 %5265, 1324""  %5265 = and i32 %4912, 65535" -> "  %5650 = mul nuw nsw i32 %5265, 31112""  %5265 = and i32 %4912, 65535" -> "  %5659 = mul nuw i32 %5265, 42170""  %5265 = and i32 %4912, 65535" -> "  %6736 = mul nuw nsw i32 %5265, 29744""  %5265 = and i32 %4912, 65535" -> "  %6727 = mul nuw nsw i32 %5265, 24315""  %5265 = and i32 %4912, 65535" -> "  %6687 = mul nuw nsw i32 %5265, 9871""  %5265 = and i32 %4912, 65535" -> "  %6678 = mul nuw i32 %5265, 42779""  %5265 = and i32 %4912, 65535" -> "  %7069 = mul nuw i32 %5265, 36786""  %5265 = and i32 %4912, 65535" -> "  %7060 = mul nuw nsw i32 %5265, 21884""  %5265 = and i32 %4912, 65535" -> "  %7020 = mul nuw nsw i32 %5265, 11561""  %5265 = and i32 %4912, 65535" -> "  %7011 = mul nuw nsw i32 %5265, 4087"
"  %5266 = mul nuw i32 %5265, 37996"
"  %5266 = mul nuw i32 %5265, 37996" -> "  %5269 = and i32 %5266, -65536""  %5266 = mul nuw i32 %5265, 37996" -> "  %5267 = and i32 %5266, 65532"
"  %5267 = and i32 %5266, 65532"
"  %5267 = and i32 %5266, 65532" -> "  %5268 = add nuw nsw i32 %5267, %5264"
"  %5268 = add nuw nsw i32 %5267, %5264"
"  %5268 = add nuw nsw i32 %5267, %5264" -> "  %5270 = add nuw i32 %5268, %5269"
"  %5269 = and i32 %5266, -65536"
"  %5269 = and i32 %5266, -65536" -> "  %5270 = add nuw i32 %5268, %5269"
"  %5270 = add nuw i32 %5268, %5269"
"  %5270 = add nuw i32 %5268, %5269" -> "  %5274 = lshr i32 %5270, 16""  %5270 = add nuw i32 %5268, %5269" -> "  %5272 = and i32 %5270, 65535"
"  %5271 = mul nuw i32 %5262, 45147"
"  %5271 = mul nuw i32 %5262, 45147" -> "  %5273 = add nuw i32 %5272, %5271"
"  %5272 = and i32 %5270, 65535"
"  %5272 = and i32 %5270, 65535" -> "  %5273 = add nuw i32 %5272, %5271"
"  %5273 = add nuw i32 %5272, %5271"
"  %5273 = add nuw i32 %5272, %5271" -> "  %5399 = and i32 %5273, 65535""  %5273 = add nuw i32 %5272, %5271" -> "  %5277 = lshr i32 %5273, 16"
"  %5274 = lshr i32 %5270, 16"
"  %5274 = lshr i32 %5270, 16" -> "  %5276 = add nuw i32 %5274, %5275"
"  %5275 = mul nuw i32 %5265, 45147"
"  %5275 = mul nuw i32 %5265, 45147" -> "  %5276 = add nuw i32 %5274, %5275"
"  %5276 = add nuw i32 %5274, %5275"
"  %5276 = add nuw i32 %5274, %5275" -> "  %5280 = and i32 %5276, -65536""  %5276 = add nuw i32 %5274, %5275" -> "  %5278 = and i32 %5276, 65535"
"  %5277 = lshr i32 %5273, 16"
"  %5277 = lshr i32 %5273, 16" -> "  %5279 = add nuw nsw i32 %5277, %5278"
"  %5278 = and i32 %5276, 65535"
"  %5278 = and i32 %5276, 65535" -> "  %5279 = add nuw nsw i32 %5277, %5278"
"  %5279 = add nuw nsw i32 %5277, %5278"
"  %5279 = add nuw nsw i32 %5277, %5278" -> "  %5281 = add nuw i32 %5279, %5280"
"  %5280 = and i32 %5276, -65536"
"  %5280 = and i32 %5276, -65536" -> "  %5281 = add nuw i32 %5279, %5280"
"  %5281 = add nuw i32 %5279, %5280"
"  %5281 = add nuw i32 %5279, %5280" -> "  %5306 = lshr i32 %5281, 16""  %5281 = add nuw i32 %5279, %5280" -> "  %5303 = and i32 %5281, 65535"
"  %5282 = and i32 %4926, 65535"
"  %5282 = and i32 %4926, 65535" -> "  %8502 = add nuw nsw i32 %8501, %5282""  %5282 = and i32 %4926, 65535" -> "  %7027 = mul nuw nsw i32 %5282, 4087""  %5282 = and i32 %4926, 65535" -> "  %7034 = mul nuw nsw i32 %5282, 11561""  %5282 = and i32 %4926, 65535" -> "  %7089 = mul nuw nsw i32 %5282, 21884""  %5282 = and i32 %4926, 65535" -> "  %7096 = mul nuw i32 %5282, 36786""  %5282 = and i32 %4926, 65535" -> "  %6694 = mul nuw i32 %5282, 42779""  %5282 = and i32 %4926, 65535" -> "  %6701 = mul nuw nsw i32 %5282, 9871""  %5282 = and i32 %4926, 65535" -> "  %6756 = mul nuw nsw i32 %5282, 24315""  %5282 = and i32 %4926, 65535" -> "  %6763 = mul nuw nsw i32 %5282, 29744""  %5282 = and i32 %4926, 65535" -> "  %5686 = mul nuw i32 %5282, 42170""  %5282 = and i32 %4926, 65535" -> "  %5679 = mul nuw nsw i32 %5282, 31112""  %5282 = and i32 %4926, 65535" -> "  %5349 = mul nuw nsw i32 %5282, 1324""  %5282 = and i32 %4926, 65535" -> "  %5356 = mul nuw i32 %5282, 62728""  %5282 = and i32 %4926, 65535" -> "  %5624 = mul nuw i32 %5282, 46547""  %5282 = and i32 %4926, 65535" -> "  %5617 = mul nuw nsw i32 %5282, 17857""  %5282 = and i32 %4926, 65535" -> "  %5291 = mul nuw i32 %5282, 45147""  %5282 = and i32 %4926, 65535" -> "  %5283 = mul nuw i32 %5282, 37996"
"  %5283 = mul nuw i32 %5282, 37996"
"  %5283 = mul nuw i32 %5282, 37996" -> "  %5302 = and i32 %5283, 65532""  %5283 = mul nuw i32 %5282, 37996" -> "  %5284 = lshr i32 %5283, 16"
"  %5284 = lshr i32 %5283, 16"
"  %5284 = lshr i32 %5283, 16" -> "  %5288 = add nuw nsw i32 %5287, %5284"
"  %5285 = and i32 %4929, 65535"
"  %5285 = and i32 %4929, 65535" -> "  %5286 = mul nuw i32 %5285, 37996""  %5285 = and i32 %4929, 65535" -> "  %5295 = mul nuw i32 %5285, 45147""  %5285 = and i32 %4929, 65535" -> "  %5619 = mul nuw nsw i32 %5285, 17857""  %5285 = and i32 %4929, 65535" -> "  %5628 = mul nuw i32 %5285, 46547""  %5285 = and i32 %4929, 65535" -> "  %5360 = mul nuw i32 %5285, 62728""  %5285 = and i32 %4929, 65535" -> "  %5351 = mul nuw nsw i32 %5285, 1324""  %5285 = and i32 %4929, 65535" -> "  %5681 = mul nuw nsw i32 %5285, 31112""  %5285 = and i32 %4929, 65535" -> "  %5690 = mul nuw i32 %5285, 42170""  %5285 = and i32 %4929, 65535" -> "  %6705 = mul nuw nsw i32 %5285, 9871""  %5285 = and i32 %4929, 65535" -> "  %6696 = mul nuw i32 %5285, 42779""  %5285 = and i32 %4929, 65535" -> "  %6767 = mul nuw nsw i32 %5285, 29744""  %5285 = and i32 %4929, 65535" -> "  %6758 = mul nuw nsw i32 %5285, 24315""  %5285 = and i32 %4929, 65535" -> "  %7100 = mul nuw i32 %5285, 36786""  %5285 = and i32 %4929, 65535" -> "  %7091 = mul nuw nsw i32 %5285, 21884""  %5285 = and i32 %4929, 65535" -> "  %7038 = mul nuw nsw i32 %5285, 11561""  %5285 = and i32 %4929, 65535" -> "  %7029 = mul nuw nsw i32 %5285, 4087"
"  %5286 = mul nuw i32 %5285, 37996"
"  %5286 = mul nuw i32 %5285, 37996" -> "  %5289 = and i32 %5286, -65536""  %5286 = mul nuw i32 %5285, 37996" -> "  %5287 = and i32 %5286, 65532"
"  %5287 = and i32 %5286, 65532"
"  %5287 = and i32 %5286, 65532" -> "  %5288 = add nuw nsw i32 %5287, %5284"
"  %5288 = add nuw nsw i32 %5287, %5284"
"  %5288 = add nuw nsw i32 %5287, %5284" -> "  %5290 = add nuw i32 %5288, %5289"
"  %5289 = and i32 %5286, -65536"
"  %5289 = and i32 %5286, -65536" -> "  %5290 = add nuw i32 %5288, %5289"
"  %5290 = add nuw i32 %5288, %5289"
"  %5290 = add nuw i32 %5288, %5289" -> "  %5294 = lshr i32 %5290, 16""  %5290 = add nuw i32 %5288, %5289" -> "  %5292 = and i32 %5290, 65535"
"  %5291 = mul nuw i32 %5282, 45147"
"  %5291 = mul nuw i32 %5282, 45147" -> "  %5293 = add nuw i32 %5292, %5291"
"  %5292 = and i32 %5290, 65535"
"  %5292 = and i32 %5290, 65535" -> "  %5293 = add nuw i32 %5292, %5291"
"  %5293 = add nuw i32 %5292, %5291"
"  %5293 = add nuw i32 %5292, %5291" -> "  %5305 = and i32 %5293, 65535""  %5293 = add nuw i32 %5292, %5291" -> "  %5297 = lshr i32 %5293, 16"
"  %5294 = lshr i32 %5290, 16"
"  %5294 = lshr i32 %5290, 16" -> "  %5296 = add nuw i32 %5294, %5295"
"  %5295 = mul nuw i32 %5285, 45147"
"  %5295 = mul nuw i32 %5285, 45147" -> "  %5296 = add nuw i32 %5294, %5295"
"  %5296 = add nuw i32 %5294, %5295"
"  %5296 = add nuw i32 %5294, %5295" -> "  %5300 = and i32 %5296, -65536""  %5296 = add nuw i32 %5294, %5295" -> "  %5298 = and i32 %5296, 65535"
"  %5297 = lshr i32 %5293, 16"
"  %5297 = lshr i32 %5293, 16" -> "  %5299 = add nuw nsw i32 %5297, %5298"
"  %5298 = and i32 %5296, 65535"
"  %5298 = and i32 %5296, 65535" -> "  %5299 = add nuw nsw i32 %5297, %5298"
"  %5299 = add nuw nsw i32 %5297, %5298"
"  %5299 = add nuw nsw i32 %5297, %5298" -> "  %5301 = add nuw i32 %5299, %5300"
"  %5300 = and i32 %5296, -65536"
"  %5300 = and i32 %5296, -65536" -> "  %5301 = add nuw i32 %5299, %5300"
"  %5301 = add nuw i32 %5299, %5300"
"  %5301 = add nuw i32 %5299, %5300" -> "  %5312 = and i32 %5301, 65535""  %5301 = add nuw i32 %5299, %5300" -> "  %5314 = and i32 %5301, -65536"
"  %5302 = and i32 %5283, 65532"
"  %5302 = and i32 %5283, 65532" -> "  %5304 = add nuw nsw i32 %5303, %5302"
"  %5303 = and i32 %5281, 65535"
"  %5303 = and i32 %5281, 65535" -> "  %5304 = add nuw nsw i32 %5303, %5302"
"  %5304 = add nuw nsw i32 %5303, %5302"
"  %5304 = add nuw nsw i32 %5303, %5302" -> "  %5336 = and i32 %5304, 65535""  %5304 = add nuw nsw i32 %5303, %5302" -> "  %5308 = lshr i32 %5304, 16"
"  %5305 = and i32 %5293, 65535"
"  %5305 = and i32 %5293, 65535" -> "  %5307 = add nuw nsw i32 %5305, %5306"
"  %5306 = lshr i32 %5281, 16"
"  %5306 = lshr i32 %5281, 16" -> "  %5307 = add nuw nsw i32 %5305, %5306"
"  %5307 = add nuw nsw i32 %5305, %5306"
"  %5307 = add nuw nsw i32 %5305, %5306" -> "  %5309 = and i32 %5307, 65535""  %5307 = add nuw nsw i32 %5305, %5306" -> "  %5311 = lshr i32 %5307, 16"
"  %5308 = lshr i32 %5304, 16"
"  %5308 = lshr i32 %5304, 16" -> "  %5310 = add nuw nsw i32 %5309, %5308"
"  %5309 = and i32 %5307, 65535"
"  %5309 = and i32 %5307, 65535" -> "  %5310 = add nuw nsw i32 %5309, %5308"
"  %5310 = add nuw nsw i32 %5309, %5308"
"  %5310 = add nuw nsw i32 %5309, %5308" -> "  %5339 = and i32 %5310, 65535""  %5310 = add nuw nsw i32 %5309, %5308" -> "  %5315 = lshr i32 %5310, 16"
"  %5311 = lshr i32 %5307, 16"
"  %5311 = lshr i32 %5307, 16" -> "  %5313 = add nuw nsw i32 %5312, %5311"
"  %5312 = and i32 %5301, 65535"
"  %5312 = and i32 %5301, 65535" -> "  %5313 = add nuw nsw i32 %5312, %5311"
"  %5313 = add nuw nsw i32 %5312, %5311"
"  %5313 = add nuw nsw i32 %5312, %5311" -> "  %5316 = add nuw i32 %5313, %5314"
"  %5314 = and i32 %5301, -65536"
"  %5314 = and i32 %5301, -65536" -> "  %5316 = add nuw i32 %5313, %5314"
"  %5315 = lshr i32 %5310, 16"
"  %5315 = lshr i32 %5310, 16" -> "  %5317 = add nuw i32 %5316, %5315"
"  %5316 = add nuw i32 %5313, %5314"
"  %5316 = add nuw i32 %5313, %5314" -> "  %5317 = add nuw i32 %5316, %5315"
"  %5317 = add nuw i32 %5316, %5315"
"  %5317 = add nuw i32 %5316, %5315" -> "  %5371 = lshr i32 %5317, 16""  %5317 = add nuw i32 %5316, %5315" -> "  %5367 = and i32 %5317, 65535"
"  %5318 = mul nuw nsw i32 %5262, 1324"
"  %5318 = mul nuw nsw i32 %5262, 1324" -> "  %5337 = and i32 %5318, 65532""  %5318 = mul nuw nsw i32 %5262, 1324" -> "  %5319 = lshr i32 %5318, 16"
"  %5319 = lshr i32 %5318, 16"
"  %5319 = lshr i32 %5318, 16" -> "  %5322 = add nuw nsw i32 %5321, %5319"
"  %5320 = mul nuw nsw i32 %5265, 1324"
"  %5320 = mul nuw nsw i32 %5265, 1324" -> "  %5323 = and i32 %5320, 134152192""  %5320 = mul nuw nsw i32 %5265, 1324" -> "  %5321 = and i32 %5320, 65532"
"  %5321 = and i32 %5320, 65532"
"  %5321 = and i32 %5320, 65532" -> "  %5322 = add nuw nsw i32 %5321, %5319"
"  %5322 = add nuw nsw i32 %5321, %5319"
"  %5322 = add nuw nsw i32 %5321, %5319" -> "  %5324 = add nuw nsw i32 %5322, %5323"
"  %5323 = and i32 %5320, 134152192"
"  %5323 = and i32 %5320, 134152192" -> "  %5324 = add nuw nsw i32 %5322, %5323"
"  %5324 = add nuw nsw i32 %5322, %5323"
"  %5324 = add nuw nsw i32 %5322, %5323" -> "  %5328 = lshr i32 %5324, 16""  %5324 = add nuw nsw i32 %5322, %5323" -> "  %5326 = and i32 %5324, 65535"
"  %5325 = mul nuw i32 %5262, 62728"
"  %5325 = mul nuw i32 %5262, 62728" -> "  %5327 = add nuw i32 %5326, %5325"
"  %5326 = and i32 %5324, 65535"
"  %5326 = and i32 %5324, 65535" -> "  %5327 = add nuw i32 %5326, %5325"
"  %5327 = add nuw i32 %5326, %5325"
"  %5327 = add nuw i32 %5326, %5325" -> "  %5340 = and i32 %5327, 65535""  %5327 = add nuw i32 %5326, %5325" -> "  %5331 = lshr i32 %5327, 16"
"  %5328 = lshr i32 %5324, 16"
"  %5328 = lshr i32 %5324, 16" -> "  %5330 = add nuw i32 %5328, %5329"
"  %5329 = mul nuw i32 %5265, 62728"
"  %5329 = mul nuw i32 %5265, 62728" -> "  %5330 = add nuw i32 %5328, %5329"
"  %5330 = add nuw i32 %5328, %5329"
"  %5330 = add nuw i32 %5328, %5329" -> "  %5334 = and i32 %5330, -65536""  %5330 = add nuw i32 %5328, %5329" -> "  %5332 = and i32 %5330, 65535"
"  %5331 = lshr i32 %5327, 16"
"  %5331 = lshr i32 %5327, 16" -> "  %5333 = add nuw nsw i32 %5331, %5332"
"  %5332 = and i32 %5330, 65535"
"  %5332 = and i32 %5330, 65535" -> "  %5333 = add nuw nsw i32 %5331, %5332"
"  %5333 = add nuw nsw i32 %5331, %5332"
"  %5333 = add nuw nsw i32 %5331, %5332" -> "  %5335 = add nuw i32 %5333, %5334"
"  %5334 = and i32 %5330, -65536"
"  %5334 = and i32 %5330, -65536" -> "  %5335 = add nuw i32 %5333, %5334"
"  %5335 = add nuw i32 %5333, %5334"
"  %5335 = add nuw i32 %5333, %5334" -> "  %5343 = add nuw i32 %5335, %5342"
"  %5336 = and i32 %5304, 65535"
"  %5336 = and i32 %5304, 65535" -> "  %5338 = add nuw nsw i32 %5336, %5337"
"  %5337 = and i32 %5318, 65532"
"  %5337 = and i32 %5318, 65532" -> "  %5338 = add nuw nsw i32 %5336, %5337"
"  %5338 = add nuw nsw i32 %5336, %5337"
"  %5338 = add nuw nsw i32 %5336, %5337" -> "  %5408 = and i32 %5338, 65535""  %5338 = add nuw nsw i32 %5336, %5337" -> "  %5345 = lshr i32 %5338, 16"
"  %5339 = and i32 %5310, 65535"
"  %5339 = and i32 %5310, 65535" -> "  %5341 = add nuw nsw i32 %5339, %5340"
"  %5340 = and i32 %5327, 65535"
"  %5340 = and i32 %5327, 65535" -> "  %5341 = add nuw nsw i32 %5339, %5340"
"  %5341 = add nuw nsw i32 %5339, %5340"
"  %5341 = add nuw nsw i32 %5339, %5340" -> "  %5344 = and i32 %5341, 65535""  %5341 = add nuw nsw i32 %5339, %5340" -> "  %5342 = lshr i32 %5341, 16"
"  %5342 = lshr i32 %5341, 16"
"  %5342 = lshr i32 %5341, 16" -> "  %5343 = add nuw i32 %5335, %5342"
"  %5343 = add nuw i32 %5335, %5342"
"  %5343 = add nuw i32 %5335, %5342" -> "  %5348 = add nuw i32 %5343, %5347"
"  %5344 = and i32 %5341, 65535"
"  %5344 = and i32 %5341, 65535" -> "  %5346 = add nuw nsw i32 %5344, %5345"
"  %5345 = lshr i32 %5338, 16"
"  %5345 = lshr i32 %5338, 16" -> "  %5346 = add nuw nsw i32 %5344, %5345"
"  %5346 = add nuw nsw i32 %5344, %5345"
"  %5346 = add nuw nsw i32 %5344, %5345" -> "  %5411 = and i32 %5346, 65535""  %5346 = add nuw nsw i32 %5344, %5345" -> "  %5347 = lshr i32 %5346, 16"
"  %5347 = lshr i32 %5346, 16"
"  %5347 = lshr i32 %5346, 16" -> "  %5348 = add nuw i32 %5343, %5347"
"  %5348 = add nuw i32 %5343, %5347"
"  %5348 = add nuw i32 %5343, %5347" -> "  %5384 = lshr i32 %5348, 16""  %5348 = add nuw i32 %5343, %5347" -> "  %5381 = and i32 %5348, 65535"
"  %5349 = mul nuw nsw i32 %5282, 1324"
"  %5349 = mul nuw nsw i32 %5282, 1324" -> "  %5368 = and i32 %5349, 65532""  %5349 = mul nuw nsw i32 %5282, 1324" -> "  %5350 = lshr i32 %5349, 16"
"  %5350 = lshr i32 %5349, 16"
"  %5350 = lshr i32 %5349, 16" -> "  %5353 = add nuw nsw i32 %5352, %5350"
"  %5351 = mul nuw nsw i32 %5285, 1324"
"  %5351 = mul nuw nsw i32 %5285, 1324" -> "  %5354 = and i32 %5351, 134152192""  %5351 = mul nuw nsw i32 %5285, 1324" -> "  %5352 = and i32 %5351, 65532"
"  %5352 = and i32 %5351, 65532"
"  %5352 = and i32 %5351, 65532" -> "  %5353 = add nuw nsw i32 %5352, %5350"
"  %5353 = add nuw nsw i32 %5352, %5350"
"  %5353 = add nuw nsw i32 %5352, %5350" -> "  %5355 = add nuw nsw i32 %5353, %5354"
"  %5354 = and i32 %5351, 134152192"
"  %5354 = and i32 %5351, 134152192" -> "  %5355 = add nuw nsw i32 %5353, %5354"
"  %5355 = add nuw nsw i32 %5353, %5354"
"  %5355 = add nuw nsw i32 %5353, %5354" -> "  %5359 = lshr i32 %5355, 16""  %5355 = add nuw nsw i32 %5353, %5354" -> "  %5357 = and i32 %5355, 65535"
"  %5356 = mul nuw i32 %5282, 62728"
"  %5356 = mul nuw i32 %5282, 62728" -> "  %5358 = add nuw i32 %5357, %5356"
"  %5357 = and i32 %5355, 65535"
"  %5357 = and i32 %5355, 65535" -> "  %5358 = add nuw i32 %5357, %5356"
"  %5358 = add nuw i32 %5357, %5356"
"  %5358 = add nuw i32 %5357, %5356" -> "  %5370 = and i32 %5358, 65535""  %5358 = add nuw i32 %5357, %5356" -> "  %5362 = lshr i32 %5358, 16"
"  %5359 = lshr i32 %5355, 16"
"  %5359 = lshr i32 %5355, 16" -> "  %5361 = add nuw i32 %5359, %5360"
"  %5360 = mul nuw i32 %5285, 62728"
"  %5360 = mul nuw i32 %5285, 62728" -> "  %5361 = add nuw i32 %5359, %5360"
"  %5361 = add nuw i32 %5359, %5360"
"  %5361 = add nuw i32 %5359, %5360" -> "  %5365 = and i32 %5361, -65536""  %5361 = add nuw i32 %5359, %5360" -> "  %5363 = and i32 %5361, 65535"
"  %5362 = lshr i32 %5358, 16"
"  %5362 = lshr i32 %5358, 16" -> "  %5364 = add nuw nsw i32 %5362, %5363"
"  %5363 = and i32 %5361, 65535"
"  %5363 = and i32 %5361, 65535" -> "  %5364 = add nuw nsw i32 %5362, %5363"
"  %5364 = add nuw nsw i32 %5362, %5363"
"  %5364 = add nuw nsw i32 %5362, %5363" -> "  %5366 = add nuw i32 %5364, %5365"
"  %5365 = and i32 %5361, -65536"
"  %5365 = and i32 %5361, -65536" -> "  %5366 = add nuw i32 %5364, %5365"
"  %5366 = add nuw i32 %5364, %5365"
"  %5366 = add nuw i32 %5364, %5365" -> "  %5374 = add nuw i32 %5366, %5373"
"  %5367 = and i32 %5317, 65535"
"  %5367 = and i32 %5317, 65535" -> "  %5369 = add nuw nsw i32 %5367, %5368"
"  %5368 = and i32 %5349, 65532"
"  %5368 = and i32 %5349, 65532" -> "  %5369 = add nuw nsw i32 %5367, %5368"
"  %5369 = add nuw nsw i32 %5367, %5368"
"  %5369 = add nuw nsw i32 %5367, %5368" -> "  %5380 = and i32 %5369, 65535""  %5369 = add nuw nsw i32 %5367, %5368" -> "  %5376 = lshr i32 %5369, 16"
"  %5370 = and i32 %5358, 65535"
"  %5370 = and i32 %5358, 65535" -> "  %5372 = add nuw nsw i32 %5371, %5370"
"  %5371 = lshr i32 %5317, 16"
"  %5371 = lshr i32 %5317, 16" -> "  %5372 = add nuw nsw i32 %5371, %5370"
"  %5372 = add nuw nsw i32 %5371, %5370"
"  %5372 = add nuw nsw i32 %5371, %5370" -> "  %5375 = and i32 %5372, 65535""  %5372 = add nuw nsw i32 %5371, %5370" -> "  %5373 = lshr i32 %5372, 16"
"  %5373 = lshr i32 %5372, 16"
"  %5373 = lshr i32 %5372, 16" -> "  %5374 = add nuw i32 %5366, %5373"
"  %5374 = add nuw i32 %5366, %5373"
"  %5374 = add nuw i32 %5366, %5373" -> "  %5379 = add nuw i32 %5374, %5378"
"  %5375 = and i32 %5372, 65535"
"  %5375 = and i32 %5372, 65535" -> "  %5377 = add nuw nsw i32 %5375, %5376"
"  %5376 = lshr i32 %5369, 16"
"  %5376 = lshr i32 %5369, 16" -> "  %5377 = add nuw nsw i32 %5375, %5376"
"  %5377 = add nuw nsw i32 %5375, %5376"
"  %5377 = add nuw nsw i32 %5375, %5376" -> "  %5383 = and i32 %5377, 65535""  %5377 = add nuw nsw i32 %5375, %5376" -> "  %5378 = lshr i32 %5377, 16"
"  %5378 = lshr i32 %5377, 16"
"  %5378 = lshr i32 %5377, 16" -> "  %5379 = add nuw i32 %5374, %5378"
"  %5379 = add nuw i32 %5374, %5378"
"  %5379 = add nuw i32 %5374, %5378" -> "  %5392 = and i32 %5379, -65536""  %5379 = add nuw i32 %5374, %5378" -> "  %5390 = and i32 %5379, 65535"
"  %5380 = and i32 %5369, 65535"
"  %5380 = and i32 %5369, 65535" -> "  %5382 = add nuw nsw i32 %5381, %5380"
"  %5381 = and i32 %5348, 65535"
"  %5381 = and i32 %5348, 65535" -> "  %5382 = add nuw nsw i32 %5381, %5380"
"  %5382 = add nuw nsw i32 %5381, %5380"
"  %5382 = add nuw nsw i32 %5381, %5380" -> "  %5422 = and i32 %5382, 65535""  %5382 = add nuw nsw i32 %5381, %5380" -> "  %5386 = lshr i32 %5382, 16"
"  %5383 = and i32 %5377, 65535"
"  %5383 = and i32 %5377, 65535" -> "  %5385 = add nuw nsw i32 %5383, %5384"
"  %5384 = lshr i32 %5348, 16"
"  %5384 = lshr i32 %5348, 16" -> "  %5385 = add nuw nsw i32 %5383, %5384"
"  %5385 = add nuw nsw i32 %5383, %5384"
"  %5385 = add nuw nsw i32 %5383, %5384" -> "  %5389 = lshr i32 %5385, 16""  %5385 = add nuw nsw i32 %5383, %5384" -> "  %5387 = and i32 %5385, 65535"
"  %5386 = lshr i32 %5382, 16"
"  %5386 = lshr i32 %5382, 16" -> "  %5388 = add nuw nsw i32 %5387, %5386"
"  %5387 = and i32 %5385, 65535"
"  %5387 = and i32 %5385, 65535" -> "  %5388 = add nuw nsw i32 %5387, %5386"
"  %5388 = add nuw nsw i32 %5387, %5386"
"  %5388 = add nuw nsw i32 %5387, %5386" -> "  %5429 = and i32 %5388, 65535""  %5388 = add nuw nsw i32 %5387, %5386" -> "  %5394 = lshr i32 %5388, 16"
"  %5389 = lshr i32 %5385, 16"
"  %5389 = lshr i32 %5385, 16" -> "  %5391 = add nuw nsw i32 %5389, %5390"
"  %5390 = and i32 %5379, 65535"
"  %5390 = and i32 %5379, 65535" -> "  %5391 = add nuw nsw i32 %5389, %5390"
"  %5391 = add nuw nsw i32 %5389, %5390"
"  %5391 = add nuw nsw i32 %5389, %5390" -> "  %5393 = add nuw i32 %5391, %5392"
"  %5392 = and i32 %5379, -65536"
"  %5392 = and i32 %5379, -65536" -> "  %5393 = add nuw i32 %5391, %5392"
"  %5393 = add nuw i32 %5391, %5392"
"  %5393 = add nuw i32 %5391, %5392" -> "  %5395 = add nuw i32 %5393, %5394"
"  %5394 = lshr i32 %5388, 16"
"  %5394 = lshr i32 %5388, 16" -> "  %5395 = add nuw i32 %5393, %5394"
"  %5395 = add nuw i32 %5393, %5394"
"  %5395 = add nuw i32 %5393, %5394" -> "  %5433 = add nuw i32 %5395, %5432"
"  %5396 = and i32 %5263, 65532"
"  %5396 = and i32 %5263, 65532" -> "  %5398 = add nuw nsw i32 %5397, %5396"
"  %5397 = and i32 %5248, 65535"
"  %5397 = and i32 %5248, 65535" -> "  %5398 = add nuw nsw i32 %5397, %5396"
"  %5398 = add nuw nsw i32 %5397, %5396"
"  %5398 = add nuw nsw i32 %5397, %5396" -> "  %5562 = and i32 %5398, 65535""  %5398 = add nuw nsw i32 %5397, %5396" -> "  %5402 = lshr i32 %5398, 16"
"  %5399 = and i32 %5273, 65535"
"  %5399 = and i32 %5273, 65535" -> "  %5401 = add nuw nsw i32 %5400, %5399"
"  %5400 = and i32 %5254, 65535"
"  %5400 = and i32 %5254, 65535" -> "  %5401 = add nuw nsw i32 %5400, %5399"
"  %5401 = add nuw nsw i32 %5400, %5399"
"  %5401 = add nuw nsw i32 %5400, %5399" -> "  %5405 = lshr i32 %5401, 16""  %5401 = add nuw nsw i32 %5400, %5399" -> "  %5403 = and i32 %5401, 65535"
"  %5402 = lshr i32 %5398, 16"
"  %5402 = lshr i32 %5398, 16" -> "  %5404 = add nuw nsw i32 %5403, %5402"
"  %5403 = and i32 %5401, 65535"
"  %5403 = and i32 %5401, 65535" -> "  %5404 = add nuw nsw i32 %5403, %5402"
"  %5404 = add nuw nsw i32 %5403, %5402"
"  %5404 = add nuw nsw i32 %5403, %5402" -> "  %5565 = and i32 %5404, 65535""  %5404 = add nuw nsw i32 %5403, %5402" -> "  %5406 = lshr i32 %5404, 16"
"  %5405 = lshr i32 %5401, 16"
"  %5405 = lshr i32 %5401, 16" -> "  %5407 = add nuw nsw i32 %5406, %5405"
"  %5406 = lshr i32 %5404, 16"
"  %5406 = lshr i32 %5404, 16" -> "  %5407 = add nuw nsw i32 %5406, %5405"
"  %5407 = add nuw nsw i32 %5406, %5405"
"  %5407 = add nuw nsw i32 %5406, %5405" -> "  %5418 = add nuw nsw i32 %5407, %5417"
"  %5408 = and i32 %5338, 65535"
"  %5408 = and i32 %5338, 65535" -> "  %5410 = add nuw nsw i32 %5408, %5409"
"  %5409 = and i32 %5261, 65535"
"  %5409 = and i32 %5261, 65535" -> "  %5410 = add nuw nsw i32 %5408, %5409"
"  %5410 = add nuw nsw i32 %5408, %5409"
"  %5410 = add nuw nsw i32 %5408, %5409" -> "  %5417 = and i32 %5410, 65535""  %5410 = add nuw nsw i32 %5408, %5409" -> "  %5414 = lshr i32 %5410, 16"
"  %5411 = and i32 %5346, 65535"
"  %5411 = and i32 %5346, 65535" -> "  %5413 = add nuw nsw i32 %5411, %5412"
"  %5412 = lshr i32 %5261, 16"
"  %5412 = lshr i32 %5261, 16" -> "  %5413 = add nuw nsw i32 %5411, %5412"
"  %5413 = add nuw nsw i32 %5411, %5412"
"  %5413 = add nuw nsw i32 %5411, %5412" -> "  %5423 = lshr i32 %5413, 16""  %5413 = add nuw nsw i32 %5411, %5412" -> "  %5415 = and i32 %5413, 65535"
"  %5414 = lshr i32 %5410, 16"
"  %5414 = lshr i32 %5410, 16" -> "  %5416 = add nuw nsw i32 %5415, %5414"
"  %5415 = and i32 %5413, 65535"
"  %5415 = and i32 %5413, 65535" -> "  %5416 = add nuw nsw i32 %5415, %5414"
"  %5416 = add nuw nsw i32 %5415, %5414"
"  %5416 = add nuw nsw i32 %5415, %5414" -> "  %5425 = lshr i32 %5416, 16""  %5416 = add nuw nsw i32 %5415, %5414" -> "  %5420 = and i32 %5416, 65535"
"  %5417 = and i32 %5410, 65535"
"  %5417 = and i32 %5410, 65535" -> "  %5418 = add nuw nsw i32 %5407, %5417"
"  %5418 = add nuw nsw i32 %5407, %5417"
"  %5418 = add nuw nsw i32 %5407, %5417" -> "  %5573 = and i32 %5418, 65535""  %5418 = add nuw nsw i32 %5407, %5417" -> "  %5419 = lshr i32 %5418, 16"
"  %5419 = lshr i32 %5418, 16"
"  %5419 = lshr i32 %5418, 16" -> "  %5421 = add nuw nsw i32 %5420, %5419"
"  %5420 = and i32 %5416, 65535"
"  %5420 = and i32 %5416, 65535" -> "  %5421 = add nuw nsw i32 %5420, %5419"
"  %5421 = add nuw nsw i32 %5420, %5419"
"  %5421 = add nuw nsw i32 %5420, %5419" -> "  %5576 = and i32 %5421, 65535""  %5421 = add nuw nsw i32 %5420, %5419" -> "  %5427 = lshr i32 %5421, 16"
"  %5422 = and i32 %5382, 65535"
"  %5422 = and i32 %5382, 65535" -> "  %5424 = add nuw nsw i32 %5422, %5423"
"  %5423 = lshr i32 %5413, 16"
"  %5423 = lshr i32 %5413, 16" -> "  %5424 = add nuw nsw i32 %5422, %5423"
"  %5424 = add nuw nsw i32 %5422, %5423"
"  %5424 = add nuw nsw i32 %5422, %5423" -> "  %5426 = add nuw nsw i32 %5424, %5425"
"  %5425 = lshr i32 %5416, 16"
"  %5425 = lshr i32 %5416, 16" -> "  %5426 = add nuw nsw i32 %5424, %5425"
"  %5426 = add nuw nsw i32 %5424, %5425"
"  %5426 = add nuw nsw i32 %5424, %5425" -> "  %5428 = add nuw nsw i32 %5426, %5427"
"  %5427 = lshr i32 %5421, 16"
"  %5427 = lshr i32 %5421, 16" -> "  %5428 = add nuw nsw i32 %5426, %5427"
"  %5428 = add nuw nsw i32 %5426, %5427"
"  %5428 = add nuw nsw i32 %5426, %5427" -> "  %5727 = and i32 %5428, 65535""  %5428 = add nuw nsw i32 %5426, %5427" -> "  %5430 = lshr i32 %5428, 16"
"  %5429 = and i32 %5388, 65535"
"  %5429 = and i32 %5388, 65535" -> "  %5431 = add nuw nsw i32 %5430, %5429"
"  %5430 = lshr i32 %5428, 16"
"  %5430 = lshr i32 %5428, 16" -> "  %5431 = add nuw nsw i32 %5430, %5429"
"  %5431 = add nuw nsw i32 %5430, %5429"
"  %5431 = add nuw nsw i32 %5430, %5429" -> "  %5730 = and i32 %5431, 65535""  %5431 = add nuw nsw i32 %5430, %5429" -> "  %5432 = lshr i32 %5431, 16"
"  %5432 = lshr i32 %5431, 16"
"  %5432 = lshr i32 %5431, 16" -> "  %5433 = add nuw i32 %5395, %5432"
"  %5433 = add nuw i32 %5395, %5432"
"  %5433 = add nuw i32 %5395, %5432" -> "  %5736 = and i32 %5433, 65535""  %5433 = add nuw i32 %5395, %5432" -> "  %5739 = lshr i32 %5433, 16"
"  %5434 = mul nuw nsw i32 %5131, 17857"
"  %5434 = mul nuw nsw i32 %5131, 17857" -> "  %5561 = and i32 %5434, 65535""  %5434 = mul nuw nsw i32 %5131, 17857" -> "  %5435 = lshr i32 %5434, 16"
"  %5435 = lshr i32 %5434, 16"
"  %5435 = lshr i32 %5434, 16" -> "  %5438 = add nuw nsw i32 %5437, %5435"
"  %5436 = mul nuw nsw i32 %5134, 17857"
"  %5436 = mul nuw nsw i32 %5134, 17857" -> "  %5439 = and i32 %5436, 2147418112""  %5436 = mul nuw nsw i32 %5134, 17857" -> "  %5437 = and i32 %5436, 65535"
"  %5437 = and i32 %5436, 65535"
"  %5437 = and i32 %5436, 65535" -> "  %5438 = add nuw nsw i32 %5437, %5435"
"  %5438 = add nuw nsw i32 %5437, %5435"
"  %5438 = add nuw nsw i32 %5437, %5435" -> "  %5440 = add nuw nsw i32 %5438, %5439"
"  %5439 = and i32 %5436, 2147418112"
"  %5439 = and i32 %5436, 2147418112" -> "  %5440 = add nuw nsw i32 %5438, %5439"
"  %5440 = add nuw nsw i32 %5438, %5439"
"  %5440 = add nuw nsw i32 %5438, %5439" -> "  %5444 = lshr i32 %5440, 16""  %5440 = add nuw nsw i32 %5438, %5439" -> "  %5442 = and i32 %5440, 65535"
"  %5441 = mul nuw i32 %5131, 46547"
"  %5441 = mul nuw i32 %5131, 46547" -> "  %5443 = add nuw i32 %5442, %5441"
"  %5442 = and i32 %5440, 65535"
"  %5442 = and i32 %5440, 65535" -> "  %5443 = add nuw i32 %5442, %5441"
"  %5443 = add nuw i32 %5442, %5441"
"  %5443 = add nuw i32 %5442, %5441" -> "  %5564 = and i32 %5443, 65535""  %5443 = add nuw i32 %5442, %5441" -> "  %5447 = lshr i32 %5443, 16"
"  %5444 = lshr i32 %5440, 16"
"  %5444 = lshr i32 %5440, 16" -> "  %5446 = add nuw i32 %5444, %5445"
"  %5445 = mul nuw i32 %5134, 46547"
"  %5445 = mul nuw i32 %5134, 46547" -> "  %5446 = add nuw i32 %5444, %5445"
"  %5446 = add nuw i32 %5444, %5445"
"  %5446 = add nuw i32 %5444, %5445" -> "  %5450 = and i32 %5446, -65536""  %5446 = add nuw i32 %5444, %5445" -> "  %5448 = and i32 %5446, 65535"
"  %5447 = lshr i32 %5443, 16"
"  %5447 = lshr i32 %5443, 16" -> "  %5449 = add nuw nsw i32 %5447, %5448"
"  %5448 = and i32 %5446, 65535"
"  %5448 = and i32 %5446, 65535" -> "  %5449 = add nuw nsw i32 %5447, %5448"
"  %5449 = add nuw nsw i32 %5447, %5448"
"  %5449 = add nuw nsw i32 %5447, %5448" -> "  %5451 = add nuw i32 %5449, %5450"
"  %5450 = and i32 %5446, -65536"
"  %5450 = and i32 %5446, -65536" -> "  %5451 = add nuw i32 %5449, %5450"
"  %5451 = add nuw i32 %5449, %5450"
"  %5451 = add nuw i32 %5449, %5450" -> "  %5470 = and i32 %5451, 65535""  %5451 = add nuw i32 %5449, %5450" -> "  %5473 = lshr i32 %5451, 16"
"  %5452 = mul nuw nsw i32 %5151, 17857"
"  %5452 = mul nuw nsw i32 %5151, 17857" -> "  %5471 = and i32 %5452, 65535""  %5452 = mul nuw nsw i32 %5151, 17857" -> "  %5453 = lshr i32 %5452, 16"
"  %5453 = lshr i32 %5452, 16"
"  %5453 = lshr i32 %5452, 16" -> "  %5456 = add nuw nsw i32 %5455, %5453"
"  %5454 = mul nuw nsw i32 %5152, 17857"
"  %5454 = mul nuw nsw i32 %5152, 17857" -> "  %5457 = and i32 %5454, 2147418112""  %5454 = mul nuw nsw i32 %5152, 17857" -> "  %5455 = and i32 %5454, 65535"
"  %5455 = and i32 %5454, 65535"
"  %5455 = and i32 %5454, 65535" -> "  %5456 = add nuw nsw i32 %5455, %5453"
"  %5456 = add nuw nsw i32 %5455, %5453"
"  %5456 = add nuw nsw i32 %5455, %5453" -> "  %5458 = add nuw nsw i32 %5456, %5457"
"  %5457 = and i32 %5454, 2147418112"
"  %5457 = and i32 %5454, 2147418112" -> "  %5458 = add nuw nsw i32 %5456, %5457"
"  %5458 = add nuw nsw i32 %5456, %5457"
"  %5458 = add nuw nsw i32 %5456, %5457" -> "  %5462 = lshr i32 %5458, 16""  %5458 = add nuw nsw i32 %5456, %5457" -> "  %5460 = and i32 %5458, 65535"
"  %5459 = mul nuw i32 %5151, 46547"
"  %5459 = mul nuw i32 %5151, 46547" -> "  %5461 = add nuw i32 %5460, %5459"
"  %5460 = and i32 %5458, 65535"
"  %5460 = and i32 %5458, 65535" -> "  %5461 = add nuw i32 %5460, %5459"
"  %5461 = add nuw i32 %5460, %5459"
"  %5461 = add nuw i32 %5460, %5459" -> "  %5474 = and i32 %5461, 65535""  %5461 = add nuw i32 %5460, %5459" -> "  %5465 = lshr i32 %5461, 16"
"  %5462 = lshr i32 %5458, 16"
"  %5462 = lshr i32 %5458, 16" -> "  %5464 = add nuw i32 %5462, %5463"
"  %5463 = mul nuw i32 %5152, 46547"
"  %5463 = mul nuw i32 %5152, 46547" -> "  %5464 = add nuw i32 %5462, %5463"
"  %5464 = add nuw i32 %5462, %5463"
"  %5464 = add nuw i32 %5462, %5463" -> "  %5468 = and i32 %5464, -65536""  %5464 = add nuw i32 %5462, %5463" -> "  %5466 = and i32 %5464, 65535"
"  %5465 = lshr i32 %5461, 16"
"  %5465 = lshr i32 %5461, 16" -> "  %5467 = add nuw nsw i32 %5465, %5466"
"  %5466 = and i32 %5464, 65535"
"  %5466 = and i32 %5464, 65535" -> "  %5467 = add nuw nsw i32 %5465, %5466"
"  %5467 = add nuw nsw i32 %5465, %5466"
"  %5467 = add nuw nsw i32 %5465, %5466" -> "  %5469 = add nuw i32 %5467, %5468"
"  %5468 = and i32 %5464, -65536"
"  %5468 = and i32 %5464, -65536" -> "  %5469 = add nuw i32 %5467, %5468"
"  %5469 = add nuw i32 %5467, %5468"
"  %5469 = add nuw i32 %5467, %5468" -> "  %5477 = add nuw i32 %5469, %5476"
"  %5470 = and i32 %5451, 65535"
"  %5470 = and i32 %5451, 65535" -> "  %5472 = add nuw nsw i32 %5470, %5471"
"  %5471 = and i32 %5452, 65535"
"  %5471 = and i32 %5452, 65535" -> "  %5472 = add nuw nsw i32 %5470, %5471"
"  %5472 = add nuw nsw i32 %5470, %5471"
"  %5472 = add nuw nsw i32 %5470, %5471" -> "  %5501 = and i32 %5472, 65535""  %5472 = add nuw nsw i32 %5470, %5471" -> "  %5479 = lshr i32 %5472, 16"
"  %5473 = lshr i32 %5451, 16"
"  %5473 = lshr i32 %5451, 16" -> "  %5475 = add nuw nsw i32 %5474, %5473"
"  %5474 = and i32 %5461, 65535"
"  %5474 = and i32 %5461, 65535" -> "  %5475 = add nuw nsw i32 %5474, %5473"
"  %5475 = add nuw nsw i32 %5474, %5473"
"  %5475 = add nuw nsw i32 %5474, %5473" -> "  %5478 = and i32 %5475, 65535""  %5475 = add nuw nsw i32 %5474, %5473" -> "  %5476 = lshr i32 %5475, 16"
"  %5476 = lshr i32 %5475, 16"
"  %5476 = lshr i32 %5475, 16" -> "  %5477 = add nuw i32 %5469, %5476"
"  %5477 = add nuw i32 %5469, %5476"
"  %5477 = add nuw i32 %5469, %5476" -> "  %5482 = add nuw i32 %5477, %5481"
"  %5478 = and i32 %5475, 65535"
"  %5478 = and i32 %5475, 65535" -> "  %5480 = add nuw nsw i32 %5478, %5479"
"  %5479 = lshr i32 %5472, 16"
"  %5479 = lshr i32 %5472, 16" -> "  %5480 = add nuw nsw i32 %5478, %5479"
"  %5480 = add nuw nsw i32 %5478, %5479"
"  %5480 = add nuw nsw i32 %5478, %5479" -> "  %5504 = and i32 %5480, 65535""  %5480 = add nuw nsw i32 %5478, %5479" -> "  %5481 = lshr i32 %5480, 16"
"  %5481 = lshr i32 %5480, 16"
"  %5481 = lshr i32 %5480, 16" -> "  %5482 = add nuw i32 %5477, %5481"
"  %5482 = add nuw i32 %5477, %5481"
"  %5482 = add nuw i32 %5477, %5481" -> "  %5536 = lshr i32 %5482, 16""  %5482 = add nuw i32 %5477, %5481" -> "  %5532 = and i32 %5482, 65535"
"  %5483 = mul nuw nsw i32 %5131, 31112"
"  %5483 = mul nuw nsw i32 %5131, 31112" -> "  %5502 = and i32 %5483, 65528""  %5483 = mul nuw nsw i32 %5131, 31112" -> "  %5484 = lshr i32 %5483, 16"
"  %5484 = lshr i32 %5483, 16"
"  %5484 = lshr i32 %5483, 16" -> "  %5487 = add nuw nsw i32 %5486, %5484"
"  %5485 = mul nuw nsw i32 %5134, 31112"
"  %5485 = mul nuw nsw i32 %5134, 31112" -> "  %5488 = and i32 %5485, 2147418112""  %5485 = mul nuw nsw i32 %5134, 31112" -> "  %5486 = and i32 %5485, 65528"
"  %5486 = and i32 %5485, 65528"
"  %5486 = and i32 %5485, 65528" -> "  %5487 = add nuw nsw i32 %5486, %5484"
"  %5487 = add nuw nsw i32 %5486, %5484"
"  %5487 = add nuw nsw i32 %5486, %5484" -> "  %5489 = add nuw nsw i32 %5487, %5488"
"  %5488 = and i32 %5485, 2147418112"
"  %5488 = and i32 %5485, 2147418112" -> "  %5489 = add nuw nsw i32 %5487, %5488"
"  %5489 = add nuw nsw i32 %5487, %5488"
"  %5489 = add nuw nsw i32 %5487, %5488" -> "  %5493 = lshr i32 %5489, 16""  %5489 = add nuw nsw i32 %5487, %5488" -> "  %5491 = and i32 %5489, 65535"
"  %5490 = mul nuw i32 %5131, 42170"
"  %5490 = mul nuw i32 %5131, 42170" -> "  %5492 = add nuw i32 %5491, %5490"
"  %5491 = and i32 %5489, 65535"
"  %5491 = and i32 %5489, 65535" -> "  %5492 = add nuw i32 %5491, %5490"
"  %5492 = add nuw i32 %5491, %5490"
"  %5492 = add nuw i32 %5491, %5490" -> "  %5505 = and i32 %5492, 65535""  %5492 = add nuw i32 %5491, %5490" -> "  %5496 = lshr i32 %5492, 16"
"  %5493 = lshr i32 %5489, 16"
"  %5493 = lshr i32 %5489, 16" -> "  %5495 = add nuw i32 %5493, %5494"
"  %5494 = mul nuw i32 %5134, 42170"
"  %5494 = mul nuw i32 %5134, 42170" -> "  %5495 = add nuw i32 %5493, %5494"
"  %5495 = add nuw i32 %5493, %5494"
"  %5495 = add nuw i32 %5493, %5494" -> "  %5499 = and i32 %5495, -65536""  %5495 = add nuw i32 %5493, %5494" -> "  %5497 = and i32 %5495, 65535"
"  %5496 = lshr i32 %5492, 16"
"  %5496 = lshr i32 %5492, 16" -> "  %5498 = add nuw nsw i32 %5496, %5497"
"  %5497 = and i32 %5495, 65535"
"  %5497 = and i32 %5495, 65535" -> "  %5498 = add nuw nsw i32 %5496, %5497"
"  %5498 = add nuw nsw i32 %5496, %5497"
"  %5498 = add nuw nsw i32 %5496, %5497" -> "  %5500 = add nuw i32 %5498, %5499"
"  %5499 = and i32 %5495, -65536"
"  %5499 = and i32 %5495, -65536" -> "  %5500 = add nuw i32 %5498, %5499"
"  %5500 = add nuw i32 %5498, %5499"
"  %5500 = add nuw i32 %5498, %5499" -> "  %5508 = add nuw i32 %5500, %5507"
"  %5501 = and i32 %5472, 65535"
"  %5501 = and i32 %5472, 65535" -> "  %5503 = add nuw nsw i32 %5501, %5502"
"  %5502 = and i32 %5483, 65528"
"  %5502 = and i32 %5483, 65528" -> "  %5503 = add nuw nsw i32 %5501, %5502"
"  %5503 = add nuw nsw i32 %5501, %5502"
"  %5503 = add nuw nsw i32 %5501, %5502" -> "  %5572 = and i32 %5503, 65535""  %5503 = add nuw nsw i32 %5501, %5502" -> "  %5510 = lshr i32 %5503, 16"
"  %5504 = and i32 %5480, 65535"
"  %5504 = and i32 %5480, 65535" -> "  %5506 = add nuw nsw i32 %5504, %5505"
"  %5505 = and i32 %5492, 65535"
"  %5505 = and i32 %5492, 65535" -> "  %5506 = add nuw nsw i32 %5504, %5505"
"  %5506 = add nuw nsw i32 %5504, %5505"
"  %5506 = add nuw nsw i32 %5504, %5505" -> "  %5509 = and i32 %5506, 65535""  %5506 = add nuw nsw i32 %5504, %5505" -> "  %5507 = lshr i32 %5506, 16"
"  %5507 = lshr i32 %5506, 16"
"  %5507 = lshr i32 %5506, 16" -> "  %5508 = add nuw i32 %5500, %5507"
"  %5508 = add nuw i32 %5500, %5507"
"  %5508 = add nuw i32 %5500, %5507" -> "  %5513 = add nuw i32 %5508, %5512"
"  %5509 = and i32 %5506, 65535"
"  %5509 = and i32 %5506, 65535" -> "  %5511 = add nuw nsw i32 %5509, %5510"
"  %5510 = lshr i32 %5503, 16"
"  %5510 = lshr i32 %5503, 16" -> "  %5511 = add nuw nsw i32 %5509, %5510"
"  %5511 = add nuw nsw i32 %5509, %5510"
"  %5511 = add nuw nsw i32 %5509, %5510" -> "  %5575 = and i32 %5511, 65535""  %5511 = add nuw nsw i32 %5509, %5510" -> "  %5512 = lshr i32 %5511, 16"
"  %5512 = lshr i32 %5511, 16"
"  %5512 = lshr i32 %5511, 16" -> "  %5513 = add nuw i32 %5508, %5512"
"  %5513 = add nuw i32 %5508, %5512"
"  %5513 = add nuw i32 %5508, %5512" -> "  %5549 = lshr i32 %5513, 16""  %5513 = add nuw i32 %5508, %5512" -> "  %5546 = and i32 %5513, 65535"
"  %5514 = mul nuw nsw i32 %5151, 31112"
"  %5514 = mul nuw nsw i32 %5151, 31112" -> "  %5533 = and i32 %5514, 65528""  %5514 = mul nuw nsw i32 %5151, 31112" -> "  %5515 = lshr i32 %5514, 16"
"  %5515 = lshr i32 %5514, 16"
"  %5515 = lshr i32 %5514, 16" -> "  %5518 = add nuw nsw i32 %5517, %5515"
"  %5516 = mul nuw nsw i32 %5152, 31112"
"  %5516 = mul nuw nsw i32 %5152, 31112" -> "  %5519 = and i32 %5516, 2147418112""  %5516 = mul nuw nsw i32 %5152, 31112" -> "  %5517 = and i32 %5516, 65528"
"  %5517 = and i32 %5516, 65528"
"  %5517 = and i32 %5516, 65528" -> "  %5518 = add nuw nsw i32 %5517, %5515"
"  %5518 = add nuw nsw i32 %5517, %5515"
"  %5518 = add nuw nsw i32 %5517, %5515" -> "  %5520 = add nuw nsw i32 %5518, %5519"
"  %5519 = and i32 %5516, 2147418112"
"  %5519 = and i32 %5516, 2147418112" -> "  %5520 = add nuw nsw i32 %5518, %5519"
"  %5520 = add nuw nsw i32 %5518, %5519"
"  %5520 = add nuw nsw i32 %5518, %5519" -> "  %5524 = lshr i32 %5520, 16""  %5520 = add nuw nsw i32 %5518, %5519" -> "  %5522 = and i32 %5520, 65535"
"  %5521 = mul nuw i32 %5151, 42170"
"  %5521 = mul nuw i32 %5151, 42170" -> "  %5523 = add nuw i32 %5522, %5521"
"  %5522 = and i32 %5520, 65535"
"  %5522 = and i32 %5520, 65535" -> "  %5523 = add nuw i32 %5522, %5521"
"  %5523 = add nuw i32 %5522, %5521"
"  %5523 = add nuw i32 %5522, %5521" -> "  %5535 = and i32 %5523, 65535""  %5523 = add nuw i32 %5522, %5521" -> "  %5527 = lshr i32 %5523, 16"
"  %5524 = lshr i32 %5520, 16"
"  %5524 = lshr i32 %5520, 16" -> "  %5526 = add nuw i32 %5524, %5525"
"  %5525 = mul nuw i32 %5152, 42170"
"  %5525 = mul nuw i32 %5152, 42170" -> "  %5526 = add nuw i32 %5524, %5525"
"  %5526 = add nuw i32 %5524, %5525"
"  %5526 = add nuw i32 %5524, %5525" -> "  %5530 = and i32 %5526, -65536""  %5526 = add nuw i32 %5524, %5525" -> "  %5528 = and i32 %5526, 65535"
"  %5527 = lshr i32 %5523, 16"
"  %5527 = lshr i32 %5523, 16" -> "  %5529 = add nuw nsw i32 %5527, %5528"
"  %5528 = and i32 %5526, 65535"
"  %5528 = and i32 %5526, 65535" -> "  %5529 = add nuw nsw i32 %5527, %5528"
"  %5529 = add nuw nsw i32 %5527, %5528"
"  %5529 = add nuw nsw i32 %5527, %5528" -> "  %5531 = add nuw i32 %5529, %5530"
"  %5530 = and i32 %5526, -65536"
"  %5530 = and i32 %5526, -65536" -> "  %5531 = add nuw i32 %5529, %5530"
"  %5531 = add nuw i32 %5529, %5530"
"  %5531 = add nuw i32 %5529, %5530" -> "  %5539 = add nuw i32 %5531, %5538"
"  %5532 = and i32 %5482, 65535"
"  %5532 = and i32 %5482, 65535" -> "  %5534 = add nuw nsw i32 %5532, %5533"
"  %5533 = and i32 %5514, 65528"
"  %5533 = and i32 %5514, 65528" -> "  %5534 = add nuw nsw i32 %5532, %5533"
"  %5534 = add nuw nsw i32 %5532, %5533"
"  %5534 = add nuw nsw i32 %5532, %5533" -> "  %5545 = and i32 %5534, 65535""  %5534 = add nuw nsw i32 %5532, %5533" -> "  %5541 = lshr i32 %5534, 16"
"  %5535 = and i32 %5523, 65535"
"  %5535 = and i32 %5523, 65535" -> "  %5537 = add nuw nsw i32 %5536, %5535"
"  %5536 = lshr i32 %5482, 16"
"  %5536 = lshr i32 %5482, 16" -> "  %5537 = add nuw nsw i32 %5536, %5535"
"  %5537 = add nuw nsw i32 %5536, %5535"
"  %5537 = add nuw nsw i32 %5536, %5535" -> "  %5540 = and i32 %5537, 65535""  %5537 = add nuw nsw i32 %5536, %5535" -> "  %5538 = lshr i32 %5537, 16"
"  %5538 = lshr i32 %5537, 16"
"  %5538 = lshr i32 %5537, 16" -> "  %5539 = add nuw i32 %5531, %5538"
"  %5539 = add nuw i32 %5531, %5538"
"  %5539 = add nuw i32 %5531, %5538" -> "  %5544 = add nuw i32 %5539, %5543"
"  %5540 = and i32 %5537, 65535"
"  %5540 = and i32 %5537, 65535" -> "  %5542 = add nuw nsw i32 %5540, %5541"
"  %5541 = lshr i32 %5534, 16"
"  %5541 = lshr i32 %5534, 16" -> "  %5542 = add nuw nsw i32 %5540, %5541"
"  %5542 = add nuw nsw i32 %5540, %5541"
"  %5542 = add nuw nsw i32 %5540, %5541" -> "  %5548 = and i32 %5542, 65535""  %5542 = add nuw nsw i32 %5540, %5541" -> "  %5543 = lshr i32 %5542, 16"
"  %5543 = lshr i32 %5542, 16"
"  %5543 = lshr i32 %5542, 16" -> "  %5544 = add nuw i32 %5539, %5543"
"  %5544 = add nuw i32 %5539, %5543"
"  %5544 = add nuw i32 %5539, %5543" -> "  %5557 = and i32 %5544, -65536""  %5544 = add nuw i32 %5539, %5543" -> "  %5555 = and i32 %5544, 65535"
"  %5545 = and i32 %5534, 65535"
"  %5545 = and i32 %5534, 65535" -> "  %5547 = add nuw nsw i32 %5546, %5545"
"  %5546 = and i32 %5513, 65535"
"  %5546 = and i32 %5513, 65535" -> "  %5547 = add nuw nsw i32 %5546, %5545"
"  %5547 = add nuw nsw i32 %5546, %5545"
"  %5547 = add nuw nsw i32 %5546, %5545" -> "  %5587 = and i32 %5547, 65535""  %5547 = add nuw nsw i32 %5546, %5545" -> "  %5551 = lshr i32 %5547, 16"
"  %5548 = and i32 %5542, 65535"
"  %5548 = and i32 %5542, 65535" -> "  %5550 = add nuw nsw i32 %5548, %5549"
"  %5549 = lshr i32 %5513, 16"
"  %5549 = lshr i32 %5513, 16" -> "  %5550 = add nuw nsw i32 %5548, %5549"
"  %5550 = add nuw nsw i32 %5548, %5549"
"  %5550 = add nuw nsw i32 %5548, %5549" -> "  %5554 = lshr i32 %5550, 16""  %5550 = add nuw nsw i32 %5548, %5549" -> "  %5552 = and i32 %5550, 65535"
"  %5551 = lshr i32 %5547, 16"
"  %5551 = lshr i32 %5547, 16" -> "  %5553 = add nuw nsw i32 %5552, %5551"
"  %5552 = and i32 %5550, 65535"
"  %5552 = and i32 %5550, 65535" -> "  %5553 = add nuw nsw i32 %5552, %5551"
"  %5553 = add nuw nsw i32 %5552, %5551"
"  %5553 = add nuw nsw i32 %5552, %5551" -> "  %5594 = and i32 %5553, 65535""  %5553 = add nuw nsw i32 %5552, %5551" -> "  %5559 = lshr i32 %5553, 16"
"  %5554 = lshr i32 %5550, 16"
"  %5554 = lshr i32 %5550, 16" -> "  %5556 = add nuw nsw i32 %5554, %5555"
"  %5555 = and i32 %5544, 65535"
"  %5555 = and i32 %5544, 65535" -> "  %5556 = add nuw nsw i32 %5554, %5555"
"  %5556 = add nuw nsw i32 %5554, %5555"
"  %5556 = add nuw nsw i32 %5554, %5555" -> "  %5558 = add nuw i32 %5556, %5557"
"  %5557 = and i32 %5544, -65536"
"  %5557 = and i32 %5544, -65536" -> "  %5558 = add nuw i32 %5556, %5557"
"  %5558 = add nuw i32 %5556, %5557"
"  %5558 = add nuw i32 %5556, %5557" -> "  %5560 = add nuw i32 %5558, %5559"
"  %5559 = lshr i32 %5553, 16"
"  %5559 = lshr i32 %5553, 16" -> "  %5560 = add nuw i32 %5558, %5559"
"  %5560 = add nuw i32 %5558, %5559"
"  %5560 = add nuw i32 %5558, %5559" -> "  %5598 = add nuw i32 %5560, %5597"
"  %5561 = and i32 %5434, 65535"
"  %5561 = and i32 %5434, 65535" -> "  %5563 = add nuw nsw i32 %5562, %5561"
"  %5562 = and i32 %5398, 65535"
"  %5562 = and i32 %5398, 65535" -> "  %5563 = add nuw nsw i32 %5562, %5561"
"  %5563 = add nuw nsw i32 %5562, %5561"
"  %5563 = add nuw nsw i32 %5562, %5561" -> "  %5567 = lshr i32 %5563, 16"
"  %5564 = and i32 %5443, 65535"
"  %5564 = and i32 %5443, 65535" -> "  %5566 = add nuw nsw i32 %5565, %5564"
"  %5565 = and i32 %5404, 65535"
"  %5565 = and i32 %5404, 65535" -> "  %5566 = add nuw nsw i32 %5565, %5564"
"  %5566 = add nuw nsw i32 %5565, %5564"
"  %5566 = add nuw nsw i32 %5565, %5564" -> "  %5570 = lshr i32 %5566, 16""  %5566 = add nuw nsw i32 %5565, %5564" -> "  %5568 = and i32 %5566, 65535"
"  %5567 = lshr i32 %5563, 16"
"  %5567 = lshr i32 %5563, 16" -> "  %5569 = add nuw nsw i32 %5568, %5567"
"  %5568 = and i32 %5566, 65535"
"  %5568 = and i32 %5566, 65535" -> "  %5569 = add nuw nsw i32 %5568, %5567"
"  %5569 = add nuw nsw i32 %5568, %5567"
"  %5569 = add nuw nsw i32 %5568, %5567" -> "  %5571 = lshr i32 %5569, 16"
"  %5570 = lshr i32 %5566, 16"
"  %5570 = lshr i32 %5566, 16" -> "  %5582 = add nuw nsw i32 %5571, %5570"
"  %5571 = lshr i32 %5569, 16"
"  %5571 = lshr i32 %5569, 16" -> "  %5582 = add nuw nsw i32 %5571, %5570"
"  %5572 = and i32 %5503, 65535"
"  %5572 = and i32 %5503, 65535" -> "  %5574 = add nuw nsw i32 %5573, %5572"
"  %5573 = and i32 %5418, 65535"
"  %5573 = and i32 %5418, 65535" -> "  %5574 = add nuw nsw i32 %5573, %5572"
"  %5574 = add nuw nsw i32 %5573, %5572"
"  %5574 = add nuw nsw i32 %5573, %5572" -> "  %5581 = and i32 %5574, 65535""  %5574 = add nuw nsw i32 %5573, %5572" -> "  %5578 = lshr i32 %5574, 16"
"  %5575 = and i32 %5511, 65535"
"  %5575 = and i32 %5511, 65535" -> "  %5577 = add nuw nsw i32 %5576, %5575"
"  %5576 = and i32 %5421, 65535"
"  %5576 = and i32 %5421, 65535" -> "  %5577 = add nuw nsw i32 %5576, %5575"
"  %5577 = add nuw nsw i32 %5576, %5575"
"  %5577 = add nuw nsw i32 %5576, %5575" -> "  %5588 = lshr i32 %5577, 16""  %5577 = add nuw nsw i32 %5576, %5575" -> "  %5579 = and i32 %5577, 65535"
"  %5578 = lshr i32 %5574, 16"
"  %5578 = lshr i32 %5574, 16" -> "  %5580 = add nuw nsw i32 %5579, %5578"
"  %5579 = and i32 %5577, 65535"
"  %5579 = and i32 %5577, 65535" -> "  %5580 = add nuw nsw i32 %5579, %5578"
"  %5580 = add nuw nsw i32 %5579, %5578"
"  %5580 = add nuw nsw i32 %5579, %5578" -> "  %5590 = lshr i32 %5580, 16""  %5580 = add nuw nsw i32 %5579, %5578" -> "  %5585 = and i32 %5580, 65535"
"  %5581 = and i32 %5574, 65535"
"  %5581 = and i32 %5574, 65535" -> "  %5583 = add nuw nsw i32 %5582, %5581"
"  %5582 = add nuw nsw i32 %5571, %5570"
"  %5582 = add nuw nsw i32 %5571, %5570" -> "  %5583 = add nuw nsw i32 %5582, %5581"
"  %5583 = add nuw nsw i32 %5582, %5581"
"  %5583 = add nuw nsw i32 %5582, %5581" -> "  %5584 = lshr i32 %5583, 16"
"  %5584 = lshr i32 %5583, 16"
"  %5584 = lshr i32 %5583, 16" -> "  %5586 = add nuw nsw i32 %5585, %5584"
"  %5585 = and i32 %5580, 65535"
"  %5585 = and i32 %5580, 65535" -> "  %5586 = add nuw nsw i32 %5585, %5584"
"  %5586 = add nuw nsw i32 %5585, %5584"
"  %5586 = add nuw nsw i32 %5585, %5584" -> "  %5592 = lshr i32 %5586, 16"
"  %5587 = and i32 %5547, 65535"
"  %5587 = and i32 %5547, 65535" -> "  %5589 = add nuw nsw i32 %5588, %5587"
"  %5588 = lshr i32 %5577, 16"
"  %5588 = lshr i32 %5577, 16" -> "  %5589 = add nuw nsw i32 %5588, %5587"
"  %5589 = add nuw nsw i32 %5588, %5587"
"  %5589 = add nuw nsw i32 %5588, %5587" -> "  %5591 = add nuw nsw i32 %5589, %5590"
"  %5590 = lshr i32 %5580, 16"
"  %5590 = lshr i32 %5580, 16" -> "  %5591 = add nuw nsw i32 %5589, %5590"
"  %5591 = add nuw nsw i32 %5589, %5590"
"  %5591 = add nuw nsw i32 %5589, %5590" -> "  %5593 = add nuw nsw i32 %5591, %5592"
"  %5592 = lshr i32 %5586, 16"
"  %5592 = lshr i32 %5586, 16" -> "  %5593 = add nuw nsw i32 %5591, %5592"
"  %5593 = add nuw nsw i32 %5591, %5592"
"  %5593 = add nuw nsw i32 %5591, %5592" -> "  %5765 = and i32 %5593, 65535""  %5593 = add nuw nsw i32 %5591, %5592" -> "  %5595 = lshr i32 %5593, 16"
"  %5594 = and i32 %5553, 65535"
"  %5594 = and i32 %5553, 65535" -> "  %5596 = add nuw nsw i32 %5595, %5594"
"  %5595 = lshr i32 %5593, 16"
"  %5595 = lshr i32 %5593, 16" -> "  %5596 = add nuw nsw i32 %5595, %5594"
"  %5596 = add nuw nsw i32 %5595, %5594"
"  %5596 = add nuw nsw i32 %5595, %5594" -> "  %5768 = and i32 %5596, 65535""  %5596 = add nuw nsw i32 %5595, %5594" -> "  %5597 = lshr i32 %5596, 16"
"  %5597 = lshr i32 %5596, 16"
"  %5597 = lshr i32 %5596, 16" -> "  %5598 = add nuw i32 %5560, %5597"
"  %5598 = add nuw i32 %5560, %5597"
"  %5598 = add nuw i32 %5560, %5597" -> "  %5774 = and i32 %5598, 65535""  %5598 = add nuw i32 %5560, %5597" -> "  %5777 = lshr i32 %5598, 16"
"  %5599 = mul nuw nsw i32 %5262, 17857"
"  %5599 = mul nuw nsw i32 %5262, 17857" -> "  %5726 = and i32 %5599, 65535""  %5599 = mul nuw nsw i32 %5262, 17857" -> "  %5600 = lshr i32 %5599, 16"
"  %5600 = lshr i32 %5599, 16"
"  %5600 = lshr i32 %5599, 16" -> "  %5603 = add nuw nsw i32 %5602, %5600"
"  %5601 = mul nuw nsw i32 %5265, 17857"
"  %5601 = mul nuw nsw i32 %5265, 17857" -> "  %5604 = and i32 %5601, 2147418112""  %5601 = mul nuw nsw i32 %5265, 17857" -> "  %5602 = and i32 %5601, 65535"
"  %5602 = and i32 %5601, 65535"
"  %5602 = and i32 %5601, 65535" -> "  %5603 = add nuw nsw i32 %5602, %5600"
"  %5603 = add nuw nsw i32 %5602, %5600"
"  %5603 = add nuw nsw i32 %5602, %5600" -> "  %5605 = add nuw nsw i32 %5603, %5604"
"  %5604 = and i32 %5601, 2147418112"
"  %5604 = and i32 %5601, 2147418112" -> "  %5605 = add nuw nsw i32 %5603, %5604"
"  %5605 = add nuw nsw i32 %5603, %5604"
"  %5605 = add nuw nsw i32 %5603, %5604" -> "  %5609 = lshr i32 %5605, 16""  %5605 = add nuw nsw i32 %5603, %5604" -> "  %5607 = and i32 %5605, 65535"
"  %5606 = mul nuw i32 %5262, 46547"
"  %5606 = mul nuw i32 %5262, 46547" -> "  %5608 = add nuw i32 %5607, %5606"
"  %5607 = and i32 %5605, 65535"
"  %5607 = and i32 %5605, 65535" -> "  %5608 = add nuw i32 %5607, %5606"
"  %5608 = add nuw i32 %5607, %5606"
"  %5608 = add nuw i32 %5607, %5606" -> "  %5729 = and i32 %5608, 65535""  %5608 = add nuw i32 %5607, %5606" -> "  %5612 = lshr i32 %5608, 16"
"  %5609 = lshr i32 %5605, 16"
"  %5609 = lshr i32 %5605, 16" -> "  %5611 = add nuw i32 %5609, %5610"
"  %5610 = mul nuw i32 %5265, 46547"
"  %5610 = mul nuw i32 %5265, 46547" -> "  %5611 = add nuw i32 %5609, %5610"
"  %5611 = add nuw i32 %5609, %5610"
"  %5611 = add nuw i32 %5609, %5610" -> "  %5615 = and i32 %5611, -65536""  %5611 = add nuw i32 %5609, %5610" -> "  %5613 = and i32 %5611, 65535"
"  %5612 = lshr i32 %5608, 16"
"  %5612 = lshr i32 %5608, 16" -> "  %5614 = add nuw nsw i32 %5612, %5613"
"  %5613 = and i32 %5611, 65535"
"  %5613 = and i32 %5611, 65535" -> "  %5614 = add nuw nsw i32 %5612, %5613"
"  %5614 = add nuw nsw i32 %5612, %5613"
"  %5614 = add nuw nsw i32 %5612, %5613" -> "  %5616 = add nuw i32 %5614, %5615"
"  %5615 = and i32 %5611, -65536"
"  %5615 = and i32 %5611, -65536" -> "  %5616 = add nuw i32 %5614, %5615"
"  %5616 = add nuw i32 %5614, %5615"
"  %5616 = add nuw i32 %5614, %5615" -> "  %5639 = lshr i32 %5616, 16""  %5616 = add nuw i32 %5614, %5615" -> "  %5635 = and i32 %5616, 65535"
"  %5617 = mul nuw nsw i32 %5282, 17857"
"  %5617 = mul nuw nsw i32 %5282, 17857" -> "  %5636 = and i32 %5617, 65535""  %5617 = mul nuw nsw i32 %5282, 17857" -> "  %5618 = lshr i32 %5617, 16"
"  %5618 = lshr i32 %5617, 16"
"  %5618 = lshr i32 %5617, 16" -> "  %5621 = add nuw nsw i32 %5620, %5618"
"  %5619 = mul nuw nsw i32 %5285, 17857"
"  %5619 = mul nuw nsw i32 %5285, 17857" -> "  %5622 = and i32 %5619, 2147418112""  %5619 = mul nuw nsw i32 %5285, 17857" -> "  %5620 = and i32 %5619, 65535"
"  %5620 = and i32 %5619, 65535"
"  %5620 = and i32 %5619, 65535" -> "  %5621 = add nuw nsw i32 %5620, %5618"
"  %5621 = add nuw nsw i32 %5620, %5618"
"  %5621 = add nuw nsw i32 %5620, %5618" -> "  %5623 = add nuw nsw i32 %5621, %5622"
"  %5622 = and i32 %5619, 2147418112"
"  %5622 = and i32 %5619, 2147418112" -> "  %5623 = add nuw nsw i32 %5621, %5622"
"  %5623 = add nuw nsw i32 %5621, %5622"
"  %5623 = add nuw nsw i32 %5621, %5622" -> "  %5627 = lshr i32 %5623, 16""  %5623 = add nuw nsw i32 %5621, %5622" -> "  %5625 = and i32 %5623, 65535"
"  %5624 = mul nuw i32 %5282, 46547"
"  %5624 = mul nuw i32 %5282, 46547" -> "  %5626 = add nuw i32 %5625, %5624"
"  %5625 = and i32 %5623, 65535"
"  %5625 = and i32 %5623, 65535" -> "  %5626 = add nuw i32 %5625, %5624"
"  %5626 = add nuw i32 %5625, %5624"
"  %5626 = add nuw i32 %5625, %5624" -> "  %5638 = and i32 %5626, 65535""  %5626 = add nuw i32 %5625, %5624" -> "  %5630 = lshr i32 %5626, 16"
"  %5627 = lshr i32 %5623, 16"
"  %5627 = lshr i32 %5623, 16" -> "  %5629 = add nuw i32 %5627, %5628"
"  %5628 = mul nuw i32 %5285, 46547"
"  %5628 = mul nuw i32 %5285, 46547" -> "  %5629 = add nuw i32 %5627, %5628"
"  %5629 = add nuw i32 %5627, %5628"
"  %5629 = add nuw i32 %5627, %5628" -> "  %5633 = and i32 %5629, -65536""  %5629 = add nuw i32 %5627, %5628" -> "  %5631 = and i32 %5629, 65535"
"  %5630 = lshr i32 %5626, 16"
"  %5630 = lshr i32 %5626, 16" -> "  %5632 = add nuw nsw i32 %5630, %5631"
"  %5631 = and i32 %5629, 65535"
"  %5631 = and i32 %5629, 65535" -> "  %5632 = add nuw nsw i32 %5630, %5631"
"  %5632 = add nuw nsw i32 %5630, %5631"
"  %5632 = add nuw nsw i32 %5630, %5631" -> "  %5634 = add nuw i32 %5632, %5633"
"  %5633 = and i32 %5629, -65536"
"  %5633 = and i32 %5629, -65536" -> "  %5634 = add nuw i32 %5632, %5633"
"  %5634 = add nuw i32 %5632, %5633"
"  %5634 = add nuw i32 %5632, %5633" -> "  %5642 = add nuw i32 %5634, %5641"
"  %5635 = and i32 %5616, 65535"
"  %5635 = and i32 %5616, 65535" -> "  %5637 = add nuw nsw i32 %5635, %5636"
"  %5636 = and i32 %5617, 65535"
"  %5636 = and i32 %5617, 65535" -> "  %5637 = add nuw nsw i32 %5635, %5636"
"  %5637 = add nuw nsw i32 %5635, %5636"
"  %5637 = add nuw nsw i32 %5635, %5636" -> "  %5666 = and i32 %5637, 65535""  %5637 = add nuw nsw i32 %5635, %5636" -> "  %5644 = lshr i32 %5637, 16"
"  %5638 = and i32 %5626, 65535"
"  %5638 = and i32 %5626, 65535" -> "  %5640 = add nuw nsw i32 %5638, %5639"
"  %5639 = lshr i32 %5616, 16"
"  %5639 = lshr i32 %5616, 16" -> "  %5640 = add nuw nsw i32 %5638, %5639"
"  %5640 = add nuw nsw i32 %5638, %5639"
"  %5640 = add nuw nsw i32 %5638, %5639" -> "  %5643 = and i32 %5640, 65535""  %5640 = add nuw nsw i32 %5638, %5639" -> "  %5641 = lshr i32 %5640, 16"
"  %5641 = lshr i32 %5640, 16"
"  %5641 = lshr i32 %5640, 16" -> "  %5642 = add nuw i32 %5634, %5641"
"  %5642 = add nuw i32 %5634, %5641"
"  %5642 = add nuw i32 %5634, %5641" -> "  %5647 = add nuw i32 %5642, %5646"
"  %5643 = and i32 %5640, 65535"
"  %5643 = and i32 %5640, 65535" -> "  %5645 = add nuw nsw i32 %5643, %5644"
"  %5644 = lshr i32 %5637, 16"
"  %5644 = lshr i32 %5637, 16" -> "  %5645 = add nuw nsw i32 %5643, %5644"
"  %5645 = add nuw nsw i32 %5643, %5644"
"  %5645 = add nuw nsw i32 %5643, %5644" -> "  %5669 = and i32 %5645, 65535""  %5645 = add nuw nsw i32 %5643, %5644" -> "  %5646 = lshr i32 %5645, 16"
"  %5646 = lshr i32 %5645, 16"
"  %5646 = lshr i32 %5645, 16" -> "  %5647 = add nuw i32 %5642, %5646"
"  %5647 = add nuw i32 %5642, %5646"
"  %5647 = add nuw i32 %5642, %5646" -> "  %5701 = lshr i32 %5647, 16""  %5647 = add nuw i32 %5642, %5646" -> "  %5697 = and i32 %5647, 65535"
"  %5648 = mul nuw nsw i32 %5262, 31112"
"  %5648 = mul nuw nsw i32 %5262, 31112" -> "  %5667 = and i32 %5648, 65528""  %5648 = mul nuw nsw i32 %5262, 31112" -> "  %5649 = lshr i32 %5648, 16"
"  %5649 = lshr i32 %5648, 16"
"  %5649 = lshr i32 %5648, 16" -> "  %5652 = add nuw nsw i32 %5651, %5649"
"  %5650 = mul nuw nsw i32 %5265, 31112"
"  %5650 = mul nuw nsw i32 %5265, 31112" -> "  %5653 = and i32 %5650, 2147418112""  %5650 = mul nuw nsw i32 %5265, 31112" -> "  %5651 = and i32 %5650, 65528"
"  %5651 = and i32 %5650, 65528"
"  %5651 = and i32 %5650, 65528" -> "  %5652 = add nuw nsw i32 %5651, %5649"
"  %5652 = add nuw nsw i32 %5651, %5649"
"  %5652 = add nuw nsw i32 %5651, %5649" -> "  %5654 = add nuw nsw i32 %5652, %5653"
"  %5653 = and i32 %5650, 2147418112"
"  %5653 = and i32 %5650, 2147418112" -> "  %5654 = add nuw nsw i32 %5652, %5653"
"  %5654 = add nuw nsw i32 %5652, %5653"
"  %5654 = add nuw nsw i32 %5652, %5653" -> "  %5658 = lshr i32 %5654, 16""  %5654 = add nuw nsw i32 %5652, %5653" -> "  %5656 = and i32 %5654, 65535"
"  %5655 = mul nuw i32 %5262, 42170"
"  %5655 = mul nuw i32 %5262, 42170" -> "  %5657 = add nuw i32 %5656, %5655"
"  %5656 = and i32 %5654, 65535"
"  %5656 = and i32 %5654, 65535" -> "  %5657 = add nuw i32 %5656, %5655"
"  %5657 = add nuw i32 %5656, %5655"
"  %5657 = add nuw i32 %5656, %5655" -> "  %5670 = and i32 %5657, 65535""  %5657 = add nuw i32 %5656, %5655" -> "  %5661 = lshr i32 %5657, 16"
"  %5658 = lshr i32 %5654, 16"
"  %5658 = lshr i32 %5654, 16" -> "  %5660 = add nuw i32 %5658, %5659"
"  %5659 = mul nuw i32 %5265, 42170"
"  %5659 = mul nuw i32 %5265, 42170" -> "  %5660 = add nuw i32 %5658, %5659"
"  %5660 = add nuw i32 %5658, %5659"
"  %5660 = add nuw i32 %5658, %5659" -> "  %5664 = and i32 %5660, -65536""  %5660 = add nuw i32 %5658, %5659" -> "  %5662 = and i32 %5660, 65535"
"  %5661 = lshr i32 %5657, 16"
"  %5661 = lshr i32 %5657, 16" -> "  %5663 = add nuw nsw i32 %5661, %5662"
"  %5662 = and i32 %5660, 65535"
"  %5662 = and i32 %5660, 65535" -> "  %5663 = add nuw nsw i32 %5661, %5662"
"  %5663 = add nuw nsw i32 %5661, %5662"
"  %5663 = add nuw nsw i32 %5661, %5662" -> "  %5665 = add nuw i32 %5663, %5664"
"  %5664 = and i32 %5660, -65536"
"  %5664 = and i32 %5660, -65536" -> "  %5665 = add nuw i32 %5663, %5664"
"  %5665 = add nuw i32 %5663, %5664"
"  %5665 = add nuw i32 %5663, %5664" -> "  %5673 = add nuw i32 %5665, %5672"
"  %5666 = and i32 %5637, 65535"
"  %5666 = and i32 %5637, 65535" -> "  %5668 = add nuw nsw i32 %5666, %5667"
"  %5667 = and i32 %5648, 65528"
"  %5667 = and i32 %5648, 65528" -> "  %5668 = add nuw nsw i32 %5666, %5667"
"  %5668 = add nuw nsw i32 %5666, %5667"
"  %5668 = add nuw nsw i32 %5666, %5667" -> "  %5735 = and i32 %5668, 65535""  %5668 = add nuw nsw i32 %5666, %5667" -> "  %5675 = lshr i32 %5668, 16"
"  %5669 = and i32 %5645, 65535"
"  %5669 = and i32 %5645, 65535" -> "  %5671 = add nuw nsw i32 %5669, %5670"
"  %5670 = and i32 %5657, 65535"
"  %5670 = and i32 %5657, 65535" -> "  %5671 = add nuw nsw i32 %5669, %5670"
"  %5671 = add nuw nsw i32 %5669, %5670"
"  %5671 = add nuw nsw i32 %5669, %5670" -> "  %5674 = and i32 %5671, 65535""  %5671 = add nuw nsw i32 %5669, %5670" -> "  %5672 = lshr i32 %5671, 16"
"  %5672 = lshr i32 %5671, 16"
"  %5672 = lshr i32 %5671, 16" -> "  %5673 = add nuw i32 %5665, %5672"
"  %5673 = add nuw i32 %5665, %5672"
"  %5673 = add nuw i32 %5665, %5672" -> "  %5678 = add nuw i32 %5673, %5677"
"  %5674 = and i32 %5671, 65535"
"  %5674 = and i32 %5671, 65535" -> "  %5676 = add nuw nsw i32 %5674, %5675"
"  %5675 = lshr i32 %5668, 16"
"  %5675 = lshr i32 %5668, 16" -> "  %5676 = add nuw nsw i32 %5674, %5675"
"  %5676 = add nuw nsw i32 %5674, %5675"
"  %5676 = add nuw nsw i32 %5674, %5675" -> "  %5738 = and i32 %5676, 65535""  %5676 = add nuw nsw i32 %5674, %5675" -> "  %5677 = lshr i32 %5676, 16"
"  %5677 = lshr i32 %5676, 16"
"  %5677 = lshr i32 %5676, 16" -> "  %5678 = add nuw i32 %5673, %5677"
"  %5678 = add nuw i32 %5673, %5677"
"  %5678 = add nuw i32 %5673, %5677" -> "  %5714 = lshr i32 %5678, 16""  %5678 = add nuw i32 %5673, %5677" -> "  %5711 = and i32 %5678, 65535"
"  %5679 = mul nuw nsw i32 %5282, 31112"
"  %5679 = mul nuw nsw i32 %5282, 31112" -> "  %5698 = and i32 %5679, 65528""  %5679 = mul nuw nsw i32 %5282, 31112" -> "  %5680 = lshr i32 %5679, 16"
"  %5680 = lshr i32 %5679, 16"
"  %5680 = lshr i32 %5679, 16" -> "  %5683 = add nuw nsw i32 %5682, %5680"
"  %5681 = mul nuw nsw i32 %5285, 31112"
"  %5681 = mul nuw nsw i32 %5285, 31112" -> "  %5684 = and i32 %5681, 2147418112""  %5681 = mul nuw nsw i32 %5285, 31112" -> "  %5682 = and i32 %5681, 65528"
"  %5682 = and i32 %5681, 65528"
"  %5682 = and i32 %5681, 65528" -> "  %5683 = add nuw nsw i32 %5682, %5680"
"  %5683 = add nuw nsw i32 %5682, %5680"
"  %5683 = add nuw nsw i32 %5682, %5680" -> "  %5685 = add nuw nsw i32 %5683, %5684"
"  %5684 = and i32 %5681, 2147418112"
"  %5684 = and i32 %5681, 2147418112" -> "  %5685 = add nuw nsw i32 %5683, %5684"
"  %5685 = add nuw nsw i32 %5683, %5684"
"  %5685 = add nuw nsw i32 %5683, %5684" -> "  %5689 = lshr i32 %5685, 16""  %5685 = add nuw nsw i32 %5683, %5684" -> "  %5687 = and i32 %5685, 65535"
"  %5686 = mul nuw i32 %5282, 42170"
"  %5686 = mul nuw i32 %5282, 42170" -> "  %5688 = add nuw i32 %5687, %5686"
"  %5687 = and i32 %5685, 65535"
"  %5687 = and i32 %5685, 65535" -> "  %5688 = add nuw i32 %5687, %5686"
"  %5688 = add nuw i32 %5687, %5686"
"  %5688 = add nuw i32 %5687, %5686" -> "  %5700 = and i32 %5688, 65535""  %5688 = add nuw i32 %5687, %5686" -> "  %5692 = lshr i32 %5688, 16"
"  %5689 = lshr i32 %5685, 16"
"  %5689 = lshr i32 %5685, 16" -> "  %5691 = add nuw i32 %5689, %5690"
"  %5690 = mul nuw i32 %5285, 42170"
"  %5690 = mul nuw i32 %5285, 42170" -> "  %5691 = add nuw i32 %5689, %5690"
"  %5691 = add nuw i32 %5689, %5690"
"  %5691 = add nuw i32 %5689, %5690" -> "  %5695 = and i32 %5691, -65536""  %5691 = add nuw i32 %5689, %5690" -> "  %5693 = and i32 %5691, 65535"
"  %5692 = lshr i32 %5688, 16"
"  %5692 = lshr i32 %5688, 16" -> "  %5694 = add nuw nsw i32 %5692, %5693"
"  %5693 = and i32 %5691, 65535"
"  %5693 = and i32 %5691, 65535" -> "  %5694 = add nuw nsw i32 %5692, %5693"
"  %5694 = add nuw nsw i32 %5692, %5693"
"  %5694 = add nuw nsw i32 %5692, %5693" -> "  %5696 = add nuw i32 %5694, %5695"
"  %5695 = and i32 %5691, -65536"
"  %5695 = and i32 %5691, -65536" -> "  %5696 = add nuw i32 %5694, %5695"
"  %5696 = add nuw i32 %5694, %5695"
"  %5696 = add nuw i32 %5694, %5695" -> "  %5704 = add nuw i32 %5696, %5703"
"  %5697 = and i32 %5647, 65535"
"  %5697 = and i32 %5647, 65535" -> "  %5699 = add nuw nsw i32 %5697, %5698"
"  %5698 = and i32 %5679, 65528"
"  %5698 = and i32 %5679, 65528" -> "  %5699 = add nuw nsw i32 %5697, %5698"
"  %5699 = add nuw nsw i32 %5697, %5698"
"  %5699 = add nuw nsw i32 %5697, %5698" -> "  %5710 = and i32 %5699, 65535""  %5699 = add nuw nsw i32 %5697, %5698" -> "  %5706 = lshr i32 %5699, 16"
"  %5700 = and i32 %5688, 65535"
"  %5700 = and i32 %5688, 65535" -> "  %5702 = add nuw nsw i32 %5701, %5700"
"  %5701 = lshr i32 %5647, 16"
"  %5701 = lshr i32 %5647, 16" -> "  %5702 = add nuw nsw i32 %5701, %5700"
"  %5702 = add nuw nsw i32 %5701, %5700"
"  %5702 = add nuw nsw i32 %5701, %5700" -> "  %5705 = and i32 %5702, 65535""  %5702 = add nuw nsw i32 %5701, %5700" -> "  %5703 = lshr i32 %5702, 16"
"  %5703 = lshr i32 %5702, 16"
"  %5703 = lshr i32 %5702, 16" -> "  %5704 = add nuw i32 %5696, %5703"
"  %5704 = add nuw i32 %5696, %5703"
"  %5704 = add nuw i32 %5696, %5703" -> "  %5709 = add nuw i32 %5704, %5708"
"  %5705 = and i32 %5702, 65535"
"  %5705 = and i32 %5702, 65535" -> "  %5707 = add nuw nsw i32 %5705, %5706"
"  %5706 = lshr i32 %5699, 16"
"  %5706 = lshr i32 %5699, 16" -> "  %5707 = add nuw nsw i32 %5705, %5706"
"  %5707 = add nuw nsw i32 %5705, %5706"
"  %5707 = add nuw nsw i32 %5705, %5706" -> "  %5713 = and i32 %5707, 65535""  %5707 = add nuw nsw i32 %5705, %5706" -> "  %5708 = lshr i32 %5707, 16"
"  %5708 = lshr i32 %5707, 16"
"  %5708 = lshr i32 %5707, 16" -> "  %5709 = add nuw i32 %5704, %5708"
"  %5709 = add nuw i32 %5704, %5708"
"  %5709 = add nuw i32 %5704, %5708" -> "  %5722 = and i32 %5709, -65536""  %5709 = add nuw i32 %5704, %5708" -> "  %5720 = and i32 %5709, 65535"
"  %5710 = and i32 %5699, 65535"
"  %5710 = and i32 %5699, 65535" -> "  %5712 = add nuw nsw i32 %5711, %5710"
"  %5711 = and i32 %5678, 65535"
"  %5711 = and i32 %5678, 65535" -> "  %5712 = add nuw nsw i32 %5711, %5710"
"  %5712 = add nuw nsw i32 %5711, %5710"
"  %5712 = add nuw nsw i32 %5711, %5710" -> "  %5752 = and i32 %5712, 65535""  %5712 = add nuw nsw i32 %5711, %5710" -> "  %5716 = lshr i32 %5712, 16"
"  %5713 = and i32 %5707, 65535"
"  %5713 = and i32 %5707, 65535" -> "  %5715 = add nuw nsw i32 %5713, %5714"
"  %5714 = lshr i32 %5678, 16"
"  %5714 = lshr i32 %5678, 16" -> "  %5715 = add nuw nsw i32 %5713, %5714"
"  %5715 = add nuw nsw i32 %5713, %5714"
"  %5715 = add nuw nsw i32 %5713, %5714" -> "  %5719 = lshr i32 %5715, 16""  %5715 = add nuw nsw i32 %5713, %5714" -> "  %5717 = and i32 %5715, 65535"
"  %5716 = lshr i32 %5712, 16"
"  %5716 = lshr i32 %5712, 16" -> "  %5718 = add nuw nsw i32 %5717, %5716"
"  %5717 = and i32 %5715, 65535"
"  %5717 = and i32 %5715, 65535" -> "  %5718 = add nuw nsw i32 %5717, %5716"
"  %5718 = add nuw nsw i32 %5717, %5716"
"  %5718 = add nuw nsw i32 %5717, %5716" -> "  %5759 = and i32 %5718, 65535""  %5718 = add nuw nsw i32 %5717, %5716" -> "  %5724 = lshr i32 %5718, 16"
"  %5719 = lshr i32 %5715, 16"
"  %5719 = lshr i32 %5715, 16" -> "  %5721 = add nuw nsw i32 %5719, %5720"
"  %5720 = and i32 %5709, 65535"
"  %5720 = and i32 %5709, 65535" -> "  %5721 = add nuw nsw i32 %5719, %5720"
"  %5721 = add nuw nsw i32 %5719, %5720"
"  %5721 = add nuw nsw i32 %5719, %5720" -> "  %5723 = add nuw i32 %5721, %5722"
"  %5722 = and i32 %5709, -65536"
"  %5722 = and i32 %5709, -65536" -> "  %5723 = add nuw i32 %5721, %5722"
"  %5723 = add nuw i32 %5721, %5722"
"  %5723 = add nuw i32 %5721, %5722" -> "  %5725 = add nuw i32 %5723, %5724"
"  %5724 = lshr i32 %5718, 16"
"  %5724 = lshr i32 %5718, 16" -> "  %5725 = add nuw i32 %5723, %5724"
"  %5725 = add nuw i32 %5723, %5724"
"  %5725 = add nuw i32 %5723, %5724" -> "  %5763 = add nuw i32 %5725, %5762"
"  %5726 = and i32 %5599, 65535"
"  %5726 = and i32 %5599, 65535" -> "  %5728 = add nuw nsw i32 %5727, %5726"
"  %5727 = and i32 %5428, 65535"
"  %5727 = and i32 %5428, 65535" -> "  %5728 = add nuw nsw i32 %5727, %5726"
"  %5728 = add nuw nsw i32 %5727, %5726"
"  %5728 = add nuw nsw i32 %5727, %5726" -> "  %5764 = and i32 %5728, 65535""  %5728 = add nuw nsw i32 %5727, %5726" -> "  %5732 = lshr i32 %5728, 16"
"  %5729 = and i32 %5608, 65535"
"  %5729 = and i32 %5608, 65535" -> "  %5731 = add nuw nsw i32 %5730, %5729"
"  %5730 = and i32 %5431, 65535"
"  %5730 = and i32 %5431, 65535" -> "  %5731 = add nuw nsw i32 %5730, %5729"
"  %5731 = add nuw nsw i32 %5730, %5729"
"  %5731 = add nuw nsw i32 %5730, %5729" -> "  %5745 = lshr i32 %5731, 16""  %5731 = add nuw nsw i32 %5730, %5729" -> "  %5733 = and i32 %5731, 65535"
"  %5732 = lshr i32 %5728, 16"
"  %5732 = lshr i32 %5728, 16" -> "  %5734 = add nuw nsw i32 %5733, %5732"
"  %5733 = and i32 %5731, 65535"
"  %5733 = and i32 %5731, 65535" -> "  %5734 = add nuw nsw i32 %5733, %5732"
"  %5734 = add nuw nsw i32 %5733, %5732"
"  %5734 = add nuw nsw i32 %5733, %5732" -> "  %5767 = and i32 %5734, 65535""  %5734 = add nuw nsw i32 %5733, %5732" -> "  %5747 = lshr i32 %5734, 16"
"  %5735 = and i32 %5668, 65535"
"  %5735 = and i32 %5668, 65535" -> "  %5737 = add nuw nsw i32 %5736, %5735"
"  %5736 = and i32 %5433, 65535"
"  %5736 = and i32 %5433, 65535" -> "  %5737 = add nuw nsw i32 %5736, %5735"
"  %5737 = add nuw nsw i32 %5736, %5735"
"  %5737 = add nuw nsw i32 %5736, %5735" -> "  %5744 = and i32 %5737, 65535""  %5737 = add nuw nsw i32 %5736, %5735" -> "  %5741 = lshr i32 %5737, 16"
"  %5738 = and i32 %5676, 65535"
"  %5738 = and i32 %5676, 65535" -> "  %5740 = add nuw nsw i32 %5739, %5738"
"  %5739 = lshr i32 %5433, 16"
"  %5739 = lshr i32 %5433, 16" -> "  %5740 = add nuw nsw i32 %5739, %5738"
"  %5740 = add nuw nsw i32 %5739, %5738"
"  %5740 = add nuw nsw i32 %5739, %5738" -> "  %5753 = lshr i32 %5740, 16""  %5740 = add nuw nsw i32 %5739, %5738" -> "  %5742 = and i32 %5740, 65535"
"  %5741 = lshr i32 %5737, 16"
"  %5741 = lshr i32 %5737, 16" -> "  %5743 = add nuw nsw i32 %5741, %5742"
"  %5742 = and i32 %5740, 65535"
"  %5742 = and i32 %5740, 65535" -> "  %5743 = add nuw nsw i32 %5741, %5742"
"  %5743 = add nuw nsw i32 %5741, %5742"
"  %5743 = add nuw nsw i32 %5741, %5742" -> "  %5755 = lshr i32 %5743, 16""  %5743 = add nuw nsw i32 %5741, %5742" -> "  %5750 = and i32 %5743, 65535"
"  %5744 = and i32 %5737, 65535"
"  %5744 = and i32 %5737, 65535" -> "  %5746 = add nuw nsw i32 %5744, %5745"
"  %5745 = lshr i32 %5731, 16"
"  %5745 = lshr i32 %5731, 16" -> "  %5746 = add nuw nsw i32 %5744, %5745"
"  %5746 = add nuw nsw i32 %5744, %5745"
"  %5746 = add nuw nsw i32 %5744, %5745" -> "  %5748 = add nuw nsw i32 %5746, %5747"
"  %5747 = lshr i32 %5734, 16"
"  %5747 = lshr i32 %5734, 16" -> "  %5748 = add nuw nsw i32 %5746, %5747"
"  %5748 = add nuw nsw i32 %5746, %5747"
"  %5748 = add nuw nsw i32 %5746, %5747" -> "  %5773 = and i32 %5748, 65535""  %5748 = add nuw nsw i32 %5746, %5747" -> "  %5749 = lshr i32 %5748, 16"
"  %5749 = lshr i32 %5748, 16"
"  %5749 = lshr i32 %5748, 16" -> "  %5751 = add nuw nsw i32 %5749, %5750"
"  %5750 = and i32 %5743, 65535"
"  %5750 = and i32 %5743, 65535" -> "  %5751 = add nuw nsw i32 %5749, %5750"
"  %5751 = add nuw nsw i32 %5749, %5750"
"  %5751 = add nuw nsw i32 %5749, %5750" -> "  %5776 = and i32 %5751, 65535""  %5751 = add nuw nsw i32 %5749, %5750" -> "  %5757 = lshr i32 %5751, 16"
"  %5752 = and i32 %5712, 65535"
"  %5752 = and i32 %5712, 65535" -> "  %5754 = add nuw nsw i32 %5753, %5752"
"  %5753 = lshr i32 %5740, 16"
"  %5753 = lshr i32 %5740, 16" -> "  %5754 = add nuw nsw i32 %5753, %5752"
"  %5754 = add nuw nsw i32 %5753, %5752"
"  %5754 = add nuw nsw i32 %5753, %5752" -> "  %5756 = add nuw nsw i32 %5754, %5755"
"  %5755 = lshr i32 %5743, 16"
"  %5755 = lshr i32 %5743, 16" -> "  %5756 = add nuw nsw i32 %5754, %5755"
"  %5756 = add nuw nsw i32 %5754, %5755"
"  %5756 = add nuw nsw i32 %5754, %5755" -> "  %5758 = add nuw nsw i32 %5756, %5757"
"  %5757 = lshr i32 %5751, 16"
"  %5757 = lshr i32 %5751, 16" -> "  %5758 = add nuw nsw i32 %5756, %5757"
"  %5758 = add nuw nsw i32 %5756, %5757"
"  %5758 = add nuw nsw i32 %5756, %5757" -> "  %5790 = and i32 %5758, 65535""  %5758 = add nuw nsw i32 %5756, %5757" -> "  %5760 = lshr i32 %5758, 16"
"  %5759 = and i32 %5718, 65535"
"  %5759 = and i32 %5718, 65535" -> "  %5761 = add nuw nsw i32 %5760, %5759"
"  %5760 = lshr i32 %5758, 16"
"  %5760 = lshr i32 %5758, 16" -> "  %5761 = add nuw nsw i32 %5760, %5759"
"  %5761 = add nuw nsw i32 %5760, %5759"
"  %5761 = add nuw nsw i32 %5760, %5759" -> "  %5797 = and i32 %5761, 65535""  %5761 = add nuw nsw i32 %5760, %5759" -> "  %5762 = lshr i32 %5761, 16"
"  %5762 = lshr i32 %5761, 16"
"  %5762 = lshr i32 %5761, 16" -> "  %5763 = add nuw i32 %5725, %5762"
"  %5763 = add nuw i32 %5725, %5762"
"  %5763 = add nuw i32 %5725, %5762" -> "  %5801 = add nuw i32 %5763, %5800"
"  %5764 = and i32 %5728, 65535"
"  %5764 = and i32 %5728, 65535" -> "  %5766 = add nuw nsw i32 %5765, %5764"
"  %5765 = and i32 %5593, 65535"
"  %5765 = and i32 %5593, 65535" -> "  %5766 = add nuw nsw i32 %5765, %5764"
"  %5766 = add nuw nsw i32 %5765, %5764"
"  %5766 = add nuw nsw i32 %5765, %5764" -> "  %6455 = and i32 %5766, 65535""  %5766 = add nuw nsw i32 %5765, %5764" -> "  %5770 = lshr i32 %5766, 16"
"  %5767 = and i32 %5734, 65535"
"  %5767 = and i32 %5734, 65535" -> "  %5769 = add nuw nsw i32 %5768, %5767"
"  %5768 = and i32 %5596, 65535"
"  %5768 = and i32 %5596, 65535" -> "  %5769 = add nuw nsw i32 %5768, %5767"
"  %5769 = add nuw nsw i32 %5768, %5767"
"  %5769 = add nuw nsw i32 %5768, %5767" -> "  %5783 = lshr i32 %5769, 16""  %5769 = add nuw nsw i32 %5768, %5767" -> "  %5771 = and i32 %5769, 65535"
"  %5770 = lshr i32 %5766, 16"
"  %5770 = lshr i32 %5766, 16" -> "  %5772 = add nuw nsw i32 %5771, %5770"
"  %5771 = and i32 %5769, 65535"
"  %5771 = and i32 %5769, 65535" -> "  %5772 = add nuw nsw i32 %5771, %5770"
"  %5772 = add nuw nsw i32 %5771, %5770"
"  %5772 = add nuw nsw i32 %5771, %5770" -> "  %6458 = and i32 %5772, 65535""  %5772 = add nuw nsw i32 %5771, %5770" -> "  %5785 = lshr i32 %5772, 16"
"  %5773 = and i32 %5748, 65535"
"  %5773 = and i32 %5748, 65535" -> "  %5775 = add nuw nsw i32 %5774, %5773"
"  %5774 = and i32 %5598, 65535"
"  %5774 = and i32 %5598, 65535" -> "  %5775 = add nuw nsw i32 %5774, %5773"
"  %5775 = add nuw nsw i32 %5774, %5773"
"  %5775 = add nuw nsw i32 %5774, %5773" -> "  %5782 = and i32 %5775, 65535""  %5775 = add nuw nsw i32 %5774, %5773" -> "  %5779 = lshr i32 %5775, 16"
"  %5776 = and i32 %5751, 65535"
"  %5776 = and i32 %5751, 65535" -> "  %5778 = add nuw nsw i32 %5776, %5777"
"  %5777 = lshr i32 %5598, 16"
"  %5777 = lshr i32 %5598, 16" -> "  %5778 = add nuw nsw i32 %5776, %5777"
"  %5778 = add nuw nsw i32 %5776, %5777"
"  %5778 = add nuw nsw i32 %5776, %5777" -> "  %5791 = lshr i32 %5778, 16""  %5778 = add nuw nsw i32 %5776, %5777" -> "  %5780 = and i32 %5778, 65535"
"  %5779 = lshr i32 %5775, 16"
"  %5779 = lshr i32 %5775, 16" -> "  %5781 = add nuw nsw i32 %5780, %5779"
"  %5780 = and i32 %5778, 65535"
"  %5780 = and i32 %5778, 65535" -> "  %5781 = add nuw nsw i32 %5780, %5779"
"  %5781 = add nuw nsw i32 %5780, %5779"
"  %5781 = add nuw nsw i32 %5780, %5779" -> "  %5793 = lshr i32 %5781, 16""  %5781 = add nuw nsw i32 %5780, %5779" -> "  %5788 = and i32 %5781, 65535"
"  %5782 = and i32 %5775, 65535"
"  %5782 = and i32 %5775, 65535" -> "  %5784 = add nuw nsw i32 %5782, %5783"
"  %5783 = lshr i32 %5769, 16"
"  %5783 = lshr i32 %5769, 16" -> "  %5784 = add nuw nsw i32 %5782, %5783"
"  %5784 = add nuw nsw i32 %5782, %5783"
"  %5784 = add nuw nsw i32 %5782, %5783" -> "  %5786 = add nuw nsw i32 %5784, %5785"
"  %5785 = lshr i32 %5772, 16"
"  %5785 = lshr i32 %5772, 16" -> "  %5786 = add nuw nsw i32 %5784, %5785"
"  %5786 = add nuw nsw i32 %5784, %5785"
"  %5786 = add nuw nsw i32 %5784, %5785" -> "  %6467 = and i32 %5786, 65535""  %5786 = add nuw nsw i32 %5784, %5785" -> "  %5787 = lshr i32 %5786, 16"
"  %5787 = lshr i32 %5786, 16"
"  %5787 = lshr i32 %5786, 16" -> "  %5789 = add nuw nsw i32 %5788, %5787"
"  %5788 = and i32 %5781, 65535"
"  %5788 = and i32 %5781, 65535" -> "  %5789 = add nuw nsw i32 %5788, %5787"
"  %5789 = add nuw nsw i32 %5788, %5787"
"  %5789 = add nuw nsw i32 %5788, %5787" -> "  %6470 = and i32 %5789, 65535""  %5789 = add nuw nsw i32 %5788, %5787" -> "  %5795 = lshr i32 %5789, 16"
"  %5790 = and i32 %5758, 65535"
"  %5790 = and i32 %5758, 65535" -> "  %5792 = add nuw nsw i32 %5791, %5790"
"  %5791 = lshr i32 %5778, 16"
"  %5791 = lshr i32 %5778, 16" -> "  %5792 = add nuw nsw i32 %5791, %5790"
"  %5792 = add nuw nsw i32 %5791, %5790"
"  %5792 = add nuw nsw i32 %5791, %5790" -> "  %5794 = add nuw nsw i32 %5792, %5793"
"  %5793 = lshr i32 %5781, 16"
"  %5793 = lshr i32 %5781, 16" -> "  %5794 = add nuw nsw i32 %5792, %5793"
"  %5794 = add nuw nsw i32 %5792, %5793"
"  %5794 = add nuw nsw i32 %5792, %5793" -> "  %5796 = add nuw nsw i32 %5794, %5795"
"  %5795 = lshr i32 %5789, 16"
"  %5795 = lshr i32 %5789, 16" -> "  %5796 = add nuw nsw i32 %5794, %5795"
"  %5796 = add nuw nsw i32 %5794, %5795"
"  %5796 = add nuw nsw i32 %5794, %5795" -> "  %6481 = and i32 %5796, 65535""  %5796 = add nuw nsw i32 %5794, %5795" -> "  %5798 = lshr i32 %5796, 16"
"  %5797 = and i32 %5761, 65535"
"  %5797 = and i32 %5761, 65535" -> "  %5799 = add nuw nsw i32 %5798, %5797"
"  %5798 = lshr i32 %5796, 16"
"  %5798 = lshr i32 %5796, 16" -> "  %5799 = add nuw nsw i32 %5798, %5797"
"  %5799 = add nuw nsw i32 %5798, %5797"
"  %5799 = add nuw nsw i32 %5798, %5797" -> "  %6484 = and i32 %5799, 65535""  %5799 = add nuw nsw i32 %5798, %5797" -> "  %5800 = lshr i32 %5799, 16"
"  %5800 = lshr i32 %5799, 16"
"  %5800 = lshr i32 %5799, 16" -> "  %5801 = add nuw i32 %5763, %5800"
"  %5801 = add nuw i32 %5763, %5800"
"  %5801 = add nuw i32 %5763, %5800" -> "  %6490 = and i32 %5801, 65535""  %5801 = add nuw i32 %5763, %5800" -> "  %6493 = lshr i32 %5801, 16"
"  %5802 = and i32 %5095, 65535"
"  %5802 = and i32 %5095, 65535" -> "  %6106 = mul nuw i32 %5802, 46547""  %5802 = and i32 %5095, 65535" -> "  %5804 = mul nuw i32 %5802, 37996""  %5802 = and i32 %5095, 65535" -> "  %5811 = mul nuw i32 %5802, 45147""  %5802 = and i32 %5095, 65535" -> "  %5858 = mul nuw nsw i32 %5802, 1324""  %5802 = and i32 %5095, 65535" -> "  %5865 = mul nuw i32 %5802, 62728""  %5802 = and i32 %5095, 65535" -> "  %6099 = mul nuw nsw i32 %5802, 17857""  %5802 = and i32 %5095, 65535" -> "  %6148 = mul nuw nsw i32 %5802, 31112""  %5802 = and i32 %5095, 65535" -> "  %6155 = mul nuw i32 %5802, 42170""  %5802 = and i32 %5095, 65535" -> "  %7362 = mul nuw nsw i32 %5802, 29744""  %5802 = and i32 %5095, 65535" -> "  %7355 = mul nuw nsw i32 %5802, 24315""  %5802 = and i32 %5095, 65535" -> "  %7313 = mul nuw nsw i32 %5802, 9871""  %5802 = and i32 %5095, 65535" -> "  %7306 = mul nuw i32 %5802, 42779""  %5802 = and i32 %5095, 65535" -> "  %7651 = mul nuw i32 %5802, 36786""  %5802 = and i32 %5095, 65535" -> "  %7644 = mul nuw nsw i32 %5802, 21884""  %5802 = and i32 %5095, 65535" -> "  %7602 = mul nuw nsw i32 %5802, 11561""  %5802 = and i32 %5095, 65535" -> "  %7595 = mul nuw nsw i32 %5802, 4087"
"  %5803 = and i32 %5101, 65535"
"  %5803 = and i32 %5101, 65535" -> "  %5806 = mul nuw i32 %5803, 37996""  %5803 = and i32 %5101, 65535" -> "  %5815 = mul nuw i32 %5803, 45147""  %5803 = and i32 %5101, 65535" -> "  %5860 = mul nuw nsw i32 %5803, 1324""  %5803 = and i32 %5101, 65535" -> "  %5869 = mul nuw i32 %5803, 62728""  %5803 = and i32 %5101, 65535" -> "  %6110 = mul nuw i32 %5803, 46547""  %5803 = and i32 %5101, 65535" -> "  %6101 = mul nuw nsw i32 %5803, 17857""  %5803 = and i32 %5101, 65535" -> "  %6150 = mul nuw nsw i32 %5803, 31112""  %5803 = and i32 %5101, 65535" -> "  %6159 = mul nuw i32 %5803, 42170""  %5803 = and i32 %5101, 65535" -> "  %7366 = mul nuw nsw i32 %5803, 29744""  %5803 = and i32 %5101, 65535" -> "  %7357 = mul nuw nsw i32 %5803, 24315""  %5803 = and i32 %5101, 65535" -> "  %7317 = mul nuw nsw i32 %5803, 9871""  %5803 = and i32 %5101, 65535" -> "  %7308 = mul nuw i32 %5803, 42779""  %5803 = and i32 %5101, 65535" -> "  %7655 = mul nuw i32 %5803, 36786""  %5803 = and i32 %5101, 65535" -> "  %7646 = mul nuw nsw i32 %5803, 21884""  %5803 = and i32 %5101, 65535" -> "  %7606 = mul nuw nsw i32 %5803, 11561""  %5803 = and i32 %5101, 65535" -> "  %7597 = mul nuw nsw i32 %5803, 4087"
"  %5804 = mul nuw i32 %5802, 37996"
"  %5804 = mul nuw i32 %5802, 37996" -> "  %6456 = and i32 %5804, 65532""  %5804 = mul nuw i32 %5802, 37996" -> "  %5805 = lshr i32 %5804, 16"
"  %5805 = lshr i32 %5804, 16"
"  %5805 = lshr i32 %5804, 16" -> "  %5808 = add nuw nsw i32 %5807, %5805"
"  %5806 = mul nuw i32 %5803, 37996"
"  %5806 = mul nuw i32 %5803, 37996" -> "  %5809 = and i32 %5806, -65536""  %5806 = mul nuw i32 %5803, 37996" -> "  %5807 = and i32 %5806, 65532"
"  %5807 = and i32 %5806, 65532"
"  %5807 = and i32 %5806, 65532" -> "  %5808 = add nuw nsw i32 %5807, %5805"
"  %5808 = add nuw nsw i32 %5807, %5805"
"  %5808 = add nuw nsw i32 %5807, %5805" -> "  %5810 = add nuw i32 %5808, %5809"
"  %5809 = and i32 %5806, -65536"
"  %5809 = and i32 %5806, -65536" -> "  %5810 = add nuw i32 %5808, %5809"
"  %5810 = add nuw i32 %5808, %5809"
"  %5810 = add nuw i32 %5808, %5809" -> "  %5814 = lshr i32 %5810, 16""  %5810 = add nuw i32 %5808, %5809" -> "  %5812 = and i32 %5810, 65535"
"  %5811 = mul nuw i32 %5802, 45147"
"  %5811 = mul nuw i32 %5802, 45147" -> "  %5813 = add nuw i32 %5812, %5811"
"  %5812 = and i32 %5810, 65535"
"  %5812 = and i32 %5810, 65535" -> "  %5813 = add nuw i32 %5812, %5811"
"  %5813 = add nuw i32 %5812, %5811"
"  %5813 = add nuw i32 %5812, %5811" -> "  %6459 = and i32 %5813, 65535""  %5813 = add nuw i32 %5812, %5811" -> "  %5817 = lshr i32 %5813, 16"
"  %5814 = lshr i32 %5810, 16"
"  %5814 = lshr i32 %5810, 16" -> "  %5816 = add nuw i32 %5814, %5815"
"  %5815 = mul nuw i32 %5803, 45147"
"  %5815 = mul nuw i32 %5803, 45147" -> "  %5816 = add nuw i32 %5814, %5815"
"  %5816 = add nuw i32 %5814, %5815"
"  %5816 = add nuw i32 %5814, %5815" -> "  %5820 = and i32 %5816, -65536""  %5816 = add nuw i32 %5814, %5815" -> "  %5818 = and i32 %5816, 65535"
"  %5817 = lshr i32 %5813, 16"
"  %5817 = lshr i32 %5813, 16" -> "  %5819 = add nuw nsw i32 %5817, %5818"
"  %5818 = and i32 %5816, 65535"
"  %5818 = and i32 %5816, 65535" -> "  %5819 = add nuw nsw i32 %5817, %5818"
"  %5819 = add nuw nsw i32 %5817, %5818"
"  %5819 = add nuw nsw i32 %5817, %5818" -> "  %5821 = add nuw i32 %5819, %5820"
"  %5820 = and i32 %5816, -65536"
"  %5820 = and i32 %5816, -65536" -> "  %5821 = add nuw i32 %5819, %5820"
"  %5821 = add nuw i32 %5819, %5820"
"  %5821 = add nuw i32 %5819, %5820" -> "  %5846 = lshr i32 %5821, 16""  %5821 = add nuw i32 %5819, %5820" -> "  %5842 = and i32 %5821, 65535"
"  %5822 = and i32 %5115, 65535"
"  %5822 = and i32 %5115, 65535" -> "  %6117 = mul nuw nsw i32 %5822, 17857""  %5822 = and i32 %5115, 65535" -> "  %7386 = mul nuw nsw i32 %5822, 24315""  %5822 = and i32 %5115, 65535" -> "  %5824 = mul nuw i32 %5822, 37996""  %5822 = and i32 %5115, 65535" -> "  %5831 = mul nuw i32 %5822, 45147""  %5822 = and i32 %5115, 65535" -> "  %5889 = mul nuw nsw i32 %5822, 1324""  %5822 = and i32 %5115, 65535" -> "  %5896 = mul nuw i32 %5822, 62728""  %5822 = and i32 %5115, 65535" -> "  %6124 = mul nuw i32 %5822, 46547""  %5822 = and i32 %5115, 65535" -> "  %6179 = mul nuw nsw i32 %5822, 31112""  %5822 = and i32 %5115, 65535" -> "  %6183 = mul nuw i32 %5822, 42170""  %5822 = and i32 %5115, 65535" -> "  %7390 = mul nuw nsw i32 %5822, 29744""  %5822 = and i32 %5115, 65535" -> "  %7331 = mul nuw nsw i32 %5822, 9871""  %5822 = and i32 %5115, 65535" -> "  %7324 = mul nuw i32 %5822, 42779""  %5822 = and i32 %5115, 65535" -> "  %7682 = mul nuw i32 %5822, 36786""  %5822 = and i32 %5115, 65535" -> "  %7675 = mul nuw nsw i32 %5822, 21884""  %5822 = and i32 %5115, 65535" -> "  %7620 = mul nuw nsw i32 %5822, 11561""  %5822 = and i32 %5115, 65535" -> "  %7613 = mul nuw nsw i32 %5822, 4087"
"  %5823 = and i32 %5118, 65535"
"  %5823 = and i32 %5118, 65535" -> "  %5826 = mul nuw i32 %5823, 37996""  %5823 = and i32 %5118, 65535" -> "  %5835 = mul nuw i32 %5823, 45147""  %5823 = and i32 %5118, 65535" -> "  %5891 = mul nuw nsw i32 %5823, 1324""  %5823 = and i32 %5118, 65535" -> "  %5900 = mul nuw i32 %5823, 62728""  %5823 = and i32 %5118, 65535" -> "  %6187 = mul nuw i32 %5823, 42170""  %5823 = and i32 %5118, 65535" -> "  %6181 = mul nuw nsw i32 %5823, 31112""  %5823 = and i32 %5118, 65535" -> "  %6128 = mul nuw i32 %5823, 46547""  %5823 = and i32 %5118, 65535" -> "  %6119 = mul nuw nsw i32 %5823, 17857""  %5823 = and i32 %5118, 65535" -> "  %7394 = mul nuw nsw i32 %5823, 29744""  %5823 = and i32 %5118, 65535" -> "  %7388 = mul nuw nsw i32 %5823, 24315""  %5823 = and i32 %5118, 65535" -> "  %7335 = mul nuw nsw i32 %5823, 9871""  %5823 = and i32 %5118, 65535" -> "  %7326 = mul nuw i32 %5823, 42779""  %5823 = and i32 %5118, 65535" -> "  %7686 = mul nuw i32 %5823, 36786""  %5823 = and i32 %5118, 65535" -> "  %7677 = mul nuw nsw i32 %5823, 21884""  %5823 = and i32 %5118, 65535" -> "  %7624 = mul nuw nsw i32 %5823, 11561""  %5823 = and i32 %5118, 65535" -> "  %7615 = mul nuw nsw i32 %5823, 4087"
"  %5824 = mul nuw i32 %5822, 37996"
"  %5824 = mul nuw i32 %5822, 37996" -> "  %5843 = and i32 %5824, 65532""  %5824 = mul nuw i32 %5822, 37996" -> "  %5825 = lshr i32 %5824, 16"
"  %5825 = lshr i32 %5824, 16"
"  %5825 = lshr i32 %5824, 16" -> "  %5828 = add nuw nsw i32 %5827, %5825"
"  %5826 = mul nuw i32 %5823, 37996"
"  %5826 = mul nuw i32 %5823, 37996" -> "  %5829 = and i32 %5826, -65536""  %5826 = mul nuw i32 %5823, 37996" -> "  %5827 = and i32 %5826, 65532"
"  %5827 = and i32 %5826, 65532"
"  %5827 = and i32 %5826, 65532" -> "  %5828 = add nuw nsw i32 %5827, %5825"
"  %5828 = add nuw nsw i32 %5827, %5825"
"  %5828 = add nuw nsw i32 %5827, %5825" -> "  %5830 = add nuw i32 %5828, %5829"
"  %5829 = and i32 %5826, -65536"
"  %5829 = and i32 %5826, -65536" -> "  %5830 = add nuw i32 %5828, %5829"
"  %5830 = add nuw i32 %5828, %5829"
"  %5830 = add nuw i32 %5828, %5829" -> "  %5834 = lshr i32 %5830, 16""  %5830 = add nuw i32 %5828, %5829" -> "  %5832 = and i32 %5830, 65535"
"  %5831 = mul nuw i32 %5822, 45147"
"  %5831 = mul nuw i32 %5822, 45147" -> "  %5833 = add nuw i32 %5832, %5831"
"  %5832 = and i32 %5830, 65535"
"  %5832 = and i32 %5830, 65535" -> "  %5833 = add nuw i32 %5832, %5831"
"  %5833 = add nuw i32 %5832, %5831"
"  %5833 = add nuw i32 %5832, %5831" -> "  %5845 = and i32 %5833, 65535""  %5833 = add nuw i32 %5832, %5831" -> "  %5837 = lshr i32 %5833, 16"
"  %5834 = lshr i32 %5830, 16"
"  %5834 = lshr i32 %5830, 16" -> "  %5836 = add nuw i32 %5834, %5835"
"  %5835 = mul nuw i32 %5823, 45147"
"  %5835 = mul nuw i32 %5823, 45147" -> "  %5836 = add nuw i32 %5834, %5835"
"  %5836 = add nuw i32 %5834, %5835"
"  %5836 = add nuw i32 %5834, %5835" -> "  %5840 = and i32 %5836, -65536""  %5836 = add nuw i32 %5834, %5835" -> "  %5838 = and i32 %5836, 65535"
"  %5837 = lshr i32 %5833, 16"
"  %5837 = lshr i32 %5833, 16" -> "  %5839 = add nuw nsw i32 %5837, %5838"
"  %5838 = and i32 %5836, 65535"
"  %5838 = and i32 %5836, 65535" -> "  %5839 = add nuw nsw i32 %5837, %5838"
"  %5839 = add nuw nsw i32 %5837, %5838"
"  %5839 = add nuw nsw i32 %5837, %5838" -> "  %5841 = add nuw i32 %5839, %5840"
"  %5840 = and i32 %5836, -65536"
"  %5840 = and i32 %5836, -65536" -> "  %5841 = add nuw i32 %5839, %5840"
"  %5841 = add nuw i32 %5839, %5840"
"  %5841 = add nuw i32 %5839, %5840" -> "  %5854 = and i32 %5841, -65536""  %5841 = add nuw i32 %5839, %5840" -> "  %5852 = and i32 %5841, 65535"
"  %5842 = and i32 %5821, 65535"
"  %5842 = and i32 %5821, 65535" -> "  %5844 = add nuw nsw i32 %5842, %5843"
"  %5843 = and i32 %5824, 65532"
"  %5843 = and i32 %5824, 65532" -> "  %5844 = add nuw nsw i32 %5842, %5843"
"  %5844 = add nuw nsw i32 %5842, %5843"
"  %5844 = add nuw nsw i32 %5842, %5843" -> "  %5876 = and i32 %5844, 65535""  %5844 = add nuw nsw i32 %5842, %5843" -> "  %5848 = lshr i32 %5844, 16"
"  %5845 = and i32 %5833, 65535"
"  %5845 = and i32 %5833, 65535" -> "  %5847 = add nuw nsw i32 %5845, %5846"
"  %5846 = lshr i32 %5821, 16"
"  %5846 = lshr i32 %5821, 16" -> "  %5847 = add nuw nsw i32 %5845, %5846"
"  %5847 = add nuw nsw i32 %5845, %5846"
"  %5847 = add nuw nsw i32 %5845, %5846" -> "  %5851 = lshr i32 %5847, 16""  %5847 = add nuw nsw i32 %5845, %5846" -> "  %5849 = and i32 %5847, 65535"
"  %5848 = lshr i32 %5844, 16"
"  %5848 = lshr i32 %5844, 16" -> "  %5850 = add nuw nsw i32 %5849, %5848"
"  %5849 = and i32 %5847, 65535"
"  %5849 = and i32 %5847, 65535" -> "  %5850 = add nuw nsw i32 %5849, %5848"
"  %5850 = add nuw nsw i32 %5849, %5848"
"  %5850 = add nuw nsw i32 %5849, %5848" -> "  %5879 = and i32 %5850, 65535""  %5850 = add nuw nsw i32 %5849, %5848" -> "  %5856 = lshr i32 %5850, 16"
"  %5851 = lshr i32 %5847, 16"
"  %5851 = lshr i32 %5847, 16" -> "  %5853 = add nuw nsw i32 %5852, %5851"
"  %5852 = and i32 %5841, 65535"
"  %5852 = and i32 %5841, 65535" -> "  %5853 = add nuw nsw i32 %5852, %5851"
"  %5853 = add nuw nsw i32 %5852, %5851"
"  %5853 = add nuw nsw i32 %5852, %5851" -> "  %5855 = add nuw i32 %5853, %5854"
"  %5854 = and i32 %5841, -65536"
"  %5854 = and i32 %5841, -65536" -> "  %5855 = add nuw i32 %5853, %5854"
"  %5855 = add nuw i32 %5853, %5854"
"  %5855 = add nuw i32 %5853, %5854" -> "  %5857 = add nuw i32 %5855, %5856"
"  %5856 = lshr i32 %5850, 16"
"  %5856 = lshr i32 %5850, 16" -> "  %5857 = add nuw i32 %5855, %5856"
"  %5857 = add nuw i32 %5855, %5856"
"  %5857 = add nuw i32 %5855, %5856" -> "  %5911 = lshr i32 %5857, 16""  %5857 = add nuw i32 %5855, %5856" -> "  %5907 = and i32 %5857, 65535"
"  %5858 = mul nuw nsw i32 %5802, 1324"
"  %5858 = mul nuw nsw i32 %5802, 1324" -> "  %5877 = and i32 %5858, 65532""  %5858 = mul nuw nsw i32 %5802, 1324" -> "  %5859 = lshr i32 %5858, 16"
"  %5859 = lshr i32 %5858, 16"
"  %5859 = lshr i32 %5858, 16" -> "  %5862 = add nuw nsw i32 %5861, %5859"
"  %5860 = mul nuw nsw i32 %5803, 1324"
"  %5860 = mul nuw nsw i32 %5803, 1324" -> "  %5863 = and i32 %5860, 134152192""  %5860 = mul nuw nsw i32 %5803, 1324" -> "  %5861 = and i32 %5860, 65532"
"  %5861 = and i32 %5860, 65532"
"  %5861 = and i32 %5860, 65532" -> "  %5862 = add nuw nsw i32 %5861, %5859"
"  %5862 = add nuw nsw i32 %5861, %5859"
"  %5862 = add nuw nsw i32 %5861, %5859" -> "  %5864 = add nuw nsw i32 %5862, %5863"
"  %5863 = and i32 %5860, 134152192"
"  %5863 = and i32 %5860, 134152192" -> "  %5864 = add nuw nsw i32 %5862, %5863"
"  %5864 = add nuw nsw i32 %5862, %5863"
"  %5864 = add nuw nsw i32 %5862, %5863" -> "  %5868 = lshr i32 %5864, 16""  %5864 = add nuw nsw i32 %5862, %5863" -> "  %5866 = and i32 %5864, 65535"
"  %5865 = mul nuw i32 %5802, 62728"
"  %5865 = mul nuw i32 %5802, 62728" -> "  %5867 = add nuw i32 %5866, %5865"
"  %5866 = and i32 %5864, 65535"
"  %5866 = and i32 %5864, 65535" -> "  %5867 = add nuw i32 %5866, %5865"
"  %5867 = add nuw i32 %5866, %5865"
"  %5867 = add nuw i32 %5866, %5865" -> "  %5880 = and i32 %5867, 65535""  %5867 = add nuw i32 %5866, %5865" -> "  %5871 = lshr i32 %5867, 16"
"  %5868 = lshr i32 %5864, 16"
"  %5868 = lshr i32 %5864, 16" -> "  %5870 = add nuw i32 %5868, %5869"
"  %5869 = mul nuw i32 %5803, 62728"
"  %5869 = mul nuw i32 %5803, 62728" -> "  %5870 = add nuw i32 %5868, %5869"
"  %5870 = add nuw i32 %5868, %5869"
"  %5870 = add nuw i32 %5868, %5869" -> "  %5874 = and i32 %5870, -65536""  %5870 = add nuw i32 %5868, %5869" -> "  %5872 = and i32 %5870, 65535"
"  %5871 = lshr i32 %5867, 16"
"  %5871 = lshr i32 %5867, 16" -> "  %5873 = add nuw nsw i32 %5871, %5872"
"  %5872 = and i32 %5870, 65535"
"  %5872 = and i32 %5870, 65535" -> "  %5873 = add nuw nsw i32 %5871, %5872"
"  %5873 = add nuw nsw i32 %5871, %5872"
"  %5873 = add nuw nsw i32 %5871, %5872" -> "  %5875 = add nuw i32 %5873, %5874"
"  %5874 = and i32 %5870, -65536"
"  %5874 = and i32 %5870, -65536" -> "  %5875 = add nuw i32 %5873, %5874"
"  %5875 = add nuw i32 %5873, %5874"
"  %5875 = add nuw i32 %5873, %5874" -> "  %5883 = add nuw i32 %5875, %5882"
"  %5876 = and i32 %5844, 65535"
"  %5876 = and i32 %5844, 65535" -> "  %5878 = add nuw nsw i32 %5876, %5877"
"  %5877 = and i32 %5858, 65532"
"  %5877 = and i32 %5858, 65532" -> "  %5878 = add nuw nsw i32 %5876, %5877"
"  %5878 = add nuw nsw i32 %5876, %5877"
"  %5878 = add nuw nsw i32 %5876, %5877" -> "  %6468 = and i32 %5878, 65535""  %5878 = add nuw nsw i32 %5876, %5877" -> "  %5885 = lshr i32 %5878, 16"
"  %5879 = and i32 %5850, 65535"
"  %5879 = and i32 %5850, 65535" -> "  %5881 = add nuw nsw i32 %5879, %5880"
"  %5880 = and i32 %5867, 65535"
"  %5880 = and i32 %5867, 65535" -> "  %5881 = add nuw nsw i32 %5879, %5880"
"  %5881 = add nuw nsw i32 %5879, %5880"
"  %5881 = add nuw nsw i32 %5879, %5880" -> "  %5884 = and i32 %5881, 65535""  %5881 = add nuw nsw i32 %5879, %5880" -> "  %5882 = lshr i32 %5881, 16"
"  %5882 = lshr i32 %5881, 16"
"  %5882 = lshr i32 %5881, 16" -> "  %5883 = add nuw i32 %5875, %5882"
"  %5883 = add nuw i32 %5875, %5882"
"  %5883 = add nuw i32 %5875, %5882" -> "  %5888 = add nuw i32 %5883, %5887"
"  %5884 = and i32 %5881, 65535"
"  %5884 = and i32 %5881, 65535" -> "  %5886 = add nuw nsw i32 %5884, %5885"
"  %5885 = lshr i32 %5878, 16"
"  %5885 = lshr i32 %5878, 16" -> "  %5886 = add nuw nsw i32 %5884, %5885"
"  %5886 = add nuw nsw i32 %5884, %5885"
"  %5886 = add nuw nsw i32 %5884, %5885" -> "  %6471 = and i32 %5886, 65535""  %5886 = add nuw nsw i32 %5884, %5885" -> "  %5887 = lshr i32 %5886, 16"
"  %5887 = lshr i32 %5886, 16"
"  %5887 = lshr i32 %5886, 16" -> "  %5888 = add nuw i32 %5883, %5887"
"  %5888 = add nuw i32 %5883, %5887"
"  %5888 = add nuw i32 %5883, %5887" -> "  %5924 = lshr i32 %5888, 16""  %5888 = add nuw i32 %5883, %5887" -> "  %5921 = and i32 %5888, 65535"
"  %5889 = mul nuw nsw i32 %5822, 1324"
"  %5889 = mul nuw nsw i32 %5822, 1324" -> "  %5908 = and i32 %5889, 65532""  %5889 = mul nuw nsw i32 %5822, 1324" -> "  %5890 = lshr i32 %5889, 16"
"  %5890 = lshr i32 %5889, 16"
"  %5890 = lshr i32 %5889, 16" -> "  %5893 = add nuw nsw i32 %5892, %5890"
"  %5891 = mul nuw nsw i32 %5823, 1324"
"  %5891 = mul nuw nsw i32 %5823, 1324" -> "  %5894 = and i32 %5891, 134152192""  %5891 = mul nuw nsw i32 %5823, 1324" -> "  %5892 = and i32 %5891, 65532"
"  %5892 = and i32 %5891, 65532"
"  %5892 = and i32 %5891, 65532" -> "  %5893 = add nuw nsw i32 %5892, %5890"
"  %5893 = add nuw nsw i32 %5892, %5890"
"  %5893 = add nuw nsw i32 %5892, %5890" -> "  %5895 = add nuw nsw i32 %5893, %5894"
"  %5894 = and i32 %5891, 134152192"
"  %5894 = and i32 %5891, 134152192" -> "  %5895 = add nuw nsw i32 %5893, %5894"
"  %5895 = add nuw nsw i32 %5893, %5894"
"  %5895 = add nuw nsw i32 %5893, %5894" -> "  %5899 = lshr i32 %5895, 16""  %5895 = add nuw nsw i32 %5893, %5894" -> "  %5897 = and i32 %5895, 65535"
"  %5896 = mul nuw i32 %5822, 62728"
"  %5896 = mul nuw i32 %5822, 62728" -> "  %5898 = add nuw i32 %5897, %5896"
"  %5897 = and i32 %5895, 65535"
"  %5897 = and i32 %5895, 65535" -> "  %5898 = add nuw i32 %5897, %5896"
"  %5898 = add nuw i32 %5897, %5896"
"  %5898 = add nuw i32 %5897, %5896" -> "  %5910 = and i32 %5898, 65535""  %5898 = add nuw i32 %5897, %5896" -> "  %5902 = lshr i32 %5898, 16"
"  %5899 = lshr i32 %5895, 16"
"  %5899 = lshr i32 %5895, 16" -> "  %5901 = add nuw i32 %5899, %5900"
"  %5900 = mul nuw i32 %5823, 62728"
"  %5900 = mul nuw i32 %5823, 62728" -> "  %5901 = add nuw i32 %5899, %5900"
"  %5901 = add nuw i32 %5899, %5900"
"  %5901 = add nuw i32 %5899, %5900" -> "  %5905 = and i32 %5901, -65536""  %5901 = add nuw i32 %5899, %5900" -> "  %5903 = and i32 %5901, 65535"
"  %5902 = lshr i32 %5898, 16"
"  %5902 = lshr i32 %5898, 16" -> "  %5904 = add nuw nsw i32 %5902, %5903"
"  %5903 = and i32 %5901, 65535"
"  %5903 = and i32 %5901, 65535" -> "  %5904 = add nuw nsw i32 %5902, %5903"
"  %5904 = add nuw nsw i32 %5902, %5903"
"  %5904 = add nuw nsw i32 %5902, %5903" -> "  %5906 = add nuw i32 %5904, %5905"
"  %5905 = and i32 %5901, -65536"
"  %5905 = and i32 %5901, -65536" -> "  %5906 = add nuw i32 %5904, %5905"
"  %5906 = add nuw i32 %5904, %5905"
"  %5906 = add nuw i32 %5904, %5905" -> "  %5914 = add nuw i32 %5906, %5913"
"  %5907 = and i32 %5857, 65535"
"  %5907 = and i32 %5857, 65535" -> "  %5909 = add nuw nsw i32 %5907, %5908"
"  %5908 = and i32 %5889, 65532"
"  %5908 = and i32 %5889, 65532" -> "  %5909 = add nuw nsw i32 %5907, %5908"
"  %5909 = add nuw nsw i32 %5907, %5908"
"  %5909 = add nuw nsw i32 %5907, %5908" -> "  %5920 = and i32 %5909, 65535""  %5909 = add nuw nsw i32 %5907, %5908" -> "  %5916 = lshr i32 %5909, 16"
"  %5910 = and i32 %5898, 65535"
"  %5910 = and i32 %5898, 65535" -> "  %5912 = add nuw nsw i32 %5911, %5910"
"  %5911 = lshr i32 %5857, 16"
"  %5911 = lshr i32 %5857, 16" -> "  %5912 = add nuw nsw i32 %5911, %5910"
"  %5912 = add nuw nsw i32 %5911, %5910"
"  %5912 = add nuw nsw i32 %5911, %5910" -> "  %5915 = and i32 %5912, 65535""  %5912 = add nuw nsw i32 %5911, %5910" -> "  %5913 = lshr i32 %5912, 16"
"  %5913 = lshr i32 %5912, 16"
"  %5913 = lshr i32 %5912, 16" -> "  %5914 = add nuw i32 %5906, %5913"
"  %5914 = add nuw i32 %5906, %5913"
"  %5914 = add nuw i32 %5906, %5913" -> "  %5919 = add nuw i32 %5914, %5918"
"  %5915 = and i32 %5912, 65535"
"  %5915 = and i32 %5912, 65535" -> "  %5917 = add nuw nsw i32 %5916, %5915"
"  %5916 = lshr i32 %5909, 16"
"  %5916 = lshr i32 %5909, 16" -> "  %5917 = add nuw nsw i32 %5916, %5915"
"  %5917 = add nuw nsw i32 %5916, %5915"
"  %5917 = add nuw nsw i32 %5916, %5915" -> "  %5923 = and i32 %5917, 65535""  %5917 = add nuw nsw i32 %5916, %5915" -> "  %5918 = lshr i32 %5917, 16"
"  %5918 = lshr i32 %5917, 16"
"  %5918 = lshr i32 %5917, 16" -> "  %5919 = add nuw i32 %5914, %5918"
"  %5919 = add nuw i32 %5914, %5918"
"  %5919 = add nuw i32 %5914, %5918" -> "  %5932 = and i32 %5919, -65536""  %5919 = add nuw i32 %5914, %5918" -> "  %5930 = and i32 %5919, 65535"
"  %5920 = and i32 %5909, 65535"
"  %5920 = and i32 %5909, 65535" -> "  %5922 = add nuw nsw i32 %5921, %5920"
"  %5921 = and i32 %5888, 65535"
"  %5921 = and i32 %5888, 65535" -> "  %5922 = add nuw nsw i32 %5921, %5920"
"  %5922 = add nuw nsw i32 %5921, %5920"
"  %5922 = add nuw nsw i32 %5921, %5920" -> "  %6062 = and i32 %5922, 65535""  %5922 = add nuw nsw i32 %5921, %5920" -> "  %5926 = lshr i32 %5922, 16"
"  %5923 = and i32 %5917, 65535"
"  %5923 = and i32 %5917, 65535" -> "  %5925 = add nuw nsw i32 %5923, %5924"
"  %5924 = lshr i32 %5888, 16"
"  %5924 = lshr i32 %5888, 16" -> "  %5925 = add nuw nsw i32 %5923, %5924"
"  %5925 = add nuw nsw i32 %5923, %5924"
"  %5925 = add nuw nsw i32 %5923, %5924" -> "  %5929 = lshr i32 %5925, 16""  %5925 = add nuw nsw i32 %5923, %5924" -> "  %5927 = and i32 %5925, 65535"
"  %5926 = lshr i32 %5922, 16"
"  %5926 = lshr i32 %5922, 16" -> "  %5928 = add nuw nsw i32 %5927, %5926"
"  %5927 = and i32 %5925, 65535"
"  %5927 = and i32 %5925, 65535" -> "  %5928 = add nuw nsw i32 %5927, %5926"
"  %5928 = add nuw nsw i32 %5927, %5926"
"  %5928 = add nuw nsw i32 %5927, %5926" -> "  %6065 = and i32 %5928, 65535""  %5928 = add nuw nsw i32 %5927, %5926" -> "  %5934 = lshr i32 %5928, 16"
"  %5929 = lshr i32 %5925, 16"
"  %5929 = lshr i32 %5925, 16" -> "  %5931 = add nuw nsw i32 %5929, %5930"
"  %5930 = and i32 %5919, 65535"
"  %5930 = and i32 %5919, 65535" -> "  %5931 = add nuw nsw i32 %5929, %5930"
"  %5931 = add nuw nsw i32 %5929, %5930"
"  %5931 = add nuw nsw i32 %5929, %5930" -> "  %5933 = add nuw i32 %5931, %5932"
"  %5932 = and i32 %5919, -65536"
"  %5932 = and i32 %5919, -65536" -> "  %5933 = add nuw i32 %5931, %5932"
"  %5933 = add nuw i32 %5931, %5932"
"  %5933 = add nuw i32 %5931, %5932" -> "  %5935 = add nuw i32 %5933, %5934"
"  %5934 = lshr i32 %5928, 16"
"  %5934 = lshr i32 %5928, 16" -> "  %5935 = add nuw i32 %5933, %5934"
"  %5935 = add nuw i32 %5933, %5934"
"  %5935 = add nuw i32 %5933, %5934" -> "  %6071 = and i32 %5935, 65535""  %5935 = add nuw i32 %5933, %5934" -> "  %6074 = lshr i32 %5935, 16"
"  %5936 = and i32 %5125, 65535"
"  %5936 = and i32 %5125, 65535" -> "  %5937 = mul nuw i32 %5936, 37996""  %5936 = and i32 %5125, 65535" -> "  %5945 = mul nuw i32 %5936, 45147""  %5936 = and i32 %5125, 65535" -> "  %6258 = mul nuw nsw i32 %5936, 17857""  %5936 = and i32 %5125, 65535" -> "  %6265 = mul nuw i32 %5936, 46547""  %5936 = and i32 %5125, 65535" -> "  %5993 = mul nuw i32 %5936, 62728""  %5936 = and i32 %5125, 65535" -> "  %5986 = mul nuw nsw i32 %5936, 1324""  %5936 = and i32 %5125, 65535" -> "  %6307 = mul nuw nsw i32 %5936, 31112""  %5936 = and i32 %5125, 65535" -> "  %6314 = mul nuw i32 %5936, 42170""  %5936 = and i32 %5125, 65535" -> "  %7486 = mul nuw nsw i32 %5936, 29744""  %5936 = and i32 %5125, 65535" -> "  %7479 = mul nuw nsw i32 %5936, 24315""  %5936 = and i32 %5125, 65535" -> "  %7437 = mul nuw nsw i32 %5936, 9871""  %5936 = and i32 %5125, 65535" -> "  %7430 = mul nuw i32 %5936, 42779""  %5936 = and i32 %5125, 65535" -> "  %7816 = mul nuw i32 %5936, 36786""  %5936 = and i32 %5125, 65535" -> "  %7809 = mul nuw nsw i32 %5936, 21884""  %5936 = and i32 %5125, 65535" -> "  %7767 = mul nuw nsw i32 %5936, 11561""  %5936 = and i32 %5125, 65535" -> "  %7760 = mul nuw nsw i32 %5936, 4087"
"  %5937 = mul nuw i32 %5936, 37996"
"  %5937 = mul nuw i32 %5936, 37996" -> "  %6061 = and i32 %5937, 65532""  %5937 = mul nuw i32 %5936, 37996" -> "  %5938 = lshr i32 %5937, 16"
"  %5938 = lshr i32 %5937, 16"
"  %5938 = lshr i32 %5937, 16" -> "  %5942 = add nuw nsw i32 %5941, %5938"
"  %5939 = and i32 %5128, 65535"
"  %5939 = and i32 %5128, 65535" -> "  %5940 = mul nuw i32 %5939, 37996""  %5939 = and i32 %5128, 65535" -> "  %5949 = mul nuw i32 %5939, 45147""  %5939 = and i32 %5128, 65535" -> "  %6260 = mul nuw nsw i32 %5939, 17857""  %5939 = and i32 %5128, 65535" -> "  %6269 = mul nuw i32 %5939, 46547""  %5939 = and i32 %5128, 65535" -> "  %5997 = mul nuw i32 %5939, 62728""  %5939 = and i32 %5128, 65535" -> "  %5988 = mul nuw nsw i32 %5939, 1324""  %5939 = and i32 %5128, 65535" -> "  %6309 = mul nuw nsw i32 %5939, 31112""  %5939 = and i32 %5128, 65535" -> "  %6318 = mul nuw i32 %5939, 42170""  %5939 = and i32 %5128, 65535" -> "  %7490 = mul nuw nsw i32 %5939, 29744""  %5939 = and i32 %5128, 65535" -> "  %7481 = mul nuw nsw i32 %5939, 24315""  %5939 = and i32 %5128, 65535" -> "  %7441 = mul nuw nsw i32 %5939, 9871""  %5939 = and i32 %5128, 65535" -> "  %7432 = mul nuw i32 %5939, 42779""  %5939 = and i32 %5128, 65535" -> "  %7820 = mul nuw i32 %5939, 36786""  %5939 = and i32 %5128, 65535" -> "  %7811 = mul nuw nsw i32 %5939, 21884""  %5939 = and i32 %5128, 65535" -> "  %7771 = mul nuw nsw i32 %5939, 11561""  %5939 = and i32 %5128, 65535" -> "  %7762 = mul nuw nsw i32 %5939, 4087"
"  %5940 = mul nuw i32 %5939, 37996"
"  %5940 = mul nuw i32 %5939, 37996" -> "  %5943 = and i32 %5940, -65536""  %5940 = mul nuw i32 %5939, 37996" -> "  %5941 = and i32 %5940, 65532"
"  %5941 = and i32 %5940, 65532"
"  %5941 = and i32 %5940, 65532" -> "  %5942 = add nuw nsw i32 %5941, %5938"
"  %5942 = add nuw nsw i32 %5941, %5938"
"  %5942 = add nuw nsw i32 %5941, %5938" -> "  %5944 = add nuw i32 %5942, %5943"
"  %5943 = and i32 %5940, -65536"
"  %5943 = and i32 %5940, -65536" -> "  %5944 = add nuw i32 %5942, %5943"
"  %5944 = add nuw i32 %5942, %5943"
"  %5944 = add nuw i32 %5942, %5943" -> "  %5948 = lshr i32 %5944, 16""  %5944 = add nuw i32 %5942, %5943" -> "  %5946 = and i32 %5944, 65535"
"  %5945 = mul nuw i32 %5936, 45147"
"  %5945 = mul nuw i32 %5936, 45147" -> "  %5947 = add nuw i32 %5946, %5945"
"  %5946 = and i32 %5944, 65535"
"  %5946 = and i32 %5944, 65535" -> "  %5947 = add nuw i32 %5946, %5945"
"  %5947 = add nuw i32 %5946, %5945"
"  %5947 = add nuw i32 %5946, %5945" -> "  %6064 = and i32 %5947, 65535""  %5947 = add nuw i32 %5946, %5945" -> "  %5951 = lshr i32 %5947, 16"
"  %5948 = lshr i32 %5944, 16"
"  %5948 = lshr i32 %5944, 16" -> "  %5950 = add nuw i32 %5948, %5949"
"  %5949 = mul nuw i32 %5939, 45147"
"  %5949 = mul nuw i32 %5939, 45147" -> "  %5950 = add nuw i32 %5948, %5949"
"  %5950 = add nuw i32 %5948, %5949"
"  %5950 = add nuw i32 %5948, %5949" -> "  %5954 = and i32 %5950, -65536""  %5950 = add nuw i32 %5948, %5949" -> "  %5952 = and i32 %5950, 65535"
"  %5951 = lshr i32 %5947, 16"
"  %5951 = lshr i32 %5947, 16" -> "  %5953 = add nuw nsw i32 %5951, %5952"
"  %5952 = and i32 %5950, 65535"
"  %5952 = and i32 %5950, 65535" -> "  %5953 = add nuw nsw i32 %5951, %5952"
"  %5953 = add nuw nsw i32 %5951, %5952"
"  %5953 = add nuw nsw i32 %5951, %5952" -> "  %5955 = add nuw i32 %5953, %5954"
"  %5954 = and i32 %5950, -65536"
"  %5954 = and i32 %5950, -65536" -> "  %5955 = add nuw i32 %5953, %5954"
"  %5955 = add nuw i32 %5953, %5954"
"  %5955 = add nuw i32 %5953, %5954" -> "  %5973 = and i32 %5955, 65535""  %5955 = add nuw i32 %5953, %5954" -> "  %5977 = lshr i32 %5955, 16"
"  %5956 = and i32 %5130, 65535"
"  %5956 = and i32 %5130, 65535" -> "  %5962 = mul nuw i32 %5956, 45147""  %5956 = and i32 %5130, 65535" -> "  %5958 = mul nuw i32 %5956, 37996""  %5956 = and i32 %5130, 65535" -> "  %7778 = mul nuw nsw i32 %5956, 4087""  %5956 = and i32 %5130, 65535" -> "  %7785 = mul nuw nsw i32 %5956, 11561""  %5956 = and i32 %5130, 65535" -> "  %7840 = mul nuw nsw i32 %5956, 21884""  %5956 = and i32 %5130, 65535" -> "  %7847 = mul nuw i32 %5956, 36786""  %5956 = and i32 %5130, 65535" -> "  %7448 = mul nuw i32 %5956, 42779""  %5956 = and i32 %5130, 65535" -> "  %7455 = mul nuw nsw i32 %5956, 9871""  %5956 = and i32 %5130, 65535" -> "  %7510 = mul nuw nsw i32 %5956, 24315""  %5956 = and i32 %5130, 65535" -> "  %7517 = mul nuw nsw i32 %5956, 29744""  %5956 = and i32 %5130, 65535" -> "  %6338 = mul nuw nsw i32 %5956, 31112""  %5956 = and i32 %5130, 65535" -> "  %6342 = mul nuw i32 %5956, 42170""  %5956 = and i32 %5130, 65535" -> "  %6276 = mul nuw nsw i32 %5956, 17857""  %5956 = and i32 %5130, 65535" -> "  %6021 = mul nuw i32 %5956, 62728""  %5956 = and i32 %5130, 65535" -> "  %6017 = mul nuw nsw i32 %5956, 1324""  %5956 = and i32 %5130, 65535" -> "  %6283 = mul nuw i32 %5956, 46547"
"  %5957 = lshr i32 %5130, 16"
"  %5957 = lshr i32 %5130, 16" -> "  %7780 = mul nuw nsw i32 %5957, 4087""  %5957 = lshr i32 %5130, 16" -> "  %7789 = mul nuw nsw i32 %5957, 11561""  %5957 = lshr i32 %5130, 16" -> "  %7842 = mul nuw nsw i32 %5957, 21884""  %5957 = lshr i32 %5130, 16" -> "  %7851 = mul nuw i32 %5957, 36786""  %5957 = lshr i32 %5130, 16" -> "  %7450 = mul nuw i32 %5957, 42779""  %5957 = lshr i32 %5130, 16" -> "  %7459 = mul nuw nsw i32 %5957, 9871""  %5957 = lshr i32 %5130, 16" -> "  %7512 = mul nuw nsw i32 %5957, 24315""  %5957 = lshr i32 %5130, 16" -> "  %7521 = mul nuw nsw i32 %5957, 29744""  %5957 = lshr i32 %5130, 16" -> "  %6278 = mul nuw nsw i32 %5957, 17857""  %5957 = lshr i32 %5130, 16" -> "  %6287 = mul nuw i32 %5957, 46547""  %5957 = lshr i32 %5130, 16" -> "  %6340 = mul nuw nsw i32 %5957, 31112""  %5957 = lshr i32 %5130, 16" -> "  %6346 = mul nuw i32 %5957, 42170""  %5957 = lshr i32 %5130, 16" -> "  %6025 = mul nuw i32 %5957, 62728""  %5957 = lshr i32 %5130, 16" -> "  %6019 = mul nuw nsw i32 %5957, 1324""  %5957 = lshr i32 %5130, 16" -> "  %5966 = mul nuw i32 %5957, 45147""  %5957 = lshr i32 %5130, 16" -> "  %5960 = mul nuw i32 %5957, 37996"
"  %5958 = mul nuw i32 %5956, 37996"
"  %5958 = mul nuw i32 %5956, 37996" -> "  %5959 = lshr i32 %5958, 16""  %5958 = mul nuw i32 %5956, 37996" -> "  %5974 = and i32 %5958, 65532"
"  %5959 = lshr i32 %5958, 16"
"  %5959 = lshr i32 %5958, 16" -> "  %5961 = add nuw i32 %5959, %5960"
"  %5960 = mul nuw i32 %5957, 37996"
"  %5960 = mul nuw i32 %5957, 37996" -> "  %5961 = add nuw i32 %5959, %5960"
"  %5961 = add nuw i32 %5959, %5960"
"  %5961 = add nuw i32 %5959, %5960" -> "  %5963 = and i32 %5961, 65535""  %5961 = add nuw i32 %5959, %5960" -> "  %5965 = lshr i32 %5961, 16"
"  %5962 = mul nuw i32 %5956, 45147"
"  %5962 = mul nuw i32 %5956, 45147" -> "  %5964 = add nuw i32 %5963, %5962"
"  %5963 = and i32 %5961, 65535"
"  %5963 = and i32 %5961, 65535" -> "  %5964 = add nuw i32 %5963, %5962"
"  %5964 = add nuw i32 %5963, %5962"
"  %5964 = add nuw i32 %5963, %5962" -> "  %5976 = and i32 %5964, 65535""  %5964 = add nuw i32 %5963, %5962" -> "  %5968 = lshr i32 %5964, 16"
"  %5965 = lshr i32 %5961, 16"
"  %5965 = lshr i32 %5961, 16" -> "  %5967 = add nuw i32 %5965, %5966"
"  %5966 = mul nuw i32 %5957, 45147"
"  %5966 = mul nuw i32 %5957, 45147" -> "  %5967 = add nuw i32 %5965, %5966"
"  %5967 = add nuw i32 %5965, %5966"
"  %5967 = add nuw i32 %5965, %5966" -> "  %5971 = and i32 %5967, -65536""  %5967 = add nuw i32 %5965, %5966" -> "  %5969 = and i32 %5967, 65535"
"  %5968 = lshr i32 %5964, 16"
"  %5968 = lshr i32 %5964, 16" -> "  %5970 = add nuw nsw i32 %5969, %5968"
"  %5969 = and i32 %5967, 65535"
"  %5969 = and i32 %5967, 65535" -> "  %5970 = add nuw nsw i32 %5969, %5968"
"  %5970 = add nuw nsw i32 %5969, %5968"
"  %5970 = add nuw nsw i32 %5969, %5968" -> "  %5972 = add nuw i32 %5970, %5971"
"  %5971 = and i32 %5967, -65536"
"  %5971 = and i32 %5967, -65536" -> "  %5972 = add nuw i32 %5970, %5971"
"  %5972 = add nuw i32 %5970, %5971"
"  %5972 = add nuw i32 %5970, %5971" -> "  %5984 = add nuw i32 %5972, %5982"
"  %5973 = and i32 %5955, 65535"
"  %5973 = and i32 %5955, 65535" -> "  %5975 = add nuw nsw i32 %5973, %5974"
"  %5974 = and i32 %5958, 65532"
"  %5974 = and i32 %5958, 65532" -> "  %5975 = add nuw nsw i32 %5973, %5974"
"  %5975 = add nuw nsw i32 %5973, %5974"
"  %5975 = add nuw nsw i32 %5973, %5974" -> "  %6004 = and i32 %5975, 65535""  %5975 = add nuw nsw i32 %5973, %5974" -> "  %5979 = lshr i32 %5975, 16"
"  %5976 = and i32 %5964, 65535"
"  %5976 = and i32 %5964, 65535" -> "  %5978 = add nuw nsw i32 %5977, %5976"
"  %5977 = lshr i32 %5955, 16"
"  %5977 = lshr i32 %5955, 16" -> "  %5978 = add nuw nsw i32 %5977, %5976"
"  %5978 = add nuw nsw i32 %5977, %5976"
"  %5978 = add nuw nsw i32 %5977, %5976" -> "  %5982 = lshr i32 %5978, 16""  %5978 = add nuw nsw i32 %5977, %5976" -> "  %5980 = and i32 %5978, 65535"
"  %5979 = lshr i32 %5975, 16"
"  %5979 = lshr i32 %5975, 16" -> "  %5981 = add nuw nsw i32 %5980, %5979"
"  %5980 = and i32 %5978, 65535"
"  %5980 = and i32 %5978, 65535" -> "  %5981 = add nuw nsw i32 %5980, %5979"
"  %5981 = add nuw nsw i32 %5980, %5979"
"  %5981 = add nuw nsw i32 %5980, %5979" -> "  %6007 = and i32 %5981, 65535""  %5981 = add nuw nsw i32 %5980, %5979" -> "  %5983 = lshr i32 %5981, 16"
"  %5982 = lshr i32 %5978, 16"
"  %5982 = lshr i32 %5978, 16" -> "  %5984 = add nuw i32 %5972, %5982"
"  %5983 = lshr i32 %5981, 16"
"  %5983 = lshr i32 %5981, 16" -> "  %5985 = add nuw i32 %5984, %5983"
"  %5984 = add nuw i32 %5972, %5982"
"  %5984 = add nuw i32 %5972, %5982" -> "  %5985 = add nuw i32 %5984, %5983"
"  %5985 = add nuw i32 %5984, %5983"
"  %5985 = add nuw i32 %5984, %5983" -> "  %6036 = lshr i32 %5985, 16""  %5985 = add nuw i32 %5984, %5983" -> "  %6032 = and i32 %5985, 65535"
"  %5986 = mul nuw nsw i32 %5936, 1324"
"  %5986 = mul nuw nsw i32 %5936, 1324" -> "  %6005 = and i32 %5986, 65532""  %5986 = mul nuw nsw i32 %5936, 1324" -> "  %5987 = lshr i32 %5986, 16"
"  %5987 = lshr i32 %5986, 16"
"  %5987 = lshr i32 %5986, 16" -> "  %5990 = add nuw nsw i32 %5989, %5987"
"  %5988 = mul nuw nsw i32 %5939, 1324"
"  %5988 = mul nuw nsw i32 %5939, 1324" -> "  %5991 = and i32 %5988, 134152192""  %5988 = mul nuw nsw i32 %5939, 1324" -> "  %5989 = and i32 %5988, 65532"
"  %5989 = and i32 %5988, 65532"
"  %5989 = and i32 %5988, 65532" -> "  %5990 = add nuw nsw i32 %5989, %5987"
"  %5990 = add nuw nsw i32 %5989, %5987"
"  %5990 = add nuw nsw i32 %5989, %5987" -> "  %5992 = add nuw nsw i32 %5990, %5991"
"  %5991 = and i32 %5988, 134152192"
"  %5991 = and i32 %5988, 134152192" -> "  %5992 = add nuw nsw i32 %5990, %5991"
"  %5992 = add nuw nsw i32 %5990, %5991"
"  %5992 = add nuw nsw i32 %5990, %5991" -> "  %5996 = lshr i32 %5992, 16""  %5992 = add nuw nsw i32 %5990, %5991" -> "  %5994 = and i32 %5992, 65535"
"  %5993 = mul nuw i32 %5936, 62728"
"  %5993 = mul nuw i32 %5936, 62728" -> "  %5995 = add nuw i32 %5994, %5993"
"  %5994 = and i32 %5992, 65535"
"  %5994 = and i32 %5992, 65535" -> "  %5995 = add nuw i32 %5994, %5993"
"  %5995 = add nuw i32 %5994, %5993"
"  %5995 = add nuw i32 %5994, %5993" -> "  %6008 = and i32 %5995, 65535""  %5995 = add nuw i32 %5994, %5993" -> "  %5999 = lshr i32 %5995, 16"
"  %5996 = lshr i32 %5992, 16"
"  %5996 = lshr i32 %5992, 16" -> "  %5998 = add nuw i32 %5996, %5997"
"  %5997 = mul nuw i32 %5939, 62728"
"  %5997 = mul nuw i32 %5939, 62728" -> "  %5998 = add nuw i32 %5996, %5997"
"  %5998 = add nuw i32 %5996, %5997"
"  %5998 = add nuw i32 %5996, %5997" -> "  %6002 = and i32 %5998, -65536""  %5998 = add nuw i32 %5996, %5997" -> "  %6000 = and i32 %5998, 65535"
"  %5999 = lshr i32 %5995, 16"
"  %5999 = lshr i32 %5995, 16" -> "  %6001 = add nuw nsw i32 %5999, %6000"
"  %6000 = and i32 %5998, 65535"
"  %6000 = and i32 %5998, 65535" -> "  %6001 = add nuw nsw i32 %5999, %6000"
"  %6001 = add nuw nsw i32 %5999, %6000"
"  %6001 = add nuw nsw i32 %5999, %6000" -> "  %6003 = add nuw i32 %6001, %6002"
"  %6002 = and i32 %5998, -65536"
"  %6002 = and i32 %5998, -65536" -> "  %6003 = add nuw i32 %6001, %6002"
"  %6003 = add nuw i32 %6001, %6002"
"  %6003 = add nuw i32 %6001, %6002" -> "  %6011 = add nuw i32 %6003, %6010"
"  %6004 = and i32 %5975, 65535"
"  %6004 = and i32 %5975, 65535" -> "  %6006 = add nuw nsw i32 %6004, %6005"
"  %6005 = and i32 %5986, 65532"
"  %6005 = and i32 %5986, 65532" -> "  %6006 = add nuw nsw i32 %6004, %6005"
"  %6006 = add nuw nsw i32 %6004, %6005"
"  %6006 = add nuw nsw i32 %6004, %6005" -> "  %6070 = and i32 %6006, 65535""  %6006 = add nuw nsw i32 %6004, %6005" -> "  %6013 = lshr i32 %6006, 16"
"  %6007 = and i32 %5981, 65535"
"  %6007 = and i32 %5981, 65535" -> "  %6009 = add nuw nsw i32 %6007, %6008"
"  %6008 = and i32 %5995, 65535"
"  %6008 = and i32 %5995, 65535" -> "  %6009 = add nuw nsw i32 %6007, %6008"
"  %6009 = add nuw nsw i32 %6007, %6008"
"  %6009 = add nuw nsw i32 %6007, %6008" -> "  %6012 = and i32 %6009, 65535""  %6009 = add nuw nsw i32 %6007, %6008" -> "  %6010 = lshr i32 %6009, 16"
"  %6010 = lshr i32 %6009, 16"
"  %6010 = lshr i32 %6009, 16" -> "  %6011 = add nuw i32 %6003, %6010"
"  %6011 = add nuw i32 %6003, %6010"
"  %6011 = add nuw i32 %6003, %6010" -> "  %6016 = add nuw i32 %6011, %6015"
"  %6012 = and i32 %6009, 65535"
"  %6012 = and i32 %6009, 65535" -> "  %6014 = add nuw nsw i32 %6012, %6013"
"  %6013 = lshr i32 %6006, 16"
"  %6013 = lshr i32 %6006, 16" -> "  %6014 = add nuw nsw i32 %6012, %6013"
"  %6014 = add nuw nsw i32 %6012, %6013"
"  %6014 = add nuw nsw i32 %6012, %6013" -> "  %6073 = and i32 %6014, 65535""  %6014 = add nuw nsw i32 %6012, %6013" -> "  %6015 = lshr i32 %6014, 16"
"  %6015 = lshr i32 %6014, 16"
"  %6015 = lshr i32 %6014, 16" -> "  %6016 = add nuw i32 %6011, %6015"
"  %6016 = add nuw i32 %6011, %6015"
"  %6016 = add nuw i32 %6011, %6015" -> "  %6049 = lshr i32 %6016, 16""  %6016 = add nuw i32 %6011, %6015" -> "  %6046 = and i32 %6016, 65535"
"  %6017 = mul nuw nsw i32 %5956, 1324"
"  %6017 = mul nuw nsw i32 %5956, 1324" -> "  %6033 = and i32 %6017, 65532""  %6017 = mul nuw nsw i32 %5956, 1324" -> "  %6018 = lshr i32 %6017, 16"
"  %6018 = lshr i32 %6017, 16"
"  %6018 = lshr i32 %6017, 16" -> "  %6020 = add nuw nsw i32 %6018, %6019"
"  %6019 = mul nuw nsw i32 %5957, 1324"
"  %6019 = mul nuw nsw i32 %5957, 1324" -> "  %6020 = add nuw nsw i32 %6018, %6019"
"  %6020 = add nuw nsw i32 %6018, %6019"
"  %6020 = add nuw nsw i32 %6018, %6019" -> "  %6024 = lshr i32 %6020, 16""  %6020 = add nuw nsw i32 %6018, %6019" -> "  %6022 = and i32 %6020, 65535"
"  %6021 = mul nuw i32 %5956, 62728"
"  %6021 = mul nuw i32 %5956, 62728" -> "  %6023 = add nuw i32 %6022, %6021"
"  %6022 = and i32 %6020, 65535"
"  %6022 = and i32 %6020, 65535" -> "  %6023 = add nuw i32 %6022, %6021"
"  %6023 = add nuw i32 %6022, %6021"
"  %6023 = add nuw i32 %6022, %6021" -> "  %6035 = and i32 %6023, 65535""  %6023 = add nuw i32 %6022, %6021" -> "  %6027 = lshr i32 %6023, 16"
"  %6024 = lshr i32 %6020, 16"
"  %6024 = lshr i32 %6020, 16" -> "  %6026 = add nuw i32 %6024, %6025"
"  %6025 = mul nuw i32 %5957, 62728"
"  %6025 = mul nuw i32 %5957, 62728" -> "  %6026 = add nuw i32 %6024, %6025"
"  %6026 = add nuw i32 %6024, %6025"
"  %6026 = add nuw i32 %6024, %6025" -> "  %6030 = and i32 %6026, -65536""  %6026 = add nuw i32 %6024, %6025" -> "  %6028 = and i32 %6026, 65535"
"  %6027 = lshr i32 %6023, 16"
"  %6027 = lshr i32 %6023, 16" -> "  %6029 = add nuw nsw i32 %6027, %6028"
"  %6028 = and i32 %6026, 65535"
"  %6028 = and i32 %6026, 65535" -> "  %6029 = add nuw nsw i32 %6027, %6028"
"  %6029 = add nuw nsw i32 %6027, %6028"
"  %6029 = add nuw nsw i32 %6027, %6028" -> "  %6031 = add nuw i32 %6029, %6030"
"  %6030 = and i32 %6026, -65536"
"  %6030 = and i32 %6026, -65536" -> "  %6031 = add nuw i32 %6029, %6030"
"  %6031 = add nuw i32 %6029, %6030"
"  %6031 = add nuw i32 %6029, %6030" -> "  %6039 = add nuw i32 %6031, %6038"
"  %6032 = and i32 %5985, 65535"
"  %6032 = and i32 %5985, 65535" -> "  %6034 = add nuw nsw i32 %6032, %6033"
"  %6033 = and i32 %6017, 65532"
"  %6033 = and i32 %6017, 65532" -> "  %6034 = add nuw nsw i32 %6032, %6033"
"  %6034 = add nuw nsw i32 %6032, %6033"
"  %6034 = add nuw nsw i32 %6032, %6033" -> "  %6045 = and i32 %6034, 65535""  %6034 = add nuw nsw i32 %6032, %6033" -> "  %6041 = lshr i32 %6034, 16"
"  %6035 = and i32 %6023, 65535"
"  %6035 = and i32 %6023, 65535" -> "  %6037 = add nuw nsw i32 %6036, %6035"
"  %6036 = lshr i32 %5985, 16"
"  %6036 = lshr i32 %5985, 16" -> "  %6037 = add nuw nsw i32 %6036, %6035"
"  %6037 = add nuw nsw i32 %6036, %6035"
"  %6037 = add nuw nsw i32 %6036, %6035" -> "  %6040 = and i32 %6037, 65535""  %6037 = add nuw nsw i32 %6036, %6035" -> "  %6038 = lshr i32 %6037, 16"
"  %6038 = lshr i32 %6037, 16"
"  %6038 = lshr i32 %6037, 16" -> "  %6039 = add nuw i32 %6031, %6038"
"  %6039 = add nuw i32 %6031, %6038"
"  %6039 = add nuw i32 %6031, %6038" -> "  %6044 = add nuw i32 %6039, %6043"
"  %6040 = and i32 %6037, 65535"
"  %6040 = and i32 %6037, 65535" -> "  %6042 = add nuw nsw i32 %6040, %6041"
"  %6041 = lshr i32 %6034, 16"
"  %6041 = lshr i32 %6034, 16" -> "  %6042 = add nuw nsw i32 %6040, %6041"
"  %6042 = add nuw nsw i32 %6040, %6041"
"  %6042 = add nuw nsw i32 %6040, %6041" -> "  %6048 = and i32 %6042, 65535""  %6042 = add nuw nsw i32 %6040, %6041" -> "  %6043 = lshr i32 %6042, 16"
"  %6043 = lshr i32 %6042, 16"
"  %6043 = lshr i32 %6042, 16" -> "  %6044 = add nuw i32 %6039, %6043"
"  %6044 = add nuw i32 %6039, %6043"
"  %6044 = add nuw i32 %6039, %6043" -> "  %6057 = and i32 %6044, -65536""  %6044 = add nuw i32 %6039, %6043" -> "  %6055 = and i32 %6044, 65535"
"  %6045 = and i32 %6034, 65535"
"  %6045 = and i32 %6034, 65535" -> "  %6047 = add nuw nsw i32 %6046, %6045"
"  %6046 = and i32 %6016, 65535"
"  %6046 = and i32 %6016, 65535" -> "  %6047 = add nuw nsw i32 %6046, %6045"
"  %6047 = add nuw nsw i32 %6046, %6045"
"  %6047 = add nuw nsw i32 %6046, %6045" -> "  %6087 = and i32 %6047, 65535""  %6047 = add nuw nsw i32 %6046, %6045" -> "  %6051 = lshr i32 %6047, 16"
"  %6048 = and i32 %6042, 65535"
"  %6048 = and i32 %6042, 65535" -> "  %6050 = add nuw nsw i32 %6048, %6049"
"  %6049 = lshr i32 %6016, 16"
"  %6049 = lshr i32 %6016, 16" -> "  %6050 = add nuw nsw i32 %6048, %6049"
"  %6050 = add nuw nsw i32 %6048, %6049"
"  %6050 = add nuw nsw i32 %6048, %6049" -> "  %6054 = lshr i32 %6050, 16""  %6050 = add nuw nsw i32 %6048, %6049" -> "  %6052 = and i32 %6050, 65535"
"  %6051 = lshr i32 %6047, 16"
"  %6051 = lshr i32 %6047, 16" -> "  %6053 = add nuw nsw i32 %6052, %6051"
"  %6052 = and i32 %6050, 65535"
"  %6052 = and i32 %6050, 65535" -> "  %6053 = add nuw nsw i32 %6052, %6051"
"  %6053 = add nuw nsw i32 %6052, %6051"
"  %6053 = add nuw nsw i32 %6052, %6051" -> "  %6094 = and i32 %6053, 65535""  %6053 = add nuw nsw i32 %6052, %6051" -> "  %6059 = lshr i32 %6053, 16"
"  %6054 = lshr i32 %6050, 16"
"  %6054 = lshr i32 %6050, 16" -> "  %6056 = add nuw nsw i32 %6054, %6055"
"  %6055 = and i32 %6044, 65535"
"  %6055 = and i32 %6044, 65535" -> "  %6056 = add nuw nsw i32 %6054, %6055"
"  %6056 = add nuw nsw i32 %6054, %6055"
"  %6056 = add nuw nsw i32 %6054, %6055" -> "  %6058 = add nuw i32 %6056, %6057"
"  %6057 = and i32 %6044, -65536"
"  %6057 = and i32 %6044, -65536" -> "  %6058 = add nuw i32 %6056, %6057"
"  %6058 = add nuw i32 %6056, %6057"
"  %6058 = add nuw i32 %6056, %6057" -> "  %6060 = add nuw i32 %6058, %6059"
"  %6059 = lshr i32 %6053, 16"
"  %6059 = lshr i32 %6053, 16" -> "  %6060 = add nuw i32 %6058, %6059"
"  %6060 = add nuw i32 %6058, %6059"
"  %6060 = add nuw i32 %6058, %6059" -> "  %6098 = add nuw i32 %6060, %6097"
"  %6061 = and i32 %5937, 65532"
"  %6061 = and i32 %5937, 65532" -> "  %6063 = add nuw nsw i32 %6062, %6061"
"  %6062 = and i32 %5922, 65535"
"  %6062 = and i32 %5922, 65535" -> "  %6063 = add nuw nsw i32 %6062, %6061"
"  %6063 = add nuw nsw i32 %6062, %6061"
"  %6063 = add nuw nsw i32 %6062, %6061" -> "  %6219 = and i32 %6063, 65535""  %6063 = add nuw nsw i32 %6062, %6061" -> "  %6067 = lshr i32 %6063, 16"
"  %6064 = and i32 %5947, 65535"
"  %6064 = and i32 %5947, 65535" -> "  %6066 = add nuw nsw i32 %6065, %6064"
"  %6065 = and i32 %5928, 65535"
"  %6065 = and i32 %5928, 65535" -> "  %6066 = add nuw nsw i32 %6065, %6064"
"  %6066 = add nuw nsw i32 %6065, %6064"
"  %6066 = add nuw nsw i32 %6065, %6064" -> "  %6080 = lshr i32 %6066, 16""  %6066 = add nuw nsw i32 %6065, %6064" -> "  %6068 = and i32 %6066, 65535"
"  %6067 = lshr i32 %6063, 16"
"  %6067 = lshr i32 %6063, 16" -> "  %6069 = add nuw nsw i32 %6068, %6067"
"  %6068 = and i32 %6066, 65535"
"  %6068 = and i32 %6066, 65535" -> "  %6069 = add nuw nsw i32 %6068, %6067"
"  %6069 = add nuw nsw i32 %6068, %6067"
"  %6069 = add nuw nsw i32 %6068, %6067" -> "  %6222 = and i32 %6069, 65535""  %6069 = add nuw nsw i32 %6068, %6067" -> "  %6081 = lshr i32 %6069, 16"
"  %6070 = and i32 %6006, 65535"
"  %6070 = and i32 %6006, 65535" -> "  %6072 = add nuw nsw i32 %6071, %6070"
"  %6071 = and i32 %5935, 65535"
"  %6071 = and i32 %5935, 65535" -> "  %6072 = add nuw nsw i32 %6071, %6070"
"  %6072 = add nuw nsw i32 %6071, %6070"
"  %6072 = add nuw nsw i32 %6071, %6070" -> "  %6079 = and i32 %6072, 65535""  %6072 = add nuw nsw i32 %6071, %6070" -> "  %6076 = lshr i32 %6072, 16"
"  %6073 = and i32 %6014, 65535"
"  %6073 = and i32 %6014, 65535" -> "  %6075 = add nuw nsw i32 %6074, %6073"
"  %6074 = lshr i32 %5935, 16"
"  %6074 = lshr i32 %5935, 16" -> "  %6075 = add nuw nsw i32 %6074, %6073"
"  %6075 = add nuw nsw i32 %6074, %6073"
"  %6075 = add nuw nsw i32 %6074, %6073" -> "  %6088 = lshr i32 %6075, 16""  %6075 = add nuw nsw i32 %6074, %6073" -> "  %6077 = and i32 %6075, 65535"
"  %6076 = lshr i32 %6072, 16"
"  %6076 = lshr i32 %6072, 16" -> "  %6078 = add nuw nsw i32 %6077, %6076"
"  %6077 = and i32 %6075, 65535"
"  %6077 = and i32 %6075, 65535" -> "  %6078 = add nuw nsw i32 %6077, %6076"
"  %6078 = add nuw nsw i32 %6077, %6076"
"  %6078 = add nuw nsw i32 %6077, %6076" -> "  %6090 = lshr i32 %6078, 16""  %6078 = add nuw nsw i32 %6077, %6076" -> "  %6085 = and i32 %6078, 65535"
"  %6079 = and i32 %6072, 65535"
"  %6079 = and i32 %6072, 65535" -> "  %6083 = add nuw nsw i32 %6082, %6079"
"  %6080 = lshr i32 %6066, 16"
"  %6080 = lshr i32 %6066, 16" -> "  %6082 = add nuw nsw i32 %6081, %6080"
"  %6081 = lshr i32 %6069, 16"
"  %6081 = lshr i32 %6069, 16" -> "  %6082 = add nuw nsw i32 %6081, %6080"
"  %6082 = add nuw nsw i32 %6081, %6080"
"  %6082 = add nuw nsw i32 %6081, %6080" -> "  %6083 = add nuw nsw i32 %6082, %6079"
"  %6083 = add nuw nsw i32 %6082, %6079"
"  %6083 = add nuw nsw i32 %6082, %6079" -> "  %6231 = and i32 %6083, 65535""  %6083 = add nuw nsw i32 %6082, %6079" -> "  %6084 = lshr i32 %6083, 16"
"  %6084 = lshr i32 %6083, 16"
"  %6084 = lshr i32 %6083, 16" -> "  %6086 = add nuw nsw i32 %6084, %6085"
"  %6085 = and i32 %6078, 65535"
"  %6085 = and i32 %6078, 65535" -> "  %6086 = add nuw nsw i32 %6084, %6085"
"  %6086 = add nuw nsw i32 %6084, %6085"
"  %6086 = add nuw nsw i32 %6084, %6085" -> "  %6234 = and i32 %6086, 65535""  %6086 = add nuw nsw i32 %6084, %6085" -> "  %6092 = lshr i32 %6086, 16"
"  %6087 = and i32 %6047, 65535"
"  %6087 = and i32 %6047, 65535" -> "  %6089 = add nuw nsw i32 %6087, %6088"
"  %6088 = lshr i32 %6075, 16"
"  %6088 = lshr i32 %6075, 16" -> "  %6089 = add nuw nsw i32 %6087, %6088"
"  %6089 = add nuw nsw i32 %6087, %6088"
"  %6089 = add nuw nsw i32 %6087, %6088" -> "  %6091 = add nuw nsw i32 %6089, %6090"
"  %6090 = lshr i32 %6078, 16"
"  %6090 = lshr i32 %6078, 16" -> "  %6091 = add nuw nsw i32 %6089, %6090"
"  %6091 = add nuw nsw i32 %6089, %6090"
"  %6091 = add nuw nsw i32 %6089, %6090" -> "  %6093 = add nuw nsw i32 %6091, %6092"
"  %6092 = lshr i32 %6086, 16"
"  %6092 = lshr i32 %6086, 16" -> "  %6093 = add nuw nsw i32 %6091, %6092"
"  %6093 = add nuw nsw i32 %6091, %6092"
"  %6093 = add nuw nsw i32 %6091, %6092" -> "  %6378 = and i32 %6093, 65535""  %6093 = add nuw nsw i32 %6091, %6092" -> "  %6095 = lshr i32 %6093, 16"
"  %6094 = and i32 %6053, 65535"
"  %6094 = and i32 %6053, 65535" -> "  %6096 = add nuw nsw i32 %6095, %6094"
"  %6095 = lshr i32 %6093, 16"
"  %6095 = lshr i32 %6093, 16" -> "  %6096 = add nuw nsw i32 %6095, %6094"
"  %6096 = add nuw nsw i32 %6095, %6094"
"  %6096 = add nuw nsw i32 %6095, %6094" -> "  %6381 = and i32 %6096, 65535""  %6096 = add nuw nsw i32 %6095, %6094" -> "  %6097 = lshr i32 %6096, 16"
"  %6097 = lshr i32 %6096, 16"
"  %6097 = lshr i32 %6096, 16" -> "  %6098 = add nuw i32 %6060, %6097"
"  %6098 = add nuw i32 %6060, %6097"
"  %6098 = add nuw i32 %6060, %6097" -> "  %6387 = and i32 %6098, 65535""  %6098 = add nuw i32 %6060, %6097" -> "  %6390 = lshr i32 %6098, 16"
"  %6099 = mul nuw nsw i32 %5802, 17857"
"  %6099 = mul nuw nsw i32 %5802, 17857" -> "  %6218 = and i32 %6099, 65535""  %6099 = mul nuw nsw i32 %5802, 17857" -> "  %6100 = lshr i32 %6099, 16"
"  %6100 = lshr i32 %6099, 16"
"  %6100 = lshr i32 %6099, 16" -> "  %6103 = add nuw nsw i32 %6102, %6100"
"  %6101 = mul nuw nsw i32 %5803, 17857"
"  %6101 = mul nuw nsw i32 %5803, 17857" -> "  %6104 = and i32 %6101, 2147418112""  %6101 = mul nuw nsw i32 %5803, 17857" -> "  %6102 = and i32 %6101, 65535"
"  %6102 = and i32 %6101, 65535"
"  %6102 = and i32 %6101, 65535" -> "  %6103 = add nuw nsw i32 %6102, %6100"
"  %6103 = add nuw nsw i32 %6102, %6100"
"  %6103 = add nuw nsw i32 %6102, %6100" -> "  %6105 = add nuw nsw i32 %6103, %6104"
"  %6104 = and i32 %6101, 2147418112"
"  %6104 = and i32 %6101, 2147418112" -> "  %6105 = add nuw nsw i32 %6103, %6104"
"  %6105 = add nuw nsw i32 %6103, %6104"
"  %6105 = add nuw nsw i32 %6103, %6104" -> "  %6109 = lshr i32 %6105, 16""  %6105 = add nuw nsw i32 %6103, %6104" -> "  %6107 = and i32 %6105, 65535"
"  %6106 = mul nuw i32 %5802, 46547"
"  %6106 = mul nuw i32 %5802, 46547" -> "  %6108 = add nuw i32 %6107, %6106"
"  %6107 = and i32 %6105, 65535"
"  %6107 = and i32 %6105, 65535" -> "  %6108 = add nuw i32 %6107, %6106"
"  %6108 = add nuw i32 %6107, %6106"
"  %6108 = add nuw i32 %6107, %6106" -> "  %6221 = and i32 %6108, 65535""  %6108 = add nuw i32 %6107, %6106" -> "  %6112 = lshr i32 %6108, 16"
"  %6109 = lshr i32 %6105, 16"
"  %6109 = lshr i32 %6105, 16" -> "  %6111 = add nuw i32 %6109, %6110"
"  %6110 = mul nuw i32 %5803, 46547"
"  %6110 = mul nuw i32 %5803, 46547" -> "  %6111 = add nuw i32 %6109, %6110"
"  %6111 = add nuw i32 %6109, %6110"
"  %6111 = add nuw i32 %6109, %6110" -> "  %6115 = and i32 %6111, -65536""  %6111 = add nuw i32 %6109, %6110" -> "  %6113 = and i32 %6111, 65535"
"  %6112 = lshr i32 %6108, 16"
"  %6112 = lshr i32 %6108, 16" -> "  %6114 = add nuw nsw i32 %6112, %6113"
"  %6113 = and i32 %6111, 65535"
"  %6113 = and i32 %6111, 65535" -> "  %6114 = add nuw nsw i32 %6112, %6113"
"  %6114 = add nuw nsw i32 %6112, %6113"
"  %6114 = add nuw nsw i32 %6112, %6113" -> "  %6116 = add nuw i32 %6114, %6115"
"  %6115 = and i32 %6111, -65536"
"  %6115 = and i32 %6111, -65536" -> "  %6116 = add nuw i32 %6114, %6115"
"  %6116 = add nuw i32 %6114, %6115"
"  %6116 = add nuw i32 %6114, %6115" -> "  %6135 = and i32 %6116, 65535""  %6116 = add nuw i32 %6114, %6115" -> "  %6139 = lshr i32 %6116, 16"
"  %6117 = mul nuw nsw i32 %5822, 17857"
"  %6117 = mul nuw nsw i32 %5822, 17857" -> "  %6136 = and i32 %6117, 65535""  %6117 = mul nuw nsw i32 %5822, 17857" -> "  %6118 = lshr i32 %6117, 16"
"  %6118 = lshr i32 %6117, 16"
"  %6118 = lshr i32 %6117, 16" -> "  %6121 = add nuw nsw i32 %6120, %6118"
"  %6119 = mul nuw nsw i32 %5823, 17857"
"  %6119 = mul nuw nsw i32 %5823, 17857" -> "  %6122 = and i32 %6119, 2147418112""  %6119 = mul nuw nsw i32 %5823, 17857" -> "  %6120 = and i32 %6119, 65535"
"  %6120 = and i32 %6119, 65535"
"  %6120 = and i32 %6119, 65535" -> "  %6121 = add nuw nsw i32 %6120, %6118"
"  %6121 = add nuw nsw i32 %6120, %6118"
"  %6121 = add nuw nsw i32 %6120, %6118" -> "  %6123 = add nuw nsw i32 %6121, %6122"
"  %6122 = and i32 %6119, 2147418112"
"  %6122 = and i32 %6119, 2147418112" -> "  %6123 = add nuw nsw i32 %6121, %6122"
"  %6123 = add nuw nsw i32 %6121, %6122"
"  %6123 = add nuw nsw i32 %6121, %6122" -> "  %6127 = lshr i32 %6123, 16""  %6123 = add nuw nsw i32 %6121, %6122" -> "  %6125 = and i32 %6123, 65535"
"  %6124 = mul nuw i32 %5822, 46547"
"  %6124 = mul nuw i32 %5822, 46547" -> "  %6126 = add nuw i32 %6125, %6124"
"  %6125 = and i32 %6123, 65535"
"  %6125 = and i32 %6123, 65535" -> "  %6126 = add nuw i32 %6125, %6124"
"  %6126 = add nuw i32 %6125, %6124"
"  %6126 = add nuw i32 %6125, %6124" -> "  %6138 = and i32 %6126, 65535""  %6126 = add nuw i32 %6125, %6124" -> "  %6130 = lshr i32 %6126, 16"
"  %6127 = lshr i32 %6123, 16"
"  %6127 = lshr i32 %6123, 16" -> "  %6129 = add nuw i32 %6127, %6128"
"  %6128 = mul nuw i32 %5823, 46547"
"  %6128 = mul nuw i32 %5823, 46547" -> "  %6129 = add nuw i32 %6127, %6128"
"  %6129 = add nuw i32 %6127, %6128"
"  %6129 = add nuw i32 %6127, %6128" -> "  %6133 = and i32 %6129, -65536""  %6129 = add nuw i32 %6127, %6128" -> "  %6131 = and i32 %6129, 65535"
"  %6130 = lshr i32 %6126, 16"
"  %6130 = lshr i32 %6126, 16" -> "  %6132 = add nuw nsw i32 %6130, %6131"
"  %6131 = and i32 %6129, 65535"
"  %6131 = and i32 %6129, 65535" -> "  %6132 = add nuw nsw i32 %6130, %6131"
"  %6132 = add nuw nsw i32 %6130, %6131"
"  %6132 = add nuw nsw i32 %6130, %6131" -> "  %6134 = add nuw i32 %6132, %6133"
"  %6133 = and i32 %6129, -65536"
"  %6133 = and i32 %6129, -65536" -> "  %6134 = add nuw i32 %6132, %6133"
"  %6134 = add nuw i32 %6132, %6133"
"  %6134 = add nuw i32 %6132, %6133" -> "  %6142 = add nuw i32 %6134, %6141"
"  %6135 = and i32 %6116, 65535"
"  %6135 = and i32 %6116, 65535" -> "  %6137 = add nuw nsw i32 %6135, %6136"
"  %6136 = and i32 %6117, 65535"
"  %6136 = and i32 %6117, 65535" -> "  %6137 = add nuw nsw i32 %6135, %6136"
"  %6137 = add nuw nsw i32 %6135, %6136"
"  %6137 = add nuw nsw i32 %6135, %6136" -> "  %6166 = and i32 %6137, 65535""  %6137 = add nuw nsw i32 %6135, %6136" -> "  %6144 = lshr i32 %6137, 16"
"  %6138 = and i32 %6126, 65535"
"  %6138 = and i32 %6126, 65535" -> "  %6140 = add nuw nsw i32 %6138, %6139"
"  %6139 = lshr i32 %6116, 16"
"  %6139 = lshr i32 %6116, 16" -> "  %6140 = add nuw nsw i32 %6138, %6139"
"  %6140 = add nuw nsw i32 %6138, %6139"
"  %6140 = add nuw nsw i32 %6138, %6139" -> "  %6143 = and i32 %6140, 65535""  %6140 = add nuw nsw i32 %6138, %6139" -> "  %6141 = lshr i32 %6140, 16"
"  %6141 = lshr i32 %6140, 16"
"  %6141 = lshr i32 %6140, 16" -> "  %6142 = add nuw i32 %6134, %6141"
"  %6142 = add nuw i32 %6134, %6141"
"  %6142 = add nuw i32 %6134, %6141" -> "  %6147 = add nuw i32 %6142, %6146"
"  %6143 = and i32 %6140, 65535"
"  %6143 = and i32 %6140, 65535" -> "  %6145 = add nuw nsw i32 %6143, %6144"
"  %6144 = lshr i32 %6137, 16"
"  %6144 = lshr i32 %6137, 16" -> "  %6145 = add nuw nsw i32 %6143, %6144"
"  %6145 = add nuw nsw i32 %6143, %6144"
"  %6145 = add nuw nsw i32 %6143, %6144" -> "  %6169 = and i32 %6145, 65535""  %6145 = add nuw nsw i32 %6143, %6144" -> "  %6146 = lshr i32 %6145, 16"
"  %6146 = lshr i32 %6145, 16"
"  %6146 = lshr i32 %6145, 16" -> "  %6147 = add nuw i32 %6142, %6146"
"  %6147 = add nuw i32 %6142, %6146"
"  %6147 = add nuw i32 %6142, %6146" -> "  %6198 = lshr i32 %6147, 16""  %6147 = add nuw i32 %6142, %6146" -> "  %6194 = and i32 %6147, 65535"
"  %6148 = mul nuw nsw i32 %5802, 31112"
"  %6148 = mul nuw nsw i32 %5802, 31112" -> "  %6167 = and i32 %6148, 65528""  %6148 = mul nuw nsw i32 %5802, 31112" -> "  %6149 = lshr i32 %6148, 16"
"  %6149 = lshr i32 %6148, 16"
"  %6149 = lshr i32 %6148, 16" -> "  %6152 = add nuw nsw i32 %6151, %6149"
"  %6150 = mul nuw nsw i32 %5803, 31112"
"  %6150 = mul nuw nsw i32 %5803, 31112" -> "  %6153 = and i32 %6150, 2147418112""  %6150 = mul nuw nsw i32 %5803, 31112" -> "  %6151 = and i32 %6150, 65528"
"  %6151 = and i32 %6150, 65528"
"  %6151 = and i32 %6150, 65528" -> "  %6152 = add nuw nsw i32 %6151, %6149"
"  %6152 = add nuw nsw i32 %6151, %6149"
"  %6152 = add nuw nsw i32 %6151, %6149" -> "  %6154 = add nuw nsw i32 %6152, %6153"
"  %6153 = and i32 %6150, 2147418112"
"  %6153 = and i32 %6150, 2147418112" -> "  %6154 = add nuw nsw i32 %6152, %6153"
"  %6154 = add nuw nsw i32 %6152, %6153"
"  %6154 = add nuw nsw i32 %6152, %6153" -> "  %6158 = lshr i32 %6154, 16""  %6154 = add nuw nsw i32 %6152, %6153" -> "  %6156 = and i32 %6154, 65535"
"  %6155 = mul nuw i32 %5802, 42170"
"  %6155 = mul nuw i32 %5802, 42170" -> "  %6157 = add nuw i32 %6156, %6155"
"  %6156 = and i32 %6154, 65535"
"  %6156 = and i32 %6154, 65535" -> "  %6157 = add nuw i32 %6156, %6155"
"  %6157 = add nuw i32 %6156, %6155"
"  %6157 = add nuw i32 %6156, %6155" -> "  %6170 = and i32 %6157, 65535""  %6157 = add nuw i32 %6156, %6155" -> "  %6161 = lshr i32 %6157, 16"
"  %6158 = lshr i32 %6154, 16"
"  %6158 = lshr i32 %6154, 16" -> "  %6160 = add nuw i32 %6158, %6159"
"  %6159 = mul nuw i32 %5803, 42170"
"  %6159 = mul nuw i32 %5803, 42170" -> "  %6160 = add nuw i32 %6158, %6159"
"  %6160 = add nuw i32 %6158, %6159"
"  %6160 = add nuw i32 %6158, %6159" -> "  %6164 = and i32 %6160, -65536""  %6160 = add nuw i32 %6158, %6159" -> "  %6162 = and i32 %6160, 65535"
"  %6161 = lshr i32 %6157, 16"
"  %6161 = lshr i32 %6157, 16" -> "  %6163 = add nuw nsw i32 %6161, %6162"
"  %6162 = and i32 %6160, 65535"
"  %6162 = and i32 %6160, 65535" -> "  %6163 = add nuw nsw i32 %6161, %6162"
"  %6163 = add nuw nsw i32 %6161, %6162"
"  %6163 = add nuw nsw i32 %6161, %6162" -> "  %6165 = add nuw i32 %6163, %6164"
"  %6164 = and i32 %6160, -65536"
"  %6164 = and i32 %6160, -65536" -> "  %6165 = add nuw i32 %6163, %6164"
"  %6165 = add nuw i32 %6163, %6164"
"  %6165 = add nuw i32 %6163, %6164" -> "  %6173 = add nuw i32 %6165, %6172"
"  %6166 = and i32 %6137, 65535"
"  %6166 = and i32 %6137, 65535" -> "  %6168 = add nuw nsw i32 %6166, %6167"
"  %6167 = and i32 %6148, 65528"
"  %6167 = and i32 %6148, 65528" -> "  %6168 = add nuw nsw i32 %6166, %6167"
"  %6168 = add nuw nsw i32 %6166, %6167"
"  %6168 = add nuw nsw i32 %6166, %6167" -> "  %6230 = and i32 %6168, 65535""  %6168 = add nuw nsw i32 %6166, %6167" -> "  %6175 = lshr i32 %6168, 16"
"  %6169 = and i32 %6145, 65535"
"  %6169 = and i32 %6145, 65535" -> "  %6171 = add nuw nsw i32 %6169, %6170"
"  %6170 = and i32 %6157, 65535"
"  %6170 = and i32 %6157, 65535" -> "  %6171 = add nuw nsw i32 %6169, %6170"
"  %6171 = add nuw nsw i32 %6169, %6170"
"  %6171 = add nuw nsw i32 %6169, %6170" -> "  %6174 = and i32 %6171, 65535""  %6171 = add nuw nsw i32 %6169, %6170" -> "  %6172 = lshr i32 %6171, 16"
"  %6172 = lshr i32 %6171, 16"
"  %6172 = lshr i32 %6171, 16" -> "  %6173 = add nuw i32 %6165, %6172"
"  %6173 = add nuw i32 %6165, %6172"
"  %6173 = add nuw i32 %6165, %6172" -> "  %6178 = add nuw i32 %6173, %6177"
"  %6174 = and i32 %6171, 65535"
"  %6174 = and i32 %6171, 65535" -> "  %6176 = add nuw nsw i32 %6174, %6175"
"  %6175 = lshr i32 %6168, 16"
"  %6175 = lshr i32 %6168, 16" -> "  %6176 = add nuw nsw i32 %6174, %6175"
"  %6176 = add nuw nsw i32 %6174, %6175"
"  %6176 = add nuw nsw i32 %6174, %6175" -> "  %6233 = and i32 %6176, 65535""  %6176 = add nuw nsw i32 %6174, %6175" -> "  %6177 = lshr i32 %6176, 16"
"  %6177 = lshr i32 %6176, 16"
"  %6177 = lshr i32 %6176, 16" -> "  %6178 = add nuw i32 %6173, %6177"
"  %6178 = add nuw i32 %6173, %6177"
"  %6178 = add nuw i32 %6173, %6177" -> "  %6211 = lshr i32 %6178, 16""  %6178 = add nuw i32 %6173, %6177" -> "  %6208 = and i32 %6178, 65535"
"  %6179 = mul nuw nsw i32 %5822, 31112"
"  %6179 = mul nuw nsw i32 %5822, 31112" -> "  %6195 = and i32 %6179, 65528""  %6179 = mul nuw nsw i32 %5822, 31112" -> "  %6180 = lshr i32 %6179, 16"
"  %6180 = lshr i32 %6179, 16"
"  %6180 = lshr i32 %6179, 16" -> "  %6182 = add nuw nsw i32 %6181, %6180"
"  %6181 = mul nuw nsw i32 %5823, 31112"
"  %6181 = mul nuw nsw i32 %5823, 31112" -> "  %6182 = add nuw nsw i32 %6181, %6180"
"  %6182 = add nuw nsw i32 %6181, %6180"
"  %6182 = add nuw nsw i32 %6181, %6180" -> "  %6186 = lshr i32 %6182, 16""  %6182 = add nuw nsw i32 %6181, %6180" -> "  %6184 = and i32 %6182, 65535"
"  %6183 = mul nuw i32 %5822, 42170"
"  %6183 = mul nuw i32 %5822, 42170" -> "  %6185 = add nuw i32 %6184, %6183"
"  %6184 = and i32 %6182, 65535"
"  %6184 = and i32 %6182, 65535" -> "  %6185 = add nuw i32 %6184, %6183"
"  %6185 = add nuw i32 %6184, %6183"
"  %6185 = add nuw i32 %6184, %6183" -> "  %6197 = and i32 %6185, 65535""  %6185 = add nuw i32 %6184, %6183" -> "  %6189 = lshr i32 %6185, 16"
"  %6186 = lshr i32 %6182, 16"
"  %6186 = lshr i32 %6182, 16" -> "  %6188 = add nuw i32 %6186, %6187"
"  %6187 = mul nuw i32 %5823, 42170"
"  %6187 = mul nuw i32 %5823, 42170" -> "  %6188 = add nuw i32 %6186, %6187"
"  %6188 = add nuw i32 %6186, %6187"
"  %6188 = add nuw i32 %6186, %6187" -> "  %6192 = and i32 %6188, -65536""  %6188 = add nuw i32 %6186, %6187" -> "  %6190 = and i32 %6188, 65535"
"  %6189 = lshr i32 %6185, 16"
"  %6189 = lshr i32 %6185, 16" -> "  %6191 = add nuw nsw i32 %6189, %6190"
"  %6190 = and i32 %6188, 65535"
"  %6190 = and i32 %6188, 65535" -> "  %6191 = add nuw nsw i32 %6189, %6190"
"  %6191 = add nuw nsw i32 %6189, %6190"
"  %6191 = add nuw nsw i32 %6189, %6190" -> "  %6193 = add nuw i32 %6191, %6192"
"  %6192 = and i32 %6188, -65536"
"  %6192 = and i32 %6188, -65536" -> "  %6193 = add nuw i32 %6191, %6192"
"  %6193 = add nuw i32 %6191, %6192"
"  %6193 = add nuw i32 %6191, %6192" -> "  %6201 = add nuw i32 %6193, %6200"
"  %6194 = and i32 %6147, 65535"
"  %6194 = and i32 %6147, 65535" -> "  %6196 = add nuw nsw i32 %6194, %6195"
"  %6195 = and i32 %6179, 65528"
"  %6195 = and i32 %6179, 65528" -> "  %6196 = add nuw nsw i32 %6194, %6195"
"  %6196 = add nuw nsw i32 %6194, %6195"
"  %6196 = add nuw nsw i32 %6194, %6195" -> "  %6207 = and i32 %6196, 65535""  %6196 = add nuw nsw i32 %6194, %6195" -> "  %6203 = lshr i32 %6196, 16"
"  %6197 = and i32 %6185, 65535"
"  %6197 = and i32 %6185, 65535" -> "  %6199 = add nuw nsw i32 %6198, %6197"
"  %6198 = lshr i32 %6147, 16"
"  %6198 = lshr i32 %6147, 16" -> "  %6199 = add nuw nsw i32 %6198, %6197"
"  %6199 = add nuw nsw i32 %6198, %6197"
"  %6199 = add nuw nsw i32 %6198, %6197" -> "  %6202 = and i32 %6199, 65535""  %6199 = add nuw nsw i32 %6198, %6197" -> "  %6200 = lshr i32 %6199, 16"
"  %6200 = lshr i32 %6199, 16"
"  %6200 = lshr i32 %6199, 16" -> "  %6201 = add nuw i32 %6193, %6200"
"  %6201 = add nuw i32 %6193, %6200"
"  %6201 = add nuw i32 %6193, %6200" -> "  %6206 = add nuw i32 %6201, %6205"
"  %6202 = and i32 %6199, 65535"
"  %6202 = and i32 %6199, 65535" -> "  %6204 = add nuw nsw i32 %6202, %6203"
"  %6203 = lshr i32 %6196, 16"
"  %6203 = lshr i32 %6196, 16" -> "  %6204 = add nuw nsw i32 %6202, %6203"
"  %6204 = add nuw nsw i32 %6202, %6203"
"  %6204 = add nuw nsw i32 %6202, %6203" -> "  %6210 = and i32 %6204, 65535""  %6204 = add nuw nsw i32 %6202, %6203" -> "  %6205 = lshr i32 %6204, 16"
"  %6205 = lshr i32 %6204, 16"
"  %6205 = lshr i32 %6204, 16" -> "  %6206 = add nuw i32 %6201, %6205"
"  %6206 = add nuw i32 %6201, %6205"
"  %6206 = add nuw i32 %6201, %6205" -> "  %6255 = add nuw i32 %6206, %6216"
"  %6207 = and i32 %6196, 65535"
"  %6207 = and i32 %6196, 65535" -> "  %6209 = add nuw nsw i32 %6208, %6207"
"  %6208 = and i32 %6178, 65535"
"  %6208 = and i32 %6178, 65535" -> "  %6209 = add nuw nsw i32 %6208, %6207"
"  %6209 = add nuw nsw i32 %6208, %6207"
"  %6209 = add nuw nsw i32 %6208, %6207" -> "  %6244 = and i32 %6209, 65535""  %6209 = add nuw nsw i32 %6208, %6207" -> "  %6213 = lshr i32 %6209, 16"
"  %6210 = and i32 %6204, 65535"
"  %6210 = and i32 %6204, 65535" -> "  %6212 = add nuw nsw i32 %6211, %6210"
"  %6211 = lshr i32 %6178, 16"
"  %6211 = lshr i32 %6178, 16" -> "  %6212 = add nuw nsw i32 %6211, %6210"
"  %6212 = add nuw nsw i32 %6211, %6210"
"  %6212 = add nuw nsw i32 %6211, %6210" -> "  %6216 = lshr i32 %6212, 16""  %6212 = add nuw nsw i32 %6211, %6210" -> "  %6214 = and i32 %6212, 65535"
"  %6213 = lshr i32 %6209, 16"
"  %6213 = lshr i32 %6209, 16" -> "  %6215 = add nuw nsw i32 %6214, %6213"
"  %6214 = and i32 %6212, 65535"
"  %6214 = and i32 %6212, 65535" -> "  %6215 = add nuw nsw i32 %6214, %6213"
"  %6215 = add nuw nsw i32 %6214, %6213"
"  %6215 = add nuw nsw i32 %6214, %6213" -> "  %6251 = and i32 %6215, 65535""  %6215 = add nuw nsw i32 %6214, %6213" -> "  %6217 = lshr i32 %6215, 16"
"  %6216 = lshr i32 %6212, 16"
"  %6216 = lshr i32 %6212, 16" -> "  %6255 = add nuw i32 %6206, %6216"
"  %6217 = lshr i32 %6215, 16"
"  %6217 = lshr i32 %6215, 16" -> "  %6256 = add nuw i32 %6255, %6217"
"  %6218 = and i32 %6099, 65535"
"  %6218 = and i32 %6099, 65535" -> "  %6220 = add nuw nsw i32 %6219, %6218"
"  %6219 = and i32 %6063, 65535"
"  %6219 = and i32 %6063, 65535" -> "  %6220 = add nuw nsw i32 %6219, %6218"
"  %6220 = add nuw nsw i32 %6219, %6218"
"  %6220 = add nuw nsw i32 %6219, %6218" -> "  %6482 = and i32 %6220, 65535""  %6220 = add nuw nsw i32 %6219, %6218" -> "  %6224 = lshr i32 %6220, 16"
"  %6221 = and i32 %6108, 65535"
"  %6221 = and i32 %6108, 65535" -> "  %6223 = add nuw nsw i32 %6222, %6221"
"  %6222 = and i32 %6069, 65535"
"  %6222 = and i32 %6069, 65535" -> "  %6223 = add nuw nsw i32 %6222, %6221"
"  %6223 = add nuw nsw i32 %6222, %6221"
"  %6223 = add nuw nsw i32 %6222, %6221" -> "  %6227 = lshr i32 %6223, 16""  %6223 = add nuw nsw i32 %6222, %6221" -> "  %6225 = and i32 %6223, 65535"
"  %6224 = lshr i32 %6220, 16"
"  %6224 = lshr i32 %6220, 16" -> "  %6226 = add nuw nsw i32 %6225, %6224"
"  %6225 = and i32 %6223, 65535"
"  %6225 = and i32 %6223, 65535" -> "  %6226 = add nuw nsw i32 %6225, %6224"
"  %6226 = add nuw nsw i32 %6225, %6224"
"  %6226 = add nuw nsw i32 %6225, %6224" -> "  %6485 = and i32 %6226, 65535""  %6226 = add nuw nsw i32 %6225, %6224" -> "  %6228 = lshr i32 %6226, 16"
"  %6227 = lshr i32 %6223, 16"
"  %6227 = lshr i32 %6223, 16" -> "  %6229 = add nuw nsw i32 %6228, %6227"
"  %6228 = lshr i32 %6226, 16"
"  %6228 = lshr i32 %6226, 16" -> "  %6229 = add nuw nsw i32 %6228, %6227"
"  %6229 = add nuw nsw i32 %6228, %6227"
"  %6229 = add nuw nsw i32 %6228, %6227" -> "  %6240 = add nuw nsw i32 %6229, %6239"
"  %6230 = and i32 %6168, 65535"
"  %6230 = and i32 %6168, 65535" -> "  %6232 = add nuw nsw i32 %6231, %6230"
"  %6231 = and i32 %6083, 65535"
"  %6231 = and i32 %6083, 65535" -> "  %6232 = add nuw nsw i32 %6231, %6230"
"  %6232 = add nuw nsw i32 %6231, %6230"
"  %6232 = add nuw nsw i32 %6231, %6230" -> "  %6239 = and i32 %6232, 65535""  %6232 = add nuw nsw i32 %6231, %6230" -> "  %6236 = lshr i32 %6232, 16"
"  %6233 = and i32 %6176, 65535"
"  %6233 = and i32 %6176, 65535" -> "  %6235 = add nuw nsw i32 %6234, %6233"
"  %6234 = and i32 %6086, 65535"
"  %6234 = and i32 %6086, 65535" -> "  %6235 = add nuw nsw i32 %6234, %6233"
"  %6235 = add nuw nsw i32 %6234, %6233"
"  %6235 = add nuw nsw i32 %6234, %6233" -> "  %6245 = lshr i32 %6235, 16""  %6235 = add nuw nsw i32 %6234, %6233" -> "  %6237 = and i32 %6235, 65535"
"  %6236 = lshr i32 %6232, 16"
"  %6236 = lshr i32 %6232, 16" -> "  %6238 = add nuw nsw i32 %6237, %6236"
"  %6237 = and i32 %6235, 65535"
"  %6237 = and i32 %6235, 65535" -> "  %6238 = add nuw nsw i32 %6237, %6236"
"  %6238 = add nuw nsw i32 %6237, %6236"
"  %6238 = add nuw nsw i32 %6237, %6236" -> "  %6247 = lshr i32 %6238, 16""  %6238 = add nuw nsw i32 %6237, %6236" -> "  %6242 = and i32 %6238, 65535"
"  %6239 = and i32 %6232, 65535"
"  %6239 = and i32 %6232, 65535" -> "  %6240 = add nuw nsw i32 %6229, %6239"
"  %6240 = add nuw nsw i32 %6229, %6239"
"  %6240 = add nuw nsw i32 %6229, %6239" -> "  %6491 = and i32 %6240, 65535""  %6240 = add nuw nsw i32 %6229, %6239" -> "  %6241 = lshr i32 %6240, 16"
"  %6241 = lshr i32 %6240, 16"
"  %6241 = lshr i32 %6240, 16" -> "  %6243 = add nuw nsw i32 %6242, %6241"
"  %6242 = and i32 %6238, 65535"
"  %6242 = and i32 %6238, 65535" -> "  %6243 = add nuw nsw i32 %6242, %6241"
"  %6243 = add nuw nsw i32 %6242, %6241"
"  %6243 = add nuw nsw i32 %6242, %6241" -> "  %6494 = and i32 %6243, 65535""  %6243 = add nuw nsw i32 %6242, %6241" -> "  %6249 = lshr i32 %6243, 16"
"  %6244 = and i32 %6209, 65535"
"  %6244 = and i32 %6209, 65535" -> "  %6246 = add nuw nsw i32 %6245, %6244"
"  %6245 = lshr i32 %6235, 16"
"  %6245 = lshr i32 %6235, 16" -> "  %6246 = add nuw nsw i32 %6245, %6244"
"  %6246 = add nuw nsw i32 %6245, %6244"
"  %6246 = add nuw nsw i32 %6245, %6244" -> "  %6248 = add nuw nsw i32 %6246, %6247"
"  %6247 = lshr i32 %6238, 16"
"  %6247 = lshr i32 %6238, 16" -> "  %6248 = add nuw nsw i32 %6246, %6247"
"  %6248 = add nuw nsw i32 %6246, %6247"
"  %6248 = add nuw nsw i32 %6246, %6247" -> "  %6250 = add nuw nsw i32 %6248, %6249"
"  %6249 = lshr i32 %6243, 16"
"  %6249 = lshr i32 %6243, 16" -> "  %6250 = add nuw nsw i32 %6248, %6249"
"  %6250 = add nuw nsw i32 %6248, %6249"
"  %6250 = add nuw nsw i32 %6248, %6249" -> "  %6418 = and i32 %6250, 65535""  %6250 = add nuw nsw i32 %6248, %6249" -> "  %6252 = lshr i32 %6250, 16"
"  %6251 = and i32 %6215, 65535"
"  %6251 = and i32 %6215, 65535" -> "  %6253 = add nuw nsw i32 %6252, %6251"
"  %6252 = lshr i32 %6250, 16"
"  %6252 = lshr i32 %6250, 16" -> "  %6253 = add nuw nsw i32 %6252, %6251"
"  %6253 = add nuw nsw i32 %6252, %6251"
"  %6253 = add nuw nsw i32 %6252, %6251" -> "  %6421 = and i32 %6253, 65535""  %6253 = add nuw nsw i32 %6252, %6251" -> "  %6254 = lshr i32 %6253, 16"
"  %6254 = lshr i32 %6253, 16"
"  %6254 = lshr i32 %6253, 16" -> "  %6257 = add nuw i32 %6256, %6254"
"  %6255 = add nuw i32 %6206, %6216"
"  %6255 = add nuw i32 %6206, %6216" -> "  %6256 = add nuw i32 %6255, %6217"
"  %6256 = add nuw i32 %6255, %6217"
"  %6256 = add nuw i32 %6255, %6217" -> "  %6257 = add nuw i32 %6256, %6254"
"  %6257 = add nuw i32 %6256, %6254"
"  %6257 = add nuw i32 %6256, %6254" -> "  %6427 = and i32 %6257, 65535""  %6257 = add nuw i32 %6256, %6254" -> "  %6430 = lshr i32 %6257, 16"
"  %6258 = mul nuw nsw i32 %5936, 17857"
"  %6258 = mul nuw nsw i32 %5936, 17857" -> "  %6377 = and i32 %6258, 65535""  %6258 = mul nuw nsw i32 %5936, 17857" -> "  %6259 = lshr i32 %6258, 16"
"  %6259 = lshr i32 %6258, 16"
"  %6259 = lshr i32 %6258, 16" -> "  %6262 = add nuw nsw i32 %6261, %6259"
"  %6260 = mul nuw nsw i32 %5939, 17857"
"  %6260 = mul nuw nsw i32 %5939, 17857" -> "  %6263 = and i32 %6260, 2147418112""  %6260 = mul nuw nsw i32 %5939, 17857" -> "  %6261 = and i32 %6260, 65535"
"  %6261 = and i32 %6260, 65535"
"  %6261 = and i32 %6260, 65535" -> "  %6262 = add nuw nsw i32 %6261, %6259"
"  %6262 = add nuw nsw i32 %6261, %6259"
"  %6262 = add nuw nsw i32 %6261, %6259" -> "  %6264 = add nuw nsw i32 %6262, %6263"
"  %6263 = and i32 %6260, 2147418112"
"  %6263 = and i32 %6260, 2147418112" -> "  %6264 = add nuw nsw i32 %6262, %6263"
"  %6264 = add nuw nsw i32 %6262, %6263"
"  %6264 = add nuw nsw i32 %6262, %6263" -> "  %6268 = lshr i32 %6264, 16""  %6264 = add nuw nsw i32 %6262, %6263" -> "  %6266 = and i32 %6264, 65535"
"  %6265 = mul nuw i32 %5936, 46547"
"  %6265 = mul nuw i32 %5936, 46547" -> "  %6267 = add nuw i32 %6266, %6265"
"  %6266 = and i32 %6264, 65535"
"  %6266 = and i32 %6264, 65535" -> "  %6267 = add nuw i32 %6266, %6265"
"  %6267 = add nuw i32 %6266, %6265"
"  %6267 = add nuw i32 %6266, %6265" -> "  %6380 = and i32 %6267, 65535""  %6267 = add nuw i32 %6266, %6265" -> "  %6271 = lshr i32 %6267, 16"
"  %6268 = lshr i32 %6264, 16"
"  %6268 = lshr i32 %6264, 16" -> "  %6270 = add nuw i32 %6268, %6269"
"  %6269 = mul nuw i32 %5939, 46547"
"  %6269 = mul nuw i32 %5939, 46547" -> "  %6270 = add nuw i32 %6268, %6269"
"  %6270 = add nuw i32 %6268, %6269"
"  %6270 = add nuw i32 %6268, %6269" -> "  %6274 = and i32 %6270, -65536""  %6270 = add nuw i32 %6268, %6269" -> "  %6272 = and i32 %6270, 65535"
"  %6271 = lshr i32 %6267, 16"
"  %6271 = lshr i32 %6267, 16" -> "  %6273 = add nuw nsw i32 %6271, %6272"
"  %6272 = and i32 %6270, 65535"
"  %6272 = and i32 %6270, 65535" -> "  %6273 = add nuw nsw i32 %6271, %6272"
"  %6273 = add nuw nsw i32 %6271, %6272"
"  %6273 = add nuw nsw i32 %6271, %6272" -> "  %6275 = add nuw i32 %6273, %6274"
"  %6274 = and i32 %6270, -65536"
"  %6274 = and i32 %6270, -65536" -> "  %6275 = add nuw i32 %6273, %6274"
"  %6275 = add nuw i32 %6273, %6274"
"  %6275 = add nuw i32 %6273, %6274" -> "  %6294 = and i32 %6275, 65535""  %6275 = add nuw i32 %6273, %6274" -> "  %6298 = lshr i32 %6275, 16"
"  %6276 = mul nuw nsw i32 %5956, 17857"
"  %6276 = mul nuw nsw i32 %5956, 17857" -> "  %6295 = and i32 %6276, 65535""  %6276 = mul nuw nsw i32 %5956, 17857" -> "  %6277 = lshr i32 %6276, 16"
"  %6277 = lshr i32 %6276, 16"
"  %6277 = lshr i32 %6276, 16" -> "  %6280 = add nuw nsw i32 %6279, %6277"
"  %6278 = mul nuw nsw i32 %5957, 17857"
"  %6278 = mul nuw nsw i32 %5957, 17857" -> "  %6281 = and i32 %6278, 2147418112""  %6278 = mul nuw nsw i32 %5957, 17857" -> "  %6279 = and i32 %6278, 65535"
"  %6279 = and i32 %6278, 65535"
"  %6279 = and i32 %6278, 65535" -> "  %6280 = add nuw nsw i32 %6279, %6277"
"  %6280 = add nuw nsw i32 %6279, %6277"
"  %6280 = add nuw nsw i32 %6279, %6277" -> "  %6282 = add nuw nsw i32 %6280, %6281"
"  %6281 = and i32 %6278, 2147418112"
"  %6281 = and i32 %6278, 2147418112" -> "  %6282 = add nuw nsw i32 %6280, %6281"
"  %6282 = add nuw nsw i32 %6280, %6281"
"  %6282 = add nuw nsw i32 %6280, %6281" -> "  %6286 = lshr i32 %6282, 16""  %6282 = add nuw nsw i32 %6280, %6281" -> "  %6284 = and i32 %6282, 65535"
"  %6283 = mul nuw i32 %5956, 46547"
"  %6283 = mul nuw i32 %5956, 46547" -> "  %6285 = add nuw i32 %6284, %6283"
"  %6284 = and i32 %6282, 65535"
"  %6284 = and i32 %6282, 65535" -> "  %6285 = add nuw i32 %6284, %6283"
"  %6285 = add nuw i32 %6284, %6283"
"  %6285 = add nuw i32 %6284, %6283" -> "  %6297 = and i32 %6285, 65535""  %6285 = add nuw i32 %6284, %6283" -> "  %6289 = lshr i32 %6285, 16"
"  %6286 = lshr i32 %6282, 16"
"  %6286 = lshr i32 %6282, 16" -> "  %6288 = add nuw i32 %6286, %6287"
"  %6287 = mul nuw i32 %5957, 46547"
"  %6287 = mul nuw i32 %5957, 46547" -> "  %6288 = add nuw i32 %6286, %6287"
"  %6288 = add nuw i32 %6286, %6287"
"  %6288 = add nuw i32 %6286, %6287" -> "  %6292 = and i32 %6288, -65536""  %6288 = add nuw i32 %6286, %6287" -> "  %6290 = and i32 %6288, 65535"
"  %6289 = lshr i32 %6285, 16"
"  %6289 = lshr i32 %6285, 16" -> "  %6291 = add nuw nsw i32 %6289, %6290"
"  %6290 = and i32 %6288, 65535"
"  %6290 = and i32 %6288, 65535" -> "  %6291 = add nuw nsw i32 %6289, %6290"
"  %6291 = add nuw nsw i32 %6289, %6290"
"  %6291 = add nuw nsw i32 %6289, %6290" -> "  %6293 = add nuw i32 %6291, %6292"
"  %6292 = and i32 %6288, -65536"
"  %6292 = and i32 %6288, -65536" -> "  %6293 = add nuw i32 %6291, %6292"
"  %6293 = add nuw i32 %6291, %6292"
"  %6293 = add nuw i32 %6291, %6292" -> "  %6301 = add nuw i32 %6293, %6300"
"  %6294 = and i32 %6275, 65535"
"  %6294 = and i32 %6275, 65535" -> "  %6296 = add nuw nsw i32 %6294, %6295"
"  %6295 = and i32 %6276, 65535"
"  %6295 = and i32 %6276, 65535" -> "  %6296 = add nuw nsw i32 %6294, %6295"
"  %6296 = add nuw nsw i32 %6294, %6295"
"  %6296 = add nuw nsw i32 %6294, %6295" -> "  %6325 = and i32 %6296, 65535""  %6296 = add nuw nsw i32 %6294, %6295" -> "  %6303 = lshr i32 %6296, 16"
"  %6297 = and i32 %6285, 65535"
"  %6297 = and i32 %6285, 65535" -> "  %6299 = add nuw nsw i32 %6298, %6297"
"  %6298 = lshr i32 %6275, 16"
"  %6298 = lshr i32 %6275, 16" -> "  %6299 = add nuw nsw i32 %6298, %6297"
"  %6299 = add nuw nsw i32 %6298, %6297"
"  %6299 = add nuw nsw i32 %6298, %6297" -> "  %6302 = and i32 %6299, 65535""  %6299 = add nuw nsw i32 %6298, %6297" -> "  %6300 = lshr i32 %6299, 16"
"  %6300 = lshr i32 %6299, 16"
"  %6300 = lshr i32 %6299, 16" -> "  %6301 = add nuw i32 %6293, %6300"
"  %6301 = add nuw i32 %6293, %6300"
"  %6301 = add nuw i32 %6293, %6300" -> "  %6306 = add nuw i32 %6301, %6305"
"  %6302 = and i32 %6299, 65535"
"  %6302 = and i32 %6299, 65535" -> "  %6304 = add nuw nsw i32 %6302, %6303"
"  %6303 = lshr i32 %6296, 16"
"  %6303 = lshr i32 %6296, 16" -> "  %6304 = add nuw nsw i32 %6302, %6303"
"  %6304 = add nuw nsw i32 %6302, %6303"
"  %6304 = add nuw nsw i32 %6302, %6303" -> "  %6328 = and i32 %6304, 65535""  %6304 = add nuw nsw i32 %6302, %6303" -> "  %6305 = lshr i32 %6304, 16"
"  %6305 = lshr i32 %6304, 16"
"  %6305 = lshr i32 %6304, 16" -> "  %6306 = add nuw i32 %6301, %6305"
"  %6306 = add nuw i32 %6301, %6305"
"  %6306 = add nuw i32 %6301, %6305" -> "  %6357 = lshr i32 %6306, 16""  %6306 = add nuw i32 %6301, %6305" -> "  %6353 = and i32 %6306, 65535"
"  %6307 = mul nuw nsw i32 %5936, 31112"
"  %6307 = mul nuw nsw i32 %5936, 31112" -> "  %6326 = and i32 %6307, 65528""  %6307 = mul nuw nsw i32 %5936, 31112" -> "  %6308 = lshr i32 %6307, 16"
"  %6308 = lshr i32 %6307, 16"
"  %6308 = lshr i32 %6307, 16" -> "  %6311 = add nuw nsw i32 %6310, %6308"
"  %6309 = mul nuw nsw i32 %5939, 31112"
"  %6309 = mul nuw nsw i32 %5939, 31112" -> "  %6312 = and i32 %6309, 2147418112""  %6309 = mul nuw nsw i32 %5939, 31112" -> "  %6310 = and i32 %6309, 65528"
"  %6310 = and i32 %6309, 65528"
"  %6310 = and i32 %6309, 65528" -> "  %6311 = add nuw nsw i32 %6310, %6308"
"  %6311 = add nuw nsw i32 %6310, %6308"
"  %6311 = add nuw nsw i32 %6310, %6308" -> "  %6313 = add nuw nsw i32 %6311, %6312"
"  %6312 = and i32 %6309, 2147418112"
"  %6312 = and i32 %6309, 2147418112" -> "  %6313 = add nuw nsw i32 %6311, %6312"
"  %6313 = add nuw nsw i32 %6311, %6312"
"  %6313 = add nuw nsw i32 %6311, %6312" -> "  %6317 = lshr i32 %6313, 16""  %6313 = add nuw nsw i32 %6311, %6312" -> "  %6315 = and i32 %6313, 65535"
"  %6314 = mul nuw i32 %5936, 42170"
"  %6314 = mul nuw i32 %5936, 42170" -> "  %6316 = add nuw i32 %6315, %6314"
"  %6315 = and i32 %6313, 65535"
"  %6315 = and i32 %6313, 65535" -> "  %6316 = add nuw i32 %6315, %6314"
"  %6316 = add nuw i32 %6315, %6314"
"  %6316 = add nuw i32 %6315, %6314" -> "  %6329 = and i32 %6316, 65535""  %6316 = add nuw i32 %6315, %6314" -> "  %6320 = lshr i32 %6316, 16"
"  %6317 = lshr i32 %6313, 16"
"  %6317 = lshr i32 %6313, 16" -> "  %6319 = add nuw i32 %6317, %6318"
"  %6318 = mul nuw i32 %5939, 42170"
"  %6318 = mul nuw i32 %5939, 42170" -> "  %6319 = add nuw i32 %6317, %6318"
"  %6319 = add nuw i32 %6317, %6318"
"  %6319 = add nuw i32 %6317, %6318" -> "  %6323 = and i32 %6319, -65536""  %6319 = add nuw i32 %6317, %6318" -> "  %6321 = and i32 %6319, 65535"
"  %6320 = lshr i32 %6316, 16"
"  %6320 = lshr i32 %6316, 16" -> "  %6322 = add nuw nsw i32 %6320, %6321"
"  %6321 = and i32 %6319, 65535"
"  %6321 = and i32 %6319, 65535" -> "  %6322 = add nuw nsw i32 %6320, %6321"
"  %6322 = add nuw nsw i32 %6320, %6321"
"  %6322 = add nuw nsw i32 %6320, %6321" -> "  %6324 = add nuw i32 %6322, %6323"
"  %6323 = and i32 %6319, -65536"
"  %6323 = and i32 %6319, -65536" -> "  %6324 = add nuw i32 %6322, %6323"
"  %6324 = add nuw i32 %6322, %6323"
"  %6324 = add nuw i32 %6322, %6323" -> "  %6332 = add nuw i32 %6324, %6331"
"  %6325 = and i32 %6296, 65535"
"  %6325 = and i32 %6296, 65535" -> "  %6327 = add nuw nsw i32 %6325, %6326"
"  %6326 = and i32 %6307, 65528"
"  %6326 = and i32 %6307, 65528" -> "  %6327 = add nuw nsw i32 %6325, %6326"
"  %6327 = add nuw nsw i32 %6325, %6326"
"  %6327 = add nuw nsw i32 %6325, %6326" -> "  %6386 = and i32 %6327, 65535""  %6327 = add nuw nsw i32 %6325, %6326" -> "  %6334 = lshr i32 %6327, 16"
"  %6328 = and i32 %6304, 65535"
"  %6328 = and i32 %6304, 65535" -> "  %6330 = add nuw nsw i32 %6328, %6329"
"  %6329 = and i32 %6316, 65535"
"  %6329 = and i32 %6316, 65535" -> "  %6330 = add nuw nsw i32 %6328, %6329"
"  %6330 = add nuw nsw i32 %6328, %6329"
"  %6330 = add nuw nsw i32 %6328, %6329" -> "  %6333 = and i32 %6330, 65535""  %6330 = add nuw nsw i32 %6328, %6329" -> "  %6331 = lshr i32 %6330, 16"
"  %6331 = lshr i32 %6330, 16"
"  %6331 = lshr i32 %6330, 16" -> "  %6332 = add nuw i32 %6324, %6331"
"  %6332 = add nuw i32 %6324, %6331"
"  %6332 = add nuw i32 %6324, %6331" -> "  %6337 = add nuw i32 %6332, %6336"
"  %6333 = and i32 %6330, 65535"
"  %6333 = and i32 %6330, 65535" -> "  %6335 = add nuw nsw i32 %6333, %6334"
"  %6334 = lshr i32 %6327, 16"
"  %6334 = lshr i32 %6327, 16" -> "  %6335 = add nuw nsw i32 %6333, %6334"
"  %6335 = add nuw nsw i32 %6333, %6334"
"  %6335 = add nuw nsw i32 %6333, %6334" -> "  %6389 = and i32 %6335, 65535""  %6335 = add nuw nsw i32 %6333, %6334" -> "  %6336 = lshr i32 %6335, 16"
"  %6336 = lshr i32 %6335, 16"
"  %6336 = lshr i32 %6335, 16" -> "  %6337 = add nuw i32 %6332, %6336"
"  %6337 = add nuw i32 %6332, %6336"
"  %6337 = add nuw i32 %6332, %6336" -> "  %6370 = lshr i32 %6337, 16""  %6337 = add nuw i32 %6332, %6336" -> "  %6367 = and i32 %6337, 65535"
"  %6338 = mul nuw nsw i32 %5956, 31112"
"  %6338 = mul nuw nsw i32 %5956, 31112" -> "  %6354 = and i32 %6338, 65528""  %6338 = mul nuw nsw i32 %5956, 31112" -> "  %6339 = lshr i32 %6338, 16"
"  %6339 = lshr i32 %6338, 16"
"  %6339 = lshr i32 %6338, 16" -> "  %6341 = add nuw nsw i32 %6339, %6340"
"  %6340 = mul nuw nsw i32 %5957, 31112"
"  %6340 = mul nuw nsw i32 %5957, 31112" -> "  %6341 = add nuw nsw i32 %6339, %6340"
"  %6341 = add nuw nsw i32 %6339, %6340"
"  %6341 = add nuw nsw i32 %6339, %6340" -> "  %6345 = lshr i32 %6341, 16""  %6341 = add nuw nsw i32 %6339, %6340" -> "  %6343 = and i32 %6341, 65535"
"  %6342 = mul nuw i32 %5956, 42170"
"  %6342 = mul nuw i32 %5956, 42170" -> "  %6344 = add nuw i32 %6343, %6342"
"  %6343 = and i32 %6341, 65535"
"  %6343 = and i32 %6341, 65535" -> "  %6344 = add nuw i32 %6343, %6342"
"  %6344 = add nuw i32 %6343, %6342"
"  %6344 = add nuw i32 %6343, %6342" -> "  %6356 = and i32 %6344, 65535""  %6344 = add nuw i32 %6343, %6342" -> "  %6348 = lshr i32 %6344, 16"
"  %6345 = lshr i32 %6341, 16"
"  %6345 = lshr i32 %6341, 16" -> "  %6347 = add nuw i32 %6345, %6346"
"  %6346 = mul nuw i32 %5957, 42170"
"  %6346 = mul nuw i32 %5957, 42170" -> "  %6347 = add nuw i32 %6345, %6346"
"  %6347 = add nuw i32 %6345, %6346"
"  %6347 = add nuw i32 %6345, %6346" -> "  %6351 = and i32 %6347, -65536""  %6347 = add nuw i32 %6345, %6346" -> "  %6349 = and i32 %6347, 65535"
"  %6348 = lshr i32 %6344, 16"
"  %6348 = lshr i32 %6344, 16" -> "  %6350 = add nuw nsw i32 %6348, %6349"
"  %6349 = and i32 %6347, 65535"
"  %6349 = and i32 %6347, 65535" -> "  %6350 = add nuw nsw i32 %6348, %6349"
"  %6350 = add nuw nsw i32 %6348, %6349"
"  %6350 = add nuw nsw i32 %6348, %6349" -> "  %6352 = add nuw i32 %6350, %6351"
"  %6351 = and i32 %6347, -65536"
"  %6351 = and i32 %6347, -65536" -> "  %6352 = add nuw i32 %6350, %6351"
"  %6352 = add nuw i32 %6350, %6351"
"  %6352 = add nuw i32 %6350, %6351" -> "  %6360 = add nuw i32 %6352, %6359"
"  %6353 = and i32 %6306, 65535"
"  %6353 = and i32 %6306, 65535" -> "  %6355 = add nuw nsw i32 %6353, %6354"
"  %6354 = and i32 %6338, 65528"
"  %6354 = and i32 %6338, 65528" -> "  %6355 = add nuw nsw i32 %6353, %6354"
"  %6355 = add nuw nsw i32 %6353, %6354"
"  %6355 = add nuw nsw i32 %6353, %6354" -> "  %6366 = and i32 %6355, 65535""  %6355 = add nuw nsw i32 %6353, %6354" -> "  %6362 = lshr i32 %6355, 16"
"  %6356 = and i32 %6344, 65535"
"  %6356 = and i32 %6344, 65535" -> "  %6358 = add nuw nsw i32 %6357, %6356"
"  %6357 = lshr i32 %6306, 16"
"  %6357 = lshr i32 %6306, 16" -> "  %6358 = add nuw nsw i32 %6357, %6356"
"  %6358 = add nuw nsw i32 %6357, %6356"
"  %6358 = add nuw nsw i32 %6357, %6356" -> "  %6361 = and i32 %6358, 65535""  %6358 = add nuw nsw i32 %6357, %6356" -> "  %6359 = lshr i32 %6358, 16"
"  %6359 = lshr i32 %6358, 16"
"  %6359 = lshr i32 %6358, 16" -> "  %6360 = add nuw i32 %6352, %6359"
"  %6360 = add nuw i32 %6352, %6359"
"  %6360 = add nuw i32 %6352, %6359" -> "  %6365 = add nuw i32 %6360, %6364"
"  %6361 = and i32 %6358, 65535"
"  %6361 = and i32 %6358, 65535" -> "  %6363 = add nuw nsw i32 %6361, %6362"
"  %6362 = lshr i32 %6355, 16"
"  %6362 = lshr i32 %6355, 16" -> "  %6363 = add nuw nsw i32 %6361, %6362"
"  %6363 = add nuw nsw i32 %6361, %6362"
"  %6363 = add nuw nsw i32 %6361, %6362" -> "  %6369 = and i32 %6363, 65535""  %6363 = add nuw nsw i32 %6361, %6362" -> "  %6364 = lshr i32 %6363, 16"
"  %6364 = lshr i32 %6363, 16"
"  %6364 = lshr i32 %6363, 16" -> "  %6365 = add nuw i32 %6360, %6364"
"  %6365 = add nuw i32 %6360, %6364"
"  %6365 = add nuw i32 %6360, %6364" -> "  %6414 = add nuw i32 %6365, %6375"
"  %6366 = and i32 %6355, 65535"
"  %6366 = and i32 %6355, 65535" -> "  %6368 = add nuw nsw i32 %6367, %6366"
"  %6367 = and i32 %6337, 65535"
"  %6367 = and i32 %6337, 65535" -> "  %6368 = add nuw nsw i32 %6367, %6366"
"  %6368 = add nuw nsw i32 %6367, %6366"
"  %6368 = add nuw nsw i32 %6367, %6366" -> "  %6403 = and i32 %6368, 65535""  %6368 = add nuw nsw i32 %6367, %6366" -> "  %6372 = lshr i32 %6368, 16"
"  %6369 = and i32 %6363, 65535"
"  %6369 = and i32 %6363, 65535" -> "  %6371 = add nuw nsw i32 %6370, %6369"
"  %6370 = lshr i32 %6337, 16"
"  %6370 = lshr i32 %6337, 16" -> "  %6371 = add nuw nsw i32 %6370, %6369"
"  %6371 = add nuw nsw i32 %6370, %6369"
"  %6371 = add nuw nsw i32 %6370, %6369" -> "  %6375 = lshr i32 %6371, 16""  %6371 = add nuw nsw i32 %6370, %6369" -> "  %6373 = and i32 %6371, 65535"
"  %6372 = lshr i32 %6368, 16"
"  %6372 = lshr i32 %6368, 16" -> "  %6374 = add nuw nsw i32 %6373, %6372"
"  %6373 = and i32 %6371, 65535"
"  %6373 = and i32 %6371, 65535" -> "  %6374 = add nuw nsw i32 %6373, %6372"
"  %6374 = add nuw nsw i32 %6373, %6372"
"  %6374 = add nuw nsw i32 %6373, %6372" -> "  %6410 = and i32 %6374, 65535""  %6374 = add nuw nsw i32 %6373, %6372" -> "  %6376 = lshr i32 %6374, 16"
"  %6375 = lshr i32 %6371, 16"
"  %6375 = lshr i32 %6371, 16" -> "  %6414 = add nuw i32 %6365, %6375"
"  %6376 = lshr i32 %6374, 16"
"  %6376 = lshr i32 %6374, 16" -> "  %6415 = add nuw i32 %6414, %6376"
"  %6377 = and i32 %6258, 65535"
"  %6377 = and i32 %6258, 65535" -> "  %6379 = add nuw nsw i32 %6378, %6377"
"  %6378 = and i32 %6093, 65535"
"  %6378 = and i32 %6093, 65535" -> "  %6379 = add nuw nsw i32 %6378, %6377"
"  %6379 = add nuw nsw i32 %6378, %6377"
"  %6379 = add nuw nsw i32 %6378, %6377" -> "  %6417 = and i32 %6379, 65535""  %6379 = add nuw nsw i32 %6378, %6377" -> "  %6383 = lshr i32 %6379, 16"
"  %6380 = and i32 %6267, 65535"
"  %6380 = and i32 %6267, 65535" -> "  %6382 = add nuw nsw i32 %6381, %6380"
"  %6381 = and i32 %6096, 65535"
"  %6381 = and i32 %6096, 65535" -> "  %6382 = add nuw nsw i32 %6381, %6380"
"  %6382 = add nuw nsw i32 %6381, %6380"
"  %6382 = add nuw nsw i32 %6381, %6380" -> "  %6396 = lshr i32 %6382, 16""  %6382 = add nuw nsw i32 %6381, %6380" -> "  %6384 = and i32 %6382, 65535"
"  %6383 = lshr i32 %6379, 16"
"  %6383 = lshr i32 %6379, 16" -> "  %6385 = add nuw nsw i32 %6384, %6383"
"  %6384 = and i32 %6382, 65535"
"  %6384 = and i32 %6382, 65535" -> "  %6385 = add nuw nsw i32 %6384, %6383"
"  %6385 = add nuw nsw i32 %6384, %6383"
"  %6385 = add nuw nsw i32 %6384, %6383" -> "  %6420 = and i32 %6385, 65535""  %6385 = add nuw nsw i32 %6384, %6383" -> "  %6398 = lshr i32 %6385, 16"
"  %6386 = and i32 %6327, 65535"
"  %6386 = and i32 %6327, 65535" -> "  %6388 = add nuw nsw i32 %6387, %6386"
"  %6387 = and i32 %6098, 65535"
"  %6387 = and i32 %6098, 65535" -> "  %6388 = add nuw nsw i32 %6387, %6386"
"  %6388 = add nuw nsw i32 %6387, %6386"
"  %6388 = add nuw nsw i32 %6387, %6386" -> "  %6395 = and i32 %6388, 65535""  %6388 = add nuw nsw i32 %6387, %6386" -> "  %6392 = lshr i32 %6388, 16"
"  %6389 = and i32 %6335, 65535"
"  %6389 = and i32 %6335, 65535" -> "  %6391 = add nuw nsw i32 %6390, %6389"
"  %6390 = lshr i32 %6098, 16"
"  %6390 = lshr i32 %6098, 16" -> "  %6391 = add nuw nsw i32 %6390, %6389"
"  %6391 = add nuw nsw i32 %6390, %6389"
"  %6391 = add nuw nsw i32 %6390, %6389" -> "  %6404 = lshr i32 %6391, 16""  %6391 = add nuw nsw i32 %6390, %6389" -> "  %6393 = and i32 %6391, 65535"
"  %6392 = lshr i32 %6388, 16"
"  %6392 = lshr i32 %6388, 16" -> "  %6394 = add nuw nsw i32 %6393, %6392"
"  %6393 = and i32 %6391, 65535"
"  %6393 = and i32 %6391, 65535" -> "  %6394 = add nuw nsw i32 %6393, %6392"
"  %6394 = add nuw nsw i32 %6393, %6392"
"  %6394 = add nuw nsw i32 %6393, %6392" -> "  %6406 = lshr i32 %6394, 16""  %6394 = add nuw nsw i32 %6393, %6392" -> "  %6401 = and i32 %6394, 65535"
"  %6395 = and i32 %6388, 65535"
"  %6395 = and i32 %6388, 65535" -> "  %6397 = add nuw nsw i32 %6395, %6396"
"  %6396 = lshr i32 %6382, 16"
"  %6396 = lshr i32 %6382, 16" -> "  %6397 = add nuw nsw i32 %6395, %6396"
"  %6397 = add nuw nsw i32 %6395, %6396"
"  %6397 = add nuw nsw i32 %6395, %6396" -> "  %6399 = add nuw nsw i32 %6397, %6398"
"  %6398 = lshr i32 %6385, 16"
"  %6398 = lshr i32 %6385, 16" -> "  %6399 = add nuw nsw i32 %6397, %6398"
"  %6399 = add nuw nsw i32 %6397, %6398"
"  %6399 = add nuw nsw i32 %6397, %6398" -> "  %6426 = and i32 %6399, 65535""  %6399 = add nuw nsw i32 %6397, %6398" -> "  %6400 = lshr i32 %6399, 16"
"  %6400 = lshr i32 %6399, 16"
"  %6400 = lshr i32 %6399, 16" -> "  %6402 = add nuw nsw i32 %6400, %6401"
"  %6401 = and i32 %6394, 65535"
"  %6401 = and i32 %6394, 65535" -> "  %6402 = add nuw nsw i32 %6400, %6401"
"  %6402 = add nuw nsw i32 %6400, %6401"
"  %6402 = add nuw nsw i32 %6400, %6401" -> "  %6429 = and i32 %6402, 65535""  %6402 = add nuw nsw i32 %6400, %6401" -> "  %6408 = lshr i32 %6402, 16"
"  %6403 = and i32 %6368, 65535"
"  %6403 = and i32 %6368, 65535" -> "  %6405 = add nuw nsw i32 %6404, %6403"
"  %6404 = lshr i32 %6391, 16"
"  %6404 = lshr i32 %6391, 16" -> "  %6405 = add nuw nsw i32 %6404, %6403"
"  %6405 = add nuw nsw i32 %6404, %6403"
"  %6405 = add nuw nsw i32 %6404, %6403" -> "  %6407 = add nuw nsw i32 %6405, %6406"
"  %6406 = lshr i32 %6394, 16"
"  %6406 = lshr i32 %6394, 16" -> "  %6407 = add nuw nsw i32 %6405, %6406"
"  %6407 = add nuw nsw i32 %6405, %6406"
"  %6407 = add nuw nsw i32 %6405, %6406" -> "  %6409 = add nuw nsw i32 %6407, %6408"
"  %6408 = lshr i32 %6402, 16"
"  %6408 = lshr i32 %6402, 16" -> "  %6409 = add nuw nsw i32 %6407, %6408"
"  %6409 = add nuw nsw i32 %6407, %6408"
"  %6409 = add nuw nsw i32 %6407, %6408" -> "  %6444 = and i32 %6409, 65535""  %6409 = add nuw nsw i32 %6407, %6408" -> "  %6411 = lshr i32 %6409, 16"
"  %6410 = and i32 %6374, 65535"
"  %6410 = and i32 %6374, 65535" -> "  %6412 = add nuw nsw i32 %6411, %6410"
"  %6411 = lshr i32 %6409, 16"
"  %6411 = lshr i32 %6409, 16" -> "  %6412 = add nuw nsw i32 %6411, %6410"
"  %6412 = add nuw nsw i32 %6411, %6410"
"  %6412 = add nuw nsw i32 %6411, %6410" -> "  %6451 = and i32 %6412, 65535""  %6412 = add nuw nsw i32 %6411, %6410" -> "  %6413 = lshr i32 %6412, 16"
"  %6413 = lshr i32 %6412, 16"
"  %6413 = lshr i32 %6412, 16" -> "  %6416 = add nuw i32 %6415, %6413"
"  %6414 = add nuw i32 %6365, %6375"
"  %6414 = add nuw i32 %6365, %6375" -> "  %6415 = add nuw i32 %6414, %6376"
"  %6415 = add nuw i32 %6414, %6376"
"  %6415 = add nuw i32 %6414, %6376" -> "  %6416 = add nuw i32 %6415, %6413"
"  %6416 = add nuw i32 %6415, %6413"
"  %6416 = add nuw i32 %6415, %6413" -> "  %6454 = add nuw i32 %6416, %6453"
"  %6417 = and i32 %6379, 65535"
"  %6417 = and i32 %6379, 65535" -> "  %6419 = add nuw nsw i32 %6418, %6417"
"  %6418 = and i32 %6250, 65535"
"  %6418 = and i32 %6250, 65535" -> "  %6419 = add nuw nsw i32 %6418, %6417"
"  %6419 = add nuw nsw i32 %6418, %6417"
"  %6419 = add nuw nsw i32 %6418, %6417" -> "  %6528 = and i32 %6419, 65535""  %6419 = add nuw nsw i32 %6418, %6417" -> "  %6423 = lshr i32 %6419, 16"
"  %6420 = and i32 %6385, 65535"
"  %6420 = and i32 %6385, 65535" -> "  %6422 = add nuw nsw i32 %6421, %6420"
"  %6421 = and i32 %6253, 65535"
"  %6421 = and i32 %6253, 65535" -> "  %6422 = add nuw nsw i32 %6421, %6420"
"  %6422 = add nuw nsw i32 %6421, %6420"
"  %6422 = add nuw nsw i32 %6421, %6420" -> "  %6436 = lshr i32 %6422, 16""  %6422 = add nuw nsw i32 %6421, %6420" -> "  %6424 = and i32 %6422, 65535"
"  %6423 = lshr i32 %6419, 16"
"  %6423 = lshr i32 %6419, 16" -> "  %6425 = add nuw nsw i32 %6424, %6423"
"  %6424 = and i32 %6422, 65535"
"  %6424 = and i32 %6422, 65535" -> "  %6425 = add nuw nsw i32 %6424, %6423"
"  %6425 = add nuw nsw i32 %6424, %6423"
"  %6425 = add nuw nsw i32 %6424, %6423" -> "  %6532 = and i32 %6425, 65535""  %6425 = add nuw nsw i32 %6424, %6423" -> "  %6438 = lshr i32 %6425, 16"
"  %6426 = and i32 %6399, 65535"
"  %6426 = and i32 %6399, 65535" -> "  %6428 = add nuw nsw i32 %6427, %6426"
"  %6427 = and i32 %6257, 65535"
"  %6427 = and i32 %6257, 65535" -> "  %6428 = add nuw nsw i32 %6427, %6426"
"  %6428 = add nuw nsw i32 %6427, %6426"
"  %6428 = add nuw nsw i32 %6427, %6426" -> "  %6435 = and i32 %6428, 65535""  %6428 = add nuw nsw i32 %6427, %6426" -> "  %6432 = lshr i32 %6428, 16"
"  %6429 = and i32 %6402, 65535"
"  %6429 = and i32 %6402, 65535" -> "  %6431 = add nuw nsw i32 %6429, %6430"
"  %6430 = lshr i32 %6257, 16"
"  %6430 = lshr i32 %6257, 16" -> "  %6431 = add nuw nsw i32 %6429, %6430"
"  %6431 = add nuw nsw i32 %6429, %6430"
"  %6431 = add nuw nsw i32 %6429, %6430" -> "  %6443 = lshr i32 %6431, 16""  %6431 = add nuw nsw i32 %6429, %6430" -> "  %6433 = and i32 %6431, 65535"
"  %6432 = lshr i32 %6428, 16"
"  %6432 = lshr i32 %6428, 16" -> "  %6434 = add nuw nsw i32 %6433, %6432"
"  %6433 = and i32 %6431, 65535"
"  %6433 = and i32 %6431, 65535" -> "  %6434 = add nuw nsw i32 %6433, %6432"
"  %6434 = add nuw nsw i32 %6433, %6432"
"  %6434 = add nuw nsw i32 %6433, %6432" -> "  %6441 = and i32 %6434, 65535""  %6434 = add nuw nsw i32 %6433, %6432" -> "  %6446 = lshr i32 %6434, 16"
"  %6435 = and i32 %6428, 65535"
"  %6435 = and i32 %6428, 65535" -> "  %6437 = add nuw nsw i32 %6435, %6436"
"  %6436 = lshr i32 %6422, 16"
"  %6436 = lshr i32 %6422, 16" -> "  %6437 = add nuw nsw i32 %6435, %6436"
"  %6437 = add nuw nsw i32 %6435, %6436"
"  %6437 = add nuw nsw i32 %6435, %6436" -> "  %6439 = add nuw nsw i32 %6437, %6438"
"  %6438 = lshr i32 %6425, 16"
"  %6438 = lshr i32 %6425, 16" -> "  %6439 = add nuw nsw i32 %6437, %6438"
"  %6439 = add nuw nsw i32 %6437, %6438"
"  %6439 = add nuw nsw i32 %6437, %6438" -> "  %6533 = and i32 %6439, 65535""  %6439 = add nuw nsw i32 %6437, %6438" -> "  %6440 = lshr i32 %6439, 16"
"  %6440 = lshr i32 %6439, 16"
"  %6440 = lshr i32 %6439, 16" -> "  %6442 = add nuw nsw i32 %6441, %6440"
"  %6441 = and i32 %6434, 65535"
"  %6441 = and i32 %6434, 65535" -> "  %6442 = add nuw nsw i32 %6441, %6440"
"  %6442 = add nuw nsw i32 %6441, %6440"
"  %6442 = add nuw nsw i32 %6441, %6440" -> "  %6538 = and i32 %6442, 65535""  %6442 = add nuw nsw i32 %6441, %6440" -> "  %6447 = lshr i32 %6442, 16"
"  %6443 = lshr i32 %6431, 16"
"  %6443 = lshr i32 %6431, 16" -> "  %6445 = add nuw nsw i32 %6443, %6444"
"  %6444 = and i32 %6409, 65535"
"  %6444 = and i32 %6409, 65535" -> "  %6445 = add nuw nsw i32 %6443, %6444"
"  %6445 = add nuw nsw i32 %6443, %6444"
"  %6445 = add nuw nsw i32 %6443, %6444" -> "  %6448 = add nuw nsw i32 %6445, %6446"
"  %6446 = lshr i32 %6434, 16"
"  %6446 = lshr i32 %6434, 16" -> "  %6448 = add nuw nsw i32 %6445, %6446"
"  %6447 = lshr i32 %6442, 16"
"  %6447 = lshr i32 %6442, 16" -> "  %6449 = add nuw nsw i32 %6448, %6447"
"  %6448 = add nuw nsw i32 %6445, %6446"
"  %6448 = add nuw nsw i32 %6445, %6446" -> "  %6449 = add nuw nsw i32 %6448, %6447"
"  %6449 = add nuw nsw i32 %6448, %6447"
"  %6449 = add nuw nsw i32 %6448, %6447" -> "  %6541 = and i32 %6449, 65535""  %6449 = add nuw nsw i32 %6448, %6447" -> "  %6450 = lshr i32 %6449, 16"
"  %6450 = lshr i32 %6449, 16"
"  %6450 = lshr i32 %6449, 16" -> "  %6452 = add nuw nsw i32 %6450, %6451"
"  %6451 = and i32 %6412, 65535"
"  %6451 = and i32 %6412, 65535" -> "  %6452 = add nuw nsw i32 %6450, %6451"
"  %6452 = add nuw nsw i32 %6450, %6451"
"  %6452 = add nuw nsw i32 %6450, %6451" -> "  %6544 = and i32 %6452, 65535""  %6452 = add nuw nsw i32 %6450, %6451" -> "  %6453 = lshr i32 %6452, 16"
"  %6453 = lshr i32 %6452, 16"
"  %6453 = lshr i32 %6452, 16" -> "  %6454 = add nuw i32 %6416, %6453"
"  %6454 = add nuw i32 %6416, %6453"
"  %6454 = add nuw i32 %6416, %6453" -> "  %6548 = add nuw i32 %6454, %6547"
"  %6455 = and i32 %5766, 65535"
"  %6455 = and i32 %5766, 65535" -> "  %6457 = add nuw nsw i32 %6455, %6456"
"  %6456 = and i32 %5804, 65532"
"  %6456 = and i32 %5804, 65532" -> "  %6457 = add nuw nsw i32 %6455, %6456"
"  %6457 = add nuw nsw i32 %6455, %6456"
"  %6457 = add nuw nsw i32 %6455, %6456" -> "  %7212 = and i32 %6457, 65535""  %6457 = add nuw nsw i32 %6455, %6456" -> "  %6461 = lshr i32 %6457, 16"
"  %6458 = and i32 %5772, 65535"
"  %6458 = and i32 %5772, 65535" -> "  %6460 = add nuw nsw i32 %6458, %6459"
"  %6459 = and i32 %5813, 65535"
"  %6459 = and i32 %5813, 65535" -> "  %6460 = add nuw nsw i32 %6458, %6459"
"  %6460 = add nuw nsw i32 %6458, %6459"
"  %6460 = add nuw nsw i32 %6458, %6459" -> "  %6464 = lshr i32 %6460, 16""  %6460 = add nuw nsw i32 %6458, %6459" -> "  %6462 = and i32 %6460, 65535"
"  %6461 = lshr i32 %6457, 16"
"  %6461 = lshr i32 %6457, 16" -> "  %6463 = add nuw nsw i32 %6462, %6461"
"  %6462 = and i32 %6460, 65535"
"  %6462 = and i32 %6460, 65535" -> "  %6463 = add nuw nsw i32 %6462, %6461"
"  %6463 = add nuw nsw i32 %6462, %6461"
"  %6463 = add nuw nsw i32 %6462, %6461" -> "  %7215 = and i32 %6463, 65535""  %6463 = add nuw nsw i32 %6462, %6461" -> "  %6465 = lshr i32 %6463, 16"
"  %6464 = lshr i32 %6460, 16"
"  %6464 = lshr i32 %6460, 16" -> "  %6466 = add nuw nsw i32 %6465, %6464"
"  %6465 = lshr i32 %6463, 16"
"  %6465 = lshr i32 %6463, 16" -> "  %6466 = add nuw nsw i32 %6465, %6464"
"  %6466 = add nuw nsw i32 %6465, %6464"
"  %6466 = add nuw nsw i32 %6465, %6464" -> "  %6477 = add nuw nsw i32 %6466, %6476"
"  %6467 = and i32 %5786, 65535"
"  %6467 = and i32 %5786, 65535" -> "  %6469 = add nuw nsw i32 %6467, %6468"
"  %6468 = and i32 %5878, 65535"
"  %6468 = and i32 %5878, 65535" -> "  %6469 = add nuw nsw i32 %6467, %6468"
"  %6469 = add nuw nsw i32 %6467, %6468"
"  %6469 = add nuw nsw i32 %6467, %6468" -> "  %6476 = and i32 %6469, 65535""  %6469 = add nuw nsw i32 %6467, %6468" -> "  %6473 = lshr i32 %6469, 16"
"  %6470 = and i32 %5789, 65535"
"  %6470 = and i32 %5789, 65535" -> "  %6472 = add nuw nsw i32 %6470, %6471"
"  %6471 = and i32 %5886, 65535"
"  %6471 = and i32 %5886, 65535" -> "  %6472 = add nuw nsw i32 %6470, %6471"
"  %6472 = add nuw nsw i32 %6470, %6471"
"  %6472 = add nuw nsw i32 %6470, %6471" -> "  %6512 = lshr i32 %6472, 16""  %6472 = add nuw nsw i32 %6470, %6471" -> "  %6474 = and i32 %6472, 65535"
"  %6473 = lshr i32 %6469, 16"
"  %6473 = lshr i32 %6469, 16" -> "  %6475 = add nuw nsw i32 %6474, %6473"
"  %6474 = and i32 %6472, 65535"
"  %6474 = and i32 %6472, 65535" -> "  %6475 = add nuw nsw i32 %6474, %6473"
"  %6475 = add nuw nsw i32 %6474, %6473"
"  %6475 = add nuw nsw i32 %6474, %6473" -> "  %6513 = lshr i32 %6475, 16""  %6475 = add nuw nsw i32 %6474, %6473" -> "  %6479 = and i32 %6475, 65535"
"  %6476 = and i32 %6469, 65535"
"  %6476 = and i32 %6469, 65535" -> "  %6477 = add nuw nsw i32 %6466, %6476"
"  %6477 = add nuw nsw i32 %6466, %6476"
"  %6477 = add nuw nsw i32 %6466, %6476" -> "  %7224 = and i32 %6477, 65535""  %6477 = add nuw nsw i32 %6466, %6476" -> "  %6478 = lshr i32 %6477, 16"
"  %6478 = lshr i32 %6477, 16"
"  %6478 = lshr i32 %6477, 16" -> "  %6480 = add nuw nsw i32 %6479, %6478"
"  %6479 = and i32 %6475, 65535"
"  %6479 = and i32 %6475, 65535" -> "  %6480 = add nuw nsw i32 %6479, %6478"
"  %6480 = add nuw nsw i32 %6479, %6478"
"  %6480 = add nuw nsw i32 %6479, %6478" -> "  %7227 = and i32 %6480, 65535""  %6480 = add nuw nsw i32 %6479, %6478" -> "  %6514 = lshr i32 %6480, 16"
"  %6481 = and i32 %5796, 65535"
"  %6481 = and i32 %5796, 65535" -> "  %6483 = add nuw nsw i32 %6481, %6482"
"  %6482 = and i32 %6220, 65535"
"  %6482 = and i32 %6220, 65535" -> "  %6483 = add nuw nsw i32 %6481, %6482"
"  %6483 = add nuw nsw i32 %6481, %6482"
"  %6483 = add nuw nsw i32 %6481, %6482" -> "  %6511 = and i32 %6483, 65535""  %6483 = add nuw nsw i32 %6481, %6482" -> "  %6487 = lshr i32 %6483, 16"
"  %6484 = and i32 %5799, 65535"
"  %6484 = and i32 %5799, 65535" -> "  %6486 = add nuw nsw i32 %6484, %6485"
"  %6485 = and i32 %6226, 65535"
"  %6485 = and i32 %6226, 65535" -> "  %6486 = add nuw nsw i32 %6484, %6485"
"  %6486 = add nuw nsw i32 %6484, %6485"
"  %6486 = add nuw nsw i32 %6484, %6485" -> "  %6503 = lshr i32 %6486, 16""  %6486 = add nuw nsw i32 %6484, %6485" -> "  %6488 = and i32 %6486, 65535"
"  %6487 = lshr i32 %6483, 16"
"  %6487 = lshr i32 %6483, 16" -> "  %6489 = add nuw nsw i32 %6488, %6487"
"  %6488 = and i32 %6486, 65535"
"  %6488 = and i32 %6486, 65535" -> "  %6489 = add nuw nsw i32 %6488, %6487"
"  %6489 = add nuw nsw i32 %6488, %6487"
"  %6489 = add nuw nsw i32 %6488, %6487" -> "  %6518 = and i32 %6489, 65535""  %6489 = add nuw nsw i32 %6488, %6487" -> "  %6505 = lshr i32 %6489, 16"
"  %6490 = and i32 %5801, 65535"
"  %6490 = and i32 %5801, 65535" -> "  %6492 = add nuw nsw i32 %6490, %6491"
"  %6491 = and i32 %6240, 65535"
"  %6491 = and i32 %6240, 65535" -> "  %6492 = add nuw nsw i32 %6490, %6491"
"  %6492 = add nuw nsw i32 %6490, %6491"
"  %6492 = add nuw nsw i32 %6490, %6491" -> "  %6502 = and i32 %6492, 65535""  %6492 = add nuw nsw i32 %6490, %6491" -> "  %6496 = lshr i32 %6492, 16"
"  %6493 = lshr i32 %5801, 16"
"  %6493 = lshr i32 %5801, 16" -> "  %6495 = add nuw nsw i32 %6494, %6493"
"  %6494 = and i32 %6243, 65535"
"  %6494 = and i32 %6243, 65535" -> "  %6495 = add nuw nsw i32 %6494, %6493"
"  %6495 = add nuw nsw i32 %6494, %6493"
"  %6495 = add nuw nsw i32 %6494, %6493" -> "  %6499 = lshr i32 %6495, 16""  %6495 = add nuw nsw i32 %6494, %6493" -> "  %6497 = and i32 %6495, 65535"
"  %6496 = lshr i32 %6492, 16"
"  %6496 = lshr i32 %6492, 16" -> "  %6498 = add nuw nsw i32 %6497, %6496"
"  %6497 = and i32 %6495, 65535"
"  %6497 = and i32 %6495, 65535" -> "  %6498 = add nuw nsw i32 %6497, %6496"
"  %6498 = add nuw nsw i32 %6497, %6496"
"  %6498 = add nuw nsw i32 %6497, %6496" -> "  %6507 = and i32 %6498, 65535""  %6498 = add nuw nsw i32 %6497, %6496" -> "  %6500 = lshr i32 %6498, 16"
"  %6499 = lshr i32 %6495, 16"
"  %6499 = lshr i32 %6495, 16" -> "  %6501 = add nuw nsw i32 %6500, %6499"
"  %6500 = lshr i32 %6498, 16"
"  %6500 = lshr i32 %6498, 16" -> "  %6501 = add nuw nsw i32 %6500, %6499"
"  %6501 = add nuw nsw i32 %6500, %6499"
"  %6501 = add nuw nsw i32 %6500, %6499" -> "  %6529 = add nuw nsw i32 %6501, %6528"
"  %6502 = and i32 %6492, 65535"
"  %6502 = and i32 %6492, 65535" -> "  %6504 = add nuw nsw i32 %6502, %6503"
"  %6503 = lshr i32 %6486, 16"
"  %6503 = lshr i32 %6486, 16" -> "  %6504 = add nuw nsw i32 %6502, %6503"
"  %6504 = add nuw nsw i32 %6502, %6503"
"  %6504 = add nuw nsw i32 %6502, %6503" -> "  %6506 = add nuw nsw i32 %6504, %6505"
"  %6505 = lshr i32 %6489, 16"
"  %6505 = lshr i32 %6489, 16" -> "  %6506 = add nuw nsw i32 %6504, %6505"
"  %6506 = add nuw nsw i32 %6504, %6505"
"  %6506 = add nuw nsw i32 %6504, %6505" -> "  %6521 = and i32 %6506, 65535""  %6506 = add nuw nsw i32 %6504, %6505" -> "  %6508 = lshr i32 %6506, 16"
"  %6507 = and i32 %6498, 65535"
"  %6507 = and i32 %6498, 65535" -> "  %6509 = add nuw nsw i32 %6507, %6508"
"  %6508 = lshr i32 %6506, 16"
"  %6508 = lshr i32 %6506, 16" -> "  %6509 = add nuw nsw i32 %6507, %6508"
"  %6509 = add nuw nsw i32 %6507, %6508"
"  %6509 = add nuw nsw i32 %6507, %6508" -> "  %6524 = and i32 %6509, 65535""  %6509 = add nuw nsw i32 %6507, %6508" -> "  %6510 = lshr i32 %6509, 16"
"  %6510 = lshr i32 %6509, 16"
"  %6510 = lshr i32 %6509, 16" -> "  %6530 = add nuw nsw i32 %6529, %6510"
"  %6511 = and i32 %6483, 65535"
"  %6511 = and i32 %6483, 65535" -> "  %6516 = add nuw nsw i32 %6515, %6511"
"  %6512 = lshr i32 %6472, 16"
"  %6512 = lshr i32 %6472, 16" -> "  %6515 = add nuw nsw i32 %6513, %6512"
"  %6513 = lshr i32 %6475, 16"
"  %6513 = lshr i32 %6475, 16" -> "  %6515 = add nuw nsw i32 %6513, %6512"
"  %6514 = lshr i32 %6480, 16"
"  %6514 = lshr i32 %6480, 16" -> "  %6517 = add nuw nsw i32 %6516, %6514"
"  %6515 = add nuw nsw i32 %6513, %6512"
"  %6515 = add nuw nsw i32 %6513, %6512" -> "  %6516 = add nuw nsw i32 %6515, %6511"
"  %6516 = add nuw nsw i32 %6515, %6511"
"  %6516 = add nuw nsw i32 %6515, %6511" -> "  %6517 = add nuw nsw i32 %6516, %6514"
"  %6517 = add nuw nsw i32 %6516, %6514"
"  %6517 = add nuw nsw i32 %6516, %6514" -> "  %7238 = and i32 %6517, 65535""  %6517 = add nuw nsw i32 %6516, %6514" -> "  %6519 = lshr i32 %6517, 16"
"  %6518 = and i32 %6489, 65535"
"  %6518 = and i32 %6489, 65535" -> "  %6520 = add nuw nsw i32 %6518, %6519"
"  %6519 = lshr i32 %6517, 16"
"  %6519 = lshr i32 %6517, 16" -> "  %6520 = add nuw nsw i32 %6518, %6519"
"  %6520 = add nuw nsw i32 %6518, %6519"
"  %6520 = add nuw nsw i32 %6518, %6519" -> "  %7241 = and i32 %6520, 65535""  %6520 = add nuw nsw i32 %6518, %6519" -> "  %6522 = lshr i32 %6520, 16"
"  %6521 = and i32 %6506, 65535"
"  %6521 = and i32 %6506, 65535" -> "  %6523 = add nuw nsw i32 %6521, %6522"
"  %6522 = lshr i32 %6520, 16"
"  %6522 = lshr i32 %6520, 16" -> "  %6523 = add nuw nsw i32 %6521, %6522"
"  %6523 = add nuw nsw i32 %6521, %6522"
"  %6523 = add nuw nsw i32 %6521, %6522" -> "  %7250 = and i32 %6523, 65535""  %6523 = add nuw nsw i32 %6521, %6522" -> "  %6525 = lshr i32 %6523, 16"
"  %6524 = and i32 %6509, 65535"
"  %6524 = and i32 %6509, 65535" -> "  %6526 = add nuw nsw i32 %6524, %6525"
"  %6525 = lshr i32 %6523, 16"
"  %6525 = lshr i32 %6523, 16" -> "  %6526 = add nuw nsw i32 %6524, %6525"
"  %6526 = add nuw nsw i32 %6524, %6525"
"  %6526 = add nuw nsw i32 %6524, %6525" -> "  %7253 = and i32 %6526, 65535""  %6526 = add nuw nsw i32 %6524, %6525" -> "  %6527 = lshr i32 %6526, 16"
"  %6527 = lshr i32 %6526, 16"
"  %6527 = lshr i32 %6526, 16" -> "  %6531 = add nuw nsw i32 %6530, %6527"
"  %6528 = and i32 %6419, 65535"
"  %6528 = and i32 %6419, 65535" -> "  %6529 = add nuw nsw i32 %6501, %6528"
"  %6529 = add nuw nsw i32 %6501, %6528"
"  %6529 = add nuw nsw i32 %6501, %6528" -> "  %6530 = add nuw nsw i32 %6529, %6510"
"  %6530 = add nuw nsw i32 %6529, %6510"
"  %6530 = add nuw nsw i32 %6529, %6510" -> "  %6531 = add nuw nsw i32 %6530, %6527"
"  %6531 = add nuw nsw i32 %6530, %6527"
"  %6531 = add nuw nsw i32 %6530, %6527" -> "  %7963 = and i32 %6531, 65535""  %6531 = add nuw nsw i32 %6530, %6527" -> "  %6534 = lshr i32 %6531, 16"
"  %6532 = and i32 %6425, 65535"
"  %6532 = and i32 %6425, 65535" -> "  %6535 = add nuw nsw i32 %6534, %6532"
"  %6533 = and i32 %6439, 65535"
"  %6533 = and i32 %6439, 65535" -> "  %6537 = add nuw nsw i32 %6536, %6533"
"  %6534 = lshr i32 %6531, 16"
"  %6534 = lshr i32 %6531, 16" -> "  %6535 = add nuw nsw i32 %6534, %6532"
"  %6535 = add nuw nsw i32 %6534, %6532"
"  %6535 = add nuw nsw i32 %6534, %6532" -> "  %7966 = and i32 %6535, 65535""  %6535 = add nuw nsw i32 %6534, %6532" -> "  %6536 = lshr i32 %6535, 16"
"  %6536 = lshr i32 %6535, 16"
"  %6536 = lshr i32 %6535, 16" -> "  %6537 = add nuw nsw i32 %6536, %6533"
"  %6537 = add nuw nsw i32 %6536, %6533"
"  %6537 = add nuw nsw i32 %6536, %6533" -> "  %7972 = and i32 %6537, 65535""  %6537 = add nuw nsw i32 %6536, %6533" -> "  %6539 = lshr i32 %6537, 16"
"  %6538 = and i32 %6442, 65535"
"  %6538 = and i32 %6442, 65535" -> "  %6540 = add nuw nsw i32 %6539, %6538"
"  %6539 = lshr i32 %6537, 16"
"  %6539 = lshr i32 %6537, 16" -> "  %6540 = add nuw nsw i32 %6539, %6538"
"  %6540 = add nuw nsw i32 %6539, %6538"
"  %6540 = add nuw nsw i32 %6539, %6538" -> "  %7975 = and i32 %6540, 65535""  %6540 = add nuw nsw i32 %6539, %6538" -> "  %6542 = lshr i32 %6540, 16"
"  %6541 = and i32 %6449, 65535"
"  %6541 = and i32 %6449, 65535" -> "  %6543 = add nuw nsw i32 %6542, %6541"
"  %6542 = lshr i32 %6540, 16"
"  %6542 = lshr i32 %6540, 16" -> "  %6543 = add nuw nsw i32 %6542, %6541"
"  %6543 = add nuw nsw i32 %6542, %6541"
"  %6543 = add nuw nsw i32 %6542, %6541" -> "  %7989 = and i32 %6543, 65535""  %6543 = add nuw nsw i32 %6542, %6541" -> "  %6545 = lshr i32 %6543, 16"
"  %6544 = and i32 %6452, 65535"
"  %6544 = and i32 %6452, 65535" -> "  %6546 = add nuw nsw i32 %6545, %6544"
"  %6545 = lshr i32 %6543, 16"
"  %6545 = lshr i32 %6543, 16" -> "  %6546 = add nuw nsw i32 %6545, %6544"
"  %6546 = add nuw nsw i32 %6545, %6544"
"  %6546 = add nuw nsw i32 %6545, %6544" -> "  %7992 = and i32 %6546, 65535""  %6546 = add nuw nsw i32 %6545, %6544" -> "  %6547 = lshr i32 %6546, 16"
"  %6547 = lshr i32 %6546, 16"
"  %6547 = lshr i32 %6546, 16" -> "  %6548 = add nuw i32 %6454, %6547"
"  %6548 = add nuw i32 %6454, %6547"
"  %6548 = add nuw i32 %6454, %6547" -> "  %7998 = and i32 %6548, 65535""  %6548 = add nuw i32 %6454, %6547" -> "  %8001 = lshr i32 %6548, 16"
"  %6549 = mul nuw i32 %5131, 42779"
"  %6549 = mul nuw i32 %5131, 42779" -> "  %7213 = and i32 %6549, 65535""  %6549 = mul nuw i32 %5131, 42779" -> "  %6550 = lshr i32 %6549, 16"
"  %6550 = lshr i32 %6549, 16"
"  %6550 = lshr i32 %6549, 16" -> "  %6553 = add nuw nsw i32 %6552, %6550"
"  %6551 = mul nuw i32 %5134, 42779"
"  %6551 = mul nuw i32 %5134, 42779" -> "  %6554 = and i32 %6551, -65536""  %6551 = mul nuw i32 %5134, 42779" -> "  %6552 = and i32 %6551, 65535"
"  %6552 = and i32 %6551, 65535"
"  %6552 = and i32 %6551, 65535" -> "  %6553 = add nuw nsw i32 %6552, %6550"
"  %6553 = add nuw nsw i32 %6552, %6550"
"  %6553 = add nuw nsw i32 %6552, %6550" -> "  %6555 = add nuw i32 %6553, %6554"
"  %6554 = and i32 %6551, -65536"
"  %6554 = and i32 %6551, -65536" -> "  %6555 = add nuw i32 %6553, %6554"
"  %6555 = add nuw i32 %6553, %6554"
"  %6555 = add nuw i32 %6553, %6554" -> "  %6559 = lshr i32 %6555, 16""  %6555 = add nuw i32 %6553, %6554" -> "  %6557 = and i32 %6555, 65535"
"  %6556 = mul nuw nsw i32 %5131, 9871"
"  %6556 = mul nuw nsw i32 %5131, 9871" -> "  %6558 = add nuw nsw i32 %6557, %6556"
"  %6557 = and i32 %6555, 65535"
"  %6557 = and i32 %6555, 65535" -> "  %6558 = add nuw nsw i32 %6557, %6556"
"  %6558 = add nuw nsw i32 %6557, %6556"
"  %6558 = add nuw nsw i32 %6557, %6556" -> "  %7216 = and i32 %6558, 65535""  %6558 = add nuw nsw i32 %6557, %6556" -> "  %6562 = lshr i32 %6558, 16"
"  %6559 = lshr i32 %6555, 16"
"  %6559 = lshr i32 %6555, 16" -> "  %6561 = add nuw nsw i32 %6559, %6560"
"  %6560 = mul nuw nsw i32 %5134, 9871"
"  %6560 = mul nuw nsw i32 %5134, 9871" -> "  %6561 = add nuw nsw i32 %6559, %6560"
"  %6561 = add nuw nsw i32 %6559, %6560"
"  %6561 = add nuw nsw i32 %6559, %6560" -> "  %6565 = and i32 %6561, 2147418112""  %6561 = add nuw nsw i32 %6559, %6560" -> "  %6563 = and i32 %6561, 65535"
"  %6562 = lshr i32 %6558, 16"
"  %6562 = lshr i32 %6558, 16" -> "  %6564 = add nuw nsw i32 %6562, %6563"
"  %6563 = and i32 %6561, 65535"
"  %6563 = and i32 %6561, 65535" -> "  %6564 = add nuw nsw i32 %6562, %6563"
"  %6564 = add nuw nsw i32 %6562, %6563"
"  %6564 = add nuw nsw i32 %6562, %6563" -> "  %6566 = add nuw nsw i32 %6564, %6565"
"  %6565 = and i32 %6561, 2147418112"
"  %6565 = and i32 %6561, 2147418112" -> "  %6566 = add nuw nsw i32 %6564, %6565"
"  %6566 = add nuw nsw i32 %6564, %6565"
"  %6566 = add nuw nsw i32 %6564, %6565" -> "  %6585 = and i32 %6566, 65535""  %6566 = add nuw nsw i32 %6564, %6565" -> "  %6588 = lshr i32 %6566, 16"
"  %6567 = mul nuw i32 %5151, 42779"
"  %6567 = mul nuw i32 %5151, 42779" -> "  %6586 = and i32 %6567, 65535""  %6567 = mul nuw i32 %5151, 42779" -> "  %6568 = lshr i32 %6567, 16"
"  %6568 = lshr i32 %6567, 16"
"  %6568 = lshr i32 %6567, 16" -> "  %6571 = add nuw nsw i32 %6570, %6568"
"  %6569 = mul nuw i32 %5152, 42779"
"  %6569 = mul nuw i32 %5152, 42779" -> "  %6572 = and i32 %6569, -65536""  %6569 = mul nuw i32 %5152, 42779" -> "  %6570 = and i32 %6569, 65535"
"  %6570 = and i32 %6569, 65535"
"  %6570 = and i32 %6569, 65535" -> "  %6571 = add nuw nsw i32 %6570, %6568"
"  %6571 = add nuw nsw i32 %6570, %6568"
"  %6571 = add nuw nsw i32 %6570, %6568" -> "  %6573 = add nuw i32 %6571, %6572"
"  %6572 = and i32 %6569, -65536"
"  %6572 = and i32 %6569, -65536" -> "  %6573 = add nuw i32 %6571, %6572"
"  %6573 = add nuw i32 %6571, %6572"
"  %6573 = add nuw i32 %6571, %6572" -> "  %6577 = lshr i32 %6573, 16""  %6573 = add nuw i32 %6571, %6572" -> "  %6575 = and i32 %6573, 65535"
"  %6574 = mul nuw nsw i32 %5151, 9871"
"  %6574 = mul nuw nsw i32 %5151, 9871" -> "  %6576 = add nuw nsw i32 %6575, %6574"
"  %6575 = and i32 %6573, 65535"
"  %6575 = and i32 %6573, 65535" -> "  %6576 = add nuw nsw i32 %6575, %6574"
"  %6576 = add nuw nsw i32 %6575, %6574"
"  %6576 = add nuw nsw i32 %6575, %6574" -> "  %6589 = and i32 %6576, 65535""  %6576 = add nuw nsw i32 %6575, %6574" -> "  %6580 = lshr i32 %6576, 16"
"  %6577 = lshr i32 %6573, 16"
"  %6577 = lshr i32 %6573, 16" -> "  %6579 = add nuw nsw i32 %6577, %6578"
"  %6578 = mul nuw nsw i32 %5152, 9871"
"  %6578 = mul nuw nsw i32 %5152, 9871" -> "  %6579 = add nuw nsw i32 %6577, %6578"
"  %6579 = add nuw nsw i32 %6577, %6578"
"  %6579 = add nuw nsw i32 %6577, %6578" -> "  %6583 = and i32 %6579, 2147418112""  %6579 = add nuw nsw i32 %6577, %6578" -> "  %6581 = and i32 %6579, 65535"
"  %6580 = lshr i32 %6576, 16"
"  %6580 = lshr i32 %6576, 16" -> "  %6582 = add nuw nsw i32 %6580, %6581"
"  %6581 = and i32 %6579, 65535"
"  %6581 = and i32 %6579, 65535" -> "  %6582 = add nuw nsw i32 %6580, %6581"
"  %6582 = add nuw nsw i32 %6580, %6581"
"  %6582 = add nuw nsw i32 %6580, %6581" -> "  %6584 = add nuw nsw i32 %6582, %6583"
"  %6583 = and i32 %6579, 2147418112"
"  %6583 = and i32 %6579, 2147418112" -> "  %6584 = add nuw nsw i32 %6582, %6583"
"  %6584 = add nuw nsw i32 %6582, %6583"
"  %6584 = add nuw nsw i32 %6582, %6583" -> "  %6592 = add nuw nsw i32 %6584, %6591"
"  %6585 = and i32 %6566, 65535"
"  %6585 = and i32 %6566, 65535" -> "  %6587 = add nuw nsw i32 %6585, %6586"
"  %6586 = and i32 %6567, 65535"
"  %6586 = and i32 %6567, 65535" -> "  %6587 = add nuw nsw i32 %6585, %6586"
"  %6587 = add nuw nsw i32 %6585, %6586"
"  %6587 = add nuw nsw i32 %6585, %6586" -> "  %6616 = and i32 %6587, 65535""  %6587 = add nuw nsw i32 %6585, %6586" -> "  %6594 = lshr i32 %6587, 16"
"  %6588 = lshr i32 %6566, 16"
"  %6588 = lshr i32 %6566, 16" -> "  %6590 = add nuw nsw i32 %6589, %6588"
"  %6589 = and i32 %6576, 65535"
"  %6589 = and i32 %6576, 65535" -> "  %6590 = add nuw nsw i32 %6589, %6588"
"  %6590 = add nuw nsw i32 %6589, %6588"
"  %6590 = add nuw nsw i32 %6589, %6588" -> "  %6593 = and i32 %6590, 65535""  %6590 = add nuw nsw i32 %6589, %6588" -> "  %6591 = lshr i32 %6590, 16"
"  %6591 = lshr i32 %6590, 16"
"  %6591 = lshr i32 %6590, 16" -> "  %6592 = add nuw nsw i32 %6584, %6591"
"  %6592 = add nuw nsw i32 %6584, %6591"
"  %6592 = add nuw nsw i32 %6584, %6591" -> "  %6597 = add nuw nsw i32 %6592, %6596"
"  %6593 = and i32 %6590, 65535"
"  %6593 = and i32 %6590, 65535" -> "  %6595 = add nuw nsw i32 %6593, %6594"
"  %6594 = lshr i32 %6587, 16"
"  %6594 = lshr i32 %6587, 16" -> "  %6595 = add nuw nsw i32 %6593, %6594"
"  %6595 = add nuw nsw i32 %6593, %6594"
"  %6595 = add nuw nsw i32 %6593, %6594" -> "  %6619 = and i32 %6595, 65535""  %6595 = add nuw nsw i32 %6593, %6594" -> "  %6596 = lshr i32 %6595, 16"
"  %6596 = lshr i32 %6595, 16"
"  %6596 = lshr i32 %6595, 16" -> "  %6597 = add nuw nsw i32 %6592, %6596"
"  %6597 = add nuw nsw i32 %6592, %6596"
"  %6597 = add nuw nsw i32 %6592, %6596" -> "  %6651 = lshr i32 %6597, 16""  %6597 = add nuw nsw i32 %6592, %6596" -> "  %6647 = and i32 %6597, 65535"
"  %6598 = mul nuw nsw i32 %5131, 24315"
"  %6598 = mul nuw nsw i32 %5131, 24315" -> "  %6617 = and i32 %6598, 65535""  %6598 = mul nuw nsw i32 %5131, 24315" -> "  %6599 = lshr i32 %6598, 16"
"  %6599 = lshr i32 %6598, 16"
"  %6599 = lshr i32 %6598, 16" -> "  %6602 = add nuw nsw i32 %6601, %6599"
"  %6600 = mul nuw nsw i32 %5134, 24315"
"  %6600 = mul nuw nsw i32 %5134, 24315" -> "  %6603 = and i32 %6600, 2147418112""  %6600 = mul nuw nsw i32 %5134, 24315" -> "  %6601 = and i32 %6600, 65535"
"  %6601 = and i32 %6600, 65535"
"  %6601 = and i32 %6600, 65535" -> "  %6602 = add nuw nsw i32 %6601, %6599"
"  %6602 = add nuw nsw i32 %6601, %6599"
"  %6602 = add nuw nsw i32 %6601, %6599" -> "  %6604 = add nuw nsw i32 %6602, %6603"
"  %6603 = and i32 %6600, 2147418112"
"  %6603 = and i32 %6600, 2147418112" -> "  %6604 = add nuw nsw i32 %6602, %6603"
"  %6604 = add nuw nsw i32 %6602, %6603"
"  %6604 = add nuw nsw i32 %6602, %6603" -> "  %6608 = lshr i32 %6604, 16""  %6604 = add nuw nsw i32 %6602, %6603" -> "  %6606 = and i32 %6604, 65535"
"  %6605 = mul nuw nsw i32 %5131, 29744"
"  %6605 = mul nuw nsw i32 %5131, 29744" -> "  %6607 = add nuw nsw i32 %6606, %6605"
"  %6606 = and i32 %6604, 65535"
"  %6606 = and i32 %6604, 65535" -> "  %6607 = add nuw nsw i32 %6606, %6605"
"  %6607 = add nuw nsw i32 %6606, %6605"
"  %6607 = add nuw nsw i32 %6606, %6605" -> "  %6620 = and i32 %6607, 65535""  %6607 = add nuw nsw i32 %6606, %6605" -> "  %6611 = lshr i32 %6607, 16"
"  %6608 = lshr i32 %6604, 16"
"  %6608 = lshr i32 %6604, 16" -> "  %6610 = add nuw nsw i32 %6608, %6609"
"  %6609 = mul nuw nsw i32 %5134, 29744"
"  %6609 = mul nuw nsw i32 %5134, 29744" -> "  %6610 = add nuw nsw i32 %6608, %6609"
"  %6610 = add nuw nsw i32 %6608, %6609"
"  %6610 = add nuw nsw i32 %6608, %6609" -> "  %6614 = and i32 %6610, 2147418112""  %6610 = add nuw nsw i32 %6608, %6609" -> "  %6612 = and i32 %6610, 65535"
"  %6611 = lshr i32 %6607, 16"
"  %6611 = lshr i32 %6607, 16" -> "  %6613 = add nuw nsw i32 %6611, %6612"
"  %6612 = and i32 %6610, 65535"
"  %6612 = and i32 %6610, 65535" -> "  %6613 = add nuw nsw i32 %6611, %6612"
"  %6613 = add nuw nsw i32 %6611, %6612"
"  %6613 = add nuw nsw i32 %6611, %6612" -> "  %6615 = add nuw nsw i32 %6613, %6614"
"  %6614 = and i32 %6610, 2147418112"
"  %6614 = and i32 %6610, 2147418112" -> "  %6615 = add nuw nsw i32 %6613, %6614"
"  %6615 = add nuw nsw i32 %6613, %6614"
"  %6615 = add nuw nsw i32 %6613, %6614" -> "  %6623 = add nuw nsw i32 %6615, %6622"
"  %6616 = and i32 %6587, 65535"
"  %6616 = and i32 %6587, 65535" -> "  %6618 = add nuw nsw i32 %6616, %6617"
"  %6617 = and i32 %6598, 65535"
"  %6617 = and i32 %6598, 65535" -> "  %6618 = add nuw nsw i32 %6616, %6617"
"  %6618 = add nuw nsw i32 %6616, %6617"
"  %6618 = add nuw nsw i32 %6616, %6617" -> "  %7225 = and i32 %6618, 65535""  %6618 = add nuw nsw i32 %6616, %6617" -> "  %6625 = lshr i32 %6618, 16"
"  %6619 = and i32 %6595, 65535"
"  %6619 = and i32 %6595, 65535" -> "  %6621 = add nuw nsw i32 %6619, %6620"
"  %6620 = and i32 %6607, 65535"
"  %6620 = and i32 %6607, 65535" -> "  %6621 = add nuw nsw i32 %6619, %6620"
"  %6621 = add nuw nsw i32 %6619, %6620"
"  %6621 = add nuw nsw i32 %6619, %6620" -> "  %6624 = and i32 %6621, 65535""  %6621 = add nuw nsw i32 %6619, %6620" -> "  %6622 = lshr i32 %6621, 16"
"  %6622 = lshr i32 %6621, 16"
"  %6622 = lshr i32 %6621, 16" -> "  %6623 = add nuw nsw i32 %6615, %6622"
"  %6623 = add nuw nsw i32 %6615, %6622"
"  %6623 = add nuw nsw i32 %6615, %6622" -> "  %6628 = add nuw nsw i32 %6623, %6627"
"  %6624 = and i32 %6621, 65535"
"  %6624 = and i32 %6621, 65535" -> "  %6626 = add nuw nsw i32 %6624, %6625"
"  %6625 = lshr i32 %6618, 16"
"  %6625 = lshr i32 %6618, 16" -> "  %6626 = add nuw nsw i32 %6624, %6625"
"  %6626 = add nuw nsw i32 %6624, %6625"
"  %6626 = add nuw nsw i32 %6624, %6625" -> "  %7228 = and i32 %6626, 65535""  %6626 = add nuw nsw i32 %6624, %6625" -> "  %6627 = lshr i32 %6626, 16"
"  %6627 = lshr i32 %6626, 16"
"  %6627 = lshr i32 %6626, 16" -> "  %6628 = add nuw nsw i32 %6623, %6627"
"  %6628 = add nuw nsw i32 %6623, %6627"
"  %6628 = add nuw nsw i32 %6623, %6627" -> "  %6664 = lshr i32 %6628, 16""  %6628 = add nuw nsw i32 %6623, %6627" -> "  %6661 = and i32 %6628, 65535"
"  %6629 = mul nuw nsw i32 %5151, 24315"
"  %6629 = mul nuw nsw i32 %5151, 24315" -> "  %6648 = and i32 %6629, 65535""  %6629 = mul nuw nsw i32 %5151, 24315" -> "  %6630 = lshr i32 %6629, 16"
"  %6630 = lshr i32 %6629, 16"
"  %6630 = lshr i32 %6629, 16" -> "  %6633 = add nuw nsw i32 %6632, %6630"
"  %6631 = mul nuw nsw i32 %5152, 24315"
"  %6631 = mul nuw nsw i32 %5152, 24315" -> "  %6634 = and i32 %6631, 2147418112""  %6631 = mul nuw nsw i32 %5152, 24315" -> "  %6632 = and i32 %6631, 65535"
"  %6632 = and i32 %6631, 65535"
"  %6632 = and i32 %6631, 65535" -> "  %6633 = add nuw nsw i32 %6632, %6630"
"  %6633 = add nuw nsw i32 %6632, %6630"
"  %6633 = add nuw nsw i32 %6632, %6630" -> "  %6635 = add nuw nsw i32 %6633, %6634"
"  %6634 = and i32 %6631, 2147418112"
"  %6634 = and i32 %6631, 2147418112" -> "  %6635 = add nuw nsw i32 %6633, %6634"
"  %6635 = add nuw nsw i32 %6633, %6634"
"  %6635 = add nuw nsw i32 %6633, %6634" -> "  %6639 = lshr i32 %6635, 16""  %6635 = add nuw nsw i32 %6633, %6634" -> "  %6637 = and i32 %6635, 65535"
"  %6636 = mul nuw nsw i32 %5151, 29744"
"  %6636 = mul nuw nsw i32 %5151, 29744" -> "  %6638 = add nuw nsw i32 %6637, %6636"
"  %6637 = and i32 %6635, 65535"
"  %6637 = and i32 %6635, 65535" -> "  %6638 = add nuw nsw i32 %6637, %6636"
"  %6638 = add nuw nsw i32 %6637, %6636"
"  %6638 = add nuw nsw i32 %6637, %6636" -> "  %6650 = and i32 %6638, 65535""  %6638 = add nuw nsw i32 %6637, %6636" -> "  %6642 = lshr i32 %6638, 16"
"  %6639 = lshr i32 %6635, 16"
"  %6639 = lshr i32 %6635, 16" -> "  %6641 = add nuw nsw i32 %6639, %6640"
"  %6640 = mul nuw nsw i32 %5152, 29744"
"  %6640 = mul nuw nsw i32 %5152, 29744" -> "  %6641 = add nuw nsw i32 %6639, %6640"
"  %6641 = add nuw nsw i32 %6639, %6640"
"  %6641 = add nuw nsw i32 %6639, %6640" -> "  %6645 = and i32 %6641, 2147418112""  %6641 = add nuw nsw i32 %6639, %6640" -> "  %6643 = and i32 %6641, 65535"
"  %6642 = lshr i32 %6638, 16"
"  %6642 = lshr i32 %6638, 16" -> "  %6644 = add nuw nsw i32 %6642, %6643"
"  %6643 = and i32 %6641, 65535"
"  %6643 = and i32 %6641, 65535" -> "  %6644 = add nuw nsw i32 %6642, %6643"
"  %6644 = add nuw nsw i32 %6642, %6643"
"  %6644 = add nuw nsw i32 %6642, %6643" -> "  %6646 = add nuw nsw i32 %6644, %6645"
"  %6645 = and i32 %6641, 2147418112"
"  %6645 = and i32 %6641, 2147418112" -> "  %6646 = add nuw nsw i32 %6644, %6645"
"  %6646 = add nuw nsw i32 %6644, %6645"
"  %6646 = add nuw nsw i32 %6644, %6645" -> "  %6654 = add nuw nsw i32 %6646, %6653"
"  %6647 = and i32 %6597, 65535"
"  %6647 = and i32 %6597, 65535" -> "  %6649 = add nuw nsw i32 %6647, %6648"
"  %6648 = and i32 %6629, 65535"
"  %6648 = and i32 %6629, 65535" -> "  %6649 = add nuw nsw i32 %6647, %6648"
"  %6649 = add nuw nsw i32 %6647, %6648"
"  %6649 = add nuw nsw i32 %6647, %6648" -> "  %6660 = and i32 %6649, 65535""  %6649 = add nuw nsw i32 %6647, %6648" -> "  %6656 = lshr i32 %6649, 16"
"  %6650 = and i32 %6638, 65535"
"  %6650 = and i32 %6638, 65535" -> "  %6652 = add nuw nsw i32 %6651, %6650"
"  %6651 = lshr i32 %6597, 16"
"  %6651 = lshr i32 %6597, 16" -> "  %6652 = add nuw nsw i32 %6651, %6650"
"  %6652 = add nuw nsw i32 %6651, %6650"
"  %6652 = add nuw nsw i32 %6651, %6650" -> "  %6655 = and i32 %6652, 65535""  %6652 = add nuw nsw i32 %6651, %6650" -> "  %6653 = lshr i32 %6652, 16"
"  %6653 = lshr i32 %6652, 16"
"  %6653 = lshr i32 %6652, 16" -> "  %6654 = add nuw nsw i32 %6646, %6653"
"  %6654 = add nuw nsw i32 %6646, %6653"
"  %6654 = add nuw nsw i32 %6646, %6653" -> "  %6659 = add nuw nsw i32 %6654, %6658"
"  %6655 = and i32 %6652, 65535"
"  %6655 = and i32 %6652, 65535" -> "  %6657 = add nuw nsw i32 %6655, %6656"
"  %6656 = lshr i32 %6649, 16"
"  %6656 = lshr i32 %6649, 16" -> "  %6657 = add nuw nsw i32 %6655, %6656"
"  %6657 = add nuw nsw i32 %6655, %6656"
"  %6657 = add nuw nsw i32 %6655, %6656" -> "  %6663 = and i32 %6657, 65535""  %6657 = add nuw nsw i32 %6655, %6656" -> "  %6658 = lshr i32 %6657, 16"
"  %6658 = lshr i32 %6657, 16"
"  %6658 = lshr i32 %6657, 16" -> "  %6659 = add nuw nsw i32 %6654, %6658"
"  %6659 = add nuw nsw i32 %6654, %6658"
"  %6659 = add nuw nsw i32 %6654, %6658" -> "  %6672 = and i32 %6659, 2147418112""  %6659 = add nuw nsw i32 %6654, %6658" -> "  %6670 = and i32 %6659, 65535"
"  %6660 = and i32 %6649, 65535"
"  %6660 = and i32 %6649, 65535" -> "  %6662 = add nuw nsw i32 %6661, %6660"
"  %6661 = and i32 %6628, 65535"
"  %6661 = and i32 %6628, 65535" -> "  %6662 = add nuw nsw i32 %6661, %6660"
"  %6662 = add nuw nsw i32 %6661, %6660"
"  %6662 = add nuw nsw i32 %6661, %6660" -> "  %6804 = and i32 %6662, 65535""  %6662 = add nuw nsw i32 %6661, %6660" -> "  %6666 = lshr i32 %6662, 16"
"  %6663 = and i32 %6657, 65535"
"  %6663 = and i32 %6657, 65535" -> "  %6665 = add nuw nsw i32 %6663, %6664"
"  %6664 = lshr i32 %6628, 16"
"  %6664 = lshr i32 %6628, 16" -> "  %6665 = add nuw nsw i32 %6663, %6664"
"  %6665 = add nuw nsw i32 %6663, %6664"
"  %6665 = add nuw nsw i32 %6663, %6664" -> "  %6669 = lshr i32 %6665, 16""  %6665 = add nuw nsw i32 %6663, %6664" -> "  %6667 = and i32 %6665, 65535"
"  %6666 = lshr i32 %6662, 16"
"  %6666 = lshr i32 %6662, 16" -> "  %6668 = add nuw nsw i32 %6667, %6666"
"  %6667 = and i32 %6665, 65535"
"  %6667 = and i32 %6665, 65535" -> "  %6668 = add nuw nsw i32 %6667, %6666"
"  %6668 = add nuw nsw i32 %6667, %6666"
"  %6668 = add nuw nsw i32 %6667, %6666" -> "  %6807 = and i32 %6668, 65535""  %6668 = add nuw nsw i32 %6667, %6666" -> "  %6674 = lshr i32 %6668, 16"
"  %6669 = lshr i32 %6665, 16"
"  %6669 = lshr i32 %6665, 16" -> "  %6671 = add nuw nsw i32 %6669, %6670"
"  %6670 = and i32 %6659, 65535"
"  %6670 = and i32 %6659, 65535" -> "  %6671 = add nuw nsw i32 %6669, %6670"
"  %6671 = add nuw nsw i32 %6669, %6670"
"  %6671 = add nuw nsw i32 %6669, %6670" -> "  %6673 = add nuw nsw i32 %6671, %6672"
"  %6672 = and i32 %6659, 2147418112"
"  %6672 = and i32 %6659, 2147418112" -> "  %6673 = add nuw nsw i32 %6671, %6672"
"  %6673 = add nuw nsw i32 %6671, %6672"
"  %6673 = add nuw nsw i32 %6671, %6672" -> "  %6675 = add nuw nsw i32 %6673, %6674"
"  %6674 = lshr i32 %6668, 16"
"  %6674 = lshr i32 %6668, 16" -> "  %6675 = add nuw nsw i32 %6673, %6674"
"  %6675 = add nuw nsw i32 %6673, %6674"
"  %6675 = add nuw nsw i32 %6673, %6674" -> "  %6814 = and i32 %6675, 65535""  %6675 = add nuw nsw i32 %6673, %6674" -> "  %6818 = lshr i32 %6675, 16"
"  %6676 = mul nuw i32 %5262, 42779"
"  %6676 = mul nuw i32 %5262, 42779" -> "  %6803 = and i32 %6676, 65535""  %6676 = mul nuw i32 %5262, 42779" -> "  %6677 = lshr i32 %6676, 16"
"  %6677 = lshr i32 %6676, 16"
"  %6677 = lshr i32 %6676, 16" -> "  %6680 = add nuw nsw i32 %6679, %6677"
"  %6678 = mul nuw i32 %5265, 42779"
"  %6678 = mul nuw i32 %5265, 42779" -> "  %6681 = and i32 %6678, -65536""  %6678 = mul nuw i32 %5265, 42779" -> "  %6679 = and i32 %6678, 65535"
"  %6679 = and i32 %6678, 65535"
"  %6679 = and i32 %6678, 65535" -> "  %6680 = add nuw nsw i32 %6679, %6677"
"  %6680 = add nuw nsw i32 %6679, %6677"
"  %6680 = add nuw nsw i32 %6679, %6677" -> "  %6682 = add nuw i32 %6680, %6681"
"  %6681 = and i32 %6678, -65536"
"  %6681 = and i32 %6678, -65536" -> "  %6682 = add nuw i32 %6680, %6681"
"  %6682 = add nuw i32 %6680, %6681"
"  %6682 = add nuw i32 %6680, %6681" -> "  %6686 = lshr i32 %6682, 16""  %6682 = add nuw i32 %6680, %6681" -> "  %6684 = and i32 %6682, 65535"
"  %6683 = mul nuw nsw i32 %5262, 9871"
"  %6683 = mul nuw nsw i32 %5262, 9871" -> "  %6685 = add nuw nsw i32 %6684, %6683"
"  %6684 = and i32 %6682, 65535"
"  %6684 = and i32 %6682, 65535" -> "  %6685 = add nuw nsw i32 %6684, %6683"
"  %6685 = add nuw nsw i32 %6684, %6683"
"  %6685 = add nuw nsw i32 %6684, %6683" -> "  %6806 = and i32 %6685, 65535""  %6685 = add nuw nsw i32 %6684, %6683" -> "  %6689 = lshr i32 %6685, 16"
"  %6686 = lshr i32 %6682, 16"
"  %6686 = lshr i32 %6682, 16" -> "  %6688 = add nuw nsw i32 %6686, %6687"
"  %6687 = mul nuw nsw i32 %5265, 9871"
"  %6687 = mul nuw nsw i32 %5265, 9871" -> "  %6688 = add nuw nsw i32 %6686, %6687"
"  %6688 = add nuw nsw i32 %6686, %6687"
"  %6688 = add nuw nsw i32 %6686, %6687" -> "  %6692 = and i32 %6688, 2147418112""  %6688 = add nuw nsw i32 %6686, %6687" -> "  %6690 = and i32 %6688, 65535"
"  %6689 = lshr i32 %6685, 16"
"  %6689 = lshr i32 %6685, 16" -> "  %6691 = add nuw nsw i32 %6689, %6690"
"  %6690 = and i32 %6688, 65535"
"  %6690 = and i32 %6688, 65535" -> "  %6691 = add nuw nsw i32 %6689, %6690"
"  %6691 = add nuw nsw i32 %6689, %6690"
"  %6691 = add nuw nsw i32 %6689, %6690" -> "  %6693 = add nuw nsw i32 %6691, %6692"
"  %6692 = and i32 %6688, 2147418112"
"  %6692 = and i32 %6688, 2147418112" -> "  %6693 = add nuw nsw i32 %6691, %6692"
"  %6693 = add nuw nsw i32 %6691, %6692"
"  %6693 = add nuw nsw i32 %6691, %6692" -> "  %6716 = lshr i32 %6693, 16""  %6693 = add nuw nsw i32 %6691, %6692" -> "  %6712 = and i32 %6693, 65535"
"  %6694 = mul nuw i32 %5282, 42779"
"  %6694 = mul nuw i32 %5282, 42779" -> "  %6713 = and i32 %6694, 65535""  %6694 = mul nuw i32 %5282, 42779" -> "  %6695 = lshr i32 %6694, 16"
"  %6695 = lshr i32 %6694, 16"
"  %6695 = lshr i32 %6694, 16" -> "  %6698 = add nuw nsw i32 %6697, %6695"
"  %6696 = mul nuw i32 %5285, 42779"
"  %6696 = mul nuw i32 %5285, 42779" -> "  %6699 = and i32 %6696, -65536""  %6696 = mul nuw i32 %5285, 42779" -> "  %6697 = and i32 %6696, 65535"
"  %6697 = and i32 %6696, 65535"
"  %6697 = and i32 %6696, 65535" -> "  %6698 = add nuw nsw i32 %6697, %6695"
"  %6698 = add nuw nsw i32 %6697, %6695"
"  %6698 = add nuw nsw i32 %6697, %6695" -> "  %6700 = add nuw i32 %6698, %6699"
"  %6699 = and i32 %6696, -65536"
"  %6699 = and i32 %6696, -65536" -> "  %6700 = add nuw i32 %6698, %6699"
"  %6700 = add nuw i32 %6698, %6699"
"  %6700 = add nuw i32 %6698, %6699" -> "  %6704 = lshr i32 %6700, 16""  %6700 = add nuw i32 %6698, %6699" -> "  %6702 = and i32 %6700, 65535"
"  %6701 = mul nuw nsw i32 %5282, 9871"
"  %6701 = mul nuw nsw i32 %5282, 9871" -> "  %6703 = add nuw nsw i32 %6702, %6701"
"  %6702 = and i32 %6700, 65535"
"  %6702 = and i32 %6700, 65535" -> "  %6703 = add nuw nsw i32 %6702, %6701"
"  %6703 = add nuw nsw i32 %6702, %6701"
"  %6703 = add nuw nsw i32 %6702, %6701" -> "  %6715 = and i32 %6703, 65535""  %6703 = add nuw nsw i32 %6702, %6701" -> "  %6707 = lshr i32 %6703, 16"
"  %6704 = lshr i32 %6700, 16"
"  %6704 = lshr i32 %6700, 16" -> "  %6706 = add nuw nsw i32 %6704, %6705"
"  %6705 = mul nuw nsw i32 %5285, 9871"
"  %6705 = mul nuw nsw i32 %5285, 9871" -> "  %6706 = add nuw nsw i32 %6704, %6705"
"  %6706 = add nuw nsw i32 %6704, %6705"
"  %6706 = add nuw nsw i32 %6704, %6705" -> "  %6710 = and i32 %6706, 2147418112""  %6706 = add nuw nsw i32 %6704, %6705" -> "  %6708 = and i32 %6706, 65535"
"  %6707 = lshr i32 %6703, 16"
"  %6707 = lshr i32 %6703, 16" -> "  %6709 = add nuw nsw i32 %6707, %6708"
"  %6708 = and i32 %6706, 65535"
"  %6708 = and i32 %6706, 65535" -> "  %6709 = add nuw nsw i32 %6707, %6708"
"  %6709 = add nuw nsw i32 %6707, %6708"
"  %6709 = add nuw nsw i32 %6707, %6708" -> "  %6711 = add nuw nsw i32 %6709, %6710"
"  %6710 = and i32 %6706, 2147418112"
"  %6710 = and i32 %6706, 2147418112" -> "  %6711 = add nuw nsw i32 %6709, %6710"
"  %6711 = add nuw nsw i32 %6709, %6710"
"  %6711 = add nuw nsw i32 %6709, %6710" -> "  %6719 = add nuw nsw i32 %6711, %6718"
"  %6712 = and i32 %6693, 65535"
"  %6712 = and i32 %6693, 65535" -> "  %6714 = add nuw nsw i32 %6712, %6713"
"  %6713 = and i32 %6694, 65535"
"  %6713 = and i32 %6694, 65535" -> "  %6714 = add nuw nsw i32 %6712, %6713"
"  %6714 = add nuw nsw i32 %6712, %6713"
"  %6714 = add nuw nsw i32 %6712, %6713" -> "  %6743 = and i32 %6714, 65535""  %6714 = add nuw nsw i32 %6712, %6713" -> "  %6721 = lshr i32 %6714, 16"
"  %6715 = and i32 %6703, 65535"
"  %6715 = and i32 %6703, 65535" -> "  %6717 = add nuw nsw i32 %6715, %6716"
"  %6716 = lshr i32 %6693, 16"
"  %6716 = lshr i32 %6693, 16" -> "  %6717 = add nuw nsw i32 %6715, %6716"
"  %6717 = add nuw nsw i32 %6715, %6716"
"  %6717 = add nuw nsw i32 %6715, %6716" -> "  %6720 = and i32 %6717, 65535""  %6717 = add nuw nsw i32 %6715, %6716" -> "  %6718 = lshr i32 %6717, 16"
"  %6718 = lshr i32 %6717, 16"
"  %6718 = lshr i32 %6717, 16" -> "  %6719 = add nuw nsw i32 %6711, %6718"
"  %6719 = add nuw nsw i32 %6711, %6718"
"  %6719 = add nuw nsw i32 %6711, %6718" -> "  %6724 = add nuw nsw i32 %6719, %6723"
"  %6720 = and i32 %6717, 65535"
"  %6720 = and i32 %6717, 65535" -> "  %6722 = add nuw nsw i32 %6720, %6721"
"  %6721 = lshr i32 %6714, 16"
"  %6721 = lshr i32 %6714, 16" -> "  %6722 = add nuw nsw i32 %6720, %6721"
"  %6722 = add nuw nsw i32 %6720, %6721"
"  %6722 = add nuw nsw i32 %6720, %6721" -> "  %6746 = and i32 %6722, 65535""  %6722 = add nuw nsw i32 %6720, %6721" -> "  %6723 = lshr i32 %6722, 16"
"  %6723 = lshr i32 %6722, 16"
"  %6723 = lshr i32 %6722, 16" -> "  %6724 = add nuw nsw i32 %6719, %6723"
"  %6724 = add nuw nsw i32 %6719, %6723"
"  %6724 = add nuw nsw i32 %6719, %6723" -> "  %6774 = and i32 %6724, 65535""  %6724 = add nuw nsw i32 %6719, %6723" -> "  %6778 = lshr i32 %6724, 16"
"  %6725 = mul nuw nsw i32 %5262, 24315"
"  %6725 = mul nuw nsw i32 %5262, 24315" -> "  %6726 = lshr i32 %6725, 16""  %6725 = mul nuw nsw i32 %5262, 24315" -> "  %6744 = and i32 %6725, 65535"
"  %6726 = lshr i32 %6725, 16"
"  %6726 = lshr i32 %6725, 16" -> "  %6729 = add nuw nsw i32 %6728, %6726"
"  %6727 = mul nuw nsw i32 %5265, 24315"
"  %6727 = mul nuw nsw i32 %5265, 24315" -> "  %6730 = and i32 %6727, 2147418112""  %6727 = mul nuw nsw i32 %5265, 24315" -> "  %6728 = and i32 %6727, 65535"
"  %6728 = and i32 %6727, 65535"
"  %6728 = and i32 %6727, 65535" -> "  %6729 = add nuw nsw i32 %6728, %6726"
"  %6729 = add nuw nsw i32 %6728, %6726"
"  %6729 = add nuw nsw i32 %6728, %6726" -> "  %6731 = add nuw nsw i32 %6729, %6730"
"  %6730 = and i32 %6727, 2147418112"
"  %6730 = and i32 %6727, 2147418112" -> "  %6731 = add nuw nsw i32 %6729, %6730"
"  %6731 = add nuw nsw i32 %6729, %6730"
"  %6731 = add nuw nsw i32 %6729, %6730" -> "  %6735 = lshr i32 %6731, 16""  %6731 = add nuw nsw i32 %6729, %6730" -> "  %6733 = and i32 %6731, 65535"
"  %6732 = mul nuw nsw i32 %5262, 29744"
"  %6732 = mul nuw nsw i32 %5262, 29744" -> "  %6734 = add nuw nsw i32 %6733, %6732"
"  %6733 = and i32 %6731, 65535"
"  %6733 = and i32 %6731, 65535" -> "  %6734 = add nuw nsw i32 %6733, %6732"
"  %6734 = add nuw nsw i32 %6733, %6732"
"  %6734 = add nuw nsw i32 %6733, %6732" -> "  %6747 = and i32 %6734, 65535""  %6734 = add nuw nsw i32 %6733, %6732" -> "  %6738 = lshr i32 %6734, 16"
"  %6735 = lshr i32 %6731, 16"
"  %6735 = lshr i32 %6731, 16" -> "  %6737 = add nuw nsw i32 %6735, %6736"
"  %6736 = mul nuw nsw i32 %5265, 29744"
"  %6736 = mul nuw nsw i32 %5265, 29744" -> "  %6737 = add nuw nsw i32 %6735, %6736"
"  %6737 = add nuw nsw i32 %6735, %6736"
"  %6737 = add nuw nsw i32 %6735, %6736" -> "  %6741 = and i32 %6737, 2147418112""  %6737 = add nuw nsw i32 %6735, %6736" -> "  %6739 = and i32 %6737, 65535"
"  %6738 = lshr i32 %6734, 16"
"  %6738 = lshr i32 %6734, 16" -> "  %6740 = add nuw nsw i32 %6738, %6739"
"  %6739 = and i32 %6737, 65535"
"  %6739 = and i32 %6737, 65535" -> "  %6740 = add nuw nsw i32 %6738, %6739"
"  %6740 = add nuw nsw i32 %6738, %6739"
"  %6740 = add nuw nsw i32 %6738, %6739" -> "  %6742 = add nuw nsw i32 %6740, %6741"
"  %6741 = and i32 %6737, 2147418112"
"  %6741 = and i32 %6737, 2147418112" -> "  %6742 = add nuw nsw i32 %6740, %6741"
"  %6742 = add nuw nsw i32 %6740, %6741"
"  %6742 = add nuw nsw i32 %6740, %6741" -> "  %6750 = add nuw nsw i32 %6742, %6749"
"  %6743 = and i32 %6714, 65535"
"  %6743 = and i32 %6714, 65535" -> "  %6745 = add nuw nsw i32 %6743, %6744"
"  %6744 = and i32 %6725, 65535"
"  %6744 = and i32 %6725, 65535" -> "  %6745 = add nuw nsw i32 %6743, %6744"
"  %6745 = add nuw nsw i32 %6743, %6744"
"  %6745 = add nuw nsw i32 %6743, %6744" -> "  %6815 = and i32 %6745, 65535""  %6745 = add nuw nsw i32 %6743, %6744" -> "  %6751 = lshr i32 %6745, 16"
"  %6746 = and i32 %6722, 65535"
"  %6746 = and i32 %6722, 65535" -> "  %6748 = add nuw nsw i32 %6746, %6747"
"  %6747 = and i32 %6734, 65535"
"  %6747 = and i32 %6734, 65535" -> "  %6748 = add nuw nsw i32 %6746, %6747"
"  %6748 = add nuw nsw i32 %6746, %6747"
"  %6748 = add nuw nsw i32 %6746, %6747" -> "  %6752 = and i32 %6748, 65535""  %6748 = add nuw nsw i32 %6746, %6747" -> "  %6749 = lshr i32 %6748, 16"
"  %6749 = lshr i32 %6748, 16"
"  %6749 = lshr i32 %6748, 16" -> "  %6750 = add nuw nsw i32 %6742, %6749"
"  %6750 = add nuw nsw i32 %6742, %6749"
"  %6750 = add nuw nsw i32 %6742, %6749" -> "  %6755 = add nuw nsw i32 %6750, %6754"
"  %6751 = lshr i32 %6745, 16"
"  %6751 = lshr i32 %6745, 16" -> "  %6753 = add nuw nsw i32 %6752, %6751"
"  %6752 = and i32 %6748, 65535"
"  %6752 = and i32 %6748, 65535" -> "  %6753 = add nuw nsw i32 %6752, %6751"
"  %6753 = add nuw nsw i32 %6752, %6751"
"  %6753 = add nuw nsw i32 %6752, %6751" -> "  %6817 = and i32 %6753, 65535""  %6753 = add nuw nsw i32 %6752, %6751" -> "  %6754 = lshr i32 %6753, 16"
"  %6754 = lshr i32 %6753, 16"
"  %6754 = lshr i32 %6753, 16" -> "  %6755 = add nuw nsw i32 %6750, %6754"
"  %6755 = add nuw nsw i32 %6750, %6754"
"  %6755 = add nuw nsw i32 %6750, %6754" -> "  %6791 = lshr i32 %6755, 16""  %6755 = add nuw nsw i32 %6750, %6754" -> "  %6788 = and i32 %6755, 65535"
"  %6756 = mul nuw nsw i32 %5282, 24315"
"  %6756 = mul nuw nsw i32 %5282, 24315" -> "  %6775 = and i32 %6756, 65535""  %6756 = mul nuw nsw i32 %5282, 24315" -> "  %6757 = lshr i32 %6756, 16"
"  %6757 = lshr i32 %6756, 16"
"  %6757 = lshr i32 %6756, 16" -> "  %6760 = add nuw nsw i32 %6759, %6757"
"  %6758 = mul nuw nsw i32 %5285, 24315"
"  %6758 = mul nuw nsw i32 %5285, 24315" -> "  %6761 = and i32 %6758, 2147418112""  %6758 = mul nuw nsw i32 %5285, 24315" -> "  %6759 = and i32 %6758, 65535"
"  %6759 = and i32 %6758, 65535"
"  %6759 = and i32 %6758, 65535" -> "  %6760 = add nuw nsw i32 %6759, %6757"
"  %6760 = add nuw nsw i32 %6759, %6757"
"  %6760 = add nuw nsw i32 %6759, %6757" -> "  %6762 = add nuw nsw i32 %6760, %6761"
"  %6761 = and i32 %6758, 2147418112"
"  %6761 = and i32 %6758, 2147418112" -> "  %6762 = add nuw nsw i32 %6760, %6761"
"  %6762 = add nuw nsw i32 %6760, %6761"
"  %6762 = add nuw nsw i32 %6760, %6761" -> "  %6766 = lshr i32 %6762, 16""  %6762 = add nuw nsw i32 %6760, %6761" -> "  %6764 = and i32 %6762, 65535"
"  %6763 = mul nuw nsw i32 %5282, 29744"
"  %6763 = mul nuw nsw i32 %5282, 29744" -> "  %6765 = add nuw nsw i32 %6764, %6763"
"  %6764 = and i32 %6762, 65535"
"  %6764 = and i32 %6762, 65535" -> "  %6765 = add nuw nsw i32 %6764, %6763"
"  %6765 = add nuw nsw i32 %6764, %6763"
"  %6765 = add nuw nsw i32 %6764, %6763" -> "  %6777 = and i32 %6765, 65535""  %6765 = add nuw nsw i32 %6764, %6763" -> "  %6769 = lshr i32 %6765, 16"
"  %6766 = lshr i32 %6762, 16"
"  %6766 = lshr i32 %6762, 16" -> "  %6768 = add nuw nsw i32 %6766, %6767"
"  %6767 = mul nuw nsw i32 %5285, 29744"
"  %6767 = mul nuw nsw i32 %5285, 29744" -> "  %6768 = add nuw nsw i32 %6766, %6767"
"  %6768 = add nuw nsw i32 %6766, %6767"
"  %6768 = add nuw nsw i32 %6766, %6767" -> "  %6772 = and i32 %6768, 2147418112""  %6768 = add nuw nsw i32 %6766, %6767" -> "  %6770 = and i32 %6768, 65535"
"  %6769 = lshr i32 %6765, 16"
"  %6769 = lshr i32 %6765, 16" -> "  %6771 = add nuw nsw i32 %6769, %6770"
"  %6770 = and i32 %6768, 65535"
"  %6770 = and i32 %6768, 65535" -> "  %6771 = add nuw nsw i32 %6769, %6770"
"  %6771 = add nuw nsw i32 %6769, %6770"
"  %6771 = add nuw nsw i32 %6769, %6770" -> "  %6773 = add nuw nsw i32 %6771, %6772"
"  %6772 = and i32 %6768, 2147418112"
"  %6772 = and i32 %6768, 2147418112" -> "  %6773 = add nuw nsw i32 %6771, %6772"
"  %6773 = add nuw nsw i32 %6771, %6772"
"  %6773 = add nuw nsw i32 %6771, %6772" -> "  %6781 = add nuw nsw i32 %6773, %6780"
"  %6774 = and i32 %6724, 65535"
"  %6774 = and i32 %6724, 65535" -> "  %6776 = add nuw nsw i32 %6774, %6775"
"  %6775 = and i32 %6756, 65535"
"  %6775 = and i32 %6756, 65535" -> "  %6776 = add nuw nsw i32 %6774, %6775"
"  %6776 = add nuw nsw i32 %6774, %6775"
"  %6776 = add nuw nsw i32 %6774, %6775" -> "  %6787 = and i32 %6776, 65535""  %6776 = add nuw nsw i32 %6774, %6775" -> "  %6783 = lshr i32 %6776, 16"
"  %6777 = and i32 %6765, 65535"
"  %6777 = and i32 %6765, 65535" -> "  %6779 = add nuw nsw i32 %6778, %6777"
"  %6778 = lshr i32 %6724, 16"
"  %6778 = lshr i32 %6724, 16" -> "  %6779 = add nuw nsw i32 %6778, %6777"
"  %6779 = add nuw nsw i32 %6778, %6777"
"  %6779 = add nuw nsw i32 %6778, %6777" -> "  %6782 = and i32 %6779, 65535""  %6779 = add nuw nsw i32 %6778, %6777" -> "  %6780 = lshr i32 %6779, 16"
"  %6780 = lshr i32 %6779, 16"
"  %6780 = lshr i32 %6779, 16" -> "  %6781 = add nuw nsw i32 %6773, %6780"
"  %6781 = add nuw nsw i32 %6773, %6780"
"  %6781 = add nuw nsw i32 %6773, %6780" -> "  %6786 = add nuw nsw i32 %6781, %6785"
"  %6782 = and i32 %6779, 65535"
"  %6782 = and i32 %6779, 65535" -> "  %6784 = add nuw nsw i32 %6782, %6783"
"  %6783 = lshr i32 %6776, 16"
"  %6783 = lshr i32 %6776, 16" -> "  %6784 = add nuw nsw i32 %6782, %6783"
"  %6784 = add nuw nsw i32 %6782, %6783"
"  %6784 = add nuw nsw i32 %6782, %6783" -> "  %6790 = and i32 %6784, 65535""  %6784 = add nuw nsw i32 %6782, %6783" -> "  %6785 = lshr i32 %6784, 16"
"  %6785 = lshr i32 %6784, 16"
"  %6785 = lshr i32 %6784, 16" -> "  %6786 = add nuw nsw i32 %6781, %6785"
"  %6786 = add nuw nsw i32 %6781, %6785"
"  %6786 = add nuw nsw i32 %6781, %6785" -> "  %6799 = and i32 %6786, 2147418112""  %6786 = add nuw nsw i32 %6781, %6785" -> "  %6797 = and i32 %6786, 65535"
"  %6787 = and i32 %6776, 65535"
"  %6787 = and i32 %6776, 65535" -> "  %6789 = add nuw nsw i32 %6788, %6787"
"  %6788 = and i32 %6755, 65535"
"  %6788 = and i32 %6755, 65535" -> "  %6789 = add nuw nsw i32 %6788, %6787"
"  %6789 = add nuw nsw i32 %6788, %6787"
"  %6789 = add nuw nsw i32 %6788, %6787" -> "  %6829 = and i32 %6789, 65535""  %6789 = add nuw nsw i32 %6788, %6787" -> "  %6793 = lshr i32 %6789, 16"
"  %6790 = and i32 %6784, 65535"
"  %6790 = and i32 %6784, 65535" -> "  %6792 = add nuw nsw i32 %6790, %6791"
"  %6791 = lshr i32 %6755, 16"
"  %6791 = lshr i32 %6755, 16" -> "  %6792 = add nuw nsw i32 %6790, %6791"
"  %6792 = add nuw nsw i32 %6790, %6791"
"  %6792 = add nuw nsw i32 %6790, %6791" -> "  %6796 = lshr i32 %6792, 16""  %6792 = add nuw nsw i32 %6790, %6791" -> "  %6794 = and i32 %6792, 65535"
"  %6793 = lshr i32 %6789, 16"
"  %6793 = lshr i32 %6789, 16" -> "  %6795 = add nuw nsw i32 %6794, %6793"
"  %6794 = and i32 %6792, 65535"
"  %6794 = and i32 %6792, 65535" -> "  %6795 = add nuw nsw i32 %6794, %6793"
"  %6795 = add nuw nsw i32 %6794, %6793"
"  %6795 = add nuw nsw i32 %6794, %6793" -> "  %6836 = and i32 %6795, 65535""  %6795 = add nuw nsw i32 %6794, %6793" -> "  %6801 = lshr i32 %6795, 16"
"  %6796 = lshr i32 %6792, 16"
"  %6796 = lshr i32 %6792, 16" -> "  %6798 = add nuw nsw i32 %6796, %6797"
"  %6797 = and i32 %6786, 65535"
"  %6797 = and i32 %6786, 65535" -> "  %6798 = add nuw nsw i32 %6796, %6797"
"  %6798 = add nuw nsw i32 %6796, %6797"
"  %6798 = add nuw nsw i32 %6796, %6797" -> "  %6800 = add nuw nsw i32 %6798, %6799"
"  %6799 = and i32 %6786, 2147418112"
"  %6799 = and i32 %6786, 2147418112" -> "  %6800 = add nuw nsw i32 %6798, %6799"
"  %6800 = add nuw nsw i32 %6798, %6799"
"  %6800 = add nuw nsw i32 %6798, %6799" -> "  %6802 = add nuw nsw i32 %6800, %6801"
"  %6801 = lshr i32 %6795, 16"
"  %6801 = lshr i32 %6795, 16" -> "  %6802 = add nuw nsw i32 %6800, %6801"
"  %6802 = add nuw nsw i32 %6800, %6801"
"  %6802 = add nuw nsw i32 %6800, %6801" -> "  %6840 = add nuw nsw i32 %6802, %6839"
"  %6803 = and i32 %6676, 65535"
"  %6803 = and i32 %6676, 65535" -> "  %6805 = add nuw nsw i32 %6804, %6803"
"  %6804 = and i32 %6662, 65535"
"  %6804 = and i32 %6662, 65535" -> "  %6805 = add nuw nsw i32 %6804, %6803"
"  %6805 = add nuw nsw i32 %6804, %6803"
"  %6805 = add nuw nsw i32 %6804, %6803" -> "  %6969 = and i32 %6805, 65535""  %6805 = add nuw nsw i32 %6804, %6803" -> "  %6809 = lshr i32 %6805, 16"
"  %6806 = and i32 %6685, 65535"
"  %6806 = and i32 %6685, 65535" -> "  %6808 = add nuw nsw i32 %6806, %6807"
"  %6807 = and i32 %6668, 65535"
"  %6807 = and i32 %6668, 65535" -> "  %6808 = add nuw nsw i32 %6806, %6807"
"  %6808 = add nuw nsw i32 %6806, %6807"
"  %6808 = add nuw nsw i32 %6806, %6807" -> "  %6812 = lshr i32 %6808, 16""  %6808 = add nuw nsw i32 %6806, %6807" -> "  %6810 = and i32 %6808, 65535"
"  %6809 = lshr i32 %6805, 16"
"  %6809 = lshr i32 %6805, 16" -> "  %6811 = add nuw nsw i32 %6810, %6809"
"  %6810 = and i32 %6808, 65535"
"  %6810 = and i32 %6808, 65535" -> "  %6811 = add nuw nsw i32 %6810, %6809"
"  %6811 = add nuw nsw i32 %6810, %6809"
"  %6811 = add nuw nsw i32 %6810, %6809" -> "  %6972 = and i32 %6811, 65535""  %6811 = add nuw nsw i32 %6810, %6809" -> "  %6813 = lshr i32 %6811, 16"
"  %6812 = lshr i32 %6808, 16"
"  %6812 = lshr i32 %6808, 16" -> "  %6824 = add nuw nsw i32 %6813, %6812"
"  %6813 = lshr i32 %6811, 16"
"  %6813 = lshr i32 %6811, 16" -> "  %6824 = add nuw nsw i32 %6813, %6812"
"  %6814 = and i32 %6675, 65535"
"  %6814 = and i32 %6675, 65535" -> "  %6816 = add nuw nsw i32 %6815, %6814"
"  %6815 = and i32 %6745, 65535"
"  %6815 = and i32 %6745, 65535" -> "  %6816 = add nuw nsw i32 %6815, %6814"
"  %6816 = add nuw nsw i32 %6815, %6814"
"  %6816 = add nuw nsw i32 %6815, %6814" -> "  %6823 = and i32 %6816, 65535""  %6816 = add nuw nsw i32 %6815, %6814" -> "  %6820 = lshr i32 %6816, 16"
"  %6817 = and i32 %6753, 65535"
"  %6817 = and i32 %6753, 65535" -> "  %6819 = add nuw nsw i32 %6817, %6818"
"  %6818 = lshr i32 %6675, 16"
"  %6818 = lshr i32 %6675, 16" -> "  %6819 = add nuw nsw i32 %6817, %6818"
"  %6819 = add nuw nsw i32 %6817, %6818"
"  %6819 = add nuw nsw i32 %6817, %6818" -> "  %6830 = lshr i32 %6819, 16""  %6819 = add nuw nsw i32 %6817, %6818" -> "  %6821 = and i32 %6819, 65535"
"  %6820 = lshr i32 %6816, 16"
"  %6820 = lshr i32 %6816, 16" -> "  %6822 = add nuw nsw i32 %6821, %6820"
"  %6821 = and i32 %6819, 65535"
"  %6821 = and i32 %6819, 65535" -> "  %6822 = add nuw nsw i32 %6821, %6820"
"  %6822 = add nuw nsw i32 %6821, %6820"
"  %6822 = add nuw nsw i32 %6821, %6820" -> "  %6832 = lshr i32 %6822, 16""  %6822 = add nuw nsw i32 %6821, %6820" -> "  %6827 = and i32 %6822, 65535"
"  %6823 = and i32 %6816, 65535"
"  %6823 = and i32 %6816, 65535" -> "  %6825 = add nuw nsw i32 %6824, %6823"
"  %6824 = add nuw nsw i32 %6813, %6812"
"  %6824 = add nuw nsw i32 %6813, %6812" -> "  %6825 = add nuw nsw i32 %6824, %6823"
"  %6825 = add nuw nsw i32 %6824, %6823"
"  %6825 = add nuw nsw i32 %6824, %6823" -> "  %6979 = and i32 %6825, 65535""  %6825 = add nuw nsw i32 %6824, %6823" -> "  %6826 = lshr i32 %6825, 16"
"  %6826 = lshr i32 %6825, 16"
"  %6826 = lshr i32 %6825, 16" -> "  %6828 = add nuw nsw i32 %6827, %6826"
"  %6827 = and i32 %6822, 65535"
"  %6827 = and i32 %6822, 65535" -> "  %6828 = add nuw nsw i32 %6827, %6826"
"  %6828 = add nuw nsw i32 %6827, %6826"
"  %6828 = add nuw nsw i32 %6827, %6826" -> "  %6983 = and i32 %6828, 65535""  %6828 = add nuw nsw i32 %6827, %6826" -> "  %6834 = lshr i32 %6828, 16"
"  %6829 = and i32 %6789, 65535"
"  %6829 = and i32 %6789, 65535" -> "  %6831 = add nuw nsw i32 %6829, %6830"
"  %6830 = lshr i32 %6819, 16"
"  %6830 = lshr i32 %6819, 16" -> "  %6831 = add nuw nsw i32 %6829, %6830"
"  %6831 = add nuw nsw i32 %6829, %6830"
"  %6831 = add nuw nsw i32 %6829, %6830" -> "  %6833 = add nuw nsw i32 %6831, %6832"
"  %6832 = lshr i32 %6822, 16"
"  %6832 = lshr i32 %6822, 16" -> "  %6833 = add nuw nsw i32 %6831, %6832"
"  %6833 = add nuw nsw i32 %6831, %6832"
"  %6833 = add nuw nsw i32 %6831, %6832" -> "  %6835 = add nuw nsw i32 %6833, %6834"
"  %6834 = lshr i32 %6828, 16"
"  %6834 = lshr i32 %6828, 16" -> "  %6835 = add nuw nsw i32 %6833, %6834"
"  %6835 = add nuw nsw i32 %6833, %6834"
"  %6835 = add nuw nsw i32 %6833, %6834" -> "  %7137 = and i32 %6835, 65535""  %6835 = add nuw nsw i32 %6833, %6834" -> "  %6837 = lshr i32 %6835, 16"
"  %6836 = and i32 %6795, 65535"
"  %6836 = and i32 %6795, 65535" -> "  %6838 = add nuw nsw i32 %6837, %6836"
"  %6837 = lshr i32 %6835, 16"
"  %6837 = lshr i32 %6835, 16" -> "  %6838 = add nuw nsw i32 %6837, %6836"
"  %6838 = add nuw nsw i32 %6837, %6836"
"  %6838 = add nuw nsw i32 %6837, %6836" -> "  %7140 = and i32 %6838, 65535""  %6838 = add nuw nsw i32 %6837, %6836" -> "  %6839 = lshr i32 %6838, 16"
"  %6839 = lshr i32 %6838, 16"
"  %6839 = lshr i32 %6838, 16" -> "  %6840 = add nuw nsw i32 %6802, %6839"
"  %6840 = add nuw nsw i32 %6802, %6839"
"  %6840 = add nuw nsw i32 %6802, %6839" -> "  %7145 = and i32 %6840, 65535""  %6840 = add nuw nsw i32 %6802, %6839" -> "  %7149 = lshr i32 %6840, 16"
"  %6841 = mul nuw nsw i32 %5131, 4087"
"  %6841 = mul nuw nsw i32 %5131, 4087" -> "  %6968 = and i32 %6841, 65535""  %6841 = mul nuw nsw i32 %5131, 4087" -> "  %6842 = lshr i32 %6841, 16"
"  %6842 = lshr i32 %6841, 16"
"  %6842 = lshr i32 %6841, 16" -> "  %6845 = add nuw nsw i32 %6844, %6842"
"  %6843 = mul nuw nsw i32 %5134, 4087"
"  %6843 = mul nuw nsw i32 %5134, 4087" -> "  %6846 = and i32 %6843, 268369920""  %6843 = mul nuw nsw i32 %5134, 4087" -> "  %6844 = and i32 %6843, 65535"
"  %6844 = and i32 %6843, 65535"
"  %6844 = and i32 %6843, 65535" -> "  %6845 = add nuw nsw i32 %6844, %6842"
"  %6845 = add nuw nsw i32 %6844, %6842"
"  %6845 = add nuw nsw i32 %6844, %6842" -> "  %6847 = add nuw nsw i32 %6845, %6846"
"  %6846 = and i32 %6843, 268369920"
"  %6846 = and i32 %6843, 268369920" -> "  %6847 = add nuw nsw i32 %6845, %6846"
"  %6847 = add nuw nsw i32 %6845, %6846"
"  %6847 = add nuw nsw i32 %6845, %6846" -> "  %6851 = lshr i32 %6847, 16""  %6847 = add nuw nsw i32 %6845, %6846" -> "  %6849 = and i32 %6847, 65535"
"  %6848 = mul nuw nsw i32 %5131, 11561"
"  %6848 = mul nuw nsw i32 %5131, 11561" -> "  %6850 = add nuw nsw i32 %6849, %6848"
"  %6849 = and i32 %6847, 65535"
"  %6849 = and i32 %6847, 65535" -> "  %6850 = add nuw nsw i32 %6849, %6848"
"  %6850 = add nuw nsw i32 %6849, %6848"
"  %6850 = add nuw nsw i32 %6849, %6848" -> "  %6971 = and i32 %6850, 65535""  %6850 = add nuw nsw i32 %6849, %6848" -> "  %6854 = lshr i32 %6850, 16"
"  %6851 = lshr i32 %6847, 16"
"  %6851 = lshr i32 %6847, 16" -> "  %6853 = add nuw nsw i32 %6851, %6852"
"  %6852 = mul nuw nsw i32 %5134, 11561"
"  %6852 = mul nuw nsw i32 %5134, 11561" -> "  %6853 = add nuw nsw i32 %6851, %6852"
"  %6853 = add nuw nsw i32 %6851, %6852"
"  %6853 = add nuw nsw i32 %6851, %6852" -> "  %6857 = and i32 %6853, 2147418112""  %6853 = add nuw nsw i32 %6851, %6852" -> "  %6855 = and i32 %6853, 65535"
"  %6854 = lshr i32 %6850, 16"
"  %6854 = lshr i32 %6850, 16" -> "  %6856 = add nuw nsw i32 %6854, %6855"
"  %6855 = and i32 %6853, 65535"
"  %6855 = and i32 %6853, 65535" -> "  %6856 = add nuw nsw i32 %6854, %6855"
"  %6856 = add nuw nsw i32 %6854, %6855"
"  %6856 = add nuw nsw i32 %6854, %6855" -> "  %6858 = add nuw nsw i32 %6856, %6857"
"  %6857 = and i32 %6853, 2147418112"
"  %6857 = and i32 %6853, 2147418112" -> "  %6858 = add nuw nsw i32 %6856, %6857"
"  %6858 = add nuw nsw i32 %6856, %6857"
"  %6858 = add nuw nsw i32 %6856, %6857" -> "  %6881 = lshr i32 %6858, 16""  %6858 = add nuw nsw i32 %6856, %6857" -> "  %6877 = and i32 %6858, 65535"
"  %6859 = mul nuw nsw i32 %5151, 4087"
"  %6859 = mul nuw nsw i32 %5151, 4087" -> "  %6878 = and i32 %6859, 65535""  %6859 = mul nuw nsw i32 %5151, 4087" -> "  %6860 = lshr i32 %6859, 16"
"  %6860 = lshr i32 %6859, 16"
"  %6860 = lshr i32 %6859, 16" -> "  %6863 = add nuw nsw i32 %6862, %6860"
"  %6861 = mul nuw nsw i32 %5152, 4087"
"  %6861 = mul nuw nsw i32 %5152, 4087" -> "  %6864 = and i32 %6861, 268369920""  %6861 = mul nuw nsw i32 %5152, 4087" -> "  %6862 = and i32 %6861, 65535"
"  %6862 = and i32 %6861, 65535"
"  %6862 = and i32 %6861, 65535" -> "  %6863 = add nuw nsw i32 %6862, %6860"
"  %6863 = add nuw nsw i32 %6862, %6860"
"  %6863 = add nuw nsw i32 %6862, %6860" -> "  %6865 = add nuw nsw i32 %6863, %6864"
"  %6864 = and i32 %6861, 268369920"
"  %6864 = and i32 %6861, 268369920" -> "  %6865 = add nuw nsw i32 %6863, %6864"
"  %6865 = add nuw nsw i32 %6863, %6864"
"  %6865 = add nuw nsw i32 %6863, %6864" -> "  %6869 = lshr i32 %6865, 16""  %6865 = add nuw nsw i32 %6863, %6864" -> "  %6867 = and i32 %6865, 65535"
"  %6866 = mul nuw nsw i32 %5151, 11561"
"  %6866 = mul nuw nsw i32 %5151, 11561" -> "  %6868 = add nuw nsw i32 %6867, %6866"
"  %6867 = and i32 %6865, 65535"
"  %6867 = and i32 %6865, 65535" -> "  %6868 = add nuw nsw i32 %6867, %6866"
"  %6868 = add nuw nsw i32 %6867, %6866"
"  %6868 = add nuw nsw i32 %6867, %6866" -> "  %6880 = and i32 %6868, 65535""  %6868 = add nuw nsw i32 %6867, %6866" -> "  %6872 = lshr i32 %6868, 16"
"  %6869 = lshr i32 %6865, 16"
"  %6869 = lshr i32 %6865, 16" -> "  %6871 = add nuw nsw i32 %6869, %6870"
"  %6870 = mul nuw nsw i32 %5152, 11561"
"  %6870 = mul nuw nsw i32 %5152, 11561" -> "  %6871 = add nuw nsw i32 %6869, %6870"
"  %6871 = add nuw nsw i32 %6869, %6870"
"  %6871 = add nuw nsw i32 %6869, %6870" -> "  %6875 = and i32 %6871, 2147418112""  %6871 = add nuw nsw i32 %6869, %6870" -> "  %6873 = and i32 %6871, 65535"
"  %6872 = lshr i32 %6868, 16"
"  %6872 = lshr i32 %6868, 16" -> "  %6874 = add nuw nsw i32 %6872, %6873"
"  %6873 = and i32 %6871, 65535"
"  %6873 = and i32 %6871, 65535" -> "  %6874 = add nuw nsw i32 %6872, %6873"
"  %6874 = add nuw nsw i32 %6872, %6873"
"  %6874 = add nuw nsw i32 %6872, %6873" -> "  %6876 = add nuw nsw i32 %6874, %6875"
"  %6875 = and i32 %6871, 2147418112"
"  %6875 = and i32 %6871, 2147418112" -> "  %6876 = add nuw nsw i32 %6874, %6875"
"  %6876 = add nuw nsw i32 %6874, %6875"
"  %6876 = add nuw nsw i32 %6874, %6875" -> "  %6884 = add nuw nsw i32 %6876, %6883"
"  %6877 = and i32 %6858, 65535"
"  %6877 = and i32 %6858, 65535" -> "  %6879 = add nuw nsw i32 %6877, %6878"
"  %6878 = and i32 %6859, 65535"
"  %6878 = and i32 %6859, 65535" -> "  %6879 = add nuw nsw i32 %6877, %6878"
"  %6879 = add nuw nsw i32 %6877, %6878"
"  %6879 = add nuw nsw i32 %6877, %6878" -> "  %6908 = and i32 %6879, 65535""  %6879 = add nuw nsw i32 %6877, %6878" -> "  %6886 = lshr i32 %6879, 16"
"  %6880 = and i32 %6868, 65535"
"  %6880 = and i32 %6868, 65535" -> "  %6882 = add nuw nsw i32 %6880, %6881"
"  %6881 = lshr i32 %6858, 16"
"  %6881 = lshr i32 %6858, 16" -> "  %6882 = add nuw nsw i32 %6880, %6881"
"  %6882 = add nuw nsw i32 %6880, %6881"
"  %6882 = add nuw nsw i32 %6880, %6881" -> "  %6885 = and i32 %6882, 65535""  %6882 = add nuw nsw i32 %6880, %6881" -> "  %6883 = lshr i32 %6882, 16"
"  %6883 = lshr i32 %6882, 16"
"  %6883 = lshr i32 %6882, 16" -> "  %6884 = add nuw nsw i32 %6876, %6883"
"  %6884 = add nuw nsw i32 %6876, %6883"
"  %6884 = add nuw nsw i32 %6876, %6883" -> "  %6889 = add nuw nsw i32 %6884, %6888"
"  %6885 = and i32 %6882, 65535"
"  %6885 = and i32 %6882, 65535" -> "  %6887 = add nuw nsw i32 %6885, %6886"
"  %6886 = lshr i32 %6879, 16"
"  %6886 = lshr i32 %6879, 16" -> "  %6887 = add nuw nsw i32 %6885, %6886"
"  %6887 = add nuw nsw i32 %6885, %6886"
"  %6887 = add nuw nsw i32 %6885, %6886" -> "  %6911 = and i32 %6887, 65535""  %6887 = add nuw nsw i32 %6885, %6886" -> "  %6888 = lshr i32 %6887, 16"
"  %6888 = lshr i32 %6887, 16"
"  %6888 = lshr i32 %6887, 16" -> "  %6889 = add nuw nsw i32 %6884, %6888"
"  %6889 = add nuw nsw i32 %6884, %6888"
"  %6889 = add nuw nsw i32 %6884, %6888" -> "  %6939 = and i32 %6889, 65535""  %6889 = add nuw nsw i32 %6884, %6888" -> "  %6943 = lshr i32 %6889, 16"
"  %6890 = mul nuw nsw i32 %5131, 21884"
"  %6890 = mul nuw nsw i32 %5131, 21884" -> "  %6909 = and i32 %6890, 65532""  %6890 = mul nuw nsw i32 %5131, 21884" -> "  %6891 = lshr i32 %6890, 16"
"  %6891 = lshr i32 %6890, 16"
"  %6891 = lshr i32 %6890, 16" -> "  %6894 = add nuw nsw i32 %6893, %6891"
"  %6892 = mul nuw nsw i32 %5134, 21884"
"  %6892 = mul nuw nsw i32 %5134, 21884" -> "  %6895 = and i32 %6892, 2147418112""  %6892 = mul nuw nsw i32 %5134, 21884" -> "  %6893 = and i32 %6892, 65532"
"  %6893 = and i32 %6892, 65532"
"  %6893 = and i32 %6892, 65532" -> "  %6894 = add nuw nsw i32 %6893, %6891"
"  %6894 = add nuw nsw i32 %6893, %6891"
"  %6894 = add nuw nsw i32 %6893, %6891" -> "  %6896 = add nuw nsw i32 %6894, %6895"
"  %6895 = and i32 %6892, 2147418112"
"  %6895 = and i32 %6892, 2147418112" -> "  %6896 = add nuw nsw i32 %6894, %6895"
"  %6896 = add nuw nsw i32 %6894, %6895"
"  %6896 = add nuw nsw i32 %6894, %6895" -> "  %6900 = lshr i32 %6896, 16""  %6896 = add nuw nsw i32 %6894, %6895" -> "  %6898 = and i32 %6896, 65535"
"  %6897 = mul nuw i32 %5131, 36786"
"  %6897 = mul nuw i32 %5131, 36786" -> "  %6899 = add nuw i32 %6898, %6897"
"  %6898 = and i32 %6896, 65535"
"  %6898 = and i32 %6896, 65535" -> "  %6899 = add nuw i32 %6898, %6897"
"  %6899 = add nuw i32 %6898, %6897"
"  %6899 = add nuw i32 %6898, %6897" -> "  %6912 = and i32 %6899, 65535""  %6899 = add nuw i32 %6898, %6897" -> "  %6903 = lshr i32 %6899, 16"
"  %6900 = lshr i32 %6896, 16"
"  %6900 = lshr i32 %6896, 16" -> "  %6902 = add nuw i32 %6900, %6901"
"  %6901 = mul nuw i32 %5134, 36786"
"  %6901 = mul nuw i32 %5134, 36786" -> "  %6902 = add nuw i32 %6900, %6901"
"  %6902 = add nuw i32 %6900, %6901"
"  %6902 = add nuw i32 %6900, %6901" -> "  %6906 = and i32 %6902, -65536""  %6902 = add nuw i32 %6900, %6901" -> "  %6904 = and i32 %6902, 65535"
"  %6903 = lshr i32 %6899, 16"
"  %6903 = lshr i32 %6899, 16" -> "  %6905 = add nuw nsw i32 %6903, %6904"
"  %6904 = and i32 %6902, 65535"
"  %6904 = and i32 %6902, 65535" -> "  %6905 = add nuw nsw i32 %6903, %6904"
"  %6905 = add nuw nsw i32 %6903, %6904"
"  %6905 = add nuw nsw i32 %6903, %6904" -> "  %6907 = add nuw i32 %6905, %6906"
"  %6906 = and i32 %6902, -65536"
"  %6906 = and i32 %6902, -65536" -> "  %6907 = add nuw i32 %6905, %6906"
"  %6907 = add nuw i32 %6905, %6906"
"  %6907 = add nuw i32 %6905, %6906" -> "  %6915 = add nuw i32 %6907, %6914"
"  %6908 = and i32 %6879, 65535"
"  %6908 = and i32 %6879, 65535" -> "  %6910 = add nuw nsw i32 %6908, %6909"
"  %6909 = and i32 %6890, 65532"
"  %6909 = and i32 %6890, 65532" -> "  %6910 = add nuw nsw i32 %6908, %6909"
"  %6910 = add nuw nsw i32 %6908, %6909"
"  %6910 = add nuw nsw i32 %6908, %6909" -> "  %6980 = and i32 %6910, 65535""  %6910 = add nuw nsw i32 %6908, %6909" -> "  %6916 = lshr i32 %6910, 16"
"  %6911 = and i32 %6887, 65535"
"  %6911 = and i32 %6887, 65535" -> "  %6913 = add nuw nsw i32 %6911, %6912"
"  %6912 = and i32 %6899, 65535"
"  %6912 = and i32 %6899, 65535" -> "  %6913 = add nuw nsw i32 %6911, %6912"
"  %6913 = add nuw nsw i32 %6911, %6912"
"  %6913 = add nuw nsw i32 %6911, %6912" -> "  %6917 = and i32 %6913, 65535""  %6913 = add nuw nsw i32 %6911, %6912" -> "  %6914 = lshr i32 %6913, 16"
"  %6914 = lshr i32 %6913, 16"
"  %6914 = lshr i32 %6913, 16" -> "  %6915 = add nuw i32 %6907, %6914"
"  %6915 = add nuw i32 %6907, %6914"
"  %6915 = add nuw i32 %6907, %6914" -> "  %6920 = add nuw i32 %6915, %6919"
"  %6916 = lshr i32 %6910, 16"
"  %6916 = lshr i32 %6910, 16" -> "  %6918 = add nuw nsw i32 %6917, %6916"
"  %6917 = and i32 %6913, 65535"
"  %6917 = and i32 %6913, 65535" -> "  %6918 = add nuw nsw i32 %6917, %6916"
"  %6918 = add nuw nsw i32 %6917, %6916"
"  %6918 = add nuw nsw i32 %6917, %6916" -> "  %6982 = and i32 %6918, 65535""  %6918 = add nuw nsw i32 %6917, %6916" -> "  %6919 = lshr i32 %6918, 16"
"  %6919 = lshr i32 %6918, 16"
"  %6919 = lshr i32 %6918, 16" -> "  %6920 = add nuw i32 %6915, %6919"
"  %6920 = add nuw i32 %6915, %6919"
"  %6920 = add nuw i32 %6915, %6919" -> "  %6956 = lshr i32 %6920, 16""  %6920 = add nuw i32 %6915, %6919" -> "  %6953 = and i32 %6920, 65535"
"  %6921 = mul nuw nsw i32 %5151, 21884"
"  %6921 = mul nuw nsw i32 %5151, 21884" -> "  %6940 = and i32 %6921, 65532""  %6921 = mul nuw nsw i32 %5151, 21884" -> "  %6922 = lshr i32 %6921, 16"
"  %6922 = lshr i32 %6921, 16"
"  %6922 = lshr i32 %6921, 16" -> "  %6925 = add nuw nsw i32 %6924, %6922"
"  %6923 = mul nuw nsw i32 %5152, 21884"
"  %6923 = mul nuw nsw i32 %5152, 21884" -> "  %6926 = and i32 %6923, 2147418112""  %6923 = mul nuw nsw i32 %5152, 21884" -> "  %6924 = and i32 %6923, 65532"
"  %6924 = and i32 %6923, 65532"
"  %6924 = and i32 %6923, 65532" -> "  %6925 = add nuw nsw i32 %6924, %6922"
"  %6925 = add nuw nsw i32 %6924, %6922"
"  %6925 = add nuw nsw i32 %6924, %6922" -> "  %6927 = add nuw nsw i32 %6925, %6926"
"  %6926 = and i32 %6923, 2147418112"
"  %6926 = and i32 %6923, 2147418112" -> "  %6927 = add nuw nsw i32 %6925, %6926"
"  %6927 = add nuw nsw i32 %6925, %6926"
"  %6927 = add nuw nsw i32 %6925, %6926" -> "  %6931 = lshr i32 %6927, 16""  %6927 = add nuw nsw i32 %6925, %6926" -> "  %6929 = and i32 %6927, 65535"
"  %6928 = mul nuw i32 %5151, 36786"
"  %6928 = mul nuw i32 %5151, 36786" -> "  %6930 = add nuw i32 %6929, %6928"
"  %6929 = and i32 %6927, 65535"
"  %6929 = and i32 %6927, 65535" -> "  %6930 = add nuw i32 %6929, %6928"
"  %6930 = add nuw i32 %6929, %6928"
"  %6930 = add nuw i32 %6929, %6928" -> "  %6942 = and i32 %6930, 65535""  %6930 = add nuw i32 %6929, %6928" -> "  %6934 = lshr i32 %6930, 16"
"  %6931 = lshr i32 %6927, 16"
"  %6931 = lshr i32 %6927, 16" -> "  %6933 = add nuw i32 %6931, %6932"
"  %6932 = mul nuw i32 %5152, 36786"
"  %6932 = mul nuw i32 %5152, 36786" -> "  %6933 = add nuw i32 %6931, %6932"
"  %6933 = add nuw i32 %6931, %6932"
"  %6933 = add nuw i32 %6931, %6932" -> "  %6937 = and i32 %6933, -65536""  %6933 = add nuw i32 %6931, %6932" -> "  %6935 = and i32 %6933, 65535"
"  %6934 = lshr i32 %6930, 16"
"  %6934 = lshr i32 %6930, 16" -> "  %6936 = add nuw nsw i32 %6934, %6935"
"  %6935 = and i32 %6933, 65535"
"  %6935 = and i32 %6933, 65535" -> "  %6936 = add nuw nsw i32 %6934, %6935"
"  %6936 = add nuw nsw i32 %6934, %6935"
"  %6936 = add nuw nsw i32 %6934, %6935" -> "  %6938 = add nuw i32 %6936, %6937"
"  %6937 = and i32 %6933, -65536"
"  %6937 = and i32 %6933, -65536" -> "  %6938 = add nuw i32 %6936, %6937"
"  %6938 = add nuw i32 %6936, %6937"
"  %6938 = add nuw i32 %6936, %6937" -> "  %6946 = add nuw i32 %6938, %6945"
"  %6939 = and i32 %6889, 65535"
"  %6939 = and i32 %6889, 65535" -> "  %6941 = add nuw nsw i32 %6939, %6940"
"  %6940 = and i32 %6921, 65532"
"  %6940 = and i32 %6921, 65532" -> "  %6941 = add nuw nsw i32 %6939, %6940"
"  %6941 = add nuw nsw i32 %6939, %6940"
"  %6941 = add nuw nsw i32 %6939, %6940" -> "  %6952 = and i32 %6941, 65535""  %6941 = add nuw nsw i32 %6939, %6940" -> "  %6948 = lshr i32 %6941, 16"
"  %6942 = and i32 %6930, 65535"
"  %6942 = and i32 %6930, 65535" -> "  %6944 = add nuw nsw i32 %6943, %6942"
"  %6943 = lshr i32 %6889, 16"
"  %6943 = lshr i32 %6889, 16" -> "  %6944 = add nuw nsw i32 %6943, %6942"
"  %6944 = add nuw nsw i32 %6943, %6942"
"  %6944 = add nuw nsw i32 %6943, %6942" -> "  %6947 = and i32 %6944, 65535""  %6944 = add nuw nsw i32 %6943, %6942" -> "  %6945 = lshr i32 %6944, 16"
"  %6945 = lshr i32 %6944, 16"
"  %6945 = lshr i32 %6944, 16" -> "  %6946 = add nuw i32 %6938, %6945"
"  %6946 = add nuw i32 %6938, %6945"
"  %6946 = add nuw i32 %6938, %6945" -> "  %6951 = add nuw i32 %6946, %6950"
"  %6947 = and i32 %6944, 65535"
"  %6947 = and i32 %6944, 65535" -> "  %6949 = add nuw nsw i32 %6947, %6948"
"  %6948 = lshr i32 %6941, 16"
"  %6948 = lshr i32 %6941, 16" -> "  %6949 = add nuw nsw i32 %6947, %6948"
"  %6949 = add nuw nsw i32 %6947, %6948"
"  %6949 = add nuw nsw i32 %6947, %6948" -> "  %6955 = and i32 %6949, 65535""  %6949 = add nuw nsw i32 %6947, %6948" -> "  %6950 = lshr i32 %6949, 16"
"  %6950 = lshr i32 %6949, 16"
"  %6950 = lshr i32 %6949, 16" -> "  %6951 = add nuw i32 %6946, %6950"
"  %6951 = add nuw i32 %6946, %6950"
"  %6951 = add nuw i32 %6946, %6950" -> "  %6964 = and i32 %6951, -65536""  %6951 = add nuw i32 %6946, %6950" -> "  %6962 = and i32 %6951, 65535"
"  %6952 = and i32 %6941, 65535"
"  %6952 = and i32 %6941, 65535" -> "  %6954 = add nuw nsw i32 %6953, %6952"
"  %6953 = and i32 %6920, 65535"
"  %6953 = and i32 %6920, 65535" -> "  %6954 = add nuw nsw i32 %6953, %6952"
"  %6954 = add nuw nsw i32 %6953, %6952"
"  %6954 = add nuw nsw i32 %6953, %6952" -> "  %6994 = and i32 %6954, 65535""  %6954 = add nuw nsw i32 %6953, %6952" -> "  %6958 = lshr i32 %6954, 16"
"  %6955 = and i32 %6949, 65535"
"  %6955 = and i32 %6949, 65535" -> "  %6957 = add nuw nsw i32 %6955, %6956"
"  %6956 = lshr i32 %6920, 16"
"  %6956 = lshr i32 %6920, 16" -> "  %6957 = add nuw nsw i32 %6955, %6956"
"  %6957 = add nuw nsw i32 %6955, %6956"
"  %6957 = add nuw nsw i32 %6955, %6956" -> "  %6961 = lshr i32 %6957, 16""  %6957 = add nuw nsw i32 %6955, %6956" -> "  %6959 = and i32 %6957, 65535"
"  %6958 = lshr i32 %6954, 16"
"  %6958 = lshr i32 %6954, 16" -> "  %6960 = add nuw nsw i32 %6959, %6958"
"  %6959 = and i32 %6957, 65535"
"  %6959 = and i32 %6957, 65535" -> "  %6960 = add nuw nsw i32 %6959, %6958"
"  %6960 = add nuw nsw i32 %6959, %6958"
"  %6960 = add nuw nsw i32 %6959, %6958" -> "  %7001 = and i32 %6960, 65535""  %6960 = add nuw nsw i32 %6959, %6958" -> "  %6966 = lshr i32 %6960, 16"
"  %6961 = lshr i32 %6957, 16"
"  %6961 = lshr i32 %6957, 16" -> "  %6963 = add nuw nsw i32 %6961, %6962"
"  %6962 = and i32 %6951, 65535"
"  %6962 = and i32 %6951, 65535" -> "  %6963 = add nuw nsw i32 %6961, %6962"
"  %6963 = add nuw nsw i32 %6961, %6962"
"  %6963 = add nuw nsw i32 %6961, %6962" -> "  %6965 = add nuw i32 %6963, %6964"
"  %6964 = and i32 %6951, -65536"
"  %6964 = and i32 %6951, -65536" -> "  %6965 = add nuw i32 %6963, %6964"
"  %6965 = add nuw i32 %6963, %6964"
"  %6965 = add nuw i32 %6963, %6964" -> "  %6967 = add nuw i32 %6965, %6966"
"  %6966 = lshr i32 %6960, 16"
"  %6966 = lshr i32 %6960, 16" -> "  %6967 = add nuw i32 %6965, %6966"
"  %6967 = add nuw i32 %6965, %6966"
"  %6967 = add nuw i32 %6965, %6966" -> "  %7005 = add nuw i32 %6967, %7004"
"  %6968 = and i32 %6841, 65535"
"  %6968 = and i32 %6841, 65535" -> "  %6970 = add nuw nsw i32 %6969, %6968"
"  %6969 = and i32 %6805, 65535"
"  %6969 = and i32 %6805, 65535" -> "  %6970 = add nuw nsw i32 %6969, %6968"
"  %6970 = add nuw nsw i32 %6969, %6968"
"  %6970 = add nuw nsw i32 %6969, %6968" -> "  %7239 = and i32 %6970, 65535""  %6970 = add nuw nsw i32 %6969, %6968" -> "  %6974 = lshr i32 %6970, 16"
"  %6971 = and i32 %6850, 65535"
"  %6971 = and i32 %6850, 65535" -> "  %6973 = add nuw nsw i32 %6972, %6971"
"  %6972 = and i32 %6811, 65535"
"  %6972 = and i32 %6811, 65535" -> "  %6973 = add nuw nsw i32 %6972, %6971"
"  %6973 = add nuw nsw i32 %6972, %6971"
"  %6973 = add nuw nsw i32 %6972, %6971" -> "  %6977 = lshr i32 %6973, 16""  %6973 = add nuw nsw i32 %6972, %6971" -> "  %6975 = and i32 %6973, 65535"
"  %6974 = lshr i32 %6970, 16"
"  %6974 = lshr i32 %6970, 16" -> "  %6976 = add nuw nsw i32 %6975, %6974"
"  %6975 = and i32 %6973, 65535"
"  %6975 = and i32 %6973, 65535" -> "  %6976 = add nuw nsw i32 %6975, %6974"
"  %6976 = add nuw nsw i32 %6975, %6974"
"  %6976 = add nuw nsw i32 %6975, %6974" -> "  %7242 = and i32 %6976, 65535""  %6976 = add nuw nsw i32 %6975, %6974" -> "  %6978 = lshr i32 %6976, 16"
"  %6977 = lshr i32 %6973, 16"
"  %6977 = lshr i32 %6973, 16" -> "  %6989 = add nuw nsw i32 %6978, %6977"
"  %6978 = lshr i32 %6976, 16"
"  %6978 = lshr i32 %6976, 16" -> "  %6989 = add nuw nsw i32 %6978, %6977"
"  %6979 = and i32 %6825, 65535"
"  %6979 = and i32 %6825, 65535" -> "  %6981 = add nuw nsw i32 %6979, %6980"
"  %6980 = and i32 %6910, 65535"
"  %6980 = and i32 %6910, 65535" -> "  %6981 = add nuw nsw i32 %6979, %6980"
"  %6981 = add nuw nsw i32 %6979, %6980"
"  %6981 = add nuw nsw i32 %6979, %6980" -> "  %6988 = and i32 %6981, 65535""  %6981 = add nuw nsw i32 %6979, %6980" -> "  %6985 = lshr i32 %6981, 16"
"  %6982 = and i32 %6918, 65535"
"  %6982 = and i32 %6918, 65535" -> "  %6984 = add nuw nsw i32 %6983, %6982"
"  %6983 = and i32 %6828, 65535"
"  %6983 = and i32 %6828, 65535" -> "  %6984 = add nuw nsw i32 %6983, %6982"
"  %6984 = add nuw nsw i32 %6983, %6982"
"  %6984 = add nuw nsw i32 %6983, %6982" -> "  %6995 = lshr i32 %6984, 16""  %6984 = add nuw nsw i32 %6983, %6982" -> "  %6986 = and i32 %6984, 65535"
"  %6985 = lshr i32 %6981, 16"
"  %6985 = lshr i32 %6981, 16" -> "  %6987 = add nuw nsw i32 %6986, %6985"
"  %6986 = and i32 %6984, 65535"
"  %6986 = and i32 %6984, 65535" -> "  %6987 = add nuw nsw i32 %6986, %6985"
"  %6987 = add nuw nsw i32 %6986, %6985"
"  %6987 = add nuw nsw i32 %6986, %6985" -> "  %6997 = lshr i32 %6987, 16""  %6987 = add nuw nsw i32 %6986, %6985" -> "  %6992 = and i32 %6987, 65535"
"  %6988 = and i32 %6981, 65535"
"  %6988 = and i32 %6981, 65535" -> "  %6990 = add nuw nsw i32 %6989, %6988"
"  %6989 = add nuw nsw i32 %6978, %6977"
"  %6989 = add nuw nsw i32 %6978, %6977" -> "  %6990 = add nuw nsw i32 %6989, %6988"
"  %6990 = add nuw nsw i32 %6989, %6988"
"  %6990 = add nuw nsw i32 %6989, %6988" -> "  %7251 = and i32 %6990, 65535""  %6990 = add nuw nsw i32 %6989, %6988" -> "  %6991 = lshr i32 %6990, 16"
"  %6991 = lshr i32 %6990, 16"
"  %6991 = lshr i32 %6990, 16" -> "  %6993 = add nuw nsw i32 %6992, %6991"
"  %6992 = and i32 %6987, 65535"
"  %6992 = and i32 %6987, 65535" -> "  %6993 = add nuw nsw i32 %6992, %6991"
"  %6993 = add nuw nsw i32 %6992, %6991"
"  %6993 = add nuw nsw i32 %6992, %6991" -> "  %7254 = and i32 %6993, 65535""  %6993 = add nuw nsw i32 %6992, %6991" -> "  %6999 = lshr i32 %6993, 16"
"  %6994 = and i32 %6954, 65535"
"  %6994 = and i32 %6954, 65535" -> "  %6996 = add nuw nsw i32 %6995, %6994"
"  %6995 = lshr i32 %6984, 16"
"  %6995 = lshr i32 %6984, 16" -> "  %6996 = add nuw nsw i32 %6995, %6994"
"  %6996 = add nuw nsw i32 %6995, %6994"
"  %6996 = add nuw nsw i32 %6995, %6994" -> "  %6998 = add nuw nsw i32 %6996, %6997"
"  %6997 = lshr i32 %6987, 16"
"  %6997 = lshr i32 %6987, 16" -> "  %6998 = add nuw nsw i32 %6996, %6997"
"  %6998 = add nuw nsw i32 %6996, %6997"
"  %6998 = add nuw nsw i32 %6996, %6997" -> "  %7000 = add nuw nsw i32 %6998, %6999"
"  %6999 = lshr i32 %6993, 16"
"  %6999 = lshr i32 %6993, 16" -> "  %7000 = add nuw nsw i32 %6998, %6999"
"  %7000 = add nuw nsw i32 %6998, %6999"
"  %7000 = add nuw nsw i32 %6998, %6999" -> "  %7175 = and i32 %7000, 65535""  %7000 = add nuw nsw i32 %6998, %6999" -> "  %7002 = lshr i32 %7000, 16"
"  %7001 = and i32 %6960, 65535"
"  %7001 = and i32 %6960, 65535" -> "  %7003 = add nuw nsw i32 %7002, %7001"
"  %7002 = lshr i32 %7000, 16"
"  %7002 = lshr i32 %7000, 16" -> "  %7003 = add nuw nsw i32 %7002, %7001"
"  %7003 = add nuw nsw i32 %7002, %7001"
"  %7003 = add nuw nsw i32 %7002, %7001" -> "  %7178 = and i32 %7003, 65535""  %7003 = add nuw nsw i32 %7002, %7001" -> "  %7004 = lshr i32 %7003, 16"
"  %7004 = lshr i32 %7003, 16"
"  %7004 = lshr i32 %7003, 16" -> "  %7005 = add nuw i32 %6967, %7004"
"  %7005 = add nuw i32 %6967, %7004"
"  %7005 = add nuw i32 %6967, %7004" -> "  %7184 = and i32 %7005, 65535""  %7005 = add nuw i32 %6967, %7004" -> "  %7187 = lshr i32 %7005, 16"
"  %7006 = mul nuw nsw i32 %5262, 4087"
"  %7006 = mul nuw nsw i32 %5262, 4087" -> "  %7136 = and i32 %7006, 65535""  %7006 = mul nuw nsw i32 %5262, 4087" -> "  %7010 = lshr i32 %7006, 16"
"  %7007 = add i64 %18, -76"
"  %7007 = add i64 %18, -76" -> "  %7008 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %7007"
"  %7008 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %7007"
"  %7008 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %7007" -> "  %7009 = bitcast i8* %7008 to i32*"
"  %7009 = bitcast i8* %7008 to i32*"
"  %7009 = bitcast i8* %7008 to i32*" -> "  store i32 %15052, i32* %7009, align 1, !noalias !32"
"  %7010 = lshr i32 %7006, 16"
"  %7010 = lshr i32 %7006, 16" -> "  %7013 = add nuw nsw i32 %7012, %7010"
"  %7011 = mul nuw nsw i32 %5265, 4087"
"  %7011 = mul nuw nsw i32 %5265, 4087" -> "  %7014 = and i32 %7011, 268369920""  %7011 = mul nuw nsw i32 %5265, 4087" -> "  %7012 = and i32 %7011, 65535"
"  %7012 = and i32 %7011, 65535"
"  %7012 = and i32 %7011, 65535" -> "  %7013 = add nuw nsw i32 %7012, %7010"
"  %7013 = add nuw nsw i32 %7012, %7010"
"  %7013 = add nuw nsw i32 %7012, %7010" -> "  %7015 = add nuw nsw i32 %7013, %7014"
"  %7014 = and i32 %7011, 268369920"
"  %7014 = and i32 %7011, 268369920" -> "  %7015 = add nuw nsw i32 %7013, %7014"
"  %7015 = add nuw nsw i32 %7013, %7014"
"  %7015 = add nuw nsw i32 %7013, %7014" -> "  %7019 = lshr i32 %7015, 16""  %7015 = add nuw nsw i32 %7013, %7014" -> "  %7017 = and i32 %7015, 65535"
"  %7016 = mul nuw nsw i32 %5262, 11561"
"  %7016 = mul nuw nsw i32 %5262, 11561" -> "  %7018 = add nuw nsw i32 %7017, %7016"
"  %7017 = and i32 %7015, 65535"
"  %7017 = and i32 %7015, 65535" -> "  %7018 = add nuw nsw i32 %7017, %7016"
"  %7018 = add nuw nsw i32 %7017, %7016"
"  %7018 = add nuw nsw i32 %7017, %7016" -> "  %7139 = and i32 %7018, 65535""  %7018 = add nuw nsw i32 %7017, %7016" -> "  %7022 = lshr i32 %7018, 16"
"  %7019 = lshr i32 %7015, 16"
"  %7019 = lshr i32 %7015, 16" -> "  %7021 = add nuw nsw i32 %7019, %7020"
"  %7020 = mul nuw nsw i32 %5265, 11561"
"  %7020 = mul nuw nsw i32 %5265, 11561" -> "  %7021 = add nuw nsw i32 %7019, %7020"
"  %7021 = add nuw nsw i32 %7019, %7020"
"  %7021 = add nuw nsw i32 %7019, %7020" -> "  %7025 = and i32 %7021, 2147418112""  %7021 = add nuw nsw i32 %7019, %7020" -> "  %7023 = and i32 %7021, 65535"
"  %7022 = lshr i32 %7018, 16"
"  %7022 = lshr i32 %7018, 16" -> "  %7024 = add nuw nsw i32 %7022, %7023"
"  %7023 = and i32 %7021, 65535"
"  %7023 = and i32 %7021, 65535" -> "  %7024 = add nuw nsw i32 %7022, %7023"
"  %7024 = add nuw nsw i32 %7022, %7023"
"  %7024 = add nuw nsw i32 %7022, %7023" -> "  %7026 = add nuw nsw i32 %7024, %7025"
"  %7025 = and i32 %7021, 2147418112"
"  %7025 = and i32 %7021, 2147418112" -> "  %7026 = add nuw nsw i32 %7024, %7025"
"  %7026 = add nuw nsw i32 %7024, %7025"
"  %7026 = add nuw nsw i32 %7024, %7025" -> "  %7049 = lshr i32 %7026, 16""  %7026 = add nuw nsw i32 %7024, %7025" -> "  %7045 = and i32 %7026, 65535"
"  %7027 = mul nuw nsw i32 %5282, 4087"
"  %7027 = mul nuw nsw i32 %5282, 4087" -> "  %7046 = and i32 %7027, 65535""  %7027 = mul nuw nsw i32 %5282, 4087" -> "  %7028 = lshr i32 %7027, 16"
"  %7028 = lshr i32 %7027, 16"
"  %7028 = lshr i32 %7027, 16" -> "  %7031 = add nuw nsw i32 %7030, %7028"
"  %7029 = mul nuw nsw i32 %5285, 4087"
"  %7029 = mul nuw nsw i32 %5285, 4087" -> "  %7032 = and i32 %7029, 268369920""  %7029 = mul nuw nsw i32 %5285, 4087" -> "  %7030 = and i32 %7029, 65535"
"  %7030 = and i32 %7029, 65535"
"  %7030 = and i32 %7029, 65535" -> "  %7031 = add nuw nsw i32 %7030, %7028"
"  %7031 = add nuw nsw i32 %7030, %7028"
"  %7031 = add nuw nsw i32 %7030, %7028" -> "  %7033 = add nuw nsw i32 %7031, %7032"
"  %7032 = and i32 %7029, 268369920"
"  %7032 = and i32 %7029, 268369920" -> "  %7033 = add nuw nsw i32 %7031, %7032"
"  %7033 = add nuw nsw i32 %7031, %7032"
"  %7033 = add nuw nsw i32 %7031, %7032" -> "  %7037 = lshr i32 %7033, 16""  %7033 = add nuw nsw i32 %7031, %7032" -> "  %7035 = and i32 %7033, 65535"
"  %7034 = mul nuw nsw i32 %5282, 11561"
"  %7034 = mul nuw nsw i32 %5282, 11561" -> "  %7036 = add nuw nsw i32 %7035, %7034"
"  %7035 = and i32 %7033, 65535"
"  %7035 = and i32 %7033, 65535" -> "  %7036 = add nuw nsw i32 %7035, %7034"
"  %7036 = add nuw nsw i32 %7035, %7034"
"  %7036 = add nuw nsw i32 %7035, %7034" -> "  %7048 = and i32 %7036, 65535""  %7036 = add nuw nsw i32 %7035, %7034" -> "  %7040 = lshr i32 %7036, 16"
"  %7037 = lshr i32 %7033, 16"
"  %7037 = lshr i32 %7033, 16" -> "  %7039 = add nuw nsw i32 %7037, %7038"
"  %7038 = mul nuw nsw i32 %5285, 11561"
"  %7038 = mul nuw nsw i32 %5285, 11561" -> "  %7039 = add nuw nsw i32 %7037, %7038"
"  %7039 = add nuw nsw i32 %7037, %7038"
"  %7039 = add nuw nsw i32 %7037, %7038" -> "  %7043 = and i32 %7039, 2147418112""  %7039 = add nuw nsw i32 %7037, %7038" -> "  %7041 = and i32 %7039, 65535"
"  %7040 = lshr i32 %7036, 16"
"  %7040 = lshr i32 %7036, 16" -> "  %7042 = add nuw nsw i32 %7040, %7041"
"  %7041 = and i32 %7039, 65535"
"  %7041 = and i32 %7039, 65535" -> "  %7042 = add nuw nsw i32 %7040, %7041"
"  %7042 = add nuw nsw i32 %7040, %7041"
"  %7042 = add nuw nsw i32 %7040, %7041" -> "  %7044 = add nuw nsw i32 %7042, %7043"
"  %7043 = and i32 %7039, 2147418112"
"  %7043 = and i32 %7039, 2147418112" -> "  %7044 = add nuw nsw i32 %7042, %7043"
"  %7044 = add nuw nsw i32 %7042, %7043"
"  %7044 = add nuw nsw i32 %7042, %7043" -> "  %7052 = add nuw nsw i32 %7044, %7051"
"  %7045 = and i32 %7026, 65535"
"  %7045 = and i32 %7026, 65535" -> "  %7047 = add nuw nsw i32 %7045, %7046"
"  %7046 = and i32 %7027, 65535"
"  %7046 = and i32 %7027, 65535" -> "  %7047 = add nuw nsw i32 %7045, %7046"
"  %7047 = add nuw nsw i32 %7045, %7046"
"  %7047 = add nuw nsw i32 %7045, %7046" -> "  %7076 = and i32 %7047, 65535""  %7047 = add nuw nsw i32 %7045, %7046" -> "  %7054 = lshr i32 %7047, 16"
"  %7048 = and i32 %7036, 65535"
"  %7048 = and i32 %7036, 65535" -> "  %7050 = add nuw nsw i32 %7048, %7049"
"  %7049 = lshr i32 %7026, 16"
"  %7049 = lshr i32 %7026, 16" -> "  %7050 = add nuw nsw i32 %7048, %7049"
"  %7050 = add nuw nsw i32 %7048, %7049"
"  %7050 = add nuw nsw i32 %7048, %7049" -> "  %7053 = and i32 %7050, 65535""  %7050 = add nuw nsw i32 %7048, %7049" -> "  %7051 = lshr i32 %7050, 16"
"  %7051 = lshr i32 %7050, 16"
"  %7051 = lshr i32 %7050, 16" -> "  %7052 = add nuw nsw i32 %7044, %7051"
"  %7052 = add nuw nsw i32 %7044, %7051"
"  %7052 = add nuw nsw i32 %7044, %7051" -> "  %7057 = add nuw nsw i32 %7052, %7056"
"  %7053 = and i32 %7050, 65535"
"  %7053 = and i32 %7050, 65535" -> "  %7055 = add nuw nsw i32 %7053, %7054"
"  %7054 = lshr i32 %7047, 16"
"  %7054 = lshr i32 %7047, 16" -> "  %7055 = add nuw nsw i32 %7053, %7054"
"  %7055 = add nuw nsw i32 %7053, %7054"
"  %7055 = add nuw nsw i32 %7053, %7054" -> "  %7079 = and i32 %7055, 65535""  %7055 = add nuw nsw i32 %7053, %7054" -> "  %7056 = lshr i32 %7055, 16"
"  %7056 = lshr i32 %7055, 16"
"  %7056 = lshr i32 %7055, 16" -> "  %7057 = add nuw nsw i32 %7052, %7056"
"  %7057 = add nuw nsw i32 %7052, %7056"
"  %7057 = add nuw nsw i32 %7052, %7056" -> "  %7107 = and i32 %7057, 65535""  %7057 = add nuw nsw i32 %7052, %7056" -> "  %7111 = lshr i32 %7057, 16"
"  %7058 = mul nuw nsw i32 %5262, 21884"
"  %7058 = mul nuw nsw i32 %5262, 21884" -> "  %7077 = and i32 %7058, 65532""  %7058 = mul nuw nsw i32 %5262, 21884" -> "  %7059 = lshr i32 %7058, 16"
"  %7059 = lshr i32 %7058, 16"
"  %7059 = lshr i32 %7058, 16" -> "  %7062 = add nuw nsw i32 %7061, %7059"
"  %7060 = mul nuw nsw i32 %5265, 21884"
"  %7060 = mul nuw nsw i32 %5265, 21884" -> "  %7063 = and i32 %7060, 2147418112""  %7060 = mul nuw nsw i32 %5265, 21884" -> "  %7061 = and i32 %7060, 65532"
"  %7061 = and i32 %7060, 65532"
"  %7061 = and i32 %7060, 65532" -> "  %7062 = add nuw nsw i32 %7061, %7059"
"  %7062 = add nuw nsw i32 %7061, %7059"
"  %7062 = add nuw nsw i32 %7061, %7059" -> "  %7064 = add nuw nsw i32 %7062, %7063"
"  %7063 = and i32 %7060, 2147418112"
"  %7063 = and i32 %7060, 2147418112" -> "  %7064 = add nuw nsw i32 %7062, %7063"
"  %7064 = add nuw nsw i32 %7062, %7063"
"  %7064 = add nuw nsw i32 %7062, %7063" -> "  %7068 = lshr i32 %7064, 16""  %7064 = add nuw nsw i32 %7062, %7063" -> "  %7066 = and i32 %7064, 65535"
"  %7065 = mul nuw i32 %5262, 36786"
"  %7065 = mul nuw i32 %5262, 36786" -> "  %7067 = add nuw i32 %7066, %7065"
"  %7066 = and i32 %7064, 65535"
"  %7066 = and i32 %7064, 65535" -> "  %7067 = add nuw i32 %7066, %7065"
"  %7067 = add nuw i32 %7066, %7065"
"  %7067 = add nuw i32 %7066, %7065" -> "  %7080 = and i32 %7067, 65535""  %7067 = add nuw i32 %7066, %7065" -> "  %7071 = lshr i32 %7067, 16"
"  %7068 = lshr i32 %7064, 16"
"  %7068 = lshr i32 %7064, 16" -> "  %7070 = add nuw i32 %7068, %7069"
"  %7069 = mul nuw i32 %5265, 36786"
"  %7069 = mul nuw i32 %5265, 36786" -> "  %7070 = add nuw i32 %7068, %7069"
"  %7070 = add nuw i32 %7068, %7069"
"  %7070 = add nuw i32 %7068, %7069" -> "  %7074 = and i32 %7070, -65536""  %7070 = add nuw i32 %7068, %7069" -> "  %7072 = and i32 %7070, 65535"
"  %7071 = lshr i32 %7067, 16"
"  %7071 = lshr i32 %7067, 16" -> "  %7073 = add nuw nsw i32 %7071, %7072"
"  %7072 = and i32 %7070, 65535"
"  %7072 = and i32 %7070, 65535" -> "  %7073 = add nuw nsw i32 %7071, %7072"
"  %7073 = add nuw nsw i32 %7071, %7072"
"  %7073 = add nuw nsw i32 %7071, %7072" -> "  %7075 = add nuw i32 %7073, %7074"
"  %7074 = and i32 %7070, -65536"
"  %7074 = and i32 %7070, -65536" -> "  %7075 = add nuw i32 %7073, %7074"
"  %7075 = add nuw i32 %7073, %7074"
"  %7075 = add nuw i32 %7073, %7074" -> "  %7083 = add nuw i32 %7075, %7082"
"  %7076 = and i32 %7047, 65535"
"  %7076 = and i32 %7047, 65535" -> "  %7078 = add nuw nsw i32 %7076, %7077"
"  %7077 = and i32 %7058, 65532"
"  %7077 = and i32 %7058, 65532" -> "  %7078 = add nuw nsw i32 %7076, %7077"
"  %7078 = add nuw nsw i32 %7076, %7077"
"  %7078 = add nuw nsw i32 %7076, %7077" -> "  %7146 = and i32 %7078, 65535""  %7078 = add nuw nsw i32 %7076, %7077" -> "  %7084 = lshr i32 %7078, 16"
"  %7079 = and i32 %7055, 65535"
"  %7079 = and i32 %7055, 65535" -> "  %7081 = add nuw nsw i32 %7079, %7080"
"  %7080 = and i32 %7067, 65535"
"  %7080 = and i32 %7067, 65535" -> "  %7081 = add nuw nsw i32 %7079, %7080"
"  %7081 = add nuw nsw i32 %7079, %7080"
"  %7081 = add nuw nsw i32 %7079, %7080" -> "  %7085 = and i32 %7081, 65535""  %7081 = add nuw nsw i32 %7079, %7080" -> "  %7082 = lshr i32 %7081, 16"
"  %7082 = lshr i32 %7081, 16"
"  %7082 = lshr i32 %7081, 16" -> "  %7083 = add nuw i32 %7075, %7082"
"  %7083 = add nuw i32 %7075, %7082"
"  %7083 = add nuw i32 %7075, %7082" -> "  %7088 = add nuw i32 %7083, %7087"
"  %7084 = lshr i32 %7078, 16"
"  %7084 = lshr i32 %7078, 16" -> "  %7086 = add nuw nsw i32 %7085, %7084"
"  %7085 = and i32 %7081, 65535"
"  %7085 = and i32 %7081, 65535" -> "  %7086 = add nuw nsw i32 %7085, %7084"
"  %7086 = add nuw nsw i32 %7085, %7084"
"  %7086 = add nuw nsw i32 %7085, %7084" -> "  %7148 = and i32 %7086, 65535""  %7086 = add nuw nsw i32 %7085, %7084" -> "  %7087 = lshr i32 %7086, 16"
"  %7087 = lshr i32 %7086, 16"
"  %7087 = lshr i32 %7086, 16" -> "  %7088 = add nuw i32 %7083, %7087"
"  %7088 = add nuw i32 %7083, %7087"
"  %7088 = add nuw i32 %7083, %7087" -> "  %7124 = lshr i32 %7088, 16""  %7088 = add nuw i32 %7083, %7087" -> "  %7121 = and i32 %7088, 65535"
"  %7089 = mul nuw nsw i32 %5282, 21884"
"  %7089 = mul nuw nsw i32 %5282, 21884" -> "  %7108 = and i32 %7089, 65532""  %7089 = mul nuw nsw i32 %5282, 21884" -> "  %7090 = lshr i32 %7089, 16"
"  %7090 = lshr i32 %7089, 16"
"  %7090 = lshr i32 %7089, 16" -> "  %7093 = add nuw nsw i32 %7092, %7090"
"  %7091 = mul nuw nsw i32 %5285, 21884"
"  %7091 = mul nuw nsw i32 %5285, 21884" -> "  %7094 = and i32 %7091, 2147418112""  %7091 = mul nuw nsw i32 %5285, 21884" -> "  %7092 = and i32 %7091, 65532"
"  %7092 = and i32 %7091, 65532"
"  %7092 = and i32 %7091, 65532" -> "  %7093 = add nuw nsw i32 %7092, %7090"
"  %7093 = add nuw nsw i32 %7092, %7090"
"  %7093 = add nuw nsw i32 %7092, %7090" -> "  %7095 = add nuw nsw i32 %7093, %7094"
"  %7094 = and i32 %7091, 2147418112"
"  %7094 = and i32 %7091, 2147418112" -> "  %7095 = add nuw nsw i32 %7093, %7094"
"  %7095 = add nuw nsw i32 %7093, %7094"
"  %7095 = add nuw nsw i32 %7093, %7094" -> "  %7099 = lshr i32 %7095, 16""  %7095 = add nuw nsw i32 %7093, %7094" -> "  %7097 = and i32 %7095, 65535"
"  %7096 = mul nuw i32 %5282, 36786"
"  %7096 = mul nuw i32 %5282, 36786" -> "  %7098 = add nuw i32 %7097, %7096"
"  %7097 = and i32 %7095, 65535"
"  %7097 = and i32 %7095, 65535" -> "  %7098 = add nuw i32 %7097, %7096"
"  %7098 = add nuw i32 %7097, %7096"
"  %7098 = add nuw i32 %7097, %7096" -> "  %7110 = and i32 %7098, 65535""  %7098 = add nuw i32 %7097, %7096" -> "  %7102 = lshr i32 %7098, 16"
"  %7099 = lshr i32 %7095, 16"
"  %7099 = lshr i32 %7095, 16" -> "  %7101 = add nuw i32 %7099, %7100"
"  %7100 = mul nuw i32 %5285, 36786"
"  %7100 = mul nuw i32 %5285, 36786" -> "  %7101 = add nuw i32 %7099, %7100"
"  %7101 = add nuw i32 %7099, %7100"
"  %7101 = add nuw i32 %7099, %7100" -> "  %7105 = and i32 %7101, -65536""  %7101 = add nuw i32 %7099, %7100" -> "  %7103 = and i32 %7101, 65535"
"  %7102 = lshr i32 %7098, 16"
"  %7102 = lshr i32 %7098, 16" -> "  %7104 = add nuw nsw i32 %7102, %7103"
"  %7103 = and i32 %7101, 65535"
"  %7103 = and i32 %7101, 65535" -> "  %7104 = add nuw nsw i32 %7102, %7103"
"  %7104 = add nuw nsw i32 %7102, %7103"
"  %7104 = add nuw nsw i32 %7102, %7103" -> "  %7106 = add nuw i32 %7104, %7105"
"  %7105 = and i32 %7101, -65536"
"  %7105 = and i32 %7101, -65536" -> "  %7106 = add nuw i32 %7104, %7105"
"  %7106 = add nuw i32 %7104, %7105"
"  %7106 = add nuw i32 %7104, %7105" -> "  %7114 = add nuw i32 %7106, %7113"
"  %7107 = and i32 %7057, 65535"
"  %7107 = and i32 %7057, 65535" -> "  %7109 = add nuw nsw i32 %7107, %7108"
"  %7108 = and i32 %7089, 65532"
"  %7108 = and i32 %7089, 65532" -> "  %7109 = add nuw nsw i32 %7107, %7108"
"  %7109 = add nuw nsw i32 %7107, %7108"
"  %7109 = add nuw nsw i32 %7107, %7108" -> "  %7120 = and i32 %7109, 65535""  %7109 = add nuw nsw i32 %7107, %7108" -> "  %7116 = lshr i32 %7109, 16"
"  %7110 = and i32 %7098, 65535"
"  %7110 = and i32 %7098, 65535" -> "  %7112 = add nuw nsw i32 %7111, %7110"
"  %7111 = lshr i32 %7057, 16"
"  %7111 = lshr i32 %7057, 16" -> "  %7112 = add nuw nsw i32 %7111, %7110"
"  %7112 = add nuw nsw i32 %7111, %7110"
"  %7112 = add nuw nsw i32 %7111, %7110" -> "  %7115 = and i32 %7112, 65535""  %7112 = add nuw nsw i32 %7111, %7110" -> "  %7113 = lshr i32 %7112, 16"
"  %7113 = lshr i32 %7112, 16"
"  %7113 = lshr i32 %7112, 16" -> "  %7114 = add nuw i32 %7106, %7113"
"  %7114 = add nuw i32 %7106, %7113"
"  %7114 = add nuw i32 %7106, %7113" -> "  %7119 = add nuw i32 %7114, %7118"
"  %7115 = and i32 %7112, 65535"
"  %7115 = and i32 %7112, 65535" -> "  %7117 = add nuw nsw i32 %7115, %7116"
"  %7116 = lshr i32 %7109, 16"
"  %7116 = lshr i32 %7109, 16" -> "  %7117 = add nuw nsw i32 %7115, %7116"
"  %7117 = add nuw nsw i32 %7115, %7116"
"  %7117 = add nuw nsw i32 %7115, %7116" -> "  %7123 = and i32 %7117, 65535""  %7117 = add nuw nsw i32 %7115, %7116" -> "  %7118 = lshr i32 %7117, 16"
"  %7118 = lshr i32 %7117, 16"
"  %7118 = lshr i32 %7117, 16" -> "  %7119 = add nuw i32 %7114, %7118"
"  %7119 = add nuw i32 %7114, %7118"
"  %7119 = add nuw i32 %7114, %7118" -> "  %7132 = and i32 %7119, -65536""  %7119 = add nuw i32 %7114, %7118" -> "  %7130 = and i32 %7119, 65535"
"  %7120 = and i32 %7109, 65535"
"  %7120 = and i32 %7109, 65535" -> "  %7122 = add nuw nsw i32 %7121, %7120"
"  %7121 = and i32 %7088, 65535"
"  %7121 = and i32 %7088, 65535" -> "  %7122 = add nuw nsw i32 %7121, %7120"
"  %7122 = add nuw nsw i32 %7121, %7120"
"  %7122 = add nuw nsw i32 %7121, %7120" -> "  %7162 = and i32 %7122, 65535""  %7122 = add nuw nsw i32 %7121, %7120" -> "  %7126 = lshr i32 %7122, 16"
"  %7123 = and i32 %7117, 65535"
"  %7123 = and i32 %7117, 65535" -> "  %7125 = add nuw nsw i32 %7123, %7124"
"  %7124 = lshr i32 %7088, 16"
"  %7124 = lshr i32 %7088, 16" -> "  %7125 = add nuw nsw i32 %7123, %7124"
"  %7125 = add nuw nsw i32 %7123, %7124"
"  %7125 = add nuw nsw i32 %7123, %7124" -> "  %7129 = lshr i32 %7125, 16""  %7125 = add nuw nsw i32 %7123, %7124" -> "  %7127 = and i32 %7125, 65535"
"  %7126 = lshr i32 %7122, 16"
"  %7126 = lshr i32 %7122, 16" -> "  %7128 = add nuw nsw i32 %7127, %7126"
"  %7127 = and i32 %7125, 65535"
"  %7127 = and i32 %7125, 65535" -> "  %7128 = add nuw nsw i32 %7127, %7126"
"  %7128 = add nuw nsw i32 %7127, %7126"
"  %7128 = add nuw nsw i32 %7127, %7126" -> "  %7169 = and i32 %7128, 65535""  %7128 = add nuw nsw i32 %7127, %7126" -> "  %7134 = lshr i32 %7128, 16"
"  %7129 = lshr i32 %7125, 16"
"  %7129 = lshr i32 %7125, 16" -> "  %7131 = add nuw nsw i32 %7129, %7130"
"  %7130 = and i32 %7119, 65535"
"  %7130 = and i32 %7119, 65535" -> "  %7131 = add nuw nsw i32 %7129, %7130"
"  %7131 = add nuw nsw i32 %7129, %7130"
"  %7131 = add nuw nsw i32 %7129, %7130" -> "  %7133 = add nuw i32 %7131, %7132"
"  %7132 = and i32 %7119, -65536"
"  %7132 = and i32 %7119, -65536" -> "  %7133 = add nuw i32 %7131, %7132"
"  %7133 = add nuw i32 %7131, %7132"
"  %7133 = add nuw i32 %7131, %7132" -> "  %7135 = add nuw i32 %7133, %7134"
"  %7134 = lshr i32 %7128, 16"
"  %7134 = lshr i32 %7128, 16" -> "  %7135 = add nuw i32 %7133, %7134"
"  %7135 = add nuw i32 %7133, %7134"
"  %7135 = add nuw i32 %7133, %7134" -> "  %7173 = add nuw i32 %7135, %7172"
"  %7136 = and i32 %7006, 65535"
"  %7136 = and i32 %7006, 65535" -> "  %7138 = add nuw nsw i32 %7137, %7136"
"  %7137 = and i32 %6835, 65535"
"  %7137 = and i32 %6835, 65535" -> "  %7138 = add nuw nsw i32 %7137, %7136"
"  %7138 = add nuw nsw i32 %7137, %7136"
"  %7138 = add nuw nsw i32 %7137, %7136" -> "  %7174 = and i32 %7138, 65535""  %7138 = add nuw nsw i32 %7137, %7136" -> "  %7142 = lshr i32 %7138, 16"
"  %7139 = and i32 %7018, 65535"
"  %7139 = and i32 %7018, 65535" -> "  %7141 = add nuw nsw i32 %7140, %7139"
"  %7140 = and i32 %6838, 65535"
"  %7140 = and i32 %6838, 65535" -> "  %7141 = add nuw nsw i32 %7140, %7139"
"  %7141 = add nuw nsw i32 %7140, %7139"
"  %7141 = add nuw nsw i32 %7140, %7139" -> "  %7155 = lshr i32 %7141, 16""  %7141 = add nuw nsw i32 %7140, %7139" -> "  %7143 = and i32 %7141, 65535"
"  %7142 = lshr i32 %7138, 16"
"  %7142 = lshr i32 %7138, 16" -> "  %7144 = add nuw nsw i32 %7143, %7142"
"  %7143 = and i32 %7141, 65535"
"  %7143 = and i32 %7141, 65535" -> "  %7144 = add nuw nsw i32 %7143, %7142"
"  %7144 = add nuw nsw i32 %7143, %7142"
"  %7144 = add nuw nsw i32 %7143, %7142" -> "  %7177 = and i32 %7144, 65535""  %7144 = add nuw nsw i32 %7143, %7142" -> "  %7157 = lshr i32 %7144, 16"
"  %7145 = and i32 %6840, 65535"
"  %7145 = and i32 %6840, 65535" -> "  %7147 = add nuw nsw i32 %7145, %7146"
"  %7146 = and i32 %7078, 65535"
"  %7146 = and i32 %7078, 65535" -> "  %7147 = add nuw nsw i32 %7145, %7146"
"  %7147 = add nuw nsw i32 %7145, %7146"
"  %7147 = add nuw nsw i32 %7145, %7146" -> "  %7154 = and i32 %7147, 65535""  %7147 = add nuw nsw i32 %7145, %7146" -> "  %7151 = lshr i32 %7147, 16"
"  %7148 = and i32 %7086, 65535"
"  %7148 = and i32 %7086, 65535" -> "  %7150 = add nuw nsw i32 %7149, %7148"
"  %7149 = lshr i32 %6840, 16"
"  %7149 = lshr i32 %6840, 16" -> "  %7150 = add nuw nsw i32 %7149, %7148"
"  %7150 = add nuw nsw i32 %7149, %7148"
"  %7150 = add nuw nsw i32 %7149, %7148" -> "  %7163 = lshr i32 %7150, 16""  %7150 = add nuw nsw i32 %7149, %7148" -> "  %7152 = and i32 %7150, 65535"
"  %7151 = lshr i32 %7147, 16"
"  %7151 = lshr i32 %7147, 16" -> "  %7153 = add nuw nsw i32 %7151, %7152"
"  %7152 = and i32 %7150, 65535"
"  %7152 = and i32 %7150, 65535" -> "  %7153 = add nuw nsw i32 %7151, %7152"
"  %7153 = add nuw nsw i32 %7151, %7152"
"  %7153 = add nuw nsw i32 %7151, %7152" -> "  %7165 = lshr i32 %7153, 16""  %7153 = add nuw nsw i32 %7151, %7152" -> "  %7160 = and i32 %7153, 65535"
"  %7154 = and i32 %7147, 65535"
"  %7154 = and i32 %7147, 65535" -> "  %7156 = add nuw nsw i32 %7154, %7155"
"  %7155 = lshr i32 %7141, 16"
"  %7155 = lshr i32 %7141, 16" -> "  %7156 = add nuw nsw i32 %7154, %7155"
"  %7156 = add nuw nsw i32 %7154, %7155"
"  %7156 = add nuw nsw i32 %7154, %7155" -> "  %7158 = add nuw nsw i32 %7156, %7157"
"  %7157 = lshr i32 %7144, 16"
"  %7157 = lshr i32 %7144, 16" -> "  %7158 = add nuw nsw i32 %7156, %7157"
"  %7158 = add nuw nsw i32 %7156, %7157"
"  %7158 = add nuw nsw i32 %7156, %7157" -> "  %7183 = and i32 %7158, 65535""  %7158 = add nuw nsw i32 %7156, %7157" -> "  %7159 = lshr i32 %7158, 16"
"  %7159 = lshr i32 %7158, 16"
"  %7159 = lshr i32 %7158, 16" -> "  %7161 = add nuw nsw i32 %7159, %7160"
"  %7160 = and i32 %7153, 65535"
"  %7160 = and i32 %7153, 65535" -> "  %7161 = add nuw nsw i32 %7159, %7160"
"  %7161 = add nuw nsw i32 %7159, %7160"
"  %7161 = add nuw nsw i32 %7159, %7160" -> "  %7186 = and i32 %7161, 65535""  %7161 = add nuw nsw i32 %7159, %7160" -> "  %7167 = lshr i32 %7161, 16"
"  %7162 = and i32 %7122, 65535"
"  %7162 = and i32 %7122, 65535" -> "  %7164 = add nuw nsw i32 %7163, %7162"
"  %7163 = lshr i32 %7150, 16"
"  %7163 = lshr i32 %7150, 16" -> "  %7164 = add nuw nsw i32 %7163, %7162"
"  %7164 = add nuw nsw i32 %7163, %7162"
"  %7164 = add nuw nsw i32 %7163, %7162" -> "  %7166 = add nuw nsw i32 %7164, %7165"
"  %7165 = lshr i32 %7153, 16"
"  %7165 = lshr i32 %7153, 16" -> "  %7166 = add nuw nsw i32 %7164, %7165"
"  %7166 = add nuw nsw i32 %7164, %7165"
"  %7166 = add nuw nsw i32 %7164, %7165" -> "  %7168 = add nuw nsw i32 %7166, %7167"
"  %7167 = lshr i32 %7161, 16"
"  %7167 = lshr i32 %7161, 16" -> "  %7168 = add nuw nsw i32 %7166, %7167"
"  %7168 = add nuw nsw i32 %7166, %7167"
"  %7168 = add nuw nsw i32 %7166, %7167" -> "  %7200 = and i32 %7168, 65535""  %7168 = add nuw nsw i32 %7166, %7167" -> "  %7170 = lshr i32 %7168, 16"
"  %7169 = and i32 %7128, 65535"
"  %7169 = and i32 %7128, 65535" -> "  %7171 = add nuw nsw i32 %7170, %7169"
"  %7170 = lshr i32 %7168, 16"
"  %7170 = lshr i32 %7168, 16" -> "  %7171 = add nuw nsw i32 %7170, %7169"
"  %7171 = add nuw nsw i32 %7170, %7169"
"  %7171 = add nuw nsw i32 %7170, %7169" -> "  %7207 = and i32 %7171, 65535""  %7171 = add nuw nsw i32 %7170, %7169" -> "  %7172 = lshr i32 %7171, 16"
"  %7172 = lshr i32 %7171, 16"
"  %7172 = lshr i32 %7171, 16" -> "  %7173 = add nuw i32 %7135, %7172"
"  %7173 = add nuw i32 %7135, %7172"
"  %7173 = add nuw i32 %7135, %7172" -> "  %7211 = add nuw i32 %7173, %7210"
"  %7174 = and i32 %7138, 65535"
"  %7174 = and i32 %7138, 65535" -> "  %7176 = add nuw nsw i32 %7175, %7174"
"  %7175 = and i32 %7000, 65535"
"  %7175 = and i32 %7000, 65535" -> "  %7176 = add nuw nsw i32 %7175, %7174"
"  %7176 = add nuw nsw i32 %7175, %7174"
"  %7176 = add nuw nsw i32 %7175, %7174" -> "  %7284 = and i32 %7176, 65535""  %7176 = add nuw nsw i32 %7175, %7174" -> "  %7180 = lshr i32 %7176, 16"
"  %7177 = and i32 %7144, 65535"
"  %7177 = and i32 %7144, 65535" -> "  %7179 = add nuw nsw i32 %7178, %7177"
"  %7178 = and i32 %7003, 65535"
"  %7178 = and i32 %7003, 65535" -> "  %7179 = add nuw nsw i32 %7178, %7177"
"  %7179 = add nuw nsw i32 %7178, %7177"
"  %7179 = add nuw nsw i32 %7178, %7177" -> "  %7193 = lshr i32 %7179, 16""  %7179 = add nuw nsw i32 %7178, %7177" -> "  %7181 = and i32 %7179, 65535"
"  %7180 = lshr i32 %7176, 16"
"  %7180 = lshr i32 %7176, 16" -> "  %7182 = add nuw nsw i32 %7181, %7180"
"  %7181 = and i32 %7179, 65535"
"  %7181 = and i32 %7179, 65535" -> "  %7182 = add nuw nsw i32 %7181, %7180"
"  %7182 = add nuw nsw i32 %7181, %7180"
"  %7182 = add nuw nsw i32 %7181, %7180" -> "  %7289 = and i32 %7182, 65535""  %7182 = add nuw nsw i32 %7181, %7180" -> "  %7195 = lshr i32 %7182, 16"
"  %7183 = and i32 %7158, 65535"
"  %7183 = and i32 %7158, 65535" -> "  %7185 = add nuw nsw i32 %7184, %7183"
"  %7184 = and i32 %7005, 65535"
"  %7184 = and i32 %7005, 65535" -> "  %7185 = add nuw nsw i32 %7184, %7183"
"  %7185 = add nuw nsw i32 %7184, %7183"
"  %7185 = add nuw nsw i32 %7184, %7183" -> "  %7192 = and i32 %7185, 65535""  %7185 = add nuw nsw i32 %7184, %7183" -> "  %7189 = lshr i32 %7185, 16"
"  %7186 = and i32 %7161, 65535"
"  %7186 = and i32 %7161, 65535" -> "  %7188 = add nuw nsw i32 %7186, %7187"
"  %7187 = lshr i32 %7005, 16"
"  %7187 = lshr i32 %7005, 16" -> "  %7188 = add nuw nsw i32 %7186, %7187"
"  %7188 = add nuw nsw i32 %7186, %7187"
"  %7188 = add nuw nsw i32 %7186, %7187" -> "  %7201 = lshr i32 %7188, 16""  %7188 = add nuw nsw i32 %7186, %7187" -> "  %7190 = and i32 %7188, 65535"
"  %7189 = lshr i32 %7185, 16"
"  %7189 = lshr i32 %7185, 16" -> "  %7191 = add nuw nsw i32 %7190, %7189"
"  %7190 = and i32 %7188, 65535"
"  %7190 = and i32 %7188, 65535" -> "  %7191 = add nuw nsw i32 %7190, %7189"
"  %7191 = add nuw nsw i32 %7190, %7189"
"  %7191 = add nuw nsw i32 %7190, %7189" -> "  %7203 = lshr i32 %7191, 16""  %7191 = add nuw nsw i32 %7190, %7189" -> "  %7198 = and i32 %7191, 65535"
"  %7192 = and i32 %7185, 65535"
"  %7192 = and i32 %7185, 65535" -> "  %7194 = add nuw nsw i32 %7192, %7193"
"  %7193 = lshr i32 %7179, 16"
"  %7193 = lshr i32 %7179, 16" -> "  %7194 = add nuw nsw i32 %7192, %7193"
"  %7194 = add nuw nsw i32 %7192, %7193"
"  %7194 = add nuw nsw i32 %7192, %7193" -> "  %7196 = add nuw nsw i32 %7194, %7195"
"  %7195 = lshr i32 %7182, 16"
"  %7195 = lshr i32 %7182, 16" -> "  %7196 = add nuw nsw i32 %7194, %7195"
"  %7196 = add nuw nsw i32 %7194, %7195"
"  %7196 = add nuw nsw i32 %7194, %7195" -> "  %7292 = and i32 %7196, 65535""  %7196 = add nuw nsw i32 %7194, %7195" -> "  %7197 = lshr i32 %7196, 16"
"  %7197 = lshr i32 %7196, 16"
"  %7197 = lshr i32 %7196, 16" -> "  %7199 = add nuw nsw i32 %7198, %7197"
"  %7198 = and i32 %7191, 65535"
"  %7198 = and i32 %7191, 65535" -> "  %7199 = add nuw nsw i32 %7198, %7197"
"  %7199 = add nuw nsw i32 %7198, %7197"
"  %7199 = add nuw nsw i32 %7198, %7197" -> "  %7296 = and i32 %7199, 65535""  %7199 = add nuw nsw i32 %7198, %7197" -> "  %7205 = lshr i32 %7199, 16"
"  %7200 = and i32 %7168, 65535"
"  %7200 = and i32 %7168, 65535" -> "  %7202 = add nuw nsw i32 %7201, %7200"
"  %7201 = lshr i32 %7188, 16"
"  %7201 = lshr i32 %7188, 16" -> "  %7202 = add nuw nsw i32 %7201, %7200"
"  %7202 = add nuw nsw i32 %7201, %7200"
"  %7202 = add nuw nsw i32 %7201, %7200" -> "  %7204 = add nuw nsw i32 %7202, %7203"
"  %7203 = lshr i32 %7191, 16"
"  %7203 = lshr i32 %7191, 16" -> "  %7204 = add nuw nsw i32 %7202, %7203"
"  %7204 = add nuw nsw i32 %7202, %7203"
"  %7204 = add nuw nsw i32 %7202, %7203" -> "  %7206 = add nuw nsw i32 %7204, %7205"
"  %7205 = lshr i32 %7199, 16"
"  %7205 = lshr i32 %7199, 16" -> "  %7206 = add nuw nsw i32 %7204, %7205"
"  %7206 = add nuw nsw i32 %7204, %7205"
"  %7206 = add nuw nsw i32 %7204, %7205" -> "  %7299 = and i32 %7206, 65535""  %7206 = add nuw nsw i32 %7204, %7205" -> "  %7208 = lshr i32 %7206, 16"
"  %7207 = and i32 %7171, 65535"
"  %7207 = and i32 %7171, 65535" -> "  %7209 = add nuw nsw i32 %7208, %7207"
"  %7208 = lshr i32 %7206, 16"
"  %7208 = lshr i32 %7206, 16" -> "  %7209 = add nuw nsw i32 %7208, %7207"
"  %7209 = add nuw nsw i32 %7208, %7207"
"  %7209 = add nuw nsw i32 %7208, %7207" -> "  %7302 = and i32 %7209, 65535""  %7209 = add nuw nsw i32 %7208, %7207" -> "  %7210 = lshr i32 %7209, 16"
"  %7210 = lshr i32 %7209, 16"
"  %7210 = lshr i32 %7209, 16" -> "  %7211 = add nuw i32 %7173, %7210"
"  %7211 = add nuw i32 %7173, %7210"
"  %7211 = add nuw i32 %7173, %7210" -> "  %7305 = add nuw i32 %7211, %7304"
"  %7212 = and i32 %6457, 65535"
"  %7212 = and i32 %6457, 65535" -> "  %7214 = add nuw nsw i32 %7212, %7213"
"  %7213 = and i32 %6549, 65535"
"  %7213 = and i32 %6549, 65535" -> "  %7214 = add nuw nsw i32 %7212, %7213"
"  %7214 = add nuw nsw i32 %7212, %7213"
"  %7214 = add nuw nsw i32 %7212, %7213" -> "  %7218 = lshr i32 %7214, 16"
"  %7215 = and i32 %6463, 65535"
"  %7215 = and i32 %6463, 65535" -> "  %7217 = add nuw nsw i32 %7215, %7216"
"  %7216 = and i32 %6558, 65535"
"  %7216 = and i32 %6558, 65535" -> "  %7217 = add nuw nsw i32 %7215, %7216"
"  %7217 = add nuw nsw i32 %7215, %7216"
"  %7217 = add nuw nsw i32 %7215, %7216" -> "  %7221 = lshr i32 %7217, 16""  %7217 = add nuw nsw i32 %7215, %7216" -> "  %7219 = and i32 %7217, 65535"
"  %7218 = lshr i32 %7214, 16"
"  %7218 = lshr i32 %7214, 16" -> "  %7220 = add nuw nsw i32 %7219, %7218"
"  %7219 = and i32 %7217, 65535"
"  %7219 = and i32 %7217, 65535" -> "  %7220 = add nuw nsw i32 %7219, %7218"
"  %7220 = add nuw nsw i32 %7219, %7218"
"  %7220 = add nuw nsw i32 %7219, %7218" -> "  %7222 = lshr i32 %7220, 16"
"  %7221 = lshr i32 %7217, 16"
"  %7221 = lshr i32 %7217, 16" -> "  %7223 = add nuw nsw i32 %7222, %7221"
"  %7222 = lshr i32 %7220, 16"
"  %7222 = lshr i32 %7220, 16" -> "  %7223 = add nuw nsw i32 %7222, %7221"
"  %7223 = add nuw nsw i32 %7222, %7221"
"  %7223 = add nuw nsw i32 %7222, %7221" -> "  %7234 = add nuw nsw i32 %7223, %7233"
"  %7224 = and i32 %6477, 65535"
"  %7224 = and i32 %6477, 65535" -> "  %7226 = add nuw nsw i32 %7224, %7225"
"  %7225 = and i32 %6618, 65535"
"  %7225 = and i32 %6618, 65535" -> "  %7226 = add nuw nsw i32 %7224, %7225"
"  %7226 = add nuw nsw i32 %7224, %7225"
"  %7226 = add nuw nsw i32 %7224, %7225" -> "  %7233 = and i32 %7226, 65535""  %7226 = add nuw nsw i32 %7224, %7225" -> "  %7230 = lshr i32 %7226, 16"
"  %7227 = and i32 %6480, 65535"
"  %7227 = and i32 %6480, 65535" -> "  %7229 = add nuw nsw i32 %7227, %7228"
"  %7228 = and i32 %6626, 65535"
"  %7228 = and i32 %6626, 65535" -> "  %7229 = add nuw nsw i32 %7227, %7228"
"  %7229 = add nuw nsw i32 %7227, %7228"
"  %7229 = add nuw nsw i32 %7227, %7228" -> "  %7267 = lshr i32 %7229, 16""  %7229 = add nuw nsw i32 %7227, %7228" -> "  %7231 = and i32 %7229, 65535"
"  %7230 = lshr i32 %7226, 16"
"  %7230 = lshr i32 %7226, 16" -> "  %7232 = add nuw nsw i32 %7231, %7230"
"  %7231 = and i32 %7229, 65535"
"  %7231 = and i32 %7229, 65535" -> "  %7232 = add nuw nsw i32 %7231, %7230"
"  %7232 = add nuw nsw i32 %7231, %7230"
"  %7232 = add nuw nsw i32 %7231, %7230" -> "  %7269 = lshr i32 %7232, 16""  %7232 = add nuw nsw i32 %7231, %7230" -> "  %7236 = and i32 %7232, 65535"
"  %7233 = and i32 %7226, 65535"
"  %7233 = and i32 %7226, 65535" -> "  %7234 = add nuw nsw i32 %7223, %7233"
"  %7234 = add nuw nsw i32 %7223, %7233"
"  %7234 = add nuw nsw i32 %7223, %7233" -> "  %7235 = lshr i32 %7234, 16"
"  %7235 = lshr i32 %7234, 16"
"  %7235 = lshr i32 %7234, 16" -> "  %7237 = add nuw nsw i32 %7236, %7235"
"  %7236 = and i32 %7232, 65535"
"  %7236 = and i32 %7232, 65535" -> "  %7237 = add nuw nsw i32 %7236, %7235"
"  %7237 = add nuw nsw i32 %7236, %7235"
"  %7237 = add nuw nsw i32 %7236, %7235" -> "  %7270 = lshr i32 %7237, 16"
"  %7238 = and i32 %6517, 65535"
"  %7238 = and i32 %6517, 65535" -> "  %7240 = add nuw nsw i32 %7238, %7239"
"  %7239 = and i32 %6970, 65535"
"  %7239 = and i32 %6970, 65535" -> "  %7240 = add nuw nsw i32 %7238, %7239"
"  %7240 = add nuw nsw i32 %7238, %7239"
"  %7240 = add nuw nsw i32 %7238, %7239" -> "  %7268 = and i32 %7240, 65535""  %7240 = add nuw nsw i32 %7238, %7239" -> "  %7244 = lshr i32 %7240, 16"
"  %7241 = and i32 %6520, 65535"
"  %7241 = and i32 %6520, 65535" -> "  %7243 = add nuw nsw i32 %7241, %7242"
"  %7242 = and i32 %6976, 65535"
"  %7242 = and i32 %6976, 65535" -> "  %7243 = add nuw nsw i32 %7241, %7242"
"  %7243 = add nuw nsw i32 %7241, %7242"
"  %7243 = add nuw nsw i32 %7241, %7242" -> "  %7247 = lshr i32 %7243, 16""  %7243 = add nuw nsw i32 %7241, %7242" -> "  %7245 = and i32 %7243, 65535"
"  %7244 = lshr i32 %7240, 16"
"  %7244 = lshr i32 %7240, 16" -> "  %7246 = add nuw nsw i32 %7245, %7244"
"  %7245 = and i32 %7243, 65535"
"  %7245 = and i32 %7243, 65535" -> "  %7246 = add nuw nsw i32 %7245, %7244"
"  %7246 = add nuw nsw i32 %7245, %7244"
"  %7246 = add nuw nsw i32 %7245, %7244" -> "  %7275 = and i32 %7246, 65535""  %7246 = add nuw nsw i32 %7245, %7244" -> "  %7248 = lshr i32 %7246, 16"
"  %7247 = lshr i32 %7243, 16"
"  %7247 = lshr i32 %7243, 16" -> "  %7249 = add nuw nsw i32 %7248, %7247"
"  %7248 = lshr i32 %7246, 16"
"  %7248 = lshr i32 %7246, 16" -> "  %7249 = add nuw nsw i32 %7248, %7247"
"  %7249 = add nuw nsw i32 %7248, %7247"
"  %7249 = add nuw nsw i32 %7248, %7247" -> "  %7262 = add nuw nsw i32 %7249, %7261"
"  %7250 = and i32 %6523, 65535"
"  %7250 = and i32 %6523, 65535" -> "  %7252 = add nuw nsw i32 %7250, %7251"
"  %7251 = and i32 %6990, 65535"
"  %7251 = and i32 %6990, 65535" -> "  %7252 = add nuw nsw i32 %7250, %7251"
"  %7252 = add nuw nsw i32 %7250, %7251"
"  %7252 = add nuw nsw i32 %7250, %7251" -> "  %7261 = and i32 %7252, 65535""  %7252 = add nuw nsw i32 %7250, %7251" -> "  %7256 = lshr i32 %7252, 16"
"  %7253 = and i32 %6526, 65535"
"  %7253 = and i32 %6526, 65535" -> "  %7255 = add nuw nsw i32 %7253, %7254"
"  %7254 = and i32 %6993, 65535"
"  %7254 = and i32 %6993, 65535" -> "  %7255 = add nuw nsw i32 %7253, %7254"
"  %7255 = add nuw nsw i32 %7253, %7254"
"  %7255 = add nuw nsw i32 %7253, %7254" -> "  %7259 = lshr i32 %7255, 16""  %7255 = add nuw nsw i32 %7253, %7254" -> "  %7257 = and i32 %7255, 65535"
"  %7256 = lshr i32 %7252, 16"
"  %7256 = lshr i32 %7252, 16" -> "  %7258 = add nuw nsw i32 %7257, %7256"
"  %7257 = and i32 %7255, 65535"
"  %7257 = and i32 %7255, 65535" -> "  %7258 = add nuw nsw i32 %7257, %7256"
"  %7258 = add nuw nsw i32 %7257, %7256"
"  %7258 = add nuw nsw i32 %7257, %7256" -> "  %7263 = and i32 %7258, 65535""  %7258 = add nuw nsw i32 %7257, %7256" -> "  %7260 = lshr i32 %7258, 16"
"  %7259 = lshr i32 %7255, 16"
"  %7259 = lshr i32 %7255, 16" -> "  %7285 = add nuw nsw i32 %7259, %7284"
"  %7260 = lshr i32 %7258, 16"
"  %7260 = lshr i32 %7258, 16" -> "  %7286 = add nuw nsw i32 %7285, %7260"
"  %7261 = and i32 %7252, 65535"
"  %7261 = and i32 %7252, 65535" -> "  %7262 = add nuw nsw i32 %7249, %7261"
"  %7262 = add nuw nsw i32 %7249, %7261"
"  %7262 = add nuw nsw i32 %7249, %7261" -> "  %7277 = and i32 %7262, 65535""  %7262 = add nuw nsw i32 %7249, %7261" -> "  %7264 = lshr i32 %7262, 16"
"  %7263 = and i32 %7258, 65535"
"  %7263 = and i32 %7258, 65535" -> "  %7265 = add nuw nsw i32 %7263, %7264"
"  %7264 = lshr i32 %7262, 16"
"  %7264 = lshr i32 %7262, 16" -> "  %7265 = add nuw nsw i32 %7263, %7264"
"  %7265 = add nuw nsw i32 %7263, %7264"
"  %7265 = add nuw nsw i32 %7263, %7264" -> "  %7280 = and i32 %7265, 65535""  %7265 = add nuw nsw i32 %7263, %7264" -> "  %7266 = lshr i32 %7265, 16"
"  %7266 = lshr i32 %7265, 16"
"  %7266 = lshr i32 %7265, 16" -> "  %7287 = add nuw nsw i32 %7286, %7266"
"  %7267 = lshr i32 %7229, 16"
"  %7267 = lshr i32 %7229, 16" -> "  %7271 = add nuw nsw i32 %7269, %7267"
"  %7268 = and i32 %7240, 65535"
"  %7268 = and i32 %7240, 65535" -> "  %7272 = add nuw nsw i32 %7271, %7268"
"  %7269 = lshr i32 %7232, 16"
"  %7269 = lshr i32 %7232, 16" -> "  %7271 = add nuw nsw i32 %7269, %7267"
"  %7270 = lshr i32 %7237, 16"
"  %7270 = lshr i32 %7237, 16" -> "  %7273 = add nuw nsw i32 %7272, %7270"
"  %7271 = add nuw nsw i32 %7269, %7267"
"  %7271 = add nuw nsw i32 %7269, %7267" -> "  %7272 = add nuw nsw i32 %7271, %7268"
"  %7272 = add nuw nsw i32 %7271, %7268"
"  %7272 = add nuw nsw i32 %7271, %7268" -> "  %7273 = add nuw nsw i32 %7272, %7270"
"  %7273 = add nuw nsw i32 %7272, %7270"
"  %7273 = add nuw nsw i32 %7272, %7270" -> "  %7274 = lshr i32 %7273, 16"
"  %7274 = lshr i32 %7273, 16"
"  %7274 = lshr i32 %7273, 16" -> "  %7276 = add nuw nsw i32 %7274, %7275"
"  %7275 = and i32 %7246, 65535"
"  %7275 = and i32 %7246, 65535" -> "  %7276 = add nuw nsw i32 %7274, %7275"
"  %7276 = add nuw nsw i32 %7274, %7275"
"  %7276 = add nuw nsw i32 %7274, %7275" -> "  %7278 = lshr i32 %7276, 16"
"  %7277 = and i32 %7262, 65535"
"  %7277 = and i32 %7262, 65535" -> "  %7279 = add nuw nsw i32 %7277, %7278"
"  %7278 = lshr i32 %7276, 16"
"  %7278 = lshr i32 %7276, 16" -> "  %7279 = add nuw nsw i32 %7277, %7278"
"  %7279 = add nuw nsw i32 %7277, %7278"
"  %7279 = add nuw nsw i32 %7277, %7278" -> "  %7281 = lshr i32 %7279, 16"
"  %7280 = and i32 %7265, 65535"
"  %7280 = and i32 %7265, 65535" -> "  %7282 = add nuw nsw i32 %7280, %7281"
"  %7281 = lshr i32 %7279, 16"
"  %7281 = lshr i32 %7279, 16" -> "  %7282 = add nuw nsw i32 %7280, %7281"
"  %7282 = add nuw nsw i32 %7280, %7281"
"  %7282 = add nuw nsw i32 %7280, %7281" -> "  %7283 = lshr i32 %7282, 16"
"  %7283 = lshr i32 %7282, 16"
"  %7283 = lshr i32 %7282, 16" -> "  %7288 = add nuw nsw i32 %7287, %7283"
"  %7284 = and i32 %7176, 65535"
"  %7284 = and i32 %7176, 65535" -> "  %7285 = add nuw nsw i32 %7259, %7284"
"  %7285 = add nuw nsw i32 %7259, %7284"
"  %7285 = add nuw nsw i32 %7259, %7284" -> "  %7286 = add nuw nsw i32 %7285, %7260"
"  %7286 = add nuw nsw i32 %7285, %7260"
"  %7286 = add nuw nsw i32 %7285, %7260" -> "  %7287 = add nuw nsw i32 %7286, %7266"
"  %7287 = add nuw nsw i32 %7286, %7266"
"  %7287 = add nuw nsw i32 %7286, %7266" -> "  %7288 = add nuw nsw i32 %7287, %7283"
"  %7288 = add nuw nsw i32 %7287, %7283"
"  %7288 = add nuw nsw i32 %7287, %7283" -> "  %8057 = and i32 %7288, 65535""  %7288 = add nuw nsw i32 %7287, %7283" -> "  %7290 = lshr i32 %7288, 16"
"  %7289 = and i32 %7182, 65535"
"  %7289 = and i32 %7182, 65535" -> "  %7291 = add nuw nsw i32 %7290, %7289"
"  %7290 = lshr i32 %7288, 16"
"  %7290 = lshr i32 %7288, 16" -> "  %7291 = add nuw nsw i32 %7290, %7289"
"  %7291 = add nuw nsw i32 %7290, %7289"
"  %7291 = add nuw nsw i32 %7290, %7289" -> "  %8060 = and i32 %7291, 65535""  %7291 = add nuw nsw i32 %7290, %7289" -> "  %7293 = lshr i32 %7291, 16"
"  %7292 = and i32 %7196, 65535"
"  %7292 = and i32 %7196, 65535" -> "  %7294 = add nuw nsw i32 %7293, %7292"
"  %7293 = lshr i32 %7291, 16"
"  %7293 = lshr i32 %7291, 16" -> "  %7294 = add nuw nsw i32 %7293, %7292"
"  %7294 = add nuw nsw i32 %7293, %7292"
"  %7294 = add nuw nsw i32 %7293, %7292" -> "  %8066 = and i32 %7294, 65535""  %7294 = add nuw nsw i32 %7293, %7292" -> "  %7295 = lshr i32 %7294, 16"
"  %7295 = lshr i32 %7294, 16"
"  %7295 = lshr i32 %7294, 16" -> "  %7297 = add nuw nsw i32 %7295, %7296"
"  %7296 = and i32 %7199, 65535"
"  %7296 = and i32 %7199, 65535" -> "  %7297 = add nuw nsw i32 %7295, %7296"
"  %7297 = add nuw nsw i32 %7295, %7296"
"  %7297 = add nuw nsw i32 %7295, %7296" -> "  %8069 = and i32 %7297, 65535""  %7297 = add nuw nsw i32 %7295, %7296" -> "  %7298 = lshr i32 %7297, 16"
"  %7298 = lshr i32 %7297, 16"
"  %7298 = lshr i32 %7297, 16" -> "  %7300 = add nuw nsw i32 %7298, %7299"
"  %7299 = and i32 %7206, 65535"
"  %7299 = and i32 %7206, 65535" -> "  %7300 = add nuw nsw i32 %7298, %7299"
"  %7300 = add nuw nsw i32 %7298, %7299"
"  %7300 = add nuw nsw i32 %7298, %7299" -> "  %8083 = and i32 %7300, 65535""  %7300 = add nuw nsw i32 %7298, %7299" -> "  %7301 = lshr i32 %7300, 16"
"  %7301 = lshr i32 %7300, 16"
"  %7301 = lshr i32 %7300, 16" -> "  %7303 = add nuw nsw i32 %7301, %7302"
"  %7302 = and i32 %7209, 65535"
"  %7302 = and i32 %7209, 65535" -> "  %7303 = add nuw nsw i32 %7301, %7302"
"  %7303 = add nuw nsw i32 %7301, %7302"
"  %7303 = add nuw nsw i32 %7301, %7302" -> "  %8086 = and i32 %7303, 65535""  %7303 = add nuw nsw i32 %7301, %7302" -> "  %7304 = lshr i32 %7303, 16"
"  %7304 = lshr i32 %7303, 16"
"  %7304 = lshr i32 %7303, 16" -> "  %7305 = add nuw i32 %7211, %7304"
"  %7305 = add nuw i32 %7211, %7304"
"  %7305 = add nuw i32 %7211, %7304" -> "  %8092 = and i32 %7305, 65535""  %7305 = add nuw i32 %7211, %7304" -> "  %8095 = lshr i32 %7305, 16"
"  %7306 = mul nuw i32 %5802, 42779"
"  %7306 = mul nuw i32 %5802, 42779" -> "  %7964 = and i32 %7306, 65535""  %7306 = mul nuw i32 %5802, 42779" -> "  %7307 = lshr i32 %7306, 16"
"  %7307 = lshr i32 %7306, 16"
"  %7307 = lshr i32 %7306, 16" -> "  %7310 = add nuw nsw i32 %7309, %7307"
"  %7308 = mul nuw i32 %5803, 42779"
"  %7308 = mul nuw i32 %5803, 42779" -> "  %7311 = and i32 %7308, -65536""  %7308 = mul nuw i32 %5803, 42779" -> "  %7309 = and i32 %7308, 65535"
"  %7309 = and i32 %7308, 65535"
"  %7309 = and i32 %7308, 65535" -> "  %7310 = add nuw nsw i32 %7309, %7307"
"  %7310 = add nuw nsw i32 %7309, %7307"
"  %7310 = add nuw nsw i32 %7309, %7307" -> "  %7312 = add nuw i32 %7310, %7311"
"  %7311 = and i32 %7308, -65536"
"  %7311 = and i32 %7308, -65536" -> "  %7312 = add nuw i32 %7310, %7311"
"  %7312 = add nuw i32 %7310, %7311"
"  %7312 = add nuw i32 %7310, %7311" -> "  %7316 = lshr i32 %7312, 16""  %7312 = add nuw i32 %7310, %7311" -> "  %7314 = and i32 %7312, 65535"
"  %7313 = mul nuw nsw i32 %5802, 9871"
"  %7313 = mul nuw nsw i32 %5802, 9871" -> "  %7315 = add nuw nsw i32 %7314, %7313"
"  %7314 = and i32 %7312, 65535"
"  %7314 = and i32 %7312, 65535" -> "  %7315 = add nuw nsw i32 %7314, %7313"
"  %7315 = add nuw nsw i32 %7314, %7313"
"  %7315 = add nuw nsw i32 %7314, %7313" -> "  %7967 = and i32 %7315, 65535""  %7315 = add nuw nsw i32 %7314, %7313" -> "  %7319 = lshr i32 %7315, 16"
"  %7316 = lshr i32 %7312, 16"
"  %7316 = lshr i32 %7312, 16" -> "  %7318 = add nuw nsw i32 %7316, %7317"
"  %7317 = mul nuw nsw i32 %5803, 9871"
"  %7317 = mul nuw nsw i32 %5803, 9871" -> "  %7318 = add nuw nsw i32 %7316, %7317"
"  %7318 = add nuw nsw i32 %7316, %7317"
"  %7318 = add nuw nsw i32 %7316, %7317" -> "  %7322 = and i32 %7318, 2147418112""  %7318 = add nuw nsw i32 %7316, %7317" -> "  %7320 = and i32 %7318, 65535"
"  %7319 = lshr i32 %7315, 16"
"  %7319 = lshr i32 %7315, 16" -> "  %7321 = add nuw nsw i32 %7319, %7320"
"  %7320 = and i32 %7318, 65535"
"  %7320 = and i32 %7318, 65535" -> "  %7321 = add nuw nsw i32 %7319, %7320"
"  %7321 = add nuw nsw i32 %7319, %7320"
"  %7321 = add nuw nsw i32 %7319, %7320" -> "  %7323 = add nuw nsw i32 %7321, %7322"
"  %7322 = and i32 %7318, 2147418112"
"  %7322 = and i32 %7318, 2147418112" -> "  %7323 = add nuw nsw i32 %7321, %7322"
"  %7323 = add nuw nsw i32 %7321, %7322"
"  %7323 = add nuw nsw i32 %7321, %7322" -> "  %7346 = lshr i32 %7323, 16""  %7323 = add nuw nsw i32 %7321, %7322" -> "  %7342 = and i32 %7323, 65535"
"  %7324 = mul nuw i32 %5822, 42779"
"  %7324 = mul nuw i32 %5822, 42779" -> "  %7343 = and i32 %7324, 65535""  %7324 = mul nuw i32 %5822, 42779" -> "  %7325 = lshr i32 %7324, 16"
"  %7325 = lshr i32 %7324, 16"
"  %7325 = lshr i32 %7324, 16" -> "  %7328 = add nuw nsw i32 %7327, %7325"
"  %7326 = mul nuw i32 %5823, 42779"
"  %7326 = mul nuw i32 %5823, 42779" -> "  %7329 = and i32 %7326, -65536""  %7326 = mul nuw i32 %5823, 42779" -> "  %7327 = and i32 %7326, 65535"
"  %7327 = and i32 %7326, 65535"
"  %7327 = and i32 %7326, 65535" -> "  %7328 = add nuw nsw i32 %7327, %7325"
"  %7328 = add nuw nsw i32 %7327, %7325"
"  %7328 = add nuw nsw i32 %7327, %7325" -> "  %7330 = add nuw i32 %7328, %7329"
"  %7329 = and i32 %7326, -65536"
"  %7329 = and i32 %7326, -65536" -> "  %7330 = add nuw i32 %7328, %7329"
"  %7330 = add nuw i32 %7328, %7329"
"  %7330 = add nuw i32 %7328, %7329" -> "  %7334 = lshr i32 %7330, 16""  %7330 = add nuw i32 %7328, %7329" -> "  %7332 = and i32 %7330, 65535"
"  %7331 = mul nuw nsw i32 %5822, 9871"
"  %7331 = mul nuw nsw i32 %5822, 9871" -> "  %7333 = add nuw nsw i32 %7332, %7331"
"  %7332 = and i32 %7330, 65535"
"  %7332 = and i32 %7330, 65535" -> "  %7333 = add nuw nsw i32 %7332, %7331"
"  %7333 = add nuw nsw i32 %7332, %7331"
"  %7333 = add nuw nsw i32 %7332, %7331" -> "  %7345 = and i32 %7333, 65535""  %7333 = add nuw nsw i32 %7332, %7331" -> "  %7337 = lshr i32 %7333, 16"
"  %7334 = lshr i32 %7330, 16"
"  %7334 = lshr i32 %7330, 16" -> "  %7336 = add nuw nsw i32 %7334, %7335"
"  %7335 = mul nuw nsw i32 %5823, 9871"
"  %7335 = mul nuw nsw i32 %5823, 9871" -> "  %7336 = add nuw nsw i32 %7334, %7335"
"  %7336 = add nuw nsw i32 %7334, %7335"
"  %7336 = add nuw nsw i32 %7334, %7335" -> "  %7340 = and i32 %7336, 2147418112""  %7336 = add nuw nsw i32 %7334, %7335" -> "  %7338 = and i32 %7336, 65535"
"  %7337 = lshr i32 %7333, 16"
"  %7337 = lshr i32 %7333, 16" -> "  %7339 = add nuw nsw i32 %7337, %7338"
"  %7338 = and i32 %7336, 65535"
"  %7338 = and i32 %7336, 65535" -> "  %7339 = add nuw nsw i32 %7337, %7338"
"  %7339 = add nuw nsw i32 %7337, %7338"
"  %7339 = add nuw nsw i32 %7337, %7338" -> "  %7341 = add nuw nsw i32 %7339, %7340"
"  %7340 = and i32 %7336, 2147418112"
"  %7340 = and i32 %7336, 2147418112" -> "  %7341 = add nuw nsw i32 %7339, %7340"
"  %7341 = add nuw nsw i32 %7339, %7340"
"  %7341 = add nuw nsw i32 %7339, %7340" -> "  %7349 = add nuw nsw i32 %7341, %7348"
"  %7342 = and i32 %7323, 65535"
"  %7342 = and i32 %7323, 65535" -> "  %7344 = add nuw nsw i32 %7342, %7343"
"  %7343 = and i32 %7324, 65535"
"  %7343 = and i32 %7324, 65535" -> "  %7344 = add nuw nsw i32 %7342, %7343"
"  %7344 = add nuw nsw i32 %7342, %7343"
"  %7344 = add nuw nsw i32 %7342, %7343" -> "  %7373 = and i32 %7344, 65535""  %7344 = add nuw nsw i32 %7342, %7343" -> "  %7351 = lshr i32 %7344, 16"
"  %7345 = and i32 %7333, 65535"
"  %7345 = and i32 %7333, 65535" -> "  %7347 = add nuw nsw i32 %7345, %7346"
"  %7346 = lshr i32 %7323, 16"
"  %7346 = lshr i32 %7323, 16" -> "  %7347 = add nuw nsw i32 %7345, %7346"
"  %7347 = add nuw nsw i32 %7345, %7346"
"  %7347 = add nuw nsw i32 %7345, %7346" -> "  %7350 = and i32 %7347, 65535""  %7347 = add nuw nsw i32 %7345, %7346" -> "  %7348 = lshr i32 %7347, 16"
"  %7348 = lshr i32 %7347, 16"
"  %7348 = lshr i32 %7347, 16" -> "  %7349 = add nuw nsw i32 %7341, %7348"
"  %7349 = add nuw nsw i32 %7341, %7348"
"  %7349 = add nuw nsw i32 %7341, %7348" -> "  %7354 = add nuw nsw i32 %7349, %7353"
"  %7350 = and i32 %7347, 65535"
"  %7350 = and i32 %7347, 65535" -> "  %7352 = add nuw nsw i32 %7350, %7351"
"  %7351 = lshr i32 %7344, 16"
"  %7351 = lshr i32 %7344, 16" -> "  %7352 = add nuw nsw i32 %7350, %7351"
"  %7352 = add nuw nsw i32 %7350, %7351"
"  %7352 = add nuw nsw i32 %7350, %7351" -> "  %7376 = and i32 %7352, 65535""  %7352 = add nuw nsw i32 %7350, %7351" -> "  %7353 = lshr i32 %7352, 16"
"  %7353 = lshr i32 %7352, 16"
"  %7353 = lshr i32 %7352, 16" -> "  %7354 = add nuw nsw i32 %7349, %7353"
"  %7354 = add nuw nsw i32 %7349, %7353"
"  %7354 = add nuw nsw i32 %7349, %7353" -> "  %7404 = lshr i32 %7354, 16""  %7354 = add nuw nsw i32 %7349, %7353" -> "  %7402 = and i32 %7354, 65535"
"  %7355 = mul nuw nsw i32 %5802, 24315"
"  %7355 = mul nuw nsw i32 %5802, 24315" -> "  %7374 = and i32 %7355, 65535""  %7355 = mul nuw nsw i32 %5802, 24315" -> "  %7356 = lshr i32 %7355, 16"
"  %7356 = lshr i32 %7355, 16"
"  %7356 = lshr i32 %7355, 16" -> "  %7359 = add nuw nsw i32 %7358, %7356"
"  %7357 = mul nuw nsw i32 %5803, 24315"
"  %7357 = mul nuw nsw i32 %5803, 24315" -> "  %7360 = and i32 %7357, 2147418112""  %7357 = mul nuw nsw i32 %5803, 24315" -> "  %7358 = and i32 %7357, 65535"
"  %7358 = and i32 %7357, 65535"
"  %7358 = and i32 %7357, 65535" -> "  %7359 = add nuw nsw i32 %7358, %7356"
"  %7359 = add nuw nsw i32 %7358, %7356"
"  %7359 = add nuw nsw i32 %7358, %7356" -> "  %7361 = add nuw nsw i32 %7359, %7360"
"  %7360 = and i32 %7357, 2147418112"
"  %7360 = and i32 %7357, 2147418112" -> "  %7361 = add nuw nsw i32 %7359, %7360"
"  %7361 = add nuw nsw i32 %7359, %7360"
"  %7361 = add nuw nsw i32 %7359, %7360" -> "  %7365 = lshr i32 %7361, 16""  %7361 = add nuw nsw i32 %7359, %7360" -> "  %7363 = and i32 %7361, 65535"
"  %7362 = mul nuw nsw i32 %5802, 29744"
"  %7362 = mul nuw nsw i32 %5802, 29744" -> "  %7364 = add nuw nsw i32 %7363, %7362"
"  %7363 = and i32 %7361, 65535"
"  %7363 = and i32 %7361, 65535" -> "  %7364 = add nuw nsw i32 %7363, %7362"
"  %7364 = add nuw nsw i32 %7363, %7362"
"  %7364 = add nuw nsw i32 %7363, %7362" -> "  %7377 = and i32 %7364, 65535""  %7364 = add nuw nsw i32 %7363, %7362" -> "  %7368 = lshr i32 %7364, 16"
"  %7365 = lshr i32 %7361, 16"
"  %7365 = lshr i32 %7361, 16" -> "  %7367 = add nuw nsw i32 %7365, %7366"
"  %7366 = mul nuw nsw i32 %5803, 29744"
"  %7366 = mul nuw nsw i32 %5803, 29744" -> "  %7367 = add nuw nsw i32 %7365, %7366"
"  %7367 = add nuw nsw i32 %7365, %7366"
"  %7367 = add nuw nsw i32 %7365, %7366" -> "  %7371 = and i32 %7367, 2147418112""  %7367 = add nuw nsw i32 %7365, %7366" -> "  %7369 = and i32 %7367, 65535"
"  %7368 = lshr i32 %7364, 16"
"  %7368 = lshr i32 %7364, 16" -> "  %7370 = add nuw nsw i32 %7368, %7369"
"  %7369 = and i32 %7367, 65535"
"  %7369 = and i32 %7367, 65535" -> "  %7370 = add nuw nsw i32 %7368, %7369"
"  %7370 = add nuw nsw i32 %7368, %7369"
"  %7370 = add nuw nsw i32 %7368, %7369" -> "  %7372 = add nuw nsw i32 %7370, %7371"
"  %7371 = and i32 %7367, 2147418112"
"  %7371 = and i32 %7367, 2147418112" -> "  %7372 = add nuw nsw i32 %7370, %7371"
"  %7372 = add nuw nsw i32 %7370, %7371"
"  %7372 = add nuw nsw i32 %7370, %7371" -> "  %7380 = add nuw nsw i32 %7372, %7379"
"  %7373 = and i32 %7344, 65535"
"  %7373 = and i32 %7344, 65535" -> "  %7375 = add nuw nsw i32 %7373, %7374"
"  %7374 = and i32 %7355, 65535"
"  %7374 = and i32 %7355, 65535" -> "  %7375 = add nuw nsw i32 %7373, %7374"
"  %7375 = add nuw nsw i32 %7373, %7374"
"  %7375 = add nuw nsw i32 %7373, %7374" -> "  %7973 = and i32 %7375, 65535""  %7375 = add nuw nsw i32 %7373, %7374" -> "  %7382 = lshr i32 %7375, 16"
"  %7376 = and i32 %7352, 65535"
"  %7376 = and i32 %7352, 65535" -> "  %7378 = add nuw nsw i32 %7376, %7377"
"  %7377 = and i32 %7364, 65535"
"  %7377 = and i32 %7364, 65535" -> "  %7378 = add nuw nsw i32 %7376, %7377"
"  %7378 = add nuw nsw i32 %7376, %7377"
"  %7378 = add nuw nsw i32 %7376, %7377" -> "  %7381 = and i32 %7378, 65535""  %7378 = add nuw nsw i32 %7376, %7377" -> "  %7379 = lshr i32 %7378, 16"
"  %7379 = lshr i32 %7378, 16"
"  %7379 = lshr i32 %7378, 16" -> "  %7380 = add nuw nsw i32 %7372, %7379"
"  %7380 = add nuw nsw i32 %7372, %7379"
"  %7380 = add nuw nsw i32 %7372, %7379" -> "  %7385 = add nuw nsw i32 %7380, %7384"
"  %7381 = and i32 %7378, 65535"
"  %7381 = and i32 %7378, 65535" -> "  %7383 = add nuw nsw i32 %7381, %7382"
"  %7382 = lshr i32 %7375, 16"
"  %7382 = lshr i32 %7375, 16" -> "  %7383 = add nuw nsw i32 %7381, %7382"
"  %7383 = add nuw nsw i32 %7381, %7382"
"  %7383 = add nuw nsw i32 %7381, %7382" -> "  %7976 = and i32 %7383, 65535""  %7383 = add nuw nsw i32 %7381, %7382" -> "  %7384 = lshr i32 %7383, 16"
"  %7384 = lshr i32 %7383, 16"
"  %7384 = lshr i32 %7383, 16" -> "  %7385 = add nuw nsw i32 %7380, %7384"
"  %7385 = add nuw nsw i32 %7380, %7384"
"  %7385 = add nuw nsw i32 %7380, %7384" -> "  %7415 = and i32 %7385, 65535""  %7385 = add nuw nsw i32 %7380, %7384" -> "  %7418 = lshr i32 %7385, 16"
"  %7386 = mul nuw nsw i32 %5822, 24315"
"  %7386 = mul nuw nsw i32 %5822, 24315" -> "  %7401 = and i32 %7386, 65535""  %7386 = mul nuw nsw i32 %5822, 24315" -> "  %7387 = lshr i32 %7386, 16"
"  %7387 = lshr i32 %7386, 16"
"  %7387 = lshr i32 %7386, 16" -> "  %7389 = add nuw nsw i32 %7388, %7387"
"  %7388 = mul nuw nsw i32 %5823, 24315"
"  %7388 = mul nuw nsw i32 %5823, 24315" -> "  %7389 = add nuw nsw i32 %7388, %7387"
"  %7389 = add nuw nsw i32 %7388, %7387"
"  %7389 = add nuw nsw i32 %7388, %7387" -> "  %7393 = lshr i32 %7389, 16""  %7389 = add nuw nsw i32 %7388, %7387" -> "  %7391 = and i32 %7389, 65535"
"  %7390 = mul nuw nsw i32 %5822, 29744"
"  %7390 = mul nuw nsw i32 %5822, 29744" -> "  %7392 = add nuw nsw i32 %7391, %7390"
"  %7391 = and i32 %7389, 65535"
"  %7391 = and i32 %7389, 65535" -> "  %7392 = add nuw nsw i32 %7391, %7390"
"  %7392 = add nuw nsw i32 %7391, %7390"
"  %7392 = add nuw nsw i32 %7391, %7390" -> "  %7405 = and i32 %7392, 65535""  %7392 = add nuw nsw i32 %7391, %7390" -> "  %7396 = lshr i32 %7392, 16"
"  %7393 = lshr i32 %7389, 16"
"  %7393 = lshr i32 %7389, 16" -> "  %7395 = add nuw nsw i32 %7393, %7394"
"  %7394 = mul nuw nsw i32 %5823, 29744"
"  %7394 = mul nuw nsw i32 %5823, 29744" -> "  %7395 = add nuw nsw i32 %7393, %7394"
"  %7395 = add nuw nsw i32 %7393, %7394"
"  %7395 = add nuw nsw i32 %7393, %7394" -> "  %7399 = and i32 %7395, 2147418112""  %7395 = add nuw nsw i32 %7393, %7394" -> "  %7397 = and i32 %7395, 65535"
"  %7396 = lshr i32 %7392, 16"
"  %7396 = lshr i32 %7392, 16" -> "  %7398 = add nuw nsw i32 %7396, %7397"
"  %7397 = and i32 %7395, 65535"
"  %7397 = and i32 %7395, 65535" -> "  %7398 = add nuw nsw i32 %7396, %7397"
"  %7398 = add nuw nsw i32 %7396, %7397"
"  %7398 = add nuw nsw i32 %7396, %7397" -> "  %7400 = add nuw nsw i32 %7398, %7399"
"  %7399 = and i32 %7395, 2147418112"
"  %7399 = and i32 %7395, 2147418112" -> "  %7400 = add nuw nsw i32 %7398, %7399"
"  %7400 = add nuw nsw i32 %7398, %7399"
"  %7400 = add nuw nsw i32 %7398, %7399" -> "  %7408 = add nuw nsw i32 %7400, %7407"
"  %7401 = and i32 %7386, 65535"
"  %7401 = and i32 %7386, 65535" -> "  %7403 = add nuw nsw i32 %7402, %7401"
"  %7402 = and i32 %7354, 65535"
"  %7402 = and i32 %7354, 65535" -> "  %7403 = add nuw nsw i32 %7402, %7401"
"  %7403 = add nuw nsw i32 %7402, %7401"
"  %7403 = add nuw nsw i32 %7402, %7401" -> "  %7414 = and i32 %7403, 65535""  %7403 = add nuw nsw i32 %7402, %7401" -> "  %7410 = lshr i32 %7403, 16"
"  %7404 = lshr i32 %7354, 16"
"  %7404 = lshr i32 %7354, 16" -> "  %7406 = add nuw nsw i32 %7404, %7405"
"  %7405 = and i32 %7392, 65535"
"  %7405 = and i32 %7392, 65535" -> "  %7406 = add nuw nsw i32 %7404, %7405"
"  %7406 = add nuw nsw i32 %7404, %7405"
"  %7406 = add nuw nsw i32 %7404, %7405" -> "  %7409 = and i32 %7406, 65535""  %7406 = add nuw nsw i32 %7404, %7405" -> "  %7407 = lshr i32 %7406, 16"
"  %7407 = lshr i32 %7406, 16"
"  %7407 = lshr i32 %7406, 16" -> "  %7408 = add nuw nsw i32 %7400, %7407"
"  %7408 = add nuw nsw i32 %7400, %7407"
"  %7408 = add nuw nsw i32 %7400, %7407" -> "  %7413 = add nuw nsw i32 %7408, %7412"
"  %7409 = and i32 %7406, 65535"
"  %7409 = and i32 %7406, 65535" -> "  %7411 = add nuw nsw i32 %7409, %7410"
"  %7410 = lshr i32 %7403, 16"
"  %7410 = lshr i32 %7403, 16" -> "  %7411 = add nuw nsw i32 %7409, %7410"
"  %7411 = add nuw nsw i32 %7409, %7410"
"  %7411 = add nuw nsw i32 %7409, %7410" -> "  %7417 = and i32 %7411, 65535""  %7411 = add nuw nsw i32 %7409, %7410" -> "  %7412 = lshr i32 %7411, 16"
"  %7412 = lshr i32 %7411, 16"
"  %7412 = lshr i32 %7411, 16" -> "  %7413 = add nuw nsw i32 %7408, %7412"
"  %7413 = add nuw nsw i32 %7408, %7412"
"  %7413 = add nuw nsw i32 %7408, %7412" -> "  %7426 = and i32 %7413, 2147418112""  %7413 = add nuw nsw i32 %7408, %7412" -> "  %7424 = and i32 %7413, 65535"
"  %7414 = and i32 %7403, 65535"
"  %7414 = and i32 %7403, 65535" -> "  %7416 = add nuw nsw i32 %7415, %7414"
"  %7415 = and i32 %7385, 65535"
"  %7415 = and i32 %7385, 65535" -> "  %7416 = add nuw nsw i32 %7415, %7414"
"  %7416 = add nuw nsw i32 %7415, %7414"
"  %7416 = add nuw nsw i32 %7415, %7414" -> "  %7557 = and i32 %7416, 65535""  %7416 = add nuw nsw i32 %7415, %7414" -> "  %7420 = lshr i32 %7416, 16"
"  %7417 = and i32 %7411, 65535"
"  %7417 = and i32 %7411, 65535" -> "  %7419 = add nuw nsw i32 %7418, %7417"
"  %7418 = lshr i32 %7385, 16"
"  %7418 = lshr i32 %7385, 16" -> "  %7419 = add nuw nsw i32 %7418, %7417"
"  %7419 = add nuw nsw i32 %7418, %7417"
"  %7419 = add nuw nsw i32 %7418, %7417" -> "  %7423 = lshr i32 %7419, 16""  %7419 = add nuw nsw i32 %7418, %7417" -> "  %7421 = and i32 %7419, 65535"
"  %7420 = lshr i32 %7416, 16"
"  %7420 = lshr i32 %7416, 16" -> "  %7422 = add nuw nsw i32 %7421, %7420"
"  %7421 = and i32 %7419, 65535"
"  %7421 = and i32 %7419, 65535" -> "  %7422 = add nuw nsw i32 %7421, %7420"
"  %7422 = add nuw nsw i32 %7421, %7420"
"  %7422 = add nuw nsw i32 %7421, %7420" -> "  %7560 = and i32 %7422, 65535""  %7422 = add nuw nsw i32 %7421, %7420" -> "  %7428 = lshr i32 %7422, 16"
"  %7423 = lshr i32 %7419, 16"
"  %7423 = lshr i32 %7419, 16" -> "  %7425 = add nuw nsw i32 %7423, %7424"
"  %7424 = and i32 %7413, 65535"
"  %7424 = and i32 %7413, 65535" -> "  %7425 = add nuw nsw i32 %7423, %7424"
"  %7425 = add nuw nsw i32 %7423, %7424"
"  %7425 = add nuw nsw i32 %7423, %7424" -> "  %7427 = add nuw nsw i32 %7425, %7426"
"  %7426 = and i32 %7413, 2147418112"
"  %7426 = and i32 %7413, 2147418112" -> "  %7427 = add nuw nsw i32 %7425, %7426"
"  %7427 = add nuw nsw i32 %7425, %7426"
"  %7427 = add nuw nsw i32 %7425, %7426" -> "  %7429 = add nuw nsw i32 %7427, %7428"
"  %7428 = lshr i32 %7422, 16"
"  %7428 = lshr i32 %7422, 16" -> "  %7429 = add nuw nsw i32 %7427, %7428"
"  %7429 = add nuw nsw i32 %7427, %7428"
"  %7429 = add nuw nsw i32 %7427, %7428" -> "  %7569 = lshr i32 %7429, 16""  %7429 = add nuw nsw i32 %7427, %7428" -> "  %7567 = and i32 %7429, 65535"
"  %7430 = mul nuw i32 %5936, 42779"
"  %7430 = mul nuw i32 %5936, 42779" -> "  %7558 = and i32 %7430, 65535""  %7430 = mul nuw i32 %5936, 42779" -> "  %7431 = lshr i32 %7430, 16"
"  %7431 = lshr i32 %7430, 16"
"  %7431 = lshr i32 %7430, 16" -> "  %7434 = add nuw nsw i32 %7433, %7431"
"  %7432 = mul nuw i32 %5939, 42779"
"  %7432 = mul nuw i32 %5939, 42779" -> "  %7435 = and i32 %7432, -65536""  %7432 = mul nuw i32 %5939, 42779" -> "  %7433 = and i32 %7432, 65535"
"  %7433 = and i32 %7432, 65535"
"  %7433 = and i32 %7432, 65535" -> "  %7434 = add nuw nsw i32 %7433, %7431"
"  %7434 = add nuw nsw i32 %7433, %7431"
"  %7434 = add nuw nsw i32 %7433, %7431" -> "  %7436 = add nuw i32 %7434, %7435"
"  %7435 = and i32 %7432, -65536"
"  %7435 = and i32 %7432, -65536" -> "  %7436 = add nuw i32 %7434, %7435"
"  %7436 = add nuw i32 %7434, %7435"
"  %7436 = add nuw i32 %7434, %7435" -> "  %7440 = lshr i32 %7436, 16""  %7436 = add nuw i32 %7434, %7435" -> "  %7438 = and i32 %7436, 65535"
"  %7437 = mul nuw nsw i32 %5936, 9871"
"  %7437 = mul nuw nsw i32 %5936, 9871" -> "  %7439 = add nuw nsw i32 %7438, %7437"
"  %7438 = and i32 %7436, 65535"
"  %7438 = and i32 %7436, 65535" -> "  %7439 = add nuw nsw i32 %7438, %7437"
"  %7439 = add nuw nsw i32 %7438, %7437"
"  %7439 = add nuw nsw i32 %7438, %7437" -> "  %7561 = and i32 %7439, 65535""  %7439 = add nuw nsw i32 %7438, %7437" -> "  %7443 = lshr i32 %7439, 16"
"  %7440 = lshr i32 %7436, 16"
"  %7440 = lshr i32 %7436, 16" -> "  %7442 = add nuw nsw i32 %7440, %7441"
"  %7441 = mul nuw nsw i32 %5939, 9871"
"  %7441 = mul nuw nsw i32 %5939, 9871" -> "  %7442 = add nuw nsw i32 %7440, %7441"
"  %7442 = add nuw nsw i32 %7440, %7441"
"  %7442 = add nuw nsw i32 %7440, %7441" -> "  %7446 = and i32 %7442, 2147418112""  %7442 = add nuw nsw i32 %7440, %7441" -> "  %7444 = and i32 %7442, 65535"
"  %7443 = lshr i32 %7439, 16"
"  %7443 = lshr i32 %7439, 16" -> "  %7445 = add nuw nsw i32 %7443, %7444"
"  %7444 = and i32 %7442, 65535"
"  %7444 = and i32 %7442, 65535" -> "  %7445 = add nuw nsw i32 %7443, %7444"
"  %7445 = add nuw nsw i32 %7443, %7444"
"  %7445 = add nuw nsw i32 %7443, %7444" -> "  %7447 = add nuw nsw i32 %7445, %7446"
"  %7446 = and i32 %7442, 2147418112"
"  %7446 = and i32 %7442, 2147418112" -> "  %7447 = add nuw nsw i32 %7445, %7446"
"  %7447 = add nuw nsw i32 %7445, %7446"
"  %7447 = add nuw nsw i32 %7445, %7446" -> "  %7470 = lshr i32 %7447, 16""  %7447 = add nuw nsw i32 %7445, %7446" -> "  %7466 = and i32 %7447, 65535"
"  %7448 = mul nuw i32 %5956, 42779"
"  %7448 = mul nuw i32 %5956, 42779" -> "  %7467 = and i32 %7448, 65535""  %7448 = mul nuw i32 %5956, 42779" -> "  %7449 = lshr i32 %7448, 16"
"  %7449 = lshr i32 %7448, 16"
"  %7449 = lshr i32 %7448, 16" -> "  %7452 = add nuw nsw i32 %7451, %7449"
"  %7450 = mul nuw i32 %5957, 42779"
"  %7450 = mul nuw i32 %5957, 42779" -> "  %7453 = and i32 %7450, -65536""  %7450 = mul nuw i32 %5957, 42779" -> "  %7451 = and i32 %7450, 65535"
"  %7451 = and i32 %7450, 65535"
"  %7451 = and i32 %7450, 65535" -> "  %7452 = add nuw nsw i32 %7451, %7449"
"  %7452 = add nuw nsw i32 %7451, %7449"
"  %7452 = add nuw nsw i32 %7451, %7449" -> "  %7454 = add nuw i32 %7452, %7453"
"  %7453 = and i32 %7450, -65536"
"  %7453 = and i32 %7450, -65536" -> "  %7454 = add nuw i32 %7452, %7453"
"  %7454 = add nuw i32 %7452, %7453"
"  %7454 = add nuw i32 %7452, %7453" -> "  %7458 = lshr i32 %7454, 16""  %7454 = add nuw i32 %7452, %7453" -> "  %7456 = and i32 %7454, 65535"
"  %7455 = mul nuw nsw i32 %5956, 9871"
"  %7455 = mul nuw nsw i32 %5956, 9871" -> "  %7457 = add nuw nsw i32 %7456, %7455"
"  %7456 = and i32 %7454, 65535"
"  %7456 = and i32 %7454, 65535" -> "  %7457 = add nuw nsw i32 %7456, %7455"
"  %7457 = add nuw nsw i32 %7456, %7455"
"  %7457 = add nuw nsw i32 %7456, %7455" -> "  %7469 = and i32 %7457, 65535""  %7457 = add nuw nsw i32 %7456, %7455" -> "  %7461 = lshr i32 %7457, 16"
"  %7458 = lshr i32 %7454, 16"
"  %7458 = lshr i32 %7454, 16" -> "  %7460 = add nuw nsw i32 %7458, %7459"
"  %7459 = mul nuw nsw i32 %5957, 9871"
"  %7459 = mul nuw nsw i32 %5957, 9871" -> "  %7460 = add nuw nsw i32 %7458, %7459"
"  %7460 = add nuw nsw i32 %7458, %7459"
"  %7460 = add nuw nsw i32 %7458, %7459" -> "  %7464 = and i32 %7460, 2147418112""  %7460 = add nuw nsw i32 %7458, %7459" -> "  %7462 = and i32 %7460, 65535"
"  %7461 = lshr i32 %7457, 16"
"  %7461 = lshr i32 %7457, 16" -> "  %7463 = add nuw nsw i32 %7461, %7462"
"  %7462 = and i32 %7460, 65535"
"  %7462 = and i32 %7460, 65535" -> "  %7463 = add nuw nsw i32 %7461, %7462"
"  %7463 = add nuw nsw i32 %7461, %7462"
"  %7463 = add nuw nsw i32 %7461, %7462" -> "  %7465 = add nuw nsw i32 %7463, %7464"
"  %7464 = and i32 %7460, 2147418112"
"  %7464 = and i32 %7460, 2147418112" -> "  %7465 = add nuw nsw i32 %7463, %7464"
"  %7465 = add nuw nsw i32 %7463, %7464"
"  %7465 = add nuw nsw i32 %7463, %7464" -> "  %7473 = add nuw nsw i32 %7465, %7472"
"  %7466 = and i32 %7447, 65535"
"  %7466 = and i32 %7447, 65535" -> "  %7468 = add nuw nsw i32 %7466, %7467"
"  %7467 = and i32 %7448, 65535"
"  %7467 = and i32 %7448, 65535" -> "  %7468 = add nuw nsw i32 %7466, %7467"
"  %7468 = add nuw nsw i32 %7466, %7467"
"  %7468 = add nuw nsw i32 %7466, %7467" -> "  %7497 = and i32 %7468, 65535""  %7468 = add nuw nsw i32 %7466, %7467" -> "  %7475 = lshr i32 %7468, 16"
"  %7469 = and i32 %7457, 65535"
"  %7469 = and i32 %7457, 65535" -> "  %7471 = add nuw nsw i32 %7470, %7469"
"  %7470 = lshr i32 %7447, 16"
"  %7470 = lshr i32 %7447, 16" -> "  %7471 = add nuw nsw i32 %7470, %7469"
"  %7471 = add nuw nsw i32 %7470, %7469"
"  %7471 = add nuw nsw i32 %7470, %7469" -> "  %7474 = and i32 %7471, 65535""  %7471 = add nuw nsw i32 %7470, %7469" -> "  %7472 = lshr i32 %7471, 16"
"  %7472 = lshr i32 %7471, 16"
"  %7472 = lshr i32 %7471, 16" -> "  %7473 = add nuw nsw i32 %7465, %7472"
"  %7473 = add nuw nsw i32 %7465, %7472"
"  %7473 = add nuw nsw i32 %7465, %7472" -> "  %7478 = add nuw nsw i32 %7473, %7477"
"  %7474 = and i32 %7471, 65535"
"  %7474 = and i32 %7471, 65535" -> "  %7476 = add nuw nsw i32 %7474, %7475"
"  %7475 = lshr i32 %7468, 16"
"  %7475 = lshr i32 %7468, 16" -> "  %7476 = add nuw nsw i32 %7474, %7475"
"  %7476 = add nuw nsw i32 %7474, %7475"
"  %7476 = add nuw nsw i32 %7474, %7475" -> "  %7500 = and i32 %7476, 65535""  %7476 = add nuw nsw i32 %7474, %7475" -> "  %7477 = lshr i32 %7476, 16"
"  %7477 = lshr i32 %7476, 16"
"  %7477 = lshr i32 %7476, 16" -> "  %7478 = add nuw nsw i32 %7473, %7477"
"  %7478 = add nuw nsw i32 %7473, %7477"
"  %7478 = add nuw nsw i32 %7473, %7477" -> "  %7532 = lshr i32 %7478, 16""  %7478 = add nuw nsw i32 %7473, %7477" -> "  %7528 = and i32 %7478, 65535"
"  %7479 = mul nuw nsw i32 %5936, 24315"
"  %7479 = mul nuw nsw i32 %5936, 24315" -> "  %7498 = and i32 %7479, 65535""  %7479 = mul nuw nsw i32 %5936, 24315" -> "  %7480 = lshr i32 %7479, 16"
"  %7480 = lshr i32 %7479, 16"
"  %7480 = lshr i32 %7479, 16" -> "  %7483 = add nuw nsw i32 %7482, %7480"
"  %7481 = mul nuw nsw i32 %5939, 24315"
"  %7481 = mul nuw nsw i32 %5939, 24315" -> "  %7484 = and i32 %7481, 2147418112""  %7481 = mul nuw nsw i32 %5939, 24315" -> "  %7482 = and i32 %7481, 65535"
"  %7482 = and i32 %7481, 65535"
"  %7482 = and i32 %7481, 65535" -> "  %7483 = add nuw nsw i32 %7482, %7480"
"  %7483 = add nuw nsw i32 %7482, %7480"
"  %7483 = add nuw nsw i32 %7482, %7480" -> "  %7485 = add nuw nsw i32 %7483, %7484"
"  %7484 = and i32 %7481, 2147418112"
"  %7484 = and i32 %7481, 2147418112" -> "  %7485 = add nuw nsw i32 %7483, %7484"
"  %7485 = add nuw nsw i32 %7483, %7484"
"  %7485 = add nuw nsw i32 %7483, %7484" -> "  %7489 = lshr i32 %7485, 16""  %7485 = add nuw nsw i32 %7483, %7484" -> "  %7487 = and i32 %7485, 65535"
"  %7486 = mul nuw nsw i32 %5936, 29744"
"  %7486 = mul nuw nsw i32 %5936, 29744" -> "  %7488 = add nuw nsw i32 %7487, %7486"
"  %7487 = and i32 %7485, 65535"
"  %7487 = and i32 %7485, 65535" -> "  %7488 = add nuw nsw i32 %7487, %7486"
"  %7488 = add nuw nsw i32 %7487, %7486"
"  %7488 = add nuw nsw i32 %7487, %7486" -> "  %7501 = and i32 %7488, 65535""  %7488 = add nuw nsw i32 %7487, %7486" -> "  %7492 = lshr i32 %7488, 16"
"  %7489 = lshr i32 %7485, 16"
"  %7489 = lshr i32 %7485, 16" -> "  %7491 = add nuw nsw i32 %7489, %7490"
"  %7490 = mul nuw nsw i32 %5939, 29744"
"  %7490 = mul nuw nsw i32 %5939, 29744" -> "  %7491 = add nuw nsw i32 %7489, %7490"
"  %7491 = add nuw nsw i32 %7489, %7490"
"  %7491 = add nuw nsw i32 %7489, %7490" -> "  %7495 = and i32 %7491, 2147418112""  %7491 = add nuw nsw i32 %7489, %7490" -> "  %7493 = and i32 %7491, 65535"
"  %7492 = lshr i32 %7488, 16"
"  %7492 = lshr i32 %7488, 16" -> "  %7494 = add nuw nsw i32 %7492, %7493"
"  %7493 = and i32 %7491, 65535"
"  %7493 = and i32 %7491, 65535" -> "  %7494 = add nuw nsw i32 %7492, %7493"
"  %7494 = add nuw nsw i32 %7492, %7493"
"  %7494 = add nuw nsw i32 %7492, %7493" -> "  %7496 = add nuw nsw i32 %7494, %7495"
"  %7495 = and i32 %7491, 2147418112"
"  %7495 = and i32 %7491, 2147418112" -> "  %7496 = add nuw nsw i32 %7494, %7495"
"  %7496 = add nuw nsw i32 %7494, %7495"
"  %7496 = add nuw nsw i32 %7494, %7495" -> "  %7504 = add nuw nsw i32 %7496, %7503"
"  %7497 = and i32 %7468, 65535"
"  %7497 = and i32 %7468, 65535" -> "  %7499 = add nuw nsw i32 %7497, %7498"
"  %7498 = and i32 %7479, 65535"
"  %7498 = and i32 %7479, 65535" -> "  %7499 = add nuw nsw i32 %7497, %7498"
"  %7499 = add nuw nsw i32 %7497, %7498"
"  %7499 = add nuw nsw i32 %7497, %7498" -> "  %7566 = and i32 %7499, 65535""  %7499 = add nuw nsw i32 %7497, %7498" -> "  %7506 = lshr i32 %7499, 16"
"  %7500 = and i32 %7476, 65535"
"  %7500 = and i32 %7476, 65535" -> "  %7502 = add nuw nsw i32 %7500, %7501"
"  %7501 = and i32 %7488, 65535"
"  %7501 = and i32 %7488, 65535" -> "  %7502 = add nuw nsw i32 %7500, %7501"
"  %7502 = add nuw nsw i32 %7500, %7501"
"  %7502 = add nuw nsw i32 %7500, %7501" -> "  %7505 = and i32 %7502, 65535""  %7502 = add nuw nsw i32 %7500, %7501" -> "  %7503 = lshr i32 %7502, 16"
"  %7503 = lshr i32 %7502, 16"
"  %7503 = lshr i32 %7502, 16" -> "  %7504 = add nuw nsw i32 %7496, %7503"
"  %7504 = add nuw nsw i32 %7496, %7503"
"  %7504 = add nuw nsw i32 %7496, %7503" -> "  %7509 = add nuw nsw i32 %7504, %7508"
"  %7505 = and i32 %7502, 65535"
"  %7505 = and i32 %7502, 65535" -> "  %7507 = add nuw nsw i32 %7505, %7506"
"  %7506 = lshr i32 %7499, 16"
"  %7506 = lshr i32 %7499, 16" -> "  %7507 = add nuw nsw i32 %7505, %7506"
"  %7507 = add nuw nsw i32 %7505, %7506"
"  %7507 = add nuw nsw i32 %7505, %7506" -> "  %7570 = and i32 %7507, 65535""  %7507 = add nuw nsw i32 %7505, %7506" -> "  %7508 = lshr i32 %7507, 16"
"  %7508 = lshr i32 %7507, 16"
"  %7508 = lshr i32 %7507, 16" -> "  %7509 = add nuw nsw i32 %7504, %7508"
"  %7509 = add nuw nsw i32 %7504, %7508"
"  %7509 = add nuw nsw i32 %7504, %7508" -> "  %7545 = lshr i32 %7509, 16""  %7509 = add nuw nsw i32 %7504, %7508" -> "  %7542 = and i32 %7509, 65535"
"  %7510 = mul nuw nsw i32 %5956, 24315"
"  %7510 = mul nuw nsw i32 %5956, 24315" -> "  %7529 = and i32 %7510, 65535""  %7510 = mul nuw nsw i32 %5956, 24315" -> "  %7511 = lshr i32 %7510, 16"
"  %7511 = lshr i32 %7510, 16"
"  %7511 = lshr i32 %7510, 16" -> "  %7514 = add nuw nsw i32 %7513, %7511"
"  %7512 = mul nuw nsw i32 %5957, 24315"
"  %7512 = mul nuw nsw i32 %5957, 24315" -> "  %7515 = and i32 %7512, 2147418112""  %7512 = mul nuw nsw i32 %5957, 24315" -> "  %7513 = and i32 %7512, 65535"
"  %7513 = and i32 %7512, 65535"
"  %7513 = and i32 %7512, 65535" -> "  %7514 = add nuw nsw i32 %7513, %7511"
"  %7514 = add nuw nsw i32 %7513, %7511"
"  %7514 = add nuw nsw i32 %7513, %7511" -> "  %7516 = add nuw nsw i32 %7514, %7515"
"  %7515 = and i32 %7512, 2147418112"
"  %7515 = and i32 %7512, 2147418112" -> "  %7516 = add nuw nsw i32 %7514, %7515"
"  %7516 = add nuw nsw i32 %7514, %7515"
"  %7516 = add nuw nsw i32 %7514, %7515" -> "  %7520 = lshr i32 %7516, 16""  %7516 = add nuw nsw i32 %7514, %7515" -> "  %7518 = and i32 %7516, 65535"
"  %7517 = mul nuw nsw i32 %5956, 29744"
"  %7517 = mul nuw nsw i32 %5956, 29744" -> "  %7519 = add nuw nsw i32 %7518, %7517"
"  %7518 = and i32 %7516, 65535"
"  %7518 = and i32 %7516, 65535" -> "  %7519 = add nuw nsw i32 %7518, %7517"
"  %7519 = add nuw nsw i32 %7518, %7517"
"  %7519 = add nuw nsw i32 %7518, %7517" -> "  %7531 = and i32 %7519, 65535""  %7519 = add nuw nsw i32 %7518, %7517" -> "  %7523 = lshr i32 %7519, 16"
"  %7520 = lshr i32 %7516, 16"
"  %7520 = lshr i32 %7516, 16" -> "  %7522 = add nuw nsw i32 %7520, %7521"
"  %7521 = mul nuw nsw i32 %5957, 29744"
"  %7521 = mul nuw nsw i32 %5957, 29744" -> "  %7522 = add nuw nsw i32 %7520, %7521"
"  %7522 = add nuw nsw i32 %7520, %7521"
"  %7522 = add nuw nsw i32 %7520, %7521" -> "  %7526 = and i32 %7522, 2147418112""  %7522 = add nuw nsw i32 %7520, %7521" -> "  %7524 = and i32 %7522, 65535"
"  %7523 = lshr i32 %7519, 16"
"  %7523 = lshr i32 %7519, 16" -> "  %7525 = add nuw nsw i32 %7523, %7524"
"  %7524 = and i32 %7522, 65535"
"  %7524 = and i32 %7522, 65535" -> "  %7525 = add nuw nsw i32 %7523, %7524"
"  %7525 = add nuw nsw i32 %7523, %7524"
"  %7525 = add nuw nsw i32 %7523, %7524" -> "  %7527 = add nuw nsw i32 %7525, %7526"
"  %7526 = and i32 %7522, 2147418112"
"  %7526 = and i32 %7522, 2147418112" -> "  %7527 = add nuw nsw i32 %7525, %7526"
"  %7527 = add nuw nsw i32 %7525, %7526"
"  %7527 = add nuw nsw i32 %7525, %7526" -> "  %7535 = add nuw nsw i32 %7527, %7534"
"  %7528 = and i32 %7478, 65535"
"  %7528 = and i32 %7478, 65535" -> "  %7530 = add nuw nsw i32 %7528, %7529"
"  %7529 = and i32 %7510, 65535"
"  %7529 = and i32 %7510, 65535" -> "  %7530 = add nuw nsw i32 %7528, %7529"
"  %7530 = add nuw nsw i32 %7528, %7529"
"  %7530 = add nuw nsw i32 %7528, %7529" -> "  %7541 = and i32 %7530, 65535""  %7530 = add nuw nsw i32 %7528, %7529" -> "  %7537 = lshr i32 %7530, 16"
"  %7531 = and i32 %7519, 65535"
"  %7531 = and i32 %7519, 65535" -> "  %7533 = add nuw nsw i32 %7532, %7531"
"  %7532 = lshr i32 %7478, 16"
"  %7532 = lshr i32 %7478, 16" -> "  %7533 = add nuw nsw i32 %7532, %7531"
"  %7533 = add nuw nsw i32 %7532, %7531"
"  %7533 = add nuw nsw i32 %7532, %7531" -> "  %7536 = and i32 %7533, 65535""  %7533 = add nuw nsw i32 %7532, %7531" -> "  %7534 = lshr i32 %7533, 16"
"  %7534 = lshr i32 %7533, 16"
"  %7534 = lshr i32 %7533, 16" -> "  %7535 = add nuw nsw i32 %7527, %7534"
"  %7535 = add nuw nsw i32 %7527, %7534"
"  %7535 = add nuw nsw i32 %7527, %7534" -> "  %7540 = add nuw nsw i32 %7535, %7539"
"  %7536 = and i32 %7533, 65535"
"  %7536 = and i32 %7533, 65535" -> "  %7538 = add nuw nsw i32 %7537, %7536"
"  %7537 = lshr i32 %7530, 16"
"  %7537 = lshr i32 %7530, 16" -> "  %7538 = add nuw nsw i32 %7537, %7536"
"  %7538 = add nuw nsw i32 %7537, %7536"
"  %7538 = add nuw nsw i32 %7537, %7536" -> "  %7544 = and i32 %7538, 65535""  %7538 = add nuw nsw i32 %7537, %7536" -> "  %7539 = lshr i32 %7538, 16"
"  %7539 = lshr i32 %7538, 16"
"  %7539 = lshr i32 %7538, 16" -> "  %7540 = add nuw nsw i32 %7535, %7539"
"  %7540 = add nuw nsw i32 %7535, %7539"
"  %7540 = add nuw nsw i32 %7535, %7539" -> "  %7553 = and i32 %7540, 2147418112""  %7540 = add nuw nsw i32 %7535, %7539" -> "  %7551 = and i32 %7540, 65535"
"  %7541 = and i32 %7530, 65535"
"  %7541 = and i32 %7530, 65535" -> "  %7543 = add nuw nsw i32 %7542, %7541"
"  %7542 = and i32 %7509, 65535"
"  %7542 = and i32 %7509, 65535" -> "  %7543 = add nuw nsw i32 %7542, %7541"
"  %7543 = add nuw nsw i32 %7542, %7541"
"  %7543 = add nuw nsw i32 %7542, %7541" -> "  %7584 = and i32 %7543, 65535""  %7543 = add nuw nsw i32 %7542, %7541" -> "  %7547 = lshr i32 %7543, 16"
"  %7544 = and i32 %7538, 65535"
"  %7544 = and i32 %7538, 65535" -> "  %7546 = add nuw nsw i32 %7545, %7544"
"  %7545 = lshr i32 %7509, 16"
"  %7545 = lshr i32 %7509, 16" -> "  %7546 = add nuw nsw i32 %7545, %7544"
"  %7546 = add nuw nsw i32 %7545, %7544"
"  %7546 = add nuw nsw i32 %7545, %7544" -> "  %7550 = lshr i32 %7546, 16""  %7546 = add nuw nsw i32 %7545, %7544" -> "  %7548 = and i32 %7546, 65535"
"  %7547 = lshr i32 %7543, 16"
"  %7547 = lshr i32 %7543, 16" -> "  %7549 = add nuw nsw i32 %7547, %7548"
"  %7548 = and i32 %7546, 65535"
"  %7548 = and i32 %7546, 65535" -> "  %7549 = add nuw nsw i32 %7547, %7548"
"  %7549 = add nuw nsw i32 %7547, %7548"
"  %7549 = add nuw nsw i32 %7547, %7548" -> "  %7591 = and i32 %7549, 65535""  %7549 = add nuw nsw i32 %7547, %7548" -> "  %7555 = lshr i32 %7549, 16"
"  %7550 = lshr i32 %7546, 16"
"  %7550 = lshr i32 %7546, 16" -> "  %7552 = add nuw nsw i32 %7550, %7551"
"  %7551 = and i32 %7540, 65535"
"  %7551 = and i32 %7540, 65535" -> "  %7552 = add nuw nsw i32 %7550, %7551"
"  %7552 = add nuw nsw i32 %7550, %7551"
"  %7552 = add nuw nsw i32 %7550, %7551" -> "  %7554 = add nuw nsw i32 %7552, %7553"
"  %7553 = and i32 %7540, 2147418112"
"  %7553 = and i32 %7540, 2147418112" -> "  %7554 = add nuw nsw i32 %7552, %7553"
"  %7554 = add nuw nsw i32 %7552, %7553"
"  %7554 = add nuw nsw i32 %7552, %7553" -> "  %7556 = add nuw nsw i32 %7554, %7555"
"  %7555 = lshr i32 %7549, 16"
"  %7555 = lshr i32 %7549, 16" -> "  %7556 = add nuw nsw i32 %7554, %7555"
"  %7556 = add nuw nsw i32 %7554, %7555"
"  %7556 = add nuw nsw i32 %7554, %7555" -> "  %7594 = add nuw nsw i32 %7556, %7593"
"  %7557 = and i32 %7416, 65535"
"  %7557 = and i32 %7416, 65535" -> "  %7559 = add nuw nsw i32 %7557, %7558"
"  %7558 = and i32 %7430, 65535"
"  %7558 = and i32 %7430, 65535" -> "  %7559 = add nuw nsw i32 %7557, %7558"
"  %7559 = add nuw nsw i32 %7557, %7558"
"  %7559 = add nuw nsw i32 %7557, %7558" -> "  %7723 = and i32 %7559, 65535""  %7559 = add nuw nsw i32 %7557, %7558" -> "  %7563 = lshr i32 %7559, 16"
"  %7560 = and i32 %7422, 65535"
"  %7560 = and i32 %7422, 65535" -> "  %7562 = add nuw nsw i32 %7560, %7561"
"  %7561 = and i32 %7439, 65535"
"  %7561 = and i32 %7439, 65535" -> "  %7562 = add nuw nsw i32 %7560, %7561"
"  %7562 = add nuw nsw i32 %7560, %7561"
"  %7562 = add nuw nsw i32 %7560, %7561" -> "  %7576 = lshr i32 %7562, 16""  %7562 = add nuw nsw i32 %7560, %7561" -> "  %7564 = and i32 %7562, 65535"
"  %7563 = lshr i32 %7559, 16"
"  %7563 = lshr i32 %7559, 16" -> "  %7565 = add nuw nsw i32 %7564, %7563"
"  %7564 = and i32 %7562, 65535"
"  %7564 = and i32 %7562, 65535" -> "  %7565 = add nuw nsw i32 %7564, %7563"
"  %7565 = add nuw nsw i32 %7564, %7563"
"  %7565 = add nuw nsw i32 %7564, %7563" -> "  %7726 = and i32 %7565, 65535""  %7565 = add nuw nsw i32 %7564, %7563" -> "  %7577 = lshr i32 %7565, 16"
"  %7566 = and i32 %7499, 65535"
"  %7566 = and i32 %7499, 65535" -> "  %7568 = add nuw nsw i32 %7567, %7566"
"  %7567 = and i32 %7429, 65535"
"  %7567 = and i32 %7429, 65535" -> "  %7568 = add nuw nsw i32 %7567, %7566"
"  %7568 = add nuw nsw i32 %7567, %7566"
"  %7568 = add nuw nsw i32 %7567, %7566" -> "  %7575 = and i32 %7568, 65535""  %7568 = add nuw nsw i32 %7567, %7566" -> "  %7572 = lshr i32 %7568, 16"
"  %7569 = lshr i32 %7429, 16"
"  %7569 = lshr i32 %7429, 16" -> "  %7571 = add nuw nsw i32 %7569, %7570"
"  %7570 = and i32 %7507, 65535"
"  %7570 = and i32 %7507, 65535" -> "  %7571 = add nuw nsw i32 %7569, %7570"
"  %7571 = add nuw nsw i32 %7569, %7570"
"  %7571 = add nuw nsw i32 %7569, %7570" -> "  %7583 = lshr i32 %7571, 16""  %7571 = add nuw nsw i32 %7569, %7570" -> "  %7573 = and i32 %7571, 65535"
"  %7572 = lshr i32 %7568, 16"
"  %7572 = lshr i32 %7568, 16" -> "  %7574 = add nuw nsw i32 %7573, %7572"
"  %7573 = and i32 %7571, 65535"
"  %7573 = and i32 %7571, 65535" -> "  %7574 = add nuw nsw i32 %7573, %7572"
"  %7574 = add nuw nsw i32 %7573, %7572"
"  %7574 = add nuw nsw i32 %7573, %7572" -> "  %7585 = lshr i32 %7574, 16""  %7574 = add nuw nsw i32 %7573, %7572" -> "  %7581 = and i32 %7574, 65535"
"  %7575 = and i32 %7568, 65535"
"  %7575 = and i32 %7568, 65535" -> "  %7579 = add nuw nsw i32 %7578, %7575"
"  %7576 = lshr i32 %7562, 16"
"  %7576 = lshr i32 %7562, 16" -> "  %7578 = add nuw nsw i32 %7577, %7576"
"  %7577 = lshr i32 %7565, 16"
"  %7577 = lshr i32 %7565, 16" -> "  %7578 = add nuw nsw i32 %7577, %7576"
"  %7578 = add nuw nsw i32 %7577, %7576"
"  %7578 = add nuw nsw i32 %7577, %7576" -> "  %7579 = add nuw nsw i32 %7578, %7575"
"  %7579 = add nuw nsw i32 %7578, %7575"
"  %7579 = add nuw nsw i32 %7578, %7575" -> "  %7733 = and i32 %7579, 65535""  %7579 = add nuw nsw i32 %7578, %7575" -> "  %7580 = lshr i32 %7579, 16"
"  %7580 = lshr i32 %7579, 16"
"  %7580 = lshr i32 %7579, 16" -> "  %7582 = add nuw nsw i32 %7580, %7581"
"  %7581 = and i32 %7574, 65535"
"  %7581 = and i32 %7574, 65535" -> "  %7582 = add nuw nsw i32 %7580, %7581"
"  %7582 = add nuw nsw i32 %7580, %7581"
"  %7582 = add nuw nsw i32 %7580, %7581" -> "  %7737 = and i32 %7582, 65535""  %7582 = add nuw nsw i32 %7580, %7581" -> "  %7586 = lshr i32 %7582, 16"
"  %7583 = lshr i32 %7571, 16"
"  %7583 = lshr i32 %7571, 16" -> "  %7587 = add nuw nsw i32 %7584, %7583"
"  %7584 = and i32 %7543, 65535"
"  %7584 = and i32 %7543, 65535" -> "  %7587 = add nuw nsw i32 %7584, %7583"
"  %7585 = lshr i32 %7574, 16"
"  %7585 = lshr i32 %7574, 16" -> "  %7588 = add nuw nsw i32 %7587, %7585"
"  %7586 = lshr i32 %7582, 16"
"  %7586 = lshr i32 %7582, 16" -> "  %7589 = add nuw nsw i32 %7588, %7586"
"  %7587 = add nuw nsw i32 %7584, %7583"
"  %7587 = add nuw nsw i32 %7584, %7583" -> "  %7588 = add nuw nsw i32 %7587, %7585"
"  %7588 = add nuw nsw i32 %7587, %7585"
"  %7588 = add nuw nsw i32 %7587, %7585" -> "  %7589 = add nuw nsw i32 %7588, %7586"
"  %7589 = add nuw nsw i32 %7588, %7586"
"  %7589 = add nuw nsw i32 %7588, %7586" -> "  %7888 = and i32 %7589, 65535""  %7589 = add nuw nsw i32 %7588, %7586" -> "  %7590 = lshr i32 %7589, 16"
"  %7590 = lshr i32 %7589, 16"
"  %7590 = lshr i32 %7589, 16" -> "  %7592 = add nuw nsw i32 %7590, %7591"
"  %7591 = and i32 %7549, 65535"
"  %7591 = and i32 %7549, 65535" -> "  %7592 = add nuw nsw i32 %7590, %7591"
"  %7592 = add nuw nsw i32 %7590, %7591"
"  %7592 = add nuw nsw i32 %7590, %7591" -> "  %7891 = and i32 %7592, 65535""  %7592 = add nuw nsw i32 %7590, %7591" -> "  %7593 = lshr i32 %7592, 16"
"  %7593 = lshr i32 %7592, 16"
"  %7593 = lshr i32 %7592, 16" -> "  %7594 = add nuw nsw i32 %7556, %7593"
"  %7594 = add nuw nsw i32 %7556, %7593"
"  %7594 = add nuw nsw i32 %7556, %7593" -> "  %7897 = and i32 %7594, 65535""  %7594 = add nuw nsw i32 %7556, %7593" -> "  %7899 = lshr i32 %7594, 16"
"  %7595 = mul nuw nsw i32 %5802, 4087"
"  %7595 = mul nuw nsw i32 %5802, 4087" -> "  %7722 = and i32 %7595, 65535""  %7595 = mul nuw nsw i32 %5802, 4087" -> "  %7596 = lshr i32 %7595, 16"
"  %7596 = lshr i32 %7595, 16"
"  %7596 = lshr i32 %7595, 16" -> "  %7599 = add nuw nsw i32 %7598, %7596"
"  %7597 = mul nuw nsw i32 %5803, 4087"
"  %7597 = mul nuw nsw i32 %5803, 4087" -> "  %7600 = and i32 %7597, 268369920""  %7597 = mul nuw nsw i32 %5803, 4087" -> "  %7598 = and i32 %7597, 65535"
"  %7598 = and i32 %7597, 65535"
"  %7598 = and i32 %7597, 65535" -> "  %7599 = add nuw nsw i32 %7598, %7596"
"  %7599 = add nuw nsw i32 %7598, %7596"
"  %7599 = add nuw nsw i32 %7598, %7596" -> "  %7601 = add nuw nsw i32 %7599, %7600"
"  %7600 = and i32 %7597, 268369920"
"  %7600 = and i32 %7597, 268369920" -> "  %7601 = add nuw nsw i32 %7599, %7600"
"  %7601 = add nuw nsw i32 %7599, %7600"
"  %7601 = add nuw nsw i32 %7599, %7600" -> "  %7605 = lshr i32 %7601, 16""  %7601 = add nuw nsw i32 %7599, %7600" -> "  %7603 = and i32 %7601, 65535"
"  %7602 = mul nuw nsw i32 %5802, 11561"
"  %7602 = mul nuw nsw i32 %5802, 11561" -> "  %7604 = add nuw nsw i32 %7603, %7602"
"  %7603 = and i32 %7601, 65535"
"  %7603 = and i32 %7601, 65535" -> "  %7604 = add nuw nsw i32 %7603, %7602"
"  %7604 = add nuw nsw i32 %7603, %7602"
"  %7604 = add nuw nsw i32 %7603, %7602" -> "  %7725 = and i32 %7604, 65535""  %7604 = add nuw nsw i32 %7603, %7602" -> "  %7608 = lshr i32 %7604, 16"
"  %7605 = lshr i32 %7601, 16"
"  %7605 = lshr i32 %7601, 16" -> "  %7607 = add nuw nsw i32 %7605, %7606"
"  %7606 = mul nuw nsw i32 %5803, 11561"
"  %7606 = mul nuw nsw i32 %5803, 11561" -> "  %7607 = add nuw nsw i32 %7605, %7606"
"  %7607 = add nuw nsw i32 %7605, %7606"
"  %7607 = add nuw nsw i32 %7605, %7606" -> "  %7611 = and i32 %7607, 2147418112""  %7607 = add nuw nsw i32 %7605, %7606" -> "  %7609 = and i32 %7607, 65535"
"  %7608 = lshr i32 %7604, 16"
"  %7608 = lshr i32 %7604, 16" -> "  %7610 = add nuw nsw i32 %7608, %7609"
"  %7609 = and i32 %7607, 65535"
"  %7609 = and i32 %7607, 65535" -> "  %7610 = add nuw nsw i32 %7608, %7609"
"  %7610 = add nuw nsw i32 %7608, %7609"
"  %7610 = add nuw nsw i32 %7608, %7609" -> "  %7612 = add nuw nsw i32 %7610, %7611"
"  %7611 = and i32 %7607, 2147418112"
"  %7611 = and i32 %7607, 2147418112" -> "  %7612 = add nuw nsw i32 %7610, %7611"
"  %7612 = add nuw nsw i32 %7610, %7611"
"  %7612 = add nuw nsw i32 %7610, %7611" -> "  %7635 = lshr i32 %7612, 16""  %7612 = add nuw nsw i32 %7610, %7611" -> "  %7631 = and i32 %7612, 65535"
"  %7613 = mul nuw nsw i32 %5822, 4087"
"  %7613 = mul nuw nsw i32 %5822, 4087" -> "  %7632 = and i32 %7613, 65535""  %7613 = mul nuw nsw i32 %5822, 4087" -> "  %7614 = lshr i32 %7613, 16"
"  %7614 = lshr i32 %7613, 16"
"  %7614 = lshr i32 %7613, 16" -> "  %7617 = add nuw nsw i32 %7616, %7614"
"  %7615 = mul nuw nsw i32 %5823, 4087"
"  %7615 = mul nuw nsw i32 %5823, 4087" -> "  %7618 = and i32 %7615, 268369920""  %7615 = mul nuw nsw i32 %5823, 4087" -> "  %7616 = and i32 %7615, 65535"
"  %7616 = and i32 %7615, 65535"
"  %7616 = and i32 %7615, 65535" -> "  %7617 = add nuw nsw i32 %7616, %7614"
"  %7617 = add nuw nsw i32 %7616, %7614"
"  %7617 = add nuw nsw i32 %7616, %7614" -> "  %7619 = add nuw nsw i32 %7617, %7618"
"  %7618 = and i32 %7615, 268369920"
"  %7618 = and i32 %7615, 268369920" -> "  %7619 = add nuw nsw i32 %7617, %7618"
"  %7619 = add nuw nsw i32 %7617, %7618"
"  %7619 = add nuw nsw i32 %7617, %7618" -> "  %7623 = lshr i32 %7619, 16""  %7619 = add nuw nsw i32 %7617, %7618" -> "  %7621 = and i32 %7619, 65535"
"  %7620 = mul nuw nsw i32 %5822, 11561"
"  %7620 = mul nuw nsw i32 %5822, 11561" -> "  %7622 = add nuw nsw i32 %7621, %7620"
"  %7621 = and i32 %7619, 65535"
"  %7621 = and i32 %7619, 65535" -> "  %7622 = add nuw nsw i32 %7621, %7620"
"  %7622 = add nuw nsw i32 %7621, %7620"
"  %7622 = add nuw nsw i32 %7621, %7620" -> "  %7634 = and i32 %7622, 65535""  %7622 = add nuw nsw i32 %7621, %7620" -> "  %7626 = lshr i32 %7622, 16"
"  %7623 = lshr i32 %7619, 16"
"  %7623 = lshr i32 %7619, 16" -> "  %7625 = add nuw nsw i32 %7623, %7624"
"  %7624 = mul nuw nsw i32 %5823, 11561"
"  %7624 = mul nuw nsw i32 %5823, 11561" -> "  %7625 = add nuw nsw i32 %7623, %7624"
"  %7625 = add nuw nsw i32 %7623, %7624"
"  %7625 = add nuw nsw i32 %7623, %7624" -> "  %7629 = and i32 %7625, 2147418112""  %7625 = add nuw nsw i32 %7623, %7624" -> "  %7627 = and i32 %7625, 65535"
"  %7626 = lshr i32 %7622, 16"
"  %7626 = lshr i32 %7622, 16" -> "  %7628 = add nuw nsw i32 %7626, %7627"
"  %7627 = and i32 %7625, 65535"
"  %7627 = and i32 %7625, 65535" -> "  %7628 = add nuw nsw i32 %7626, %7627"
"  %7628 = add nuw nsw i32 %7626, %7627"
"  %7628 = add nuw nsw i32 %7626, %7627" -> "  %7630 = add nuw nsw i32 %7628, %7629"
"  %7629 = and i32 %7625, 2147418112"
"  %7629 = and i32 %7625, 2147418112" -> "  %7630 = add nuw nsw i32 %7628, %7629"
"  %7630 = add nuw nsw i32 %7628, %7629"
"  %7630 = add nuw nsw i32 %7628, %7629" -> "  %7638 = add nuw nsw i32 %7630, %7637"
"  %7631 = and i32 %7612, 65535"
"  %7631 = and i32 %7612, 65535" -> "  %7633 = add nuw nsw i32 %7631, %7632"
"  %7632 = and i32 %7613, 65535"
"  %7632 = and i32 %7613, 65535" -> "  %7633 = add nuw nsw i32 %7631, %7632"
"  %7633 = add nuw nsw i32 %7631, %7632"
"  %7633 = add nuw nsw i32 %7631, %7632" -> "  %7662 = and i32 %7633, 65535""  %7633 = add nuw nsw i32 %7631, %7632" -> "  %7640 = lshr i32 %7633, 16"
"  %7634 = and i32 %7622, 65535"
"  %7634 = and i32 %7622, 65535" -> "  %7636 = add nuw nsw i32 %7634, %7635"
"  %7635 = lshr i32 %7612, 16"
"  %7635 = lshr i32 %7612, 16" -> "  %7636 = add nuw nsw i32 %7634, %7635"
"  %7636 = add nuw nsw i32 %7634, %7635"
"  %7636 = add nuw nsw i32 %7634, %7635" -> "  %7639 = and i32 %7636, 65535""  %7636 = add nuw nsw i32 %7634, %7635" -> "  %7637 = lshr i32 %7636, 16"
"  %7637 = lshr i32 %7636, 16"
"  %7637 = lshr i32 %7636, 16" -> "  %7638 = add nuw nsw i32 %7630, %7637"
"  %7638 = add nuw nsw i32 %7630, %7637"
"  %7638 = add nuw nsw i32 %7630, %7637" -> "  %7643 = add nuw nsw i32 %7638, %7642"
"  %7639 = and i32 %7636, 65535"
"  %7639 = and i32 %7636, 65535" -> "  %7641 = add nuw nsw i32 %7639, %7640"
"  %7640 = lshr i32 %7633, 16"
"  %7640 = lshr i32 %7633, 16" -> "  %7641 = add nuw nsw i32 %7639, %7640"
"  %7641 = add nuw nsw i32 %7639, %7640"
"  %7641 = add nuw nsw i32 %7639, %7640" -> "  %7665 = and i32 %7641, 65535""  %7641 = add nuw nsw i32 %7639, %7640" -> "  %7642 = lshr i32 %7641, 16"
"  %7642 = lshr i32 %7641, 16"
"  %7642 = lshr i32 %7641, 16" -> "  %7643 = add nuw nsw i32 %7638, %7642"
"  %7643 = add nuw nsw i32 %7638, %7642"
"  %7643 = add nuw nsw i32 %7638, %7642" -> "  %7697 = lshr i32 %7643, 16""  %7643 = add nuw nsw i32 %7638, %7642" -> "  %7693 = and i32 %7643, 65535"
"  %7644 = mul nuw nsw i32 %5802, 21884"
"  %7644 = mul nuw nsw i32 %5802, 21884" -> "  %7663 = and i32 %7644, 65532""  %7644 = mul nuw nsw i32 %5802, 21884" -> "  %7645 = lshr i32 %7644, 16"
"  %7645 = lshr i32 %7644, 16"
"  %7645 = lshr i32 %7644, 16" -> "  %7648 = add nuw nsw i32 %7647, %7645"
"  %7646 = mul nuw nsw i32 %5803, 21884"
"  %7646 = mul nuw nsw i32 %5803, 21884" -> "  %7649 = and i32 %7646, 2147418112""  %7646 = mul nuw nsw i32 %5803, 21884" -> "  %7647 = and i32 %7646, 65532"
"  %7647 = and i32 %7646, 65532"
"  %7647 = and i32 %7646, 65532" -> "  %7648 = add nuw nsw i32 %7647, %7645"
"  %7648 = add nuw nsw i32 %7647, %7645"
"  %7648 = add nuw nsw i32 %7647, %7645" -> "  %7650 = add nuw nsw i32 %7648, %7649"
"  %7649 = and i32 %7646, 2147418112"
"  %7649 = and i32 %7646, 2147418112" -> "  %7650 = add nuw nsw i32 %7648, %7649"
"  %7650 = add nuw nsw i32 %7648, %7649"
"  %7650 = add nuw nsw i32 %7648, %7649" -> "  %7654 = lshr i32 %7650, 16""  %7650 = add nuw nsw i32 %7648, %7649" -> "  %7652 = and i32 %7650, 65535"
"  %7651 = mul nuw i32 %5802, 36786"
"  %7651 = mul nuw i32 %5802, 36786" -> "  %7653 = add nuw i32 %7652, %7651"
"  %7652 = and i32 %7650, 65535"
"  %7652 = and i32 %7650, 65535" -> "  %7653 = add nuw i32 %7652, %7651"
"  %7653 = add nuw i32 %7652, %7651"
"  %7653 = add nuw i32 %7652, %7651" -> "  %7666 = and i32 %7653, 65535""  %7653 = add nuw i32 %7652, %7651" -> "  %7657 = lshr i32 %7653, 16"
"  %7654 = lshr i32 %7650, 16"
"  %7654 = lshr i32 %7650, 16" -> "  %7656 = add nuw i32 %7654, %7655"
"  %7655 = mul nuw i32 %5803, 36786"
"  %7655 = mul nuw i32 %5803, 36786" -> "  %7656 = add nuw i32 %7654, %7655"
"  %7656 = add nuw i32 %7654, %7655"
"  %7656 = add nuw i32 %7654, %7655" -> "  %7660 = and i32 %7656, -65536""  %7656 = add nuw i32 %7654, %7655" -> "  %7658 = and i32 %7656, 65535"
"  %7657 = lshr i32 %7653, 16"
"  %7657 = lshr i32 %7653, 16" -> "  %7659 = add nuw nsw i32 %7657, %7658"
"  %7658 = and i32 %7656, 65535"
"  %7658 = and i32 %7656, 65535" -> "  %7659 = add nuw nsw i32 %7657, %7658"
"  %7659 = add nuw nsw i32 %7657, %7658"
"  %7659 = add nuw nsw i32 %7657, %7658" -> "  %7661 = add nuw i32 %7659, %7660"
"  %7660 = and i32 %7656, -65536"
"  %7660 = and i32 %7656, -65536" -> "  %7661 = add nuw i32 %7659, %7660"
"  %7661 = add nuw i32 %7659, %7660"
"  %7661 = add nuw i32 %7659, %7660" -> "  %7669 = add nuw i32 %7661, %7668"
"  %7662 = and i32 %7633, 65535"
"  %7662 = and i32 %7633, 65535" -> "  %7664 = add nuw nsw i32 %7662, %7663"
"  %7663 = and i32 %7644, 65532"
"  %7663 = and i32 %7644, 65532" -> "  %7664 = add nuw nsw i32 %7662, %7663"
"  %7664 = add nuw nsw i32 %7662, %7663"
"  %7664 = add nuw nsw i32 %7662, %7663" -> "  %7734 = and i32 %7664, 65535""  %7664 = add nuw nsw i32 %7662, %7663" -> "  %7671 = lshr i32 %7664, 16"
"  %7665 = and i32 %7641, 65535"
"  %7665 = and i32 %7641, 65535" -> "  %7667 = add nuw nsw i32 %7665, %7666"
"  %7666 = and i32 %7653, 65535"
"  %7666 = and i32 %7653, 65535" -> "  %7667 = add nuw nsw i32 %7665, %7666"
"  %7667 = add nuw nsw i32 %7665, %7666"
"  %7667 = add nuw nsw i32 %7665, %7666" -> "  %7670 = and i32 %7667, 65535""  %7667 = add nuw nsw i32 %7665, %7666" -> "  %7668 = lshr i32 %7667, 16"
"  %7668 = lshr i32 %7667, 16"
"  %7668 = lshr i32 %7667, 16" -> "  %7669 = add nuw i32 %7661, %7668"
"  %7669 = add nuw i32 %7661, %7668"
"  %7669 = add nuw i32 %7661, %7668" -> "  %7674 = add nuw i32 %7669, %7673"
"  %7670 = and i32 %7667, 65535"
"  %7670 = and i32 %7667, 65535" -> "  %7672 = add nuw nsw i32 %7670, %7671"
"  %7671 = lshr i32 %7664, 16"
"  %7671 = lshr i32 %7664, 16" -> "  %7672 = add nuw nsw i32 %7670, %7671"
"  %7672 = add nuw nsw i32 %7670, %7671"
"  %7672 = add nuw nsw i32 %7670, %7671" -> "  %7736 = and i32 %7672, 65535""  %7672 = add nuw nsw i32 %7670, %7671" -> "  %7673 = lshr i32 %7672, 16"
"  %7673 = lshr i32 %7672, 16"
"  %7673 = lshr i32 %7672, 16" -> "  %7674 = add nuw i32 %7669, %7673"
"  %7674 = add nuw i32 %7669, %7673"
"  %7674 = add nuw i32 %7669, %7673" -> "  %7710 = lshr i32 %7674, 16""  %7674 = add nuw i32 %7669, %7673" -> "  %7707 = and i32 %7674, 65535"
"  %7675 = mul nuw nsw i32 %5822, 21884"
"  %7675 = mul nuw nsw i32 %5822, 21884" -> "  %7694 = and i32 %7675, 65532""  %7675 = mul nuw nsw i32 %5822, 21884" -> "  %7676 = lshr i32 %7675, 16"
"  %7676 = lshr i32 %7675, 16"
"  %7676 = lshr i32 %7675, 16" -> "  %7679 = add nuw nsw i32 %7678, %7676"
"  %7677 = mul nuw nsw i32 %5823, 21884"
"  %7677 = mul nuw nsw i32 %5823, 21884" -> "  %7680 = and i32 %7677, 2147418112""  %7677 = mul nuw nsw i32 %5823, 21884" -> "  %7678 = and i32 %7677, 65532"
"  %7678 = and i32 %7677, 65532"
"  %7678 = and i32 %7677, 65532" -> "  %7679 = add nuw nsw i32 %7678, %7676"
"  %7679 = add nuw nsw i32 %7678, %7676"
"  %7679 = add nuw nsw i32 %7678, %7676" -> "  %7681 = add nuw nsw i32 %7679, %7680"
"  %7680 = and i32 %7677, 2147418112"
"  %7680 = and i32 %7677, 2147418112" -> "  %7681 = add nuw nsw i32 %7679, %7680"
"  %7681 = add nuw nsw i32 %7679, %7680"
"  %7681 = add nuw nsw i32 %7679, %7680" -> "  %7685 = lshr i32 %7681, 16""  %7681 = add nuw nsw i32 %7679, %7680" -> "  %7683 = and i32 %7681, 65535"
"  %7682 = mul nuw i32 %5822, 36786"
"  %7682 = mul nuw i32 %5822, 36786" -> "  %7684 = add nuw i32 %7683, %7682"
"  %7683 = and i32 %7681, 65535"
"  %7683 = and i32 %7681, 65535" -> "  %7684 = add nuw i32 %7683, %7682"
"  %7684 = add nuw i32 %7683, %7682"
"  %7684 = add nuw i32 %7683, %7682" -> "  %7696 = and i32 %7684, 65535""  %7684 = add nuw i32 %7683, %7682" -> "  %7688 = lshr i32 %7684, 16"
"  %7685 = lshr i32 %7681, 16"
"  %7685 = lshr i32 %7681, 16" -> "  %7687 = add nuw i32 %7685, %7686"
"  %7686 = mul nuw i32 %5823, 36786"
"  %7686 = mul nuw i32 %5823, 36786" -> "  %7687 = add nuw i32 %7685, %7686"
"  %7687 = add nuw i32 %7685, %7686"
"  %7687 = add nuw i32 %7685, %7686" -> "  %7691 = and i32 %7687, -65536""  %7687 = add nuw i32 %7685, %7686" -> "  %7689 = and i32 %7687, 65535"
"  %7688 = lshr i32 %7684, 16"
"  %7688 = lshr i32 %7684, 16" -> "  %7690 = add nuw nsw i32 %7688, %7689"
"  %7689 = and i32 %7687, 65535"
"  %7689 = and i32 %7687, 65535" -> "  %7690 = add nuw nsw i32 %7688, %7689"
"  %7690 = add nuw nsw i32 %7688, %7689"
"  %7690 = add nuw nsw i32 %7688, %7689" -> "  %7692 = add nuw i32 %7690, %7691"
"  %7691 = and i32 %7687, -65536"
"  %7691 = and i32 %7687, -65536" -> "  %7692 = add nuw i32 %7690, %7691"
"  %7692 = add nuw i32 %7690, %7691"
"  %7692 = add nuw i32 %7690, %7691" -> "  %7700 = add nuw i32 %7692, %7699"
"  %7693 = and i32 %7643, 65535"
"  %7693 = and i32 %7643, 65535" -> "  %7695 = add nuw nsw i32 %7693, %7694"
"  %7694 = and i32 %7675, 65532"
"  %7694 = and i32 %7675, 65532" -> "  %7695 = add nuw nsw i32 %7693, %7694"
"  %7695 = add nuw nsw i32 %7693, %7694"
"  %7695 = add nuw nsw i32 %7693, %7694" -> "  %7706 = and i32 %7695, 65535""  %7695 = add nuw nsw i32 %7693, %7694" -> "  %7702 = lshr i32 %7695, 16"
"  %7696 = and i32 %7684, 65535"
"  %7696 = and i32 %7684, 65535" -> "  %7698 = add nuw nsw i32 %7697, %7696"
"  %7697 = lshr i32 %7643, 16"
"  %7697 = lshr i32 %7643, 16" -> "  %7698 = add nuw nsw i32 %7697, %7696"
"  %7698 = add nuw nsw i32 %7697, %7696"
"  %7698 = add nuw nsw i32 %7697, %7696" -> "  %7701 = and i32 %7698, 65535""  %7698 = add nuw nsw i32 %7697, %7696" -> "  %7699 = lshr i32 %7698, 16"
"  %7699 = lshr i32 %7698, 16"
"  %7699 = lshr i32 %7698, 16" -> "  %7700 = add nuw i32 %7692, %7699"
"  %7700 = add nuw i32 %7692, %7699"
"  %7700 = add nuw i32 %7692, %7699" -> "  %7705 = add nuw i32 %7700, %7704"
"  %7701 = and i32 %7698, 65535"
"  %7701 = and i32 %7698, 65535" -> "  %7703 = add nuw nsw i32 %7702, %7701"
"  %7702 = lshr i32 %7695, 16"
"  %7702 = lshr i32 %7695, 16" -> "  %7703 = add nuw nsw i32 %7702, %7701"
"  %7703 = add nuw nsw i32 %7702, %7701"
"  %7703 = add nuw nsw i32 %7702, %7701" -> "  %7709 = and i32 %7703, 65535""  %7703 = add nuw nsw i32 %7702, %7701" -> "  %7704 = lshr i32 %7703, 16"
"  %7704 = lshr i32 %7703, 16"
"  %7704 = lshr i32 %7703, 16" -> "  %7705 = add nuw i32 %7700, %7704"
"  %7705 = add nuw i32 %7700, %7704"
"  %7705 = add nuw i32 %7700, %7704" -> "  %7718 = and i32 %7705, -65536""  %7705 = add nuw i32 %7700, %7704" -> "  %7716 = and i32 %7705, 65535"
"  %7706 = and i32 %7695, 65535"
"  %7706 = and i32 %7695, 65535" -> "  %7708 = add nuw nsw i32 %7707, %7706"
"  %7707 = and i32 %7674, 65535"
"  %7707 = and i32 %7674, 65535" -> "  %7708 = add nuw nsw i32 %7707, %7706"
"  %7708 = add nuw nsw i32 %7707, %7706"
"  %7708 = add nuw nsw i32 %7707, %7706" -> "  %7749 = and i32 %7708, 65535""  %7708 = add nuw nsw i32 %7707, %7706" -> "  %7712 = lshr i32 %7708, 16"
"  %7709 = and i32 %7703, 65535"
"  %7709 = and i32 %7703, 65535" -> "  %7711 = add nuw nsw i32 %7710, %7709"
"  %7710 = lshr i32 %7674, 16"
"  %7710 = lshr i32 %7674, 16" -> "  %7711 = add nuw nsw i32 %7710, %7709"
"  %7711 = add nuw nsw i32 %7710, %7709"
"  %7711 = add nuw nsw i32 %7710, %7709" -> "  %7715 = lshr i32 %7711, 16""  %7711 = add nuw nsw i32 %7710, %7709" -> "  %7713 = and i32 %7711, 65535"
"  %7712 = lshr i32 %7708, 16"
"  %7712 = lshr i32 %7708, 16" -> "  %7714 = add nuw nsw i32 %7712, %7713"
"  %7713 = and i32 %7711, 65535"
"  %7713 = and i32 %7711, 65535" -> "  %7714 = add nuw nsw i32 %7712, %7713"
"  %7714 = add nuw nsw i32 %7712, %7713"
"  %7714 = add nuw nsw i32 %7712, %7713" -> "  %7756 = and i32 %7714, 65535""  %7714 = add nuw nsw i32 %7712, %7713" -> "  %7720 = lshr i32 %7714, 16"
"  %7715 = lshr i32 %7711, 16"
"  %7715 = lshr i32 %7711, 16" -> "  %7717 = add nuw nsw i32 %7715, %7716"
"  %7716 = and i32 %7705, 65535"
"  %7716 = and i32 %7705, 65535" -> "  %7717 = add nuw nsw i32 %7715, %7716"
"  %7717 = add nuw nsw i32 %7715, %7716"
"  %7717 = add nuw nsw i32 %7715, %7716" -> "  %7719 = add nuw i32 %7717, %7718"
"  %7718 = and i32 %7705, -65536"
"  %7718 = and i32 %7705, -65536" -> "  %7719 = add nuw i32 %7717, %7718"
"  %7719 = add nuw i32 %7717, %7718"
"  %7719 = add nuw i32 %7717, %7718" -> "  %7721 = add nuw i32 %7719, %7720"
"  %7720 = lshr i32 %7714, 16"
"  %7720 = lshr i32 %7714, 16" -> "  %7721 = add nuw i32 %7719, %7720"
"  %7721 = add nuw i32 %7719, %7720"
"  %7721 = add nuw i32 %7719, %7720" -> "  %7759 = add nuw i32 %7721, %7758"
"  %7722 = and i32 %7595, 65535"
"  %7722 = and i32 %7595, 65535" -> "  %7724 = add nuw nsw i32 %7723, %7722"
"  %7723 = and i32 %7559, 65535"
"  %7723 = and i32 %7559, 65535" -> "  %7724 = add nuw nsw i32 %7723, %7722"
"  %7724 = add nuw nsw i32 %7723, %7722"
"  %7724 = add nuw nsw i32 %7723, %7722" -> "  %7990 = and i32 %7724, 65535""  %7724 = add nuw nsw i32 %7723, %7722" -> "  %7728 = lshr i32 %7724, 16"
"  %7725 = and i32 %7604, 65535"
"  %7725 = and i32 %7604, 65535" -> "  %7727 = add nuw nsw i32 %7726, %7725"
"  %7726 = and i32 %7565, 65535"
"  %7726 = and i32 %7565, 65535" -> "  %7727 = add nuw nsw i32 %7726, %7725"
"  %7727 = add nuw nsw i32 %7726, %7725"
"  %7727 = add nuw nsw i32 %7726, %7725" -> "  %7731 = lshr i32 %7727, 16""  %7727 = add nuw nsw i32 %7726, %7725" -> "  %7729 = and i32 %7727, 65535"
"  %7728 = lshr i32 %7724, 16"
"  %7728 = lshr i32 %7724, 16" -> "  %7730 = add nuw nsw i32 %7729, %7728"
"  %7729 = and i32 %7727, 65535"
"  %7729 = and i32 %7727, 65535" -> "  %7730 = add nuw nsw i32 %7729, %7728"
"  %7730 = add nuw nsw i32 %7729, %7728"
"  %7730 = add nuw nsw i32 %7729, %7728" -> "  %7993 = and i32 %7730, 65535""  %7730 = add nuw nsw i32 %7729, %7728" -> "  %7732 = lshr i32 %7730, 16"
"  %7731 = lshr i32 %7727, 16"
"  %7731 = lshr i32 %7727, 16" -> "  %7743 = add nuw nsw i32 %7732, %7731"
"  %7732 = lshr i32 %7730, 16"
"  %7732 = lshr i32 %7730, 16" -> "  %7743 = add nuw nsw i32 %7732, %7731"
"  %7733 = and i32 %7579, 65535"
"  %7733 = and i32 %7579, 65535" -> "  %7735 = add nuw nsw i32 %7733, %7734"
"  %7734 = and i32 %7664, 65535"
"  %7734 = and i32 %7664, 65535" -> "  %7735 = add nuw nsw i32 %7733, %7734"
"  %7735 = add nuw nsw i32 %7733, %7734"
"  %7735 = add nuw nsw i32 %7733, %7734" -> "  %7742 = and i32 %7735, 65535""  %7735 = add nuw nsw i32 %7733, %7734" -> "  %7739 = lshr i32 %7735, 16"
"  %7736 = and i32 %7672, 65535"
"  %7736 = and i32 %7672, 65535" -> "  %7738 = add nuw nsw i32 %7737, %7736"
"  %7737 = and i32 %7582, 65535"
"  %7737 = and i32 %7582, 65535" -> "  %7738 = add nuw nsw i32 %7737, %7736"
"  %7738 = add nuw nsw i32 %7737, %7736"
"  %7738 = add nuw nsw i32 %7737, %7736" -> "  %7748 = lshr i32 %7738, 16""  %7738 = add nuw nsw i32 %7737, %7736" -> "  %7740 = and i32 %7738, 65535"
"  %7739 = lshr i32 %7735, 16"
"  %7739 = lshr i32 %7735, 16" -> "  %7741 = add nuw nsw i32 %7740, %7739"
"  %7740 = and i32 %7738, 65535"
"  %7740 = and i32 %7738, 65535" -> "  %7741 = add nuw nsw i32 %7740, %7739"
"  %7741 = add nuw nsw i32 %7740, %7739"
"  %7741 = add nuw nsw i32 %7740, %7739" -> "  %7751 = lshr i32 %7741, 16""  %7741 = add nuw nsw i32 %7740, %7739" -> "  %7746 = and i32 %7741, 65535"
"  %7742 = and i32 %7735, 65535"
"  %7742 = and i32 %7735, 65535" -> "  %7744 = add nuw nsw i32 %7743, %7742"
"  %7743 = add nuw nsw i32 %7732, %7731"
"  %7743 = add nuw nsw i32 %7732, %7731" -> "  %7744 = add nuw nsw i32 %7743, %7742"
"  %7744 = add nuw nsw i32 %7743, %7742"
"  %7744 = add nuw nsw i32 %7743, %7742" -> "  %7999 = and i32 %7744, 65535""  %7744 = add nuw nsw i32 %7743, %7742" -> "  %7745 = lshr i32 %7744, 16"
"  %7745 = lshr i32 %7744, 16"
"  %7745 = lshr i32 %7744, 16" -> "  %7747 = add nuw nsw i32 %7746, %7745"
"  %7746 = and i32 %7741, 65535"
"  %7746 = and i32 %7741, 65535" -> "  %7747 = add nuw nsw i32 %7746, %7745"
"  %7747 = add nuw nsw i32 %7746, %7745"
"  %7747 = add nuw nsw i32 %7746, %7745" -> "  %8002 = and i32 %7747, 65535""  %7747 = add nuw nsw i32 %7746, %7745" -> "  %7753 = lshr i32 %7747, 16"
"  %7748 = lshr i32 %7738, 16"
"  %7748 = lshr i32 %7738, 16" -> "  %7750 = add nuw nsw i32 %7748, %7749"
"  %7749 = and i32 %7708, 65535"
"  %7749 = and i32 %7708, 65535" -> "  %7750 = add nuw nsw i32 %7748, %7749"
"  %7750 = add nuw nsw i32 %7748, %7749"
"  %7750 = add nuw nsw i32 %7748, %7749" -> "  %7752 = add nuw nsw i32 %7750, %7751"
"  %7751 = lshr i32 %7741, 16"
"  %7751 = lshr i32 %7741, 16" -> "  %7752 = add nuw nsw i32 %7750, %7751"
"  %7752 = add nuw nsw i32 %7750, %7751"
"  %7752 = add nuw nsw i32 %7750, %7751" -> "  %7754 = add nuw nsw i32 %7752, %7753"
"  %7753 = lshr i32 %7747, 16"
"  %7753 = lshr i32 %7747, 16" -> "  %7754 = add nuw nsw i32 %7752, %7753"
"  %7754 = add nuw nsw i32 %7752, %7753"
"  %7754 = add nuw nsw i32 %7752, %7753" -> "  %7926 = and i32 %7754, 65535""  %7754 = add nuw nsw i32 %7752, %7753" -> "  %7755 = lshr i32 %7754, 16"
"  %7755 = lshr i32 %7754, 16"
"  %7755 = lshr i32 %7754, 16" -> "  %7757 = add nuw nsw i32 %7755, %7756"
"  %7756 = and i32 %7714, 65535"
"  %7756 = and i32 %7714, 65535" -> "  %7757 = add nuw nsw i32 %7755, %7756"
"  %7757 = add nuw nsw i32 %7755, %7756"
"  %7757 = add nuw nsw i32 %7755, %7756" -> "  %7929 = and i32 %7757, 65535""  %7757 = add nuw nsw i32 %7755, %7756" -> "  %7758 = lshr i32 %7757, 16"
"  %7758 = lshr i32 %7757, 16"
"  %7758 = lshr i32 %7757, 16" -> "  %7759 = add nuw i32 %7721, %7758"
"  %7759 = add nuw i32 %7721, %7758"
"  %7759 = add nuw i32 %7721, %7758" -> "  %7935 = and i32 %7759, 65535""  %7759 = add nuw i32 %7721, %7758" -> "  %7938 = lshr i32 %7759, 16"
"  %7760 = mul nuw nsw i32 %5936, 4087"
"  %7760 = mul nuw nsw i32 %5936, 4087" -> "  %7887 = and i32 %7760, 65535""  %7760 = mul nuw nsw i32 %5936, 4087" -> "  %7761 = lshr i32 %7760, 16"
"  %7761 = lshr i32 %7760, 16"
"  %7761 = lshr i32 %7760, 16" -> "  %7764 = add nuw nsw i32 %7763, %7761"
"  %7762 = mul nuw nsw i32 %5939, 4087"
"  %7762 = mul nuw nsw i32 %5939, 4087" -> "  %7765 = and i32 %7762, 268369920""  %7762 = mul nuw nsw i32 %5939, 4087" -> "  %7763 = and i32 %7762, 65535"
"  %7763 = and i32 %7762, 65535"
"  %7763 = and i32 %7762, 65535" -> "  %7764 = add nuw nsw i32 %7763, %7761"
"  %7764 = add nuw nsw i32 %7763, %7761"
"  %7764 = add nuw nsw i32 %7763, %7761" -> "  %7766 = add nuw nsw i32 %7764, %7765"
"  %7765 = and i32 %7762, 268369920"
"  %7765 = and i32 %7762, 268369920" -> "  %7766 = add nuw nsw i32 %7764, %7765"
"  %7766 = add nuw nsw i32 %7764, %7765"
"  %7766 = add nuw nsw i32 %7764, %7765" -> "  %7770 = lshr i32 %7766, 16""  %7766 = add nuw nsw i32 %7764, %7765" -> "  %7768 = and i32 %7766, 65535"
"  %7767 = mul nuw nsw i32 %5936, 11561"
"  %7767 = mul nuw nsw i32 %5936, 11561" -> "  %7769 = add nuw nsw i32 %7768, %7767"
"  %7768 = and i32 %7766, 65535"
"  %7768 = and i32 %7766, 65535" -> "  %7769 = add nuw nsw i32 %7768, %7767"
"  %7769 = add nuw nsw i32 %7768, %7767"
"  %7769 = add nuw nsw i32 %7768, %7767" -> "  %7890 = and i32 %7769, 65535""  %7769 = add nuw nsw i32 %7768, %7767" -> "  %7773 = lshr i32 %7769, 16"
"  %7770 = lshr i32 %7766, 16"
"  %7770 = lshr i32 %7766, 16" -> "  %7772 = add nuw nsw i32 %7770, %7771"
"  %7771 = mul nuw nsw i32 %5939, 11561"
"  %7771 = mul nuw nsw i32 %5939, 11561" -> "  %7772 = add nuw nsw i32 %7770, %7771"
"  %7772 = add nuw nsw i32 %7770, %7771"
"  %7772 = add nuw nsw i32 %7770, %7771" -> "  %7776 = and i32 %7772, 2147418112""  %7772 = add nuw nsw i32 %7770, %7771" -> "  %7774 = and i32 %7772, 65535"
"  %7773 = lshr i32 %7769, 16"
"  %7773 = lshr i32 %7769, 16" -> "  %7775 = add nuw nsw i32 %7773, %7774"
"  %7774 = and i32 %7772, 65535"
"  %7774 = and i32 %7772, 65535" -> "  %7775 = add nuw nsw i32 %7773, %7774"
"  %7775 = add nuw nsw i32 %7773, %7774"
"  %7775 = add nuw nsw i32 %7773, %7774" -> "  %7777 = add nuw nsw i32 %7775, %7776"
"  %7776 = and i32 %7772, 2147418112"
"  %7776 = and i32 %7772, 2147418112" -> "  %7777 = add nuw nsw i32 %7775, %7776"
"  %7777 = add nuw nsw i32 %7775, %7776"
"  %7777 = add nuw nsw i32 %7775, %7776" -> "  %7800 = lshr i32 %7777, 16""  %7777 = add nuw nsw i32 %7775, %7776" -> "  %7796 = and i32 %7777, 65535"
"  %7778 = mul nuw nsw i32 %5956, 4087"
"  %7778 = mul nuw nsw i32 %5956, 4087" -> "  %7797 = and i32 %7778, 65535""  %7778 = mul nuw nsw i32 %5956, 4087" -> "  %7779 = lshr i32 %7778, 16"
"  %7779 = lshr i32 %7778, 16"
"  %7779 = lshr i32 %7778, 16" -> "  %7782 = add nuw nsw i32 %7781, %7779"
"  %7780 = mul nuw nsw i32 %5957, 4087"
"  %7780 = mul nuw nsw i32 %5957, 4087" -> "  %7783 = and i32 %7780, 268369920""  %7780 = mul nuw nsw i32 %5957, 4087" -> "  %7781 = and i32 %7780, 65535"
"  %7781 = and i32 %7780, 65535"
"  %7781 = and i32 %7780, 65535" -> "  %7782 = add nuw nsw i32 %7781, %7779"
"  %7782 = add nuw nsw i32 %7781, %7779"
"  %7782 = add nuw nsw i32 %7781, %7779" -> "  %7784 = add nuw nsw i32 %7782, %7783"
"  %7783 = and i32 %7780, 268369920"
"  %7783 = and i32 %7780, 268369920" -> "  %7784 = add nuw nsw i32 %7782, %7783"
"  %7784 = add nuw nsw i32 %7782, %7783"
"  %7784 = add nuw nsw i32 %7782, %7783" -> "  %7788 = lshr i32 %7784, 16""  %7784 = add nuw nsw i32 %7782, %7783" -> "  %7786 = and i32 %7784, 65535"
"  %7785 = mul nuw nsw i32 %5956, 11561"
"  %7785 = mul nuw nsw i32 %5956, 11561" -> "  %7787 = add nuw nsw i32 %7786, %7785"
"  %7786 = and i32 %7784, 65535"
"  %7786 = and i32 %7784, 65535" -> "  %7787 = add nuw nsw i32 %7786, %7785"
"  %7787 = add nuw nsw i32 %7786, %7785"
"  %7787 = add nuw nsw i32 %7786, %7785" -> "  %7799 = and i32 %7787, 65535""  %7787 = add nuw nsw i32 %7786, %7785" -> "  %7791 = lshr i32 %7787, 16"
"  %7788 = lshr i32 %7784, 16"
"  %7788 = lshr i32 %7784, 16" -> "  %7790 = add nuw nsw i32 %7788, %7789"
"  %7789 = mul nuw nsw i32 %5957, 11561"
"  %7789 = mul nuw nsw i32 %5957, 11561" -> "  %7790 = add nuw nsw i32 %7788, %7789"
"  %7790 = add nuw nsw i32 %7788, %7789"
"  %7790 = add nuw nsw i32 %7788, %7789" -> "  %7794 = and i32 %7790, 2147418112""  %7790 = add nuw nsw i32 %7788, %7789" -> "  %7792 = and i32 %7790, 65535"
"  %7791 = lshr i32 %7787, 16"
"  %7791 = lshr i32 %7787, 16" -> "  %7793 = add nuw nsw i32 %7791, %7792"
"  %7792 = and i32 %7790, 65535"
"  %7792 = and i32 %7790, 65535" -> "  %7793 = add nuw nsw i32 %7791, %7792"
"  %7793 = add nuw nsw i32 %7791, %7792"
"  %7793 = add nuw nsw i32 %7791, %7792" -> "  %7795 = add nuw nsw i32 %7793, %7794"
"  %7794 = and i32 %7790, 2147418112"
"  %7794 = and i32 %7790, 2147418112" -> "  %7795 = add nuw nsw i32 %7793, %7794"
"  %7795 = add nuw nsw i32 %7793, %7794"
"  %7795 = add nuw nsw i32 %7793, %7794" -> "  %7803 = add nuw nsw i32 %7795, %7802"
"  %7796 = and i32 %7777, 65535"
"  %7796 = and i32 %7777, 65535" -> "  %7798 = add nuw nsw i32 %7796, %7797"
"  %7797 = and i32 %7778, 65535"
"  %7797 = and i32 %7778, 65535" -> "  %7798 = add nuw nsw i32 %7796, %7797"
"  %7798 = add nuw nsw i32 %7796, %7797"
"  %7798 = add nuw nsw i32 %7796, %7797" -> "  %7827 = and i32 %7798, 65535""  %7798 = add nuw nsw i32 %7796, %7797" -> "  %7805 = lshr i32 %7798, 16"
"  %7799 = and i32 %7787, 65535"
"  %7799 = and i32 %7787, 65535" -> "  %7801 = add nuw nsw i32 %7800, %7799"
"  %7800 = lshr i32 %7777, 16"
"  %7800 = lshr i32 %7777, 16" -> "  %7801 = add nuw nsw i32 %7800, %7799"
"  %7801 = add nuw nsw i32 %7800, %7799"
"  %7801 = add nuw nsw i32 %7800, %7799" -> "  %7804 = and i32 %7801, 65535""  %7801 = add nuw nsw i32 %7800, %7799" -> "  %7802 = lshr i32 %7801, 16"
"  %7802 = lshr i32 %7801, 16"
"  %7802 = lshr i32 %7801, 16" -> "  %7803 = add nuw nsw i32 %7795, %7802"
"  %7803 = add nuw nsw i32 %7795, %7802"
"  %7803 = add nuw nsw i32 %7795, %7802" -> "  %7808 = add nuw nsw i32 %7803, %7807"
"  %7804 = and i32 %7801, 65535"
"  %7804 = and i32 %7801, 65535" -> "  %7806 = add nuw nsw i32 %7804, %7805"
"  %7805 = lshr i32 %7798, 16"
"  %7805 = lshr i32 %7798, 16" -> "  %7806 = add nuw nsw i32 %7804, %7805"
"  %7806 = add nuw nsw i32 %7804, %7805"
"  %7806 = add nuw nsw i32 %7804, %7805" -> "  %7830 = and i32 %7806, 65535""  %7806 = add nuw nsw i32 %7804, %7805" -> "  %7807 = lshr i32 %7806, 16"
"  %7807 = lshr i32 %7806, 16"
"  %7807 = lshr i32 %7806, 16" -> "  %7808 = add nuw nsw i32 %7803, %7807"
"  %7808 = add nuw nsw i32 %7803, %7807"
"  %7808 = add nuw nsw i32 %7803, %7807" -> "  %7862 = lshr i32 %7808, 16""  %7808 = add nuw nsw i32 %7803, %7807" -> "  %7858 = and i32 %7808, 65535"
"  %7809 = mul nuw nsw i32 %5936, 21884"
"  %7809 = mul nuw nsw i32 %5936, 21884" -> "  %7828 = and i32 %7809, 65532""  %7809 = mul nuw nsw i32 %5936, 21884" -> "  %7810 = lshr i32 %7809, 16"
"  %7810 = lshr i32 %7809, 16"
"  %7810 = lshr i32 %7809, 16" -> "  %7813 = add nuw nsw i32 %7812, %7810"
"  %7811 = mul nuw nsw i32 %5939, 21884"
"  %7811 = mul nuw nsw i32 %5939, 21884" -> "  %7814 = and i32 %7811, 2147418112""  %7811 = mul nuw nsw i32 %5939, 21884" -> "  %7812 = and i32 %7811, 65532"
"  %7812 = and i32 %7811, 65532"
"  %7812 = and i32 %7811, 65532" -> "  %7813 = add nuw nsw i32 %7812, %7810"
"  %7813 = add nuw nsw i32 %7812, %7810"
"  %7813 = add nuw nsw i32 %7812, %7810" -> "  %7815 = add nuw nsw i32 %7813, %7814"
"  %7814 = and i32 %7811, 2147418112"
"  %7814 = and i32 %7811, 2147418112" -> "  %7815 = add nuw nsw i32 %7813, %7814"
"  %7815 = add nuw nsw i32 %7813, %7814"
"  %7815 = add nuw nsw i32 %7813, %7814" -> "  %7819 = lshr i32 %7815, 16""  %7815 = add nuw nsw i32 %7813, %7814" -> "  %7817 = and i32 %7815, 65535"
"  %7816 = mul nuw i32 %5936, 36786"
"  %7816 = mul nuw i32 %5936, 36786" -> "  %7818 = add nuw i32 %7817, %7816"
"  %7817 = and i32 %7815, 65535"
"  %7817 = and i32 %7815, 65535" -> "  %7818 = add nuw i32 %7817, %7816"
"  %7818 = add nuw i32 %7817, %7816"
"  %7818 = add nuw i32 %7817, %7816" -> "  %7831 = and i32 %7818, 65535""  %7818 = add nuw i32 %7817, %7816" -> "  %7822 = lshr i32 %7818, 16"
"  %7819 = lshr i32 %7815, 16"
"  %7819 = lshr i32 %7815, 16" -> "  %7821 = add nuw i32 %7819, %7820"
"  %7820 = mul nuw i32 %5939, 36786"
"  %7820 = mul nuw i32 %5939, 36786" -> "  %7821 = add nuw i32 %7819, %7820"
"  %7821 = add nuw i32 %7819, %7820"
"  %7821 = add nuw i32 %7819, %7820" -> "  %7825 = and i32 %7821, -65536""  %7821 = add nuw i32 %7819, %7820" -> "  %7823 = and i32 %7821, 65535"
"  %7822 = lshr i32 %7818, 16"
"  %7822 = lshr i32 %7818, 16" -> "  %7824 = add nuw nsw i32 %7822, %7823"
"  %7823 = and i32 %7821, 65535"
"  %7823 = and i32 %7821, 65535" -> "  %7824 = add nuw nsw i32 %7822, %7823"
"  %7824 = add nuw nsw i32 %7822, %7823"
"  %7824 = add nuw nsw i32 %7822, %7823" -> "  %7826 = add nuw i32 %7824, %7825"
"  %7825 = and i32 %7821, -65536"
"  %7825 = and i32 %7821, -65536" -> "  %7826 = add nuw i32 %7824, %7825"
"  %7826 = add nuw i32 %7824, %7825"
"  %7826 = add nuw i32 %7824, %7825" -> "  %7834 = add nuw i32 %7826, %7833"
"  %7827 = and i32 %7798, 65535"
"  %7827 = and i32 %7798, 65535" -> "  %7829 = add nuw nsw i32 %7827, %7828"
"  %7828 = and i32 %7809, 65532"
"  %7828 = and i32 %7809, 65532" -> "  %7829 = add nuw nsw i32 %7827, %7828"
"  %7829 = add nuw nsw i32 %7827, %7828"
"  %7829 = add nuw nsw i32 %7827, %7828" -> "  %7896 = and i32 %7829, 65535""  %7829 = add nuw nsw i32 %7827, %7828" -> "  %7836 = lshr i32 %7829, 16"
"  %7830 = and i32 %7806, 65535"
"  %7830 = and i32 %7806, 65535" -> "  %7832 = add nuw nsw i32 %7830, %7831"
"  %7831 = and i32 %7818, 65535"
"  %7831 = and i32 %7818, 65535" -> "  %7832 = add nuw nsw i32 %7830, %7831"
"  %7832 = add nuw nsw i32 %7830, %7831"
"  %7832 = add nuw nsw i32 %7830, %7831" -> "  %7835 = and i32 %7832, 65535""  %7832 = add nuw nsw i32 %7830, %7831" -> "  %7833 = lshr i32 %7832, 16"
"  %7833 = lshr i32 %7832, 16"
"  %7833 = lshr i32 %7832, 16" -> "  %7834 = add nuw i32 %7826, %7833"
"  %7834 = add nuw i32 %7826, %7833"
"  %7834 = add nuw i32 %7826, %7833" -> "  %7839 = add nuw i32 %7834, %7838"
"  %7835 = and i32 %7832, 65535"
"  %7835 = and i32 %7832, 65535" -> "  %7837 = add nuw nsw i32 %7835, %7836"
"  %7836 = lshr i32 %7829, 16"
"  %7836 = lshr i32 %7829, 16" -> "  %7837 = add nuw nsw i32 %7835, %7836"
"  %7837 = add nuw nsw i32 %7835, %7836"
"  %7837 = add nuw nsw i32 %7835, %7836" -> "  %7900 = and i32 %7837, 65535""  %7837 = add nuw nsw i32 %7835, %7836" -> "  %7838 = lshr i32 %7837, 16"
"  %7838 = lshr i32 %7837, 16"
"  %7838 = lshr i32 %7837, 16" -> "  %7839 = add nuw i32 %7834, %7838"
"  %7839 = add nuw i32 %7834, %7838"
"  %7839 = add nuw i32 %7834, %7838" -> "  %7875 = lshr i32 %7839, 16""  %7839 = add nuw i32 %7834, %7838" -> "  %7872 = and i32 %7839, 65535"
"  %7840 = mul nuw nsw i32 %5956, 21884"
"  %7840 = mul nuw nsw i32 %5956, 21884" -> "  %7859 = and i32 %7840, 65532""  %7840 = mul nuw nsw i32 %5956, 21884" -> "  %7841 = lshr i32 %7840, 16"
"  %7841 = lshr i32 %7840, 16"
"  %7841 = lshr i32 %7840, 16" -> "  %7844 = add nuw nsw i32 %7843, %7841"
"  %7842 = mul nuw nsw i32 %5957, 21884"
"  %7842 = mul nuw nsw i32 %5957, 21884" -> "  %7845 = and i32 %7842, 2147418112""  %7842 = mul nuw nsw i32 %5957, 21884" -> "  %7843 = and i32 %7842, 65532"
"  %7843 = and i32 %7842, 65532"
"  %7843 = and i32 %7842, 65532" -> "  %7844 = add nuw nsw i32 %7843, %7841"
"  %7844 = add nuw nsw i32 %7843, %7841"
"  %7844 = add nuw nsw i32 %7843, %7841" -> "  %7846 = add nuw nsw i32 %7844, %7845"
"  %7845 = and i32 %7842, 2147418112"
"  %7845 = and i32 %7842, 2147418112" -> "  %7846 = add nuw nsw i32 %7844, %7845"
"  %7846 = add nuw nsw i32 %7844, %7845"
"  %7846 = add nuw nsw i32 %7844, %7845" -> "  %7850 = lshr i32 %7846, 16""  %7846 = add nuw nsw i32 %7844, %7845" -> "  %7848 = and i32 %7846, 65535"
"  %7847 = mul nuw i32 %5956, 36786"
"  %7847 = mul nuw i32 %5956, 36786" -> "  %7849 = add nuw i32 %7848, %7847"
"  %7848 = and i32 %7846, 65535"
"  %7848 = and i32 %7846, 65535" -> "  %7849 = add nuw i32 %7848, %7847"
"  %7849 = add nuw i32 %7848, %7847"
"  %7849 = add nuw i32 %7848, %7847" -> "  %7861 = and i32 %7849, 65535""  %7849 = add nuw i32 %7848, %7847" -> "  %7853 = lshr i32 %7849, 16"
"  %7850 = lshr i32 %7846, 16"
"  %7850 = lshr i32 %7846, 16" -> "  %7852 = add nuw i32 %7850, %7851"
"  %7851 = mul nuw i32 %5957, 36786"
"  %7851 = mul nuw i32 %5957, 36786" -> "  %7852 = add nuw i32 %7850, %7851"
"  %7852 = add nuw i32 %7850, %7851"
"  %7852 = add nuw i32 %7850, %7851" -> "  %7856 = and i32 %7852, -65536""  %7852 = add nuw i32 %7850, %7851" -> "  %7854 = and i32 %7852, 65535"
"  %7853 = lshr i32 %7849, 16"
"  %7853 = lshr i32 %7849, 16" -> "  %7855 = add nuw nsw i32 %7853, %7854"
"  %7854 = and i32 %7852, 65535"
"  %7854 = and i32 %7852, 65535" -> "  %7855 = add nuw nsw i32 %7853, %7854"
"  %7855 = add nuw nsw i32 %7853, %7854"
"  %7855 = add nuw nsw i32 %7853, %7854" -> "  %7857 = add nuw i32 %7855, %7856"
"  %7856 = and i32 %7852, -65536"
"  %7856 = and i32 %7852, -65536" -> "  %7857 = add nuw i32 %7855, %7856"
"  %7857 = add nuw i32 %7855, %7856"
"  %7857 = add nuw i32 %7855, %7856" -> "  %7865 = add nuw i32 %7857, %7864"
"  %7858 = and i32 %7808, 65535"
"  %7858 = and i32 %7808, 65535" -> "  %7860 = add nuw nsw i32 %7858, %7859"
"  %7859 = and i32 %7840, 65532"
"  %7859 = and i32 %7840, 65532" -> "  %7860 = add nuw nsw i32 %7858, %7859"
"  %7860 = add nuw nsw i32 %7858, %7859"
"  %7860 = add nuw nsw i32 %7858, %7859" -> "  %7871 = and i32 %7860, 65535""  %7860 = add nuw nsw i32 %7858, %7859" -> "  %7867 = lshr i32 %7860, 16"
"  %7861 = and i32 %7849, 65535"
"  %7861 = and i32 %7849, 65535" -> "  %7863 = add nuw nsw i32 %7862, %7861"
"  %7862 = lshr i32 %7808, 16"
"  %7862 = lshr i32 %7808, 16" -> "  %7863 = add nuw nsw i32 %7862, %7861"
"  %7863 = add nuw nsw i32 %7862, %7861"
"  %7863 = add nuw nsw i32 %7862, %7861" -> "  %7866 = and i32 %7863, 65535""  %7863 = add nuw nsw i32 %7862, %7861" -> "  %7864 = lshr i32 %7863, 16"
"  %7864 = lshr i32 %7863, 16"
"  %7864 = lshr i32 %7863, 16" -> "  %7865 = add nuw i32 %7857, %7864"
"  %7865 = add nuw i32 %7857, %7864"
"  %7865 = add nuw i32 %7857, %7864" -> "  %7870 = add nuw i32 %7865, %7869"
"  %7866 = and i32 %7863, 65535"
"  %7866 = and i32 %7863, 65535" -> "  %7868 = add nuw nsw i32 %7867, %7866"
"  %7867 = lshr i32 %7860, 16"
"  %7867 = lshr i32 %7860, 16" -> "  %7868 = add nuw nsw i32 %7867, %7866"
"  %7868 = add nuw nsw i32 %7867, %7866"
"  %7868 = add nuw nsw i32 %7867, %7866" -> "  %7874 = and i32 %7868, 65535""  %7868 = add nuw nsw i32 %7867, %7866" -> "  %7869 = lshr i32 %7868, 16"
"  %7869 = lshr i32 %7868, 16"
"  %7869 = lshr i32 %7868, 16" -> "  %7870 = add nuw i32 %7865, %7869"
"  %7870 = add nuw i32 %7865, %7869"
"  %7870 = add nuw i32 %7865, %7869" -> "  %7883 = and i32 %7870, -65536""  %7870 = add nuw i32 %7865, %7869" -> "  %7881 = and i32 %7870, 65535"
"  %7871 = and i32 %7860, 65535"
"  %7871 = and i32 %7860, 65535" -> "  %7873 = add nuw nsw i32 %7872, %7871"
"  %7872 = and i32 %7839, 65535"
"  %7872 = and i32 %7839, 65535" -> "  %7873 = add nuw nsw i32 %7872, %7871"
"  %7873 = add nuw nsw i32 %7872, %7871"
"  %7873 = add nuw nsw i32 %7872, %7871" -> "  %7914 = and i32 %7873, 65535""  %7873 = add nuw nsw i32 %7872, %7871" -> "  %7877 = lshr i32 %7873, 16"
"  %7874 = and i32 %7868, 65535"
"  %7874 = and i32 %7868, 65535" -> "  %7876 = add nuw nsw i32 %7875, %7874"
"  %7875 = lshr i32 %7839, 16"
"  %7875 = lshr i32 %7839, 16" -> "  %7876 = add nuw nsw i32 %7875, %7874"
"  %7876 = add nuw nsw i32 %7875, %7874"
"  %7876 = add nuw nsw i32 %7875, %7874" -> "  %7880 = lshr i32 %7876, 16""  %7876 = add nuw nsw i32 %7875, %7874" -> "  %7878 = and i32 %7876, 65535"
"  %7877 = lshr i32 %7873, 16"
"  %7877 = lshr i32 %7873, 16" -> "  %7879 = add nuw nsw i32 %7877, %7878"
"  %7878 = and i32 %7876, 65535"
"  %7878 = and i32 %7876, 65535" -> "  %7879 = add nuw nsw i32 %7877, %7878"
"  %7879 = add nuw nsw i32 %7877, %7878"
"  %7879 = add nuw nsw i32 %7877, %7878" -> "  %7921 = and i32 %7879, 65535""  %7879 = add nuw nsw i32 %7877, %7878" -> "  %7885 = lshr i32 %7879, 16"
"  %7880 = lshr i32 %7876, 16"
"  %7880 = lshr i32 %7876, 16" -> "  %7882 = add nuw nsw i32 %7880, %7881"
"  %7881 = and i32 %7870, 65535"
"  %7881 = and i32 %7870, 65535" -> "  %7882 = add nuw nsw i32 %7880, %7881"
"  %7882 = add nuw nsw i32 %7880, %7881"
"  %7882 = add nuw nsw i32 %7880, %7881" -> "  %7884 = add nuw i32 %7882, %7883"
"  %7883 = and i32 %7870, -65536"
"  %7883 = and i32 %7870, -65536" -> "  %7884 = add nuw i32 %7882, %7883"
"  %7884 = add nuw i32 %7882, %7883"
"  %7884 = add nuw i32 %7882, %7883" -> "  %7886 = add nuw i32 %7884, %7885"
"  %7885 = lshr i32 %7879, 16"
"  %7885 = lshr i32 %7879, 16" -> "  %7886 = add nuw i32 %7884, %7885"
"  %7886 = add nuw i32 %7884, %7885"
"  %7886 = add nuw i32 %7884, %7885" -> "  %7924 = add nuw i32 %7886, %7923"
"  %7887 = and i32 %7760, 65535"
"  %7887 = and i32 %7760, 65535" -> "  %7889 = add nuw nsw i32 %7888, %7887"
"  %7888 = and i32 %7589, 65535"
"  %7888 = and i32 %7589, 65535" -> "  %7889 = add nuw nsw i32 %7888, %7887"
"  %7889 = add nuw nsw i32 %7888, %7887"
"  %7889 = add nuw nsw i32 %7888, %7887" -> "  %7925 = and i32 %7889, 65535""  %7889 = add nuw nsw i32 %7888, %7887" -> "  %7893 = lshr i32 %7889, 16"
"  %7890 = and i32 %7769, 65535"
"  %7890 = and i32 %7769, 65535" -> "  %7892 = add nuw nsw i32 %7891, %7890"
"  %7891 = and i32 %7592, 65535"
"  %7891 = and i32 %7592, 65535" -> "  %7892 = add nuw nsw i32 %7891, %7890"
"  %7892 = add nuw nsw i32 %7891, %7890"
"  %7892 = add nuw nsw i32 %7891, %7890" -> "  %7905 = lshr i32 %7892, 16""  %7892 = add nuw nsw i32 %7891, %7890" -> "  %7894 = and i32 %7892, 65535"
"  %7893 = lshr i32 %7889, 16"
"  %7893 = lshr i32 %7889, 16" -> "  %7895 = add nuw nsw i32 %7894, %7893"
"  %7894 = and i32 %7892, 65535"
"  %7894 = and i32 %7892, 65535" -> "  %7895 = add nuw nsw i32 %7894, %7893"
"  %7895 = add nuw nsw i32 %7894, %7893"
"  %7895 = add nuw nsw i32 %7894, %7893" -> "  %7928 = and i32 %7895, 65535""  %7895 = add nuw nsw i32 %7894, %7893" -> "  %7907 = lshr i32 %7895, 16"
"  %7896 = and i32 %7829, 65535"
"  %7896 = and i32 %7829, 65535" -> "  %7898 = add nuw nsw i32 %7897, %7896"
"  %7897 = and i32 %7594, 65535"
"  %7897 = and i32 %7594, 65535" -> "  %7898 = add nuw nsw i32 %7897, %7896"
"  %7898 = add nuw nsw i32 %7897, %7896"
"  %7898 = add nuw nsw i32 %7897, %7896" -> "  %7906 = and i32 %7898, 65535""  %7898 = add nuw nsw i32 %7897, %7896" -> "  %7902 = lshr i32 %7898, 16"
"  %7899 = lshr i32 %7594, 16"
"  %7899 = lshr i32 %7594, 16" -> "  %7901 = add nuw nsw i32 %7899, %7900"
"  %7900 = and i32 %7837, 65535"
"  %7900 = and i32 %7837, 65535" -> "  %7901 = add nuw nsw i32 %7899, %7900"
"  %7901 = add nuw nsw i32 %7899, %7900"
"  %7901 = add nuw nsw i32 %7899, %7900" -> "  %7913 = lshr i32 %7901, 16""  %7901 = add nuw nsw i32 %7899, %7900" -> "  %7903 = and i32 %7901, 65535"
"  %7902 = lshr i32 %7898, 16"
"  %7902 = lshr i32 %7898, 16" -> "  %7904 = add nuw nsw i32 %7903, %7902"
"  %7903 = and i32 %7901, 65535"
"  %7903 = and i32 %7901, 65535" -> "  %7904 = add nuw nsw i32 %7903, %7902"
"  %7904 = add nuw nsw i32 %7903, %7902"
"  %7904 = add nuw nsw i32 %7903, %7902" -> "  %7915 = lshr i32 %7904, 16""  %7904 = add nuw nsw i32 %7903, %7902" -> "  %7911 = and i32 %7904, 65535"
"  %7905 = lshr i32 %7892, 16"
"  %7905 = lshr i32 %7892, 16" -> "  %7908 = add nuw nsw i32 %7907, %7905"
"  %7906 = and i32 %7898, 65535"
"  %7906 = and i32 %7898, 65535" -> "  %7909 = add nuw nsw i32 %7908, %7906"
"  %7907 = lshr i32 %7895, 16"
"  %7907 = lshr i32 %7895, 16" -> "  %7908 = add nuw nsw i32 %7907, %7905"
"  %7908 = add nuw nsw i32 %7907, %7905"
"  %7908 = add nuw nsw i32 %7907, %7905" -> "  %7909 = add nuw nsw i32 %7908, %7906"
"  %7909 = add nuw nsw i32 %7908, %7906"
"  %7909 = add nuw nsw i32 %7908, %7906" -> "  %7934 = and i32 %7909, 65535""  %7909 = add nuw nsw i32 %7908, %7906" -> "  %7910 = lshr i32 %7909, 16"
"  %7910 = lshr i32 %7909, 16"
"  %7910 = lshr i32 %7909, 16" -> "  %7912 = add nuw nsw i32 %7910, %7911"
"  %7911 = and i32 %7904, 65535"
"  %7911 = and i32 %7904, 65535" -> "  %7912 = add nuw nsw i32 %7910, %7911"
"  %7912 = add nuw nsw i32 %7910, %7911"
"  %7912 = add nuw nsw i32 %7910, %7911" -> "  %7937 = and i32 %7912, 65535""  %7912 = add nuw nsw i32 %7910, %7911" -> "  %7916 = lshr i32 %7912, 16"
"  %7913 = lshr i32 %7901, 16"
"  %7913 = lshr i32 %7901, 16" -> "  %7917 = add nuw nsw i32 %7913, %7914"
"  %7914 = and i32 %7873, 65535"
"  %7914 = and i32 %7873, 65535" -> "  %7917 = add nuw nsw i32 %7913, %7914"
"  %7915 = lshr i32 %7904, 16"
"  %7915 = lshr i32 %7904, 16" -> "  %7918 = add nuw nsw i32 %7917, %7915"
"  %7916 = lshr i32 %7912, 16"
"  %7916 = lshr i32 %7912, 16" -> "  %7919 = add nuw nsw i32 %7918, %7916"
"  %7917 = add nuw nsw i32 %7913, %7914"
"  %7917 = add nuw nsw i32 %7913, %7914" -> "  %7918 = add nuw nsw i32 %7917, %7915"
"  %7918 = add nuw nsw i32 %7917, %7915"
"  %7918 = add nuw nsw i32 %7917, %7915" -> "  %7919 = add nuw nsw i32 %7918, %7916"
"  %7919 = add nuw nsw i32 %7918, %7916"
"  %7919 = add nuw nsw i32 %7918, %7916" -> "  %7951 = and i32 %7919, 65535""  %7919 = add nuw nsw i32 %7918, %7916" -> "  %7920 = lshr i32 %7919, 16"
"  %7920 = lshr i32 %7919, 16"
"  %7920 = lshr i32 %7919, 16" -> "  %7922 = add nuw nsw i32 %7920, %7921"
"  %7921 = and i32 %7879, 65535"
"  %7921 = and i32 %7879, 65535" -> "  %7922 = add nuw nsw i32 %7920, %7921"
"  %7922 = add nuw nsw i32 %7920, %7921"
"  %7922 = add nuw nsw i32 %7920, %7921" -> "  %7958 = and i32 %7922, 65535""  %7922 = add nuw nsw i32 %7920, %7921" -> "  %7923 = lshr i32 %7922, 16"
"  %7923 = lshr i32 %7922, 16"
"  %7923 = lshr i32 %7922, 16" -> "  %7924 = add nuw i32 %7886, %7923"
"  %7924 = add nuw i32 %7886, %7923"
"  %7924 = add nuw i32 %7886, %7923" -> "  %7962 = add nuw i32 %7924, %7961"
"  %7925 = and i32 %7889, 65535"
"  %7925 = and i32 %7889, 65535" -> "  %7927 = add nuw nsw i32 %7926, %7925"
"  %7926 = and i32 %7754, 65535"
"  %7926 = and i32 %7754, 65535" -> "  %7927 = add nuw nsw i32 %7926, %7925"
"  %7927 = add nuw nsw i32 %7926, %7925"
"  %7927 = add nuw nsw i32 %7926, %7925" -> "  %8035 = and i32 %7927, 65535""  %7927 = add nuw nsw i32 %7926, %7925" -> "  %7931 = lshr i32 %7927, 16"
"  %7928 = and i32 %7895, 65535"
"  %7928 = and i32 %7895, 65535" -> "  %7930 = add nuw nsw i32 %7929, %7928"
"  %7929 = and i32 %7757, 65535"
"  %7929 = and i32 %7757, 65535" -> "  %7930 = add nuw nsw i32 %7929, %7928"
"  %7930 = add nuw nsw i32 %7929, %7928"
"  %7930 = add nuw nsw i32 %7929, %7928" -> "  %7944 = lshr i32 %7930, 16""  %7930 = add nuw nsw i32 %7929, %7928" -> "  %7932 = and i32 %7930, 65535"
"  %7931 = lshr i32 %7927, 16"
"  %7931 = lshr i32 %7927, 16" -> "  %7933 = add nuw nsw i32 %7932, %7931"
"  %7932 = and i32 %7930, 65535"
"  %7932 = and i32 %7930, 65535" -> "  %7933 = add nuw nsw i32 %7932, %7931"
"  %7933 = add nuw nsw i32 %7932, %7931"
"  %7933 = add nuw nsw i32 %7932, %7931" -> "  %8040 = and i32 %7933, 65535""  %7933 = add nuw nsw i32 %7932, %7931" -> "  %7945 = lshr i32 %7933, 16"
"  %7934 = and i32 %7909, 65535"
"  %7934 = and i32 %7909, 65535" -> "  %7936 = add nuw nsw i32 %7935, %7934"
"  %7935 = and i32 %7759, 65535"
"  %7935 = and i32 %7759, 65535" -> "  %7936 = add nuw nsw i32 %7935, %7934"
"  %7936 = add nuw nsw i32 %7935, %7934"
"  %7936 = add nuw nsw i32 %7935, %7934" -> "  %7943 = and i32 %7936, 65535""  %7936 = add nuw nsw i32 %7935, %7934" -> "  %7940 = lshr i32 %7936, 16"
"  %7937 = and i32 %7912, 65535"
"  %7937 = and i32 %7912, 65535" -> "  %7939 = add nuw nsw i32 %7937, %7938"
"  %7938 = lshr i32 %7759, 16"
"  %7938 = lshr i32 %7759, 16" -> "  %7939 = add nuw nsw i32 %7937, %7938"
"  %7939 = add nuw nsw i32 %7937, %7938"
"  %7939 = add nuw nsw i32 %7937, %7938" -> "  %7952 = lshr i32 %7939, 16""  %7939 = add nuw nsw i32 %7937, %7938" -> "  %7941 = and i32 %7939, 65535"
"  %7940 = lshr i32 %7936, 16"
"  %7940 = lshr i32 %7936, 16" -> "  %7942 = add nuw nsw i32 %7941, %7940"
"  %7941 = and i32 %7939, 65535"
"  %7941 = and i32 %7939, 65535" -> "  %7942 = add nuw nsw i32 %7941, %7940"
"  %7942 = add nuw nsw i32 %7941, %7940"
"  %7942 = add nuw nsw i32 %7941, %7940" -> "  %7954 = lshr i32 %7942, 16""  %7942 = add nuw nsw i32 %7941, %7940" -> "  %7949 = and i32 %7942, 65535"
"  %7943 = and i32 %7936, 65535"
"  %7943 = and i32 %7936, 65535" -> "  %7947 = add nuw nsw i32 %7946, %7943"
"  %7944 = lshr i32 %7930, 16"
"  %7944 = lshr i32 %7930, 16" -> "  %7946 = add nuw nsw i32 %7945, %7944"
"  %7945 = lshr i32 %7933, 16"
"  %7945 = lshr i32 %7933, 16" -> "  %7946 = add nuw nsw i32 %7945, %7944"
"  %7946 = add nuw nsw i32 %7945, %7944"
"  %7946 = add nuw nsw i32 %7945, %7944" -> "  %7947 = add nuw nsw i32 %7946, %7943"
"  %7947 = add nuw nsw i32 %7946, %7943"
"  %7947 = add nuw nsw i32 %7946, %7943" -> "  %8041 = and i32 %7947, 65535""  %7947 = add nuw nsw i32 %7946, %7943" -> "  %7948 = lshr i32 %7947, 16"
"  %7948 = lshr i32 %7947, 16"
"  %7948 = lshr i32 %7947, 16" -> "  %7950 = add nuw nsw i32 %7948, %7949"
"  %7949 = and i32 %7942, 65535"
"  %7949 = and i32 %7942, 65535" -> "  %7950 = add nuw nsw i32 %7948, %7949"
"  %7950 = add nuw nsw i32 %7948, %7949"
"  %7950 = add nuw nsw i32 %7948, %7949" -> "  %8047 = and i32 %7950, 65535""  %7950 = add nuw nsw i32 %7948, %7949" -> "  %7956 = lshr i32 %7950, 16"
"  %7951 = and i32 %7919, 65535"
"  %7951 = and i32 %7919, 65535" -> "  %7953 = add nuw nsw i32 %7952, %7951"
"  %7952 = lshr i32 %7939, 16"
"  %7952 = lshr i32 %7939, 16" -> "  %7953 = add nuw nsw i32 %7952, %7951"
"  %7953 = add nuw nsw i32 %7952, %7951"
"  %7953 = add nuw nsw i32 %7952, %7951" -> "  %7955 = add nuw nsw i32 %7953, %7954"
"  %7954 = lshr i32 %7942, 16"
"  %7954 = lshr i32 %7942, 16" -> "  %7955 = add nuw nsw i32 %7953, %7954"
"  %7955 = add nuw nsw i32 %7953, %7954"
"  %7955 = add nuw nsw i32 %7953, %7954" -> "  %7957 = add nuw nsw i32 %7955, %7956"
"  %7956 = lshr i32 %7950, 16"
"  %7956 = lshr i32 %7950, 16" -> "  %7957 = add nuw nsw i32 %7955, %7956"
"  %7957 = add nuw nsw i32 %7955, %7956"
"  %7957 = add nuw nsw i32 %7955, %7956" -> "  %8049 = and i32 %7957, 65535""  %7957 = add nuw nsw i32 %7955, %7956" -> "  %7959 = lshr i32 %7957, 16"
"  %7958 = and i32 %7922, 65535"
"  %7958 = and i32 %7922, 65535" -> "  %7960 = add nuw nsw i32 %7959, %7958"
"  %7959 = lshr i32 %7957, 16"
"  %7959 = lshr i32 %7957, 16" -> "  %7960 = add nuw nsw i32 %7959, %7958"
"  %7960 = add nuw nsw i32 %7959, %7958"
"  %7960 = add nuw nsw i32 %7959, %7958" -> "  %8053 = and i32 %7960, 65535""  %7960 = add nuw nsw i32 %7959, %7958" -> "  %7961 = lshr i32 %7960, 16"
"  %7961 = lshr i32 %7960, 16"
"  %7961 = lshr i32 %7960, 16" -> "  %7962 = add nuw i32 %7924, %7961"
"  %7962 = add nuw i32 %7924, %7961"
"  %7962 = add nuw i32 %7924, %7961" -> "  %8056 = add nuw i32 %7962, %8055"
"  %7963 = and i32 %6531, 65535"
"  %7963 = and i32 %6531, 65535" -> "  %7965 = add nuw nsw i32 %7963, %7964"
"  %7964 = and i32 %7306, 65535"
"  %7964 = and i32 %7306, 65535" -> "  %7965 = add nuw nsw i32 %7963, %7964"
"  %7965 = add nuw nsw i32 %7963, %7964"
"  %7965 = add nuw nsw i32 %7963, %7964" -> "  %8058 = and i32 %7965, 65535""  %7965 = add nuw nsw i32 %7963, %7964" -> "  %7969 = lshr i32 %7965, 16"
"  %7966 = and i32 %6535, 65535"
"  %7966 = and i32 %6535, 65535" -> "  %7968 = add nuw nsw i32 %7966, %7967"
"  %7967 = and i32 %7315, 65535"
"  %7967 = and i32 %7315, 65535" -> "  %7968 = add nuw nsw i32 %7966, %7967"
"  %7968 = add nuw nsw i32 %7966, %7967"
"  %7968 = add nuw nsw i32 %7966, %7967" -> "  %7982 = lshr i32 %7968, 16""  %7968 = add nuw nsw i32 %7966, %7967" -> "  %7970 = and i32 %7968, 65535"
"  %7969 = lshr i32 %7965, 16"
"  %7969 = lshr i32 %7965, 16" -> "  %7971 = add nuw nsw i32 %7970, %7969"
"  %7970 = and i32 %7968, 65535"
"  %7970 = and i32 %7968, 65535" -> "  %7971 = add nuw nsw i32 %7970, %7969"
"  %7971 = add nuw nsw i32 %7970, %7969"
"  %7971 = add nuw nsw i32 %7970, %7969" -> "  %8061 = and i32 %7971, 65535""  %7971 = add nuw nsw i32 %7970, %7969" -> "  %7983 = lshr i32 %7971, 16"
"  %7972 = and i32 %6537, 65535"
"  %7972 = and i32 %6537, 65535" -> "  %7974 = add nuw nsw i32 %7972, %7973"
"  %7973 = and i32 %7375, 65535"
"  %7973 = and i32 %7375, 65535" -> "  %7974 = add nuw nsw i32 %7972, %7973"
"  %7974 = add nuw nsw i32 %7972, %7973"
"  %7974 = add nuw nsw i32 %7972, %7973" -> "  %7981 = and i32 %7974, 65535""  %7974 = add nuw nsw i32 %7972, %7973" -> "  %7978 = lshr i32 %7974, 16"
"  %7975 = and i32 %6540, 65535"
"  %7975 = and i32 %6540, 65535" -> "  %7977 = add nuw nsw i32 %7975, %7976"
"  %7976 = and i32 %7383, 65535"
"  %7976 = and i32 %7383, 65535" -> "  %7977 = add nuw nsw i32 %7975, %7976"
"  %7977 = add nuw nsw i32 %7975, %7976"
"  %7977 = add nuw nsw i32 %7975, %7976" -> "  %8019 = lshr i32 %7977, 16""  %7977 = add nuw nsw i32 %7975, %7976" -> "  %7979 = and i32 %7977, 65535"
"  %7978 = lshr i32 %7974, 16"
"  %7978 = lshr i32 %7974, 16" -> "  %7980 = add nuw nsw i32 %7979, %7978"
"  %7979 = and i32 %7977, 65535"
"  %7979 = and i32 %7977, 65535" -> "  %7980 = add nuw nsw i32 %7979, %7978"
"  %7980 = add nuw nsw i32 %7979, %7978"
"  %7980 = add nuw nsw i32 %7979, %7978" -> "  %8020 = lshr i32 %7980, 16""  %7980 = add nuw nsw i32 %7979, %7978" -> "  %7987 = and i32 %7980, 65535"
"  %7981 = and i32 %7974, 65535"
"  %7981 = and i32 %7974, 65535" -> "  %7985 = add nuw nsw i32 %7984, %7981"
"  %7982 = lshr i32 %7968, 16"
"  %7982 = lshr i32 %7968, 16" -> "  %7984 = add nuw nsw i32 %7983, %7982"
"  %7983 = lshr i32 %7971, 16"
"  %7983 = lshr i32 %7971, 16" -> "  %7984 = add nuw nsw i32 %7983, %7982"
"  %7984 = add nuw nsw i32 %7983, %7982"
"  %7984 = add nuw nsw i32 %7983, %7982" -> "  %7985 = add nuw nsw i32 %7984, %7981"
"  %7985 = add nuw nsw i32 %7984, %7981"
"  %7985 = add nuw nsw i32 %7984, %7981" -> "  %8067 = and i32 %7985, 65535""  %7985 = add nuw nsw i32 %7984, %7981" -> "  %7986 = lshr i32 %7985, 16"
"  %7986 = lshr i32 %7985, 16"
"  %7986 = lshr i32 %7985, 16" -> "  %7988 = add nuw nsw i32 %7987, %7986"
"  %7987 = and i32 %7980, 65535"
"  %7987 = and i32 %7980, 65535" -> "  %7988 = add nuw nsw i32 %7987, %7986"
"  %7988 = add nuw nsw i32 %7987, %7986"
"  %7988 = add nuw nsw i32 %7987, %7986" -> "  %8070 = and i32 %7988, 65535""  %7988 = add nuw nsw i32 %7987, %7986" -> "  %8021 = lshr i32 %7988, 16"
"  %7989 = and i32 %6543, 65535"
"  %7989 = and i32 %6543, 65535" -> "  %7991 = add nuw nsw i32 %7989, %7990"
"  %7990 = and i32 %7724, 65535"
"  %7990 = and i32 %7724, 65535" -> "  %7991 = add nuw nsw i32 %7989, %7990"
"  %7991 = add nuw nsw i32 %7989, %7990"
"  %7991 = add nuw nsw i32 %7989, %7990" -> "  %8018 = and i32 %7991, 65535""  %7991 = add nuw nsw i32 %7989, %7990" -> "  %7995 = lshr i32 %7991, 16"
"  %7992 = and i32 %6546, 65535"
"  %7992 = and i32 %6546, 65535" -> "  %7994 = add nuw nsw i32 %7992, %7993"
"  %7993 = and i32 %7730, 65535"
"  %7993 = and i32 %7730, 65535" -> "  %7994 = add nuw nsw i32 %7992, %7993"
"  %7994 = add nuw nsw i32 %7992, %7993"
"  %7994 = add nuw nsw i32 %7992, %7993" -> "  %8010 = lshr i32 %7994, 16""  %7994 = add nuw nsw i32 %7992, %7993" -> "  %7996 = and i32 %7994, 65535"
"  %7995 = lshr i32 %7991, 16"
"  %7995 = lshr i32 %7991, 16" -> "  %7997 = add nuw nsw i32 %7996, %7995"
"  %7996 = and i32 %7994, 65535"
"  %7996 = and i32 %7994, 65535" -> "  %7997 = add nuw nsw i32 %7996, %7995"
"  %7997 = add nuw nsw i32 %7996, %7995"
"  %7997 = add nuw nsw i32 %7996, %7995" -> "  %8025 = and i32 %7997, 65535""  %7997 = add nuw nsw i32 %7996, %7995" -> "  %8012 = lshr i32 %7997, 16"
"  %7998 = and i32 %6548, 65535"
"  %7998 = and i32 %6548, 65535" -> "  %8000 = add nuw nsw i32 %7998, %7999"
"  %7999 = and i32 %7744, 65535"
"  %7999 = and i32 %7744, 65535" -> "  %8000 = add nuw nsw i32 %7998, %7999"
"  %8000 = add nuw nsw i32 %7998, %7999"
"  %8000 = add nuw nsw i32 %7998, %7999" -> "  %8009 = and i32 %8000, 65535""  %8000 = add nuw nsw i32 %7998, %7999" -> "  %8004 = lshr i32 %8000, 16"
"  %8001 = lshr i32 %6548, 16"
"  %8001 = lshr i32 %6548, 16" -> "  %8003 = add nuw nsw i32 %8001, %8002"
"  %8002 = and i32 %7747, 65535"
"  %8002 = and i32 %7747, 65535" -> "  %8003 = add nuw nsw i32 %8001, %8002"
"  %8003 = add nuw nsw i32 %8001, %8002"
"  %8003 = add nuw nsw i32 %8001, %8002" -> "  %8007 = lshr i32 %8003, 16""  %8003 = add nuw nsw i32 %8001, %8002" -> "  %8005 = and i32 %8003, 65535"
"  %8004 = lshr i32 %8000, 16"
"  %8004 = lshr i32 %8000, 16" -> "  %8006 = add nuw nsw i32 %8005, %8004"
"  %8005 = and i32 %8003, 65535"
"  %8005 = and i32 %8003, 65535" -> "  %8006 = add nuw nsw i32 %8005, %8004"
"  %8006 = add nuw nsw i32 %8005, %8004"
"  %8006 = add nuw nsw i32 %8005, %8004" -> "  %8014 = and i32 %8006, 65535""  %8006 = add nuw nsw i32 %8005, %8004" -> "  %8008 = lshr i32 %8006, 16"
"  %8007 = lshr i32 %8003, 16"
"  %8007 = lshr i32 %8003, 16" -> "  %8036 = add nuw nsw i32 %8007, %8035"
"  %8008 = lshr i32 %8006, 16"
"  %8008 = lshr i32 %8006, 16" -> "  %8037 = add nuw nsw i32 %8036, %8008"
"  %8009 = and i32 %8000, 65535"
"  %8009 = and i32 %8000, 65535" -> "  %8011 = add nuw nsw i32 %8009, %8010"
"  %8010 = lshr i32 %7994, 16"
"  %8010 = lshr i32 %7994, 16" -> "  %8011 = add nuw nsw i32 %8009, %8010"
"  %8011 = add nuw nsw i32 %8009, %8010"
"  %8011 = add nuw nsw i32 %8009, %8010" -> "  %8013 = add nuw nsw i32 %8011, %8012"
"  %8012 = lshr i32 %7997, 16"
"  %8012 = lshr i32 %7997, 16" -> "  %8013 = add nuw nsw i32 %8011, %8012"
"  %8013 = add nuw nsw i32 %8011, %8012"
"  %8013 = add nuw nsw i32 %8011, %8012" -> "  %8028 = and i32 %8013, 65535""  %8013 = add nuw nsw i32 %8011, %8012" -> "  %8015 = lshr i32 %8013, 16"
"  %8014 = and i32 %8006, 65535"
"  %8014 = and i32 %8006, 65535" -> "  %8016 = add nuw nsw i32 %8015, %8014"
"  %8015 = lshr i32 %8013, 16"
"  %8015 = lshr i32 %8013, 16" -> "  %8016 = add nuw nsw i32 %8015, %8014"
"  %8016 = add nuw nsw i32 %8015, %8014"
"  %8016 = add nuw nsw i32 %8015, %8014" -> "  %8031 = and i32 %8016, 65535""  %8016 = add nuw nsw i32 %8015, %8014" -> "  %8017 = lshr i32 %8016, 16"
"  %8017 = lshr i32 %8016, 16"
"  %8017 = lshr i32 %8016, 16" -> "  %8038 = add nuw nsw i32 %8037, %8017"
"  %8018 = and i32 %7991, 65535"
"  %8018 = and i32 %7991, 65535" -> "  %8023 = add nuw nsw i32 %8022, %8018"
"  %8019 = lshr i32 %7977, 16"
"  %8019 = lshr i32 %7977, 16" -> "  %8022 = add nuw nsw i32 %8020, %8019"
"  %8020 = lshr i32 %7980, 16"
"  %8020 = lshr i32 %7980, 16" -> "  %8022 = add nuw nsw i32 %8020, %8019"
"  %8021 = lshr i32 %7988, 16"
"  %8021 = lshr i32 %7988, 16" -> "  %8024 = add nuw nsw i32 %8023, %8021"
"  %8022 = add nuw nsw i32 %8020, %8019"
"  %8022 = add nuw nsw i32 %8020, %8019" -> "  %8023 = add nuw nsw i32 %8022, %8018"
"  %8023 = add nuw nsw i32 %8022, %8018"
"  %8023 = add nuw nsw i32 %8022, %8018" -> "  %8024 = add nuw nsw i32 %8023, %8021"
"  %8024 = add nuw nsw i32 %8023, %8021"
"  %8024 = add nuw nsw i32 %8023, %8021" -> "  %8084 = and i32 %8024, 65535""  %8024 = add nuw nsw i32 %8023, %8021" -> "  %8026 = lshr i32 %8024, 16"
"  %8025 = and i32 %7997, 65535"
"  %8025 = and i32 %7997, 65535" -> "  %8027 = add nuw nsw i32 %8025, %8026"
"  %8026 = lshr i32 %8024, 16"
"  %8026 = lshr i32 %8024, 16" -> "  %8027 = add nuw nsw i32 %8025, %8026"
"  %8027 = add nuw nsw i32 %8025, %8026"
"  %8027 = add nuw nsw i32 %8025, %8026" -> "  %8087 = and i32 %8027, 65535""  %8027 = add nuw nsw i32 %8025, %8026" -> "  %8029 = lshr i32 %8027, 16"
"  %8028 = and i32 %8013, 65535"
"  %8028 = and i32 %8013, 65535" -> "  %8030 = add nuw nsw i32 %8028, %8029"
"  %8029 = lshr i32 %8027, 16"
"  %8029 = lshr i32 %8027, 16" -> "  %8030 = add nuw nsw i32 %8028, %8029"
"  %8030 = add nuw nsw i32 %8028, %8029"
"  %8030 = add nuw nsw i32 %8028, %8029" -> "  %8093 = and i32 %8030, 65535""  %8030 = add nuw nsw i32 %8028, %8029" -> "  %8032 = lshr i32 %8030, 16"
"  %8031 = and i32 %8016, 65535"
"  %8031 = and i32 %8016, 65535" -> "  %8033 = add nuw nsw i32 %8031, %8032"
"  %8032 = lshr i32 %8030, 16"
"  %8032 = lshr i32 %8030, 16" -> "  %8033 = add nuw nsw i32 %8031, %8032"
"  %8033 = add nuw nsw i32 %8031, %8032"
"  %8033 = add nuw nsw i32 %8031, %8032" -> "  %8096 = and i32 %8033, 65535""  %8033 = add nuw nsw i32 %8031, %8032" -> "  %8034 = lshr i32 %8033, 16"
"  %8034 = lshr i32 %8033, 16"
"  %8034 = lshr i32 %8033, 16" -> "  %8039 = add nuw nsw i32 %8038, %8034"
"  %8035 = and i32 %7927, 65535"
"  %8035 = and i32 %7927, 65535" -> "  %8036 = add nuw nsw i32 %8007, %8035"
"  %8036 = add nuw nsw i32 %8007, %8035"
"  %8036 = add nuw nsw i32 %8007, %8035" -> "  %8037 = add nuw nsw i32 %8036, %8008"
"  %8037 = add nuw nsw i32 %8036, %8008"
"  %8037 = add nuw nsw i32 %8036, %8008" -> "  %8038 = add nuw nsw i32 %8037, %8017"
"  %8038 = add nuw nsw i32 %8037, %8017"
"  %8038 = add nuw nsw i32 %8037, %8017" -> "  %8039 = add nuw nsw i32 %8038, %8034"
"  %8039 = add nuw nsw i32 %8038, %8034"
"  %8039 = add nuw nsw i32 %8038, %8034" -> "  %8130 = and i32 %8039, 65535""  %8039 = add nuw nsw i32 %8038, %8034" -> "  %8042 = lshr i32 %8039, 16"
"  %8040 = and i32 %7933, 65535"
"  %8040 = and i32 %7933, 65535" -> "  %8043 = add nuw nsw i32 %8042, %8040"
"  %8041 = and i32 %7947, 65535"
"  %8041 = and i32 %7947, 65535" -> "  %8045 = add nuw nsw i32 %8044, %8041"
"  %8042 = lshr i32 %8039, 16"
"  %8042 = lshr i32 %8039, 16" -> "  %8043 = add nuw nsw i32 %8042, %8040"
"  %8043 = add nuw nsw i32 %8042, %8040"
"  %8043 = add nuw nsw i32 %8042, %8040" -> "  %8135 = and i32 %8043, 65535""  %8043 = add nuw nsw i32 %8042, %8040" -> "  %8044 = lshr i32 %8043, 16"
"  %8044 = lshr i32 %8043, 16"
"  %8044 = lshr i32 %8043, 16" -> "  %8045 = add nuw nsw i32 %8044, %8041"
"  %8045 = add nuw nsw i32 %8044, %8041"
"  %8045 = add nuw nsw i32 %8044, %8041" -> "  %8138 = and i32 %8045, 65535""  %8045 = add nuw nsw i32 %8044, %8041" -> "  %8046 = lshr i32 %8045, 16"
"  %8046 = lshr i32 %8045, 16"
"  %8046 = lshr i32 %8045, 16" -> "  %8048 = add nuw nsw i32 %8046, %8047"
"  %8047 = and i32 %7950, 65535"
"  %8047 = and i32 %7950, 65535" -> "  %8048 = add nuw nsw i32 %8046, %8047"
"  %8048 = add nuw nsw i32 %8046, %8047"
"  %8048 = add nuw nsw i32 %8046, %8047" -> "  %8144 = and i32 %8048, 65535""  %8048 = add nuw nsw i32 %8046, %8047" -> "  %8050 = lshr i32 %8048, 16"
"  %8049 = and i32 %7957, 65535"
"  %8049 = and i32 %7957, 65535" -> "  %8051 = add nuw nsw i32 %8050, %8049"
"  %8050 = lshr i32 %8048, 16"
"  %8050 = lshr i32 %8048, 16" -> "  %8051 = add nuw nsw i32 %8050, %8049"
"  %8051 = add nuw nsw i32 %8050, %8049"
"  %8051 = add nuw nsw i32 %8050, %8049" -> "  %8146 = and i32 %8051, 65535""  %8051 = add nuw nsw i32 %8050, %8049" -> "  %8052 = lshr i32 %8051, 16"
"  %8052 = lshr i32 %8051, 16"
"  %8052 = lshr i32 %8051, 16" -> "  %8054 = add nuw nsw i32 %8052, %8053"
"  %8053 = and i32 %7960, 65535"
"  %8053 = and i32 %7960, 65535" -> "  %8054 = add nuw nsw i32 %8052, %8053"
"  %8054 = add nuw nsw i32 %8052, %8053"
"  %8054 = add nuw nsw i32 %8052, %8053" -> "  %8150 = and i32 %8054, 65535""  %8054 = add nuw nsw i32 %8052, %8053" -> "  %8055 = lshr i32 %8054, 16"
"  %8055 = lshr i32 %8054, 16"
"  %8055 = lshr i32 %8054, 16" -> "  %8056 = add nuw i32 %7962, %8055"
"  %8056 = add nuw i32 %7962, %8055"
"  %8056 = add nuw i32 %7962, %8055" -> "  %8155 = add nuw i32 %8056, %8154"
"  %8057 = and i32 %7288, 65535"
"  %8057 = and i32 %7288, 65535" -> "  %8059 = add nuw nsw i32 %8057, %8058"
"  %8058 = and i32 %7965, 65535"
"  %8058 = and i32 %7965, 65535" -> "  %8059 = add nuw nsw i32 %8057, %8058"
"  %8059 = add nuw nsw i32 %8057, %8058"
"  %8059 = add nuw nsw i32 %8057, %8058" -> "  %8063 = lshr i32 %8059, 16"
"  %8060 = and i32 %7291, 65535"
"  %8060 = and i32 %7291, 65535" -> "  %8062 = add nuw nsw i32 %8060, %8061"
"  %8061 = and i32 %7971, 65535"
"  %8061 = and i32 %7971, 65535" -> "  %8062 = add nuw nsw i32 %8060, %8061"
"  %8062 = add nuw nsw i32 %8060, %8061"
"  %8062 = add nuw nsw i32 %8060, %8061" -> "  %8076 = lshr i32 %8062, 16""  %8062 = add nuw nsw i32 %8060, %8061" -> "  %8064 = and i32 %8062, 65535"
"  %8063 = lshr i32 %8059, 16"
"  %8063 = lshr i32 %8059, 16" -> "  %8065 = add nuw nsw i32 %8064, %8063"
"  %8064 = and i32 %8062, 65535"
"  %8064 = and i32 %8062, 65535" -> "  %8065 = add nuw nsw i32 %8064, %8063"
"  %8065 = add nuw nsw i32 %8064, %8063"
"  %8065 = add nuw nsw i32 %8064, %8063" -> "  %8078 = lshr i32 %8065, 16"
"  %8066 = and i32 %7294, 65535"
"  %8066 = and i32 %7294, 65535" -> "  %8068 = add nuw nsw i32 %8066, %8067"
"  %8067 = and i32 %7985, 65535"
"  %8067 = and i32 %7985, 65535" -> "  %8068 = add nuw nsw i32 %8066, %8067"
"  %8068 = add nuw nsw i32 %8066, %8067"
"  %8068 = add nuw nsw i32 %8066, %8067" -> "  %8075 = and i32 %8068, 65535""  %8068 = add nuw nsw i32 %8066, %8067" -> "  %8072 = lshr i32 %8068, 16"
"  %8069 = and i32 %7297, 65535"
"  %8069 = and i32 %7297, 65535" -> "  %8071 = add nuw nsw i32 %8069, %8070"
"  %8070 = and i32 %7988, 65535"
"  %8070 = and i32 %7988, 65535" -> "  %8071 = add nuw nsw i32 %8069, %8070"
"  %8071 = add nuw nsw i32 %8069, %8070"
"  %8071 = add nuw nsw i32 %8069, %8070" -> "  %8113 = lshr i32 %8071, 16""  %8071 = add nuw nsw i32 %8069, %8070" -> "  %8073 = and i32 %8071, 65535"
"  %8072 = lshr i32 %8068, 16"
"  %8072 = lshr i32 %8068, 16" -> "  %8074 = add nuw nsw i32 %8073, %8072"
"  %8073 = and i32 %8071, 65535"
"  %8073 = and i32 %8071, 65535" -> "  %8074 = add nuw nsw i32 %8073, %8072"
"  %8074 = add nuw nsw i32 %8073, %8072"
"  %8074 = add nuw nsw i32 %8073, %8072" -> "  %8115 = lshr i32 %8074, 16""  %8074 = add nuw nsw i32 %8073, %8072" -> "  %8081 = and i32 %8074, 65535"
"  %8075 = and i32 %8068, 65535"
"  %8075 = and i32 %8068, 65535" -> "  %8077 = add nuw nsw i32 %8075, %8076"
"  %8076 = lshr i32 %8062, 16"
"  %8076 = lshr i32 %8062, 16" -> "  %8077 = add nuw nsw i32 %8075, %8076"
"  %8077 = add nuw nsw i32 %8075, %8076"
"  %8077 = add nuw nsw i32 %8075, %8076" -> "  %8079 = add nuw nsw i32 %8077, %8078"
"  %8078 = lshr i32 %8065, 16"
"  %8078 = lshr i32 %8065, 16" -> "  %8079 = add nuw nsw i32 %8077, %8078"
"  %8079 = add nuw nsw i32 %8077, %8078"
"  %8079 = add nuw nsw i32 %8077, %8078" -> "  %8080 = lshr i32 %8079, 16"
"  %8080 = lshr i32 %8079, 16"
"  %8080 = lshr i32 %8079, 16" -> "  %8082 = add nuw nsw i32 %8081, %8080"
"  %8081 = and i32 %8074, 65535"
"  %8081 = and i32 %8074, 65535" -> "  %8082 = add nuw nsw i32 %8081, %8080"
"  %8082 = add nuw nsw i32 %8081, %8080"
"  %8082 = add nuw nsw i32 %8081, %8080" -> "  %8117 = lshr i32 %8082, 16"
"  %8083 = and i32 %7300, 65535"
"  %8083 = and i32 %7300, 65535" -> "  %8085 = add nuw nsw i32 %8083, %8084"
"  %8084 = and i32 %8024, 65535"
"  %8084 = and i32 %8024, 65535" -> "  %8085 = add nuw nsw i32 %8083, %8084"
"  %8085 = add nuw nsw i32 %8083, %8084"
"  %8085 = add nuw nsw i32 %8083, %8084" -> "  %8112 = and i32 %8085, 65535""  %8085 = add nuw nsw i32 %8083, %8084" -> "  %8089 = lshr i32 %8085, 16"
"  %8086 = and i32 %7303, 65535"
"  %8086 = and i32 %7303, 65535" -> "  %8088 = add nuw nsw i32 %8086, %8087"
"  %8087 = and i32 %8027, 65535"
"  %8087 = and i32 %8027, 65535" -> "  %8088 = add nuw nsw i32 %8086, %8087"
"  %8088 = add nuw nsw i32 %8086, %8087"
"  %8088 = add nuw nsw i32 %8086, %8087" -> "  %8104 = lshr i32 %8088, 16""  %8088 = add nuw nsw i32 %8086, %8087" -> "  %8090 = and i32 %8088, 65535"
"  %8089 = lshr i32 %8085, 16"
"  %8089 = lshr i32 %8085, 16" -> "  %8091 = add nuw nsw i32 %8090, %8089"
"  %8090 = and i32 %8088, 65535"
"  %8090 = and i32 %8088, 65535" -> "  %8091 = add nuw nsw i32 %8090, %8089"
"  %8091 = add nuw nsw i32 %8090, %8089"
"  %8091 = add nuw nsw i32 %8090, %8089" -> "  %8119 = and i32 %8091, 65535""  %8091 = add nuw nsw i32 %8090, %8089" -> "  %8106 = lshr i32 %8091, 16"
"  %8092 = and i32 %7305, 65535"
"  %8092 = and i32 %7305, 65535" -> "  %8094 = add nuw nsw i32 %8092, %8093"
"  %8093 = and i32 %8030, 65535"
"  %8093 = and i32 %8030, 65535" -> "  %8094 = add nuw nsw i32 %8092, %8093"
"  %8094 = add nuw nsw i32 %8092, %8093"
"  %8094 = add nuw nsw i32 %8092, %8093" -> "  %8103 = and i32 %8094, 65535""  %8094 = add nuw nsw i32 %8092, %8093" -> "  %8098 = lshr i32 %8094, 16"
"  %8095 = lshr i32 %7305, 16"
"  %8095 = lshr i32 %7305, 16" -> "  %8097 = add nuw nsw i32 %8096, %8095"
"  %8096 = and i32 %8033, 65535"
"  %8096 = and i32 %8033, 65535" -> "  %8097 = add nuw nsw i32 %8096, %8095"
"  %8097 = add nuw nsw i32 %8096, %8095"
"  %8097 = add nuw nsw i32 %8096, %8095" -> "  %8101 = lshr i32 %8097, 16""  %8097 = add nuw nsw i32 %8096, %8095" -> "  %8099 = and i32 %8097, 65535"
"  %8098 = lshr i32 %8094, 16"
"  %8098 = lshr i32 %8094, 16" -> "  %8100 = add nuw nsw i32 %8099, %8098"
"  %8099 = and i32 %8097, 65535"
"  %8099 = and i32 %8097, 65535" -> "  %8100 = add nuw nsw i32 %8099, %8098"
"  %8100 = add nuw nsw i32 %8099, %8098"
"  %8100 = add nuw nsw i32 %8099, %8098" -> "  %8108 = and i32 %8100, 65535""  %8100 = add nuw nsw i32 %8099, %8098" -> "  %8102 = lshr i32 %8100, 16"
"  %8101 = lshr i32 %8097, 16"
"  %8101 = lshr i32 %8097, 16" -> "  %8131 = add nuw nsw i32 %8130, %8101"
"  %8102 = lshr i32 %8100, 16"
"  %8102 = lshr i32 %8100, 16" -> "  %8132 = add nuw nsw i32 %8131, %8102"
"  %8103 = and i32 %8094, 65535"
"  %8103 = and i32 %8094, 65535" -> "  %8105 = add nuw nsw i32 %8103, %8104"
"  %8104 = lshr i32 %8088, 16"
"  %8104 = lshr i32 %8088, 16" -> "  %8105 = add nuw nsw i32 %8103, %8104"
"  %8105 = add nuw nsw i32 %8103, %8104"
"  %8105 = add nuw nsw i32 %8103, %8104" -> "  %8107 = add nuw nsw i32 %8105, %8106"
"  %8106 = lshr i32 %8091, 16"
"  %8106 = lshr i32 %8091, 16" -> "  %8107 = add nuw nsw i32 %8105, %8106"
"  %8107 = add nuw nsw i32 %8105, %8106"
"  %8107 = add nuw nsw i32 %8105, %8106" -> "  %8122 = and i32 %8107, 65535""  %8107 = add nuw nsw i32 %8105, %8106" -> "  %8109 = lshr i32 %8107, 16"
"  %8108 = and i32 %8100, 65535"
"  %8108 = and i32 %8100, 65535" -> "  %8110 = add nuw nsw i32 %8109, %8108"
"  %8109 = lshr i32 %8107, 16"
"  %8109 = lshr i32 %8107, 16" -> "  %8110 = add nuw nsw i32 %8109, %8108"
"  %8110 = add nuw nsw i32 %8109, %8108"
"  %8110 = add nuw nsw i32 %8109, %8108" -> "  %8125 = and i32 %8110, 65535""  %8110 = add nuw nsw i32 %8109, %8108" -> "  %8111 = lshr i32 %8110, 16"
"  %8111 = lshr i32 %8110, 16"
"  %8111 = lshr i32 %8110, 16" -> "  %8133 = add nuw nsw i32 %8132, %8111"
"  %8112 = and i32 %8085, 65535"
"  %8112 = and i32 %8085, 65535" -> "  %8114 = add nuw nsw i32 %8112, %8113"
"  %8113 = lshr i32 %8071, 16"
"  %8113 = lshr i32 %8071, 16" -> "  %8114 = add nuw nsw i32 %8112, %8113"
"  %8114 = add nuw nsw i32 %8112, %8113"
"  %8114 = add nuw nsw i32 %8112, %8113" -> "  %8116 = add nuw nsw i32 %8114, %8115"
"  %8115 = lshr i32 %8074, 16"
"  %8115 = lshr i32 %8074, 16" -> "  %8116 = add nuw nsw i32 %8114, %8115"
"  %8116 = add nuw nsw i32 %8114, %8115"
"  %8116 = add nuw nsw i32 %8114, %8115" -> "  %8118 = add nuw nsw i32 %8116, %8117"
"  %8117 = lshr i32 %8082, 16"
"  %8117 = lshr i32 %8082, 16" -> "  %8118 = add nuw nsw i32 %8116, %8117"
"  %8118 = add nuw nsw i32 %8116, %8117"
"  %8118 = add nuw nsw i32 %8116, %8117" -> "  %8120 = lshr i32 %8118, 16"
"  %8119 = and i32 %8091, 65535"
"  %8119 = and i32 %8091, 65535" -> "  %8121 = add nuw nsw i32 %8120, %8119"
"  %8120 = lshr i32 %8118, 16"
"  %8120 = lshr i32 %8118, 16" -> "  %8121 = add nuw nsw i32 %8120, %8119"
"  %8121 = add nuw nsw i32 %8120, %8119"
"  %8121 = add nuw nsw i32 %8120, %8119" -> "  %8123 = lshr i32 %8121, 16"
"  %8122 = and i32 %8107, 65535"
"  %8122 = and i32 %8107, 65535" -> "  %8124 = add nuw nsw i32 %8122, %8123"
"  %8123 = lshr i32 %8121, 16"
"  %8123 = lshr i32 %8121, 16" -> "  %8124 = add nuw nsw i32 %8122, %8123"
"  %8124 = add nuw nsw i32 %8122, %8123"
"  %8124 = add nuw nsw i32 %8122, %8123" -> "  %8126 = lshr i32 %8124, 16"
"  %8125 = and i32 %8110, 65535"
"  %8125 = and i32 %8110, 65535" -> "  %8127 = add nuw nsw i32 %8126, %8125"
"  %8126 = lshr i32 %8124, 16"
"  %8126 = lshr i32 %8124, 16" -> "  %8127 = add nuw nsw i32 %8126, %8125"
"  %8127 = add nuw nsw i32 %8126, %8125"
"  %8127 = add nuw nsw i32 %8126, %8125" -> "  %8129 = lshr i32 %8127, 16""  %8127 = add nuw nsw i32 %8126, %8125" -> "  %8128 = lshr i32 %8127, 15"
"  %8128 = lshr i32 %8127, 15"
"  %8128 = lshr i32 %8127, 15" -> "  %8177 = and i32 %8128, 1"
"  %8129 = lshr i32 %8127, 16"
"  %8129 = lshr i32 %8127, 16" -> "  %8134 = add nuw nsw i32 %8133, %8129"
"  %8130 = and i32 %8039, 65535"
"  %8130 = and i32 %8039, 65535" -> "  %8131 = add nuw nsw i32 %8130, %8101"
"  %8131 = add nuw nsw i32 %8130, %8101"
"  %8131 = add nuw nsw i32 %8130, %8101" -> "  %8132 = add nuw nsw i32 %8131, %8102"
"  %8132 = add nuw nsw i32 %8131, %8102"
"  %8132 = add nuw nsw i32 %8131, %8102" -> "  %8133 = add nuw nsw i32 %8132, %8111"
"  %8133 = add nuw nsw i32 %8132, %8111"
"  %8133 = add nuw nsw i32 %8132, %8111" -> "  %8134 = add nuw nsw i32 %8133, %8129"
"  %8134 = add nuw nsw i32 %8133, %8129"
"  %8134 = add nuw nsw i32 %8133, %8129" -> "  %8178 = shl nuw nsw i32 %8134, 1""  %8134 = add nuw nsw i32 %8133, %8129" -> "  %8164 = lshr i32 %8134, 15""  %8134 = add nuw nsw i32 %8133, %8129" -> "  %8136 = lshr i32 %8134, 16"
"  %8135 = and i32 %8043, 65535"
"  %8135 = and i32 %8043, 65535" -> "  %8137 = add nuw nsw i32 %8136, %8135"
"  %8136 = lshr i32 %8134, 16"
"  %8136 = lshr i32 %8134, 16" -> "  %8137 = add nuw nsw i32 %8136, %8135"
"  %8137 = add nuw nsw i32 %8136, %8135"
"  %8137 = add nuw nsw i32 %8136, %8135" -> "  %8166 = shl nuw nsw i32 %8137, 1""  %8137 = add nuw nsw i32 %8136, %8135" -> "  %8140 = lshr i32 %8137, 16""  %8137 = add nuw nsw i32 %8136, %8135" -> "  %8139 = lshr i32 %8137, 15"
"  %8138 = and i32 %8045, 65535"
"  %8138 = and i32 %8045, 65535" -> "  %8141 = add nuw nsw i32 %8140, %8138"
"  %8139 = lshr i32 %8137, 15"
"  %8139 = lshr i32 %8137, 15" -> "  %8160 = and i32 %8139, 1"
"  %8140 = lshr i32 %8137, 16"
"  %8140 = lshr i32 %8137, 16" -> "  %8141 = add nuw nsw i32 %8140, %8138"
"  %8141 = add nuw nsw i32 %8140, %8138"
"  %8141 = add nuw nsw i32 %8140, %8138" -> "  %8161 = shl nuw nsw i32 %8141, 1""  %8141 = add nuw nsw i32 %8140, %8138" -> "  %8143 = lshr i32 %8141, 16""  %8141 = add nuw nsw i32 %8140, %8138" -> "  %8142 = lshr i32 %8141, 15"
"  %8142 = lshr i32 %8141, 15"
"  %8142 = lshr i32 %8141, 15" -> "  %8156 = and i32 %8142, 1"
"  %8143 = lshr i32 %8141, 16"
"  %8143 = lshr i32 %8141, 16" -> "  %8145 = add nuw nsw i32 %8143, %8144"
"  %8144 = and i32 %8048, 65535"
"  %8144 = and i32 %8048, 65535" -> "  %8145 = add nuw nsw i32 %8143, %8144"
"  %8145 = add nuw nsw i32 %8143, %8144"
"  %8145 = add nuw nsw i32 %8143, %8144" -> "  %8157 = shl nuw nsw i32 %8145, 1""  %8145 = add nuw nsw i32 %8143, %8144" -> "  %8148 = lshr i32 %8145, 16""  %8145 = add nuw nsw i32 %8143, %8144" -> "  %8147 = lshr i32 %8145, 15"
"  %8146 = and i32 %8051, 65535"
"  %8146 = and i32 %8051, 65535" -> "  %8149 = add nuw nsw i32 %8148, %8146"
"  %8147 = lshr i32 %8145, 15"
"  %8147 = lshr i32 %8145, 15" -> "  %8173 = and i32 %8147, 1"
"  %8148 = lshr i32 %8145, 16"
"  %8148 = lshr i32 %8145, 16" -> "  %8149 = add nuw nsw i32 %8148, %8146"
"  %8149 = add nuw nsw i32 %8148, %8146"
"  %8149 = add nuw nsw i32 %8148, %8146" -> "  %8372 = lshr i32 %8149, 15""  %8149 = add nuw nsw i32 %8148, %8146" -> "  %8174 = shl nuw nsw i32 %8149, 1""  %8149 = add nuw nsw i32 %8148, %8146" -> "  %8151 = lshr i32 %8149, 16"
"  %8150 = and i32 %8054, 65535"
"  %8150 = and i32 %8054, 65535" -> "  %8152 = add nuw nsw i32 %8151, %8150"
"  %8151 = lshr i32 %8149, 16"
"  %8151 = lshr i32 %8149, 16" -> "  %8152 = add nuw nsw i32 %8151, %8150"
"  %8152 = add nuw nsw i32 %8151, %8150"
"  %8152 = add nuw nsw i32 %8151, %8150" -> "  %8374 = shl nuw nsw i32 %8152, 1""  %8152 = add nuw nsw i32 %8151, %8150" -> "  %8154 = lshr i32 %8152, 16""  %8152 = add nuw nsw i32 %8151, %8150" -> "  %8153 = lshr i32 %8152, 15"
"  %8153 = lshr i32 %8152, 15"
"  %8153 = lshr i32 %8152, 15" -> "  %8169 = and i32 %8153, 1"
"  %8154 = lshr i32 %8152, 16"
"  %8154 = lshr i32 %8152, 16" -> "  %8155 = add nuw i32 %8056, %8154"
"  %8155 = add nuw i32 %8056, %8154"
"  %8155 = add nuw i32 %8056, %8154" -> "  %8395 = lshr i32 %8155, 15""  %8155 = add nuw i32 %8056, %8154" -> "  %8170 = shl i32 %8155, 1"
"  %8156 = and i32 %8142, 1"
"  %8156 = and i32 %8142, 1" -> "  %8159 = or i32 %8158, %8156"
"  %8157 = shl nuw nsw i32 %8145, 1"
"  %8157 = shl nuw nsw i32 %8145, 1" -> "  %8158 = and i32 %8157, 65534"
"  %8158 = and i32 %8157, 65534"
"  %8158 = and i32 %8157, 65534" -> "  %8159 = or i32 %8158, %8156"
"  %8159 = or i32 %8158, %8156"
"  %8159 = or i32 %8158, %8156" -> "  %8330 = mul nuw nsw i32 %8159, 1146""  %8159 = or i32 %8158, %8156" -> "  %8269 = mul nuw i32 %8159, 63663""  %8159 = or i32 %8158, %8156" -> "  %8265 = mul nuw nsw i32 %8159, 7935""  %8159 = or i32 %8158, %8156" -> "  %8238 = mul nuw i32 %8159, 34017""  %8159 = or i32 %8158, %8156" -> "  %8234 = mul nuw nsw i32 %8159, 17399"
"  %8160 = and i32 %8139, 1"
"  %8160 = and i32 %8139, 1" -> "  %8163 = or i32 %8162, %8160"
"  %8161 = shl nuw nsw i32 %8141, 1"
"  %8161 = shl nuw nsw i32 %8141, 1" -> "  %8162 = and i32 %8161, 65534"
"  %8162 = and i32 %8161, 65534"
"  %8162 = and i32 %8161, 65534" -> "  %8163 = or i32 %8162, %8160"
"  %8163 = or i32 %8162, %8160"
"  %8163 = or i32 %8162, %8160" -> "  %8328 = mul nuw nsw i32 %8163, 1146""  %8163 = or i32 %8162, %8160" -> "  %8327 = mul nuw i32 %8163, 43563""  %8163 = or i32 %8162, %8160" -> "  %8260 = mul nuw i32 %8163, 63663""  %8163 = or i32 %8162, %8160" -> "  %8258 = mul nuw nsw i32 %8163, 7935""  %8163 = or i32 %8162, %8160" -> "  %8229 = mul nuw i32 %8163, 34017""  %8163 = or i32 %8162, %8160" -> "  %8227 = mul nuw nsw i32 %8163, 17399"
"  %8164 = lshr i32 %8134, 15"
"  %8164 = lshr i32 %8134, 15" -> "  %8165 = and i32 %8164, 1"
"  %8165 = and i32 %8164, 1"
"  %8165 = and i32 %8164, 1" -> "  %8168 = or i32 %8167, %8165"
"  %8166 = shl nuw nsw i32 %8137, 1"
"  %8166 = shl nuw nsw i32 %8137, 1" -> "  %8167 = and i32 %8166, 65534"
"  %8167 = and i32 %8166, 65534"
"  %8167 = and i32 %8166, 65534" -> "  %8168 = or i32 %8167, %8165"
"  %8168 = or i32 %8167, %8165"
"  %8168 = or i32 %8167, %8165" -> "  %8323 = mul nuw nsw i32 %8168, 13953""  %8168 = or i32 %8167, %8165" -> "  %8313 = mul nuw i32 %8168, 43563""  %8168 = or i32 %8167, %8165" -> "  %8309 = mul nuw nsw i32 %8168, 1146""  %8168 = or i32 %8167, %8165" -> "  %8207 = mul nuw i32 %8168, 63663""  %8168 = or i32 %8167, %8165" -> "  %8203 = mul nuw nsw i32 %8168, 7935""  %8168 = or i32 %8167, %8165" -> "  %8192 = mul nuw i32 %8168, 34017""  %8168 = or i32 %8167, %8165" -> "  %8188 = mul nuw nsw i32 %8168, 17399"
"  %8169 = and i32 %8153, 1"
"  %8169 = and i32 %8153, 1" -> "  %8172 = or i32 %8171, %8169"
"  %8170 = shl i32 %8155, 1"
"  %8170 = shl i32 %8155, 1" -> "  %8171 = and i32 %8170, 65534"
"  %8171 = and i32 %8170, 65534"
"  %8171 = and i32 %8170, 65534" -> "  %8172 = or i32 %8171, %8169"
"  %8172 = or i32 %8171, %8169"
"  %8172 = or i32 %8171, %8169" -> "  %8398 = mul nuw i32 %8172, 34017""  %8172 = or i32 %8171, %8169" -> "  %8399 = mul nuw nsw i32 %8172, 17399"
"  %8173 = and i32 %8147, 1"
"  %8173 = and i32 %8147, 1" -> "  %8176 = or i32 %8175, %8173"
"  %8174 = shl nuw nsw i32 %8149, 1"
"  %8174 = shl nuw nsw i32 %8149, 1" -> "  %8175 = and i32 %8174, 65534"
"  %8175 = and i32 %8174, 65534"
"  %8175 = and i32 %8174, 65534" -> "  %8176 = or i32 %8175, %8173"
"  %8176 = or i32 %8175, %8173"
"  %8176 = or i32 %8175, %8173" -> "  %8368 = mul nuw nsw i32 %8176, 17399""  %8176 = or i32 %8175, %8173" -> "  %8370 = mul nuw i32 %8176, 34017""  %8176 = or i32 %8175, %8173" -> "  %8388 = mul nuw nsw i32 %8176, 7935""  %8176 = or i32 %8175, %8173" -> "  %8390 = mul nuw i32 %8176, 63663"
"  %8177 = and i32 %8128, 1"
"  %8177 = and i32 %8128, 1" -> "  %8180 = or i32 %8179, %8177"
"  %8178 = shl nuw nsw i32 %8134, 1"
"  %8178 = shl nuw nsw i32 %8134, 1" -> "  %8179 = and i32 %8178, 65534"
"  %8179 = and i32 %8178, 65534"
"  %8179 = and i32 %8178, 65534" -> "  %8180 = or i32 %8179, %8177"
"  %8180 = or i32 %8179, %8177"
"  %8180 = or i32 %8179, %8177" -> "  %8199 = mul nuw nsw i32 %8180, 7935""  %8180 = or i32 %8179, %8177" -> "  %8322 = mul nuw i32 %8180, 58377""  %8180 = or i32 %8179, %8177" -> "  %8320 = mul nuw nsw i32 %8180, 13953""  %8180 = or i32 %8179, %8177" -> "  %8304 = mul nuw i32 %8180, 43563""  %8180 = or i32 %8179, %8177" -> "  %8302 = mul nuw nsw i32 %8180, 1146""  %8180 = or i32 %8179, %8177" -> "  %8201 = mul nuw i32 %8180, 63663""  %8180 = or i32 %8179, %8177" -> "  %8183 = mul nuw i32 %8180, 34017""  %8180 = or i32 %8179, %8177" -> "  %8181 = mul nuw nsw i32 %8180, 17399"
"  %8181 = mul nuw nsw i32 %8180, 17399"
"  %8181 = mul nuw nsw i32 %8180, 17399" -> "  %8438 = and i32 %8181, 65535""  %8181 = mul nuw nsw i32 %8180, 17399" -> "  %8182 = lshr i32 %8181, 16"
"  %8182 = lshr i32 %8181, 16"
"  %8182 = lshr i32 %8181, 16" -> "  %8185 = add nuw nsw i32 %8182, %8184"
"  %8183 = mul nuw i32 %8180, 34017"
"  %8183 = mul nuw i32 %8180, 34017" -> "  %8186 = and i32 %8183, -65536""  %8183 = mul nuw i32 %8180, 34017" -> "  %8184 = and i32 %8183, 65535"
"  %8184 = and i32 %8183, 65535"
"  %8184 = and i32 %8183, 65535" -> "  %8185 = add nuw nsw i32 %8182, %8184"
"  %8185 = add nuw nsw i32 %8182, %8184"
"  %8185 = add nuw nsw i32 %8182, %8184" -> "  %8187 = add nuw i32 %8185, %8186"
"  %8186 = and i32 %8183, -65536"
"  %8186 = and i32 %8183, -65536" -> "  %8187 = add nuw i32 %8185, %8186"
"  %8187 = add nuw i32 %8185, %8186"
"  %8187 = add nuw i32 %8185, %8186" -> "  %8191 = lshr i32 %8187, 16""  %8187 = add nuw i32 %8185, %8186" -> "  %8189 = and i32 %8187, 65535"
"  %8188 = mul nuw nsw i32 %8168, 17399"
"  %8188 = mul nuw nsw i32 %8168, 17399" -> "  %8190 = add nuw nsw i32 %8189, %8188"
"  %8189 = and i32 %8187, 65535"
"  %8189 = and i32 %8187, 65535" -> "  %8190 = add nuw nsw i32 %8189, %8188"
"  %8190 = add nuw nsw i32 %8189, %8188"
"  %8190 = add nuw nsw i32 %8189, %8188" -> "  %8440 = and i32 %8190, 65535""  %8190 = add nuw nsw i32 %8189, %8188" -> "  %8194 = lshr i32 %8190, 16"
"  %8191 = lshr i32 %8187, 16"
"  %8191 = lshr i32 %8187, 16" -> "  %8193 = add nuw i32 %8191, %8192"
"  %8192 = mul nuw i32 %8168, 34017"
"  %8192 = mul nuw i32 %8168, 34017" -> "  %8193 = add nuw i32 %8191, %8192"
"  %8193 = add nuw i32 %8191, %8192"
"  %8193 = add nuw i32 %8191, %8192" -> "  %8197 = and i32 %8193, -65536""  %8193 = add nuw i32 %8191, %8192" -> "  %8195 = and i32 %8193, 65535"
"  %8194 = lshr i32 %8190, 16"
"  %8194 = lshr i32 %8190, 16" -> "  %8196 = add nuw nsw i32 %8194, %8195"
"  %8195 = and i32 %8193, 65535"
"  %8195 = and i32 %8193, 65535" -> "  %8196 = add nuw nsw i32 %8194, %8195"
"  %8196 = add nuw nsw i32 %8194, %8195"
"  %8196 = add nuw nsw i32 %8194, %8195" -> "  %8198 = add nuw i32 %8196, %8197"
"  %8197 = and i32 %8193, -65536"
"  %8197 = and i32 %8193, -65536" -> "  %8198 = add nuw i32 %8196, %8197"
"  %8198 = add nuw i32 %8196, %8197"
"  %8198 = add nuw i32 %8196, %8197" -> "  %8218 = lshr i32 %8198, 16""  %8198 = add nuw i32 %8196, %8197" -> "  %8215 = and i32 %8198, 65535"
"  %8199 = mul nuw nsw i32 %8180, 7935"
"  %8199 = mul nuw nsw i32 %8180, 7935" -> "  %8214 = and i32 %8199, 65535""  %8199 = mul nuw nsw i32 %8180, 7935" -> "  %8200 = lshr i32 %8199, 16"
"  %8200 = lshr i32 %8199, 16"
"  %8200 = lshr i32 %8199, 16" -> "  %8202 = add i32 %8200, %8201"
"  %8201 = mul nuw i32 %8180, 63663"
"  %8201 = mul nuw i32 %8180, 63663" -> "  %8202 = add i32 %8200, %8201"
"  %8202 = add i32 %8200, %8201"
"  %8202 = add i32 %8200, %8201" -> "  %8206 = lshr i32 %8202, 16""  %8202 = add i32 %8200, %8201" -> "  %8204 = and i32 %8202, 65535"
"  %8203 = mul nuw nsw i32 %8168, 7935"
"  %8203 = mul nuw nsw i32 %8168, 7935" -> "  %8205 = add nuw nsw i32 %8204, %8203"
"  %8204 = and i32 %8202, 65535"
"  %8204 = and i32 %8202, 65535" -> "  %8205 = add nuw nsw i32 %8204, %8203"
"  %8205 = add nuw nsw i32 %8204, %8203"
"  %8205 = add nuw nsw i32 %8204, %8203" -> "  %8217 = and i32 %8205, 65535""  %8205 = add nuw nsw i32 %8204, %8203" -> "  %8209 = lshr i32 %8205, 16"
"  %8206 = lshr i32 %8202, 16"
"  %8206 = lshr i32 %8202, 16" -> "  %8208 = add nuw i32 %8206, %8207"
"  %8207 = mul nuw i32 %8168, 63663"
"  %8207 = mul nuw i32 %8168, 63663" -> "  %8208 = add nuw i32 %8206, %8207"
"  %8208 = add nuw i32 %8206, %8207"
"  %8208 = add nuw i32 %8206, %8207" -> "  %8212 = and i32 %8208, -65536""  %8208 = add nuw i32 %8206, %8207" -> "  %8210 = and i32 %8208, 65535"
"  %8209 = lshr i32 %8205, 16"
"  %8209 = lshr i32 %8205, 16" -> "  %8211 = add nuw nsw i32 %8209, %8210"
"  %8210 = and i32 %8208, 65535"
"  %8210 = and i32 %8208, 65535" -> "  %8211 = add nuw nsw i32 %8209, %8210"
"  %8211 = add nuw nsw i32 %8209, %8210"
"  %8211 = add nuw nsw i32 %8209, %8210" -> "  %8213 = add nuw i32 %8211, %8212"
"  %8212 = and i32 %8208, -65536"
"  %8212 = and i32 %8208, -65536" -> "  %8213 = add nuw i32 %8211, %8212"
"  %8213 = add nuw i32 %8211, %8212"
"  %8213 = add nuw i32 %8211, %8212" -> "  %8221 = add i32 %8213, %8220"
"  %8214 = and i32 %8199, 65535"
"  %8214 = and i32 %8199, 65535" -> "  %8216 = add nuw nsw i32 %8215, %8214"
"  %8215 = and i32 %8198, 65535"
"  %8215 = and i32 %8198, 65535" -> "  %8216 = add nuw nsw i32 %8215, %8214"
"  %8216 = add nuw nsw i32 %8215, %8214"
"  %8216 = add nuw nsw i32 %8215, %8214" -> "  %8245 = and i32 %8216, 65535""  %8216 = add nuw nsw i32 %8215, %8214" -> "  %8223 = lshr i32 %8216, 16"
"  %8217 = and i32 %8205, 65535"
"  %8217 = and i32 %8205, 65535" -> "  %8219 = add nuw nsw i32 %8218, %8217"
"  %8218 = lshr i32 %8198, 16"
"  %8218 = lshr i32 %8198, 16" -> "  %8219 = add nuw nsw i32 %8218, %8217"
"  %8219 = add nuw nsw i32 %8218, %8217"
"  %8219 = add nuw nsw i32 %8218, %8217" -> "  %8222 = and i32 %8219, 65535""  %8219 = add nuw nsw i32 %8218, %8217" -> "  %8220 = lshr i32 %8219, 16"
"  %8220 = lshr i32 %8219, 16"
"  %8220 = lshr i32 %8219, 16" -> "  %8221 = add i32 %8213, %8220"
"  %8221 = add i32 %8213, %8220"
"  %8221 = add i32 %8213, %8220" -> "  %8226 = add i32 %8221, %8225"
"  %8222 = and i32 %8219, 65535"
"  %8222 = and i32 %8219, 65535" -> "  %8224 = add nuw nsw i32 %8223, %8222"
"  %8223 = lshr i32 %8216, 16"
"  %8223 = lshr i32 %8216, 16" -> "  %8224 = add nuw nsw i32 %8223, %8222"
"  %8224 = add nuw nsw i32 %8223, %8222"
"  %8224 = add nuw nsw i32 %8223, %8222" -> "  %8248 = and i32 %8224, 65535""  %8224 = add nuw nsw i32 %8223, %8222" -> "  %8225 = lshr i32 %8224, 16"
"  %8225 = lshr i32 %8224, 16"
"  %8225 = lshr i32 %8224, 16" -> "  %8226 = add i32 %8221, %8225"
"  %8226 = add i32 %8221, %8225"
"  %8226 = add i32 %8221, %8225" -> "  %8280 = lshr i32 %8226, 16""  %8226 = add i32 %8221, %8225" -> "  %8276 = and i32 %8226, 65535"
"  %8227 = mul nuw nsw i32 %8163, 17399"
"  %8227 = mul nuw nsw i32 %8163, 17399" -> "  %8246 = and i32 %8227, 65535""  %8227 = mul nuw nsw i32 %8163, 17399" -> "  %8228 = lshr i32 %8227, 16"
"  %8228 = lshr i32 %8227, 16"
"  %8228 = lshr i32 %8227, 16" -> "  %8231 = add nuw nsw i32 %8228, %8230"
"  %8229 = mul nuw i32 %8163, 34017"
"  %8229 = mul nuw i32 %8163, 34017" -> "  %8232 = and i32 %8229, -65536""  %8229 = mul nuw i32 %8163, 34017" -> "  %8230 = and i32 %8229, 65535"
"  %8230 = and i32 %8229, 65535"
"  %8230 = and i32 %8229, 65535" -> "  %8231 = add nuw nsw i32 %8228, %8230"
"  %8231 = add nuw nsw i32 %8228, %8230"
"  %8231 = add nuw nsw i32 %8228, %8230" -> "  %8233 = add i32 %8231, %8232"
"  %8232 = and i32 %8229, -65536"
"  %8232 = and i32 %8229, -65536" -> "  %8233 = add i32 %8231, %8232"
"  %8233 = add i32 %8231, %8232"
"  %8233 = add i32 %8231, %8232" -> "  %8237 = lshr i32 %8233, 16""  %8233 = add i32 %8231, %8232" -> "  %8235 = and i32 %8233, 65535"
"  %8234 = mul nuw nsw i32 %8159, 17399"
"  %8234 = mul nuw nsw i32 %8159, 17399" -> "  %8236 = add nuw i32 %8235, %8234"
"  %8235 = and i32 %8233, 65535"
"  %8235 = and i32 %8233, 65535" -> "  %8236 = add nuw i32 %8235, %8234"
"  %8236 = add nuw i32 %8235, %8234"
"  %8236 = add nuw i32 %8235, %8234" -> "  %8249 = and i32 %8236, 65535""  %8236 = add nuw i32 %8235, %8234" -> "  %8240 = lshr i32 %8236, 16"
"  %8237 = lshr i32 %8233, 16"
"  %8237 = lshr i32 %8233, 16" -> "  %8239 = add i32 %8237, %8238"
"  %8238 = mul nuw i32 %8159, 34017"
"  %8238 = mul nuw i32 %8159, 34017" -> "  %8239 = add i32 %8237, %8238"
"  %8239 = add i32 %8237, %8238"
"  %8239 = add i32 %8237, %8238" -> "  %8243 = and i32 %8239, -65536""  %8239 = add i32 %8237, %8238" -> "  %8241 = and i32 %8239, 65535"
"  %8240 = lshr i32 %8236, 16"
"  %8240 = lshr i32 %8236, 16" -> "  %8242 = add nuw nsw i32 %8240, %8241"
"  %8241 = and i32 %8239, 65535"
"  %8241 = and i32 %8239, 65535" -> "  %8242 = add nuw nsw i32 %8240, %8241"
"  %8242 = add nuw nsw i32 %8240, %8241"
"  %8242 = add nuw nsw i32 %8240, %8241" -> "  %8244 = add i32 %8242, %8243"
"  %8243 = and i32 %8239, -65536"
"  %8243 = and i32 %8239, -65536" -> "  %8244 = add i32 %8242, %8243"
"  %8244 = add i32 %8242, %8243"
"  %8244 = add i32 %8242, %8243" -> "  %8252 = add i32 %8244, %8251"
"  %8245 = and i32 %8216, 65535"
"  %8245 = and i32 %8216, 65535" -> "  %8247 = add nuw nsw i32 %8245, %8246"
"  %8246 = and i32 %8227, 65535"
"  %8246 = and i32 %8227, 65535" -> "  %8247 = add nuw nsw i32 %8245, %8246"
"  %8247 = add nuw nsw i32 %8245, %8246"
"  %8247 = add nuw nsw i32 %8245, %8246" -> "  %8444 = and i32 %8247, 65535""  %8247 = add nuw nsw i32 %8245, %8246" -> "  %8254 = lshr i32 %8247, 16"
"  %8248 = and i32 %8224, 65535"
"  %8248 = and i32 %8224, 65535" -> "  %8250 = add nuw nsw i32 %8248, %8249"
"  %8249 = and i32 %8236, 65535"
"  %8249 = and i32 %8236, 65535" -> "  %8250 = add nuw nsw i32 %8248, %8249"
"  %8250 = add nuw nsw i32 %8248, %8249"
"  %8250 = add nuw nsw i32 %8248, %8249" -> "  %8253 = and i32 %8250, 65535""  %8250 = add nuw nsw i32 %8248, %8249" -> "  %8251 = lshr i32 %8250, 16"
"  %8251 = lshr i32 %8250, 16"
"  %8251 = lshr i32 %8250, 16" -> "  %8252 = add i32 %8244, %8251"
"  %8252 = add i32 %8244, %8251"
"  %8252 = add i32 %8244, %8251" -> "  %8257 = add i32 %8252, %8256"
"  %8253 = and i32 %8250, 65535"
"  %8253 = and i32 %8250, 65535" -> "  %8255 = add nuw nsw i32 %8253, %8254"
"  %8254 = lshr i32 %8247, 16"
"  %8254 = lshr i32 %8247, 16" -> "  %8255 = add nuw nsw i32 %8253, %8254"
"  %8255 = add nuw nsw i32 %8253, %8254"
"  %8255 = add nuw nsw i32 %8253, %8254" -> "  %8448 = and i32 %8255, 65535""  %8255 = add nuw nsw i32 %8253, %8254" -> "  %8256 = lshr i32 %8255, 16"
"  %8256 = lshr i32 %8255, 16"
"  %8256 = lshr i32 %8255, 16" -> "  %8257 = add i32 %8252, %8256"
"  %8257 = add i32 %8252, %8256"
"  %8257 = add i32 %8252, %8256" -> "  %8293 = lshr i32 %8257, 16""  %8257 = add i32 %8252, %8256" -> "  %8290 = and i32 %8257, 65535"
"  %8258 = mul nuw nsw i32 %8163, 7935"
"  %8258 = mul nuw nsw i32 %8163, 7935" -> "  %8277 = and i32 %8258, 65535""  %8258 = mul nuw nsw i32 %8163, 7935" -> "  %8259 = lshr i32 %8258, 16"
"  %8259 = lshr i32 %8258, 16"
"  %8259 = lshr i32 %8258, 16" -> "  %8262 = add nuw nsw i32 %8259, %8261"
"  %8260 = mul nuw i32 %8163, 63663"
"  %8260 = mul nuw i32 %8163, 63663" -> "  %8263 = and i32 %8260, -65536""  %8260 = mul nuw i32 %8163, 63663" -> "  %8261 = and i32 %8260, 65535"
"  %8261 = and i32 %8260, 65535"
"  %8261 = and i32 %8260, 65535" -> "  %8262 = add nuw nsw i32 %8259, %8261"
"  %8262 = add nuw nsw i32 %8259, %8261"
"  %8262 = add nuw nsw i32 %8259, %8261" -> "  %8264 = add i32 %8262, %8263"
"  %8263 = and i32 %8260, -65536"
"  %8263 = and i32 %8260, -65536" -> "  %8264 = add i32 %8262, %8263"
"  %8264 = add i32 %8262, %8263"
"  %8264 = add i32 %8262, %8263" -> "  %8268 = lshr i32 %8264, 16""  %8264 = add i32 %8262, %8263" -> "  %8266 = and i32 %8264, 65535"
"  %8265 = mul nuw nsw i32 %8159, 7935"
"  %8265 = mul nuw nsw i32 %8159, 7935" -> "  %8267 = add nuw nsw i32 %8266, %8265"
"  %8266 = and i32 %8264, 65535"
"  %8266 = and i32 %8264, 65535" -> "  %8267 = add nuw nsw i32 %8266, %8265"
"  %8267 = add nuw nsw i32 %8266, %8265"
"  %8267 = add nuw nsw i32 %8266, %8265" -> "  %8279 = and i32 %8267, 65535""  %8267 = add nuw nsw i32 %8266, %8265" -> "  %8271 = lshr i32 %8267, 16"
"  %8268 = lshr i32 %8264, 16"
"  %8268 = lshr i32 %8264, 16" -> "  %8270 = add i32 %8268, %8269"
"  %8269 = mul nuw i32 %8159, 63663"
"  %8269 = mul nuw i32 %8159, 63663" -> "  %8270 = add i32 %8268, %8269"
"  %8270 = add i32 %8268, %8269"
"  %8270 = add i32 %8268, %8269" -> "  %8274 = and i32 %8270, -65536""  %8270 = add i32 %8268, %8269" -> "  %8272 = and i32 %8270, 65535"
"  %8271 = lshr i32 %8267, 16"
"  %8271 = lshr i32 %8267, 16" -> "  %8273 = add nuw nsw i32 %8271, %8272"
"  %8272 = and i32 %8270, 65535"
"  %8272 = and i32 %8270, 65535" -> "  %8273 = add nuw nsw i32 %8271, %8272"
"  %8273 = add nuw nsw i32 %8271, %8272"
"  %8273 = add nuw nsw i32 %8271, %8272" -> "  %8275 = add i32 %8273, %8274"
"  %8274 = and i32 %8270, -65536"
"  %8274 = and i32 %8270, -65536" -> "  %8275 = add i32 %8273, %8274"
"  %8275 = add i32 %8273, %8274"
"  %8275 = add i32 %8273, %8274" -> "  %8283 = add i32 %8275, %8282"
"  %8276 = and i32 %8226, 65535"
"  %8276 = and i32 %8226, 65535" -> "  %8278 = add nuw nsw i32 %8276, %8277"
"  %8277 = and i32 %8258, 65535"
"  %8277 = and i32 %8258, 65535" -> "  %8278 = add nuw nsw i32 %8276, %8277"
"  %8278 = add nuw nsw i32 %8276, %8277"
"  %8278 = add nuw nsw i32 %8276, %8277" -> "  %8289 = and i32 %8278, 65535""  %8278 = add nuw nsw i32 %8276, %8277" -> "  %8285 = lshr i32 %8278, 16"
"  %8279 = and i32 %8267, 65535"
"  %8279 = and i32 %8267, 65535" -> "  %8281 = add nuw nsw i32 %8280, %8279"
"  %8280 = lshr i32 %8226, 16"
"  %8280 = lshr i32 %8226, 16" -> "  %8281 = add nuw nsw i32 %8280, %8279"
"  %8281 = add nuw nsw i32 %8280, %8279"
"  %8281 = add nuw nsw i32 %8280, %8279" -> "  %8284 = and i32 %8281, 65535""  %8281 = add nuw nsw i32 %8280, %8279" -> "  %8282 = lshr i32 %8281, 16"
"  %8282 = lshr i32 %8281, 16"
"  %8282 = lshr i32 %8281, 16" -> "  %8283 = add i32 %8275, %8282"
"  %8283 = add i32 %8275, %8282"
"  %8283 = add i32 %8275, %8282" -> "  %8288 = add i32 %8283, %8287"
"  %8284 = and i32 %8281, 65535"
"  %8284 = and i32 %8281, 65535" -> "  %8286 = add nuw nsw i32 %8284, %8285"
"  %8285 = lshr i32 %8278, 16"
"  %8285 = lshr i32 %8278, 16" -> "  %8286 = add nuw nsw i32 %8284, %8285"
"  %8286 = add nuw nsw i32 %8284, %8285"
"  %8286 = add nuw nsw i32 %8284, %8285" -> "  %8292 = and i32 %8286, 65535""  %8286 = add nuw nsw i32 %8284, %8285" -> "  %8287 = lshr i32 %8286, 16"
"  %8287 = lshr i32 %8286, 16"
"  %8287 = lshr i32 %8286, 16" -> "  %8288 = add i32 %8283, %8287"
"  %8288 = add i32 %8283, %8287"
"  %8288 = add i32 %8283, %8287" -> "  %8300 = add i32 %8288, %8298"
"  %8289 = and i32 %8278, 65535"
"  %8289 = and i32 %8278, 65535" -> "  %8291 = add nuw nsw i32 %8290, %8289"
"  %8290 = and i32 %8257, 65535"
"  %8290 = and i32 %8257, 65535" -> "  %8291 = add nuw nsw i32 %8290, %8289"
"  %8291 = add nuw nsw i32 %8290, %8289"
"  %8291 = add nuw nsw i32 %8290, %8289" -> "  %8338 = and i32 %8291, 65535""  %8291 = add nuw nsw i32 %8290, %8289" -> "  %8295 = lshr i32 %8291, 16"
"  %8292 = and i32 %8286, 65535"
"  %8292 = and i32 %8286, 65535" -> "  %8294 = add nuw nsw i32 %8293, %8292"
"  %8293 = lshr i32 %8257, 16"
"  %8293 = lshr i32 %8257, 16" -> "  %8294 = add nuw nsw i32 %8293, %8292"
"  %8294 = add nuw nsw i32 %8293, %8292"
"  %8294 = add nuw nsw i32 %8293, %8292" -> "  %8298 = lshr i32 %8294, 16""  %8294 = add nuw nsw i32 %8293, %8292" -> "  %8296 = and i32 %8294, 65535"
"  %8295 = lshr i32 %8291, 16"
"  %8295 = lshr i32 %8291, 16" -> "  %8297 = add nuw nsw i32 %8296, %8295"
"  %8296 = and i32 %8294, 65535"
"  %8296 = and i32 %8294, 65535" -> "  %8297 = add nuw nsw i32 %8296, %8295"
"  %8297 = add nuw nsw i32 %8296, %8295"
"  %8297 = add nuw nsw i32 %8296, %8295" -> "  %8341 = and i32 %8297, 65535""  %8297 = add nuw nsw i32 %8296, %8295" -> "  %8299 = lshr i32 %8297, 16"
"  %8298 = lshr i32 %8294, 16"
"  %8298 = lshr i32 %8294, 16" -> "  %8300 = add i32 %8288, %8298"
"  %8299 = lshr i32 %8297, 16"
"  %8299 = lshr i32 %8297, 16" -> "  %8301 = add i32 %8300, %8299"
"  %8300 = add i32 %8288, %8298"
"  %8300 = add i32 %8288, %8298" -> "  %8301 = add i32 %8300, %8299"
"  %8301 = add i32 %8300, %8299"
"  %8301 = add i32 %8300, %8299" -> "  %8348 = and i32 %8301, 65535""  %8301 = add i32 %8300, %8299" -> "  %8337 = lshr i32 %8301, 16"
"  %8302 = mul nuw nsw i32 %8180, 1146"
"  %8302 = mul nuw nsw i32 %8180, 1146" -> "  %8339 = and i32 %8302, 65534""  %8302 = mul nuw nsw i32 %8180, 1146" -> "  %8303 = lshr i32 %8302, 16"
"  %8303 = lshr i32 %8302, 16"
"  %8303 = lshr i32 %8302, 16" -> "  %8306 = add nuw nsw i32 %8303, %8305"
"  %8304 = mul nuw i32 %8180, 43563"
"  %8304 = mul nuw i32 %8180, 43563" -> "  %8307 = and i32 %8304, -65536""  %8304 = mul nuw i32 %8180, 43563" -> "  %8305 = and i32 %8304, 65535"
"  %8305 = and i32 %8304, 65535"
"  %8305 = and i32 %8304, 65535" -> "  %8306 = add nuw nsw i32 %8303, %8305"
"  %8306 = add nuw nsw i32 %8303, %8305"
"  %8306 = add nuw nsw i32 %8303, %8305" -> "  %8308 = add i32 %8306, %8307"
"  %8307 = and i32 %8304, -65536"
"  %8307 = and i32 %8304, -65536" -> "  %8308 = add i32 %8306, %8307"
"  %8308 = add i32 %8306, %8307"
"  %8308 = add i32 %8306, %8307" -> "  %8312 = lshr i32 %8308, 16""  %8308 = add i32 %8306, %8307" -> "  %8310 = and i32 %8308, 65535"
"  %8309 = mul nuw nsw i32 %8168, 1146"
"  %8309 = mul nuw nsw i32 %8168, 1146" -> "  %8311 = add nuw nsw i32 %8310, %8309"
"  %8310 = and i32 %8308, 65535"
"  %8310 = and i32 %8308, 65535" -> "  %8311 = add nuw nsw i32 %8310, %8309"
"  %8311 = add nuw nsw i32 %8310, %8309"
"  %8311 = add nuw nsw i32 %8310, %8309" -> "  %8342 = and i32 %8311, 65535""  %8311 = add nuw nsw i32 %8310, %8309" -> "  %8315 = lshr i32 %8311, 16"
"  %8312 = lshr i32 %8308, 16"
"  %8312 = lshr i32 %8308, 16" -> "  %8314 = add i32 %8312, %8313"
"  %8313 = mul nuw i32 %8168, 43563"
"  %8313 = mul nuw i32 %8168, 43563" -> "  %8314 = add i32 %8312, %8313"
"  %8314 = add i32 %8312, %8313"
"  %8314 = add i32 %8312, %8313" -> "  %8318 = and i32 %8314, -65536""  %8314 = add i32 %8312, %8313" -> "  %8316 = and i32 %8314, 65535"
"  %8315 = lshr i32 %8311, 16"
"  %8315 = lshr i32 %8311, 16" -> "  %8317 = add nuw nsw i32 %8315, %8316"
"  %8316 = and i32 %8314, 65535"
"  %8316 = and i32 %8314, 65535" -> "  %8317 = add nuw nsw i32 %8315, %8316"
"  %8317 = add nuw nsw i32 %8315, %8316"
"  %8317 = add nuw nsw i32 %8315, %8316" -> "  %8319 = add i32 %8317, %8318"
"  %8318 = and i32 %8314, -65536"
"  %8318 = and i32 %8314, -65536" -> "  %8319 = add i32 %8317, %8318"
"  %8319 = add i32 %8317, %8318"
"  %8319 = add i32 %8317, %8318" -> "  %8331 = lshr i32 %8319, 16""  %8319 = add i32 %8317, %8318" -> "  %8324 = and i32 %8319, 65535"
"  %8320 = mul nuw nsw i32 %8180, 13953"
"  %8320 = mul nuw nsw i32 %8180, 13953" -> "  %8325 = and i32 %8320, 65535""  %8320 = mul nuw nsw i32 %8180, 13953" -> "  %8321 = lshr i32 %8320, 16"
"  %8321 = lshr i32 %8320, 16"
"  %8321 = lshr i32 %8320, 16" -> "  %8357 = add i32 %8321, %8322"
"  %8322 = mul nuw i32 %8180, 58377"
"  %8322 = mul nuw i32 %8180, 58377" -> "  %8357 = add i32 %8321, %8322"
"  %8323 = mul nuw nsw i32 %8168, 13953"
"  %8323 = mul nuw nsw i32 %8168, 13953" -> "  %8358 = add i32 %8357, %8323"
"  %8324 = and i32 %8319, 65535"
"  %8324 = and i32 %8319, 65535" -> "  %8326 = add nuw nsw i32 %8324, %8325"
"  %8325 = and i32 %8320, 65535"
"  %8325 = and i32 %8320, 65535" -> "  %8326 = add nuw nsw i32 %8324, %8325"
"  %8326 = add nuw nsw i32 %8324, %8325"
"  %8326 = add nuw nsw i32 %8324, %8325" -> "  %8333 = and i32 %8326, 65535""  %8326 = add nuw nsw i32 %8324, %8325" -> "  %8332 = lshr i32 %8326, 16"
"  %8327 = mul nuw i32 %8163, 43563"
"  %8327 = mul nuw i32 %8163, 43563" -> "  %8359 = add i32 %8358, %8327"
"  %8328 = mul nuw nsw i32 %8163, 1146"
"  %8328 = mul nuw nsw i32 %8163, 1146" -> "  %8334 = and i32 %8328, 65534""  %8328 = mul nuw nsw i32 %8163, 1146" -> "  %8329 = lshr i32 %8328, 16"
"  %8329 = lshr i32 %8328, 16"
"  %8329 = lshr i32 %8328, 16" -> "  %8360 = add i32 %8359, %8329"
"  %8330 = mul nuw nsw i32 %8159, 1146"
"  %8330 = mul nuw nsw i32 %8159, 1146" -> "  %8361 = add i32 %8360, %8330"
"  %8331 = lshr i32 %8319, 16"
"  %8331 = lshr i32 %8319, 16" -> "  %8362 = add i32 %8361, %8331"
"  %8332 = lshr i32 %8326, 16"
"  %8332 = lshr i32 %8326, 16" -> "  %8363 = add i32 %8362, %8332"
"  %8333 = and i32 %8326, 65535"
"  %8333 = and i32 %8326, 65535" -> "  %8335 = add nuw nsw i32 %8333, %8334"
"  %8334 = and i32 %8328, 65534"
"  %8334 = and i32 %8328, 65534" -> "  %8335 = add nuw nsw i32 %8333, %8334"
"  %8335 = add nuw nsw i32 %8333, %8334"
"  %8335 = add nuw nsw i32 %8333, %8334" -> "  %8347 = and i32 %8335, 65535""  %8335 = add nuw nsw i32 %8333, %8334" -> "  %8336 = lshr i32 %8335, 16"
"  %8336 = lshr i32 %8335, 16"
"  %8336 = lshr i32 %8335, 16" -> "  %8364 = add i32 %8363, %8336"
"  %8337 = lshr i32 %8301, 16"
"  %8337 = lshr i32 %8301, 16" -> "  %8365 = add i32 %8364, %8337"
"  %8338 = and i32 %8291, 65535"
"  %8338 = and i32 %8291, 65535" -> "  %8340 = add nuw nsw i32 %8338, %8339"
"  %8339 = and i32 %8302, 65534"
"  %8339 = and i32 %8302, 65534" -> "  %8340 = add nuw nsw i32 %8338, %8339"
"  %8340 = add nuw nsw i32 %8338, %8339"
"  %8340 = add nuw nsw i32 %8338, %8339" -> "  %8408 = and i32 %8340, 65535""  %8340 = add nuw nsw i32 %8338, %8339" -> "  %8344 = lshr i32 %8340, 16"
"  %8341 = and i32 %8297, 65535"
"  %8341 = and i32 %8297, 65535" -> "  %8343 = add nuw nsw i32 %8341, %8342"
"  %8342 = and i32 %8311, 65535"
"  %8342 = and i32 %8311, 65535" -> "  %8343 = add nuw nsw i32 %8341, %8342"
"  %8343 = add nuw nsw i32 %8341, %8342"
"  %8343 = add nuw nsw i32 %8341, %8342" -> "  %8352 = lshr i32 %8343, 16""  %8343 = add nuw nsw i32 %8341, %8342" -> "  %8345 = and i32 %8343, 65535"
"  %8344 = lshr i32 %8340, 16"
"  %8344 = lshr i32 %8340, 16" -> "  %8346 = add nuw nsw i32 %8345, %8344"
"  %8345 = and i32 %8343, 65535"
"  %8345 = and i32 %8343, 65535" -> "  %8346 = add nuw nsw i32 %8345, %8344"
"  %8346 = add nuw nsw i32 %8345, %8344"
"  %8346 = add nuw nsw i32 %8345, %8344" -> "  %8411 = and i32 %8346, 65535""  %8346 = add nuw nsw i32 %8345, %8344" -> "  %8354 = lshr i32 %8346, 16"
"  %8347 = and i32 %8335, 65535"
"  %8347 = and i32 %8335, 65535" -> "  %8349 = add nuw nsw i32 %8348, %8347"
"  %8348 = and i32 %8301, 65535"
"  %8348 = and i32 %8301, 65535" -> "  %8349 = add nuw nsw i32 %8348, %8347"
"  %8349 = add nuw nsw i32 %8348, %8347"
"  %8349 = add nuw nsw i32 %8348, %8347" -> "  %8351 = and i32 %8349, 65535""  %8349 = add nuw nsw i32 %8348, %8347" -> "  %8350 = lshr i32 %8349, 16"
"  %8350 = lshr i32 %8349, 16"
"  %8350 = lshr i32 %8349, 16" -> "  %8366 = add i32 %8365, %8350"
"  %8351 = and i32 %8349, 65535"
"  %8351 = and i32 %8349, 65535" -> "  %8353 = add nuw nsw i32 %8351, %8352"
"  %8352 = lshr i32 %8343, 16"
"  %8352 = lshr i32 %8343, 16" -> "  %8353 = add nuw nsw i32 %8351, %8352"
"  %8353 = add nuw nsw i32 %8351, %8352"
"  %8353 = add nuw nsw i32 %8351, %8352" -> "  %8355 = add nuw nsw i32 %8353, %8354"
"  %8354 = lshr i32 %8346, 16"
"  %8354 = lshr i32 %8346, 16" -> "  %8355 = add nuw nsw i32 %8353, %8354"
"  %8355 = add nuw nsw i32 %8353, %8354"
"  %8355 = add nuw nsw i32 %8353, %8354" -> "  %8419 = and i32 %8355, 65535""  %8355 = add nuw nsw i32 %8353, %8354" -> "  %8356 = lshr i32 %8355, 16"
"  %8356 = lshr i32 %8355, 16"
"  %8356 = lshr i32 %8355, 16" -> "  %8367 = add i32 %8366, %8356"
"  %8357 = add i32 %8321, %8322"
"  %8357 = add i32 %8321, %8322" -> "  %8358 = add i32 %8357, %8323"
"  %8358 = add i32 %8357, %8323"
"  %8358 = add i32 %8357, %8323" -> "  %8359 = add i32 %8358, %8327"
"  %8359 = add i32 %8358, %8327"
"  %8359 = add i32 %8358, %8327" -> "  %8360 = add i32 %8359, %8329"
"  %8360 = add i32 %8359, %8329"
"  %8360 = add i32 %8359, %8329" -> "  %8361 = add i32 %8360, %8330"
"  %8361 = add i32 %8360, %8330"
"  %8361 = add i32 %8360, %8330" -> "  %8362 = add i32 %8361, %8331"
"  %8362 = add i32 %8361, %8331"
"  %8362 = add i32 %8361, %8331" -> "  %8363 = add i32 %8362, %8332"
"  %8363 = add i32 %8362, %8332"
"  %8363 = add i32 %8362, %8332" -> "  %8364 = add i32 %8363, %8336"
"  %8364 = add i32 %8363, %8336"
"  %8364 = add i32 %8363, %8336" -> "  %8365 = add i32 %8364, %8337"
"  %8365 = add i32 %8364, %8337"
"  %8365 = add i32 %8364, %8337" -> "  %8366 = add i32 %8365, %8350"
"  %8366 = add i32 %8365, %8350"
"  %8366 = add i32 %8365, %8350" -> "  %8367 = add i32 %8366, %8356"
"  %8367 = add i32 %8366, %8356"
"  %8367 = add i32 %8366, %8356" -> "  %8421 = and i32 %8367, 65535"
"  %8368 = mul nuw nsw i32 %8176, 17399"
"  %8368 = mul nuw nsw i32 %8176, 17399" -> "  %8407 = and i32 %8368, 65535""  %8368 = mul nuw nsw i32 %8176, 17399" -> "  %8369 = lshr i32 %8368, 16"
"  %8369 = lshr i32 %8368, 16"
"  %8369 = lshr i32 %8368, 16" -> "  %8371 = add i32 %8369, %8370"
"  %8370 = mul nuw i32 %8176, 34017"
"  %8370 = mul nuw i32 %8176, 34017" -> "  %8371 = add i32 %8369, %8370"
"  %8371 = add i32 %8369, %8370"
"  %8371 = add i32 %8369, %8370" -> "  %8380 = lshr i32 %8371, 16""  %8371 = add i32 %8369, %8370" -> "  %8378 = and i32 %8371, 65535"
"  %8372 = lshr i32 %8149, 15"
"  %8372 = lshr i32 %8149, 15" -> "  %8373 = and i32 %8372, 1"
"  %8373 = and i32 %8372, 1"
"  %8373 = and i32 %8372, 1" -> "  %8376 = or i32 %8375, %8373"
"  %8374 = shl nuw nsw i32 %8152, 1"
"  %8374 = shl nuw nsw i32 %8152, 1" -> "  %8375 = and i32 %8374, 65534"
"  %8375 = and i32 %8374, 65534"
"  %8375 = and i32 %8374, 65534" -> "  %8376 = or i32 %8375, %8373"
"  %8376 = or i32 %8375, %8373"
"  %8376 = or i32 %8375, %8373" -> "  %8391 = mul nuw nsw i32 %8376, 7935""  %8376 = or i32 %8375, %8373" -> "  %8381 = mul nuw i32 %8376, 34017""  %8376 = or i32 %8375, %8373" -> "  %8377 = mul nuw nsw i32 %8376, 17399"
"  %8377 = mul nuw nsw i32 %8376, 17399"
"  %8377 = mul nuw nsw i32 %8376, 17399" -> "  %8379 = add nuw nsw i32 %8378, %8377"
"  %8378 = and i32 %8371, 65535"
"  %8378 = and i32 %8371, 65535" -> "  %8379 = add nuw nsw i32 %8378, %8377"
"  %8379 = add nuw nsw i32 %8378, %8377"
"  %8379 = add nuw nsw i32 %8378, %8377" -> "  %8410 = and i32 %8379, 65535""  %8379 = add nuw nsw i32 %8378, %8377" -> "  %8383 = lshr i32 %8379, 16"
"  %8380 = lshr i32 %8371, 16"
"  %8380 = lshr i32 %8371, 16" -> "  %8382 = add nuw i32 %8380, %8381"
"  %8381 = mul nuw i32 %8376, 34017"
"  %8381 = mul nuw i32 %8376, 34017" -> "  %8382 = add nuw i32 %8380, %8381"
"  %8382 = add nuw i32 %8380, %8381"
"  %8382 = add nuw i32 %8380, %8381" -> "  %8386 = and i32 %8382, -65536""  %8382 = add nuw i32 %8380, %8381" -> "  %8384 = and i32 %8382, 65535"
"  %8383 = lshr i32 %8379, 16"
"  %8383 = lshr i32 %8379, 16" -> "  %8385 = add nuw nsw i32 %8383, %8384"
"  %8384 = and i32 %8382, 65535"
"  %8384 = and i32 %8382, 65535" -> "  %8385 = add nuw nsw i32 %8383, %8384"
"  %8385 = add nuw nsw i32 %8383, %8384"
"  %8385 = add nuw nsw i32 %8383, %8384" -> "  %8387 = add i32 %8385, %8386"
"  %8386 = and i32 %8382, -65536"
"  %8386 = and i32 %8382, -65536" -> "  %8387 = add i32 %8385, %8386"
"  %8387 = add i32 %8385, %8386"
"  %8387 = add i32 %8385, %8386" -> "  %8401 = lshr i32 %8387, 16""  %8387 = add i32 %8385, %8386" -> "  %8392 = and i32 %8387, 65535"
"  %8388 = mul nuw nsw i32 %8176, 7935"
"  %8388 = mul nuw nsw i32 %8176, 7935" -> "  %8393 = and i32 %8388, 65535""  %8388 = mul nuw nsw i32 %8176, 7935" -> "  %8389 = lshr i32 %8388, 16"
"  %8389 = lshr i32 %8388, 16"
"  %8389 = lshr i32 %8388, 16" -> "  %8427 = add i32 %8389, %8390"
"  %8390 = mul nuw i32 %8176, 63663"
"  %8390 = mul nuw i32 %8176, 63663" -> "  %8427 = add i32 %8389, %8390"
"  %8391 = mul nuw nsw i32 %8376, 7935"
"  %8391 = mul nuw nsw i32 %8376, 7935" -> "  %8428 = add i32 %8427, %8391"
"  %8392 = and i32 %8387, 65535"
"  %8392 = and i32 %8387, 65535" -> "  %8394 = add nuw nsw i32 %8392, %8393"
"  %8393 = and i32 %8388, 65535"
"  %8393 = and i32 %8388, 65535" -> "  %8394 = add nuw nsw i32 %8392, %8393"
"  %8394 = add nuw nsw i32 %8392, %8393"
"  %8394 = add nuw nsw i32 %8392, %8393" -> "  %8403 = and i32 %8394, 65535""  %8394 = add nuw nsw i32 %8392, %8393" -> "  %8402 = lshr i32 %8394, 16"
"  %8395 = lshr i32 %8155, 15"
"  %8395 = lshr i32 %8155, 15" -> "  %8396 = and i32 %8395, 65535"
"  %8396 = and i32 %8395, 65535"
"  %8396 = and i32 %8395, 65535" -> "  %8397 = mul nuw nsw i32 %8396, 17399"
"  %8397 = mul nuw nsw i32 %8396, 17399"
"  %8397 = mul nuw nsw i32 %8396, 17399" -> "  %8429 = add i32 %8428, %8397"
"  %8398 = mul nuw i32 %8172, 34017"
"  %8398 = mul nuw i32 %8172, 34017" -> "  %8430 = add i32 %8429, %8398"
"  %8399 = mul nuw nsw i32 %8172, 17399"
"  %8399 = mul nuw nsw i32 %8172, 17399" -> "  %8404 = and i32 %8399, 65535""  %8399 = mul nuw nsw i32 %8172, 17399" -> "  %8400 = lshr i32 %8399, 16"
"  %8400 = lshr i32 %8399, 16"
"  %8400 = lshr i32 %8399, 16" -> "  %8431 = add i32 %8430, %8400"
"  %8401 = lshr i32 %8387, 16"
"  %8401 = lshr i32 %8387, 16" -> "  %8432 = add i32 %8431, %8401"
"  %8402 = lshr i32 %8394, 16"
"  %8402 = lshr i32 %8394, 16" -> "  %8433 = add i32 %8432, %8402"
"  %8403 = and i32 %8394, 65535"
"  %8403 = and i32 %8394, 65535" -> "  %8405 = add nuw nsw i32 %8403, %8404"
"  %8404 = and i32 %8399, 65535"
"  %8404 = and i32 %8399, 65535" -> "  %8405 = add nuw nsw i32 %8403, %8404"
"  %8405 = add nuw nsw i32 %8403, %8404"
"  %8405 = add nuw nsw i32 %8403, %8404" -> "  %8418 = and i32 %8405, 65535""  %8405 = add nuw nsw i32 %8403, %8404" -> "  %8406 = lshr i32 %8405, 16"
"  %8406 = lshr i32 %8405, 16"
"  %8406 = lshr i32 %8405, 16" -> "  %8434 = add i32 %8433, %8406"
"  %8407 = and i32 %8368, 65535"
"  %8407 = and i32 %8368, 65535" -> "  %8409 = add nuw nsw i32 %8408, %8407"
"  %8408 = and i32 %8340, 65535"
"  %8408 = and i32 %8340, 65535" -> "  %8409 = add nuw nsw i32 %8408, %8407"
"  %8409 = add nuw nsw i32 %8408, %8407"
"  %8409 = add nuw nsw i32 %8408, %8407" -> "  %8453 = and i32 %8409, 65535""  %8409 = add nuw nsw i32 %8408, %8407" -> "  %8413 = lshr i32 %8409, 16"
"  %8410 = and i32 %8379, 65535"
"  %8410 = and i32 %8379, 65535" -> "  %8412 = add nuw nsw i32 %8411, %8410"
"  %8411 = and i32 %8346, 65535"
"  %8411 = and i32 %8346, 65535" -> "  %8412 = add nuw nsw i32 %8411, %8410"
"  %8412 = add nuw nsw i32 %8411, %8410"
"  %8412 = add nuw nsw i32 %8411, %8410" -> "  %8416 = lshr i32 %8412, 16""  %8412 = add nuw nsw i32 %8411, %8410" -> "  %8414 = and i32 %8412, 65535"
"  %8413 = lshr i32 %8409, 16"
"  %8413 = lshr i32 %8409, 16" -> "  %8415 = add nuw nsw i32 %8414, %8413"
"  %8414 = and i32 %8412, 65535"
"  %8414 = and i32 %8412, 65535" -> "  %8415 = add nuw nsw i32 %8414, %8413"
"  %8415 = add nuw nsw i32 %8414, %8413"
"  %8415 = add nuw nsw i32 %8414, %8413" -> "  %8456 = and i32 %8415, 65535""  %8415 = add nuw nsw i32 %8414, %8413" -> "  %8417 = lshr i32 %8415, 16"
"  %8416 = lshr i32 %8412, 16"
"  %8416 = lshr i32 %8412, 16" -> "  %8424 = add nuw nsw i32 %8417, %8416"
"  %8417 = lshr i32 %8415, 16"
"  %8417 = lshr i32 %8415, 16" -> "  %8424 = add nuw nsw i32 %8417, %8416"
"  %8418 = and i32 %8405, 65535"
"  %8418 = and i32 %8405, 65535" -> "  %8420 = add nuw nsw i32 %8419, %8418"
"  %8419 = and i32 %8355, 65535"
"  %8419 = and i32 %8355, 65535" -> "  %8420 = add nuw nsw i32 %8419, %8418"
"  %8420 = add nuw nsw i32 %8419, %8418"
"  %8420 = add nuw nsw i32 %8419, %8418" -> "  %8423 = and i32 %8420, 65535""  %8420 = add nuw nsw i32 %8419, %8418" -> "  %8422 = lshr i32 %8420, 16"
"  %8421 = and i32 %8367, 65535"
"  %8421 = and i32 %8367, 65535" -> "  %8435 = add i32 %8434, %8421"
"  %8422 = lshr i32 %8420, 16"
"  %8422 = lshr i32 %8420, 16" -> "  %8436 = add i32 %8435, %8422"
"  %8423 = and i32 %8420, 65535"
"  %8423 = and i32 %8420, 65535" -> "  %8425 = add nuw nsw i32 %8424, %8423"
"  %8424 = add nuw nsw i32 %8417, %8416"
"  %8424 = add nuw nsw i32 %8417, %8416" -> "  %8425 = add nuw nsw i32 %8424, %8423"
"  %8425 = add nuw nsw i32 %8424, %8423"
"  %8425 = add nuw nsw i32 %8424, %8423" -> "  %8460 = and i32 %8425, 65535""  %8425 = add nuw nsw i32 %8424, %8423" -> "  %8426 = lshr i32 %8425, 16"
"  %8426 = lshr i32 %8425, 16"
"  %8426 = lshr i32 %8425, 16" -> "  %8437 = add i32 %8436, %8426"
"  %8427 = add i32 %8389, %8390"
"  %8427 = add i32 %8389, %8390" -> "  %8428 = add i32 %8427, %8391"
"  %8428 = add i32 %8427, %8391"
"  %8428 = add i32 %8427, %8391" -> "  %8429 = add i32 %8428, %8397"
"  %8429 = add i32 %8428, %8397"
"  %8429 = add i32 %8428, %8397" -> "  %8430 = add i32 %8429, %8398"
"  %8430 = add i32 %8429, %8398"
"  %8430 = add i32 %8429, %8398" -> "  %8431 = add i32 %8430, %8400"
"  %8431 = add i32 %8430, %8400"
"  %8431 = add i32 %8430, %8400" -> "  %8432 = add i32 %8431, %8401"
"  %8432 = add i32 %8431, %8401"
"  %8432 = add i32 %8431, %8401" -> "  %8433 = add i32 %8432, %8402"
"  %8433 = add i32 %8432, %8402"
"  %8433 = add i32 %8432, %8402" -> "  %8434 = add i32 %8433, %8406"
"  %8434 = add i32 %8433, %8406"
"  %8434 = add i32 %8433, %8406" -> "  %8435 = add i32 %8434, %8421"
"  %8435 = add i32 %8434, %8421"
"  %8435 = add i32 %8434, %8421" -> "  %8436 = add i32 %8435, %8422"
"  %8436 = add i32 %8435, %8422"
"  %8436 = add i32 %8435, %8422" -> "  %8437 = add i32 %8436, %8426"
"  %8437 = add i32 %8436, %8426"
"  %8437 = add i32 %8436, %8426" -> "  %8503 = xor i32 %8437, 65535"
"  %8438 = and i32 %8181, 65535"
"  %8438 = and i32 %8181, 65535" -> "  %8439 = sub nuw nsw i32 65536, %8438"
"  %8439 = sub nuw nsw i32 65536, %8438"
"  %8439 = sub nuw nsw i32 65536, %8438" -> "  %8464 = and i32 %8439, 65535""  %8439 = sub nuw nsw i32 65536, %8438" -> "  %8442 = lshr i32 %8439, 16"
"  %8440 = and i32 %8190, 65535"
"  %8440 = and i32 %8190, 65535" -> "  %8441 = xor i32 %8440, 65535"
"  %8441 = xor i32 %8440, 65535"
"  %8441 = xor i32 %8440, 65535" -> "  %8443 = add nuw nsw i32 %8441, %8442"
"  %8442 = lshr i32 %8439, 16"
"  %8442 = lshr i32 %8439, 16" -> "  %8443 = add nuw nsw i32 %8441, %8442"
"  %8443 = add nuw nsw i32 %8441, %8442"
"  %8443 = add nuw nsw i32 %8441, %8442" -> "  %8466 = and i32 %8443, 65535""  %8443 = add nuw nsw i32 %8441, %8442" -> "  %8446 = lshr i32 %8443, 16"
"  %8444 = and i32 %8247, 65535"
"  %8444 = and i32 %8247, 65535" -> "  %8445 = xor i32 %8444, 65535"
"  %8445 = xor i32 %8444, 65535"
"  %8445 = xor i32 %8444, 65535" -> "  %8447 = add nuw nsw i32 %8445, %8446"
"  %8446 = lshr i32 %8443, 16"
"  %8446 = lshr i32 %8443, 16" -> "  %8447 = add nuw nsw i32 %8445, %8446"
"  %8447 = add nuw nsw i32 %8445, %8446"
"  %8447 = add nuw nsw i32 %8445, %8446" -> "  %8474 = and i32 %8447, 65535""  %8447 = add nuw nsw i32 %8445, %8446" -> "  %8450 = lshr i32 %8447, 16"
"  %8448 = and i32 %8255, 65535"
"  %8448 = and i32 %8255, 65535" -> "  %8449 = xor i32 %8448, 65535"
"  %8449 = xor i32 %8448, 65535"
"  %8449 = xor i32 %8448, 65535" -> "  %8451 = add nuw nsw i32 %8449, %8450"
"  %8450 = lshr i32 %8447, 16"
"  %8450 = lshr i32 %8447, 16" -> "  %8451 = add nuw nsw i32 %8449, %8450"
"  %8451 = add nuw nsw i32 %8449, %8450"
"  %8451 = add nuw nsw i32 %8449, %8450" -> "  %8476 = and i32 %8451, 65535""  %8451 = add nuw nsw i32 %8449, %8450" -> "  %8452 = lshr i32 %8451, 16"
"  %8452 = lshr i32 %8451, 16"
"  %8452 = lshr i32 %8451, 16" -> "  %8455 = add nuw nsw i32 %8454, %8452"
"  %8453 = and i32 %8409, 65535"
"  %8453 = and i32 %8409, 65535" -> "  %8454 = xor i32 %8453, 65535"
"  %8454 = xor i32 %8453, 65535"
"  %8454 = xor i32 %8453, 65535" -> "  %8455 = add nuw nsw i32 %8454, %8452"
"  %8455 = add nuw nsw i32 %8454, %8452"
"  %8455 = add nuw nsw i32 %8454, %8452" -> "  %8491 = and i32 %8455, 65535""  %8455 = add nuw nsw i32 %8454, %8452" -> "  %8458 = lshr i32 %8455, 16"
"  %8456 = and i32 %8415, 65535"
"  %8456 = and i32 %8415, 65535" -> "  %8457 = xor i32 %8456, 65535"
"  %8457 = xor i32 %8456, 65535"
"  %8457 = xor i32 %8456, 65535" -> "  %8459 = add nuw nsw i32 %8457, %8458"
"  %8458 = lshr i32 %8455, 16"
"  %8458 = lshr i32 %8455, 16" -> "  %8459 = add nuw nsw i32 %8457, %8458"
"  %8459 = add nuw nsw i32 %8457, %8458"
"  %8459 = add nuw nsw i32 %8457, %8458" -> "  %8493 = and i32 %8459, 65535""  %8459 = add nuw nsw i32 %8457, %8458" -> "  %8462 = lshr i32 %8459, 16"
"  %8460 = and i32 %8425, 65535"
"  %8460 = and i32 %8425, 65535" -> "  %8461 = xor i32 %8460, 65535"
"  %8461 = xor i32 %8460, 65535"
"  %8461 = xor i32 %8460, 65535" -> "  %8463 = add nuw nsw i32 %8461, %8462"
"  %8462 = lshr i32 %8459, 16"
"  %8462 = lshr i32 %8459, 16" -> "  %8463 = add nuw nsw i32 %8461, %8462"
"  %8463 = add nuw nsw i32 %8461, %8462"
"  %8463 = add nuw nsw i32 %8461, %8462" -> "  %8516 = add i32 %8515, %8463""  %8463 = add nuw nsw i32 %8461, %8462" -> "  %8501 = and i32 %8463, 65535"
"  %8464 = and i32 %8439, 65535"
"  %8464 = and i32 %8439, 65535" -> "  %8465 = add nuw nsw i32 %8464, %5131"
"  %8465 = add nuw nsw i32 %8464, %5131"
"  %8465 = add nuw nsw i32 %8464, %5131" -> "  %8523 = and i32 %8465, 65535""  %8465 = add nuw nsw i32 %8464, %5131" -> "  %8468 = lshr i32 %8465, 16"
"  %8466 = and i32 %8443, 65535"
"  %8466 = and i32 %8443, 65535" -> "  %8467 = add nuw nsw i32 %8466, %5134"
"  %8467 = add nuw nsw i32 %8466, %5134"
"  %8467 = add nuw nsw i32 %8466, %5134" -> "  %8471 = lshr i32 %8467, 16""  %8467 = add nuw nsw i32 %8466, %5134" -> "  %8469 = and i32 %8467, 65535"
"  %8468 = lshr i32 %8465, 16"
"  %8468 = lshr i32 %8465, 16" -> "  %8470 = add nuw nsw i32 %8469, %8468"
"  %8469 = and i32 %8467, 65535"
"  %8469 = and i32 %8467, 65535" -> "  %8470 = add nuw nsw i32 %8469, %8468"
"  %8470 = add nuw nsw i32 %8469, %8468"
"  %8470 = add nuw nsw i32 %8469, %8468" -> "  %8524 = and i32 %8470, 65535""  %8470 = add nuw nsw i32 %8469, %8468" -> "  %8472 = lshr i32 %8470, 16"
"  %8471 = lshr i32 %8467, 16"
"  %8471 = lshr i32 %8467, 16" -> "  %8473 = add nuw nsw i32 %8472, %8471"
"  %8472 = lshr i32 %8470, 16"
"  %8472 = lshr i32 %8470, 16" -> "  %8473 = add nuw nsw i32 %8472, %8471"
"  %8473 = add nuw nsw i32 %8472, %8471"
"  %8473 = add nuw nsw i32 %8472, %8471" -> "  %8485 = add nuw nsw i32 %8473, %8484"
"  %8474 = and i32 %8447, 65535"
"  %8474 = and i32 %8447, 65535" -> "  %8475 = add nuw nsw i32 %8474, %5151"
"  %8475 = add nuw nsw i32 %8474, %5151"
"  %8475 = add nuw nsw i32 %8474, %5151" -> "  %8484 = and i32 %8475, 65535""  %8475 = add nuw nsw i32 %8474, %5151" -> "  %8478 = lshr i32 %8475, 16"
"  %8476 = and i32 %8451, 65535"
"  %8476 = and i32 %8451, 65535" -> "  %8477 = add nuw nsw i32 %8476, %5152"
"  %8477 = add nuw nsw i32 %8476, %5152"
"  %8477 = add nuw nsw i32 %8476, %5152" -> "  %8481 = lshr i32 %8477, 16""  %8477 = add nuw nsw i32 %8476, %5152" -> "  %8479 = and i32 %8477, 65535"
"  %8478 = lshr i32 %8475, 16"
"  %8478 = lshr i32 %8475, 16" -> "  %8480 = add nuw nsw i32 %8479, %8478"
"  %8479 = and i32 %8477, 65535"
"  %8479 = and i32 %8477, 65535" -> "  %8480 = add nuw nsw i32 %8479, %8478"
"  %8480 = add nuw nsw i32 %8479, %8478"
"  %8480 = add nuw nsw i32 %8479, %8478" -> "  %8486 = and i32 %8480, 65535""  %8480 = add nuw nsw i32 %8479, %8478" -> "  %8482 = lshr i32 %8480, 16"
"  %8481 = lshr i32 %8477, 16"
"  %8481 = lshr i32 %8477, 16" -> "  %8483 = add nuw nsw i32 %8482, %8481"
"  %8482 = lshr i32 %8480, 16"
"  %8482 = lshr i32 %8480, 16" -> "  %8483 = add nuw nsw i32 %8482, %8481"
"  %8483 = add nuw nsw i32 %8482, %8481"
"  %8483 = add nuw nsw i32 %8482, %8481" -> "  %8490 = add nuw nsw i32 %8483, %8489"
"  %8484 = and i32 %8475, 65535"
"  %8484 = and i32 %8475, 65535" -> "  %8485 = add nuw nsw i32 %8473, %8484"
"  %8485 = add nuw nsw i32 %8473, %8484"
"  %8485 = add nuw nsw i32 %8473, %8484" -> "  %8542 = and i32 %8485, 65535""  %8485 = add nuw nsw i32 %8473, %8484" -> "  %8487 = lshr i32 %8485, 16"
"  %8486 = and i32 %8480, 65535"
"  %8486 = and i32 %8480, 65535" -> "  %8488 = add nuw nsw i32 %8486, %8487"
"  %8487 = lshr i32 %8485, 16"
"  %8487 = lshr i32 %8485, 16" -> "  %8488 = add nuw nsw i32 %8486, %8487"
"  %8488 = add nuw nsw i32 %8486, %8487"
"  %8488 = add nuw nsw i32 %8486, %8487" -> "  %8543 = and i32 %8488, 65535""  %8488 = add nuw nsw i32 %8486, %8487" -> "  %8489 = lshr i32 %8488, 16"
"  %8489 = lshr i32 %8488, 16"
"  %8489 = lshr i32 %8488, 16" -> "  %8490 = add nuw nsw i32 %8483, %8489"
"  %8490 = add nuw nsw i32 %8483, %8489"
"  %8490 = add nuw nsw i32 %8483, %8489" -> "  %8508 = add nuw nsw i32 %8490, %8507"
"  %8491 = and i32 %8455, 65535"
"  %8491 = and i32 %8455, 65535" -> "  %8492 = add nuw nsw i32 %8491, %5262"
"  %8492 = add nuw nsw i32 %8491, %5262"
"  %8492 = add nuw nsw i32 %8491, %5262" -> "  %8507 = and i32 %8492, 65535""  %8492 = add nuw nsw i32 %8491, %5262" -> "  %8495 = lshr i32 %8492, 16"
"  %8493 = and i32 %8459, 65535"
"  %8493 = and i32 %8459, 65535" -> "  %8494 = add nuw nsw i32 %8493, %5265"
"  %8494 = add nuw nsw i32 %8493, %5265"
"  %8494 = add nuw nsw i32 %8493, %5265" -> "  %8498 = lshr i32 %8494, 16""  %8494 = add nuw nsw i32 %8493, %5265" -> "  %8496 = and i32 %8494, 65535"
"  %8495 = lshr i32 %8492, 16"
"  %8495 = lshr i32 %8492, 16" -> "  %8497 = add nuw nsw i32 %8496, %8495"
"  %8496 = and i32 %8494, 65535"
"  %8496 = and i32 %8494, 65535" -> "  %8497 = add nuw nsw i32 %8496, %8495"
"  %8497 = add nuw nsw i32 %8496, %8495"
"  %8497 = add nuw nsw i32 %8496, %8495" -> "  %8509 = and i32 %8497, 65535""  %8497 = add nuw nsw i32 %8496, %8495" -> "  %8499 = lshr i32 %8497, 16"
"  %8498 = lshr i32 %8494, 16"
"  %8498 = lshr i32 %8494, 16" -> "  %8500 = add nuw nsw i32 %8499, %8498"
"  %8499 = lshr i32 %8497, 16"
"  %8499 = lshr i32 %8497, 16" -> "  %8500 = add nuw nsw i32 %8499, %8498"
"  %8500 = add nuw nsw i32 %8499, %8498"
"  %8500 = add nuw nsw i32 %8499, %8498" -> "  %8506 = add nuw nsw i32 %8500, %8505"
"  %8501 = and i32 %8463, 65535"
"  %8501 = and i32 %8463, 65535" -> "  %8502 = add nuw nsw i32 %8501, %5282"
"  %8502 = add nuw nsw i32 %8501, %5282"
"  %8502 = add nuw nsw i32 %8501, %5282" -> "  %8518 = add i32 %8517, %8502""  %8502 = add nuw nsw i32 %8501, %5282" -> "  %8505 = and i32 %8502, 65535"
"  %8503 = xor i32 %8437, 65535"
"  %8503 = xor i32 %8437, 65535" -> "  %8504 = add i32 %8503, %4929"
"  %8504 = add i32 %8503, %4929"
"  %8504 = add i32 %8503, %4929" -> "  %8515 = shl i32 %8504, 16"
"  %8505 = and i32 %8502, 65535"
"  %8505 = and i32 %8502, 65535" -> "  %8506 = add nuw nsw i32 %8500, %8505"
"  %8506 = add nuw nsw i32 %8500, %8505"
"  %8506 = add nuw nsw i32 %8500, %8505" -> "  %8520 = add i32 %8519, %8506""  %8506 = add nuw nsw i32 %8500, %8505" -> "  %8513 = and i32 %8506, 65535"
"  %8507 = and i32 %8492, 65535"
"  %8507 = and i32 %8492, 65535" -> "  %8508 = add nuw nsw i32 %8490, %8507"
"  %8508 = add nuw nsw i32 %8490, %8507"
"  %8508 = add nuw nsw i32 %8490, %8507" -> "  %8649 = and i32 %8508, 65535""  %8508 = add nuw nsw i32 %8490, %8507" -> "  %8510 = lshr i32 %8508, 16"
"  %8509 = and i32 %8497, 65535"
"  %8509 = and i32 %8497, 65535" -> "  %8511 = add nuw nsw i32 %8509, %8510"
"  %8510 = lshr i32 %8508, 16"
"  %8510 = lshr i32 %8508, 16" -> "  %8511 = add nuw nsw i32 %8509, %8510"
"  %8511 = add nuw nsw i32 %8509, %8510"
"  %8511 = add nuw nsw i32 %8509, %8510" -> "  %8652 = and i32 %8511, 65535""  %8511 = add nuw nsw i32 %8509, %8510" -> "  %8512 = lshr i32 %8511, 16"
"  %8512 = lshr i32 %8511, 16"
"  %8512 = lshr i32 %8511, 16" -> "  %8514 = add nuw nsw i32 %8513, %8512"
"  %8513 = and i32 %8506, 65535"
"  %8513 = and i32 %8506, 65535" -> "  %8514 = add nuw nsw i32 %8513, %8512"
"  %8514 = add nuw nsw i32 %8513, %8512"
"  %8514 = add nuw nsw i32 %8513, %8512" -> "  %8522 = add i32 %8514, %8521"
"  %8515 = shl i32 %8504, 16"
"  %8515 = shl i32 %8504, 16" -> "  %8516 = add i32 %8515, %8463"
"  %8516 = add i32 %8515, %8463"
"  %8516 = add i32 %8515, %8463" -> "  %8517 = and i32 %8516, -65536"
"  %8517 = and i32 %8516, -65536"
"  %8517 = and i32 %8516, -65536" -> "  %8518 = add i32 %8517, %8502"
"  %8518 = add i32 %8517, %8502"
"  %8518 = add i32 %8517, %8502" -> "  %8519 = and i32 %8518, -65536"
"  %8519 = and i32 %8518, -65536"
"  %8519 = and i32 %8518, -65536" -> "  %8520 = add i32 %8519, %8506"
"  %8520 = add i32 %8519, %8506"
"  %8520 = add i32 %8519, %8506" -> "  %8521 = and i32 %8520, -65536"
"  %8521 = and i32 %8520, -65536"
"  %8521 = and i32 %8520, -65536" -> "  %8522 = add i32 %8514, %8521"
"  %8522 = add i32 %8514, %8521"
"  %8522 = add i32 %8514, %8521" -> "  %8675 = and i32 %8522, 65535""  %8522 = add i32 %8514, %8521" -> "  %8678 = lshr i32 %8522, 16"
"  %8523 = and i32 %8465, 65535"
"  %8523 = and i32 %8465, 65535" -> "  %8679 = mul nuw i32 %8678, %8523""  %8523 = and i32 %8465, 65535" -> "  %8676 = mul nuw i32 %8675, %8523""  %8523 = and i32 %8465, 65535" -> "  %8653 = mul nuw i32 %8652, %8523""  %8523 = and i32 %8465, 65535" -> "  %8650 = mul nuw i32 %8649, %8523""  %8523 = and i32 %8465, 65535" -> "  %8546 = mul nuw i32 %8543, %8523""  %8523 = and i32 %8465, 65535" -> "  %8544 = mul nuw i32 %8542, %8523""  %8523 = and i32 %8465, 65535" -> "  %8527 = mul nuw i32 %8524, %8523""  %8523 = and i32 %8465, 65535" -> "  %8525 = mul nuw i32 %8523, %8523""  %8523 = and i32 %8465, 65535" -> "  %8525 = mul nuw i32 %8523, %8523"
"  %8524 = and i32 %8470, 65535"
"  %8524 = and i32 %8470, 65535" -> "  %8692 = mul nuw i32 %8678, %8524""  %8524 = and i32 %8470, 65535" -> "  %8680 = mul nuw i32 %8675, %8524""  %8524 = and i32 %8470, 65535" -> "  %8669 = mul nuw i32 %8652, %8524""  %8524 = and i32 %8470, 65535" -> "  %8656 = mul nuw i32 %8649, %8524""  %8524 = and i32 %8470, 65535" -> "  %8562 = mul nuw i32 %8543, %8524""  %8524 = and i32 %8470, 65535" -> "  %8549 = mul nuw i32 %8542, %8524""  %8524 = and i32 %8470, 65535" -> "  %8527 = mul nuw i32 %8524, %8523""  %8524 = and i32 %8470, 65535" -> "  %8535 = mul nuw i32 %8524, %8524""  %8524 = and i32 %8470, 65535" -> "  %8535 = mul nuw i32 %8524, %8524"
"  %8525 = mul nuw i32 %8523, %8523"
"  %8525 = mul nuw i32 %8523, %8523" -> "  %9136 = and i32 %8525, 65535""  %8525 = mul nuw i32 %8523, %8523" -> "  %8526 = lshr i32 %8525, 16"
"  %8526 = lshr i32 %8525, 16"
"  %8526 = lshr i32 %8525, 16" -> "  %8529 = add nuw nsw i32 %8528, %8526"
"  %8527 = mul nuw i32 %8524, %8523"
"  %8527 = mul nuw i32 %8524, %8523" -> "  %8533 = add nuw i32 %8532, %8527""  %8527 = mul nuw i32 %8524, %8523" -> "  %8530 = and i32 %8527, -65536""  %8527 = mul nuw i32 %8524, %8523" -> "  %8528 = and i32 %8527, 65535"
"  %8528 = and i32 %8527, 65535"
"  %8528 = and i32 %8527, 65535" -> "  %8529 = add nuw nsw i32 %8528, %8526"
"  %8529 = add nuw nsw i32 %8528, %8526"
"  %8529 = add nuw nsw i32 %8528, %8526" -> "  %8531 = add nuw i32 %8529, %8530"
"  %8530 = and i32 %8527, -65536"
"  %8530 = and i32 %8527, -65536" -> "  %8531 = add nuw i32 %8529, %8530"
"  %8531 = add nuw i32 %8529, %8530"
"  %8531 = add nuw i32 %8529, %8530" -> "  %8534 = lshr i32 %8531, 16""  %8531 = add nuw i32 %8529, %8530" -> "  %8532 = and i32 %8531, 65535"
"  %8532 = and i32 %8531, 65535"
"  %8532 = and i32 %8531, 65535" -> "  %8533 = add nuw i32 %8532, %8527"
"  %8533 = add nuw i32 %8532, %8527"
"  %8533 = add nuw i32 %8532, %8527" -> "  %9137 = and i32 %8533, 65535""  %8533 = add nuw i32 %8532, %8527" -> "  %8537 = lshr i32 %8533, 16"
"  %8534 = lshr i32 %8531, 16"
"  %8534 = lshr i32 %8531, 16" -> "  %8536 = add nuw i32 %8534, %8535"
"  %8535 = mul nuw i32 %8524, %8524"
"  %8535 = mul nuw i32 %8524, %8524" -> "  %8536 = add nuw i32 %8534, %8535"
"  %8536 = add nuw i32 %8534, %8535"
"  %8536 = add nuw i32 %8534, %8535" -> "  %8540 = and i32 %8536, -65536""  %8536 = add nuw i32 %8534, %8535" -> "  %8538 = and i32 %8536, 65535"
"  %8537 = lshr i32 %8533, 16"
"  %8537 = lshr i32 %8533, 16" -> "  %8539 = add nuw nsw i32 %8537, %8538"
"  %8538 = and i32 %8536, 65535"
"  %8538 = and i32 %8536, 65535" -> "  %8539 = add nuw nsw i32 %8537, %8538"
"  %8539 = add nuw nsw i32 %8537, %8538"
"  %8539 = add nuw nsw i32 %8537, %8538" -> "  %8541 = add i32 %8539, %8540"
"  %8540 = and i32 %8536, -65536"
"  %8540 = and i32 %8536, -65536" -> "  %8541 = add i32 %8539, %8540"
"  %8541 = add i32 %8539, %8540"
"  %8541 = add i32 %8539, %8540" -> "  %8571 = and i32 %8541, 65535""  %8541 = add i32 %8539, %8540" -> "  %8569 = lshr i32 %8541, 16"
"  %8542 = and i32 %8485, 65535"
"  %8542 = and i32 %8485, 65535" -> "  %8747 = mul nuw i32 %8678, %8542""  %8542 = and i32 %8485, 65535" -> "  %8745 = mul nuw i32 %8675, %8542""  %8542 = and i32 %8485, 65535" -> "  %8713 = mul nuw i32 %8652, %8542""  %8542 = and i32 %8485, 65535" -> "  %8711 = mul nuw i32 %8649, %8542""  %8542 = and i32 %8485, 65535" -> "  %8605 = mul nuw i32 %8543, %8542""  %8542 = and i32 %8485, 65535" -> "  %8549 = mul nuw i32 %8542, %8524""  %8542 = and i32 %8485, 65535" -> "  %8544 = mul nuw i32 %8542, %8523""  %8542 = and i32 %8485, 65535" -> "  %8603 = mul nuw i32 %8542, %8542""  %8542 = and i32 %8485, 65535" -> "  %8603 = mul nuw i32 %8542, %8542"
"  %8543 = and i32 %8488, 65535"
"  %8543 = and i32 %8488, 65535" -> "  %8757 = mul nuw i32 %8678, %8543""  %8543 = and i32 %8488, 65535" -> "  %8748 = mul nuw i32 %8675, %8543""  %8543 = and i32 %8488, 65535" -> "  %8726 = mul nuw i32 %8652, %8543""  %8543 = and i32 %8488, 65535" -> "  %8716 = mul nuw i32 %8649, %8543""  %8543 = and i32 %8488, 65535" -> "  %8605 = mul nuw i32 %8543, %8542""  %8543 = and i32 %8488, 65535" -> "  %8562 = mul nuw i32 %8543, %8524""  %8543 = and i32 %8488, 65535" -> "  %8546 = mul nuw i32 %8543, %8523""  %8543 = and i32 %8488, 65535" -> "  %8613 = mul nuw i32 %8543, %8543""  %8543 = and i32 %8488, 65535" -> "  %8613 = mul nuw i32 %8543, %8543"
"  %8544 = mul nuw i32 %8542, %8523"
"  %8544 = mul nuw i32 %8542, %8523" -> "  %8572 = and i32 %8544, 65535""  %8544 = mul nuw i32 %8542, %8523" -> "  %8545 = lshr i32 %8544, 16"
"  %8545 = lshr i32 %8544, 16"
"  %8545 = lshr i32 %8544, 16" -> "  %8548 = add nuw nsw i32 %8547, %8545""  %8545 = lshr i32 %8544, 16" -> "  %8551 = add nuw nsw i32 %8550, %8545"
"  %8546 = mul nuw i32 %8543, %8523"
"  %8546 = mul nuw i32 %8543, %8523" -> "  %8555 = add nuw i32 %8546, %8554""  %8546 = mul nuw i32 %8543, %8523" -> "  %8556 = and i32 %8546, -65536""  %8546 = mul nuw i32 %8543, %8523" -> "  %8547 = and i32 %8546, 65535"
"  %8547 = and i32 %8546, 65535"
"  %8547 = and i32 %8546, 65535" -> "  %8548 = add nuw nsw i32 %8547, %8545"
"  %8548 = add nuw nsw i32 %8547, %8545"
"  %8548 = add nuw nsw i32 %8547, %8545" -> "  %8557 = add nuw i32 %8548, %8556"
"  %8549 = mul nuw i32 %8542, %8524"
"  %8549 = mul nuw i32 %8542, %8524" -> "  %8559 = add nuw i32 %8558, %8549""  %8549 = mul nuw i32 %8542, %8524" -> "  %8552 = and i32 %8549, -65536""  %8549 = mul nuw i32 %8542, %8524" -> "  %8550 = and i32 %8549, 65535"
"  %8550 = and i32 %8549, 65535"
"  %8550 = and i32 %8549, 65535" -> "  %8551 = add nuw nsw i32 %8550, %8545"
"  %8551 = add nuw nsw i32 %8550, %8545"
"  %8551 = add nuw nsw i32 %8550, %8545" -> "  %8553 = add nuw i32 %8551, %8552"
"  %8552 = and i32 %8549, -65536"
"  %8552 = and i32 %8549, -65536" -> "  %8553 = add nuw i32 %8551, %8552"
"  %8553 = add nuw i32 %8551, %8552"
"  %8553 = add nuw i32 %8551, %8552" -> "  %8584 = lshr i32 %8553, 16""  %8553 = add nuw i32 %8551, %8552" -> "  %8554 = and i32 %8553, 65535"
"  %8554 = and i32 %8553, 65535"
"  %8554 = and i32 %8553, 65535" -> "  %8555 = add nuw i32 %8546, %8554"
"  %8555 = add nuw i32 %8546, %8554"
"  %8555 = add nuw i32 %8546, %8554" -> "  %8594 = and i32 %8555, 65535""  %8555 = add nuw i32 %8546, %8554" -> "  %8586 = lshr i32 %8555, 16"
"  %8556 = and i32 %8546, -65536"
"  %8556 = and i32 %8546, -65536" -> "  %8557 = add nuw i32 %8548, %8556"
"  %8557 = add nuw i32 %8548, %8556"
"  %8557 = add nuw i32 %8548, %8556" -> "  %8560 = lshr i32 %8557, 16""  %8557 = add nuw i32 %8548, %8556" -> "  %8558 = and i32 %8557, 65535"
"  %8558 = and i32 %8557, 65535"
"  %8558 = and i32 %8557, 65535" -> "  %8559 = add nuw i32 %8558, %8549"
"  %8559 = add nuw i32 %8558, %8549"
"  %8559 = add nuw i32 %8558, %8549" -> "  %8568 = and i32 %8559, 65535""  %8559 = add nuw i32 %8558, %8549" -> "  %8561 = lshr i32 %8559, 16"
"  %8560 = lshr i32 %8557, 16"
"  %8560 = lshr i32 %8557, 16" -> "  %8563 = add nuw i32 %8560, %8562"
"  %8561 = lshr i32 %8559, 16"
"  %8561 = lshr i32 %8559, 16" -> "  %8565 = add nuw nsw i32 %8564, %8561"
"  %8562 = mul nuw i32 %8543, %8524"
"  %8562 = mul nuw i32 %8543, %8524" -> "  %8585 = add nuw i32 %8562, %8584""  %8562 = mul nuw i32 %8543, %8524" -> "  %8563 = add nuw i32 %8560, %8562"
"  %8563 = add nuw i32 %8560, %8562"
"  %8563 = add nuw i32 %8560, %8562" -> "  %8566 = and i32 %8563, -65536""  %8563 = add nuw i32 %8560, %8562" -> "  %8564 = and i32 %8563, 65535"
"  %8564 = and i32 %8563, 65535"
"  %8564 = and i32 %8563, 65535" -> "  %8565 = add nuw nsw i32 %8564, %8561"
"  %8565 = add nuw nsw i32 %8564, %8561"
"  %8565 = add nuw nsw i32 %8564, %8561" -> "  %8567 = add i32 %8565, %8566"
"  %8566 = and i32 %8563, -65536"
"  %8566 = and i32 %8563, -65536" -> "  %8567 = add i32 %8565, %8566"
"  %8567 = add i32 %8565, %8566"
"  %8567 = add i32 %8565, %8566" -> "  %8580 = and i32 %8567, -65536""  %8567 = add i32 %8565, %8566" -> "  %8578 = and i32 %8567, 65535"
"  %8568 = and i32 %8559, 65535"
"  %8568 = and i32 %8559, 65535" -> "  %8570 = add nuw nsw i32 %8568, %8569"
"  %8569 = lshr i32 %8541, 16"
"  %8569 = lshr i32 %8541, 16" -> "  %8570 = add nuw nsw i32 %8568, %8569"
"  %8570 = add nuw nsw i32 %8568, %8569"
"  %8570 = add nuw nsw i32 %8568, %8569" -> "  %8577 = lshr i32 %8570, 16""  %8570 = add nuw nsw i32 %8568, %8569" -> "  %8575 = and i32 %8570, 65535"
"  %8571 = and i32 %8541, 65535"
"  %8571 = and i32 %8541, 65535" -> "  %8573 = add nuw nsw i32 %8571, %8572"
"  %8572 = and i32 %8544, 65535"
"  %8572 = and i32 %8544, 65535" -> "  %8592 = add nuw nsw i32 %8591, %8572""  %8572 = and i32 %8544, 65535" -> "  %8573 = add nuw nsw i32 %8571, %8572"
"  %8573 = add nuw nsw i32 %8571, %8572"
"  %8573 = add nuw nsw i32 %8571, %8572" -> "  %8591 = and i32 %8573, 65535""  %8573 = add nuw nsw i32 %8571, %8572" -> "  %8574 = lshr i32 %8573, 16"
"  %8574 = lshr i32 %8573, 16"
"  %8574 = lshr i32 %8573, 16" -> "  %8576 = add nuw nsw i32 %8575, %8574"
"  %8575 = and i32 %8570, 65535"
"  %8575 = and i32 %8570, 65535" -> "  %8576 = add nuw nsw i32 %8575, %8574"
"  %8576 = add nuw nsw i32 %8575, %8574"
"  %8576 = add nuw nsw i32 %8575, %8574" -> "  %8593 = and i32 %8576, 65535""  %8576 = add nuw nsw i32 %8575, %8574" -> "  %8582 = lshr i32 %8576, 16"
"  %8577 = lshr i32 %8570, 16"
"  %8577 = lshr i32 %8570, 16" -> "  %8579 = add nuw nsw i32 %8578, %8577"
"  %8578 = and i32 %8567, 65535"
"  %8578 = and i32 %8567, 65535" -> "  %8579 = add nuw nsw i32 %8578, %8577"
"  %8579 = add nuw nsw i32 %8578, %8577"
"  %8579 = add nuw nsw i32 %8578, %8577" -> "  %8581 = add i32 %8579, %8580"
"  %8580 = and i32 %8567, -65536"
"  %8580 = and i32 %8567, -65536" -> "  %8581 = add i32 %8579, %8580"
"  %8581 = add i32 %8579, %8580"
"  %8581 = add i32 %8579, %8580" -> "  %8583 = add i32 %8581, %8582"
"  %8582 = lshr i32 %8576, 16"
"  %8582 = lshr i32 %8576, 16" -> "  %8583 = add i32 %8581, %8582"
"  %8583 = add i32 %8581, %8582"
"  %8583 = add i32 %8581, %8582" -> "  %8624 = lshr i32 %8583, 16""  %8583 = add i32 %8581, %8582" -> "  %8620 = and i32 %8583, 65535"
"  %8584 = lshr i32 %8553, 16"
"  %8584 = lshr i32 %8553, 16" -> "  %8585 = add nuw i32 %8562, %8584"
"  %8585 = add nuw i32 %8562, %8584"
"  %8585 = add nuw i32 %8562, %8584" -> "  %8589 = and i32 %8585, -65536""  %8585 = add nuw i32 %8562, %8584" -> "  %8587 = and i32 %8585, 65535"
"  %8586 = lshr i32 %8555, 16"
"  %8586 = lshr i32 %8555, 16" -> "  %8588 = add nuw nsw i32 %8587, %8586"
"  %8587 = and i32 %8585, 65535"
"  %8587 = and i32 %8585, 65535" -> "  %8588 = add nuw nsw i32 %8587, %8586"
"  %8588 = add nuw nsw i32 %8587, %8586"
"  %8588 = add nuw nsw i32 %8587, %8586" -> "  %8590 = add i32 %8588, %8589"
"  %8589 = and i32 %8585, -65536"
"  %8589 = and i32 %8585, -65536" -> "  %8590 = add i32 %8588, %8589"
"  %8590 = add i32 %8588, %8589"
"  %8590 = add i32 %8588, %8589" -> "  %8597 = add i32 %8590, %8596"
"  %8591 = and i32 %8573, 65535"
"  %8591 = and i32 %8573, 65535" -> "  %8592 = add nuw nsw i32 %8591, %8572"
"  %8592 = add nuw nsw i32 %8591, %8572"
"  %8592 = add nuw nsw i32 %8591, %8572" -> "  %9156 = and i32 %8592, 65535""  %8592 = add nuw nsw i32 %8591, %8572" -> "  %8599 = lshr i32 %8592, 16"
"  %8593 = and i32 %8576, 65535"
"  %8593 = and i32 %8576, 65535" -> "  %8595 = add nuw nsw i32 %8593, %8594"
"  %8594 = and i32 %8555, 65535"
"  %8594 = and i32 %8555, 65535" -> "  %8595 = add nuw nsw i32 %8593, %8594"
"  %8595 = add nuw nsw i32 %8593, %8594"
"  %8595 = add nuw nsw i32 %8593, %8594" -> "  %8598 = and i32 %8595, 65535""  %8595 = add nuw nsw i32 %8593, %8594" -> "  %8596 = lshr i32 %8595, 16"
"  %8596 = lshr i32 %8595, 16"
"  %8596 = lshr i32 %8595, 16" -> "  %8597 = add i32 %8590, %8596"
"  %8597 = add i32 %8590, %8596"
"  %8597 = add i32 %8590, %8596" -> "  %8602 = add i32 %8597, %8601"
"  %8598 = and i32 %8595, 65535"
"  %8598 = and i32 %8595, 65535" -> "  %8600 = add nuw nsw i32 %8598, %8599"
"  %8599 = lshr i32 %8592, 16"
"  %8599 = lshr i32 %8592, 16" -> "  %8600 = add nuw nsw i32 %8598, %8599"
"  %8600 = add nuw nsw i32 %8598, %8599"
"  %8600 = add nuw nsw i32 %8598, %8599" -> "  %9159 = and i32 %8600, 65535""  %8600 = add nuw nsw i32 %8598, %8599" -> "  %8601 = lshr i32 %8600, 16"
"  %8601 = lshr i32 %8600, 16"
"  %8601 = lshr i32 %8600, 16" -> "  %8602 = add i32 %8597, %8601"
"  %8602 = add i32 %8597, %8601"
"  %8602 = add i32 %8597, %8601" -> "  %8637 = lshr i32 %8602, 16""  %8602 = add i32 %8597, %8601" -> "  %8634 = and i32 %8602, 65535"
"  %8603 = mul nuw i32 %8542, %8542"
"  %8603 = mul nuw i32 %8542, %8542" -> "  %8621 = and i32 %8603, 65535""  %8603 = mul nuw i32 %8542, %8542" -> "  %8604 = lshr i32 %8603, 16"
"  %8604 = lshr i32 %8603, 16"
"  %8604 = lshr i32 %8603, 16" -> "  %8607 = add nuw nsw i32 %8606, %8604"
"  %8605 = mul nuw i32 %8543, %8542"
"  %8605 = mul nuw i32 %8543, %8542" -> "  %8611 = add nuw i32 %8610, %8605""  %8605 = mul nuw i32 %8543, %8542" -> "  %8608 = and i32 %8605, -65536""  %8605 = mul nuw i32 %8543, %8542" -> "  %8606 = and i32 %8605, 65535"
"  %8606 = and i32 %8605, 65535"
"  %8606 = and i32 %8605, 65535" -> "  %8607 = add nuw nsw i32 %8606, %8604"
"  %8607 = add nuw nsw i32 %8606, %8604"
"  %8607 = add nuw nsw i32 %8606, %8604" -> "  %8609 = add nuw i32 %8607, %8608"
"  %8608 = and i32 %8605, -65536"
"  %8608 = and i32 %8605, -65536" -> "  %8609 = add nuw i32 %8607, %8608"
"  %8609 = add nuw i32 %8607, %8608"
"  %8609 = add nuw i32 %8607, %8608" -> "  %8612 = lshr i32 %8609, 16""  %8609 = add nuw i32 %8607, %8608" -> "  %8610 = and i32 %8609, 65535"
"  %8610 = and i32 %8609, 65535"
"  %8610 = and i32 %8609, 65535" -> "  %8611 = add nuw i32 %8610, %8605"
"  %8611 = add nuw i32 %8610, %8605"
"  %8611 = add nuw i32 %8610, %8605" -> "  %8623 = and i32 %8611, 65535""  %8611 = add nuw i32 %8610, %8605" -> "  %8615 = lshr i32 %8611, 16"
"  %8612 = lshr i32 %8609, 16"
"  %8612 = lshr i32 %8609, 16" -> "  %8614 = add nuw i32 %8612, %8613"
"  %8613 = mul nuw i32 %8543, %8543"
"  %8613 = mul nuw i32 %8543, %8543" -> "  %8614 = add nuw i32 %8612, %8613"
"  %8614 = add nuw i32 %8612, %8613"
"  %8614 = add nuw i32 %8612, %8613" -> "  %8618 = and i32 %8614, -65536""  %8614 = add nuw i32 %8612, %8613" -> "  %8616 = and i32 %8614, 65535"
"  %8615 = lshr i32 %8611, 16"
"  %8615 = lshr i32 %8611, 16" -> "  %8617 = add nuw nsw i32 %8615, %8616"
"  %8616 = and i32 %8614, 65535"
"  %8616 = and i32 %8614, 65535" -> "  %8617 = add nuw nsw i32 %8615, %8616"
"  %8617 = add nuw nsw i32 %8615, %8616"
"  %8617 = add nuw nsw i32 %8615, %8616" -> "  %8619 = add i32 %8617, %8618"
"  %8618 = and i32 %8614, -65536"
"  %8618 = and i32 %8614, -65536" -> "  %8619 = add i32 %8617, %8618"
"  %8619 = add i32 %8617, %8618"
"  %8619 = add i32 %8617, %8618" -> "  %8627 = add i32 %8619, %8626"
"  %8620 = and i32 %8583, 65535"
"  %8620 = and i32 %8583, 65535" -> "  %8622 = add nuw nsw i32 %8620, %8621"
"  %8621 = and i32 %8603, 65535"
"  %8621 = and i32 %8603, 65535" -> "  %8622 = add nuw nsw i32 %8620, %8621"
"  %8622 = add nuw nsw i32 %8620, %8621"
"  %8622 = add nuw nsw i32 %8620, %8621" -> "  %8633 = and i32 %8622, 65535""  %8622 = add nuw nsw i32 %8620, %8621" -> "  %8629 = lshr i32 %8622, 16"
"  %8623 = and i32 %8611, 65535"
"  %8623 = and i32 %8611, 65535" -> "  %8625 = add nuw nsw i32 %8624, %8623"
"  %8624 = lshr i32 %8583, 16"
"  %8624 = lshr i32 %8583, 16" -> "  %8625 = add nuw nsw i32 %8624, %8623"
"  %8625 = add nuw nsw i32 %8624, %8623"
"  %8625 = add nuw nsw i32 %8624, %8623" -> "  %8628 = and i32 %8625, 65535""  %8625 = add nuw nsw i32 %8624, %8623" -> "  %8626 = lshr i32 %8625, 16"
"  %8626 = lshr i32 %8625, 16"
"  %8626 = lshr i32 %8625, 16" -> "  %8627 = add i32 %8619, %8626"
"  %8627 = add i32 %8619, %8626"
"  %8627 = add i32 %8619, %8626" -> "  %8632 = add i32 %8627, %8631"
"  %8628 = and i32 %8625, 65535"
"  %8628 = and i32 %8625, 65535" -> "  %8630 = add nuw nsw i32 %8628, %8629"
"  %8629 = lshr i32 %8622, 16"
"  %8629 = lshr i32 %8622, 16" -> "  %8630 = add nuw nsw i32 %8628, %8629"
"  %8630 = add nuw nsw i32 %8628, %8629"
"  %8630 = add nuw nsw i32 %8628, %8629" -> "  %8636 = and i32 %8630, 65535""  %8630 = add nuw nsw i32 %8628, %8629" -> "  %8631 = lshr i32 %8630, 16"
"  %8631 = lshr i32 %8630, 16"
"  %8631 = lshr i32 %8630, 16" -> "  %8632 = add i32 %8627, %8631"
"  %8632 = add i32 %8627, %8631"
"  %8632 = add i32 %8627, %8631" -> "  %8645 = and i32 %8632, -65536""  %8632 = add i32 %8627, %8631" -> "  %8643 = and i32 %8632, 65535"
"  %8633 = and i32 %8622, 65535"
"  %8633 = and i32 %8622, 65535" -> "  %8635 = add nuw nsw i32 %8634, %8633"
"  %8634 = and i32 %8602, 65535"
"  %8634 = and i32 %8602, 65535" -> "  %8635 = add nuw nsw i32 %8634, %8633"
"  %8635 = add nuw nsw i32 %8634, %8633"
"  %8635 = add nuw nsw i32 %8634, %8633" -> "  %8796 = and i32 %8635, 65535""  %8635 = add nuw nsw i32 %8634, %8633" -> "  %8639 = lshr i32 %8635, 16"
"  %8636 = and i32 %8630, 65535"
"  %8636 = and i32 %8630, 65535" -> "  %8638 = add nuw nsw i32 %8636, %8637"
"  %8637 = lshr i32 %8602, 16"
"  %8637 = lshr i32 %8602, 16" -> "  %8638 = add nuw nsw i32 %8636, %8637"
"  %8638 = add nuw nsw i32 %8636, %8637"
"  %8638 = add nuw nsw i32 %8636, %8637" -> "  %8642 = lshr i32 %8638, 16""  %8638 = add nuw nsw i32 %8636, %8637" -> "  %8640 = and i32 %8638, 65535"
"  %8639 = lshr i32 %8635, 16"
"  %8639 = lshr i32 %8635, 16" -> "  %8641 = add nuw nsw i32 %8640, %8639"
"  %8640 = and i32 %8638, 65535"
"  %8640 = and i32 %8638, 65535" -> "  %8641 = add nuw nsw i32 %8640, %8639"
"  %8641 = add nuw nsw i32 %8640, %8639"
"  %8641 = add nuw nsw i32 %8640, %8639" -> "  %8793 = and i32 %8641, 65535""  %8641 = add nuw nsw i32 %8640, %8639" -> "  %8647 = lshr i32 %8641, 16"
"  %8642 = lshr i32 %8638, 16"
"  %8642 = lshr i32 %8638, 16" -> "  %8644 = add nuw nsw i32 %8642, %8643"
"  %8643 = and i32 %8632, 65535"
"  %8643 = and i32 %8632, 65535" -> "  %8644 = add nuw nsw i32 %8642, %8643"
"  %8644 = add nuw nsw i32 %8642, %8643"
"  %8644 = add nuw nsw i32 %8642, %8643" -> "  %8646 = add i32 %8644, %8645"
"  %8645 = and i32 %8632, -65536"
"  %8645 = and i32 %8632, -65536" -> "  %8646 = add i32 %8644, %8645"
"  %8646 = add i32 %8644, %8645"
"  %8646 = add i32 %8644, %8645" -> "  %8648 = add i32 %8646, %8647"
"  %8647 = lshr i32 %8641, 16"
"  %8647 = lshr i32 %8641, 16" -> "  %8648 = add i32 %8646, %8647"
"  %8648 = add i32 %8646, %8647"
"  %8648 = add i32 %8646, %8647" -> "  %8805 = and i32 %8648, 65535""  %8648 = add i32 %8646, %8647" -> "  %8808 = lshr i32 %8648, 16"
"  %8649 = and i32 %8508, 65535"
"  %8649 = and i32 %8508, 65535" -> "  %8963 = mul nuw i32 %8678, %8649""  %8649 = and i32 %8508, 65535" -> "  %8961 = mul nuw i32 %8675, %8649""  %8649 = and i32 %8508, 65535" -> "  %8946 = mul nuw i32 %8652, %8649""  %8649 = and i32 %8508, 65535" -> "  %8716 = mul nuw i32 %8649, %8543""  %8649 = and i32 %8508, 65535" -> "  %8711 = mul nuw i32 %8649, %8542""  %8649 = and i32 %8508, 65535" -> "  %8656 = mul nuw i32 %8649, %8524""  %8649 = and i32 %8508, 65535" -> "  %8650 = mul nuw i32 %8649, %8523""  %8649 = and i32 %8508, 65535" -> "  %8944 = mul nuw i32 %8649, %8649""  %8649 = and i32 %8508, 65535" -> "  %8944 = mul nuw i32 %8649, %8649"
"  %8650 = mul nuw i32 %8649, %8523"
"  %8650 = mul nuw i32 %8649, %8523" -> "  %8795 = and i32 %8650, 65535""  %8650 = mul nuw i32 %8649, %8523" -> "  %8651 = lshr i32 %8650, 16"
"  %8651 = lshr i32 %8650, 16"
"  %8651 = lshr i32 %8650, 16" -> "  %8655 = add nuw nsw i32 %8654, %8651""  %8651 = lshr i32 %8650, 16" -> "  %8658 = add nuw nsw i32 %8651, %8657"
"  %8652 = and i32 %8511, 65535"
"  %8652 = and i32 %8511, 65535" -> "  %8976 = mul nuw i32 %8678, %8652""  %8652 = and i32 %8511, 65535" -> "  %8966 = mul nuw i32 %8675, %8652""  %8652 = and i32 %8511, 65535" -> "  %8946 = mul nuw i32 %8652, %8649""  %8652 = and i32 %8511, 65535" -> "  %8726 = mul nuw i32 %8652, %8543""  %8652 = and i32 %8511, 65535" -> "  %8713 = mul nuw i32 %8652, %8542""  %8652 = and i32 %8511, 65535" -> "  %8669 = mul nuw i32 %8652, %8524""  %8652 = and i32 %8511, 65535" -> "  %8653 = mul nuw i32 %8652, %8523""  %8652 = and i32 %8511, 65535" -> "  %8954 = mul nuw i32 %8652, %8652""  %8652 = and i32 %8511, 65535" -> "  %8954 = mul nuw i32 %8652, %8652"
"  %8653 = mul nuw i32 %8652, %8523"
"  %8653 = mul nuw i32 %8652, %8523" -> "  %8662 = add nuw i32 %8653, %8661""  %8653 = mul nuw i32 %8652, %8523" -> "  %8663 = and i32 %8653, -65536""  %8653 = mul nuw i32 %8652, %8523" -> "  %8654 = and i32 %8653, 65535"
"  %8654 = and i32 %8653, 65535"
"  %8654 = and i32 %8653, 65535" -> "  %8655 = add nuw nsw i32 %8654, %8651"
"  %8655 = add nuw nsw i32 %8654, %8651"
"  %8655 = add nuw nsw i32 %8654, %8651" -> "  %8664 = add nuw i32 %8655, %8663"
"  %8656 = mul nuw i32 %8649, %8524"
"  %8656 = mul nuw i32 %8649, %8524" -> "  %8666 = add nuw i32 %8665, %8656""  %8656 = mul nuw i32 %8649, %8524" -> "  %8659 = and i32 %8656, -65536""  %8656 = mul nuw i32 %8649, %8524" -> "  %8657 = and i32 %8656, 65535"
"  %8657 = and i32 %8656, 65535"
"  %8657 = and i32 %8656, 65535" -> "  %8658 = add nuw nsw i32 %8651, %8657"
"  %8658 = add nuw nsw i32 %8651, %8657"
"  %8658 = add nuw nsw i32 %8651, %8657" -> "  %8660 = add nuw i32 %8658, %8659"
"  %8659 = and i32 %8656, -65536"
"  %8659 = and i32 %8656, -65536" -> "  %8660 = add nuw i32 %8658, %8659"
"  %8660 = add nuw i32 %8658, %8659"
"  %8660 = add nuw i32 %8658, %8659" -> "  %8830 = lshr i32 %8660, 16""  %8660 = add nuw i32 %8658, %8659" -> "  %8661 = and i32 %8660, 65535"
"  %8661 = and i32 %8660, 65535"
"  %8661 = and i32 %8660, 65535" -> "  %8662 = add nuw i32 %8653, %8661"
"  %8662 = add nuw i32 %8653, %8661"
"  %8662 = add nuw i32 %8653, %8661" -> "  %8832 = lshr i32 %8662, 16""  %8662 = add nuw i32 %8653, %8661" -> "  %8909 = and i32 %8662, 65535"
"  %8663 = and i32 %8653, -65536"
"  %8663 = and i32 %8653, -65536" -> "  %8664 = add nuw i32 %8655, %8663"
"  %8664 = add nuw i32 %8655, %8663"
"  %8664 = add nuw i32 %8655, %8663" -> "  %8667 = lshr i32 %8664, 16""  %8664 = add nuw i32 %8655, %8663" -> "  %8665 = and i32 %8664, 65535"
"  %8665 = and i32 %8664, 65535"
"  %8665 = and i32 %8664, 65535" -> "  %8666 = add nuw i32 %8665, %8656"
"  %8666 = add nuw i32 %8665, %8656"
"  %8666 = add nuw i32 %8665, %8656" -> "  %8792 = and i32 %8666, 65535""  %8666 = add nuw i32 %8665, %8656" -> "  %8668 = lshr i32 %8666, 16"
"  %8667 = lshr i32 %8664, 16"
"  %8667 = lshr i32 %8664, 16" -> "  %8670 = add nuw i32 %8667, %8669"
"  %8668 = lshr i32 %8666, 16"
"  %8668 = lshr i32 %8666, 16" -> "  %8672 = add nuw nsw i32 %8668, %8671"
"  %8669 = mul nuw i32 %8652, %8524"
"  %8669 = mul nuw i32 %8652, %8524" -> "  %8831 = add nuw i32 %8669, %8830""  %8669 = mul nuw i32 %8652, %8524" -> "  %8670 = add nuw i32 %8667, %8669"
"  %8670 = add nuw i32 %8667, %8669"
"  %8670 = add nuw i32 %8667, %8669" -> "  %8673 = and i32 %8670, -65536""  %8670 = add nuw i32 %8667, %8669" -> "  %8671 = and i32 %8670, 65535"
"  %8671 = and i32 %8670, 65535"
"  %8671 = and i32 %8670, 65535" -> "  %8672 = add nuw nsw i32 %8668, %8671"
"  %8672 = add nuw nsw i32 %8668, %8671"
"  %8672 = add nuw nsw i32 %8668, %8671" -> "  %8674 = add i32 %8672, %8673"
"  %8673 = and i32 %8670, -65536"
"  %8673 = and i32 %8670, -65536" -> "  %8674 = add i32 %8672, %8673"
"  %8674 = add i32 %8672, %8673"
"  %8674 = add i32 %8672, %8673" -> "  %8702 = and i32 %8674, 65535""  %8674 = add i32 %8672, %8673" -> "  %8698 = lshr i32 %8674, 16"
"  %8675 = and i32 %8522, 65535"
"  %8675 = and i32 %8522, 65535" -> "  %8966 = mul nuw i32 %8675, %8652""  %8675 = and i32 %8522, 65535" -> "  %8961 = mul nuw i32 %8675, %8649""  %8675 = and i32 %8522, 65535" -> "  %8748 = mul nuw i32 %8675, %8543""  %8675 = and i32 %8522, 65535" -> "  %8745 = mul nuw i32 %8675, %8542""  %8675 = and i32 %8522, 65535" -> "  %8680 = mul nuw i32 %8675, %8524""  %8675 = and i32 %8522, 65535" -> "  %8676 = mul nuw i32 %8675, %8523""  %8675 = and i32 %8522, 65535" -> "  %9016 = mul nuw i32 %8678, %8675""  %8675 = and i32 %8522, 65535" -> "  %9014 = mul nuw i32 %8675, %8675""  %8675 = and i32 %8522, 65535" -> "  %9014 = mul nuw i32 %8675, %8675"
"  %8676 = mul nuw i32 %8675, %8523"
"  %8676 = mul nuw i32 %8675, %8523" -> "  %8701 = and i32 %8676, 65535""  %8676 = mul nuw i32 %8675, %8523" -> "  %8677 = lshr i32 %8676, 16"
"  %8677 = lshr i32 %8676, 16"
"  %8677 = lshr i32 %8676, 16" -> "  %8687 = add nuw i32 %8677, %8679""  %8677 = lshr i32 %8676, 16" -> "  %8682 = add nuw nsw i32 %8677, %8681"
"  %8678 = lshr i32 %8522, 16"
"  %8678 = lshr i32 %8522, 16" -> "  %8976 = mul nuw i32 %8678, %8652""  %8678 = lshr i32 %8522, 16" -> "  %8963 = mul nuw i32 %8678, %8649""  %8678 = lshr i32 %8522, 16" -> "  %8757 = mul nuw i32 %8678, %8543""  %8678 = lshr i32 %8522, 16" -> "  %8747 = mul nuw i32 %8678, %8542""  %8678 = lshr i32 %8522, 16" -> "  %8692 = mul nuw i32 %8678, %8524""  %8678 = lshr i32 %8522, 16" -> "  %8679 = mul nuw i32 %8678, %8523""  %8678 = lshr i32 %8522, 16" -> "  %9016 = mul nuw i32 %8678, %8675""  %8678 = lshr i32 %8522, 16" -> "  %9024 = mul nuw i32 %8678, %8678""  %8678 = lshr i32 %8522, 16" -> "  %9024 = mul nuw i32 %8678, %8678"
"  %8679 = mul nuw i32 %8678, %8523"
"  %8679 = mul nuw i32 %8678, %8523" -> "  %8687 = add nuw i32 %8677, %8679""  %8679 = mul nuw i32 %8678, %8523" -> "  %8686 = add nuw i32 %8685, %8679"
"  %8680 = mul nuw i32 %8675, %8524"
"  %8680 = mul nuw i32 %8675, %8524" -> "  %8689 = add nuw i32 %8688, %8680""  %8680 = mul nuw i32 %8675, %8524" -> "  %8683 = and i32 %8680, -65536""  %8680 = mul nuw i32 %8675, %8524" -> "  %8681 = and i32 %8680, 65535"
"  %8681 = and i32 %8680, 65535"
"  %8681 = and i32 %8680, 65535" -> "  %8682 = add nuw nsw i32 %8677, %8681"
"  %8682 = add nuw nsw i32 %8677, %8681"
"  %8682 = add nuw nsw i32 %8677, %8681" -> "  %8684 = add nuw i32 %8682, %8683"
"  %8683 = and i32 %8680, -65536"
"  %8683 = and i32 %8680, -65536" -> "  %8684 = add nuw i32 %8682, %8683"
"  %8684 = add nuw i32 %8682, %8683"
"  %8684 = add nuw i32 %8682, %8683" -> "  %8856 = lshr i32 %8684, 16""  %8684 = add nuw i32 %8682, %8683" -> "  %8685 = and i32 %8684, 65535"
"  %8685 = and i32 %8684, 65535"
"  %8685 = and i32 %8684, 65535" -> "  %8686 = add nuw i32 %8685, %8679"
"  %8686 = add nuw i32 %8685, %8679"
"  %8686 = add nuw i32 %8685, %8679" -> "  %8858 = lshr i32 %8686, 16""  %8686 = add nuw i32 %8685, %8679" -> "  %8866 = and i32 %8686, 65535"
"  %8687 = add nuw i32 %8677, %8679"
"  %8687 = add nuw i32 %8677, %8679" -> "  %8690 = lshr i32 %8687, 16""  %8687 = add nuw i32 %8677, %8679" -> "  %8688 = and i32 %8687, 65535"
"  %8688 = and i32 %8687, 65535"
"  %8688 = and i32 %8687, 65535" -> "  %8689 = add nuw i32 %8688, %8680"
"  %8689 = add nuw i32 %8688, %8680"
"  %8689 = add nuw i32 %8688, %8680" -> "  %8699 = and i32 %8689, 65535""  %8689 = add nuw i32 %8688, %8680" -> "  %8691 = lshr i32 %8689, 16"
"  %8690 = lshr i32 %8687, 16"
"  %8690 = lshr i32 %8687, 16" -> "  %8693 = add nuw i32 %8690, %8692"
"  %8691 = lshr i32 %8689, 16"
"  %8691 = lshr i32 %8689, 16" -> "  %8695 = add nuw nsw i32 %8694, %8691"
"  %8692 = mul nuw i32 %8678, %8524"
"  %8692 = mul nuw i32 %8678, %8524" -> "  %8857 = add nuw i32 %8856, %8692""  %8692 = mul nuw i32 %8678, %8524" -> "  %8693 = add nuw i32 %8690, %8692"
"  %8693 = add nuw i32 %8690, %8692"
"  %8693 = add nuw i32 %8690, %8692" -> "  %8696 = and i32 %8693, -65536""  %8693 = add nuw i32 %8690, %8692" -> "  %8694 = and i32 %8693, 65535"
"  %8694 = and i32 %8693, 65535"
"  %8694 = and i32 %8693, 65535" -> "  %8695 = add nuw nsw i32 %8694, %8691"
"  %8695 = add nuw nsw i32 %8694, %8691"
"  %8695 = add nuw nsw i32 %8694, %8691" -> "  %8697 = add i32 %8695, %8696"
"  %8696 = and i32 %8693, -65536"
"  %8696 = and i32 %8693, -65536" -> "  %8697 = add i32 %8695, %8696"
"  %8697 = add i32 %8695, %8696"
"  %8697 = add i32 %8695, %8696" -> "  %8709 = add i32 %8697, %8707"
"  %8698 = lshr i32 %8674, 16"
"  %8698 = lshr i32 %8674, 16" -> "  %8700 = add nuw nsw i32 %8699, %8698"
"  %8699 = and i32 %8689, 65535"
"  %8699 = and i32 %8689, 65535" -> "  %8700 = add nuw nsw i32 %8699, %8698"
"  %8700 = add nuw nsw i32 %8699, %8698"
"  %8700 = add nuw nsw i32 %8699, %8698" -> "  %8707 = lshr i32 %8700, 16""  %8700 = add nuw nsw i32 %8699, %8698" -> "  %8705 = and i32 %8700, 65535"
"  %8701 = and i32 %8676, 65535"
"  %8701 = and i32 %8676, 65535" -> "  %8703 = add nuw nsw i32 %8702, %8701""  %8701 = and i32 %8676, 65535" -> "  %8864 = add nuw nsw i32 %8701, %8863"
"  %8702 = and i32 %8674, 65535"
"  %8702 = and i32 %8674, 65535" -> "  %8703 = add nuw nsw i32 %8702, %8701"
"  %8703 = add nuw nsw i32 %8702, %8701"
"  %8703 = add nuw nsw i32 %8702, %8701" -> "  %8738 = and i32 %8703, 65535""  %8703 = add nuw nsw i32 %8702, %8701" -> "  %8704 = lshr i32 %8703, 16"
"  %8704 = lshr i32 %8703, 16"
"  %8704 = lshr i32 %8703, 16" -> "  %8706 = add nuw nsw i32 %8705, %8704"
"  %8705 = and i32 %8700, 65535"
"  %8705 = and i32 %8700, 65535" -> "  %8706 = add nuw nsw i32 %8705, %8704"
"  %8706 = add nuw nsw i32 %8705, %8704"
"  %8706 = add nuw nsw i32 %8705, %8704" -> "  %8732 = and i32 %8706, 65535""  %8706 = add nuw nsw i32 %8705, %8704" -> "  %8708 = lshr i32 %8706, 16"
"  %8707 = lshr i32 %8700, 16"
"  %8707 = lshr i32 %8700, 16" -> "  %8709 = add i32 %8697, %8707"
"  %8708 = lshr i32 %8706, 16"
"  %8708 = lshr i32 %8706, 16" -> "  %8710 = add i32 %8709, %8708"
"  %8709 = add i32 %8697, %8707"
"  %8709 = add i32 %8697, %8707" -> "  %8710 = add i32 %8709, %8708"
"  %8710 = add i32 %8709, %8708"
"  %8710 = add i32 %8709, %8708" -> "  %8769 = and i32 %8710, 65535""  %8710 = add i32 %8709, %8708" -> "  %8764 = lshr i32 %8710, 16"
"  %8711 = mul nuw i32 %8649, %8542"
"  %8711 = mul nuw i32 %8649, %8542" -> "  %8737 = and i32 %8711, 65535""  %8711 = mul nuw i32 %8649, %8542" -> "  %8712 = lshr i32 %8711, 16"
"  %8712 = lshr i32 %8711, 16"
"  %8712 = lshr i32 %8711, 16" -> "  %8715 = add nuw nsw i32 %8714, %8712""  %8712 = lshr i32 %8711, 16" -> "  %8717 = add nuw i32 %8712, %8716"
"  %8713 = mul nuw i32 %8652, %8542"
"  %8713 = mul nuw i32 %8652, %8542" -> "  %8719 = add nuw i32 %8713, %8718""  %8713 = mul nuw i32 %8652, %8542" -> "  %8720 = and i32 %8713, -65536""  %8713 = mul nuw i32 %8652, %8542" -> "  %8714 = and i32 %8713, 65535"
"  %8714 = and i32 %8713, 65535"
"  %8714 = and i32 %8713, 65535" -> "  %8715 = add nuw nsw i32 %8714, %8712"
"  %8715 = add nuw nsw i32 %8714, %8712"
"  %8715 = add nuw nsw i32 %8714, %8712" -> "  %8721 = add nuw i32 %8715, %8720"
"  %8716 = mul nuw i32 %8649, %8543"
"  %8716 = mul nuw i32 %8649, %8543" -> "  %8723 = add nuw i32 %8722, %8716""  %8716 = mul nuw i32 %8649, %8543" -> "  %8717 = add nuw i32 %8712, %8716"
"  %8717 = add nuw i32 %8712, %8716"
"  %8717 = add nuw i32 %8712, %8716" -> "  %8837 = lshr i32 %8717, 16""  %8717 = add nuw i32 %8712, %8716" -> "  %8718 = and i32 %8717, 65535"
"  %8718 = and i32 %8717, 65535"
"  %8718 = and i32 %8717, 65535" -> "  %8719 = add nuw i32 %8713, %8718"
"  %8719 = add nuw i32 %8713, %8718"
"  %8719 = add nuw i32 %8713, %8718" -> "  %8839 = lshr i32 %8719, 16""  %8719 = add nuw i32 %8713, %8718" -> "  %8846 = and i32 %8719, 65535"
"  %8720 = and i32 %8713, -65536"
"  %8720 = and i32 %8713, -65536" -> "  %8721 = add nuw i32 %8715, %8720"
"  %8721 = add nuw i32 %8715, %8720"
"  %8721 = add nuw i32 %8715, %8720" -> "  %8724 = lshr i32 %8721, 16""  %8721 = add nuw i32 %8715, %8720" -> "  %8722 = and i32 %8721, 65535"
"  %8722 = and i32 %8721, 65535"
"  %8722 = and i32 %8721, 65535" -> "  %8723 = add nuw i32 %8722, %8716"
"  %8723 = add nuw i32 %8722, %8716"
"  %8723 = add nuw i32 %8722, %8716" -> "  %8733 = and i32 %8723, 65535""  %8723 = add nuw i32 %8722, %8716" -> "  %8725 = lshr i32 %8723, 16"
"  %8724 = lshr i32 %8721, 16"
"  %8724 = lshr i32 %8721, 16" -> "  %8727 = add nuw i32 %8724, %8726"
"  %8725 = lshr i32 %8723, 16"
"  %8725 = lshr i32 %8723, 16" -> "  %8729 = add nuw nsw i32 %8725, %8728"
"  %8726 = mul nuw i32 %8652, %8543"
"  %8726 = mul nuw i32 %8652, %8543" -> "  %8838 = add nuw i32 %8726, %8837""  %8726 = mul nuw i32 %8652, %8543" -> "  %8727 = add nuw i32 %8724, %8726"
"  %8727 = add nuw i32 %8724, %8726"
"  %8727 = add nuw i32 %8724, %8726" -> "  %8730 = and i32 %8727, -65536""  %8727 = add nuw i32 %8724, %8726" -> "  %8728 = and i32 %8727, 65535"
"  %8728 = and i32 %8727, 65535"
"  %8728 = and i32 %8727, 65535" -> "  %8729 = add nuw nsw i32 %8725, %8728"
"  %8729 = add nuw nsw i32 %8725, %8728"
"  %8729 = add nuw nsw i32 %8725, %8728" -> "  %8731 = add i32 %8729, %8730"
"  %8730 = and i32 %8727, -65536"
"  %8730 = and i32 %8727, -65536" -> "  %8731 = add i32 %8729, %8730"
"  %8731 = add i32 %8729, %8730"
"  %8731 = add i32 %8729, %8730" -> "  %8736 = add i32 %8731, %8735"
"  %8732 = and i32 %8706, 65535"
"  %8732 = and i32 %8706, 65535" -> "  %8734 = add nuw nsw i32 %8732, %8733"
"  %8733 = and i32 %8723, 65535"
"  %8733 = and i32 %8723, 65535" -> "  %8734 = add nuw nsw i32 %8732, %8733"
"  %8734 = add nuw nsw i32 %8732, %8733"
"  %8734 = add nuw nsw i32 %8732, %8733" -> "  %8739 = and i32 %8734, 65535""  %8734 = add nuw nsw i32 %8732, %8733" -> "  %8735 = lshr i32 %8734, 16"
"  %8735 = lshr i32 %8734, 16"
"  %8735 = lshr i32 %8734, 16" -> "  %8736 = add i32 %8731, %8735"
"  %8736 = add i32 %8731, %8735"
"  %8736 = add i32 %8731, %8735" -> "  %8744 = add i32 %8736, %8743"
"  %8737 = and i32 %8711, 65535"
"  %8737 = and i32 %8711, 65535" -> "  %8845 = add nuw nsw i32 %8844, %8737""  %8737 = and i32 %8711, 65535" -> "  %8740 = add nuw nsw i32 %8738, %8737"
"  %8738 = and i32 %8703, 65535"
"  %8738 = and i32 %8703, 65535" -> "  %8740 = add nuw nsw i32 %8738, %8737"
"  %8739 = and i32 %8734, 65535"
"  %8739 = and i32 %8734, 65535" -> "  %8742 = add nuw nsw i32 %8739, %8741"
"  %8740 = add nuw nsw i32 %8738, %8737"
"  %8740 = add nuw nsw i32 %8738, %8737" -> "  %8804 = and i32 %8740, 65535""  %8740 = add nuw nsw i32 %8738, %8737" -> "  %8741 = lshr i32 %8740, 16"
"  %8741 = lshr i32 %8740, 16"
"  %8741 = lshr i32 %8740, 16" -> "  %8742 = add nuw nsw i32 %8739, %8741"
"  %8742 = add nuw nsw i32 %8739, %8741"
"  %8742 = add nuw nsw i32 %8739, %8741" -> "  %8807 = and i32 %8742, 65535""  %8742 = add nuw nsw i32 %8739, %8741" -> "  %8743 = lshr i32 %8742, 16"
"  %8743 = lshr i32 %8742, 16"
"  %8743 = lshr i32 %8742, 16" -> "  %8744 = add i32 %8736, %8743"
"  %8744 = add i32 %8736, %8743"
"  %8744 = add i32 %8736, %8743" -> "  %8780 = lshr i32 %8744, 16""  %8744 = add i32 %8736, %8743" -> "  %8777 = and i32 %8744, 65535"
"  %8745 = mul nuw i32 %8675, %8542"
"  %8745 = mul nuw i32 %8675, %8542" -> "  %8768 = and i32 %8745, 65535""  %8745 = mul nuw i32 %8675, %8542" -> "  %8746 = lshr i32 %8745, 16"
"  %8746 = lshr i32 %8745, 16"
"  %8746 = lshr i32 %8745, 16" -> "  %8752 = add nuw i32 %8746, %8747""  %8746 = lshr i32 %8745, 16" -> "  %8749 = add nuw i32 %8746, %8748"
"  %8747 = mul nuw i32 %8678, %8542"
"  %8747 = mul nuw i32 %8678, %8542" -> "  %8752 = add nuw i32 %8746, %8747""  %8747 = mul nuw i32 %8678, %8542" -> "  %8751 = add nuw i32 %8750, %8747"
"  %8748 = mul nuw i32 %8675, %8543"
"  %8748 = mul nuw i32 %8675, %8543" -> "  %8754 = add nuw i32 %8753, %8748""  %8748 = mul nuw i32 %8675, %8543" -> "  %8749 = add nuw i32 %8746, %8748"
"  %8749 = add nuw i32 %8746, %8748"
"  %8749 = add nuw i32 %8746, %8748" -> "  %8875 = lshr i32 %8749, 16""  %8749 = add nuw i32 %8746, %8748" -> "  %8750 = and i32 %8749, 65535"
"  %8750 = and i32 %8749, 65535"
"  %8750 = and i32 %8749, 65535" -> "  %8751 = add nuw i32 %8750, %8747"
"  %8751 = add nuw i32 %8750, %8747"
"  %8751 = add nuw i32 %8750, %8747" -> "  %8885 = and i32 %8751, 65535""  %8751 = add nuw i32 %8750, %8747" -> "  %8877 = lshr i32 %8751, 16"
"  %8752 = add nuw i32 %8746, %8747"
"  %8752 = add nuw i32 %8746, %8747" -> "  %8755 = lshr i32 %8752, 16""  %8752 = add nuw i32 %8746, %8747" -> "  %8753 = and i32 %8752, 65535"
"  %8753 = and i32 %8752, 65535"
"  %8753 = and i32 %8752, 65535" -> "  %8754 = add nuw i32 %8753, %8748"
"  %8754 = add nuw i32 %8753, %8748"
"  %8754 = add nuw i32 %8753, %8748" -> "  %8763 = and i32 %8754, 65535""  %8754 = add nuw i32 %8753, %8748" -> "  %8756 = lshr i32 %8754, 16"
"  %8755 = lshr i32 %8752, 16"
"  %8755 = lshr i32 %8752, 16" -> "  %8758 = add nuw i32 %8755, %8757"
"  %8756 = lshr i32 %8754, 16"
"  %8756 = lshr i32 %8754, 16" -> "  %8760 = add nuw nsw i32 %8756, %8759"
"  %8757 = mul nuw i32 %8678, %8543"
"  %8757 = mul nuw i32 %8678, %8543" -> "  %8876 = add nuw i32 %8875, %8757""  %8757 = mul nuw i32 %8678, %8543" -> "  %8758 = add nuw i32 %8755, %8757"
"  %8758 = add nuw i32 %8755, %8757"
"  %8758 = add nuw i32 %8755, %8757" -> "  %8761 = and i32 %8758, -65536""  %8758 = add nuw i32 %8755, %8757" -> "  %8759 = and i32 %8758, 65535"
"  %8759 = and i32 %8758, 65535"
"  %8759 = and i32 %8758, 65535" -> "  %8760 = add nuw nsw i32 %8756, %8759"
"  %8760 = add nuw nsw i32 %8756, %8759"
"  %8760 = add nuw nsw i32 %8756, %8759" -> "  %8762 = add i32 %8760, %8761"
"  %8761 = and i32 %8758, -65536"
"  %8761 = and i32 %8758, -65536" -> "  %8762 = add i32 %8760, %8761"
"  %8762 = add i32 %8760, %8761"
"  %8762 = add i32 %8760, %8761" -> "  %8767 = add i32 %8762, %8766"
"  %8763 = and i32 %8754, 65535"
"  %8763 = and i32 %8754, 65535" -> "  %8765 = add nuw nsw i32 %8764, %8763"
"  %8764 = lshr i32 %8710, 16"
"  %8764 = lshr i32 %8710, 16" -> "  %8765 = add nuw nsw i32 %8764, %8763"
"  %8765 = add nuw nsw i32 %8764, %8763"
"  %8765 = add nuw nsw i32 %8764, %8763" -> "  %8770 = and i32 %8765, 65535""  %8765 = add nuw nsw i32 %8764, %8763" -> "  %8766 = lshr i32 %8765, 16"
"  %8766 = lshr i32 %8765, 16"
"  %8766 = lshr i32 %8765, 16" -> "  %8767 = add i32 %8762, %8766"
"  %8767 = add i32 %8762, %8766"
"  %8767 = add i32 %8762, %8766" -> "  %8775 = add i32 %8767, %8774"
"  %8768 = and i32 %8745, 65535"
"  %8768 = and i32 %8745, 65535" -> "  %8883 = add nuw nsw i32 %8882, %8768""  %8768 = and i32 %8745, 65535" -> "  %8771 = add nuw nsw i32 %8769, %8768"
"  %8769 = and i32 %8710, 65535"
"  %8769 = and i32 %8710, 65535" -> "  %8771 = add nuw nsw i32 %8769, %8768"
"  %8770 = and i32 %8765, 65535"
"  %8770 = and i32 %8765, 65535" -> "  %8773 = add nuw nsw i32 %8770, %8772"
"  %8771 = add nuw nsw i32 %8769, %8768"
"  %8771 = add nuw nsw i32 %8769, %8768" -> "  %8776 = and i32 %8771, 65535""  %8771 = add nuw nsw i32 %8769, %8768" -> "  %8772 = lshr i32 %8771, 16"
"  %8772 = lshr i32 %8771, 16"
"  %8772 = lshr i32 %8771, 16" -> "  %8773 = add nuw nsw i32 %8770, %8772"
"  %8773 = add nuw nsw i32 %8770, %8772"
"  %8773 = add nuw nsw i32 %8770, %8772" -> "  %8779 = and i32 %8773, 65535""  %8773 = add nuw nsw i32 %8770, %8772" -> "  %8774 = lshr i32 %8773, 16"
"  %8774 = lshr i32 %8773, 16"
"  %8774 = lshr i32 %8773, 16" -> "  %8775 = add i32 %8767, %8774"
"  %8775 = add i32 %8767, %8774"
"  %8775 = add i32 %8767, %8774" -> "  %8788 = and i32 %8775, -65536""  %8775 = add i32 %8767, %8774" -> "  %8786 = and i32 %8775, 65535"
"  %8776 = and i32 %8771, 65535"
"  %8776 = and i32 %8771, 65535" -> "  %8778 = add nuw nsw i32 %8777, %8776"
"  %8777 = and i32 %8744, 65535"
"  %8777 = and i32 %8744, 65535" -> "  %8778 = add nuw nsw i32 %8777, %8776"
"  %8778 = add nuw nsw i32 %8777, %8776"
"  %8778 = add nuw nsw i32 %8777, %8776" -> "  %8818 = and i32 %8778, 65535""  %8778 = add nuw nsw i32 %8777, %8776" -> "  %8782 = lshr i32 %8778, 16"
"  %8779 = and i32 %8773, 65535"
"  %8779 = and i32 %8773, 65535" -> "  %8781 = add nuw nsw i32 %8779, %8780"
"  %8780 = lshr i32 %8744, 16"
"  %8780 = lshr i32 %8744, 16" -> "  %8781 = add nuw nsw i32 %8779, %8780"
"  %8781 = add nuw nsw i32 %8779, %8780"
"  %8781 = add nuw nsw i32 %8779, %8780" -> "  %8785 = lshr i32 %8781, 16""  %8781 = add nuw nsw i32 %8779, %8780" -> "  %8783 = and i32 %8781, 65535"
"  %8782 = lshr i32 %8778, 16"
"  %8782 = lshr i32 %8778, 16" -> "  %8784 = add nuw nsw i32 %8783, %8782"
"  %8783 = and i32 %8781, 65535"
"  %8783 = and i32 %8781, 65535" -> "  %8784 = add nuw nsw i32 %8783, %8782"
"  %8784 = add nuw nsw i32 %8783, %8782"
"  %8784 = add nuw nsw i32 %8783, %8782" -> "  %8825 = and i32 %8784, 65535""  %8784 = add nuw nsw i32 %8783, %8782" -> "  %8790 = lshr i32 %8784, 16"
"  %8785 = lshr i32 %8781, 16"
"  %8785 = lshr i32 %8781, 16" -> "  %8787 = add nuw nsw i32 %8785, %8786"
"  %8786 = and i32 %8775, 65535"
"  %8786 = and i32 %8775, 65535" -> "  %8787 = add nuw nsw i32 %8785, %8786"
"  %8787 = add nuw nsw i32 %8785, %8786"
"  %8787 = add nuw nsw i32 %8785, %8786" -> "  %8789 = add i32 %8787, %8788"
"  %8788 = and i32 %8775, -65536"
"  %8788 = and i32 %8775, -65536" -> "  %8789 = add i32 %8787, %8788"
"  %8789 = add i32 %8787, %8788"
"  %8789 = add i32 %8787, %8788" -> "  %8791 = add i32 %8789, %8790"
"  %8790 = lshr i32 %8784, 16"
"  %8790 = lshr i32 %8784, 16" -> "  %8791 = add i32 %8789, %8790"
"  %8791 = add i32 %8789, %8790"
"  %8791 = add i32 %8789, %8790" -> "  %8829 = add i32 %8791, %8828"
"  %8792 = and i32 %8666, 65535"
"  %8792 = and i32 %8666, 65535" -> "  %8794 = add nuw nsw i32 %8793, %8792"
"  %8793 = and i32 %8641, 65535"
"  %8793 = and i32 %8641, 65535" -> "  %8794 = add nuw nsw i32 %8793, %8792"
"  %8794 = add nuw nsw i32 %8793, %8792"
"  %8794 = add nuw nsw i32 %8793, %8792" -> "  %8801 = lshr i32 %8794, 16""  %8794 = add nuw nsw i32 %8793, %8792" -> "  %8799 = and i32 %8794, 65535"
"  %8795 = and i32 %8650, 65535"
"  %8795 = and i32 %8650, 65535" -> "  %8908 = add nuw nsw i32 %8907, %8795""  %8795 = and i32 %8650, 65535" -> "  %8797 = add nuw nsw i32 %8796, %8795"
"  %8796 = and i32 %8635, 65535"
"  %8796 = and i32 %8635, 65535" -> "  %8797 = add nuw nsw i32 %8796, %8795"
"  %8797 = add nuw nsw i32 %8796, %8795"
"  %8797 = add nuw nsw i32 %8796, %8795" -> "  %8907 = and i32 %8797, 65535""  %8797 = add nuw nsw i32 %8796, %8795" -> "  %8798 = lshr i32 %8797, 16"
"  %8798 = lshr i32 %8797, 16"
"  %8798 = lshr i32 %8797, 16" -> "  %8800 = add nuw nsw i32 %8799, %8798"
"  %8799 = and i32 %8794, 65535"
"  %8799 = and i32 %8794, 65535" -> "  %8800 = add nuw nsw i32 %8799, %8798"
"  %8800 = add nuw nsw i32 %8799, %8798"
"  %8800 = add nuw nsw i32 %8799, %8798" -> "  %8910 = and i32 %8800, 65535""  %8800 = add nuw nsw i32 %8799, %8798" -> "  %8802 = lshr i32 %8800, 16"
"  %8801 = lshr i32 %8794, 16"
"  %8801 = lshr i32 %8794, 16" -> "  %8803 = add nuw nsw i32 %8802, %8801"
"  %8802 = lshr i32 %8800, 16"
"  %8802 = lshr i32 %8800, 16" -> "  %8803 = add nuw nsw i32 %8802, %8801"
"  %8803 = add nuw nsw i32 %8802, %8801"
"  %8803 = add nuw nsw i32 %8802, %8801" -> "  %8814 = add nuw nsw i32 %8803, %8813"
"  %8804 = and i32 %8740, 65535"
"  %8804 = and i32 %8740, 65535" -> "  %8806 = add nuw nsw i32 %8804, %8805"
"  %8805 = and i32 %8648, 65535"
"  %8805 = and i32 %8648, 65535" -> "  %8806 = add nuw nsw i32 %8804, %8805"
"  %8806 = add nuw nsw i32 %8804, %8805"
"  %8806 = add nuw nsw i32 %8804, %8805" -> "  %8813 = and i32 %8806, 65535""  %8806 = add nuw nsw i32 %8804, %8805" -> "  %8810 = lshr i32 %8806, 16"
"  %8807 = and i32 %8742, 65535"
"  %8807 = and i32 %8742, 65535" -> "  %8809 = add nuw nsw i32 %8807, %8808"
"  %8808 = lshr i32 %8648, 16"
"  %8808 = lshr i32 %8648, 16" -> "  %8809 = add nuw nsw i32 %8807, %8808"
"  %8809 = add nuw nsw i32 %8807, %8808"
"  %8809 = add nuw nsw i32 %8807, %8808" -> "  %8819 = lshr i32 %8809, 16""  %8809 = add nuw nsw i32 %8807, %8808" -> "  %8811 = and i32 %8809, 65535"
"  %8810 = lshr i32 %8806, 16"
"  %8810 = lshr i32 %8806, 16" -> "  %8812 = add nuw nsw i32 %8811, %8810"
"  %8811 = and i32 %8809, 65535"
"  %8811 = and i32 %8809, 65535" -> "  %8812 = add nuw nsw i32 %8811, %8810"
"  %8812 = add nuw nsw i32 %8811, %8810"
"  %8812 = add nuw nsw i32 %8811, %8810" -> "  %8821 = lshr i32 %8812, 16""  %8812 = add nuw nsw i32 %8811, %8810" -> "  %8816 = and i32 %8812, 65535"
"  %8813 = and i32 %8806, 65535"
"  %8813 = and i32 %8806, 65535" -> "  %8814 = add nuw nsw i32 %8803, %8813"
"  %8814 = add nuw nsw i32 %8803, %8813"
"  %8814 = add nuw nsw i32 %8803, %8813" -> "  %8918 = and i32 %8814, 65535""  %8814 = add nuw nsw i32 %8803, %8813" -> "  %8815 = lshr i32 %8814, 16"
"  %8815 = lshr i32 %8814, 16"
"  %8815 = lshr i32 %8814, 16" -> "  %8817 = add nuw nsw i32 %8816, %8815"
"  %8816 = and i32 %8812, 65535"
"  %8816 = and i32 %8812, 65535" -> "  %8817 = add nuw nsw i32 %8816, %8815"
"  %8817 = add nuw nsw i32 %8816, %8815"
"  %8817 = add nuw nsw i32 %8816, %8815" -> "  %8921 = and i32 %8817, 65535""  %8817 = add nuw nsw i32 %8816, %8815" -> "  %8823 = lshr i32 %8817, 16"
"  %8818 = and i32 %8778, 65535"
"  %8818 = and i32 %8778, 65535" -> "  %8820 = add nuw nsw i32 %8818, %8819"
"  %8819 = lshr i32 %8809, 16"
"  %8819 = lshr i32 %8809, 16" -> "  %8820 = add nuw nsw i32 %8818, %8819"
"  %8820 = add nuw nsw i32 %8818, %8819"
"  %8820 = add nuw nsw i32 %8818, %8819" -> "  %8822 = add nuw nsw i32 %8820, %8821"
"  %8821 = lshr i32 %8812, 16"
"  %8821 = lshr i32 %8812, 16" -> "  %8822 = add nuw nsw i32 %8820, %8821"
"  %8822 = add nuw nsw i32 %8820, %8821"
"  %8822 = add nuw nsw i32 %8820, %8821" -> "  %8824 = add nuw nsw i32 %8822, %8823"
"  %8823 = lshr i32 %8817, 16"
"  %8823 = lshr i32 %8817, 16" -> "  %8824 = add nuw nsw i32 %8822, %8823"
"  %8824 = add nuw nsw i32 %8822, %8823"
"  %8824 = add nuw nsw i32 %8822, %8823" -> "  %9061 = and i32 %8824, 65535""  %8824 = add nuw nsw i32 %8822, %8823" -> "  %8826 = lshr i32 %8824, 16"
"  %8825 = and i32 %8784, 65535"
"  %8825 = and i32 %8784, 65535" -> "  %8827 = add nuw nsw i32 %8826, %8825"
"  %8826 = lshr i32 %8824, 16"
"  %8826 = lshr i32 %8824, 16" -> "  %8827 = add nuw nsw i32 %8826, %8825"
"  %8827 = add nuw nsw i32 %8826, %8825"
"  %8827 = add nuw nsw i32 %8826, %8825" -> "  %9064 = and i32 %8827, 65535""  %8827 = add nuw nsw i32 %8826, %8825" -> "  %8828 = lshr i32 %8827, 16"
"  %8828 = lshr i32 %8827, 16"
"  %8828 = lshr i32 %8827, 16" -> "  %8829 = add i32 %8791, %8828"
"  %8829 = add i32 %8791, %8828"
"  %8829 = add i32 %8791, %8828" -> "  %9070 = and i32 %8829, 65535""  %8829 = add i32 %8791, %8828" -> "  %9073 = lshr i32 %8829, 16"
"  %8830 = lshr i32 %8660, 16"
"  %8830 = lshr i32 %8660, 16" -> "  %8831 = add nuw i32 %8669, %8830"
"  %8831 = add nuw i32 %8669, %8830"
"  %8831 = add nuw i32 %8669, %8830" -> "  %8835 = and i32 %8831, -65536""  %8831 = add nuw i32 %8669, %8830" -> "  %8833 = and i32 %8831, 65535"
"  %8832 = lshr i32 %8662, 16"
"  %8832 = lshr i32 %8662, 16" -> "  %8834 = add nuw nsw i32 %8832, %8833"
"  %8833 = and i32 %8831, 65535"
"  %8833 = and i32 %8831, 65535" -> "  %8834 = add nuw nsw i32 %8832, %8833"
"  %8834 = add nuw nsw i32 %8832, %8833"
"  %8834 = add nuw nsw i32 %8832, %8833" -> "  %8836 = add i32 %8834, %8835"
"  %8835 = and i32 %8831, -65536"
"  %8835 = and i32 %8831, -65536" -> "  %8836 = add i32 %8834, %8835"
"  %8836 = add i32 %8834, %8835"
"  %8836 = add i32 %8834, %8835" -> "  %8847 = lshr i32 %8836, 16""  %8836 = add i32 %8834, %8835" -> "  %8844 = and i32 %8836, 65535"
"  %8837 = lshr i32 %8717, 16"
"  %8837 = lshr i32 %8717, 16" -> "  %8838 = add nuw i32 %8726, %8837"
"  %8838 = add nuw i32 %8726, %8837"
"  %8838 = add nuw i32 %8726, %8837" -> "  %8842 = and i32 %8838, -65536""  %8838 = add nuw i32 %8726, %8837" -> "  %8840 = and i32 %8838, 65535"
"  %8839 = lshr i32 %8719, 16"
"  %8839 = lshr i32 %8719, 16" -> "  %8841 = add nuw nsw i32 %8839, %8840"
"  %8840 = and i32 %8838, 65535"
"  %8840 = and i32 %8838, 65535" -> "  %8841 = add nuw nsw i32 %8839, %8840"
"  %8841 = add nuw nsw i32 %8839, %8840"
"  %8841 = add nuw nsw i32 %8839, %8840" -> "  %8843 = add i32 %8841, %8842"
"  %8842 = and i32 %8838, -65536"
"  %8842 = and i32 %8838, -65536" -> "  %8843 = add i32 %8841, %8842"
"  %8843 = add i32 %8841, %8842"
"  %8843 = add i32 %8841, %8842" -> "  %8850 = add i32 %8843, %8849"
"  %8844 = and i32 %8836, 65535"
"  %8844 = and i32 %8836, 65535" -> "  %8845 = add nuw nsw i32 %8844, %8737"
"  %8845 = add nuw nsw i32 %8844, %8737"
"  %8845 = add nuw nsw i32 %8844, %8737" -> "  %8863 = and i32 %8845, 65535""  %8845 = add nuw nsw i32 %8844, %8737" -> "  %8852 = lshr i32 %8845, 16"
"  %8846 = and i32 %8719, 65535"
"  %8846 = and i32 %8719, 65535" -> "  %8848 = add nuw nsw i32 %8847, %8846"
"  %8847 = lshr i32 %8836, 16"
"  %8847 = lshr i32 %8836, 16" -> "  %8848 = add nuw nsw i32 %8847, %8846"
"  %8848 = add nuw nsw i32 %8847, %8846"
"  %8848 = add nuw nsw i32 %8847, %8846" -> "  %8851 = and i32 %8848, 65535""  %8848 = add nuw nsw i32 %8847, %8846" -> "  %8849 = lshr i32 %8848, 16"
"  %8849 = lshr i32 %8848, 16"
"  %8849 = lshr i32 %8848, 16" -> "  %8850 = add i32 %8843, %8849"
"  %8850 = add i32 %8843, %8849"
"  %8850 = add i32 %8843, %8849" -> "  %8855 = add i32 %8850, %8854"
"  %8851 = and i32 %8848, 65535"
"  %8851 = and i32 %8848, 65535" -> "  %8853 = add nuw nsw i32 %8852, %8851"
"  %8852 = lshr i32 %8845, 16"
"  %8852 = lshr i32 %8845, 16" -> "  %8853 = add nuw nsw i32 %8852, %8851"
"  %8853 = add nuw nsw i32 %8852, %8851"
"  %8853 = add nuw nsw i32 %8852, %8851" -> "  %8865 = and i32 %8853, 65535""  %8853 = add nuw nsw i32 %8852, %8851" -> "  %8854 = lshr i32 %8853, 16"
"  %8854 = lshr i32 %8853, 16"
"  %8854 = lshr i32 %8853, 16" -> "  %8855 = add i32 %8850, %8854"
"  %8855 = add i32 %8850, %8854"
"  %8855 = add i32 %8850, %8854" -> "  %8884 = lshr i32 %8855, 16""  %8855 = add i32 %8850, %8854" -> "  %8882 = and i32 %8855, 65535"
"  %8856 = lshr i32 %8684, 16"
"  %8856 = lshr i32 %8684, 16" -> "  %8857 = add nuw i32 %8856, %8692"
"  %8857 = add nuw i32 %8856, %8692"
"  %8857 = add nuw i32 %8856, %8692" -> "  %8861 = and i32 %8857, -65536""  %8857 = add nuw i32 %8856, %8692" -> "  %8859 = and i32 %8857, 65535"
"  %8858 = lshr i32 %8686, 16"
"  %8858 = lshr i32 %8686, 16" -> "  %8860 = add nuw nsw i32 %8858, %8859"
"  %8859 = and i32 %8857, 65535"
"  %8859 = and i32 %8857, 65535" -> "  %8860 = add nuw nsw i32 %8858, %8859"
"  %8860 = add nuw nsw i32 %8858, %8859"
"  %8860 = add nuw nsw i32 %8858, %8859" -> "  %8862 = add i32 %8860, %8861"
"  %8861 = and i32 %8857, -65536"
"  %8861 = and i32 %8857, -65536" -> "  %8862 = add i32 %8860, %8861"
"  %8862 = add i32 %8860, %8861"
"  %8862 = add i32 %8860, %8861" -> "  %8869 = add i32 %8862, %8868"
"  %8863 = and i32 %8845, 65535"
"  %8863 = and i32 %8845, 65535" -> "  %8864 = add nuw nsw i32 %8701, %8863"
"  %8864 = add nuw nsw i32 %8701, %8863"
"  %8864 = add nuw nsw i32 %8701, %8863" -> "  %8917 = and i32 %8864, 65535""  %8864 = add nuw nsw i32 %8701, %8863" -> "  %8871 = lshr i32 %8864, 16"
"  %8865 = and i32 %8853, 65535"
"  %8865 = and i32 %8853, 65535" -> "  %8867 = add nuw nsw i32 %8866, %8865"
"  %8866 = and i32 %8686, 65535"
"  %8866 = and i32 %8686, 65535" -> "  %8867 = add nuw nsw i32 %8866, %8865"
"  %8867 = add nuw nsw i32 %8866, %8865"
"  %8867 = add nuw nsw i32 %8866, %8865" -> "  %8870 = and i32 %8867, 65535""  %8867 = add nuw nsw i32 %8866, %8865" -> "  %8868 = lshr i32 %8867, 16"
"  %8868 = lshr i32 %8867, 16"
"  %8868 = lshr i32 %8867, 16" -> "  %8869 = add i32 %8862, %8868"
"  %8869 = add i32 %8862, %8868"
"  %8869 = add i32 %8862, %8868" -> "  %8874 = add i32 %8869, %8873"
"  %8870 = and i32 %8867, 65535"
"  %8870 = and i32 %8867, 65535" -> "  %8872 = add nuw nsw i32 %8870, %8871"
"  %8871 = lshr i32 %8864, 16"
"  %8871 = lshr i32 %8864, 16" -> "  %8872 = add nuw nsw i32 %8870, %8871"
"  %8872 = add nuw nsw i32 %8870, %8871"
"  %8872 = add nuw nsw i32 %8870, %8871" -> "  %8920 = and i32 %8872, 65535""  %8872 = add nuw nsw i32 %8870, %8871" -> "  %8873 = lshr i32 %8872, 16"
"  %8873 = lshr i32 %8872, 16"
"  %8873 = lshr i32 %8872, 16" -> "  %8874 = add i32 %8869, %8873"
"  %8874 = add i32 %8869, %8873"
"  %8874 = add i32 %8869, %8873" -> "  %8898 = lshr i32 %8874, 16""  %8874 = add i32 %8869, %8873" -> "  %8895 = and i32 %8874, 65535"
"  %8875 = lshr i32 %8749, 16"
"  %8875 = lshr i32 %8749, 16" -> "  %8876 = add nuw i32 %8875, %8757"
"  %8876 = add nuw i32 %8875, %8757"
"  %8876 = add nuw i32 %8875, %8757" -> "  %8880 = and i32 %8876, -65536""  %8876 = add nuw i32 %8875, %8757" -> "  %8878 = and i32 %8876, 65535"
"  %8877 = lshr i32 %8751, 16"
"  %8877 = lshr i32 %8751, 16" -> "  %8879 = add nuw nsw i32 %8878, %8877"
"  %8878 = and i32 %8876, 65535"
"  %8878 = and i32 %8876, 65535" -> "  %8879 = add nuw nsw i32 %8878, %8877"
"  %8879 = add nuw nsw i32 %8878, %8877"
"  %8879 = add nuw nsw i32 %8878, %8877" -> "  %8881 = add i32 %8879, %8880"
"  %8880 = and i32 %8876, -65536"
"  %8880 = and i32 %8876, -65536" -> "  %8881 = add i32 %8879, %8880"
"  %8881 = add i32 %8879, %8880"
"  %8881 = add i32 %8879, %8880" -> "  %8888 = add i32 %8881, %8887"
"  %8882 = and i32 %8855, 65535"
"  %8882 = and i32 %8855, 65535" -> "  %8883 = add nuw nsw i32 %8882, %8768"
"  %8883 = add nuw nsw i32 %8882, %8768"
"  %8883 = add nuw nsw i32 %8882, %8768" -> "  %8894 = and i32 %8883, 65535""  %8883 = add nuw nsw i32 %8882, %8768" -> "  %8890 = lshr i32 %8883, 16"
"  %8884 = lshr i32 %8855, 16"
"  %8884 = lshr i32 %8855, 16" -> "  %8886 = add nuw nsw i32 %8885, %8884"
"  %8885 = and i32 %8751, 65535"
"  %8885 = and i32 %8751, 65535" -> "  %8886 = add nuw nsw i32 %8885, %8884"
"  %8886 = add nuw nsw i32 %8885, %8884"
"  %8886 = add nuw nsw i32 %8885, %8884" -> "  %8889 = and i32 %8886, 65535""  %8886 = add nuw nsw i32 %8885, %8884" -> "  %8887 = lshr i32 %8886, 16"
"  %8887 = lshr i32 %8886, 16"
"  %8887 = lshr i32 %8886, 16" -> "  %8888 = add i32 %8881, %8887"
"  %8888 = add i32 %8881, %8887"
"  %8888 = add i32 %8881, %8887" -> "  %8893 = add i32 %8888, %8892"
"  %8889 = and i32 %8886, 65535"
"  %8889 = and i32 %8886, 65535" -> "  %8891 = add nuw nsw i32 %8889, %8890"
"  %8890 = lshr i32 %8883, 16"
"  %8890 = lshr i32 %8883, 16" -> "  %8891 = add nuw nsw i32 %8889, %8890"
"  %8891 = add nuw nsw i32 %8889, %8890"
"  %8891 = add nuw nsw i32 %8889, %8890" -> "  %8897 = and i32 %8891, 65535""  %8891 = add nuw nsw i32 %8889, %8890" -> "  %8892 = lshr i32 %8891, 16"
"  %8892 = lshr i32 %8891, 16"
"  %8892 = lshr i32 %8891, 16" -> "  %8893 = add i32 %8888, %8892"
"  %8893 = add i32 %8888, %8892"
"  %8893 = add i32 %8888, %8892" -> "  %8901 = add i32 %8893, %8900"
"  %8894 = and i32 %8883, 65535"
"  %8894 = and i32 %8883, 65535" -> "  %8896 = add nuw nsw i32 %8895, %8894"
"  %8895 = and i32 %8874, 65535"
"  %8895 = and i32 %8874, 65535" -> "  %8896 = add nuw nsw i32 %8895, %8894"
"  %8896 = add nuw nsw i32 %8895, %8894"
"  %8896 = add nuw nsw i32 %8895, %8894" -> "  %8932 = and i32 %8896, 65535""  %8896 = add nuw nsw i32 %8895, %8894" -> "  %8903 = lshr i32 %8896, 16"
"  %8897 = and i32 %8891, 65535"
"  %8897 = and i32 %8891, 65535" -> "  %8899 = add nuw nsw i32 %8898, %8897"
"  %8898 = lshr i32 %8874, 16"
"  %8898 = lshr i32 %8874, 16" -> "  %8899 = add nuw nsw i32 %8898, %8897"
"  %8899 = add nuw nsw i32 %8898, %8897"
"  %8899 = add nuw nsw i32 %8898, %8897" -> "  %8902 = and i32 %8899, 65535""  %8899 = add nuw nsw i32 %8898, %8897" -> "  %8900 = lshr i32 %8899, 16"
"  %8900 = lshr i32 %8899, 16"
"  %8900 = lshr i32 %8899, 16" -> "  %8901 = add i32 %8893, %8900"
"  %8901 = add i32 %8893, %8900"
"  %8901 = add i32 %8893, %8900" -> "  %8906 = add i32 %8901, %8905"
"  %8902 = and i32 %8899, 65535"
"  %8902 = and i32 %8899, 65535" -> "  %8904 = add nuw nsw i32 %8902, %8903"
"  %8903 = lshr i32 %8896, 16"
"  %8903 = lshr i32 %8896, 16" -> "  %8904 = add nuw nsw i32 %8902, %8903"
"  %8904 = add nuw nsw i32 %8902, %8903"
"  %8904 = add nuw nsw i32 %8902, %8903" -> "  %8939 = and i32 %8904, 65535""  %8904 = add nuw nsw i32 %8902, %8903" -> "  %8905 = lshr i32 %8904, 16"
"  %8905 = lshr i32 %8904, 16"
"  %8905 = lshr i32 %8904, 16" -> "  %8906 = add i32 %8901, %8905"
"  %8906 = add i32 %8901, %8905"
"  %8906 = add i32 %8901, %8905" -> "  %8943 = add i32 %8906, %8942"
"  %8907 = and i32 %8797, 65535"
"  %8907 = and i32 %8797, 65535" -> "  %8908 = add nuw nsw i32 %8907, %8795"
"  %8908 = add nuw nsw i32 %8907, %8795"
"  %8908 = add nuw nsw i32 %8907, %8795" -> "  %9270 = and i32 %8908, 65535""  %8908 = add nuw nsw i32 %8907, %8795" -> "  %8912 = lshr i32 %8908, 16"
"  %8909 = and i32 %8662, 65535"
"  %8909 = and i32 %8662, 65535" -> "  %8911 = add nuw nsw i32 %8910, %8909"
"  %8910 = and i32 %8800, 65535"
"  %8910 = and i32 %8800, 65535" -> "  %8911 = add nuw nsw i32 %8910, %8909"
"  %8911 = add nuw nsw i32 %8910, %8909"
"  %8911 = add nuw nsw i32 %8910, %8909" -> "  %8915 = lshr i32 %8911, 16""  %8911 = add nuw nsw i32 %8910, %8909" -> "  %8913 = and i32 %8911, 65535"
"  %8912 = lshr i32 %8908, 16"
"  %8912 = lshr i32 %8908, 16" -> "  %8914 = add nuw nsw i32 %8913, %8912"
"  %8913 = and i32 %8911, 65535"
"  %8913 = and i32 %8911, 65535" -> "  %8914 = add nuw nsw i32 %8913, %8912"
"  %8914 = add nuw nsw i32 %8913, %8912"
"  %8914 = add nuw nsw i32 %8913, %8912" -> "  %9273 = and i32 %8914, 65535""  %8914 = add nuw nsw i32 %8913, %8912" -> "  %8916 = lshr i32 %8914, 16"
"  %8915 = lshr i32 %8911, 16"
"  %8915 = lshr i32 %8911, 16" -> "  %8927 = add nuw nsw i32 %8916, %8915"
"  %8916 = lshr i32 %8914, 16"
"  %8916 = lshr i32 %8914, 16" -> "  %8927 = add nuw nsw i32 %8916, %8915"
"  %8917 = and i32 %8864, 65535"
"  %8917 = and i32 %8864, 65535" -> "  %8919 = add nuw nsw i32 %8918, %8917"
"  %8918 = and i32 %8814, 65535"
"  %8918 = and i32 %8814, 65535" -> "  %8919 = add nuw nsw i32 %8918, %8917"
"  %8919 = add nuw nsw i32 %8918, %8917"
"  %8919 = add nuw nsw i32 %8918, %8917" -> "  %8926 = and i32 %8919, 65535""  %8919 = add nuw nsw i32 %8918, %8917" -> "  %8923 = lshr i32 %8919, 16"
"  %8920 = and i32 %8872, 65535"
"  %8920 = and i32 %8872, 65535" -> "  %8922 = add nuw nsw i32 %8921, %8920"
"  %8921 = and i32 %8817, 65535"
"  %8921 = and i32 %8817, 65535" -> "  %8922 = add nuw nsw i32 %8921, %8920"
"  %8922 = add nuw nsw i32 %8921, %8920"
"  %8922 = add nuw nsw i32 %8921, %8920" -> "  %8933 = lshr i32 %8922, 16""  %8922 = add nuw nsw i32 %8921, %8920" -> "  %8924 = and i32 %8922, 65535"
"  %8923 = lshr i32 %8919, 16"
"  %8923 = lshr i32 %8919, 16" -> "  %8925 = add nuw nsw i32 %8924, %8923"
"  %8924 = and i32 %8922, 65535"
"  %8924 = and i32 %8922, 65535" -> "  %8925 = add nuw nsw i32 %8924, %8923"
"  %8925 = add nuw nsw i32 %8924, %8923"
"  %8925 = add nuw nsw i32 %8924, %8923" -> "  %8935 = lshr i32 %8925, 16""  %8925 = add nuw nsw i32 %8924, %8923" -> "  %8930 = and i32 %8925, 65535"
"  %8926 = and i32 %8919, 65535"
"  %8926 = and i32 %8919, 65535" -> "  %8928 = add nuw nsw i32 %8927, %8926"
"  %8927 = add nuw nsw i32 %8916, %8915"
"  %8927 = add nuw nsw i32 %8916, %8915" -> "  %8928 = add nuw nsw i32 %8927, %8926"
"  %8928 = add nuw nsw i32 %8927, %8926"
"  %8928 = add nuw nsw i32 %8927, %8926" -> "  %9290 = and i32 %8928, 65535""  %8928 = add nuw nsw i32 %8927, %8926" -> "  %8929 = lshr i32 %8928, 16"
"  %8929 = lshr i32 %8928, 16"
"  %8929 = lshr i32 %8928, 16" -> "  %8931 = add nuw nsw i32 %8930, %8929"
"  %8930 = and i32 %8925, 65535"
"  %8930 = and i32 %8925, 65535" -> "  %8931 = add nuw nsw i32 %8930, %8929"
"  %8931 = add nuw nsw i32 %8930, %8929"
"  %8931 = add nuw nsw i32 %8930, %8929" -> "  %12514 = add i32 %12513, %8931""  %8931 = add nuw nsw i32 %8930, %8929" -> "  %9293 = and i32 %8931, 65535""  %8931 = add nuw nsw i32 %8930, %8929" -> "  %8937 = lshr i32 %8931, 16"
"  %8932 = and i32 %8896, 65535"
"  %8932 = and i32 %8896, 65535" -> "  %8934 = add nuw nsw i32 %8933, %8932"
"  %8933 = lshr i32 %8922, 16"
"  %8933 = lshr i32 %8922, 16" -> "  %8934 = add nuw nsw i32 %8933, %8932"
"  %8934 = add nuw nsw i32 %8933, %8932"
"  %8934 = add nuw nsw i32 %8933, %8932" -> "  %8936 = add nuw nsw i32 %8934, %8935"
"  %8935 = lshr i32 %8925, 16"
"  %8935 = lshr i32 %8925, 16" -> "  %8936 = add nuw nsw i32 %8934, %8935"
"  %8936 = add nuw nsw i32 %8934, %8935"
"  %8936 = add nuw nsw i32 %8934, %8935" -> "  %8938 = add nuw nsw i32 %8936, %8937"
"  %8937 = lshr i32 %8931, 16"
"  %8937 = lshr i32 %8931, 16" -> "  %8938 = add nuw nsw i32 %8936, %8937"
"  %8938 = add nuw nsw i32 %8936, %8937"
"  %8938 = add nuw nsw i32 %8936, %8937" -> "  %9099 = and i32 %8938, 65535""  %8938 = add nuw nsw i32 %8936, %8937" -> "  %8940 = lshr i32 %8938, 16"
"  %8939 = and i32 %8904, 65535"
"  %8939 = and i32 %8904, 65535" -> "  %8941 = add nuw nsw i32 %8940, %8939"
"  %8940 = lshr i32 %8938, 16"
"  %8940 = lshr i32 %8938, 16" -> "  %8941 = add nuw nsw i32 %8940, %8939"
"  %8941 = add nuw nsw i32 %8940, %8939"
"  %8941 = add nuw nsw i32 %8940, %8939" -> "  %9102 = and i32 %8941, 65535""  %8941 = add nuw nsw i32 %8940, %8939" -> "  %8942 = lshr i32 %8941, 16"
"  %8942 = lshr i32 %8941, 16"
"  %8942 = lshr i32 %8941, 16" -> "  %8943 = add i32 %8906, %8942"
"  %8943 = add i32 %8906, %8942"
"  %8943 = add i32 %8906, %8942" -> "  %9108 = and i32 %8943, 65535""  %8943 = add i32 %8906, %8942" -> "  %9111 = lshr i32 %8943, 16"
"  %8944 = mul nuw i32 %8649, %8649"
"  %8944 = mul nuw i32 %8649, %8649" -> "  %8945 = lshr i32 %8944, 16""  %8944 = mul nuw i32 %8649, %8649" -> "  %9060 = and i32 %8944, 65535"
"  %8945 = lshr i32 %8944, 16"
"  %8945 = lshr i32 %8944, 16" -> "  %8948 = add nuw nsw i32 %8947, %8945"
"  %8946 = mul nuw i32 %8652, %8649"
"  %8946 = mul nuw i32 %8652, %8649" -> "  %8952 = add nuw i32 %8951, %8946""  %8946 = mul nuw i32 %8652, %8649" -> "  %8949 = and i32 %8946, -65536""  %8946 = mul nuw i32 %8652, %8649" -> "  %8947 = and i32 %8946, 65535"
"  %8947 = and i32 %8946, 65535"
"  %8947 = and i32 %8946, 65535" -> "  %8948 = add nuw nsw i32 %8947, %8945"
"  %8948 = add nuw nsw i32 %8947, %8945"
"  %8948 = add nuw nsw i32 %8947, %8945" -> "  %8950 = add nuw i32 %8948, %8949"
"  %8949 = and i32 %8946, -65536"
"  %8949 = and i32 %8946, -65536" -> "  %8950 = add nuw i32 %8948, %8949"
"  %8950 = add nuw i32 %8948, %8949"
"  %8950 = add nuw i32 %8948, %8949" -> "  %8953 = lshr i32 %8950, 16""  %8950 = add nuw i32 %8948, %8949" -> "  %8951 = and i32 %8950, 65535"
"  %8951 = and i32 %8950, 65535"
"  %8951 = and i32 %8950, 65535" -> "  %8952 = add nuw i32 %8951, %8946"
"  %8952 = add nuw i32 %8951, %8946"
"  %8952 = add nuw i32 %8951, %8946" -> "  %9063 = and i32 %8952, 65535""  %8952 = add nuw i32 %8951, %8946" -> "  %8956 = lshr i32 %8952, 16"
"  %8953 = lshr i32 %8950, 16"
"  %8953 = lshr i32 %8950, 16" -> "  %8955 = add nuw i32 %8953, %8954"
"  %8954 = mul nuw i32 %8652, %8652"
"  %8954 = mul nuw i32 %8652, %8652" -> "  %8955 = add nuw i32 %8953, %8954"
"  %8955 = add nuw i32 %8953, %8954"
"  %8955 = add nuw i32 %8953, %8954" -> "  %8959 = and i32 %8955, -65536""  %8955 = add nuw i32 %8953, %8954" -> "  %8957 = and i32 %8955, 65535"
"  %8956 = lshr i32 %8952, 16"
"  %8956 = lshr i32 %8952, 16" -> "  %8958 = add nuw nsw i32 %8956, %8957"
"  %8957 = and i32 %8955, 65535"
"  %8957 = and i32 %8955, 65535" -> "  %8958 = add nuw nsw i32 %8956, %8957"
"  %8958 = add nuw nsw i32 %8956, %8957"
"  %8958 = add nuw nsw i32 %8956, %8957" -> "  %8960 = add i32 %8958, %8959"
"  %8959 = and i32 %8955, -65536"
"  %8959 = and i32 %8955, -65536" -> "  %8960 = add i32 %8958, %8959"
"  %8960 = add i32 %8958, %8959"
"  %8960 = add i32 %8958, %8959" -> "  %8988 = and i32 %8960, 65535""  %8960 = add i32 %8958, %8959" -> "  %8982 = lshr i32 %8960, 16"
"  %8961 = mul nuw i32 %8675, %8649"
"  %8961 = mul nuw i32 %8675, %8649" -> "  %8989 = and i32 %8961, 65535""  %8961 = mul nuw i32 %8675, %8649" -> "  %8962 = lshr i32 %8961, 16"
"  %8962 = lshr i32 %8961, 16"
"  %8962 = lshr i32 %8961, 16" -> "  %8967 = add nuw i32 %8962, %8966""  %8962 = lshr i32 %8961, 16" -> "  %8965 = add nuw nsw i32 %8964, %8962"
"  %8963 = mul nuw i32 %8678, %8649"
"  %8963 = mul nuw i32 %8678, %8649" -> "  %8969 = add nuw i32 %8968, %8963""  %8963 = mul nuw i32 %8678, %8649" -> "  %8970 = and i32 %8963, -65536""  %8963 = mul nuw i32 %8678, %8649" -> "  %8964 = and i32 %8963, 65535"
"  %8964 = and i32 %8963, 65535"
"  %8964 = and i32 %8963, 65535" -> "  %8965 = add nuw nsw i32 %8964, %8962"
"  %8965 = add nuw nsw i32 %8964, %8962"
"  %8965 = add nuw nsw i32 %8964, %8962" -> "  %8971 = add nuw i32 %8965, %8970"
"  %8966 = mul nuw i32 %8675, %8652"
"  %8966 = mul nuw i32 %8675, %8652" -> "  %8973 = add nuw i32 %8972, %8966""  %8966 = mul nuw i32 %8675, %8652" -> "  %8967 = add nuw i32 %8962, %8966"
"  %8967 = add nuw i32 %8962, %8966"
"  %8967 = add nuw i32 %8962, %8966" -> "  %8995 = lshr i32 %8967, 16""  %8967 = add nuw i32 %8962, %8966" -> "  %8968 = and i32 %8967, 65535"
"  %8968 = and i32 %8967, 65535"
"  %8968 = and i32 %8967, 65535" -> "  %8969 = add nuw i32 %8968, %8963"
"  %8969 = add nuw i32 %8968, %8963"
"  %8969 = add nuw i32 %8968, %8963" -> "  %9005 = and i32 %8969, 65535""  %8969 = add nuw i32 %8968, %8963" -> "  %8997 = lshr i32 %8969, 16"
"  %8970 = and i32 %8963, -65536"
"  %8970 = and i32 %8963, -65536" -> "  %8971 = add nuw i32 %8965, %8970"
"  %8971 = add nuw i32 %8965, %8970"
"  %8971 = add nuw i32 %8965, %8970" -> "  %8974 = lshr i32 %8971, 16""  %8971 = add nuw i32 %8965, %8970" -> "  %8972 = and i32 %8971, 65535"
"  %8972 = and i32 %8971, 65535"
"  %8972 = and i32 %8971, 65535" -> "  %8973 = add nuw i32 %8972, %8966"
"  %8973 = add nuw i32 %8972, %8966"
"  %8973 = add nuw i32 %8972, %8966" -> "  %8983 = and i32 %8973, 65535""  %8973 = add nuw i32 %8972, %8966" -> "  %8975 = lshr i32 %8973, 16"
"  %8974 = lshr i32 %8971, 16"
"  %8974 = lshr i32 %8971, 16" -> "  %8977 = add nuw i32 %8974, %8976"
"  %8975 = lshr i32 %8973, 16"
"  %8975 = lshr i32 %8973, 16" -> "  %8979 = add nuw nsw i32 %8978, %8975"
"  %8976 = mul nuw i32 %8678, %8652"
"  %8976 = mul nuw i32 %8678, %8652" -> "  %8996 = add nuw i32 %8995, %8976""  %8976 = mul nuw i32 %8678, %8652" -> "  %8977 = add nuw i32 %8974, %8976"
"  %8977 = add nuw i32 %8974, %8976"
"  %8977 = add nuw i32 %8974, %8976" -> "  %8980 = and i32 %8977, -65536""  %8977 = add nuw i32 %8974, %8976" -> "  %8978 = and i32 %8977, 65535"
"  %8978 = and i32 %8977, 65535"
"  %8978 = and i32 %8977, 65535" -> "  %8979 = add nuw nsw i32 %8978, %8975"
"  %8979 = add nuw nsw i32 %8978, %8975"
"  %8979 = add nuw nsw i32 %8978, %8975" -> "  %8981 = add i32 %8979, %8980"
"  %8980 = and i32 %8977, -65536"
"  %8980 = and i32 %8977, -65536" -> "  %8981 = add i32 %8979, %8980"
"  %8981 = add i32 %8979, %8980"
"  %8981 = add i32 %8979, %8980" -> "  %8986 = add i32 %8981, %8985"
"  %8982 = lshr i32 %8960, 16"
"  %8982 = lshr i32 %8960, 16" -> "  %8984 = add nuw nsw i32 %8983, %8982"
"  %8983 = and i32 %8973, 65535"
"  %8983 = and i32 %8973, 65535" -> "  %8984 = add nuw nsw i32 %8983, %8982"
"  %8984 = add nuw nsw i32 %8983, %8982"
"  %8984 = add nuw nsw i32 %8983, %8982" -> "  %8987 = and i32 %8984, 65535""  %8984 = add nuw nsw i32 %8983, %8982" -> "  %8985 = lshr i32 %8984, 16"
"  %8985 = lshr i32 %8984, 16"
"  %8985 = lshr i32 %8984, 16" -> "  %8986 = add i32 %8981, %8985"
"  %8986 = add i32 %8981, %8985"
"  %8986 = add i32 %8981, %8985" -> "  %8994 = add i32 %8986, %8993"
"  %8987 = and i32 %8984, 65535"
"  %8987 = and i32 %8984, 65535" -> "  %8992 = add nuw nsw i32 %8987, %8991"
"  %8988 = and i32 %8960, 65535"
"  %8988 = and i32 %8960, 65535" -> "  %8990 = add nuw nsw i32 %8988, %8989"
"  %8989 = and i32 %8961, 65535"
"  %8989 = and i32 %8961, 65535" -> "  %9003 = add nuw nsw i32 %9002, %8989""  %8989 = and i32 %8961, 65535" -> "  %8990 = add nuw nsw i32 %8988, %8989"
"  %8990 = add nuw nsw i32 %8988, %8989"
"  %8990 = add nuw nsw i32 %8988, %8989" -> "  %9002 = and i32 %8990, 65535""  %8990 = add nuw nsw i32 %8988, %8989" -> "  %8991 = lshr i32 %8990, 16"
"  %8991 = lshr i32 %8990, 16"
"  %8991 = lshr i32 %8990, 16" -> "  %8992 = add nuw nsw i32 %8987, %8991"
"  %8992 = add nuw nsw i32 %8987, %8991"
"  %8992 = add nuw nsw i32 %8987, %8991" -> "  %9004 = and i32 %8992, 65535""  %8992 = add nuw nsw i32 %8987, %8991" -> "  %8993 = lshr i32 %8992, 16"
"  %8993 = lshr i32 %8992, 16"
"  %8993 = lshr i32 %8992, 16" -> "  %8994 = add i32 %8986, %8993"
"  %8994 = add i32 %8986, %8993"
"  %8994 = add i32 %8986, %8993" -> "  %9035 = lshr i32 %8994, 16""  %8994 = add i32 %8986, %8993" -> "  %9031 = and i32 %8994, 65535"
"  %8995 = lshr i32 %8967, 16"
"  %8995 = lshr i32 %8967, 16" -> "  %8996 = add nuw i32 %8995, %8976"
"  %8996 = add nuw i32 %8995, %8976"
"  %8996 = add nuw i32 %8995, %8976" -> "  %9000 = and i32 %8996, -65536""  %8996 = add nuw i32 %8995, %8976" -> "  %8998 = and i32 %8996, 65535"
"  %8997 = lshr i32 %8969, 16"
"  %8997 = lshr i32 %8969, 16" -> "  %8999 = add nuw nsw i32 %8998, %8997"
"  %8998 = and i32 %8996, 65535"
"  %8998 = and i32 %8996, 65535" -> "  %8999 = add nuw nsw i32 %8998, %8997"
"  %8999 = add nuw nsw i32 %8998, %8997"
"  %8999 = add nuw nsw i32 %8998, %8997" -> "  %9001 = add i32 %8999, %9000"
"  %9000 = and i32 %8996, -65536"
"  %9000 = and i32 %8996, -65536" -> "  %9001 = add i32 %8999, %9000"
"  %9001 = add i32 %8999, %9000"
"  %9001 = add i32 %8999, %9000" -> "  %9008 = add i32 %9001, %9007"
"  %9002 = and i32 %8990, 65535"
"  %9002 = and i32 %8990, 65535" -> "  %9003 = add nuw nsw i32 %9002, %8989"
"  %9003 = add nuw nsw i32 %9002, %8989"
"  %9003 = add nuw nsw i32 %9002, %8989" -> "  %9069 = and i32 %9003, 65535""  %9003 = add nuw nsw i32 %9002, %8989" -> "  %9010 = lshr i32 %9003, 16"
"  %9004 = and i32 %8992, 65535"
"  %9004 = and i32 %8992, 65535" -> "  %9006 = add nuw nsw i32 %9004, %9005"
"  %9005 = and i32 %8969, 65535"
"  %9005 = and i32 %8969, 65535" -> "  %9006 = add nuw nsw i32 %9004, %9005"
"  %9006 = add nuw nsw i32 %9004, %9005"
"  %9006 = add nuw nsw i32 %9004, %9005" -> "  %9009 = and i32 %9006, 65535""  %9006 = add nuw nsw i32 %9004, %9005" -> "  %9007 = lshr i32 %9006, 16"
"  %9007 = lshr i32 %9006, 16"
"  %9007 = lshr i32 %9006, 16" -> "  %9008 = add i32 %9001, %9007"
"  %9008 = add i32 %9001, %9007"
"  %9008 = add i32 %9001, %9007" -> "  %9013 = add i32 %9008, %9012"
"  %9009 = and i32 %9006, 65535"
"  %9009 = and i32 %9006, 65535" -> "  %9011 = add nuw nsw i32 %9009, %9010"
"  %9010 = lshr i32 %9003, 16"
"  %9010 = lshr i32 %9003, 16" -> "  %9011 = add nuw nsw i32 %9009, %9010"
"  %9011 = add nuw nsw i32 %9009, %9010"
"  %9011 = add nuw nsw i32 %9009, %9010" -> "  %9072 = and i32 %9011, 65535""  %9011 = add nuw nsw i32 %9009, %9010" -> "  %9012 = lshr i32 %9011, 16"
"  %9012 = lshr i32 %9011, 16"
"  %9012 = lshr i32 %9011, 16" -> "  %9013 = add i32 %9008, %9012"
"  %9013 = add i32 %9008, %9012"
"  %9013 = add i32 %9008, %9012" -> "  %9048 = lshr i32 %9013, 16""  %9013 = add i32 %9008, %9012" -> "  %9045 = and i32 %9013, 65535"
"  %9014 = mul nuw i32 %8675, %8675"
"  %9014 = mul nuw i32 %8675, %8675" -> "  %9032 = and i32 %9014, 65535""  %9014 = mul nuw i32 %8675, %8675" -> "  %9015 = lshr i32 %9014, 16"
"  %9015 = lshr i32 %9014, 16"
"  %9015 = lshr i32 %9014, 16" -> "  %9018 = add nuw nsw i32 %9017, %9015"
"  %9016 = mul nuw i32 %8678, %8675"
"  %9016 = mul nuw i32 %8678, %8675" -> "  %9022 = add nuw i32 %9021, %9016""  %9016 = mul nuw i32 %8678, %8675" -> "  %9019 = and i32 %9016, -65536""  %9016 = mul nuw i32 %8678, %8675" -> "  %9017 = and i32 %9016, 65535"
"  %9017 = and i32 %9016, 65535"
"  %9017 = and i32 %9016, 65535" -> "  %9018 = add nuw nsw i32 %9017, %9015"
"  %9018 = add nuw nsw i32 %9017, %9015"
"  %9018 = add nuw nsw i32 %9017, %9015" -> "  %9020 = add nuw i32 %9018, %9019"
"  %9019 = and i32 %9016, -65536"
"  %9019 = and i32 %9016, -65536" -> "  %9020 = add nuw i32 %9018, %9019"
"  %9020 = add nuw i32 %9018, %9019"
"  %9020 = add nuw i32 %9018, %9019" -> "  %9023 = lshr i32 %9020, 16""  %9020 = add nuw i32 %9018, %9019" -> "  %9021 = and i32 %9020, 65535"
"  %9021 = and i32 %9020, 65535"
"  %9021 = and i32 %9020, 65535" -> "  %9022 = add nuw i32 %9021, %9016"
"  %9022 = add nuw i32 %9021, %9016"
"  %9022 = add nuw i32 %9021, %9016" -> "  %9034 = and i32 %9022, 65535""  %9022 = add nuw i32 %9021, %9016" -> "  %9026 = lshr i32 %9022, 16"
"  %9023 = lshr i32 %9020, 16"
"  %9023 = lshr i32 %9020, 16" -> "  %9025 = add nuw i32 %9023, %9024"
"  %9024 = mul nuw i32 %8678, %8678"
"  %9024 = mul nuw i32 %8678, %8678" -> "  %9025 = add nuw i32 %9023, %9024"
"  %9025 = add nuw i32 %9023, %9024"
"  %9025 = add nuw i32 %9023, %9024" -> "  %9029 = and i32 %9025, -65536""  %9025 = add nuw i32 %9023, %9024" -> "  %9027 = and i32 %9025, 65535"
"  %9026 = lshr i32 %9022, 16"
"  %9026 = lshr i32 %9022, 16" -> "  %9028 = add nuw nsw i32 %9026, %9027"
"  %9027 = and i32 %9025, 65535"
"  %9027 = and i32 %9025, 65535" -> "  %9028 = add nuw nsw i32 %9026, %9027"
"  %9028 = add nuw nsw i32 %9026, %9027"
"  %9028 = add nuw nsw i32 %9026, %9027" -> "  %9030 = add i32 %9028, %9029"
"  %9029 = and i32 %9025, -65536"
"  %9029 = and i32 %9025, -65536" -> "  %9030 = add i32 %9028, %9029"
"  %9030 = add i32 %9028, %9029"
"  %9030 = add i32 %9028, %9029" -> "  %9038 = add i32 %9030, %9037"
"  %9031 = and i32 %8994, 65535"
"  %9031 = and i32 %8994, 65535" -> "  %9033 = add nuw nsw i32 %9031, %9032"
"  %9032 = and i32 %9014, 65535"
"  %9032 = and i32 %9014, 65535" -> "  %9033 = add nuw nsw i32 %9031, %9032"
"  %9033 = add nuw nsw i32 %9031, %9032"
"  %9033 = add nuw nsw i32 %9031, %9032" -> "  %9044 = and i32 %9033, 65535""  %9033 = add nuw nsw i32 %9031, %9032" -> "  %9040 = lshr i32 %9033, 16"
"  %9034 = and i32 %9022, 65535"
"  %9034 = and i32 %9022, 65535" -> "  %9036 = add nuw nsw i32 %9035, %9034"
"  %9035 = lshr i32 %8994, 16"
"  %9035 = lshr i32 %8994, 16" -> "  %9036 = add nuw nsw i32 %9035, %9034"
"  %9036 = add nuw nsw i32 %9035, %9034"
"  %9036 = add nuw nsw i32 %9035, %9034" -> "  %9039 = and i32 %9036, 65535""  %9036 = add nuw nsw i32 %9035, %9034" -> "  %9037 = lshr i32 %9036, 16"
"  %9037 = lshr i32 %9036, 16"
"  %9037 = lshr i32 %9036, 16" -> "  %9038 = add i32 %9030, %9037"
"  %9038 = add i32 %9030, %9037"
"  %9038 = add i32 %9030, %9037" -> "  %9043 = add i32 %9038, %9042"
"  %9039 = and i32 %9036, 65535"
"  %9039 = and i32 %9036, 65535" -> "  %9041 = add nuw nsw i32 %9039, %9040"
"  %9040 = lshr i32 %9033, 16"
"  %9040 = lshr i32 %9033, 16" -> "  %9041 = add nuw nsw i32 %9039, %9040"
"  %9041 = add nuw nsw i32 %9039, %9040"
"  %9041 = add nuw nsw i32 %9039, %9040" -> "  %9047 = and i32 %9041, 65535""  %9041 = add nuw nsw i32 %9039, %9040" -> "  %9042 = lshr i32 %9041, 16"
"  %9042 = lshr i32 %9041, 16"
"  %9042 = lshr i32 %9041, 16" -> "  %9043 = add i32 %9038, %9042"
"  %9043 = add i32 %9038, %9042"
"  %9043 = add i32 %9038, %9042" -> "  %9056 = and i32 %9043, -65536""  %9043 = add i32 %9038, %9042" -> "  %9054 = and i32 %9043, 65535"
"  %9044 = and i32 %9033, 65535"
"  %9044 = and i32 %9033, 65535" -> "  %9046 = add nuw nsw i32 %9045, %9044"
"  %9045 = and i32 %9013, 65535"
"  %9045 = and i32 %9013, 65535" -> "  %9046 = add nuw nsw i32 %9045, %9044"
"  %9046 = add nuw nsw i32 %9045, %9044"
"  %9046 = add nuw nsw i32 %9045, %9044" -> "  %9086 = and i32 %9046, 65535""  %9046 = add nuw nsw i32 %9045, %9044" -> "  %9050 = lshr i32 %9046, 16"
"  %9047 = and i32 %9041, 65535"
"  %9047 = and i32 %9041, 65535" -> "  %9049 = add nuw nsw i32 %9047, %9048"
"  %9048 = lshr i32 %9013, 16"
"  %9048 = lshr i32 %9013, 16" -> "  %9049 = add nuw nsw i32 %9047, %9048"
"  %9049 = add nuw nsw i32 %9047, %9048"
"  %9049 = add nuw nsw i32 %9047, %9048" -> "  %9053 = lshr i32 %9049, 16""  %9049 = add nuw nsw i32 %9047, %9048" -> "  %9051 = and i32 %9049, 65535"
"  %9050 = lshr i32 %9046, 16"
"  %9050 = lshr i32 %9046, 16" -> "  %9052 = add nuw nsw i32 %9051, %9050"
"  %9051 = and i32 %9049, 65535"
"  %9051 = and i32 %9049, 65535" -> "  %9052 = add nuw nsw i32 %9051, %9050"
"  %9052 = add nuw nsw i32 %9051, %9050"
"  %9052 = add nuw nsw i32 %9051, %9050" -> "  %9093 = and i32 %9052, 65535""  %9052 = add nuw nsw i32 %9051, %9050" -> "  %9058 = lshr i32 %9052, 16"
"  %9053 = lshr i32 %9049, 16"
"  %9053 = lshr i32 %9049, 16" -> "  %9055 = add nuw nsw i32 %9053, %9054"
"  %9054 = and i32 %9043, 65535"
"  %9054 = and i32 %9043, 65535" -> "  %9055 = add nuw nsw i32 %9053, %9054"
"  %9055 = add nuw nsw i32 %9053, %9054"
"  %9055 = add nuw nsw i32 %9053, %9054" -> "  %9057 = add i32 %9055, %9056"
"  %9056 = and i32 %9043, -65536"
"  %9056 = and i32 %9043, -65536" -> "  %9057 = add i32 %9055, %9056"
"  %9057 = add i32 %9055, %9056"
"  %9057 = add i32 %9055, %9056" -> "  %9059 = add i32 %9057, %9058"
"  %9058 = lshr i32 %9052, 16"
"  %9058 = lshr i32 %9052, 16" -> "  %9059 = add i32 %9057, %9058"
"  %9059 = add i32 %9057, %9058"
"  %9059 = add i32 %9057, %9058" -> "  %9097 = add i32 %9059, %9096"
"  %9060 = and i32 %8944, 65535"
"  %9060 = and i32 %8944, 65535" -> "  %9062 = add nuw nsw i32 %9061, %9060"
"  %9061 = and i32 %8824, 65535"
"  %9061 = and i32 %8824, 65535" -> "  %9062 = add nuw nsw i32 %9061, %9060"
"  %9062 = add nuw nsw i32 %9061, %9060"
"  %9062 = add nuw nsw i32 %9061, %9060" -> "  %9098 = and i32 %9062, 65535""  %9062 = add nuw nsw i32 %9061, %9060" -> "  %9066 = lshr i32 %9062, 16"
"  %9063 = and i32 %8952, 65535"
"  %9063 = and i32 %8952, 65535" -> "  %9065 = add nuw nsw i32 %9064, %9063"
"  %9064 = and i32 %8827, 65535"
"  %9064 = and i32 %8827, 65535" -> "  %9065 = add nuw nsw i32 %9064, %9063"
"  %9065 = add nuw nsw i32 %9064, %9063"
"  %9065 = add nuw nsw i32 %9064, %9063" -> "  %9079 = lshr i32 %9065, 16""  %9065 = add nuw nsw i32 %9064, %9063" -> "  %9067 = and i32 %9065, 65535"
"  %9066 = lshr i32 %9062, 16"
"  %9066 = lshr i32 %9062, 16" -> "  %9068 = add nuw nsw i32 %9067, %9066"
"  %9067 = and i32 %9065, 65535"
"  %9067 = and i32 %9065, 65535" -> "  %9068 = add nuw nsw i32 %9067, %9066"
"  %9068 = add nuw nsw i32 %9067, %9066"
"  %9068 = add nuw nsw i32 %9067, %9066" -> "  %9101 = and i32 %9068, 65535""  %9068 = add nuw nsw i32 %9067, %9066" -> "  %9081 = lshr i32 %9068, 16"
"  %9069 = and i32 %9003, 65535"
"  %9069 = and i32 %9003, 65535" -> "  %9071 = add nuw nsw i32 %9070, %9069"
"  %9070 = and i32 %8829, 65535"
"  %9070 = and i32 %8829, 65535" -> "  %9071 = add nuw nsw i32 %9070, %9069"
"  %9071 = add nuw nsw i32 %9070, %9069"
"  %9071 = add nuw nsw i32 %9070, %9069" -> "  %9078 = and i32 %9071, 65535""  %9071 = add nuw nsw i32 %9070, %9069" -> "  %9075 = lshr i32 %9071, 16"
"  %9072 = and i32 %9011, 65535"
"  %9072 = and i32 %9011, 65535" -> "  %9074 = add nuw nsw i32 %9073, %9072"
"  %9073 = lshr i32 %8829, 16"
"  %9073 = lshr i32 %8829, 16" -> "  %9074 = add nuw nsw i32 %9073, %9072"
"  %9074 = add nuw nsw i32 %9073, %9072"
"  %9074 = add nuw nsw i32 %9073, %9072" -> "  %9087 = lshr i32 %9074, 16""  %9074 = add nuw nsw i32 %9073, %9072" -> "  %9076 = and i32 %9074, 65535"
"  %9075 = lshr i32 %9071, 16"
"  %9075 = lshr i32 %9071, 16" -> "  %9077 = add nuw nsw i32 %9075, %9076"
"  %9076 = and i32 %9074, 65535"
"  %9076 = and i32 %9074, 65535" -> "  %9077 = add nuw nsw i32 %9075, %9076"
"  %9077 = add nuw nsw i32 %9075, %9076"
"  %9077 = add nuw nsw i32 %9075, %9076" -> "  %9089 = lshr i32 %9077, 16""  %9077 = add nuw nsw i32 %9075, %9076" -> "  %9084 = and i32 %9077, 65535"
"  %9078 = and i32 %9071, 65535"
"  %9078 = and i32 %9071, 65535" -> "  %9080 = add nuw nsw i32 %9078, %9079"
"  %9079 = lshr i32 %9065, 16"
"  %9079 = lshr i32 %9065, 16" -> "  %9080 = add nuw nsw i32 %9078, %9079"
"  %9080 = add nuw nsw i32 %9078, %9079"
"  %9080 = add nuw nsw i32 %9078, %9079" -> "  %9082 = add nuw nsw i32 %9080, %9081"
"  %9081 = lshr i32 %9068, 16"
"  %9081 = lshr i32 %9068, 16" -> "  %9082 = add nuw nsw i32 %9080, %9081"
"  %9082 = add nuw nsw i32 %9080, %9081"
"  %9082 = add nuw nsw i32 %9080, %9081" -> "  %9107 = and i32 %9082, 65535""  %9082 = add nuw nsw i32 %9080, %9081" -> "  %9083 = lshr i32 %9082, 16"
"  %9083 = lshr i32 %9082, 16"
"  %9083 = lshr i32 %9082, 16" -> "  %9085 = add nuw nsw i32 %9083, %9084"
"  %9084 = and i32 %9077, 65535"
"  %9084 = and i32 %9077, 65535" -> "  %9085 = add nuw nsw i32 %9083, %9084"
"  %9085 = add nuw nsw i32 %9083, %9084"
"  %9085 = add nuw nsw i32 %9083, %9084" -> "  %9110 = and i32 %9085, 65535""  %9085 = add nuw nsw i32 %9083, %9084" -> "  %9091 = lshr i32 %9085, 16"
"  %9086 = and i32 %9046, 65535"
"  %9086 = and i32 %9046, 65535" -> "  %9088 = add nuw nsw i32 %9087, %9086"
"  %9087 = lshr i32 %9074, 16"
"  %9087 = lshr i32 %9074, 16" -> "  %9088 = add nuw nsw i32 %9087, %9086"
"  %9088 = add nuw nsw i32 %9087, %9086"
"  %9088 = add nuw nsw i32 %9087, %9086" -> "  %9090 = add nuw nsw i32 %9088, %9089"
"  %9089 = lshr i32 %9077, 16"
"  %9089 = lshr i32 %9077, 16" -> "  %9090 = add nuw nsw i32 %9088, %9089"
"  %9090 = add nuw nsw i32 %9088, %9089"
"  %9090 = add nuw nsw i32 %9088, %9089" -> "  %9092 = add nuw nsw i32 %9090, %9091"
"  %9091 = lshr i32 %9085, 16"
"  %9091 = lshr i32 %9085, 16" -> "  %9092 = add nuw nsw i32 %9090, %9091"
"  %9092 = add nuw nsw i32 %9090, %9091"
"  %9092 = add nuw nsw i32 %9090, %9091" -> "  %9124 = and i32 %9092, 65535""  %9092 = add nuw nsw i32 %9090, %9091" -> "  %9094 = lshr i32 %9092, 16"
"  %9093 = and i32 %9052, 65535"
"  %9093 = and i32 %9052, 65535" -> "  %9095 = add nuw nsw i32 %9094, %9093"
"  %9094 = lshr i32 %9092, 16"
"  %9094 = lshr i32 %9092, 16" -> "  %9095 = add nuw nsw i32 %9094, %9093"
"  %9095 = add nuw nsw i32 %9094, %9093"
"  %9095 = add nuw nsw i32 %9094, %9093" -> "  %9131 = and i32 %9095, 65535""  %9095 = add nuw nsw i32 %9094, %9093" -> "  %9096 = lshr i32 %9095, 16"
"  %9096 = lshr i32 %9095, 16"
"  %9096 = lshr i32 %9095, 16" -> "  %9097 = add i32 %9059, %9096"
"  %9097 = add i32 %9059, %9096"
"  %9097 = add i32 %9059, %9096" -> "  %9135 = add i32 %9097, %9134"
"  %9098 = and i32 %9062, 65535"
"  %9098 = and i32 %9062, 65535" -> "  %9100 = add nuw nsw i32 %9099, %9098"
"  %9099 = and i32 %8938, 65535"
"  %9099 = and i32 %8938, 65535" -> "  %9100 = add nuw nsw i32 %9099, %9098"
"  %9100 = add nuw nsw i32 %9099, %9098"
"  %9100 = add nuw nsw i32 %9099, %9098" -> "  %9798 = and i32 %9100, 65535""  %9100 = add nuw nsw i32 %9099, %9098" -> "  %9104 = lshr i32 %9100, 16"
"  %9101 = and i32 %9068, 65535"
"  %9101 = and i32 %9068, 65535" -> "  %9103 = add nuw nsw i32 %9102, %9101"
"  %9102 = and i32 %8941, 65535"
"  %9102 = and i32 %8941, 65535" -> "  %9103 = add nuw nsw i32 %9102, %9101"
"  %9103 = add nuw nsw i32 %9102, %9101"
"  %9103 = add nuw nsw i32 %9102, %9101" -> "  %9117 = lshr i32 %9103, 16""  %9103 = add nuw nsw i32 %9102, %9101" -> "  %9105 = and i32 %9103, 65535"
"  %9104 = lshr i32 %9100, 16"
"  %9104 = lshr i32 %9100, 16" -> "  %9106 = add nuw nsw i32 %9105, %9104"
"  %9105 = and i32 %9103, 65535"
"  %9105 = and i32 %9103, 65535" -> "  %9106 = add nuw nsw i32 %9105, %9104"
"  %9106 = add nuw nsw i32 %9105, %9104"
"  %9106 = add nuw nsw i32 %9105, %9104" -> "  %9799 = and i32 %9106, 65535""  %9106 = add nuw nsw i32 %9105, %9104" -> "  %9118 = lshr i32 %9106, 16"
"  %9107 = and i32 %9082, 65535"
"  %9107 = and i32 %9082, 65535" -> "  %9109 = add nuw nsw i32 %9108, %9107"
"  %9108 = and i32 %8943, 65535"
"  %9108 = and i32 %8943, 65535" -> "  %9109 = add nuw nsw i32 %9108, %9107"
"  %9109 = add nuw nsw i32 %9108, %9107"
"  %9109 = add nuw nsw i32 %9108, %9107" -> "  %9116 = and i32 %9109, 65535""  %9109 = add nuw nsw i32 %9108, %9107" -> "  %9113 = lshr i32 %9109, 16"
"  %9110 = and i32 %9085, 65535"
"  %9110 = and i32 %9085, 65535" -> "  %9112 = add nuw nsw i32 %9110, %9111"
"  %9111 = lshr i32 %8943, 16"
"  %9111 = lshr i32 %8943, 16" -> "  %9112 = add nuw nsw i32 %9110, %9111"
"  %9112 = add nuw nsw i32 %9110, %9111"
"  %9112 = add nuw nsw i32 %9110, %9111" -> "  %9125 = lshr i32 %9112, 16""  %9112 = add nuw nsw i32 %9110, %9111" -> "  %9114 = and i32 %9112, 65535"
"  %9113 = lshr i32 %9109, 16"
"  %9113 = lshr i32 %9109, 16" -> "  %9115 = add nuw nsw i32 %9114, %9113"
"  %9114 = and i32 %9112, 65535"
"  %9114 = and i32 %9112, 65535" -> "  %9115 = add nuw nsw i32 %9114, %9113"
"  %9115 = add nuw nsw i32 %9114, %9113"
"  %9115 = add nuw nsw i32 %9114, %9113" -> "  %9127 = lshr i32 %9115, 16""  %9115 = add nuw nsw i32 %9114, %9113" -> "  %9122 = and i32 %9115, 65535"
"  %9116 = and i32 %9109, 65535"
"  %9116 = and i32 %9109, 65535" -> "  %9120 = add nuw nsw i32 %9119, %9116"
"  %9117 = lshr i32 %9103, 16"
"  %9117 = lshr i32 %9103, 16" -> "  %9119 = add nuw nsw i32 %9118, %9117"
"  %9118 = lshr i32 %9106, 16"
"  %9118 = lshr i32 %9106, 16" -> "  %9119 = add nuw nsw i32 %9118, %9117"
"  %9119 = add nuw nsw i32 %9118, %9117"
"  %9119 = add nuw nsw i32 %9118, %9117" -> "  %9120 = add nuw nsw i32 %9119, %9116"
"  %9120 = add nuw nsw i32 %9119, %9116"
"  %9120 = add nuw nsw i32 %9119, %9116" -> "  %9819 = and i32 %9120, 65535""  %9120 = add nuw nsw i32 %9119, %9116" -> "  %9121 = lshr i32 %9120, 16"
"  %9121 = lshr i32 %9120, 16"
"  %9121 = lshr i32 %9120, 16" -> "  %9123 = add nuw nsw i32 %9122, %9121"
"  %9122 = and i32 %9115, 65535"
"  %9122 = and i32 %9115, 65535" -> "  %9123 = add nuw nsw i32 %9122, %9121"
"  %9123 = add nuw nsw i32 %9122, %9121"
"  %9123 = add nuw nsw i32 %9122, %9121" -> "  %9818 = and i32 %9123, 65535""  %9123 = add nuw nsw i32 %9122, %9121" -> "  %9129 = lshr i32 %9123, 16"
"  %9124 = and i32 %9092, 65535"
"  %9124 = and i32 %9092, 65535" -> "  %9126 = add nuw nsw i32 %9125, %9124"
"  %9125 = lshr i32 %9112, 16"
"  %9125 = lshr i32 %9112, 16" -> "  %9126 = add nuw nsw i32 %9125, %9124"
"  %9126 = add nuw nsw i32 %9125, %9124"
"  %9126 = add nuw nsw i32 %9125, %9124" -> "  %9128 = add nuw nsw i32 %9126, %9127"
"  %9127 = lshr i32 %9115, 16"
"  %9127 = lshr i32 %9115, 16" -> "  %9128 = add nuw nsw i32 %9126, %9127"
"  %9128 = add nuw nsw i32 %9126, %9127"
"  %9128 = add nuw nsw i32 %9126, %9127" -> "  %9130 = add nuw nsw i32 %9128, %9129"
"  %9129 = lshr i32 %9123, 16"
"  %9129 = lshr i32 %9123, 16" -> "  %9130 = add nuw nsw i32 %9128, %9129"
"  %9130 = add nuw nsw i32 %9128, %9129"
"  %9130 = add nuw nsw i32 %9128, %9129" -> "  %9932 = and i32 %9130, 65535""  %9130 = add nuw nsw i32 %9128, %9129" -> "  %9132 = lshr i32 %9130, 16"
"  %9131 = and i32 %9095, 65535"
"  %9131 = and i32 %9095, 65535" -> "  %9133 = add nuw nsw i32 %9132, %9131"
"  %9132 = lshr i32 %9130, 16"
"  %9132 = lshr i32 %9130, 16" -> "  %9133 = add nuw nsw i32 %9132, %9131"
"  %9133 = add nuw nsw i32 %9132, %9131"
"  %9133 = add nuw nsw i32 %9132, %9131" -> "  %9935 = and i32 %9133, 65535""  %9133 = add nuw nsw i32 %9132, %9131" -> "  %9134 = lshr i32 %9133, 16"
"  %9134 = lshr i32 %9133, 16"
"  %9134 = lshr i32 %9133, 16" -> "  %9135 = add i32 %9097, %9134"
"  %9135 = add i32 %9097, %9134"
"  %9135 = add i32 %9097, %9134" -> "  %9952 = and i32 %9135, 65535""  %9135 = add i32 %9097, %9134" -> "  %9953 = lshr i32 %9135, 16"
"  %9136 = and i32 %8525, 65535"
"  %9136 = and i32 %8525, 65535" -> "  %12476 = add nuw nsw i32 %12475, %9136""  %9136 = and i32 %8525, 65535" -> "  %10905 = mul nuw i32 %9136, 36786""  %9136 = and i32 %8525, 65535" -> "  %10898 = mul nuw nsw i32 %9136, 21884""  %9136 = and i32 %8525, 65535" -> "  %9439 = mul nuw nsw i32 %9136, 17857""  %9136 = and i32 %8525, 65535" -> "  %9138 = mul nuw i32 %9136, 37996""  %9136 = and i32 %8525, 65535" -> "  %9145 = mul nuw i32 %9136, 45147""  %9136 = and i32 %8525, 65535" -> "  %9192 = mul nuw nsw i32 %9136, 1324""  %9136 = and i32 %8525, 65535" -> "  %9199 = mul nuw i32 %9136, 62728""  %9136 = and i32 %8525, 65535" -> "  %9495 = mul nuw i32 %9136, 42170""  %9136 = and i32 %8525, 65535" -> "  %9488 = mul nuw nsw i32 %9136, 31112""  %9136 = and i32 %8525, 65535" -> "  %9446 = mul nuw i32 %9136, 46547""  %9136 = and i32 %8525, 65535" -> "  %10616 = mul nuw nsw i32 %9136, 29744""  %9136 = and i32 %8525, 65535" -> "  %10609 = mul nuw nsw i32 %9136, 24315""  %9136 = and i32 %8525, 65535" -> "  %10567 = mul nuw nsw i32 %9136, 9871""  %9136 = and i32 %8525, 65535" -> "  %10560 = mul nuw i32 %9136, 42779""  %9136 = and i32 %8525, 65535" -> "  %10856 = mul nuw nsw i32 %9136, 11561""  %9136 = and i32 %8525, 65535" -> "  %10849 = mul nuw nsw i32 %9136, 4087"
"  %9137 = and i32 %8533, 65535"
"  %9137 = and i32 %8533, 65535" -> "  %12478 = add nuw nsw i32 %12477, %9137""  %9137 = and i32 %8533, 65535" -> "  %9140 = mul nuw i32 %9137, 37996""  %9137 = and i32 %8533, 65535" -> "  %9149 = mul nuw i32 %9137, 45147""  %9137 = and i32 %8533, 65535" -> "  %9194 = mul nuw nsw i32 %9137, 1324""  %9137 = and i32 %8533, 65535" -> "  %9203 = mul nuw i32 %9137, 62728""  %9137 = and i32 %8533, 65535" -> "  %9499 = mul nuw i32 %9137, 42170""  %9137 = and i32 %8533, 65535" -> "  %9490 = mul nuw nsw i32 %9137, 31112""  %9137 = and i32 %8533, 65535" -> "  %9450 = mul nuw i32 %9137, 46547""  %9137 = and i32 %8533, 65535" -> "  %9441 = mul nuw nsw i32 %9137, 17857""  %9137 = and i32 %8533, 65535" -> "  %10620 = mul nuw nsw i32 %9137, 29744""  %9137 = and i32 %8533, 65535" -> "  %10611 = mul nuw nsw i32 %9137, 24315""  %9137 = and i32 %8533, 65535" -> "  %10571 = mul nuw nsw i32 %9137, 9871""  %9137 = and i32 %8533, 65535" -> "  %10562 = mul nuw i32 %9137, 42779""  %9137 = and i32 %8533, 65535" -> "  %10909 = mul nuw i32 %9137, 36786""  %9137 = and i32 %8533, 65535" -> "  %10900 = mul nuw nsw i32 %9137, 21884""  %9137 = and i32 %8533, 65535" -> "  %10860 = mul nuw nsw i32 %9137, 11561""  %9137 = and i32 %8533, 65535" -> "  %10851 = mul nuw nsw i32 %9137, 4087"
"  %9138 = mul nuw i32 %9136, 37996"
"  %9138 = mul nuw i32 %9136, 37996" -> "  %9139 = lshr i32 %9138, 16"
"  %9139 = lshr i32 %9138, 16"
"  %9139 = lshr i32 %9138, 16" -> "  %9142 = add nuw nsw i32 %9141, %9139"
"  %9140 = mul nuw i32 %9137, 37996"
"  %9140 = mul nuw i32 %9137, 37996" -> "  %9143 = and i32 %9140, -65536""  %9140 = mul nuw i32 %9137, 37996" -> "  %9141 = and i32 %9140, 65532"
"  %9141 = and i32 %9140, 65532"
"  %9141 = and i32 %9140, 65532" -> "  %9142 = add nuw nsw i32 %9141, %9139"
"  %9142 = add nuw nsw i32 %9141, %9139"
"  %9142 = add nuw nsw i32 %9141, %9139" -> "  %9144 = add nuw i32 %9142, %9143"
"  %9143 = and i32 %9140, -65536"
"  %9143 = and i32 %9140, -65536" -> "  %9144 = add nuw i32 %9142, %9143"
"  %9144 = add nuw i32 %9142, %9143"
"  %9144 = add nuw i32 %9142, %9143" -> "  %9148 = lshr i32 %9144, 16""  %9144 = add nuw i32 %9142, %9143" -> "  %9146 = and i32 %9144, 65535"
"  %9145 = mul nuw i32 %9136, 45147"
"  %9145 = mul nuw i32 %9136, 45147" -> "  %9147 = add nuw i32 %9146, %9145"
"  %9146 = and i32 %9144, 65535"
"  %9146 = and i32 %9144, 65535" -> "  %9147 = add nuw i32 %9146, %9145"
"  %9147 = add nuw i32 %9146, %9145"
"  %9147 = add nuw i32 %9146, %9145" -> "  %9151 = lshr i32 %9147, 16"
"  %9148 = lshr i32 %9144, 16"
"  %9148 = lshr i32 %9144, 16" -> "  %9150 = add nuw i32 %9148, %9149"
"  %9149 = mul nuw i32 %9137, 45147"
"  %9149 = mul nuw i32 %9137, 45147" -> "  %9150 = add nuw i32 %9148, %9149"
"  %9150 = add nuw i32 %9148, %9149"
"  %9150 = add nuw i32 %9148, %9149" -> "  %9154 = and i32 %9150, -65536""  %9150 = add nuw i32 %9148, %9149" -> "  %9152 = and i32 %9150, 65535"
"  %9151 = lshr i32 %9147, 16"
"  %9151 = lshr i32 %9147, 16" -> "  %9153 = add nuw nsw i32 %9151, %9152"
"  %9152 = and i32 %9150, 65535"
"  %9152 = and i32 %9150, 65535" -> "  %9153 = add nuw nsw i32 %9151, %9152"
"  %9153 = add nuw nsw i32 %9151, %9152"
"  %9153 = add nuw nsw i32 %9151, %9152" -> "  %9155 = add nuw i32 %9153, %9154"
"  %9154 = and i32 %9150, -65536"
"  %9154 = and i32 %9150, -65536" -> "  %9155 = add nuw i32 %9153, %9154"
"  %9155 = add nuw i32 %9153, %9154"
"  %9155 = add nuw i32 %9153, %9154" -> "  %9180 = lshr i32 %9155, 16""  %9155 = add nuw i32 %9153, %9154" -> "  %9176 = and i32 %9155, 65535"
"  %9156 = and i32 %8592, 65535"
"  %9156 = and i32 %8592, 65535" -> "  %12486 = add nuw nsw i32 %12485, %9156""  %9156 = and i32 %8592, 65535" -> "  %10578 = mul nuw i32 %9156, 42779""  %9156 = and i32 %8592, 65535" -> "  %9457 = mul nuw nsw i32 %9156, 17857""  %9156 = and i32 %8592, 65535" -> "  %9157 = mul nuw i32 %9156, 37996""  %9156 = and i32 %8592, 65535" -> "  %9165 = mul nuw i32 %9156, 45147""  %9156 = and i32 %8592, 65535" -> "  %9223 = mul nuw nsw i32 %9156, 1324""  %9156 = and i32 %8592, 65535" -> "  %9230 = mul nuw i32 %9156, 62728""  %9156 = and i32 %8592, 65535" -> "  %9526 = mul nuw i32 %9156, 42170""  %9156 = and i32 %8592, 65535" -> "  %9519 = mul nuw nsw i32 %9156, 31112""  %9156 = and i32 %8592, 65535" -> "  %9464 = mul nuw i32 %9156, 46547""  %9156 = and i32 %8592, 65535" -> "  %10647 = mul nuw nsw i32 %9156, 29744""  %9156 = and i32 %8592, 65535" -> "  %10640 = mul nuw nsw i32 %9156, 24315""  %9156 = and i32 %8592, 65535" -> "  %10585 = mul nuw nsw i32 %9156, 9871""  %9156 = and i32 %8592, 65535" -> "  %10936 = mul nuw i32 %9156, 36786""  %9156 = and i32 %8592, 65535" -> "  %10929 = mul nuw nsw i32 %9156, 21884""  %9156 = and i32 %8592, 65535" -> "  %10874 = mul nuw nsw i32 %9156, 11561""  %9156 = and i32 %8592, 65535" -> "  %10867 = mul nuw nsw i32 %9156, 4087"
"  %9157 = mul nuw i32 %9156, 37996"
"  %9157 = mul nuw i32 %9156, 37996" -> "  %9177 = and i32 %9157, 65532""  %9157 = mul nuw i32 %9156, 37996" -> "  %9158 = lshr i32 %9157, 16"
"  %9158 = lshr i32 %9157, 16"
"  %9158 = lshr i32 %9157, 16" -> "  %9162 = add nuw nsw i32 %9161, %9158"
"  %9159 = and i32 %8600, 65535"
"  %9159 = and i32 %8600, 65535" -> "  %12488 = add nuw nsw i32 %12487, %9159""  %9159 = and i32 %8600, 65535" -> "  %9459 = mul nuw nsw i32 %9159, 17857""  %9159 = and i32 %8600, 65535" -> "  %9160 = mul nuw i32 %9159, 37996""  %9159 = and i32 %8600, 65535" -> "  %9169 = mul nuw i32 %9159, 45147""  %9159 = and i32 %8600, 65535" -> "  %9225 = mul nuw nsw i32 %9159, 1324""  %9159 = and i32 %8600, 65535" -> "  %9234 = mul nuw i32 %9159, 62728""  %9159 = and i32 %8600, 65535" -> "  %9530 = mul nuw i32 %9159, 42170""  %9159 = and i32 %8600, 65535" -> "  %9521 = mul nuw nsw i32 %9159, 31112""  %9159 = and i32 %8600, 65535" -> "  %9468 = mul nuw i32 %9159, 46547""  %9159 = and i32 %8600, 65535" -> "  %10651 = mul nuw nsw i32 %9159, 29744""  %9159 = and i32 %8600, 65535" -> "  %10642 = mul nuw nsw i32 %9159, 24315""  %9159 = and i32 %8600, 65535" -> "  %10589 = mul nuw nsw i32 %9159, 9871""  %9159 = and i32 %8600, 65535" -> "  %10580 = mul nuw i32 %9159, 42779""  %9159 = and i32 %8600, 65535" -> "  %10940 = mul nuw i32 %9159, 36786""  %9159 = and i32 %8600, 65535" -> "  %10931 = mul nuw nsw i32 %9159, 21884""  %9159 = and i32 %8600, 65535" -> "  %10878 = mul nuw nsw i32 %9159, 11561""  %9159 = and i32 %8600, 65535" -> "  %10869 = mul nuw nsw i32 %9159, 4087"
"  %9160 = mul nuw i32 %9159, 37996"
"  %9160 = mul nuw i32 %9159, 37996" -> "  %9163 = and i32 %9160, -65536""  %9160 = mul nuw i32 %9159, 37996" -> "  %9161 = and i32 %9160, 65532"
"  %9161 = and i32 %9160, 65532"
"  %9161 = and i32 %9160, 65532" -> "  %9162 = add nuw nsw i32 %9161, %9158"
"  %9162 = add nuw nsw i32 %9161, %9158"
"  %9162 = add nuw nsw i32 %9161, %9158" -> "  %9164 = add nuw i32 %9162, %9163"
"  %9163 = and i32 %9160, -65536"
"  %9163 = and i32 %9160, -65536" -> "  %9164 = add nuw i32 %9162, %9163"
"  %9164 = add nuw i32 %9162, %9163"
"  %9164 = add nuw i32 %9162, %9163" -> "  %9168 = lshr i32 %9164, 16""  %9164 = add nuw i32 %9162, %9163" -> "  %9166 = and i32 %9164, 65535"
"  %9165 = mul nuw i32 %9156, 45147"
"  %9165 = mul nuw i32 %9156, 45147" -> "  %9167 = add nuw i32 %9166, %9165"
"  %9166 = and i32 %9164, 65535"
"  %9166 = and i32 %9164, 65535" -> "  %9167 = add nuw i32 %9166, %9165"
"  %9167 = add nuw i32 %9166, %9165"
"  %9167 = add nuw i32 %9166, %9165" -> "  %9179 = and i32 %9167, 65535""  %9167 = add nuw i32 %9166, %9165" -> "  %9171 = lshr i32 %9167, 16"
"  %9168 = lshr i32 %9164, 16"
"  %9168 = lshr i32 %9164, 16" -> "  %9170 = add nuw i32 %9168, %9169"
"  %9169 = mul nuw i32 %9159, 45147"
"  %9169 = mul nuw i32 %9159, 45147" -> "  %9170 = add nuw i32 %9168, %9169"
"  %9170 = add nuw i32 %9168, %9169"
"  %9170 = add nuw i32 %9168, %9169" -> "  %9174 = and i32 %9170, -65536""  %9170 = add nuw i32 %9168, %9169" -> "  %9172 = and i32 %9170, 65535"
"  %9171 = lshr i32 %9167, 16"
"  %9171 = lshr i32 %9167, 16" -> "  %9173 = add nuw nsw i32 %9171, %9172"
"  %9172 = and i32 %9170, 65535"
"  %9172 = and i32 %9170, 65535" -> "  %9173 = add nuw nsw i32 %9171, %9172"
"  %9173 = add nuw nsw i32 %9171, %9172"
"  %9173 = add nuw nsw i32 %9171, %9172" -> "  %9175 = add nuw i32 %9173, %9174"
"  %9174 = and i32 %9170, -65536"
"  %9174 = and i32 %9170, -65536" -> "  %9175 = add nuw i32 %9173, %9174"
"  %9175 = add nuw i32 %9173, %9174"
"  %9175 = add nuw i32 %9173, %9174" -> "  %9188 = and i32 %9175, -65536""  %9175 = add nuw i32 %9173, %9174" -> "  %9186 = and i32 %9175, 65535"
"  %9176 = and i32 %9155, 65535"
"  %9176 = and i32 %9155, 65535" -> "  %9178 = add nuw nsw i32 %9176, %9177"
"  %9177 = and i32 %9157, 65532"
"  %9177 = and i32 %9157, 65532" -> "  %9178 = add nuw nsw i32 %9176, %9177"
"  %9178 = add nuw nsw i32 %9176, %9177"
"  %9178 = add nuw nsw i32 %9176, %9177" -> "  %9210 = and i32 %9178, 65535""  %9178 = add nuw nsw i32 %9176, %9177" -> "  %9182 = lshr i32 %9178, 16"
"  %9179 = and i32 %9167, 65535"
"  %9179 = and i32 %9167, 65535" -> "  %9181 = add nuw nsw i32 %9179, %9180"
"  %9180 = lshr i32 %9155, 16"
"  %9180 = lshr i32 %9155, 16" -> "  %9181 = add nuw nsw i32 %9179, %9180"
"  %9181 = add nuw nsw i32 %9179, %9180"
"  %9181 = add nuw nsw i32 %9179, %9180" -> "  %9185 = lshr i32 %9181, 16""  %9181 = add nuw nsw i32 %9179, %9180" -> "  %9183 = and i32 %9181, 65535"
"  %9182 = lshr i32 %9178, 16"
"  %9182 = lshr i32 %9178, 16" -> "  %9184 = add nuw nsw i32 %9183, %9182"
"  %9183 = and i32 %9181, 65535"
"  %9183 = and i32 %9181, 65535" -> "  %9184 = add nuw nsw i32 %9183, %9182"
"  %9184 = add nuw nsw i32 %9183, %9182"
"  %9184 = add nuw nsw i32 %9183, %9182" -> "  %9213 = and i32 %9184, 65535""  %9184 = add nuw nsw i32 %9183, %9182" -> "  %9190 = lshr i32 %9184, 16"
"  %9185 = lshr i32 %9181, 16"
"  %9185 = lshr i32 %9181, 16" -> "  %9187 = add nuw nsw i32 %9186, %9185"
"  %9186 = and i32 %9175, 65535"
"  %9186 = and i32 %9175, 65535" -> "  %9187 = add nuw nsw i32 %9186, %9185"
"  %9187 = add nuw nsw i32 %9186, %9185"
"  %9187 = add nuw nsw i32 %9186, %9185" -> "  %9189 = add nuw i32 %9187, %9188"
"  %9188 = and i32 %9175, -65536"
"  %9188 = and i32 %9175, -65536" -> "  %9189 = add nuw i32 %9187, %9188"
"  %9189 = add nuw i32 %9187, %9188"
"  %9189 = add nuw i32 %9187, %9188" -> "  %9191 = add nuw i32 %9189, %9190"
"  %9190 = lshr i32 %9184, 16"
"  %9190 = lshr i32 %9184, 16" -> "  %9191 = add nuw i32 %9189, %9190"
"  %9191 = add nuw i32 %9189, %9190"
"  %9191 = add nuw i32 %9189, %9190" -> "  %9245 = lshr i32 %9191, 16""  %9191 = add nuw i32 %9189, %9190" -> "  %9241 = and i32 %9191, 65535"
"  %9192 = mul nuw nsw i32 %9136, 1324"
"  %9192 = mul nuw nsw i32 %9136, 1324" -> "  %9211 = and i32 %9192, 65532""  %9192 = mul nuw nsw i32 %9136, 1324" -> "  %9193 = lshr i32 %9192, 16"
"  %9193 = lshr i32 %9192, 16"
"  %9193 = lshr i32 %9192, 16" -> "  %9196 = add nuw nsw i32 %9195, %9193"
"  %9194 = mul nuw nsw i32 %9137, 1324"
"  %9194 = mul nuw nsw i32 %9137, 1324" -> "  %9197 = and i32 %9194, 134152192""  %9194 = mul nuw nsw i32 %9137, 1324" -> "  %9195 = and i32 %9194, 65532"
"  %9195 = and i32 %9194, 65532"
"  %9195 = and i32 %9194, 65532" -> "  %9196 = add nuw nsw i32 %9195, %9193"
"  %9196 = add nuw nsw i32 %9195, %9193"
"  %9196 = add nuw nsw i32 %9195, %9193" -> "  %9198 = add nuw nsw i32 %9196, %9197"
"  %9197 = and i32 %9194, 134152192"
"  %9197 = and i32 %9194, 134152192" -> "  %9198 = add nuw nsw i32 %9196, %9197"
"  %9198 = add nuw nsw i32 %9196, %9197"
"  %9198 = add nuw nsw i32 %9196, %9197" -> "  %9202 = lshr i32 %9198, 16""  %9198 = add nuw nsw i32 %9196, %9197" -> "  %9200 = and i32 %9198, 65535"
"  %9199 = mul nuw i32 %9136, 62728"
"  %9199 = mul nuw i32 %9136, 62728" -> "  %9201 = add nuw i32 %9200, %9199"
"  %9200 = and i32 %9198, 65535"
"  %9200 = and i32 %9198, 65535" -> "  %9201 = add nuw i32 %9200, %9199"
"  %9201 = add nuw i32 %9200, %9199"
"  %9201 = add nuw i32 %9200, %9199" -> "  %9214 = and i32 %9201, 65535""  %9201 = add nuw i32 %9200, %9199" -> "  %9205 = lshr i32 %9201, 16"
"  %9202 = lshr i32 %9198, 16"
"  %9202 = lshr i32 %9198, 16" -> "  %9204 = add nuw i32 %9202, %9203"
"  %9203 = mul nuw i32 %9137, 62728"
"  %9203 = mul nuw i32 %9137, 62728" -> "  %9204 = add nuw i32 %9202, %9203"
"  %9204 = add nuw i32 %9202, %9203"
"  %9204 = add nuw i32 %9202, %9203" -> "  %9208 = and i32 %9204, -65536""  %9204 = add nuw i32 %9202, %9203" -> "  %9206 = and i32 %9204, 65535"
"  %9205 = lshr i32 %9201, 16"
"  %9205 = lshr i32 %9201, 16" -> "  %9207 = add nuw nsw i32 %9205, %9206"
"  %9206 = and i32 %9204, 65535"
"  %9206 = and i32 %9204, 65535" -> "  %9207 = add nuw nsw i32 %9205, %9206"
"  %9207 = add nuw nsw i32 %9205, %9206"
"  %9207 = add nuw nsw i32 %9205, %9206" -> "  %9209 = add nuw i32 %9207, %9208"
"  %9208 = and i32 %9204, -65536"
"  %9208 = and i32 %9204, -65536" -> "  %9209 = add nuw i32 %9207, %9208"
"  %9209 = add nuw i32 %9207, %9208"
"  %9209 = add nuw i32 %9207, %9208" -> "  %9217 = add nuw i32 %9209, %9216"
"  %9210 = and i32 %9178, 65535"
"  %9210 = and i32 %9178, 65535" -> "  %9212 = add nuw nsw i32 %9210, %9211"
"  %9211 = and i32 %9192, 65532"
"  %9211 = and i32 %9192, 65532" -> "  %9212 = add nuw nsw i32 %9210, %9211"
"  %9212 = add nuw nsw i32 %9210, %9211"
"  %9212 = add nuw nsw i32 %9210, %9211" -> "  %9219 = lshr i32 %9212, 16"
"  %9213 = and i32 %9184, 65535"
"  %9213 = and i32 %9184, 65535" -> "  %9215 = add nuw nsw i32 %9213, %9214"
"  %9214 = and i32 %9201, 65535"
"  %9214 = and i32 %9201, 65535" -> "  %9215 = add nuw nsw i32 %9213, %9214"
"  %9215 = add nuw nsw i32 %9213, %9214"
"  %9215 = add nuw nsw i32 %9213, %9214" -> "  %9218 = and i32 %9215, 65535""  %9215 = add nuw nsw i32 %9213, %9214" -> "  %9216 = lshr i32 %9215, 16"
"  %9216 = lshr i32 %9215, 16"
"  %9216 = lshr i32 %9215, 16" -> "  %9217 = add nuw i32 %9209, %9216"
"  %9217 = add nuw i32 %9209, %9216"
"  %9217 = add nuw i32 %9209, %9216" -> "  %9222 = add nuw i32 %9217, %9221"
"  %9218 = and i32 %9215, 65535"
"  %9218 = and i32 %9215, 65535" -> "  %9220 = add nuw nsw i32 %9218, %9219"
"  %9219 = lshr i32 %9212, 16"
"  %9219 = lshr i32 %9212, 16" -> "  %9220 = add nuw nsw i32 %9218, %9219"
"  %9220 = add nuw nsw i32 %9218, %9219"
"  %9220 = add nuw nsw i32 %9218, %9219" -> "  %9221 = lshr i32 %9220, 16"
"  %9221 = lshr i32 %9220, 16"
"  %9221 = lshr i32 %9220, 16" -> "  %9222 = add nuw i32 %9217, %9221"
"  %9222 = add nuw i32 %9217, %9221"
"  %9222 = add nuw i32 %9217, %9221" -> "  %9258 = lshr i32 %9222, 16""  %9222 = add nuw i32 %9217, %9221" -> "  %9255 = and i32 %9222, 65535"
"  %9223 = mul nuw nsw i32 %9156, 1324"
"  %9223 = mul nuw nsw i32 %9156, 1324" -> "  %9242 = and i32 %9223, 65532""  %9223 = mul nuw nsw i32 %9156, 1324" -> "  %9224 = lshr i32 %9223, 16"
"  %9224 = lshr i32 %9223, 16"
"  %9224 = lshr i32 %9223, 16" -> "  %9227 = add nuw nsw i32 %9226, %9224"
"  %9225 = mul nuw nsw i32 %9159, 1324"
"  %9225 = mul nuw nsw i32 %9159, 1324" -> "  %9228 = and i32 %9225, 134152192""  %9225 = mul nuw nsw i32 %9159, 1324" -> "  %9226 = and i32 %9225, 65532"
"  %9226 = and i32 %9225, 65532"
"  %9226 = and i32 %9225, 65532" -> "  %9227 = add nuw nsw i32 %9226, %9224"
"  %9227 = add nuw nsw i32 %9226, %9224"
"  %9227 = add nuw nsw i32 %9226, %9224" -> "  %9229 = add nuw nsw i32 %9227, %9228"
"  %9228 = and i32 %9225, 134152192"
"  %9228 = and i32 %9225, 134152192" -> "  %9229 = add nuw nsw i32 %9227, %9228"
"  %9229 = add nuw nsw i32 %9227, %9228"
"  %9229 = add nuw nsw i32 %9227, %9228" -> "  %9233 = lshr i32 %9229, 16""  %9229 = add nuw nsw i32 %9227, %9228" -> "  %9231 = and i32 %9229, 65535"
"  %9230 = mul nuw i32 %9156, 62728"
"  %9230 = mul nuw i32 %9156, 62728" -> "  %9232 = add nuw i32 %9231, %9230"
"  %9231 = and i32 %9229, 65535"
"  %9231 = and i32 %9229, 65535" -> "  %9232 = add nuw i32 %9231, %9230"
"  %9232 = add nuw i32 %9231, %9230"
"  %9232 = add nuw i32 %9231, %9230" -> "  %9244 = and i32 %9232, 65535""  %9232 = add nuw i32 %9231, %9230" -> "  %9236 = lshr i32 %9232, 16"
"  %9233 = lshr i32 %9229, 16"
"  %9233 = lshr i32 %9229, 16" -> "  %9235 = add nuw i32 %9233, %9234"
"  %9234 = mul nuw i32 %9159, 62728"
"  %9234 = mul nuw i32 %9159, 62728" -> "  %9235 = add nuw i32 %9233, %9234"
"  %9235 = add nuw i32 %9233, %9234"
"  %9235 = add nuw i32 %9233, %9234" -> "  %9239 = and i32 %9235, -65536""  %9235 = add nuw i32 %9233, %9234" -> "  %9237 = and i32 %9235, 65535"
"  %9236 = lshr i32 %9232, 16"
"  %9236 = lshr i32 %9232, 16" -> "  %9238 = add nuw nsw i32 %9236, %9237"
"  %9237 = and i32 %9235, 65535"
"  %9237 = and i32 %9235, 65535" -> "  %9238 = add nuw nsw i32 %9236, %9237"
"  %9238 = add nuw nsw i32 %9236, %9237"
"  %9238 = add nuw nsw i32 %9236, %9237" -> "  %9240 = add nuw i32 %9238, %9239"
"  %9239 = and i32 %9235, -65536"
"  %9239 = and i32 %9235, -65536" -> "  %9240 = add nuw i32 %9238, %9239"
"  %9240 = add nuw i32 %9238, %9239"
"  %9240 = add nuw i32 %9238, %9239" -> "  %9248 = add nuw i32 %9240, %9247"
"  %9241 = and i32 %9191, 65535"
"  %9241 = and i32 %9191, 65535" -> "  %9243 = add nuw nsw i32 %9241, %9242"
"  %9242 = and i32 %9223, 65532"
"  %9242 = and i32 %9223, 65532" -> "  %9243 = add nuw nsw i32 %9241, %9242"
"  %9243 = add nuw nsw i32 %9241, %9242"
"  %9243 = add nuw nsw i32 %9241, %9242" -> "  %9254 = and i32 %9243, 65535""  %9243 = add nuw nsw i32 %9241, %9242" -> "  %9250 = lshr i32 %9243, 16"
"  %9244 = and i32 %9232, 65535"
"  %9244 = and i32 %9232, 65535" -> "  %9246 = add nuw nsw i32 %9245, %9244"
"  %9245 = lshr i32 %9191, 16"
"  %9245 = lshr i32 %9191, 16" -> "  %9246 = add nuw nsw i32 %9245, %9244"
"  %9246 = add nuw nsw i32 %9245, %9244"
"  %9246 = add nuw nsw i32 %9245, %9244" -> "  %9249 = and i32 %9246, 65535""  %9246 = add nuw nsw i32 %9245, %9244" -> "  %9247 = lshr i32 %9246, 16"
"  %9247 = lshr i32 %9246, 16"
"  %9247 = lshr i32 %9246, 16" -> "  %9248 = add nuw i32 %9240, %9247"
"  %9248 = add nuw i32 %9240, %9247"
"  %9248 = add nuw i32 %9240, %9247" -> "  %9253 = add nuw i32 %9248, %9252"
"  %9249 = and i32 %9246, 65535"
"  %9249 = and i32 %9246, 65535" -> "  %9251 = add nuw nsw i32 %9250, %9249"
"  %9250 = lshr i32 %9243, 16"
"  %9250 = lshr i32 %9243, 16" -> "  %9251 = add nuw nsw i32 %9250, %9249"
"  %9251 = add nuw nsw i32 %9250, %9249"
"  %9251 = add nuw nsw i32 %9250, %9249" -> "  %9257 = and i32 %9251, 65535""  %9251 = add nuw nsw i32 %9250, %9249" -> "  %9252 = lshr i32 %9251, 16"
"  %9252 = lshr i32 %9251, 16"
"  %9252 = lshr i32 %9251, 16" -> "  %9253 = add nuw i32 %9248, %9252"
"  %9253 = add nuw i32 %9248, %9252"
"  %9253 = add nuw i32 %9248, %9252" -> "  %9266 = and i32 %9253, -65536""  %9253 = add nuw i32 %9248, %9252" -> "  %9264 = and i32 %9253, 65535"
"  %9254 = and i32 %9243, 65535"
"  %9254 = and i32 %9243, 65535" -> "  %9256 = add nuw nsw i32 %9255, %9254"
"  %9255 = and i32 %9222, 65535"
"  %9255 = and i32 %9222, 65535" -> "  %9256 = add nuw nsw i32 %9255, %9254"
"  %9256 = add nuw nsw i32 %9255, %9254"
"  %9256 = add nuw nsw i32 %9255, %9254" -> "  %9402 = and i32 %9256, 65535""  %9256 = add nuw nsw i32 %9255, %9254" -> "  %9260 = lshr i32 %9256, 16"
"  %9257 = and i32 %9251, 65535"
"  %9257 = and i32 %9251, 65535" -> "  %9259 = add nuw nsw i32 %9257, %9258"
"  %9258 = lshr i32 %9222, 16"
"  %9258 = lshr i32 %9222, 16" -> "  %9259 = add nuw nsw i32 %9257, %9258"
"  %9259 = add nuw nsw i32 %9257, %9258"
"  %9259 = add nuw nsw i32 %9257, %9258" -> "  %9263 = lshr i32 %9259, 16""  %9259 = add nuw nsw i32 %9257, %9258" -> "  %9261 = and i32 %9259, 65535"
"  %9260 = lshr i32 %9256, 16"
"  %9260 = lshr i32 %9256, 16" -> "  %9262 = add nuw nsw i32 %9261, %9260"
"  %9261 = and i32 %9259, 65535"
"  %9261 = and i32 %9259, 65535" -> "  %9262 = add nuw nsw i32 %9261, %9260"
"  %9262 = add nuw nsw i32 %9261, %9260"
"  %9262 = add nuw nsw i32 %9261, %9260" -> "  %9405 = and i32 %9262, 65535""  %9262 = add nuw nsw i32 %9261, %9260" -> "  %9268 = lshr i32 %9262, 16"
"  %9263 = lshr i32 %9259, 16"
"  %9263 = lshr i32 %9259, 16" -> "  %9265 = add nuw nsw i32 %9263, %9264"
"  %9264 = and i32 %9253, 65535"
"  %9264 = and i32 %9253, 65535" -> "  %9265 = add nuw nsw i32 %9263, %9264"
"  %9265 = add nuw nsw i32 %9263, %9264"
"  %9265 = add nuw nsw i32 %9263, %9264" -> "  %9267 = add nuw i32 %9265, %9266"
"  %9266 = and i32 %9253, -65536"
"  %9266 = and i32 %9253, -65536" -> "  %9267 = add nuw i32 %9265, %9266"
"  %9267 = add nuw i32 %9265, %9266"
"  %9267 = add nuw i32 %9265, %9266" -> "  %9269 = add nuw i32 %9267, %9268"
"  %9268 = lshr i32 %9262, 16"
"  %9268 = lshr i32 %9262, 16" -> "  %9269 = add nuw i32 %9267, %9268"
"  %9269 = add nuw i32 %9267, %9268"
"  %9269 = add nuw i32 %9267, %9268" -> "  %9413 = and i32 %9269, 65535""  %9269 = add nuw i32 %9267, %9268" -> "  %9416 = lshr i32 %9269, 16"
"  %9270 = and i32 %8908, 65535"
"  %9270 = and i32 %8908, 65535" -> "  %12503 = add nuw nsw i32 %12502, %9270""  %9270 = and i32 %8908, 65535" -> "  %11070 = mul nuw i32 %9270, 36786""  %9270 = and i32 %8908, 65535" -> "  %11063 = mul nuw nsw i32 %9270, 21884""  %9270 = and i32 %8908, 65535" -> "  %10733 = mul nuw nsw i32 %9270, 24315""  %9270 = and i32 %8908, 65535" -> "  %9271 = mul nuw i32 %9270, 37996""  %9270 = and i32 %8908, 65535" -> "  %9279 = mul nuw i32 %9270, 45147""  %9270 = and i32 %8908, 65535" -> "  %9330 = mul nuw i32 %9270, 62728""  %9270 = and i32 %8908, 65535" -> "  %9323 = mul nuw nsw i32 %9270, 1324""  %9270 = and i32 %8908, 65535" -> "  %9657 = mul nuw i32 %9270, 42170""  %9270 = and i32 %8908, 65535" -> "  %9650 = mul nuw nsw i32 %9270, 31112""  %9270 = and i32 %8908, 65535" -> "  %9608 = mul nuw i32 %9270, 46547""  %9270 = and i32 %8908, 65535" -> "  %9601 = mul nuw nsw i32 %9270, 17857""  %9270 = and i32 %8908, 65535" -> "  %10740 = mul nuw nsw i32 %9270, 29744""  %9270 = and i32 %8908, 65535" -> "  %10691 = mul nuw nsw i32 %9270, 9871""  %9270 = and i32 %8908, 65535" -> "  %10684 = mul nuw i32 %9270, 42779""  %9270 = and i32 %8908, 65535" -> "  %11021 = mul nuw nsw i32 %9270, 11561""  %9270 = and i32 %8908, 65535" -> "  %11014 = mul nuw nsw i32 %9270, 4087"
"  %9271 = mul nuw i32 %9270, 37996"
"  %9271 = mul nuw i32 %9270, 37996" -> "  %9401 = and i32 %9271, 65532""  %9271 = mul nuw i32 %9270, 37996" -> "  %9272 = lshr i32 %9271, 16"
"  %9272 = lshr i32 %9271, 16"
"  %9272 = lshr i32 %9271, 16" -> "  %9276 = add nuw nsw i32 %9275, %9272"
"  %9273 = and i32 %8914, 65535"
"  %9273 = and i32 %8914, 65535" -> "  %12505 = add nuw nsw i32 %12504, %9273""  %9273 = and i32 %8914, 65535" -> "  %10744 = mul nuw nsw i32 %9273, 29744""  %9273 = and i32 %8914, 65535" -> "  %9274 = mul nuw i32 %9273, 37996""  %9273 = and i32 %8914, 65535" -> "  %9283 = mul nuw i32 %9273, 45147""  %9273 = and i32 %8914, 65535" -> "  %9334 = mul nuw i32 %9273, 62728""  %9273 = and i32 %8914, 65535" -> "  %9325 = mul nuw nsw i32 %9273, 1324""  %9273 = and i32 %8914, 65535" -> "  %9661 = mul nuw i32 %9273, 42170""  %9273 = and i32 %8914, 65535" -> "  %9652 = mul nuw nsw i32 %9273, 31112""  %9273 = and i32 %8914, 65535" -> "  %9612 = mul nuw i32 %9273, 46547""  %9273 = and i32 %8914, 65535" -> "  %9603 = mul nuw nsw i32 %9273, 17857""  %9273 = and i32 %8914, 65535" -> "  %10735 = mul nuw nsw i32 %9273, 24315""  %9273 = and i32 %8914, 65535" -> "  %10695 = mul nuw nsw i32 %9273, 9871""  %9273 = and i32 %8914, 65535" -> "  %10686 = mul nuw i32 %9273, 42779""  %9273 = and i32 %8914, 65535" -> "  %11074 = mul nuw i32 %9273, 36786""  %9273 = and i32 %8914, 65535" -> "  %11065 = mul nuw nsw i32 %9273, 21884""  %9273 = and i32 %8914, 65535" -> "  %11025 = mul nuw nsw i32 %9273, 11561""  %9273 = and i32 %8914, 65535" -> "  %11016 = mul nuw nsw i32 %9273, 4087"
"  %9274 = mul nuw i32 %9273, 37996"
"  %9274 = mul nuw i32 %9273, 37996" -> "  %9277 = and i32 %9274, -65536""  %9274 = mul nuw i32 %9273, 37996" -> "  %9275 = and i32 %9274, 65532"
"  %9275 = and i32 %9274, 65532"
"  %9275 = and i32 %9274, 65532" -> "  %9276 = add nuw nsw i32 %9275, %9272"
"  %9276 = add nuw nsw i32 %9275, %9272"
"  %9276 = add nuw nsw i32 %9275, %9272" -> "  %9278 = add nuw i32 %9276, %9277"
"  %9277 = and i32 %9274, -65536"
"  %9277 = and i32 %9274, -65536" -> "  %9278 = add nuw i32 %9276, %9277"
"  %9278 = add nuw i32 %9276, %9277"
"  %9278 = add nuw i32 %9276, %9277" -> "  %9282 = lshr i32 %9278, 16""  %9278 = add nuw i32 %9276, %9277" -> "  %9280 = and i32 %9278, 65535"
"  %9279 = mul nuw i32 %9270, 45147"
"  %9279 = mul nuw i32 %9270, 45147" -> "  %9281 = add nuw i32 %9280, %9279"
"  %9280 = and i32 %9278, 65535"
"  %9280 = and i32 %9278, 65535" -> "  %9281 = add nuw i32 %9280, %9279"
"  %9281 = add nuw i32 %9280, %9279"
"  %9281 = add nuw i32 %9280, %9279" -> "  %9404 = and i32 %9281, 65535""  %9281 = add nuw i32 %9280, %9279" -> "  %9285 = lshr i32 %9281, 16"
"  %9282 = lshr i32 %9278, 16"
"  %9282 = lshr i32 %9278, 16" -> "  %9284 = add nuw i32 %9282, %9283"
"  %9283 = mul nuw i32 %9273, 45147"
"  %9283 = mul nuw i32 %9273, 45147" -> "  %9284 = add nuw i32 %9282, %9283"
"  %9284 = add nuw i32 %9282, %9283"
"  %9284 = add nuw i32 %9282, %9283" -> "  %9288 = and i32 %9284, -65536""  %9284 = add nuw i32 %9282, %9283" -> "  %9286 = and i32 %9284, 65535"
"  %9285 = lshr i32 %9281, 16"
"  %9285 = lshr i32 %9281, 16" -> "  %9287 = add nuw nsw i32 %9285, %9286"
"  %9286 = and i32 %9284, 65535"
"  %9286 = and i32 %9284, 65535" -> "  %9287 = add nuw nsw i32 %9285, %9286"
"  %9287 = add nuw nsw i32 %9285, %9286"
"  %9287 = add nuw nsw i32 %9285, %9286" -> "  %9289 = add nuw i32 %9287, %9288"
"  %9288 = and i32 %9284, -65536"
"  %9288 = and i32 %9284, -65536" -> "  %9289 = add nuw i32 %9287, %9288"
"  %9289 = add nuw i32 %9287, %9288"
"  %9289 = add nuw i32 %9287, %9288" -> "  %9310 = and i32 %9289, 65535""  %9289 = add nuw i32 %9287, %9288" -> "  %9313 = lshr i32 %9289, 16"
"  %9290 = and i32 %8928, 65535"
"  %9290 = and i32 %8928, 65535" -> "  %12512 = add nuw nsw i32 %12511, %9290""  %9290 = and i32 %8928, 65535" -> "  %11032 = mul nuw nsw i32 %9290, 4087""  %9290 = and i32 %8928, 65535" -> "  %11039 = mul nuw nsw i32 %9290, 11561""  %9290 = and i32 %8928, 65535" -> "  %11094 = mul nuw nsw i32 %9290, 21884""  %9290 = and i32 %8928, 65535" -> "  %11101 = mul nuw i32 %9290, 36786""  %9290 = and i32 %8928, 65535" -> "  %10702 = mul nuw i32 %9290, 42779""  %9290 = and i32 %8928, 65535" -> "  %10709 = mul nuw nsw i32 %9290, 9871""  %9290 = and i32 %8928, 65535" -> "  %10764 = mul nuw nsw i32 %9290, 24315""  %9290 = and i32 %8928, 65535" -> "  %10771 = mul nuw nsw i32 %9290, 29744""  %9290 = and i32 %8928, 65535" -> "  %9681 = mul nuw nsw i32 %9290, 31112""  %9290 = and i32 %8928, 65535" -> "  %9685 = mul nuw i32 %9290, 42170""  %9290 = and i32 %8928, 65535" -> "  %9354 = mul nuw nsw i32 %9290, 1324""  %9290 = and i32 %8928, 65535" -> "  %9361 = mul nuw i32 %9290, 62728""  %9290 = and i32 %8928, 65535" -> "  %9299 = mul nuw i32 %9290, 45147""  %9290 = and i32 %8928, 65535" -> "  %9619 = mul nuw nsw i32 %9290, 17857""  %9290 = and i32 %8928, 65535" -> "  %9626 = mul nuw i32 %9290, 46547""  %9290 = and i32 %8928, 65535" -> "  %9291 = mul nuw i32 %9290, 37996"
"  %9291 = mul nuw i32 %9290, 37996"
"  %9291 = mul nuw i32 %9290, 37996" -> "  %9311 = and i32 %9291, 65532""  %9291 = mul nuw i32 %9290, 37996" -> "  %9292 = lshr i32 %9291, 16"
"  %9292 = lshr i32 %9291, 16"
"  %9292 = lshr i32 %9291, 16" -> "  %9296 = add nuw nsw i32 %9295, %9292"
"  %9293 = and i32 %8931, 65535"
"  %9293 = and i32 %8931, 65535" -> "  %11034 = mul nuw nsw i32 %9293, 4087""  %9293 = and i32 %8931, 65535" -> "  %11043 = mul nuw nsw i32 %9293, 11561""  %9293 = and i32 %8931, 65535" -> "  %11096 = mul nuw nsw i32 %9293, 21884""  %9293 = and i32 %8931, 65535" -> "  %11105 = mul nuw i32 %9293, 36786""  %9293 = and i32 %8931, 65535" -> "  %10766 = mul nuw nsw i32 %9293, 24315""  %9293 = and i32 %8931, 65535" -> "  %10775 = mul nuw nsw i32 %9293, 29744""  %9293 = and i32 %8931, 65535" -> "  %10704 = mul nuw i32 %9293, 42779""  %9293 = and i32 %8931, 65535" -> "  %10713 = mul nuw nsw i32 %9293, 9871""  %9293 = and i32 %8931, 65535" -> "  %9621 = mul nuw nsw i32 %9293, 17857""  %9293 = and i32 %8931, 65535" -> "  %9630 = mul nuw i32 %9293, 46547""  %9293 = and i32 %8931, 65535" -> "  %9683 = mul nuw nsw i32 %9293, 31112""  %9293 = and i32 %8931, 65535" -> "  %9689 = mul nuw i32 %9293, 42170""  %9293 = and i32 %8931, 65535" -> "  %9356 = mul nuw nsw i32 %9293, 1324""  %9293 = and i32 %8931, 65535" -> "  %9365 = mul nuw i32 %9293, 62728""  %9293 = and i32 %8931, 65535" -> "  %9294 = mul nuw i32 %9293, 37996""  %9293 = and i32 %8931, 65535" -> "  %9303 = mul nuw i32 %9293, 45147"
"  %9294 = mul nuw i32 %9293, 37996"
"  %9294 = mul nuw i32 %9293, 37996" -> "  %9297 = and i32 %9294, -65536""  %9294 = mul nuw i32 %9293, 37996" -> "  %9295 = and i32 %9294, 65532"
"  %9295 = and i32 %9294, 65532"
"  %9295 = and i32 %9294, 65532" -> "  %9296 = add nuw nsw i32 %9295, %9292"
"  %9296 = add nuw nsw i32 %9295, %9292"
"  %9296 = add nuw nsw i32 %9295, %9292" -> "  %9298 = add nuw i32 %9296, %9297"
"  %9297 = and i32 %9294, -65536"
"  %9297 = and i32 %9294, -65536" -> "  %9298 = add nuw i32 %9296, %9297"
"  %9298 = add nuw i32 %9296, %9297"
"  %9298 = add nuw i32 %9296, %9297" -> "  %9302 = lshr i32 %9298, 16""  %9298 = add nuw i32 %9296, %9297" -> "  %9300 = and i32 %9298, 65535"
"  %9299 = mul nuw i32 %9290, 45147"
"  %9299 = mul nuw i32 %9290, 45147" -> "  %9301 = add nuw i32 %9300, %9299"
"  %9300 = and i32 %9298, 65535"
"  %9300 = and i32 %9298, 65535" -> "  %9301 = add nuw i32 %9300, %9299"
"  %9301 = add nuw i32 %9300, %9299"
"  %9301 = add nuw i32 %9300, %9299" -> "  %9314 = and i32 %9301, 65535""  %9301 = add nuw i32 %9300, %9299" -> "  %9305 = lshr i32 %9301, 16"
"  %9302 = lshr i32 %9298, 16"
"  %9302 = lshr i32 %9298, 16" -> "  %9304 = add nuw i32 %9302, %9303"
"  %9303 = mul nuw i32 %9293, 45147"
"  %9303 = mul nuw i32 %9293, 45147" -> "  %9304 = add nuw i32 %9302, %9303"
"  %9304 = add nuw i32 %9302, %9303"
"  %9304 = add nuw i32 %9302, %9303" -> "  %9308 = and i32 %9304, -65536""  %9304 = add nuw i32 %9302, %9303" -> "  %9306 = and i32 %9304, 65535"
"  %9305 = lshr i32 %9301, 16"
"  %9305 = lshr i32 %9301, 16" -> "  %9307 = add nuw nsw i32 %9305, %9306"
"  %9306 = and i32 %9304, 65535"
"  %9306 = and i32 %9304, 65535" -> "  %9307 = add nuw nsw i32 %9305, %9306"
"  %9307 = add nuw nsw i32 %9305, %9306"
"  %9307 = add nuw nsw i32 %9305, %9306" -> "  %9309 = add nuw i32 %9307, %9308"
"  %9308 = and i32 %9304, -65536"
"  %9308 = and i32 %9304, -65536" -> "  %9309 = add nuw i32 %9307, %9308"
"  %9309 = add nuw i32 %9307, %9308"
"  %9309 = add nuw i32 %9307, %9308" -> "  %9321 = add nuw i32 %9309, %9319"
"  %9310 = and i32 %9289, 65535"
"  %9310 = and i32 %9289, 65535" -> "  %9312 = add nuw nsw i32 %9310, %9311"
"  %9311 = and i32 %9291, 65532"
"  %9311 = and i32 %9291, 65532" -> "  %9312 = add nuw nsw i32 %9310, %9311"
"  %9312 = add nuw nsw i32 %9310, %9311"
"  %9312 = add nuw nsw i32 %9310, %9311" -> "  %9341 = and i32 %9312, 65535""  %9312 = add nuw nsw i32 %9310, %9311" -> "  %9316 = lshr i32 %9312, 16"
"  %9313 = lshr i32 %9289, 16"
"  %9313 = lshr i32 %9289, 16" -> "  %9315 = add nuw nsw i32 %9314, %9313"
"  %9314 = and i32 %9301, 65535"
"  %9314 = and i32 %9301, 65535" -> "  %9315 = add nuw nsw i32 %9314, %9313"
"  %9315 = add nuw nsw i32 %9314, %9313"
"  %9315 = add nuw nsw i32 %9314, %9313" -> "  %9319 = lshr i32 %9315, 16""  %9315 = add nuw nsw i32 %9314, %9313" -> "  %9317 = and i32 %9315, 65535"
"  %9316 = lshr i32 %9312, 16"
"  %9316 = lshr i32 %9312, 16" -> "  %9318 = add nuw nsw i32 %9317, %9316"
"  %9317 = and i32 %9315, 65535"
"  %9317 = and i32 %9315, 65535" -> "  %9318 = add nuw nsw i32 %9317, %9316"
"  %9318 = add nuw nsw i32 %9317, %9316"
"  %9318 = add nuw nsw i32 %9317, %9316" -> "  %9344 = and i32 %9318, 65535""  %9318 = add nuw nsw i32 %9317, %9316" -> "  %9320 = lshr i32 %9318, 16"
"  %9319 = lshr i32 %9315, 16"
"  %9319 = lshr i32 %9315, 16" -> "  %9321 = add nuw i32 %9309, %9319"
"  %9320 = lshr i32 %9318, 16"
"  %9320 = lshr i32 %9318, 16" -> "  %9322 = add nuw i32 %9321, %9320"
"  %9321 = add nuw i32 %9309, %9319"
"  %9321 = add nuw i32 %9309, %9319" -> "  %9322 = add nuw i32 %9321, %9320"
"  %9322 = add nuw i32 %9321, %9320"
"  %9322 = add nuw i32 %9321, %9320" -> "  %9376 = lshr i32 %9322, 16""  %9322 = add nuw i32 %9321, %9320" -> "  %9372 = and i32 %9322, 65535"
"  %9323 = mul nuw nsw i32 %9270, 1324"
"  %9323 = mul nuw nsw i32 %9270, 1324" -> "  %9342 = and i32 %9323, 65532""  %9323 = mul nuw nsw i32 %9270, 1324" -> "  %9324 = lshr i32 %9323, 16"
"  %9324 = lshr i32 %9323, 16"
"  %9324 = lshr i32 %9323, 16" -> "  %9327 = add nuw nsw i32 %9326, %9324"
"  %9325 = mul nuw nsw i32 %9273, 1324"
"  %9325 = mul nuw nsw i32 %9273, 1324" -> "  %9328 = and i32 %9325, 134152192""  %9325 = mul nuw nsw i32 %9273, 1324" -> "  %9326 = and i32 %9325, 65532"
"  %9326 = and i32 %9325, 65532"
"  %9326 = and i32 %9325, 65532" -> "  %9327 = add nuw nsw i32 %9326, %9324"
"  %9327 = add nuw nsw i32 %9326, %9324"
"  %9327 = add nuw nsw i32 %9326, %9324" -> "  %9329 = add nuw nsw i32 %9327, %9328"
"  %9328 = and i32 %9325, 134152192"
"  %9328 = and i32 %9325, 134152192" -> "  %9329 = add nuw nsw i32 %9327, %9328"
"  %9329 = add nuw nsw i32 %9327, %9328"
"  %9329 = add nuw nsw i32 %9327, %9328" -> "  %9333 = lshr i32 %9329, 16""  %9329 = add nuw nsw i32 %9327, %9328" -> "  %9331 = and i32 %9329, 65535"
"  %9330 = mul nuw i32 %9270, 62728"
"  %9330 = mul nuw i32 %9270, 62728" -> "  %9332 = add nuw i32 %9331, %9330"
"  %9331 = and i32 %9329, 65535"
"  %9331 = and i32 %9329, 65535" -> "  %9332 = add nuw i32 %9331, %9330"
"  %9332 = add nuw i32 %9331, %9330"
"  %9332 = add nuw i32 %9331, %9330" -> "  %9345 = and i32 %9332, 65535""  %9332 = add nuw i32 %9331, %9330" -> "  %9336 = lshr i32 %9332, 16"
"  %9333 = lshr i32 %9329, 16"
"  %9333 = lshr i32 %9329, 16" -> "  %9335 = add nuw i32 %9333, %9334"
"  %9334 = mul nuw i32 %9273, 62728"
"  %9334 = mul nuw i32 %9273, 62728" -> "  %9335 = add nuw i32 %9333, %9334"
"  %9335 = add nuw i32 %9333, %9334"
"  %9335 = add nuw i32 %9333, %9334" -> "  %9339 = and i32 %9335, -65536""  %9335 = add nuw i32 %9333, %9334" -> "  %9337 = and i32 %9335, 65535"
"  %9336 = lshr i32 %9332, 16"
"  %9336 = lshr i32 %9332, 16" -> "  %9338 = add nuw nsw i32 %9336, %9337"
"  %9337 = and i32 %9335, 65535"
"  %9337 = and i32 %9335, 65535" -> "  %9338 = add nuw nsw i32 %9336, %9337"
"  %9338 = add nuw nsw i32 %9336, %9337"
"  %9338 = add nuw nsw i32 %9336, %9337" -> "  %9340 = add nuw i32 %9338, %9339"
"  %9339 = and i32 %9335, -65536"
"  %9339 = and i32 %9335, -65536" -> "  %9340 = add nuw i32 %9338, %9339"
"  %9340 = add nuw i32 %9338, %9339"
"  %9340 = add nuw i32 %9338, %9339" -> "  %9348 = add nuw i32 %9340, %9347"
"  %9341 = and i32 %9312, 65535"
"  %9341 = and i32 %9312, 65535" -> "  %9343 = add nuw nsw i32 %9341, %9342"
"  %9342 = and i32 %9323, 65532"
"  %9342 = and i32 %9323, 65532" -> "  %9343 = add nuw nsw i32 %9341, %9342"
"  %9343 = add nuw nsw i32 %9341, %9342"
"  %9343 = add nuw nsw i32 %9341, %9342" -> "  %9412 = and i32 %9343, 65535""  %9343 = add nuw nsw i32 %9341, %9342" -> "  %9350 = lshr i32 %9343, 16"
"  %9344 = and i32 %9318, 65535"
"  %9344 = and i32 %9318, 65535" -> "  %9346 = add nuw nsw i32 %9344, %9345"
"  %9345 = and i32 %9332, 65535"
"  %9345 = and i32 %9332, 65535" -> "  %9346 = add nuw nsw i32 %9344, %9345"
"  %9346 = add nuw nsw i32 %9344, %9345"
"  %9346 = add nuw nsw i32 %9344, %9345" -> "  %9349 = and i32 %9346, 65535""  %9346 = add nuw nsw i32 %9344, %9345" -> "  %9347 = lshr i32 %9346, 16"
"  %9347 = lshr i32 %9346, 16"
"  %9347 = lshr i32 %9346, 16" -> "  %9348 = add nuw i32 %9340, %9347"
"  %9348 = add nuw i32 %9340, %9347"
"  %9348 = add nuw i32 %9340, %9347" -> "  %9353 = add nuw i32 %9348, %9352"
"  %9349 = and i32 %9346, 65535"
"  %9349 = and i32 %9346, 65535" -> "  %9351 = add nuw nsw i32 %9349, %9350"
"  %9350 = lshr i32 %9343, 16"
"  %9350 = lshr i32 %9343, 16" -> "  %9351 = add nuw nsw i32 %9349, %9350"
"  %9351 = add nuw nsw i32 %9349, %9350"
"  %9351 = add nuw nsw i32 %9349, %9350" -> "  %9415 = and i32 %9351, 65535""  %9351 = add nuw nsw i32 %9349, %9350" -> "  %9352 = lshr i32 %9351, 16"
"  %9352 = lshr i32 %9351, 16"
"  %9352 = lshr i32 %9351, 16" -> "  %9353 = add nuw i32 %9348, %9352"
"  %9353 = add nuw i32 %9348, %9352"
"  %9353 = add nuw i32 %9348, %9352" -> "  %9389 = lshr i32 %9353, 16""  %9353 = add nuw i32 %9348, %9352" -> "  %9386 = and i32 %9353, 65535"
"  %9354 = mul nuw nsw i32 %9290, 1324"
"  %9354 = mul nuw nsw i32 %9290, 1324" -> "  %9373 = and i32 %9354, 65532""  %9354 = mul nuw nsw i32 %9290, 1324" -> "  %9355 = lshr i32 %9354, 16"
"  %9355 = lshr i32 %9354, 16"
"  %9355 = lshr i32 %9354, 16" -> "  %9358 = add nuw nsw i32 %9357, %9355"
"  %9356 = mul nuw nsw i32 %9293, 1324"
"  %9356 = mul nuw nsw i32 %9293, 1324" -> "  %9359 = and i32 %9356, 134152192""  %9356 = mul nuw nsw i32 %9293, 1324" -> "  %9357 = and i32 %9356, 65532"
"  %9357 = and i32 %9356, 65532"
"  %9357 = and i32 %9356, 65532" -> "  %9358 = add nuw nsw i32 %9357, %9355"
"  %9358 = add nuw nsw i32 %9357, %9355"
"  %9358 = add nuw nsw i32 %9357, %9355" -> "  %9360 = add nuw nsw i32 %9358, %9359"
"  %9359 = and i32 %9356, 134152192"
"  %9359 = and i32 %9356, 134152192" -> "  %9360 = add nuw nsw i32 %9358, %9359"
"  %9360 = add nuw nsw i32 %9358, %9359"
"  %9360 = add nuw nsw i32 %9358, %9359" -> "  %9364 = lshr i32 %9360, 16""  %9360 = add nuw nsw i32 %9358, %9359" -> "  %9362 = and i32 %9360, 65535"
"  %9361 = mul nuw i32 %9290, 62728"
"  %9361 = mul nuw i32 %9290, 62728" -> "  %9363 = add nuw i32 %9362, %9361"
"  %9362 = and i32 %9360, 65535"
"  %9362 = and i32 %9360, 65535" -> "  %9363 = add nuw i32 %9362, %9361"
"  %9363 = add nuw i32 %9362, %9361"
"  %9363 = add nuw i32 %9362, %9361" -> "  %9375 = and i32 %9363, 65535""  %9363 = add nuw i32 %9362, %9361" -> "  %9367 = lshr i32 %9363, 16"
"  %9364 = lshr i32 %9360, 16"
"  %9364 = lshr i32 %9360, 16" -> "  %9366 = add nuw i32 %9364, %9365"
"  %9365 = mul nuw i32 %9293, 62728"
"  %9365 = mul nuw i32 %9293, 62728" -> "  %9366 = add nuw i32 %9364, %9365"
"  %9366 = add nuw i32 %9364, %9365"
"  %9366 = add nuw i32 %9364, %9365" -> "  %9370 = and i32 %9366, -65536""  %9366 = add nuw i32 %9364, %9365" -> "  %9368 = and i32 %9366, 65535"
"  %9367 = lshr i32 %9363, 16"
"  %9367 = lshr i32 %9363, 16" -> "  %9369 = add nuw nsw i32 %9367, %9368"
"  %9368 = and i32 %9366, 65535"
"  %9368 = and i32 %9366, 65535" -> "  %9369 = add nuw nsw i32 %9367, %9368"
"  %9369 = add nuw nsw i32 %9367, %9368"
"  %9369 = add nuw nsw i32 %9367, %9368" -> "  %9371 = add nuw i32 %9369, %9370"
"  %9370 = and i32 %9366, -65536"
"  %9370 = and i32 %9366, -65536" -> "  %9371 = add nuw i32 %9369, %9370"
"  %9371 = add nuw i32 %9369, %9370"
"  %9371 = add nuw i32 %9369, %9370" -> "  %9379 = add nuw i32 %9371, %9378"
"  %9372 = and i32 %9322, 65535"
"  %9372 = and i32 %9322, 65535" -> "  %9374 = add nuw nsw i32 %9372, %9373"
"  %9373 = and i32 %9354, 65532"
"  %9373 = and i32 %9354, 65532" -> "  %9374 = add nuw nsw i32 %9372, %9373"
"  %9374 = add nuw nsw i32 %9372, %9373"
"  %9374 = add nuw nsw i32 %9372, %9373" -> "  %9385 = and i32 %9374, 65535""  %9374 = add nuw nsw i32 %9372, %9373" -> "  %9381 = lshr i32 %9374, 16"
"  %9375 = and i32 %9363, 65535"
"  %9375 = and i32 %9363, 65535" -> "  %9377 = add nuw nsw i32 %9376, %9375"
"  %9376 = lshr i32 %9322, 16"
"  %9376 = lshr i32 %9322, 16" -> "  %9377 = add nuw nsw i32 %9376, %9375"
"  %9377 = add nuw nsw i32 %9376, %9375"
"  %9377 = add nuw nsw i32 %9376, %9375" -> "  %9380 = and i32 %9377, 65535""  %9377 = add nuw nsw i32 %9376, %9375" -> "  %9378 = lshr i32 %9377, 16"
"  %9378 = lshr i32 %9377, 16"
"  %9378 = lshr i32 %9377, 16" -> "  %9379 = add nuw i32 %9371, %9378"
"  %9379 = add nuw i32 %9371, %9378"
"  %9379 = add nuw i32 %9371, %9378" -> "  %9384 = add nuw i32 %9379, %9383"
"  %9380 = and i32 %9377, 65535"
"  %9380 = and i32 %9377, 65535" -> "  %9382 = add nuw nsw i32 %9380, %9381"
"  %9381 = lshr i32 %9374, 16"
"  %9381 = lshr i32 %9374, 16" -> "  %9382 = add nuw nsw i32 %9380, %9381"
"  %9382 = add nuw nsw i32 %9380, %9381"
"  %9382 = add nuw nsw i32 %9380, %9381" -> "  %9388 = and i32 %9382, 65535""  %9382 = add nuw nsw i32 %9380, %9381" -> "  %9383 = lshr i32 %9382, 16"
"  %9383 = lshr i32 %9382, 16"
"  %9383 = lshr i32 %9382, 16" -> "  %9384 = add nuw i32 %9379, %9383"
"  %9384 = add nuw i32 %9379, %9383"
"  %9384 = add nuw i32 %9379, %9383" -> "  %9397 = and i32 %9384, -65536""  %9384 = add nuw i32 %9379, %9383" -> "  %9395 = and i32 %9384, 65535"
"  %9385 = and i32 %9374, 65535"
"  %9385 = and i32 %9374, 65535" -> "  %9387 = add nuw nsw i32 %9386, %9385"
"  %9386 = and i32 %9353, 65535"
"  %9386 = and i32 %9353, 65535" -> "  %9387 = add nuw nsw i32 %9386, %9385"
"  %9387 = add nuw nsw i32 %9386, %9385"
"  %9387 = add nuw nsw i32 %9386, %9385" -> "  %9427 = and i32 %9387, 65535""  %9387 = add nuw nsw i32 %9386, %9385" -> "  %9391 = lshr i32 %9387, 16"
"  %9388 = and i32 %9382, 65535"
"  %9388 = and i32 %9382, 65535" -> "  %9390 = add nuw nsw i32 %9388, %9389"
"  %9389 = lshr i32 %9353, 16"
"  %9389 = lshr i32 %9353, 16" -> "  %9390 = add nuw nsw i32 %9388, %9389"
"  %9390 = add nuw nsw i32 %9388, %9389"
"  %9390 = add nuw nsw i32 %9388, %9389" -> "  %9394 = lshr i32 %9390, 16""  %9390 = add nuw nsw i32 %9388, %9389" -> "  %9392 = and i32 %9390, 65535"
"  %9391 = lshr i32 %9387, 16"
"  %9391 = lshr i32 %9387, 16" -> "  %9393 = add nuw nsw i32 %9392, %9391"
"  %9392 = and i32 %9390, 65535"
"  %9392 = and i32 %9390, 65535" -> "  %9393 = add nuw nsw i32 %9392, %9391"
"  %9393 = add nuw nsw i32 %9392, %9391"
"  %9393 = add nuw nsw i32 %9392, %9391" -> "  %9434 = and i32 %9393, 65535""  %9393 = add nuw nsw i32 %9392, %9391" -> "  %9399 = lshr i32 %9393, 16"
"  %9394 = lshr i32 %9390, 16"
"  %9394 = lshr i32 %9390, 16" -> "  %9396 = add nuw nsw i32 %9394, %9395"
"  %9395 = and i32 %9384, 65535"
"  %9395 = and i32 %9384, 65535" -> "  %9396 = add nuw nsw i32 %9394, %9395"
"  %9396 = add nuw nsw i32 %9394, %9395"
"  %9396 = add nuw nsw i32 %9394, %9395" -> "  %9398 = add nuw i32 %9396, %9397"
"  %9397 = and i32 %9384, -65536"
"  %9397 = and i32 %9384, -65536" -> "  %9398 = add nuw i32 %9396, %9397"
"  %9398 = add nuw i32 %9396, %9397"
"  %9398 = add nuw i32 %9396, %9397" -> "  %9400 = add nuw i32 %9398, %9399"
"  %9399 = lshr i32 %9393, 16"
"  %9399 = lshr i32 %9393, 16" -> "  %9400 = add nuw i32 %9398, %9399"
"  %9400 = add nuw i32 %9398, %9399"
"  %9400 = add nuw i32 %9398, %9399" -> "  %9438 = add nuw i32 %9400, %9437"
"  %9401 = and i32 %9271, 65532"
"  %9401 = and i32 %9271, 65532" -> "  %9403 = add nuw nsw i32 %9402, %9401"
"  %9402 = and i32 %9256, 65535"
"  %9402 = and i32 %9256, 65535" -> "  %9403 = add nuw nsw i32 %9402, %9401"
"  %9403 = add nuw nsw i32 %9402, %9401"
"  %9403 = add nuw nsw i32 %9402, %9401" -> "  %9562 = and i32 %9403, 65535""  %9403 = add nuw nsw i32 %9402, %9401" -> "  %9407 = lshr i32 %9403, 16"
"  %9404 = and i32 %9281, 65535"
"  %9404 = and i32 %9281, 65535" -> "  %9406 = add nuw nsw i32 %9405, %9404"
"  %9405 = and i32 %9262, 65535"
"  %9405 = and i32 %9262, 65535" -> "  %9406 = add nuw nsw i32 %9405, %9404"
"  %9406 = add nuw nsw i32 %9405, %9404"
"  %9406 = add nuw nsw i32 %9405, %9404" -> "  %9410 = lshr i32 %9406, 16""  %9406 = add nuw nsw i32 %9405, %9404" -> "  %9408 = and i32 %9406, 65535"
"  %9407 = lshr i32 %9403, 16"
"  %9407 = lshr i32 %9403, 16" -> "  %9409 = add nuw nsw i32 %9408, %9407"
"  %9408 = and i32 %9406, 65535"
"  %9408 = and i32 %9406, 65535" -> "  %9409 = add nuw nsw i32 %9408, %9407"
"  %9409 = add nuw nsw i32 %9408, %9407"
"  %9409 = add nuw nsw i32 %9408, %9407" -> "  %9565 = and i32 %9409, 65535""  %9409 = add nuw nsw i32 %9408, %9407" -> "  %9411 = lshr i32 %9409, 16"
"  %9410 = lshr i32 %9406, 16"
"  %9410 = lshr i32 %9406, 16" -> "  %9422 = add nuw nsw i32 %9411, %9410"
"  %9411 = lshr i32 %9409, 16"
"  %9411 = lshr i32 %9409, 16" -> "  %9422 = add nuw nsw i32 %9411, %9410"
"  %9412 = and i32 %9343, 65535"
"  %9412 = and i32 %9343, 65535" -> "  %9414 = add nuw nsw i32 %9412, %9413"
"  %9413 = and i32 %9269, 65535"
"  %9413 = and i32 %9269, 65535" -> "  %9414 = add nuw nsw i32 %9412, %9413"
"  %9414 = add nuw nsw i32 %9412, %9413"
"  %9414 = add nuw nsw i32 %9412, %9413" -> "  %9421 = and i32 %9414, 65535""  %9414 = add nuw nsw i32 %9412, %9413" -> "  %9418 = lshr i32 %9414, 16"
"  %9415 = and i32 %9351, 65535"
"  %9415 = and i32 %9351, 65535" -> "  %9417 = add nuw nsw i32 %9415, %9416"
"  %9416 = lshr i32 %9269, 16"
"  %9416 = lshr i32 %9269, 16" -> "  %9417 = add nuw nsw i32 %9415, %9416"
"  %9417 = add nuw nsw i32 %9415, %9416"
"  %9417 = add nuw nsw i32 %9415, %9416" -> "  %9428 = lshr i32 %9417, 16""  %9417 = add nuw nsw i32 %9415, %9416" -> "  %9419 = and i32 %9417, 65535"
"  %9418 = lshr i32 %9414, 16"
"  %9418 = lshr i32 %9414, 16" -> "  %9420 = add nuw nsw i32 %9419, %9418"
"  %9419 = and i32 %9417, 65535"
"  %9419 = and i32 %9417, 65535" -> "  %9420 = add nuw nsw i32 %9419, %9418"
"  %9420 = add nuw nsw i32 %9419, %9418"
"  %9420 = add nuw nsw i32 %9419, %9418" -> "  %9430 = lshr i32 %9420, 16""  %9420 = add nuw nsw i32 %9419, %9418" -> "  %9425 = and i32 %9420, 65535"
"  %9421 = and i32 %9414, 65535"
"  %9421 = and i32 %9414, 65535" -> "  %9423 = add nuw nsw i32 %9422, %9421"
"  %9422 = add nuw nsw i32 %9411, %9410"
"  %9422 = add nuw nsw i32 %9411, %9410" -> "  %9423 = add nuw nsw i32 %9422, %9421"
"  %9423 = add nuw nsw i32 %9422, %9421"
"  %9423 = add nuw nsw i32 %9422, %9421" -> "  %9573 = and i32 %9423, 65535""  %9423 = add nuw nsw i32 %9422, %9421" -> "  %9424 = lshr i32 %9423, 16"
"  %9424 = lshr i32 %9423, 16"
"  %9424 = lshr i32 %9423, 16" -> "  %9426 = add nuw nsw i32 %9425, %9424"
"  %9425 = and i32 %9420, 65535"
"  %9425 = and i32 %9420, 65535" -> "  %9426 = add nuw nsw i32 %9425, %9424"
"  %9426 = add nuw nsw i32 %9425, %9424"
"  %9426 = add nuw nsw i32 %9425, %9424" -> "  %9576 = and i32 %9426, 65535""  %9426 = add nuw nsw i32 %9425, %9424" -> "  %9432 = lshr i32 %9426, 16"
"  %9427 = and i32 %9387, 65535"
"  %9427 = and i32 %9387, 65535" -> "  %9429 = add nuw nsw i32 %9427, %9428"
"  %9428 = lshr i32 %9417, 16"
"  %9428 = lshr i32 %9417, 16" -> "  %9429 = add nuw nsw i32 %9427, %9428"
"  %9429 = add nuw nsw i32 %9427, %9428"
"  %9429 = add nuw nsw i32 %9427, %9428" -> "  %9431 = add nuw nsw i32 %9429, %9430"
"  %9430 = lshr i32 %9420, 16"
"  %9430 = lshr i32 %9420, 16" -> "  %9431 = add nuw nsw i32 %9429, %9430"
"  %9431 = add nuw nsw i32 %9429, %9430"
"  %9431 = add nuw nsw i32 %9429, %9430" -> "  %9433 = add nuw nsw i32 %9431, %9432"
"  %9432 = lshr i32 %9426, 16"
"  %9432 = lshr i32 %9426, 16" -> "  %9433 = add nuw nsw i32 %9431, %9432"
"  %9433 = add nuw nsw i32 %9431, %9432"
"  %9433 = add nuw nsw i32 %9431, %9432" -> "  %9721 = and i32 %9433, 65535""  %9433 = add nuw nsw i32 %9431, %9432" -> "  %9435 = lshr i32 %9433, 16"
"  %9434 = and i32 %9393, 65535"
"  %9434 = and i32 %9393, 65535" -> "  %9436 = add nuw nsw i32 %9435, %9434"
"  %9435 = lshr i32 %9433, 16"
"  %9435 = lshr i32 %9433, 16" -> "  %9436 = add nuw nsw i32 %9435, %9434"
"  %9436 = add nuw nsw i32 %9435, %9434"
"  %9436 = add nuw nsw i32 %9435, %9434" -> "  %9724 = and i32 %9436, 65535""  %9436 = add nuw nsw i32 %9435, %9434" -> "  %9437 = lshr i32 %9436, 16"
"  %9437 = lshr i32 %9436, 16"
"  %9437 = lshr i32 %9436, 16" -> "  %9438 = add nuw i32 %9400, %9437"
"  %9438 = add nuw i32 %9400, %9437"
"  %9438 = add nuw i32 %9400, %9437" -> "  %9730 = and i32 %9438, 65535""  %9438 = add nuw i32 %9400, %9437" -> "  %9733 = lshr i32 %9438, 16"
"  %9439 = mul nuw nsw i32 %9136, 17857"
"  %9439 = mul nuw nsw i32 %9136, 17857" -> "  %9440 = lshr i32 %9439, 16""  %9439 = mul nuw nsw i32 %9136, 17857" -> "  %9561 = and i32 %9439, 65535"
"  %9440 = lshr i32 %9439, 16"
"  %9440 = lshr i32 %9439, 16" -> "  %9443 = add nuw nsw i32 %9442, %9440"
"  %9441 = mul nuw nsw i32 %9137, 17857"
"  %9441 = mul nuw nsw i32 %9137, 17857" -> "  %9444 = and i32 %9441, 2147418112""  %9441 = mul nuw nsw i32 %9137, 17857" -> "  %9442 = and i32 %9441, 65535"
"  %9442 = and i32 %9441, 65535"
"  %9442 = and i32 %9441, 65535" -> "  %9443 = add nuw nsw i32 %9442, %9440"
"  %9443 = add nuw nsw i32 %9442, %9440"
"  %9443 = add nuw nsw i32 %9442, %9440" -> "  %9445 = add nuw nsw i32 %9443, %9444"
"  %9444 = and i32 %9441, 2147418112"
"  %9444 = and i32 %9441, 2147418112" -> "  %9445 = add nuw nsw i32 %9443, %9444"
"  %9445 = add nuw nsw i32 %9443, %9444"
"  %9445 = add nuw nsw i32 %9443, %9444" -> "  %9449 = lshr i32 %9445, 16""  %9445 = add nuw nsw i32 %9443, %9444" -> "  %9447 = and i32 %9445, 65535"
"  %9446 = mul nuw i32 %9136, 46547"
"  %9446 = mul nuw i32 %9136, 46547" -> "  %9448 = add nuw i32 %9447, %9446"
"  %9447 = and i32 %9445, 65535"
"  %9447 = and i32 %9445, 65535" -> "  %9448 = add nuw i32 %9447, %9446"
"  %9448 = add nuw i32 %9447, %9446"
"  %9448 = add nuw i32 %9447, %9446" -> "  %9564 = and i32 %9448, 65535""  %9448 = add nuw i32 %9447, %9446" -> "  %9452 = lshr i32 %9448, 16"
"  %9449 = lshr i32 %9445, 16"
"  %9449 = lshr i32 %9445, 16" -> "  %9451 = add nuw i32 %9449, %9450"
"  %9450 = mul nuw i32 %9137, 46547"
"  %9450 = mul nuw i32 %9137, 46547" -> "  %9451 = add nuw i32 %9449, %9450"
"  %9451 = add nuw i32 %9449, %9450"
"  %9451 = add nuw i32 %9449, %9450" -> "  %9455 = and i32 %9451, -65536""  %9451 = add nuw i32 %9449, %9450" -> "  %9453 = and i32 %9451, 65535"
"  %9452 = lshr i32 %9448, 16"
"  %9452 = lshr i32 %9448, 16" -> "  %9454 = add nuw nsw i32 %9452, %9453"
"  %9453 = and i32 %9451, 65535"
"  %9453 = and i32 %9451, 65535" -> "  %9454 = add nuw nsw i32 %9452, %9453"
"  %9454 = add nuw nsw i32 %9452, %9453"
"  %9454 = add nuw nsw i32 %9452, %9453" -> "  %9456 = add nuw i32 %9454, %9455"
"  %9455 = and i32 %9451, -65536"
"  %9455 = and i32 %9451, -65536" -> "  %9456 = add nuw i32 %9454, %9455"
"  %9456 = add nuw i32 %9454, %9455"
"  %9456 = add nuw i32 %9454, %9455" -> "  %9475 = and i32 %9456, 65535""  %9456 = add nuw i32 %9454, %9455" -> "  %9479 = lshr i32 %9456, 16"
"  %9457 = mul nuw nsw i32 %9156, 17857"
"  %9457 = mul nuw nsw i32 %9156, 17857" -> "  %9458 = lshr i32 %9457, 16""  %9457 = mul nuw nsw i32 %9156, 17857" -> "  %9476 = and i32 %9457, 65535"
"  %9458 = lshr i32 %9457, 16"
"  %9458 = lshr i32 %9457, 16" -> "  %9461 = add nuw nsw i32 %9460, %9458"
"  %9459 = mul nuw nsw i32 %9159, 17857"
"  %9459 = mul nuw nsw i32 %9159, 17857" -> "  %9462 = and i32 %9459, 2147418112""  %9459 = mul nuw nsw i32 %9159, 17857" -> "  %9460 = and i32 %9459, 65535"
"  %9460 = and i32 %9459, 65535"
"  %9460 = and i32 %9459, 65535" -> "  %9461 = add nuw nsw i32 %9460, %9458"
"  %9461 = add nuw nsw i32 %9460, %9458"
"  %9461 = add nuw nsw i32 %9460, %9458" -> "  %9463 = add nuw nsw i32 %9461, %9462"
"  %9462 = and i32 %9459, 2147418112"
"  %9462 = and i32 %9459, 2147418112" -> "  %9463 = add nuw nsw i32 %9461, %9462"
"  %9463 = add nuw nsw i32 %9461, %9462"
"  %9463 = add nuw nsw i32 %9461, %9462" -> "  %9467 = lshr i32 %9463, 16""  %9463 = add nuw nsw i32 %9461, %9462" -> "  %9465 = and i32 %9463, 65535"
"  %9464 = mul nuw i32 %9156, 46547"
"  %9464 = mul nuw i32 %9156, 46547" -> "  %9466 = add nuw i32 %9465, %9464"
"  %9465 = and i32 %9463, 65535"
"  %9465 = and i32 %9463, 65535" -> "  %9466 = add nuw i32 %9465, %9464"
"  %9466 = add nuw i32 %9465, %9464"
"  %9466 = add nuw i32 %9465, %9464" -> "  %9478 = and i32 %9466, 65535""  %9466 = add nuw i32 %9465, %9464" -> "  %9470 = lshr i32 %9466, 16"
"  %9467 = lshr i32 %9463, 16"
"  %9467 = lshr i32 %9463, 16" -> "  %9469 = add nuw i32 %9467, %9468"
"  %9468 = mul nuw i32 %9159, 46547"
"  %9468 = mul nuw i32 %9159, 46547" -> "  %9469 = add nuw i32 %9467, %9468"
"  %9469 = add nuw i32 %9467, %9468"
"  %9469 = add nuw i32 %9467, %9468" -> "  %9473 = and i32 %9469, -65536""  %9469 = add nuw i32 %9467, %9468" -> "  %9471 = and i32 %9469, 65535"
"  %9470 = lshr i32 %9466, 16"
"  %9470 = lshr i32 %9466, 16" -> "  %9472 = add nuw nsw i32 %9471, %9470"
"  %9471 = and i32 %9469, 65535"
"  %9471 = and i32 %9469, 65535" -> "  %9472 = add nuw nsw i32 %9471, %9470"
"  %9472 = add nuw nsw i32 %9471, %9470"
"  %9472 = add nuw nsw i32 %9471, %9470" -> "  %9474 = add nuw i32 %9472, %9473"
"  %9473 = and i32 %9469, -65536"
"  %9473 = and i32 %9469, -65536" -> "  %9474 = add nuw i32 %9472, %9473"
"  %9474 = add nuw i32 %9472, %9473"
"  %9474 = add nuw i32 %9472, %9473" -> "  %9482 = add nuw i32 %9474, %9481"
"  %9475 = and i32 %9456, 65535"
"  %9475 = and i32 %9456, 65535" -> "  %9477 = add nuw nsw i32 %9475, %9476"
"  %9476 = and i32 %9457, 65535"
"  %9476 = and i32 %9457, 65535" -> "  %9477 = add nuw nsw i32 %9475, %9476"
"  %9477 = add nuw nsw i32 %9475, %9476"
"  %9477 = add nuw nsw i32 %9475, %9476" -> "  %9506 = and i32 %9477, 65535""  %9477 = add nuw nsw i32 %9475, %9476" -> "  %9484 = lshr i32 %9477, 16"
"  %9478 = and i32 %9466, 65535"
"  %9478 = and i32 %9466, 65535" -> "  %9480 = add nuw nsw i32 %9478, %9479"
"  %9479 = lshr i32 %9456, 16"
"  %9479 = lshr i32 %9456, 16" -> "  %9480 = add nuw nsw i32 %9478, %9479"
"  %9480 = add nuw nsw i32 %9478, %9479"
"  %9480 = add nuw nsw i32 %9478, %9479" -> "  %9483 = and i32 %9480, 65535""  %9480 = add nuw nsw i32 %9478, %9479" -> "  %9481 = lshr i32 %9480, 16"
"  %9481 = lshr i32 %9480, 16"
"  %9481 = lshr i32 %9480, 16" -> "  %9482 = add nuw i32 %9474, %9481"
"  %9482 = add nuw i32 %9474, %9481"
"  %9482 = add nuw i32 %9474, %9481" -> "  %9487 = add nuw i32 %9482, %9486"
"  %9483 = and i32 %9480, 65535"
"  %9483 = and i32 %9480, 65535" -> "  %9485 = add nuw nsw i32 %9483, %9484"
"  %9484 = lshr i32 %9477, 16"
"  %9484 = lshr i32 %9477, 16" -> "  %9485 = add nuw nsw i32 %9483, %9484"
"  %9485 = add nuw nsw i32 %9483, %9484"
"  %9485 = add nuw nsw i32 %9483, %9484" -> "  %9509 = and i32 %9485, 65535""  %9485 = add nuw nsw i32 %9483, %9484" -> "  %9486 = lshr i32 %9485, 16"
"  %9486 = lshr i32 %9485, 16"
"  %9486 = lshr i32 %9485, 16" -> "  %9487 = add nuw i32 %9482, %9486"
"  %9487 = add nuw i32 %9482, %9486"
"  %9487 = add nuw i32 %9482, %9486" -> "  %9541 = lshr i32 %9487, 16""  %9487 = add nuw i32 %9482, %9486" -> "  %9537 = and i32 %9487, 65535"
"  %9488 = mul nuw nsw i32 %9136, 31112"
"  %9488 = mul nuw nsw i32 %9136, 31112" -> "  %9507 = and i32 %9488, 65528""  %9488 = mul nuw nsw i32 %9136, 31112" -> "  %9489 = lshr i32 %9488, 16"
"  %9489 = lshr i32 %9488, 16"
"  %9489 = lshr i32 %9488, 16" -> "  %9492 = add nuw nsw i32 %9491, %9489"
"  %9490 = mul nuw nsw i32 %9137, 31112"
"  %9490 = mul nuw nsw i32 %9137, 31112" -> "  %9493 = and i32 %9490, 2147418112""  %9490 = mul nuw nsw i32 %9137, 31112" -> "  %9491 = and i32 %9490, 65528"
"  %9491 = and i32 %9490, 65528"
"  %9491 = and i32 %9490, 65528" -> "  %9492 = add nuw nsw i32 %9491, %9489"
"  %9492 = add nuw nsw i32 %9491, %9489"
"  %9492 = add nuw nsw i32 %9491, %9489" -> "  %9494 = add nuw nsw i32 %9492, %9493"
"  %9493 = and i32 %9490, 2147418112"
"  %9493 = and i32 %9490, 2147418112" -> "  %9494 = add nuw nsw i32 %9492, %9493"
"  %9494 = add nuw nsw i32 %9492, %9493"
"  %9494 = add nuw nsw i32 %9492, %9493" -> "  %9498 = lshr i32 %9494, 16""  %9494 = add nuw nsw i32 %9492, %9493" -> "  %9496 = and i32 %9494, 65535"
"  %9495 = mul nuw i32 %9136, 42170"
"  %9495 = mul nuw i32 %9136, 42170" -> "  %9497 = add nuw i32 %9496, %9495"
"  %9496 = and i32 %9494, 65535"
"  %9496 = and i32 %9494, 65535" -> "  %9497 = add nuw i32 %9496, %9495"
"  %9497 = add nuw i32 %9496, %9495"
"  %9497 = add nuw i32 %9496, %9495" -> "  %9510 = and i32 %9497, 65535""  %9497 = add nuw i32 %9496, %9495" -> "  %9501 = lshr i32 %9497, 16"
"  %9498 = lshr i32 %9494, 16"
"  %9498 = lshr i32 %9494, 16" -> "  %9500 = add nuw i32 %9498, %9499"
"  %9499 = mul nuw i32 %9137, 42170"
"  %9499 = mul nuw i32 %9137, 42170" -> "  %9500 = add nuw i32 %9498, %9499"
"  %9500 = add nuw i32 %9498, %9499"
"  %9500 = add nuw i32 %9498, %9499" -> "  %9504 = and i32 %9500, -65536""  %9500 = add nuw i32 %9498, %9499" -> "  %9502 = and i32 %9500, 65535"
"  %9501 = lshr i32 %9497, 16"
"  %9501 = lshr i32 %9497, 16" -> "  %9503 = add nuw nsw i32 %9501, %9502"
"  %9502 = and i32 %9500, 65535"
"  %9502 = and i32 %9500, 65535" -> "  %9503 = add nuw nsw i32 %9501, %9502"
"  %9503 = add nuw nsw i32 %9501, %9502"
"  %9503 = add nuw nsw i32 %9501, %9502" -> "  %9505 = add nuw i32 %9503, %9504"
"  %9504 = and i32 %9500, -65536"
"  %9504 = and i32 %9500, -65536" -> "  %9505 = add nuw i32 %9503, %9504"
"  %9505 = add nuw i32 %9503, %9504"
"  %9505 = add nuw i32 %9503, %9504" -> "  %9513 = add nuw i32 %9505, %9512"
"  %9506 = and i32 %9477, 65535"
"  %9506 = and i32 %9477, 65535" -> "  %9508 = add nuw nsw i32 %9506, %9507"
"  %9507 = and i32 %9488, 65528"
"  %9507 = and i32 %9488, 65528" -> "  %9508 = add nuw nsw i32 %9506, %9507"
"  %9508 = add nuw nsw i32 %9506, %9507"
"  %9508 = add nuw nsw i32 %9506, %9507" -> "  %9572 = and i32 %9508, 65535""  %9508 = add nuw nsw i32 %9506, %9507" -> "  %9515 = lshr i32 %9508, 16"
"  %9509 = and i32 %9485, 65535"
"  %9509 = and i32 %9485, 65535" -> "  %9511 = add nuw nsw i32 %9509, %9510"
"  %9510 = and i32 %9497, 65535"
"  %9510 = and i32 %9497, 65535" -> "  %9511 = add nuw nsw i32 %9509, %9510"
"  %9511 = add nuw nsw i32 %9509, %9510"
"  %9511 = add nuw nsw i32 %9509, %9510" -> "  %9514 = and i32 %9511, 65535""  %9511 = add nuw nsw i32 %9509, %9510" -> "  %9512 = lshr i32 %9511, 16"
"  %9512 = lshr i32 %9511, 16"
"  %9512 = lshr i32 %9511, 16" -> "  %9513 = add nuw i32 %9505, %9512"
"  %9513 = add nuw i32 %9505, %9512"
"  %9513 = add nuw i32 %9505, %9512" -> "  %9518 = add nuw i32 %9513, %9517"
"  %9514 = and i32 %9511, 65535"
"  %9514 = and i32 %9511, 65535" -> "  %9516 = add nuw nsw i32 %9514, %9515"
"  %9515 = lshr i32 %9508, 16"
"  %9515 = lshr i32 %9508, 16" -> "  %9516 = add nuw nsw i32 %9514, %9515"
"  %9516 = add nuw nsw i32 %9514, %9515"
"  %9516 = add nuw nsw i32 %9514, %9515" -> "  %9575 = and i32 %9516, 65535""  %9516 = add nuw nsw i32 %9514, %9515" -> "  %9517 = lshr i32 %9516, 16"
"  %9517 = lshr i32 %9516, 16"
"  %9517 = lshr i32 %9516, 16" -> "  %9518 = add nuw i32 %9513, %9517"
"  %9518 = add nuw i32 %9513, %9517"
"  %9518 = add nuw i32 %9513, %9517" -> "  %9554 = lshr i32 %9518, 16""  %9518 = add nuw i32 %9513, %9517" -> "  %9551 = and i32 %9518, 65535"
"  %9519 = mul nuw nsw i32 %9156, 31112"
"  %9519 = mul nuw nsw i32 %9156, 31112" -> "  %9538 = and i32 %9519, 65528""  %9519 = mul nuw nsw i32 %9156, 31112" -> "  %9520 = lshr i32 %9519, 16"
"  %9520 = lshr i32 %9519, 16"
"  %9520 = lshr i32 %9519, 16" -> "  %9523 = add nuw nsw i32 %9522, %9520"
"  %9521 = mul nuw nsw i32 %9159, 31112"
"  %9521 = mul nuw nsw i32 %9159, 31112" -> "  %9524 = and i32 %9521, 2147418112""  %9521 = mul nuw nsw i32 %9159, 31112" -> "  %9522 = and i32 %9521, 65528"
"  %9522 = and i32 %9521, 65528"
"  %9522 = and i32 %9521, 65528" -> "  %9523 = add nuw nsw i32 %9522, %9520"
"  %9523 = add nuw nsw i32 %9522, %9520"
"  %9523 = add nuw nsw i32 %9522, %9520" -> "  %9525 = add nuw nsw i32 %9523, %9524"
"  %9524 = and i32 %9521, 2147418112"
"  %9524 = and i32 %9521, 2147418112" -> "  %9525 = add nuw nsw i32 %9523, %9524"
"  %9525 = add nuw nsw i32 %9523, %9524"
"  %9525 = add nuw nsw i32 %9523, %9524" -> "  %9529 = lshr i32 %9525, 16""  %9525 = add nuw nsw i32 %9523, %9524" -> "  %9527 = and i32 %9525, 65535"
"  %9526 = mul nuw i32 %9156, 42170"
"  %9526 = mul nuw i32 %9156, 42170" -> "  %9528 = add nuw i32 %9527, %9526"
"  %9527 = and i32 %9525, 65535"
"  %9527 = and i32 %9525, 65535" -> "  %9528 = add nuw i32 %9527, %9526"
"  %9528 = add nuw i32 %9527, %9526"
"  %9528 = add nuw i32 %9527, %9526" -> "  %9540 = and i32 %9528, 65535""  %9528 = add nuw i32 %9527, %9526" -> "  %9532 = lshr i32 %9528, 16"
"  %9529 = lshr i32 %9525, 16"
"  %9529 = lshr i32 %9525, 16" -> "  %9531 = add nuw i32 %9529, %9530"
"  %9530 = mul nuw i32 %9159, 42170"
"  %9530 = mul nuw i32 %9159, 42170" -> "  %9531 = add nuw i32 %9529, %9530"
"  %9531 = add nuw i32 %9529, %9530"
"  %9531 = add nuw i32 %9529, %9530" -> "  %9535 = and i32 %9531, -65536""  %9531 = add nuw i32 %9529, %9530" -> "  %9533 = and i32 %9531, 65535"
"  %9532 = lshr i32 %9528, 16"
"  %9532 = lshr i32 %9528, 16" -> "  %9534 = add nuw nsw i32 %9532, %9533"
"  %9533 = and i32 %9531, 65535"
"  %9533 = and i32 %9531, 65535" -> "  %9534 = add nuw nsw i32 %9532, %9533"
"  %9534 = add nuw nsw i32 %9532, %9533"
"  %9534 = add nuw nsw i32 %9532, %9533" -> "  %9536 = add nuw i32 %9534, %9535"
"  %9535 = and i32 %9531, -65536"
"  %9535 = and i32 %9531, -65536" -> "  %9536 = add nuw i32 %9534, %9535"
"  %9536 = add nuw i32 %9534, %9535"
"  %9536 = add nuw i32 %9534, %9535" -> "  %9544 = add nuw i32 %9536, %9543"
"  %9537 = and i32 %9487, 65535"
"  %9537 = and i32 %9487, 65535" -> "  %9539 = add nuw nsw i32 %9537, %9538"
"  %9538 = and i32 %9519, 65528"
"  %9538 = and i32 %9519, 65528" -> "  %9539 = add nuw nsw i32 %9537, %9538"
"  %9539 = add nuw nsw i32 %9537, %9538"
"  %9539 = add nuw nsw i32 %9537, %9538" -> "  %9550 = and i32 %9539, 65535""  %9539 = add nuw nsw i32 %9537, %9538" -> "  %9546 = lshr i32 %9539, 16"
"  %9540 = and i32 %9528, 65535"
"  %9540 = and i32 %9528, 65535" -> "  %9542 = add nuw nsw i32 %9541, %9540"
"  %9541 = lshr i32 %9487, 16"
"  %9541 = lshr i32 %9487, 16" -> "  %9542 = add nuw nsw i32 %9541, %9540"
"  %9542 = add nuw nsw i32 %9541, %9540"
"  %9542 = add nuw nsw i32 %9541, %9540" -> "  %9545 = and i32 %9542, 65535""  %9542 = add nuw nsw i32 %9541, %9540" -> "  %9543 = lshr i32 %9542, 16"
"  %9543 = lshr i32 %9542, 16"
"  %9543 = lshr i32 %9542, 16" -> "  %9544 = add nuw i32 %9536, %9543"
"  %9544 = add nuw i32 %9536, %9543"
"  %9544 = add nuw i32 %9536, %9543" -> "  %9549 = add nuw i32 %9544, %9548"
"  %9545 = and i32 %9542, 65535"
"  %9545 = and i32 %9542, 65535" -> "  %9547 = add nuw nsw i32 %9545, %9546"
"  %9546 = lshr i32 %9539, 16"
"  %9546 = lshr i32 %9539, 16" -> "  %9547 = add nuw nsw i32 %9545, %9546"
"  %9547 = add nuw nsw i32 %9545, %9546"
"  %9547 = add nuw nsw i32 %9545, %9546" -> "  %9553 = and i32 %9547, 65535""  %9547 = add nuw nsw i32 %9545, %9546" -> "  %9548 = lshr i32 %9547, 16"
"  %9548 = lshr i32 %9547, 16"
"  %9548 = lshr i32 %9547, 16" -> "  %9549 = add nuw i32 %9544, %9548"
"  %9549 = add nuw i32 %9544, %9548"
"  %9549 = add nuw i32 %9544, %9548" -> "  %9598 = add nuw i32 %9549, %9559"
"  %9550 = and i32 %9539, 65535"
"  %9550 = and i32 %9539, 65535" -> "  %9552 = add nuw nsw i32 %9551, %9550"
"  %9551 = and i32 %9518, 65535"
"  %9551 = and i32 %9518, 65535" -> "  %9552 = add nuw nsw i32 %9551, %9550"
"  %9552 = add nuw nsw i32 %9551, %9550"
"  %9552 = add nuw nsw i32 %9551, %9550" -> "  %9587 = and i32 %9552, 65535""  %9552 = add nuw nsw i32 %9551, %9550" -> "  %9556 = lshr i32 %9552, 16"
"  %9553 = and i32 %9547, 65535"
"  %9553 = and i32 %9547, 65535" -> "  %9555 = add nuw nsw i32 %9554, %9553"
"  %9554 = lshr i32 %9518, 16"
"  %9554 = lshr i32 %9518, 16" -> "  %9555 = add nuw nsw i32 %9554, %9553"
"  %9555 = add nuw nsw i32 %9554, %9553"
"  %9555 = add nuw nsw i32 %9554, %9553" -> "  %9559 = lshr i32 %9555, 16""  %9555 = add nuw nsw i32 %9554, %9553" -> "  %9557 = and i32 %9555, 65535"
"  %9556 = lshr i32 %9552, 16"
"  %9556 = lshr i32 %9552, 16" -> "  %9558 = add nuw nsw i32 %9557, %9556"
"  %9557 = and i32 %9555, 65535"
"  %9557 = and i32 %9555, 65535" -> "  %9558 = add nuw nsw i32 %9557, %9556"
"  %9558 = add nuw nsw i32 %9557, %9556"
"  %9558 = add nuw nsw i32 %9557, %9556" -> "  %9594 = and i32 %9558, 65535""  %9558 = add nuw nsw i32 %9557, %9556" -> "  %9560 = lshr i32 %9558, 16"
"  %9559 = lshr i32 %9555, 16"
"  %9559 = lshr i32 %9555, 16" -> "  %9598 = add nuw i32 %9549, %9559"
"  %9560 = lshr i32 %9558, 16"
"  %9560 = lshr i32 %9558, 16" -> "  %9599 = add nuw i32 %9598, %9560"
"  %9561 = and i32 %9439, 65535"
"  %9561 = and i32 %9439, 65535" -> "  %9563 = add nuw nsw i32 %9562, %9561"
"  %9562 = and i32 %9403, 65535"
"  %9562 = and i32 %9403, 65535" -> "  %9563 = add nuw nsw i32 %9562, %9561"
"  %9563 = add nuw nsw i32 %9562, %9561"
"  %9563 = add nuw nsw i32 %9562, %9561" -> "  %9567 = lshr i32 %9563, 16"
"  %9564 = and i32 %9448, 65535"
"  %9564 = and i32 %9448, 65535" -> "  %9566 = add nuw nsw i32 %9565, %9564"
"  %9565 = and i32 %9409, 65535"
"  %9565 = and i32 %9409, 65535" -> "  %9566 = add nuw nsw i32 %9565, %9564"
"  %9566 = add nuw nsw i32 %9565, %9564"
"  %9566 = add nuw nsw i32 %9565, %9564" -> "  %9570 = lshr i32 %9566, 16""  %9566 = add nuw nsw i32 %9565, %9564" -> "  %9568 = and i32 %9566, 65535"
"  %9567 = lshr i32 %9563, 16"
"  %9567 = lshr i32 %9563, 16" -> "  %9569 = add nuw nsw i32 %9568, %9567"
"  %9568 = and i32 %9566, 65535"
"  %9568 = and i32 %9566, 65535" -> "  %9569 = add nuw nsw i32 %9568, %9567"
"  %9569 = add nuw nsw i32 %9568, %9567"
"  %9569 = add nuw nsw i32 %9568, %9567" -> "  %9571 = lshr i32 %9569, 16"
"  %9570 = lshr i32 %9566, 16"
"  %9570 = lshr i32 %9566, 16" -> "  %9582 = add nuw nsw i32 %9571, %9570"
"  %9571 = lshr i32 %9569, 16"
"  %9571 = lshr i32 %9569, 16" -> "  %9582 = add nuw nsw i32 %9571, %9570"
"  %9572 = and i32 %9508, 65535"
"  %9572 = and i32 %9508, 65535" -> "  %9574 = add nuw nsw i32 %9573, %9572"
"  %9573 = and i32 %9423, 65535"
"  %9573 = and i32 %9423, 65535" -> "  %9574 = add nuw nsw i32 %9573, %9572"
"  %9574 = add nuw nsw i32 %9573, %9572"
"  %9574 = add nuw nsw i32 %9573, %9572" -> "  %9581 = and i32 %9574, 65535""  %9574 = add nuw nsw i32 %9573, %9572" -> "  %9578 = lshr i32 %9574, 16"
"  %9575 = and i32 %9516, 65535"
"  %9575 = and i32 %9516, 65535" -> "  %9577 = add nuw nsw i32 %9576, %9575"
"  %9576 = and i32 %9426, 65535"
"  %9576 = and i32 %9426, 65535" -> "  %9577 = add nuw nsw i32 %9576, %9575"
"  %9577 = add nuw nsw i32 %9576, %9575"
"  %9577 = add nuw nsw i32 %9576, %9575" -> "  %9588 = lshr i32 %9577, 16""  %9577 = add nuw nsw i32 %9576, %9575" -> "  %9579 = and i32 %9577, 65535"
"  %9578 = lshr i32 %9574, 16"
"  %9578 = lshr i32 %9574, 16" -> "  %9580 = add nuw nsw i32 %9579, %9578"
"  %9579 = and i32 %9577, 65535"
"  %9579 = and i32 %9577, 65535" -> "  %9580 = add nuw nsw i32 %9579, %9578"
"  %9580 = add nuw nsw i32 %9579, %9578"
"  %9580 = add nuw nsw i32 %9579, %9578" -> "  %9590 = lshr i32 %9580, 16""  %9580 = add nuw nsw i32 %9579, %9578" -> "  %9585 = and i32 %9580, 65535"
"  %9581 = and i32 %9574, 65535"
"  %9581 = and i32 %9574, 65535" -> "  %9583 = add nuw nsw i32 %9582, %9581"
"  %9582 = add nuw nsw i32 %9571, %9570"
"  %9582 = add nuw nsw i32 %9571, %9570" -> "  %9583 = add nuw nsw i32 %9582, %9581"
"  %9583 = add nuw nsw i32 %9582, %9581"
"  %9583 = add nuw nsw i32 %9582, %9581" -> "  %9584 = lshr i32 %9583, 16"
"  %9584 = lshr i32 %9583, 16"
"  %9584 = lshr i32 %9583, 16" -> "  %9586 = add nuw nsw i32 %9585, %9584"
"  %9585 = and i32 %9580, 65535"
"  %9585 = and i32 %9580, 65535" -> "  %9586 = add nuw nsw i32 %9585, %9584"
"  %9586 = add nuw nsw i32 %9585, %9584"
"  %9586 = add nuw nsw i32 %9585, %9584" -> "  %9592 = lshr i32 %9586, 16"
"  %9587 = and i32 %9552, 65535"
"  %9587 = and i32 %9552, 65535" -> "  %9589 = add nuw nsw i32 %9588, %9587"
"  %9588 = lshr i32 %9577, 16"
"  %9588 = lshr i32 %9577, 16" -> "  %9589 = add nuw nsw i32 %9588, %9587"
"  %9589 = add nuw nsw i32 %9588, %9587"
"  %9589 = add nuw nsw i32 %9588, %9587" -> "  %9591 = add nuw nsw i32 %9589, %9590"
"  %9590 = lshr i32 %9580, 16"
"  %9590 = lshr i32 %9580, 16" -> "  %9591 = add nuw nsw i32 %9589, %9590"
"  %9591 = add nuw nsw i32 %9589, %9590"
"  %9591 = add nuw nsw i32 %9589, %9590" -> "  %9593 = add nuw nsw i32 %9591, %9592"
"  %9592 = lshr i32 %9586, 16"
"  %9592 = lshr i32 %9586, 16" -> "  %9593 = add nuw nsw i32 %9591, %9592"
"  %9593 = add nuw nsw i32 %9591, %9592"
"  %9593 = add nuw nsw i32 %9591, %9592" -> "  %9761 = and i32 %9593, 65535""  %9593 = add nuw nsw i32 %9591, %9592" -> "  %9595 = lshr i32 %9593, 16"
"  %9594 = and i32 %9558, 65535"
"  %9594 = and i32 %9558, 65535" -> "  %9596 = add nuw nsw i32 %9595, %9594"
"  %9595 = lshr i32 %9593, 16"
"  %9595 = lshr i32 %9593, 16" -> "  %9596 = add nuw nsw i32 %9595, %9594"
"  %9596 = add nuw nsw i32 %9595, %9594"
"  %9596 = add nuw nsw i32 %9595, %9594" -> "  %9764 = and i32 %9596, 65535""  %9596 = add nuw nsw i32 %9595, %9594" -> "  %9597 = lshr i32 %9596, 16"
"  %9597 = lshr i32 %9596, 16"
"  %9597 = lshr i32 %9596, 16" -> "  %9600 = add nuw i32 %9599, %9597"
"  %9598 = add nuw i32 %9549, %9559"
"  %9598 = add nuw i32 %9549, %9559" -> "  %9599 = add nuw i32 %9598, %9560"
"  %9599 = add nuw i32 %9598, %9560"
"  %9599 = add nuw i32 %9598, %9560" -> "  %9600 = add nuw i32 %9599, %9597"
"  %9600 = add nuw i32 %9599, %9597"
"  %9600 = add nuw i32 %9599, %9597" -> "  %9770 = and i32 %9600, 65535""  %9600 = add nuw i32 %9599, %9597" -> "  %9773 = lshr i32 %9600, 16"
"  %9601 = mul nuw nsw i32 %9270, 17857"
"  %9601 = mul nuw nsw i32 %9270, 17857" -> "  %9720 = and i32 %9601, 65535""  %9601 = mul nuw nsw i32 %9270, 17857" -> "  %9602 = lshr i32 %9601, 16"
"  %9602 = lshr i32 %9601, 16"
"  %9602 = lshr i32 %9601, 16" -> "  %9605 = add nuw nsw i32 %9604, %9602"
"  %9603 = mul nuw nsw i32 %9273, 17857"
"  %9603 = mul nuw nsw i32 %9273, 17857" -> "  %9606 = and i32 %9603, 2147418112""  %9603 = mul nuw nsw i32 %9273, 17857" -> "  %9604 = and i32 %9603, 65535"
"  %9604 = and i32 %9603, 65535"
"  %9604 = and i32 %9603, 65535" -> "  %9605 = add nuw nsw i32 %9604, %9602"
"  %9605 = add nuw nsw i32 %9604, %9602"
"  %9605 = add nuw nsw i32 %9604, %9602" -> "  %9607 = add nuw nsw i32 %9605, %9606"
"  %9606 = and i32 %9603, 2147418112"
"  %9606 = and i32 %9603, 2147418112" -> "  %9607 = add nuw nsw i32 %9605, %9606"
"  %9607 = add nuw nsw i32 %9605, %9606"
"  %9607 = add nuw nsw i32 %9605, %9606" -> "  %9611 = lshr i32 %9607, 16""  %9607 = add nuw nsw i32 %9605, %9606" -> "  %9609 = and i32 %9607, 65535"
"  %9608 = mul nuw i32 %9270, 46547"
"  %9608 = mul nuw i32 %9270, 46547" -> "  %9610 = add nuw i32 %9609, %9608"
"  %9609 = and i32 %9607, 65535"
"  %9609 = and i32 %9607, 65535" -> "  %9610 = add nuw i32 %9609, %9608"
"  %9610 = add nuw i32 %9609, %9608"
"  %9610 = add nuw i32 %9609, %9608" -> "  %9723 = and i32 %9610, 65535""  %9610 = add nuw i32 %9609, %9608" -> "  %9614 = lshr i32 %9610, 16"
"  %9611 = lshr i32 %9607, 16"
"  %9611 = lshr i32 %9607, 16" -> "  %9613 = add nuw i32 %9611, %9612"
"  %9612 = mul nuw i32 %9273, 46547"
"  %9612 = mul nuw i32 %9273, 46547" -> "  %9613 = add nuw i32 %9611, %9612"
"  %9613 = add nuw i32 %9611, %9612"
"  %9613 = add nuw i32 %9611, %9612" -> "  %9617 = and i32 %9613, -65536""  %9613 = add nuw i32 %9611, %9612" -> "  %9615 = and i32 %9613, 65535"
"  %9614 = lshr i32 %9610, 16"
"  %9614 = lshr i32 %9610, 16" -> "  %9616 = add nuw nsw i32 %9614, %9615"
"  %9615 = and i32 %9613, 65535"
"  %9615 = and i32 %9613, 65535" -> "  %9616 = add nuw nsw i32 %9614, %9615"
"  %9616 = add nuw nsw i32 %9614, %9615"
"  %9616 = add nuw nsw i32 %9614, %9615" -> "  %9618 = add nuw i32 %9616, %9617"
"  %9617 = and i32 %9613, -65536"
"  %9617 = and i32 %9613, -65536" -> "  %9618 = add nuw i32 %9616, %9617"
"  %9618 = add nuw i32 %9616, %9617"
"  %9618 = add nuw i32 %9616, %9617" -> "  %9637 = and i32 %9618, 65535""  %9618 = add nuw i32 %9616, %9617" -> "  %9640 = lshr i32 %9618, 16"
"  %9619 = mul nuw nsw i32 %9290, 17857"
"  %9619 = mul nuw nsw i32 %9290, 17857" -> "  %9620 = lshr i32 %9619, 16""  %9619 = mul nuw nsw i32 %9290, 17857" -> "  %9638 = and i32 %9619, 65535"
"  %9620 = lshr i32 %9619, 16"
"  %9620 = lshr i32 %9619, 16" -> "  %9623 = add nuw nsw i32 %9622, %9620"
"  %9621 = mul nuw nsw i32 %9293, 17857"
"  %9621 = mul nuw nsw i32 %9293, 17857" -> "  %9624 = and i32 %9621, 2147418112""  %9621 = mul nuw nsw i32 %9293, 17857" -> "  %9622 = and i32 %9621, 65535"
"  %9622 = and i32 %9621, 65535"
"  %9622 = and i32 %9621, 65535" -> "  %9623 = add nuw nsw i32 %9622, %9620"
"  %9623 = add nuw nsw i32 %9622, %9620"
"  %9623 = add nuw nsw i32 %9622, %9620" -> "  %9625 = add nuw nsw i32 %9623, %9624"
"  %9624 = and i32 %9621, 2147418112"
"  %9624 = and i32 %9621, 2147418112" -> "  %9625 = add nuw nsw i32 %9623, %9624"
"  %9625 = add nuw nsw i32 %9623, %9624"
"  %9625 = add nuw nsw i32 %9623, %9624" -> "  %9629 = lshr i32 %9625, 16""  %9625 = add nuw nsw i32 %9623, %9624" -> "  %9627 = and i32 %9625, 65535"
"  %9626 = mul nuw i32 %9290, 46547"
"  %9626 = mul nuw i32 %9290, 46547" -> "  %9628 = add nuw i32 %9627, %9626"
"  %9627 = and i32 %9625, 65535"
"  %9627 = and i32 %9625, 65535" -> "  %9628 = add nuw i32 %9627, %9626"
"  %9628 = add nuw i32 %9627, %9626"
"  %9628 = add nuw i32 %9627, %9626" -> "  %9641 = and i32 %9628, 65535""  %9628 = add nuw i32 %9627, %9626" -> "  %9632 = lshr i32 %9628, 16"
"  %9629 = lshr i32 %9625, 16"
"  %9629 = lshr i32 %9625, 16" -> "  %9631 = add nuw i32 %9629, %9630"
"  %9630 = mul nuw i32 %9293, 46547"
"  %9630 = mul nuw i32 %9293, 46547" -> "  %9631 = add nuw i32 %9629, %9630"
"  %9631 = add nuw i32 %9629, %9630"
"  %9631 = add nuw i32 %9629, %9630" -> "  %9635 = and i32 %9631, -65536""  %9631 = add nuw i32 %9629, %9630" -> "  %9633 = and i32 %9631, 65535"
"  %9632 = lshr i32 %9628, 16"
"  %9632 = lshr i32 %9628, 16" -> "  %9634 = add nuw nsw i32 %9633, %9632"
"  %9633 = and i32 %9631, 65535"
"  %9633 = and i32 %9631, 65535" -> "  %9634 = add nuw nsw i32 %9633, %9632"
"  %9634 = add nuw nsw i32 %9633, %9632"
"  %9634 = add nuw nsw i32 %9633, %9632" -> "  %9636 = add nuw i32 %9634, %9635"
"  %9635 = and i32 %9631, -65536"
"  %9635 = and i32 %9631, -65536" -> "  %9636 = add nuw i32 %9634, %9635"
"  %9636 = add nuw i32 %9634, %9635"
"  %9636 = add nuw i32 %9634, %9635" -> "  %9644 = add nuw i32 %9636, %9643"
"  %9637 = and i32 %9618, 65535"
"  %9637 = and i32 %9618, 65535" -> "  %9639 = add nuw nsw i32 %9637, %9638"
"  %9638 = and i32 %9619, 65535"
"  %9638 = and i32 %9619, 65535" -> "  %9639 = add nuw nsw i32 %9637, %9638"
"  %9639 = add nuw nsw i32 %9637, %9638"
"  %9639 = add nuw nsw i32 %9637, %9638" -> "  %9668 = and i32 %9639, 65535""  %9639 = add nuw nsw i32 %9637, %9638" -> "  %9646 = lshr i32 %9639, 16"
"  %9640 = lshr i32 %9618, 16"
"  %9640 = lshr i32 %9618, 16" -> "  %9642 = add nuw nsw i32 %9641, %9640"
"  %9641 = and i32 %9628, 65535"
"  %9641 = and i32 %9628, 65535" -> "  %9642 = add nuw nsw i32 %9641, %9640"
"  %9642 = add nuw nsw i32 %9641, %9640"
"  %9642 = add nuw nsw i32 %9641, %9640" -> "  %9645 = and i32 %9642, 65535""  %9642 = add nuw nsw i32 %9641, %9640" -> "  %9643 = lshr i32 %9642, 16"
"  %9643 = lshr i32 %9642, 16"
"  %9643 = lshr i32 %9642, 16" -> "  %9644 = add nuw i32 %9636, %9643"
"  %9644 = add nuw i32 %9636, %9643"
"  %9644 = add nuw i32 %9636, %9643" -> "  %9649 = add nuw i32 %9644, %9648"
"  %9645 = and i32 %9642, 65535"
"  %9645 = and i32 %9642, 65535" -> "  %9647 = add nuw nsw i32 %9645, %9646"
"  %9646 = lshr i32 %9639, 16"
"  %9646 = lshr i32 %9639, 16" -> "  %9647 = add nuw nsw i32 %9645, %9646"
"  %9647 = add nuw nsw i32 %9645, %9646"
"  %9647 = add nuw nsw i32 %9645, %9646" -> "  %9671 = and i32 %9647, 65535""  %9647 = add nuw nsw i32 %9645, %9646" -> "  %9648 = lshr i32 %9647, 16"
"  %9648 = lshr i32 %9647, 16"
"  %9648 = lshr i32 %9647, 16" -> "  %9649 = add nuw i32 %9644, %9648"
"  %9649 = add nuw i32 %9644, %9648"
"  %9649 = add nuw i32 %9644, %9648" -> "  %9700 = lshr i32 %9649, 16""  %9649 = add nuw i32 %9644, %9648" -> "  %9696 = and i32 %9649, 65535"
"  %9650 = mul nuw nsw i32 %9270, 31112"
"  %9650 = mul nuw nsw i32 %9270, 31112" -> "  %9669 = and i32 %9650, 65528""  %9650 = mul nuw nsw i32 %9270, 31112" -> "  %9651 = lshr i32 %9650, 16"
"  %9651 = lshr i32 %9650, 16"
"  %9651 = lshr i32 %9650, 16" -> "  %9654 = add nuw nsw i32 %9653, %9651"
"  %9652 = mul nuw nsw i32 %9273, 31112"
"  %9652 = mul nuw nsw i32 %9273, 31112" -> "  %9655 = and i32 %9652, 2147418112""  %9652 = mul nuw nsw i32 %9273, 31112" -> "  %9653 = and i32 %9652, 65528"
"  %9653 = and i32 %9652, 65528"
"  %9653 = and i32 %9652, 65528" -> "  %9654 = add nuw nsw i32 %9653, %9651"
"  %9654 = add nuw nsw i32 %9653, %9651"
"  %9654 = add nuw nsw i32 %9653, %9651" -> "  %9656 = add nuw nsw i32 %9654, %9655"
"  %9655 = and i32 %9652, 2147418112"
"  %9655 = and i32 %9652, 2147418112" -> "  %9656 = add nuw nsw i32 %9654, %9655"
"  %9656 = add nuw nsw i32 %9654, %9655"
"  %9656 = add nuw nsw i32 %9654, %9655" -> "  %9660 = lshr i32 %9656, 16""  %9656 = add nuw nsw i32 %9654, %9655" -> "  %9658 = and i32 %9656, 65535"
"  %9657 = mul nuw i32 %9270, 42170"
"  %9657 = mul nuw i32 %9270, 42170" -> "  %9659 = add nuw i32 %9658, %9657"
"  %9658 = and i32 %9656, 65535"
"  %9658 = and i32 %9656, 65535" -> "  %9659 = add nuw i32 %9658, %9657"
"  %9659 = add nuw i32 %9658, %9657"
"  %9659 = add nuw i32 %9658, %9657" -> "  %9672 = and i32 %9659, 65535""  %9659 = add nuw i32 %9658, %9657" -> "  %9663 = lshr i32 %9659, 16"
"  %9660 = lshr i32 %9656, 16"
"  %9660 = lshr i32 %9656, 16" -> "  %9662 = add nuw i32 %9660, %9661"
"  %9661 = mul nuw i32 %9273, 42170"
"  %9661 = mul nuw i32 %9273, 42170" -> "  %9662 = add nuw i32 %9660, %9661"
"  %9662 = add nuw i32 %9660, %9661"
"  %9662 = add nuw i32 %9660, %9661" -> "  %9666 = and i32 %9662, -65536""  %9662 = add nuw i32 %9660, %9661" -> "  %9664 = and i32 %9662, 65535"
"  %9663 = lshr i32 %9659, 16"
"  %9663 = lshr i32 %9659, 16" -> "  %9665 = add nuw nsw i32 %9663, %9664"
"  %9664 = and i32 %9662, 65535"
"  %9664 = and i32 %9662, 65535" -> "  %9665 = add nuw nsw i32 %9663, %9664"
"  %9665 = add nuw nsw i32 %9663, %9664"
"  %9665 = add nuw nsw i32 %9663, %9664" -> "  %9667 = add nuw i32 %9665, %9666"
"  %9666 = and i32 %9662, -65536"
"  %9666 = and i32 %9662, -65536" -> "  %9667 = add nuw i32 %9665, %9666"
"  %9667 = add nuw i32 %9665, %9666"
"  %9667 = add nuw i32 %9665, %9666" -> "  %9675 = add nuw i32 %9667, %9674"
"  %9668 = and i32 %9639, 65535"
"  %9668 = and i32 %9639, 65535" -> "  %9670 = add nuw nsw i32 %9668, %9669"
"  %9669 = and i32 %9650, 65528"
"  %9669 = and i32 %9650, 65528" -> "  %9670 = add nuw nsw i32 %9668, %9669"
"  %9670 = add nuw nsw i32 %9668, %9669"
"  %9670 = add nuw nsw i32 %9668, %9669" -> "  %9729 = and i32 %9670, 65535""  %9670 = add nuw nsw i32 %9668, %9669" -> "  %9677 = lshr i32 %9670, 16"
"  %9671 = and i32 %9647, 65535"
"  %9671 = and i32 %9647, 65535" -> "  %9673 = add nuw nsw i32 %9671, %9672"
"  %9672 = and i32 %9659, 65535"
"  %9672 = and i32 %9659, 65535" -> "  %9673 = add nuw nsw i32 %9671, %9672"
"  %9673 = add nuw nsw i32 %9671, %9672"
"  %9673 = add nuw nsw i32 %9671, %9672" -> "  %9676 = and i32 %9673, 65535""  %9673 = add nuw nsw i32 %9671, %9672" -> "  %9674 = lshr i32 %9673, 16"
"  %9674 = lshr i32 %9673, 16"
"  %9674 = lshr i32 %9673, 16" -> "  %9675 = add nuw i32 %9667, %9674"
"  %9675 = add nuw i32 %9667, %9674"
"  %9675 = add nuw i32 %9667, %9674" -> "  %9680 = add nuw i32 %9675, %9679"
"  %9676 = and i32 %9673, 65535"
"  %9676 = and i32 %9673, 65535" -> "  %9678 = add nuw nsw i32 %9676, %9677"
"  %9677 = lshr i32 %9670, 16"
"  %9677 = lshr i32 %9670, 16" -> "  %9678 = add nuw nsw i32 %9676, %9677"
"  %9678 = add nuw nsw i32 %9676, %9677"
"  %9678 = add nuw nsw i32 %9676, %9677" -> "  %9732 = and i32 %9678, 65535""  %9678 = add nuw nsw i32 %9676, %9677" -> "  %9679 = lshr i32 %9678, 16"
"  %9679 = lshr i32 %9678, 16"
"  %9679 = lshr i32 %9678, 16" -> "  %9680 = add nuw i32 %9675, %9679"
"  %9680 = add nuw i32 %9675, %9679"
"  %9680 = add nuw i32 %9675, %9679" -> "  %9713 = lshr i32 %9680, 16""  %9680 = add nuw i32 %9675, %9679" -> "  %9710 = and i32 %9680, 65535"
"  %9681 = mul nuw nsw i32 %9290, 31112"
"  %9681 = mul nuw nsw i32 %9290, 31112" -> "  %9697 = and i32 %9681, 65528""  %9681 = mul nuw nsw i32 %9290, 31112" -> "  %9682 = lshr i32 %9681, 16"
"  %9682 = lshr i32 %9681, 16"
"  %9682 = lshr i32 %9681, 16" -> "  %9684 = add nuw nsw i32 %9683, %9682"
"  %9683 = mul nuw nsw i32 %9293, 31112"
"  %9683 = mul nuw nsw i32 %9293, 31112" -> "  %9684 = add nuw nsw i32 %9683, %9682"
"  %9684 = add nuw nsw i32 %9683, %9682"
"  %9684 = add nuw nsw i32 %9683, %9682" -> "  %9688 = lshr i32 %9684, 16""  %9684 = add nuw nsw i32 %9683, %9682" -> "  %9686 = and i32 %9684, 65535"
"  %9685 = mul nuw i32 %9290, 42170"
"  %9685 = mul nuw i32 %9290, 42170" -> "  %9687 = add nuw i32 %9686, %9685"
"  %9686 = and i32 %9684, 65535"
"  %9686 = and i32 %9684, 65535" -> "  %9687 = add nuw i32 %9686, %9685"
"  %9687 = add nuw i32 %9686, %9685"
"  %9687 = add nuw i32 %9686, %9685" -> "  %9699 = and i32 %9687, 65535""  %9687 = add nuw i32 %9686, %9685" -> "  %9691 = lshr i32 %9687, 16"
"  %9688 = lshr i32 %9684, 16"
"  %9688 = lshr i32 %9684, 16" -> "  %9690 = add nuw i32 %9688, %9689"
"  %9689 = mul nuw i32 %9293, 42170"
"  %9689 = mul nuw i32 %9293, 42170" -> "  %9690 = add nuw i32 %9688, %9689"
"  %9690 = add nuw i32 %9688, %9689"
"  %9690 = add nuw i32 %9688, %9689" -> "  %9694 = and i32 %9690, -65536""  %9690 = add nuw i32 %9688, %9689" -> "  %9692 = and i32 %9690, 65535"
"  %9691 = lshr i32 %9687, 16"
"  %9691 = lshr i32 %9687, 16" -> "  %9693 = add nuw nsw i32 %9691, %9692"
"  %9692 = and i32 %9690, 65535"
"  %9692 = and i32 %9690, 65535" -> "  %9693 = add nuw nsw i32 %9691, %9692"
"  %9693 = add nuw nsw i32 %9691, %9692"
"  %9693 = add nuw nsw i32 %9691, %9692" -> "  %9695 = add nuw i32 %9693, %9694"
"  %9694 = and i32 %9690, -65536"
"  %9694 = and i32 %9690, -65536" -> "  %9695 = add nuw i32 %9693, %9694"
"  %9695 = add nuw i32 %9693, %9694"
"  %9695 = add nuw i32 %9693, %9694" -> "  %9703 = add nuw i32 %9695, %9702"
"  %9696 = and i32 %9649, 65535"
"  %9696 = and i32 %9649, 65535" -> "  %9698 = add nuw nsw i32 %9696, %9697"
"  %9697 = and i32 %9681, 65528"
"  %9697 = and i32 %9681, 65528" -> "  %9698 = add nuw nsw i32 %9696, %9697"
"  %9698 = add nuw nsw i32 %9696, %9697"
"  %9698 = add nuw nsw i32 %9696, %9697" -> "  %9709 = and i32 %9698, 65535""  %9698 = add nuw nsw i32 %9696, %9697" -> "  %9705 = lshr i32 %9698, 16"
"  %9699 = and i32 %9687, 65535"
"  %9699 = and i32 %9687, 65535" -> "  %9701 = add nuw nsw i32 %9700, %9699"
"  %9700 = lshr i32 %9649, 16"
"  %9700 = lshr i32 %9649, 16" -> "  %9701 = add nuw nsw i32 %9700, %9699"
"  %9701 = add nuw nsw i32 %9700, %9699"
"  %9701 = add nuw nsw i32 %9700, %9699" -> "  %9704 = and i32 %9701, 65535""  %9701 = add nuw nsw i32 %9700, %9699" -> "  %9702 = lshr i32 %9701, 16"
"  %9702 = lshr i32 %9701, 16"
"  %9702 = lshr i32 %9701, 16" -> "  %9703 = add nuw i32 %9695, %9702"
"  %9703 = add nuw i32 %9695, %9702"
"  %9703 = add nuw i32 %9695, %9702" -> "  %9708 = add nuw i32 %9703, %9707"
"  %9704 = and i32 %9701, 65535"
"  %9704 = and i32 %9701, 65535" -> "  %9706 = add nuw nsw i32 %9704, %9705"
"  %9705 = lshr i32 %9698, 16"
"  %9705 = lshr i32 %9698, 16" -> "  %9706 = add nuw nsw i32 %9704, %9705"
"  %9706 = add nuw nsw i32 %9704, %9705"
"  %9706 = add nuw nsw i32 %9704, %9705" -> "  %9712 = and i32 %9706, 65535""  %9706 = add nuw nsw i32 %9704, %9705" -> "  %9707 = lshr i32 %9706, 16"
"  %9707 = lshr i32 %9706, 16"
"  %9707 = lshr i32 %9706, 16" -> "  %9708 = add nuw i32 %9703, %9707"
"  %9708 = add nuw i32 %9703, %9707"
"  %9708 = add nuw i32 %9703, %9707" -> "  %9757 = add nuw i32 %9708, %9718"
"  %9709 = and i32 %9698, 65535"
"  %9709 = and i32 %9698, 65535" -> "  %9711 = add nuw nsw i32 %9710, %9709"
"  %9710 = and i32 %9680, 65535"
"  %9710 = and i32 %9680, 65535" -> "  %9711 = add nuw nsw i32 %9710, %9709"
"  %9711 = add nuw nsw i32 %9710, %9709"
"  %9711 = add nuw nsw i32 %9710, %9709" -> "  %9746 = and i32 %9711, 65535""  %9711 = add nuw nsw i32 %9710, %9709" -> "  %9715 = lshr i32 %9711, 16"
"  %9712 = and i32 %9706, 65535"
"  %9712 = and i32 %9706, 65535" -> "  %9714 = add nuw nsw i32 %9713, %9712"
"  %9713 = lshr i32 %9680, 16"
"  %9713 = lshr i32 %9680, 16" -> "  %9714 = add nuw nsw i32 %9713, %9712"
"  %9714 = add nuw nsw i32 %9713, %9712"
"  %9714 = add nuw nsw i32 %9713, %9712" -> "  %9718 = lshr i32 %9714, 16""  %9714 = add nuw nsw i32 %9713, %9712" -> "  %9716 = and i32 %9714, 65535"
"  %9715 = lshr i32 %9711, 16"
"  %9715 = lshr i32 %9711, 16" -> "  %9717 = add nuw nsw i32 %9716, %9715"
"  %9716 = and i32 %9714, 65535"
"  %9716 = and i32 %9714, 65535" -> "  %9717 = add nuw nsw i32 %9716, %9715"
"  %9717 = add nuw nsw i32 %9716, %9715"
"  %9717 = add nuw nsw i32 %9716, %9715" -> "  %9753 = and i32 %9717, 65535""  %9717 = add nuw nsw i32 %9716, %9715" -> "  %9719 = lshr i32 %9717, 16"
"  %9718 = lshr i32 %9714, 16"
"  %9718 = lshr i32 %9714, 16" -> "  %9757 = add nuw i32 %9708, %9718"
"  %9719 = lshr i32 %9717, 16"
"  %9719 = lshr i32 %9717, 16" -> "  %9758 = add nuw i32 %9757, %9719"
"  %9720 = and i32 %9601, 65535"
"  %9720 = and i32 %9601, 65535" -> "  %9722 = add nuw nsw i32 %9721, %9720"
"  %9721 = and i32 %9433, 65535"
"  %9721 = and i32 %9433, 65535" -> "  %9722 = add nuw nsw i32 %9721, %9720"
"  %9722 = add nuw nsw i32 %9721, %9720"
"  %9722 = add nuw nsw i32 %9721, %9720" -> "  %9760 = and i32 %9722, 65535""  %9722 = add nuw nsw i32 %9721, %9720" -> "  %9726 = lshr i32 %9722, 16"
"  %9723 = and i32 %9610, 65535"
"  %9723 = and i32 %9610, 65535" -> "  %9725 = add nuw nsw i32 %9724, %9723"
"  %9724 = and i32 %9436, 65535"
"  %9724 = and i32 %9436, 65535" -> "  %9725 = add nuw nsw i32 %9724, %9723"
"  %9725 = add nuw nsw i32 %9724, %9723"
"  %9725 = add nuw nsw i32 %9724, %9723" -> "  %9739 = lshr i32 %9725, 16""  %9725 = add nuw nsw i32 %9724, %9723" -> "  %9727 = and i32 %9725, 65535"
"  %9726 = lshr i32 %9722, 16"
"  %9726 = lshr i32 %9722, 16" -> "  %9728 = add nuw nsw i32 %9727, %9726"
"  %9727 = and i32 %9725, 65535"
"  %9727 = and i32 %9725, 65535" -> "  %9728 = add nuw nsw i32 %9727, %9726"
"  %9728 = add nuw nsw i32 %9727, %9726"
"  %9728 = add nuw nsw i32 %9727, %9726" -> "  %9763 = and i32 %9728, 65535""  %9728 = add nuw nsw i32 %9727, %9726" -> "  %9741 = lshr i32 %9728, 16"
"  %9729 = and i32 %9670, 65535"
"  %9729 = and i32 %9670, 65535" -> "  %9731 = add nuw nsw i32 %9730, %9729"
"  %9730 = and i32 %9438, 65535"
"  %9730 = and i32 %9438, 65535" -> "  %9731 = add nuw nsw i32 %9730, %9729"
"  %9731 = add nuw nsw i32 %9730, %9729"
"  %9731 = add nuw nsw i32 %9730, %9729" -> "  %9738 = and i32 %9731, 65535""  %9731 = add nuw nsw i32 %9730, %9729" -> "  %9735 = lshr i32 %9731, 16"
"  %9732 = and i32 %9678, 65535"
"  %9732 = and i32 %9678, 65535" -> "  %9734 = add nuw nsw i32 %9733, %9732"
"  %9733 = lshr i32 %9438, 16"
"  %9733 = lshr i32 %9438, 16" -> "  %9734 = add nuw nsw i32 %9733, %9732"
"  %9734 = add nuw nsw i32 %9733, %9732"
"  %9734 = add nuw nsw i32 %9733, %9732" -> "  %9747 = lshr i32 %9734, 16""  %9734 = add nuw nsw i32 %9733, %9732" -> "  %9736 = and i32 %9734, 65535"
"  %9735 = lshr i32 %9731, 16"
"  %9735 = lshr i32 %9731, 16" -> "  %9737 = add nuw nsw i32 %9736, %9735"
"  %9736 = and i32 %9734, 65535"
"  %9736 = and i32 %9734, 65535" -> "  %9737 = add nuw nsw i32 %9736, %9735"
"  %9737 = add nuw nsw i32 %9736, %9735"
"  %9737 = add nuw nsw i32 %9736, %9735" -> "  %9749 = lshr i32 %9737, 16""  %9737 = add nuw nsw i32 %9736, %9735" -> "  %9744 = and i32 %9737, 65535"
"  %9738 = and i32 %9731, 65535"
"  %9738 = and i32 %9731, 65535" -> "  %9740 = add nuw nsw i32 %9738, %9739"
"  %9739 = lshr i32 %9725, 16"
"  %9739 = lshr i32 %9725, 16" -> "  %9740 = add nuw nsw i32 %9738, %9739"
"  %9740 = add nuw nsw i32 %9738, %9739"
"  %9740 = add nuw nsw i32 %9738, %9739" -> "  %9742 = add nuw nsw i32 %9740, %9741"
"  %9741 = lshr i32 %9728, 16"
"  %9741 = lshr i32 %9728, 16" -> "  %9742 = add nuw nsw i32 %9740, %9741"
"  %9742 = add nuw nsw i32 %9740, %9741"
"  %9742 = add nuw nsw i32 %9740, %9741" -> "  %9769 = and i32 %9742, 65535""  %9742 = add nuw nsw i32 %9740, %9741" -> "  %9743 = lshr i32 %9742, 16"
"  %9743 = lshr i32 %9742, 16"
"  %9743 = lshr i32 %9742, 16" -> "  %9745 = add nuw nsw i32 %9743, %9744"
"  %9744 = and i32 %9737, 65535"
"  %9744 = and i32 %9737, 65535" -> "  %9745 = add nuw nsw i32 %9743, %9744"
"  %9745 = add nuw nsw i32 %9743, %9744"
"  %9745 = add nuw nsw i32 %9743, %9744" -> "  %9772 = and i32 %9745, 65535""  %9745 = add nuw nsw i32 %9743, %9744" -> "  %9751 = lshr i32 %9745, 16"
"  %9746 = and i32 %9711, 65535"
"  %9746 = and i32 %9711, 65535" -> "  %9748 = add nuw nsw i32 %9747, %9746"
"  %9747 = lshr i32 %9734, 16"
"  %9747 = lshr i32 %9734, 16" -> "  %9748 = add nuw nsw i32 %9747, %9746"
"  %9748 = add nuw nsw i32 %9747, %9746"
"  %9748 = add nuw nsw i32 %9747, %9746" -> "  %9750 = add nuw nsw i32 %9748, %9749"
"  %9749 = lshr i32 %9737, 16"
"  %9749 = lshr i32 %9737, 16" -> "  %9750 = add nuw nsw i32 %9748, %9749"
"  %9750 = add nuw nsw i32 %9748, %9749"
"  %9750 = add nuw nsw i32 %9748, %9749" -> "  %9752 = add nuw nsw i32 %9750, %9751"
"  %9751 = lshr i32 %9745, 16"
"  %9751 = lshr i32 %9745, 16" -> "  %9752 = add nuw nsw i32 %9750, %9751"
"  %9752 = add nuw nsw i32 %9750, %9751"
"  %9752 = add nuw nsw i32 %9750, %9751" -> "  %9786 = and i32 %9752, 65535""  %9752 = add nuw nsw i32 %9750, %9751" -> "  %9754 = lshr i32 %9752, 16"
"  %9753 = and i32 %9717, 65535"
"  %9753 = and i32 %9717, 65535" -> "  %9755 = add nuw nsw i32 %9754, %9753"
"  %9754 = lshr i32 %9752, 16"
"  %9754 = lshr i32 %9752, 16" -> "  %9755 = add nuw nsw i32 %9754, %9753"
"  %9755 = add nuw nsw i32 %9754, %9753"
"  %9755 = add nuw nsw i32 %9754, %9753" -> "  %9794 = and i32 %9755, 65535""  %9755 = add nuw nsw i32 %9754, %9753" -> "  %9756 = lshr i32 %9755, 16"
"  %9756 = lshr i32 %9755, 16"
"  %9756 = lshr i32 %9755, 16" -> "  %9759 = add nuw i32 %9758, %9756"
"  %9757 = add nuw i32 %9708, %9718"
"  %9757 = add nuw i32 %9708, %9718" -> "  %9758 = add nuw i32 %9757, %9719"
"  %9758 = add nuw i32 %9757, %9719"
"  %9758 = add nuw i32 %9757, %9719" -> "  %9759 = add nuw i32 %9758, %9756"
"  %9759 = add nuw i32 %9758, %9756"
"  %9759 = add nuw i32 %9758, %9756" -> "  %9797 = add nuw i32 %9759, %9796"
"  %9760 = and i32 %9722, 65535"
"  %9760 = and i32 %9722, 65535" -> "  %9762 = add nuw nsw i32 %9761, %9760"
"  %9761 = and i32 %9593, 65535"
"  %9761 = and i32 %9593, 65535" -> "  %9762 = add nuw nsw i32 %9761, %9760"
"  %9762 = add nuw nsw i32 %9761, %9760"
"  %9762 = add nuw nsw i32 %9761, %9760" -> "  %10466 = and i32 %9762, 65535""  %9762 = add nuw nsw i32 %9761, %9760" -> "  %9766 = lshr i32 %9762, 16"
"  %9763 = and i32 %9728, 65535"
"  %9763 = and i32 %9728, 65535" -> "  %9765 = add nuw nsw i32 %9764, %9763"
"  %9764 = and i32 %9596, 65535"
"  %9764 = and i32 %9596, 65535" -> "  %9765 = add nuw nsw i32 %9764, %9763"
"  %9765 = add nuw nsw i32 %9764, %9763"
"  %9765 = add nuw nsw i32 %9764, %9763" -> "  %9779 = lshr i32 %9765, 16""  %9765 = add nuw nsw i32 %9764, %9763" -> "  %9767 = and i32 %9765, 65535"
"  %9766 = lshr i32 %9762, 16"
"  %9766 = lshr i32 %9762, 16" -> "  %9768 = add nuw nsw i32 %9767, %9766"
"  %9767 = and i32 %9765, 65535"
"  %9767 = and i32 %9765, 65535" -> "  %9768 = add nuw nsw i32 %9767, %9766"
"  %9768 = add nuw nsw i32 %9767, %9766"
"  %9768 = add nuw nsw i32 %9767, %9766" -> "  %10469 = and i32 %9768, 65535""  %9768 = add nuw nsw i32 %9767, %9766" -> "  %9780 = lshr i32 %9768, 16"
"  %9769 = and i32 %9742, 65535"
"  %9769 = and i32 %9742, 65535" -> "  %9771 = add nuw nsw i32 %9770, %9769"
"  %9770 = and i32 %9600, 65535"
"  %9770 = and i32 %9600, 65535" -> "  %9771 = add nuw nsw i32 %9770, %9769"
"  %9771 = add nuw nsw i32 %9770, %9769"
"  %9771 = add nuw nsw i32 %9770, %9769" -> "  %9778 = and i32 %9771, 65535""  %9771 = add nuw nsw i32 %9770, %9769" -> "  %9775 = lshr i32 %9771, 16"
"  %9772 = and i32 %9745, 65535"
"  %9772 = and i32 %9745, 65535" -> "  %9774 = add nuw nsw i32 %9772, %9773"
"  %9773 = lshr i32 %9600, 16"
"  %9773 = lshr i32 %9600, 16" -> "  %9774 = add nuw nsw i32 %9772, %9773"
"  %9774 = add nuw nsw i32 %9772, %9773"
"  %9774 = add nuw nsw i32 %9772, %9773" -> "  %9787 = lshr i32 %9774, 16""  %9774 = add nuw nsw i32 %9772, %9773" -> "  %9776 = and i32 %9774, 65535"
"  %9775 = lshr i32 %9771, 16"
"  %9775 = lshr i32 %9771, 16" -> "  %9777 = add nuw nsw i32 %9776, %9775"
"  %9776 = and i32 %9774, 65535"
"  %9776 = and i32 %9774, 65535" -> "  %9777 = add nuw nsw i32 %9776, %9775"
"  %9777 = add nuw nsw i32 %9776, %9775"
"  %9777 = add nuw nsw i32 %9776, %9775" -> "  %9789 = lshr i32 %9777, 16""  %9777 = add nuw nsw i32 %9776, %9775" -> "  %9784 = and i32 %9777, 65535"
"  %9778 = and i32 %9771, 65535"
"  %9778 = and i32 %9771, 65535" -> "  %9782 = add nuw nsw i32 %9781, %9778"
"  %9779 = lshr i32 %9765, 16"
"  %9779 = lshr i32 %9765, 16" -> "  %9781 = add nuw nsw i32 %9780, %9779"
"  %9780 = lshr i32 %9768, 16"
"  %9780 = lshr i32 %9768, 16" -> "  %9781 = add nuw nsw i32 %9780, %9779"
"  %9781 = add nuw nsw i32 %9780, %9779"
"  %9781 = add nuw nsw i32 %9780, %9779" -> "  %9782 = add nuw nsw i32 %9781, %9778"
"  %9782 = add nuw nsw i32 %9781, %9778"
"  %9782 = add nuw nsw i32 %9781, %9778" -> "  %10478 = and i32 %9782, 65535""  %9782 = add nuw nsw i32 %9781, %9778" -> "  %9783 = lshr i32 %9782, 16"
"  %9783 = lshr i32 %9782, 16"
"  %9783 = lshr i32 %9782, 16" -> "  %9785 = add nuw nsw i32 %9784, %9783"
"  %9784 = and i32 %9777, 65535"
"  %9784 = and i32 %9777, 65535" -> "  %9785 = add nuw nsw i32 %9784, %9783"
"  %9785 = add nuw nsw i32 %9784, %9783"
"  %9785 = add nuw nsw i32 %9784, %9783" -> "  %10481 = and i32 %9785, 65535""  %9785 = add nuw nsw i32 %9784, %9783" -> "  %9791 = lshr i32 %9785, 16"
"  %9786 = and i32 %9752, 65535"
"  %9786 = and i32 %9752, 65535" -> "  %9788 = add nuw nsw i32 %9787, %9786"
"  %9787 = lshr i32 %9774, 16"
"  %9787 = lshr i32 %9774, 16" -> "  %9788 = add nuw nsw i32 %9787, %9786"
"  %9788 = add nuw nsw i32 %9787, %9786"
"  %9788 = add nuw nsw i32 %9787, %9786" -> "  %9790 = add nuw nsw i32 %9788, %9789"
"  %9789 = lshr i32 %9777, 16"
"  %9789 = lshr i32 %9777, 16" -> "  %9790 = add nuw nsw i32 %9788, %9789"
"  %9790 = add nuw nsw i32 %9788, %9789"
"  %9790 = add nuw nsw i32 %9788, %9789" -> "  %9792 = add nuw nsw i32 %9790, %9791"
"  %9791 = lshr i32 %9785, 16"
"  %9791 = lshr i32 %9785, 16" -> "  %9792 = add nuw nsw i32 %9790, %9791"
"  %9792 = add nuw nsw i32 %9790, %9791"
"  %9792 = add nuw nsw i32 %9790, %9791" -> "  %10492 = and i32 %9792, 65535""  %9792 = add nuw nsw i32 %9790, %9791" -> "  %9793 = lshr i32 %9792, 16"
"  %9793 = lshr i32 %9792, 16"
"  %9793 = lshr i32 %9792, 16" -> "  %9795 = add nuw nsw i32 %9793, %9794"
"  %9794 = and i32 %9755, 65535"
"  %9794 = and i32 %9755, 65535" -> "  %9795 = add nuw nsw i32 %9793, %9794"
"  %9795 = add nuw nsw i32 %9793, %9794"
"  %9795 = add nuw nsw i32 %9793, %9794" -> "  %10495 = and i32 %9795, 65535""  %9795 = add nuw nsw i32 %9793, %9794" -> "  %9796 = lshr i32 %9795, 16"
"  %9796 = lshr i32 %9795, 16"
"  %9796 = lshr i32 %9795, 16" -> "  %9797 = add nuw i32 %9759, %9796"
"  %9797 = add nuw i32 %9759, %9796"
"  %9797 = add nuw i32 %9759, %9796" -> "  %10501 = and i32 %9797, 65535""  %9797 = add nuw i32 %9759, %9796" -> "  %10504 = lshr i32 %9797, 16"
"  %9798 = and i32 %9100, 65535"
"  %9798 = and i32 %9100, 65535" -> "  %11603 = mul nuw nsw i32 %9798, 4087""  %9798 = and i32 %9100, 65535" -> "  %11610 = mul nuw nsw i32 %9798, 11561""  %9798 = and i32 %9100, 65535" -> "  %11652 = mul nuw nsw i32 %9798, 21884""  %9798 = and i32 %9100, 65535" -> "  %11659 = mul nuw i32 %9798, 36786""  %9798 = and i32 %9100, 65535" -> "  %11311 = mul nuw i32 %9798, 42779""  %9798 = and i32 %9100, 65535" -> "  %11318 = mul nuw nsw i32 %9798, 9871""  %9798 = and i32 %9100, 65535" -> "  %11360 = mul nuw nsw i32 %9798, 24315""  %9798 = and i32 %9100, 65535" -> "  %11367 = mul nuw nsw i32 %9798, 29744""  %9798 = and i32 %9100, 65535" -> "  %10104 = mul nuw nsw i32 %9798, 17857""  %9798 = and i32 %9100, 65535" -> "  %10153 = mul nuw nsw i32 %9798, 31112""  %9798 = and i32 %9100, 65535" -> "  %10157 = mul nuw i32 %9798, 42170""  %9798 = and i32 %9100, 65535" -> "  %9861 = mul nuw i32 %9798, 62728""  %9798 = and i32 %9100, 65535" -> "  %9807 = mul nuw i32 %9798, 45147""  %9798 = and i32 %9100, 65535" -> "  %9800 = mul nuw i32 %9798, 37996""  %9798 = and i32 %9100, 65535" -> "  %10111 = mul nuw i32 %9798, 46547""  %9798 = and i32 %9100, 65535" -> "  %9854 = mul nuw nsw i32 %9798, 1324"
"  %9799 = and i32 %9106, 65535"
"  %9799 = and i32 %9106, 65535" -> "  %9802 = mul nuw i32 %9799, 37996""  %9799 = and i32 %9106, 65535" -> "  %9811 = mul nuw i32 %9799, 45147""  %9799 = and i32 %9106, 65535" -> "  %9856 = mul nuw nsw i32 %9799, 1324""  %9799 = and i32 %9106, 65535" -> "  %9865 = mul nuw i32 %9799, 62728""  %9799 = and i32 %9106, 65535" -> "  %10161 = mul nuw i32 %9799, 42170""  %9799 = and i32 %9106, 65535" -> "  %10155 = mul nuw nsw i32 %9799, 31112""  %9799 = and i32 %9106, 65535" -> "  %10115 = mul nuw i32 %9799, 46547""  %9799 = and i32 %9106, 65535" -> "  %10106 = mul nuw nsw i32 %9799, 17857""  %9799 = and i32 %9106, 65535" -> "  %11371 = mul nuw nsw i32 %9799, 29744""  %9799 = and i32 %9106, 65535" -> "  %11362 = mul nuw nsw i32 %9799, 24315""  %9799 = and i32 %9106, 65535" -> "  %11322 = mul nuw nsw i32 %9799, 9871""  %9799 = and i32 %9106, 65535" -> "  %11313 = mul nuw i32 %9799, 42779""  %9799 = and i32 %9106, 65535" -> "  %11663 = mul nuw i32 %9799, 36786""  %9799 = and i32 %9106, 65535" -> "  %11654 = mul nuw nsw i32 %9799, 21884""  %9799 = and i32 %9106, 65535" -> "  %11614 = mul nuw nsw i32 %9799, 11561""  %9799 = and i32 %9106, 65535" -> "  %11605 = mul nuw nsw i32 %9799, 4087"
"  %9800 = mul nuw i32 %9798, 37996"
"  %9800 = mul nuw i32 %9798, 37996" -> "  %10467 = and i32 %9800, 65532""  %9800 = mul nuw i32 %9798, 37996" -> "  %9801 = lshr i32 %9800, 16"
"  %9801 = lshr i32 %9800, 16"
"  %9801 = lshr i32 %9800, 16" -> "  %9804 = add nuw nsw i32 %9803, %9801"
"  %9802 = mul nuw i32 %9799, 37996"
"  %9802 = mul nuw i32 %9799, 37996" -> "  %9805 = and i32 %9802, -65536""  %9802 = mul nuw i32 %9799, 37996" -> "  %9803 = and i32 %9802, 65532"
"  %9803 = and i32 %9802, 65532"
"  %9803 = and i32 %9802, 65532" -> "  %9804 = add nuw nsw i32 %9803, %9801"
"  %9804 = add nuw nsw i32 %9803, %9801"
"  %9804 = add nuw nsw i32 %9803, %9801" -> "  %9806 = add nuw i32 %9804, %9805"
"  %9805 = and i32 %9802, -65536"
"  %9805 = and i32 %9802, -65536" -> "  %9806 = add nuw i32 %9804, %9805"
"  %9806 = add nuw i32 %9804, %9805"
"  %9806 = add nuw i32 %9804, %9805" -> "  %9810 = lshr i32 %9806, 16""  %9806 = add nuw i32 %9804, %9805" -> "  %9808 = and i32 %9806, 65535"
"  %9807 = mul nuw i32 %9798, 45147"
"  %9807 = mul nuw i32 %9798, 45147" -> "  %9809 = add nuw i32 %9808, %9807"
"  %9808 = and i32 %9806, 65535"
"  %9808 = and i32 %9806, 65535" -> "  %9809 = add nuw i32 %9808, %9807"
"  %9809 = add nuw i32 %9808, %9807"
"  %9809 = add nuw i32 %9808, %9807" -> "  %10470 = and i32 %9809, 65535""  %9809 = add nuw i32 %9808, %9807" -> "  %9813 = lshr i32 %9809, 16"
"  %9810 = lshr i32 %9806, 16"
"  %9810 = lshr i32 %9806, 16" -> "  %9812 = add nuw i32 %9810, %9811"
"  %9811 = mul nuw i32 %9799, 45147"
"  %9811 = mul nuw i32 %9799, 45147" -> "  %9812 = add nuw i32 %9810, %9811"
"  %9812 = add nuw i32 %9810, %9811"
"  %9812 = add nuw i32 %9810, %9811" -> "  %9816 = and i32 %9812, -65536""  %9812 = add nuw i32 %9810, %9811" -> "  %9814 = and i32 %9812, 65535"
"  %9813 = lshr i32 %9809, 16"
"  %9813 = lshr i32 %9809, 16" -> "  %9815 = add nuw nsw i32 %9813, %9814"
"  %9814 = and i32 %9812, 65535"
"  %9814 = and i32 %9812, 65535" -> "  %9815 = add nuw nsw i32 %9813, %9814"
"  %9815 = add nuw nsw i32 %9813, %9814"
"  %9815 = add nuw nsw i32 %9813, %9814" -> "  %9817 = add nuw i32 %9815, %9816"
"  %9816 = and i32 %9812, -65536"
"  %9816 = and i32 %9812, -65536" -> "  %9817 = add nuw i32 %9815, %9816"
"  %9817 = add nuw i32 %9815, %9816"
"  %9817 = add nuw i32 %9815, %9816" -> "  %9842 = lshr i32 %9817, 16""  %9817 = add nuw i32 %9815, %9816" -> "  %9838 = and i32 %9817, 65535"
"  %9818 = and i32 %9123, 65535"
"  %9818 = and i32 %9123, 65535" -> "  %9822 = mul nuw i32 %9818, 37996""  %9818 = and i32 %9123, 65535" -> "  %9831 = mul nuw i32 %9818, 45147""  %9818 = and i32 %9123, 65535" -> "  %9887 = mul nuw nsw i32 %9818, 1324""  %9818 = and i32 %9123, 65535" -> "  %9896 = mul nuw i32 %9818, 62728""  %9818 = and i32 %9123, 65535" -> "  %10192 = mul nuw i32 %9818, 42170""  %9818 = and i32 %9123, 65535" -> "  %10183 = mul nuw nsw i32 %9818, 31112""  %9818 = and i32 %9123, 65535" -> "  %10133 = mul nuw i32 %9818, 46547""  %9818 = and i32 %9123, 65535" -> "  %10124 = mul nuw nsw i32 %9818, 17857""  %9818 = and i32 %9123, 65535" -> "  %11402 = mul nuw nsw i32 %9818, 29744""  %9818 = and i32 %9123, 65535" -> "  %11393 = mul nuw nsw i32 %9818, 24315""  %9818 = and i32 %9123, 65535" -> "  %11340 = mul nuw nsw i32 %9818, 9871""  %9818 = and i32 %9123, 65535" -> "  %11331 = mul nuw i32 %9818, 42779""  %9818 = and i32 %9123, 65535" -> "  %11694 = mul nuw i32 %9818, 36786""  %9818 = and i32 %9123, 65535" -> "  %11685 = mul nuw nsw i32 %9818, 21884""  %9818 = and i32 %9123, 65535" -> "  %11632 = mul nuw nsw i32 %9818, 11561""  %9818 = and i32 %9123, 65535" -> "  %11623 = mul nuw nsw i32 %9818, 4087"
"  %9819 = and i32 %9120, 65535"
"  %9819 = and i32 %9120, 65535" -> "  %11391 = mul nuw nsw i32 %9819, 24315""  %9819 = and i32 %9120, 65535" -> "  %9820 = mul nuw i32 %9819, 37996""  %9819 = and i32 %9120, 65535" -> "  %9827 = mul nuw i32 %9819, 45147""  %9819 = and i32 %9120, 65535" -> "  %9885 = mul nuw nsw i32 %9819, 1324""  %9819 = and i32 %9120, 65535" -> "  %9892 = mul nuw i32 %9819, 62728""  %9819 = and i32 %9120, 65535" -> "  %10188 = mul nuw i32 %9819, 42170""  %9819 = and i32 %9120, 65535" -> "  %10181 = mul nuw nsw i32 %9819, 31112""  %9819 = and i32 %9120, 65535" -> "  %10129 = mul nuw i32 %9819, 46547""  %9819 = and i32 %9120, 65535" -> "  %10122 = mul nuw nsw i32 %9819, 17857""  %9819 = and i32 %9120, 65535" -> "  %11398 = mul nuw nsw i32 %9819, 29744""  %9819 = and i32 %9120, 65535" -> "  %11336 = mul nuw nsw i32 %9819, 9871""  %9819 = and i32 %9120, 65535" -> "  %11329 = mul nuw i32 %9819, 42779""  %9819 = and i32 %9120, 65535" -> "  %11690 = mul nuw i32 %9819, 36786""  %9819 = and i32 %9120, 65535" -> "  %11683 = mul nuw nsw i32 %9819, 21884""  %9819 = and i32 %9120, 65535" -> "  %11628 = mul nuw nsw i32 %9819, 11561""  %9819 = and i32 %9120, 65535" -> "  %11621 = mul nuw nsw i32 %9819, 4087"
"  %9820 = mul nuw i32 %9819, 37996"
"  %9820 = mul nuw i32 %9819, 37996" -> "  %9839 = and i32 %9820, 65532""  %9820 = mul nuw i32 %9819, 37996" -> "  %9821 = lshr i32 %9820, 16"
"  %9821 = lshr i32 %9820, 16"
"  %9821 = lshr i32 %9820, 16" -> "  %9824 = add nuw nsw i32 %9823, %9821"
"  %9822 = mul nuw i32 %9818, 37996"
"  %9822 = mul nuw i32 %9818, 37996" -> "  %9825 = and i32 %9822, -65536""  %9822 = mul nuw i32 %9818, 37996" -> "  %9823 = and i32 %9822, 65532"
"  %9823 = and i32 %9822, 65532"
"  %9823 = and i32 %9822, 65532" -> "  %9824 = add nuw nsw i32 %9823, %9821"
"  %9824 = add nuw nsw i32 %9823, %9821"
"  %9824 = add nuw nsw i32 %9823, %9821" -> "  %9826 = add nuw i32 %9824, %9825"
"  %9825 = and i32 %9822, -65536"
"  %9825 = and i32 %9822, -65536" -> "  %9826 = add nuw i32 %9824, %9825"
"  %9826 = add nuw i32 %9824, %9825"
"  %9826 = add nuw i32 %9824, %9825" -> "  %9830 = lshr i32 %9826, 16""  %9826 = add nuw i32 %9824, %9825" -> "  %9828 = and i32 %9826, 65535"
"  %9827 = mul nuw i32 %9819, 45147"
"  %9827 = mul nuw i32 %9819, 45147" -> "  %9829 = add nuw i32 %9828, %9827"
"  %9828 = and i32 %9826, 65535"
"  %9828 = and i32 %9826, 65535" -> "  %9829 = add nuw i32 %9828, %9827"
"  %9829 = add nuw i32 %9828, %9827"
"  %9829 = add nuw i32 %9828, %9827" -> "  %9841 = and i32 %9829, 65535""  %9829 = add nuw i32 %9828, %9827" -> "  %9833 = lshr i32 %9829, 16"
"  %9830 = lshr i32 %9826, 16"
"  %9830 = lshr i32 %9826, 16" -> "  %9832 = add nuw i32 %9830, %9831"
"  %9831 = mul nuw i32 %9818, 45147"
"  %9831 = mul nuw i32 %9818, 45147" -> "  %9832 = add nuw i32 %9830, %9831"
"  %9832 = add nuw i32 %9830, %9831"
"  %9832 = add nuw i32 %9830, %9831" -> "  %9836 = and i32 %9832, -65536""  %9832 = add nuw i32 %9830, %9831" -> "  %9834 = and i32 %9832, 65535"
"  %9833 = lshr i32 %9829, 16"
"  %9833 = lshr i32 %9829, 16" -> "  %9835 = add nuw nsw i32 %9833, %9834"
"  %9834 = and i32 %9832, 65535"
"  %9834 = and i32 %9832, 65535" -> "  %9835 = add nuw nsw i32 %9833, %9834"
"  %9835 = add nuw nsw i32 %9833, %9834"
"  %9835 = add nuw nsw i32 %9833, %9834" -> "  %9837 = add nuw i32 %9835, %9836"
"  %9836 = and i32 %9832, -65536"
"  %9836 = and i32 %9832, -65536" -> "  %9837 = add nuw i32 %9835, %9836"
"  %9837 = add nuw i32 %9835, %9836"
"  %9837 = add nuw i32 %9835, %9836" -> "  %9850 = and i32 %9837, -65536""  %9837 = add nuw i32 %9835, %9836" -> "  %9848 = and i32 %9837, 65535"
"  %9838 = and i32 %9817, 65535"
"  %9838 = and i32 %9817, 65535" -> "  %9840 = add nuw nsw i32 %9838, %9839"
"  %9839 = and i32 %9820, 65532"
"  %9839 = and i32 %9820, 65532" -> "  %9840 = add nuw nsw i32 %9838, %9839"
"  %9840 = add nuw nsw i32 %9838, %9839"
"  %9840 = add nuw nsw i32 %9838, %9839" -> "  %9872 = and i32 %9840, 65535""  %9840 = add nuw nsw i32 %9838, %9839" -> "  %9844 = lshr i32 %9840, 16"
"  %9841 = and i32 %9829, 65535"
"  %9841 = and i32 %9829, 65535" -> "  %9843 = add nuw nsw i32 %9841, %9842"
"  %9842 = lshr i32 %9817, 16"
"  %9842 = lshr i32 %9817, 16" -> "  %9843 = add nuw nsw i32 %9841, %9842"
"  %9843 = add nuw nsw i32 %9841, %9842"
"  %9843 = add nuw nsw i32 %9841, %9842" -> "  %9847 = lshr i32 %9843, 16""  %9843 = add nuw nsw i32 %9841, %9842" -> "  %9845 = and i32 %9843, 65535"
"  %9844 = lshr i32 %9840, 16"
"  %9844 = lshr i32 %9840, 16" -> "  %9846 = add nuw nsw i32 %9845, %9844"
"  %9845 = and i32 %9843, 65535"
"  %9845 = and i32 %9843, 65535" -> "  %9846 = add nuw nsw i32 %9845, %9844"
"  %9846 = add nuw nsw i32 %9845, %9844"
"  %9846 = add nuw nsw i32 %9845, %9844" -> "  %9875 = and i32 %9846, 65535""  %9846 = add nuw nsw i32 %9845, %9844" -> "  %9852 = lshr i32 %9846, 16"
"  %9847 = lshr i32 %9843, 16"
"  %9847 = lshr i32 %9843, 16" -> "  %9849 = add nuw nsw i32 %9848, %9847"
"  %9848 = and i32 %9837, 65535"
"  %9848 = and i32 %9837, 65535" -> "  %9849 = add nuw nsw i32 %9848, %9847"
"  %9849 = add nuw nsw i32 %9848, %9847"
"  %9849 = add nuw nsw i32 %9848, %9847" -> "  %9851 = add nuw i32 %9849, %9850"
"  %9850 = and i32 %9837, -65536"
"  %9850 = and i32 %9837, -65536" -> "  %9851 = add nuw i32 %9849, %9850"
"  %9851 = add nuw i32 %9849, %9850"
"  %9851 = add nuw i32 %9849, %9850" -> "  %9853 = add nuw i32 %9851, %9852"
"  %9852 = lshr i32 %9846, 16"
"  %9852 = lshr i32 %9846, 16" -> "  %9853 = add nuw i32 %9851, %9852"
"  %9853 = add nuw i32 %9851, %9852"
"  %9853 = add nuw i32 %9851, %9852" -> "  %9907 = lshr i32 %9853, 16""  %9853 = add nuw i32 %9851, %9852" -> "  %9903 = and i32 %9853, 65535"
"  %9854 = mul nuw nsw i32 %9798, 1324"
"  %9854 = mul nuw nsw i32 %9798, 1324" -> "  %9873 = and i32 %9854, 65532""  %9854 = mul nuw nsw i32 %9798, 1324" -> "  %9855 = lshr i32 %9854, 16"
"  %9855 = lshr i32 %9854, 16"
"  %9855 = lshr i32 %9854, 16" -> "  %9858 = add nuw nsw i32 %9857, %9855"
"  %9856 = mul nuw nsw i32 %9799, 1324"
"  %9856 = mul nuw nsw i32 %9799, 1324" -> "  %9859 = and i32 %9856, 134152192""  %9856 = mul nuw nsw i32 %9799, 1324" -> "  %9857 = and i32 %9856, 65532"
"  %9857 = and i32 %9856, 65532"
"  %9857 = and i32 %9856, 65532" -> "  %9858 = add nuw nsw i32 %9857, %9855"
"  %9858 = add nuw nsw i32 %9857, %9855"
"  %9858 = add nuw nsw i32 %9857, %9855" -> "  %9860 = add nuw nsw i32 %9858, %9859"
"  %9859 = and i32 %9856, 134152192"
"  %9859 = and i32 %9856, 134152192" -> "  %9860 = add nuw nsw i32 %9858, %9859"
"  %9860 = add nuw nsw i32 %9858, %9859"
"  %9860 = add nuw nsw i32 %9858, %9859" -> "  %9864 = lshr i32 %9860, 16""  %9860 = add nuw nsw i32 %9858, %9859" -> "  %9862 = and i32 %9860, 65535"
"  %9861 = mul nuw i32 %9798, 62728"
"  %9861 = mul nuw i32 %9798, 62728" -> "  %9863 = add nuw i32 %9862, %9861"
"  %9862 = and i32 %9860, 65535"
"  %9862 = and i32 %9860, 65535" -> "  %9863 = add nuw i32 %9862, %9861"
"  %9863 = add nuw i32 %9862, %9861"
"  %9863 = add nuw i32 %9862, %9861" -> "  %9876 = and i32 %9863, 65535""  %9863 = add nuw i32 %9862, %9861" -> "  %9867 = lshr i32 %9863, 16"
"  %9864 = lshr i32 %9860, 16"
"  %9864 = lshr i32 %9860, 16" -> "  %9866 = add nuw i32 %9864, %9865"
"  %9865 = mul nuw i32 %9799, 62728"
"  %9865 = mul nuw i32 %9799, 62728" -> "  %9866 = add nuw i32 %9864, %9865"
"  %9866 = add nuw i32 %9864, %9865"
"  %9866 = add nuw i32 %9864, %9865" -> "  %9870 = and i32 %9866, -65536""  %9866 = add nuw i32 %9864, %9865" -> "  %9868 = and i32 %9866, 65535"
"  %9867 = lshr i32 %9863, 16"
"  %9867 = lshr i32 %9863, 16" -> "  %9869 = add nuw nsw i32 %9867, %9868"
"  %9868 = and i32 %9866, 65535"
"  %9868 = and i32 %9866, 65535" -> "  %9869 = add nuw nsw i32 %9867, %9868"
"  %9869 = add nuw nsw i32 %9867, %9868"
"  %9869 = add nuw nsw i32 %9867, %9868" -> "  %9871 = add nuw i32 %9869, %9870"
"  %9870 = and i32 %9866, -65536"
"  %9870 = and i32 %9866, -65536" -> "  %9871 = add nuw i32 %9869, %9870"
"  %9871 = add nuw i32 %9869, %9870"
"  %9871 = add nuw i32 %9869, %9870" -> "  %9879 = add nuw i32 %9871, %9878"
"  %9872 = and i32 %9840, 65535"
"  %9872 = and i32 %9840, 65535" -> "  %9874 = add nuw nsw i32 %9872, %9873"
"  %9873 = and i32 %9854, 65532"
"  %9873 = and i32 %9854, 65532" -> "  %9874 = add nuw nsw i32 %9872, %9873"
"  %9874 = add nuw nsw i32 %9872, %9873"
"  %9874 = add nuw nsw i32 %9872, %9873" -> "  %10479 = and i32 %9874, 65535""  %9874 = add nuw nsw i32 %9872, %9873" -> "  %9881 = lshr i32 %9874, 16"
"  %9875 = and i32 %9846, 65535"
"  %9875 = and i32 %9846, 65535" -> "  %9877 = add nuw nsw i32 %9875, %9876"
"  %9876 = and i32 %9863, 65535"
"  %9876 = and i32 %9863, 65535" -> "  %9877 = add nuw nsw i32 %9875, %9876"
"  %9877 = add nuw nsw i32 %9875, %9876"
"  %9877 = add nuw nsw i32 %9875, %9876" -> "  %9880 = and i32 %9877, 65535""  %9877 = add nuw nsw i32 %9875, %9876" -> "  %9878 = lshr i32 %9877, 16"
"  %9878 = lshr i32 %9877, 16"
"  %9878 = lshr i32 %9877, 16" -> "  %9879 = add nuw i32 %9871, %9878"
"  %9879 = add nuw i32 %9871, %9878"
"  %9879 = add nuw i32 %9871, %9878" -> "  %9884 = add nuw i32 %9879, %9883"
"  %9880 = and i32 %9877, 65535"
"  %9880 = and i32 %9877, 65535" -> "  %9882 = add nuw nsw i32 %9880, %9881"
"  %9881 = lshr i32 %9874, 16"
"  %9881 = lshr i32 %9874, 16" -> "  %9882 = add nuw nsw i32 %9880, %9881"
"  %9882 = add nuw nsw i32 %9880, %9881"
"  %9882 = add nuw nsw i32 %9880, %9881" -> "  %10482 = and i32 %9882, 65535""  %9882 = add nuw nsw i32 %9880, %9881" -> "  %9883 = lshr i32 %9882, 16"
"  %9883 = lshr i32 %9882, 16"
"  %9883 = lshr i32 %9882, 16" -> "  %9884 = add nuw i32 %9879, %9883"
"  %9884 = add nuw i32 %9879, %9883"
"  %9884 = add nuw i32 %9879, %9883" -> "  %9920 = lshr i32 %9884, 16""  %9884 = add nuw i32 %9879, %9883" -> "  %9917 = and i32 %9884, 65535"
"  %9885 = mul nuw nsw i32 %9819, 1324"
"  %9885 = mul nuw nsw i32 %9819, 1324" -> "  %9904 = and i32 %9885, 65532""  %9885 = mul nuw nsw i32 %9819, 1324" -> "  %9886 = lshr i32 %9885, 16"
"  %9886 = lshr i32 %9885, 16"
"  %9886 = lshr i32 %9885, 16" -> "  %9889 = add nuw nsw i32 %9888, %9886"
"  %9887 = mul nuw nsw i32 %9818, 1324"
"  %9887 = mul nuw nsw i32 %9818, 1324" -> "  %9890 = and i32 %9887, 134152192""  %9887 = mul nuw nsw i32 %9818, 1324" -> "  %9888 = and i32 %9887, 65532"
"  %9888 = and i32 %9887, 65532"
"  %9888 = and i32 %9887, 65532" -> "  %9889 = add nuw nsw i32 %9888, %9886"
"  %9889 = add nuw nsw i32 %9888, %9886"
"  %9889 = add nuw nsw i32 %9888, %9886" -> "  %9891 = add nuw nsw i32 %9889, %9890"
"  %9890 = and i32 %9887, 134152192"
"  %9890 = and i32 %9887, 134152192" -> "  %9891 = add nuw nsw i32 %9889, %9890"
"  %9891 = add nuw nsw i32 %9889, %9890"
"  %9891 = add nuw nsw i32 %9889, %9890" -> "  %9895 = lshr i32 %9891, 16""  %9891 = add nuw nsw i32 %9889, %9890" -> "  %9893 = and i32 %9891, 65535"
"  %9892 = mul nuw i32 %9819, 62728"
"  %9892 = mul nuw i32 %9819, 62728" -> "  %9894 = add nuw i32 %9893, %9892"
"  %9893 = and i32 %9891, 65535"
"  %9893 = and i32 %9891, 65535" -> "  %9894 = add nuw i32 %9893, %9892"
"  %9894 = add nuw i32 %9893, %9892"
"  %9894 = add nuw i32 %9893, %9892" -> "  %9906 = and i32 %9894, 65535""  %9894 = add nuw i32 %9893, %9892" -> "  %9898 = lshr i32 %9894, 16"
"  %9895 = lshr i32 %9891, 16"
"  %9895 = lshr i32 %9891, 16" -> "  %9897 = add nuw i32 %9895, %9896"
"  %9896 = mul nuw i32 %9818, 62728"
"  %9896 = mul nuw i32 %9818, 62728" -> "  %9897 = add nuw i32 %9895, %9896"
"  %9897 = add nuw i32 %9895, %9896"
"  %9897 = add nuw i32 %9895, %9896" -> "  %9901 = and i32 %9897, -65536""  %9897 = add nuw i32 %9895, %9896" -> "  %9899 = and i32 %9897, 65535"
"  %9898 = lshr i32 %9894, 16"
"  %9898 = lshr i32 %9894, 16" -> "  %9900 = add nuw nsw i32 %9898, %9899"
"  %9899 = and i32 %9897, 65535"
"  %9899 = and i32 %9897, 65535" -> "  %9900 = add nuw nsw i32 %9898, %9899"
"  %9900 = add nuw nsw i32 %9898, %9899"
"  %9900 = add nuw nsw i32 %9898, %9899" -> "  %9902 = add nuw i32 %9900, %9901"
"  %9901 = and i32 %9897, -65536"
"  %9901 = and i32 %9897, -65536" -> "  %9902 = add nuw i32 %9900, %9901"
"  %9902 = add nuw i32 %9900, %9901"
"  %9902 = add nuw i32 %9900, %9901" -> "  %9910 = add nuw i32 %9902, %9909"
"  %9903 = and i32 %9853, 65535"
"  %9903 = and i32 %9853, 65535" -> "  %9905 = add nuw nsw i32 %9903, %9904"
"  %9904 = and i32 %9885, 65532"
"  %9904 = and i32 %9885, 65532" -> "  %9905 = add nuw nsw i32 %9903, %9904"
"  %9905 = add nuw nsw i32 %9903, %9904"
"  %9905 = add nuw nsw i32 %9903, %9904" -> "  %9916 = and i32 %9905, 65535""  %9905 = add nuw nsw i32 %9903, %9904" -> "  %9912 = lshr i32 %9905, 16"
"  %9906 = and i32 %9894, 65535"
"  %9906 = and i32 %9894, 65535" -> "  %9908 = add nuw nsw i32 %9907, %9906"
"  %9907 = lshr i32 %9853, 16"
"  %9907 = lshr i32 %9853, 16" -> "  %9908 = add nuw nsw i32 %9907, %9906"
"  %9908 = add nuw nsw i32 %9907, %9906"
"  %9908 = add nuw nsw i32 %9907, %9906" -> "  %9911 = and i32 %9908, 65535""  %9908 = add nuw nsw i32 %9907, %9906" -> "  %9909 = lshr i32 %9908, 16"
"  %9909 = lshr i32 %9908, 16"
"  %9909 = lshr i32 %9908, 16" -> "  %9910 = add nuw i32 %9902, %9909"
"  %9910 = add nuw i32 %9902, %9909"
"  %9910 = add nuw i32 %9902, %9909" -> "  %9915 = add nuw i32 %9910, %9914"
"  %9911 = and i32 %9908, 65535"
"  %9911 = and i32 %9908, 65535" -> "  %9913 = add nuw nsw i32 %9912, %9911"
"  %9912 = lshr i32 %9905, 16"
"  %9912 = lshr i32 %9905, 16" -> "  %9913 = add nuw nsw i32 %9912, %9911"
"  %9913 = add nuw nsw i32 %9912, %9911"
"  %9913 = add nuw nsw i32 %9912, %9911" -> "  %9919 = and i32 %9913, 65535""  %9913 = add nuw nsw i32 %9912, %9911" -> "  %9914 = lshr i32 %9913, 16"
"  %9914 = lshr i32 %9913, 16"
"  %9914 = lshr i32 %9913, 16" -> "  %9915 = add nuw i32 %9910, %9914"
"  %9915 = add nuw i32 %9910, %9914"
"  %9915 = add nuw i32 %9910, %9914" -> "  %9928 = and i32 %9915, -65536""  %9915 = add nuw i32 %9910, %9914" -> "  %9926 = and i32 %9915, 65535"
"  %9916 = and i32 %9905, 65535"
"  %9916 = and i32 %9905, 65535" -> "  %9918 = add nuw nsw i32 %9917, %9916"
"  %9917 = and i32 %9884, 65535"
"  %9917 = and i32 %9884, 65535" -> "  %9918 = add nuw nsw i32 %9917, %9916"
"  %9918 = add nuw nsw i32 %9917, %9916"
"  %9918 = add nuw nsw i32 %9917, %9916" -> "  %10067 = and i32 %9918, 65535""  %9918 = add nuw nsw i32 %9917, %9916" -> "  %9922 = lshr i32 %9918, 16"
"  %9919 = and i32 %9913, 65535"
"  %9919 = and i32 %9913, 65535" -> "  %9921 = add nuw nsw i32 %9919, %9920"
"  %9920 = lshr i32 %9884, 16"
"  %9920 = lshr i32 %9884, 16" -> "  %9921 = add nuw nsw i32 %9919, %9920"
"  %9921 = add nuw nsw i32 %9919, %9920"
"  %9921 = add nuw nsw i32 %9919, %9920" -> "  %9925 = lshr i32 %9921, 16""  %9921 = add nuw nsw i32 %9919, %9920" -> "  %9923 = and i32 %9921, 65535"
"  %9922 = lshr i32 %9918, 16"
"  %9922 = lshr i32 %9918, 16" -> "  %9924 = add nuw nsw i32 %9923, %9922"
"  %9923 = and i32 %9921, 65535"
"  %9923 = and i32 %9921, 65535" -> "  %9924 = add nuw nsw i32 %9923, %9922"
"  %9924 = add nuw nsw i32 %9923, %9922"
"  %9924 = add nuw nsw i32 %9923, %9922" -> "  %10070 = and i32 %9924, 65535""  %9924 = add nuw nsw i32 %9923, %9922" -> "  %9930 = lshr i32 %9924, 16"
"  %9925 = lshr i32 %9921, 16"
"  %9925 = lshr i32 %9921, 16" -> "  %9927 = add nuw nsw i32 %9925, %9926"
"  %9926 = and i32 %9915, 65535"
"  %9926 = and i32 %9915, 65535" -> "  %9927 = add nuw nsw i32 %9925, %9926"
"  %9927 = add nuw nsw i32 %9925, %9926"
"  %9927 = add nuw nsw i32 %9925, %9926" -> "  %9929 = add nuw i32 %9927, %9928"
"  %9928 = and i32 %9915, -65536"
"  %9928 = and i32 %9915, -65536" -> "  %9929 = add nuw i32 %9927, %9928"
"  %9929 = add nuw i32 %9927, %9928"
"  %9929 = add nuw i32 %9927, %9928" -> "  %9931 = add nuw i32 %9929, %9930"
"  %9930 = lshr i32 %9924, 16"
"  %9930 = lshr i32 %9924, 16" -> "  %9931 = add nuw i32 %9929, %9930"
"  %9931 = add nuw i32 %9929, %9930"
"  %9931 = add nuw i32 %9929, %9930" -> "  %10076 = and i32 %9931, 65535""  %9931 = add nuw i32 %9929, %9930" -> "  %10079 = lshr i32 %9931, 16"
"  %9932 = and i32 %9130, 65535"
"  %9932 = and i32 %9130, 65535" -> "  %10273 = mul nuw i32 %9932, 46547""  %9932 = and i32 %9130, 65535" -> "  %9933 = mul nuw i32 %9932, 37996""  %9932 = and i32 %9130, 65535" -> "  %9941 = mul nuw i32 %9932, 45147""  %9932 = and i32 %9130, 65535" -> "  %9995 = mul nuw i32 %9932, 62728""  %9932 = and i32 %9130, 65535" -> "  %9988 = mul nuw nsw i32 %9932, 1324""  %9932 = and i32 %9130, 65535" -> "  %10319 = mul nuw i32 %9932, 42170""  %9932 = and i32 %9130, 65535" -> "  %10315 = mul nuw nsw i32 %9932, 31112""  %9932 = and i32 %9130, 65535" -> "  %10266 = mul nuw nsw i32 %9932, 17857""  %9932 = and i32 %9130, 65535" -> "  %11494 = mul nuw nsw i32 %9932, 29744""  %9932 = and i32 %9130, 65535" -> "  %11487 = mul nuw nsw i32 %9932, 24315""  %9932 = and i32 %9130, 65535" -> "  %11445 = mul nuw nsw i32 %9932, 9871""  %9932 = and i32 %9130, 65535" -> "  %11438 = mul nuw i32 %9932, 42779""  %9932 = and i32 %9130, 65535" -> "  %11824 = mul nuw i32 %9932, 36786""  %9932 = and i32 %9130, 65535" -> "  %11817 = mul nuw nsw i32 %9932, 21884""  %9932 = and i32 %9130, 65535" -> "  %11775 = mul nuw nsw i32 %9932, 11561""  %9932 = and i32 %9130, 65535" -> "  %11768 = mul nuw nsw i32 %9932, 4087"
"  %9933 = mul nuw i32 %9932, 37996"
"  %9933 = mul nuw i32 %9932, 37996" -> "  %10066 = and i32 %9933, 65532""  %9933 = mul nuw i32 %9932, 37996" -> "  %9934 = lshr i32 %9933, 16"
"  %9934 = lshr i32 %9933, 16"
"  %9934 = lshr i32 %9933, 16" -> "  %9938 = add nuw nsw i32 %9937, %9934"
"  %9935 = and i32 %9133, 65535"
"  %9935 = and i32 %9133, 65535" -> "  %9936 = mul nuw i32 %9935, 37996""  %9935 = and i32 %9133, 65535" -> "  %9945 = mul nuw i32 %9935, 45147""  %9935 = and i32 %9133, 65535" -> "  %9999 = mul nuw i32 %9935, 62728""  %9935 = and i32 %9133, 65535" -> "  %9990 = mul nuw nsw i32 %9935, 1324""  %9935 = and i32 %9133, 65535" -> "  %10323 = mul nuw i32 %9935, 42170""  %9935 = and i32 %9133, 65535" -> "  %10317 = mul nuw nsw i32 %9935, 31112""  %9935 = and i32 %9133, 65535" -> "  %10277 = mul nuw i32 %9935, 46547""  %9935 = and i32 %9133, 65535" -> "  %10268 = mul nuw nsw i32 %9935, 17857""  %9935 = and i32 %9133, 65535" -> "  %11498 = mul nuw nsw i32 %9935, 29744""  %9935 = and i32 %9133, 65535" -> "  %11489 = mul nuw nsw i32 %9935, 24315""  %9935 = and i32 %9133, 65535" -> "  %11449 = mul nuw nsw i32 %9935, 9871""  %9935 = and i32 %9133, 65535" -> "  %11440 = mul nuw i32 %9935, 42779""  %9935 = and i32 %9133, 65535" -> "  %11828 = mul nuw i32 %9935, 36786""  %9935 = and i32 %9133, 65535" -> "  %11819 = mul nuw nsw i32 %9935, 21884""  %9935 = and i32 %9133, 65535" -> "  %11779 = mul nuw nsw i32 %9935, 11561""  %9935 = and i32 %9133, 65535" -> "  %11770 = mul nuw nsw i32 %9935, 4087"
"  %9936 = mul nuw i32 %9935, 37996"
"  %9936 = mul nuw i32 %9935, 37996" -> "  %9939 = and i32 %9936, -65536""  %9936 = mul nuw i32 %9935, 37996" -> "  %9937 = and i32 %9936, 65532"
"  %9937 = and i32 %9936, 65532"
"  %9937 = and i32 %9936, 65532" -> "  %9938 = add nuw nsw i32 %9937, %9934"
"  %9938 = add nuw nsw i32 %9937, %9934"
"  %9938 = add nuw nsw i32 %9937, %9934" -> "  %9940 = add nuw i32 %9938, %9939"
"  %9939 = and i32 %9936, -65536"
"  %9939 = and i32 %9936, -65536" -> "  %9940 = add nuw i32 %9938, %9939"
"  %9940 = add nuw i32 %9938, %9939"
"  %9940 = add nuw i32 %9938, %9939" -> "  %9944 = lshr i32 %9940, 16""  %9940 = add nuw i32 %9938, %9939" -> "  %9942 = and i32 %9940, 65535"
"  %9941 = mul nuw i32 %9932, 45147"
"  %9941 = mul nuw i32 %9932, 45147" -> "  %9943 = add nuw i32 %9942, %9941"
"  %9942 = and i32 %9940, 65535"
"  %9942 = and i32 %9940, 65535" -> "  %9943 = add nuw i32 %9942, %9941"
"  %9943 = add nuw i32 %9942, %9941"
"  %9943 = add nuw i32 %9942, %9941" -> "  %10069 = and i32 %9943, 65535""  %9943 = add nuw i32 %9942, %9941" -> "  %9947 = lshr i32 %9943, 16"
"  %9944 = lshr i32 %9940, 16"
"  %9944 = lshr i32 %9940, 16" -> "  %9946 = add nuw i32 %9944, %9945"
"  %9945 = mul nuw i32 %9935, 45147"
"  %9945 = mul nuw i32 %9935, 45147" -> "  %9946 = add nuw i32 %9944, %9945"
"  %9946 = add nuw i32 %9944, %9945"
"  %9946 = add nuw i32 %9944, %9945" -> "  %9950 = and i32 %9946, -65536""  %9946 = add nuw i32 %9944, %9945" -> "  %9948 = and i32 %9946, 65535"
"  %9947 = lshr i32 %9943, 16"
"  %9947 = lshr i32 %9943, 16" -> "  %9949 = add nuw nsw i32 %9947, %9948"
"  %9948 = and i32 %9946, 65535"
"  %9948 = and i32 %9946, 65535" -> "  %9949 = add nuw nsw i32 %9947, %9948"
"  %9949 = add nuw nsw i32 %9947, %9948"
"  %9949 = add nuw nsw i32 %9947, %9948" -> "  %9951 = add nuw i32 %9949, %9950"
"  %9950 = and i32 %9946, -65536"
"  %9950 = and i32 %9946, -65536" -> "  %9951 = add nuw i32 %9949, %9950"
"  %9951 = add nuw i32 %9949, %9950"
"  %9951 = add nuw i32 %9949, %9950" -> "  %9976 = lshr i32 %9951, 16""  %9951 = add nuw i32 %9949, %9950" -> "  %9972 = and i32 %9951, 65535"
"  %9952 = and i32 %9135, 65535"
"  %9952 = and i32 %9135, 65535" -> "  %11786 = mul nuw nsw i32 %9952, 4087""  %9952 = and i32 %9135, 65535" -> "  %11793 = mul nuw nsw i32 %9952, 11561""  %9952 = and i32 %9135, 65535" -> "  %11848 = mul nuw nsw i32 %9952, 21884""  %9952 = and i32 %9135, 65535" -> "  %11855 = mul nuw i32 %9952, 36786""  %9952 = and i32 %9135, 65535" -> "  %11456 = mul nuw i32 %9952, 42779""  %9952 = and i32 %9135, 65535" -> "  %11463 = mul nuw nsw i32 %9952, 9871""  %9952 = and i32 %9135, 65535" -> "  %11518 = mul nuw nsw i32 %9952, 24315""  %9952 = and i32 %9135, 65535" -> "  %11525 = mul nuw nsw i32 %9952, 29744""  %9952 = and i32 %9135, 65535" -> "  %10284 = mul nuw nsw i32 %9952, 17857""  %9952 = and i32 %9135, 65535" -> "  %10291 = mul nuw i32 %9952, 46547""  %9952 = and i32 %9135, 65535" -> "  %10343 = mul nuw nsw i32 %9952, 31112""  %9952 = and i32 %9135, 65535" -> "  %10350 = mul nuw i32 %9952, 42170""  %9952 = and i32 %9135, 65535" -> "  %10026 = mul nuw i32 %9952, 62728""  %9952 = and i32 %9135, 65535" -> "  %10019 = mul nuw nsw i32 %9952, 1324""  %9952 = and i32 %9135, 65535" -> "  %9961 = mul nuw i32 %9952, 45147""  %9952 = and i32 %9135, 65535" -> "  %9954 = mul nuw i32 %9952, 37996"
"  %9953 = lshr i32 %9135, 16"
"  %9953 = lshr i32 %9135, 16" -> "  %11788 = mul nuw nsw i32 %9953, 4087""  %9953 = lshr i32 %9135, 16" -> "  %11797 = mul nuw nsw i32 %9953, 11561""  %9953 = lshr i32 %9135, 16" -> "  %11850 = mul nuw nsw i32 %9953, 21884""  %9953 = lshr i32 %9135, 16" -> "  %11859 = mul nuw i32 %9953, 36786""  %9953 = lshr i32 %9135, 16" -> "  %11458 = mul nuw i32 %9953, 42779""  %9953 = lshr i32 %9135, 16" -> "  %11467 = mul nuw nsw i32 %9953, 9871""  %9953 = lshr i32 %9135, 16" -> "  %11520 = mul nuw nsw i32 %9953, 24315""  %9953 = lshr i32 %9135, 16" -> "  %11529 = mul nuw nsw i32 %9953, 29744""  %9953 = lshr i32 %9135, 16" -> "  %10286 = mul nuw nsw i32 %9953, 17857""  %9953 = lshr i32 %9135, 16" -> "  %10295 = mul nuw i32 %9953, 46547""  %9953 = lshr i32 %9135, 16" -> "  %10345 = mul nuw nsw i32 %9953, 31112""  %9953 = lshr i32 %9135, 16" -> "  %10354 = mul nuw i32 %9953, 42170""  %9953 = lshr i32 %9135, 16" -> "  %10030 = mul nuw i32 %9953, 62728""  %9953 = lshr i32 %9135, 16" -> "  %10021 = mul nuw nsw i32 %9953, 1324""  %9953 = lshr i32 %9135, 16" -> "  %9965 = mul nuw i32 %9953, 45147""  %9953 = lshr i32 %9135, 16" -> "  %9956 = mul nuw i32 %9953, 37996"
"  %9954 = mul nuw i32 %9952, 37996"
"  %9954 = mul nuw i32 %9952, 37996" -> "  %9973 = and i32 %9954, 65532""  %9954 = mul nuw i32 %9952, 37996" -> "  %9955 = lshr i32 %9954, 16"
"  %9955 = lshr i32 %9954, 16"
"  %9955 = lshr i32 %9954, 16" -> "  %9958 = add nuw nsw i32 %9955, %9957"
"  %9956 = mul nuw i32 %9953, 37996"
"  %9956 = mul nuw i32 %9953, 37996" -> "  %9959 = and i32 %9956, -65536""  %9956 = mul nuw i32 %9953, 37996" -> "  %9957 = and i32 %9956, 65532"
"  %9957 = and i32 %9956, 65532"
"  %9957 = and i32 %9956, 65532" -> "  %9958 = add nuw nsw i32 %9955, %9957"
"  %9958 = add nuw nsw i32 %9955, %9957"
"  %9958 = add nuw nsw i32 %9955, %9957" -> "  %9960 = add nuw i32 %9958, %9959"
"  %9959 = and i32 %9956, -65536"
"  %9959 = and i32 %9956, -65536" -> "  %9960 = add nuw i32 %9958, %9959"
"  %9960 = add nuw i32 %9958, %9959"
"  %9960 = add nuw i32 %9958, %9959" -> "  %9964 = lshr i32 %9960, 16""  %9960 = add nuw i32 %9958, %9959" -> "  %9962 = and i32 %9960, 65535"
"  %9961 = mul nuw i32 %9952, 45147"
"  %9961 = mul nuw i32 %9952, 45147" -> "  %9963 = add nuw i32 %9962, %9961"
"  %9962 = and i32 %9960, 65535"
"  %9962 = and i32 %9960, 65535" -> "  %9963 = add nuw i32 %9962, %9961"
"  %9963 = add nuw i32 %9962, %9961"
"  %9963 = add nuw i32 %9962, %9961" -> "  %9975 = and i32 %9963, 65535""  %9963 = add nuw i32 %9962, %9961" -> "  %9967 = lshr i32 %9963, 16"
"  %9964 = lshr i32 %9960, 16"
"  %9964 = lshr i32 %9960, 16" -> "  %9966 = add nuw i32 %9964, %9965"
"  %9965 = mul nuw i32 %9953, 45147"
"  %9965 = mul nuw i32 %9953, 45147" -> "  %9966 = add nuw i32 %9964, %9965"
"  %9966 = add nuw i32 %9964, %9965"
"  %9966 = add nuw i32 %9964, %9965" -> "  %9970 = and i32 %9966, -65536""  %9966 = add nuw i32 %9964, %9965" -> "  %9968 = and i32 %9966, 65535"
"  %9967 = lshr i32 %9963, 16"
"  %9967 = lshr i32 %9963, 16" -> "  %9969 = add nuw nsw i32 %9967, %9968"
"  %9968 = and i32 %9966, 65535"
"  %9968 = and i32 %9966, 65535" -> "  %9969 = add nuw nsw i32 %9967, %9968"
"  %9969 = add nuw nsw i32 %9967, %9968"
"  %9969 = add nuw nsw i32 %9967, %9968" -> "  %9971 = add nuw i32 %9969, %9970"
"  %9970 = and i32 %9966, -65536"
"  %9970 = and i32 %9966, -65536" -> "  %9971 = add nuw i32 %9969, %9970"
"  %9971 = add nuw i32 %9969, %9970"
"  %9971 = add nuw i32 %9969, %9970" -> "  %9984 = and i32 %9971, -65536""  %9971 = add nuw i32 %9969, %9970" -> "  %9982 = and i32 %9971, 65535"
"  %9972 = and i32 %9951, 65535"
"  %9972 = and i32 %9951, 65535" -> "  %9974 = add nuw nsw i32 %9972, %9973"
"  %9973 = and i32 %9954, 65532"
"  %9973 = and i32 %9954, 65532" -> "  %9974 = add nuw nsw i32 %9972, %9973"
"  %9974 = add nuw nsw i32 %9972, %9973"
"  %9974 = add nuw nsw i32 %9972, %9973" -> "  %10006 = and i32 %9974, 65535""  %9974 = add nuw nsw i32 %9972, %9973" -> "  %9978 = lshr i32 %9974, 16"
"  %9975 = and i32 %9963, 65535"
"  %9975 = and i32 %9963, 65535" -> "  %9977 = add nuw nsw i32 %9976, %9975"
"  %9976 = lshr i32 %9951, 16"
"  %9976 = lshr i32 %9951, 16" -> "  %9977 = add nuw nsw i32 %9976, %9975"
"  %9977 = add nuw nsw i32 %9976, %9975"
"  %9977 = add nuw nsw i32 %9976, %9975" -> "  %9981 = lshr i32 %9977, 16""  %9977 = add nuw nsw i32 %9976, %9975" -> "  %9979 = and i32 %9977, 65535"
"  %9978 = lshr i32 %9974, 16"
"  %9978 = lshr i32 %9974, 16" -> "  %9980 = add nuw nsw i32 %9979, %9978"
"  %9979 = and i32 %9977, 65535"
"  %9979 = and i32 %9977, 65535" -> "  %9980 = add nuw nsw i32 %9979, %9978"
"  %9980 = add nuw nsw i32 %9979, %9978"
"  %9980 = add nuw nsw i32 %9979, %9978" -> "  %10009 = and i32 %9980, 65535""  %9980 = add nuw nsw i32 %9979, %9978" -> "  %9986 = lshr i32 %9980, 16"
"  %9981 = lshr i32 %9977, 16"
"  %9981 = lshr i32 %9977, 16" -> "  %9983 = add nuw nsw i32 %9982, %9981"
"  %9982 = and i32 %9971, 65535"
"  %9982 = and i32 %9971, 65535" -> "  %9983 = add nuw nsw i32 %9982, %9981"
"  %9983 = add nuw nsw i32 %9982, %9981"
"  %9983 = add nuw nsw i32 %9982, %9981" -> "  %9985 = add nuw i32 %9983, %9984"
"  %9984 = and i32 %9971, -65536"
"  %9984 = and i32 %9971, -65536" -> "  %9985 = add nuw i32 %9983, %9984"
"  %9985 = add nuw i32 %9983, %9984"
"  %9985 = add nuw i32 %9983, %9984" -> "  %9987 = add nuw i32 %9985, %9986"
"  %9986 = lshr i32 %9980, 16"
"  %9986 = lshr i32 %9980, 16" -> "  %9987 = add nuw i32 %9985, %9986"
"  %9987 = add nuw i32 %9985, %9986"
"  %9987 = add nuw i32 %9985, %9986" -> "  %10041 = lshr i32 %9987, 16""  %9987 = add nuw i32 %9985, %9986" -> "  %10037 = and i32 %9987, 65535"
"  %9988 = mul nuw nsw i32 %9932, 1324"
"  %9988 = mul nuw nsw i32 %9932, 1324" -> "  %10007 = and i32 %9988, 65532""  %9988 = mul nuw nsw i32 %9932, 1324" -> "  %9989 = lshr i32 %9988, 16"
"  %9989 = lshr i32 %9988, 16"
"  %9989 = lshr i32 %9988, 16" -> "  %9992 = add nuw nsw i32 %9991, %9989"
"  %9990 = mul nuw nsw i32 %9935, 1324"
"  %9990 = mul nuw nsw i32 %9935, 1324" -> "  %9993 = and i32 %9990, 134152192""  %9990 = mul nuw nsw i32 %9935, 1324" -> "  %9991 = and i32 %9990, 65532"
"  %9991 = and i32 %9990, 65532"
"  %9991 = and i32 %9990, 65532" -> "  %9992 = add nuw nsw i32 %9991, %9989"
"  %9992 = add nuw nsw i32 %9991, %9989"
"  %9992 = add nuw nsw i32 %9991, %9989" -> "  %9994 = add nuw nsw i32 %9992, %9993"
"  %9993 = and i32 %9990, 134152192"
"  %9993 = and i32 %9990, 134152192" -> "  %9994 = add nuw nsw i32 %9992, %9993"
"  %9994 = add nuw nsw i32 %9992, %9993"
"  %9994 = add nuw nsw i32 %9992, %9993" -> "  %9998 = lshr i32 %9994, 16""  %9994 = add nuw nsw i32 %9992, %9993" -> "  %9996 = and i32 %9994, 65535"
"  %9995 = mul nuw i32 %9932, 62728"
"  %9995 = mul nuw i32 %9932, 62728" -> "  %9997 = add nuw i32 %9996, %9995"
"  %9996 = and i32 %9994, 65535"
"  %9996 = and i32 %9994, 65535" -> "  %9997 = add nuw i32 %9996, %9995"
"  %9997 = add nuw i32 %9996, %9995"
"  %9997 = add nuw i32 %9996, %9995" -> "  %10010 = and i32 %9997, 65535""  %9997 = add nuw i32 %9996, %9995" -> "  %10001 = lshr i32 %9997, 16"
"  %9998 = lshr i32 %9994, 16"
"  %9998 = lshr i32 %9994, 16" -> "  %10000 = add nuw i32 %9998, %9999"
"  %9999 = mul nuw i32 %9935, 62728"
"  %9999 = mul nuw i32 %9935, 62728" -> "  %10000 = add nuw i32 %9998, %9999"
"  %10000 = add nuw i32 %9998, %9999"
"  %10000 = add nuw i32 %9998, %9999" -> "  %10004 = and i32 %10000, -65536""  %10000 = add nuw i32 %9998, %9999" -> "  %10002 = and i32 %10000, 65535"
"  %10001 = lshr i32 %9997, 16"
"  %10001 = lshr i32 %9997, 16" -> "  %10003 = add nuw nsw i32 %10001, %10002"
"  %10002 = and i32 %10000, 65535"
"  %10002 = and i32 %10000, 65535" -> "  %10003 = add nuw nsw i32 %10001, %10002"
"  %10003 = add nuw nsw i32 %10001, %10002"
"  %10003 = add nuw nsw i32 %10001, %10002" -> "  %10005 = add nuw i32 %10003, %10004"
"  %10004 = and i32 %10000, -65536"
"  %10004 = and i32 %10000, -65536" -> "  %10005 = add nuw i32 %10003, %10004"
"  %10005 = add nuw i32 %10003, %10004"
"  %10005 = add nuw i32 %10003, %10004" -> "  %10013 = add nuw i32 %10005, %10012"
"  %10006 = and i32 %9974, 65535"
"  %10006 = and i32 %9974, 65535" -> "  %10008 = add nuw nsw i32 %10006, %10007"
"  %10007 = and i32 %9988, 65532"
"  %10007 = and i32 %9988, 65532" -> "  %10008 = add nuw nsw i32 %10006, %10007"
"  %10008 = add nuw nsw i32 %10006, %10007"
"  %10008 = add nuw nsw i32 %10006, %10007" -> "  %10075 = and i32 %10008, 65535""  %10008 = add nuw nsw i32 %10006, %10007" -> "  %10015 = lshr i32 %10008, 16"
"  %10009 = and i32 %9980, 65535"
"  %10009 = and i32 %9980, 65535" -> "  %10011 = add nuw nsw i32 %10009, %10010"
"  %10010 = and i32 %9997, 65535"
"  %10010 = and i32 %9997, 65535" -> "  %10011 = add nuw nsw i32 %10009, %10010"
"  %10011 = add nuw nsw i32 %10009, %10010"
"  %10011 = add nuw nsw i32 %10009, %10010" -> "  %10014 = and i32 %10011, 65535""  %10011 = add nuw nsw i32 %10009, %10010" -> "  %10012 = lshr i32 %10011, 16"
"  %10012 = lshr i32 %10011, 16"
"  %10012 = lshr i32 %10011, 16" -> "  %10013 = add nuw i32 %10005, %10012"
"  %10013 = add nuw i32 %10005, %10012"
"  %10013 = add nuw i32 %10005, %10012" -> "  %10018 = add nuw i32 %10013, %10017"
"  %10014 = and i32 %10011, 65535"
"  %10014 = and i32 %10011, 65535" -> "  %10016 = add nuw nsw i32 %10014, %10015"
"  %10015 = lshr i32 %10008, 16"
"  %10015 = lshr i32 %10008, 16" -> "  %10016 = add nuw nsw i32 %10014, %10015"
"  %10016 = add nuw nsw i32 %10014, %10015"
"  %10016 = add nuw nsw i32 %10014, %10015" -> "  %10078 = and i32 %10016, 65535""  %10016 = add nuw nsw i32 %10014, %10015" -> "  %10017 = lshr i32 %10016, 16"
"  %10017 = lshr i32 %10016, 16"
"  %10017 = lshr i32 %10016, 16" -> "  %10018 = add nuw i32 %10013, %10017"
"  %10018 = add nuw i32 %10013, %10017"
"  %10018 = add nuw i32 %10013, %10017" -> "  %10054 = lshr i32 %10018, 16""  %10018 = add nuw i32 %10013, %10017" -> "  %10051 = and i32 %10018, 65535"
"  %10019 = mul nuw nsw i32 %9952, 1324"
"  %10019 = mul nuw nsw i32 %9952, 1324" -> "  %10038 = and i32 %10019, 65532""  %10019 = mul nuw nsw i32 %9952, 1324" -> "  %10020 = lshr i32 %10019, 16"
"  %10020 = lshr i32 %10019, 16"
"  %10020 = lshr i32 %10019, 16" -> "  %10023 = add nuw nsw i32 %10020, %10022"
"  %10021 = mul nuw nsw i32 %9953, 1324"
"  %10021 = mul nuw nsw i32 %9953, 1324" -> "  %10024 = and i32 %10021, 134152192""  %10021 = mul nuw nsw i32 %9953, 1324" -> "  %10022 = and i32 %10021, 65532"
"  %10022 = and i32 %10021, 65532"
"  %10022 = and i32 %10021, 65532" -> "  %10023 = add nuw nsw i32 %10020, %10022"
"  %10023 = add nuw nsw i32 %10020, %10022"
"  %10023 = add nuw nsw i32 %10020, %10022" -> "  %10025 = add nuw nsw i32 %10023, %10024"
"  %10024 = and i32 %10021, 134152192"
"  %10024 = and i32 %10021, 134152192" -> "  %10025 = add nuw nsw i32 %10023, %10024"
"  %10025 = add nuw nsw i32 %10023, %10024"
"  %10025 = add nuw nsw i32 %10023, %10024" -> "  %10029 = lshr i32 %10025, 16""  %10025 = add nuw nsw i32 %10023, %10024" -> "  %10027 = and i32 %10025, 65535"
"  %10026 = mul nuw i32 %9952, 62728"
"  %10026 = mul nuw i32 %9952, 62728" -> "  %10028 = add nuw i32 %10027, %10026"
"  %10027 = and i32 %10025, 65535"
"  %10027 = and i32 %10025, 65535" -> "  %10028 = add nuw i32 %10027, %10026"
"  %10028 = add nuw i32 %10027, %10026"
"  %10028 = add nuw i32 %10027, %10026" -> "  %10040 = and i32 %10028, 65535""  %10028 = add nuw i32 %10027, %10026" -> "  %10032 = lshr i32 %10028, 16"
"  %10029 = lshr i32 %10025, 16"
"  %10029 = lshr i32 %10025, 16" -> "  %10031 = add nuw i32 %10029, %10030"
"  %10030 = mul nuw i32 %9953, 62728"
"  %10030 = mul nuw i32 %9953, 62728" -> "  %10031 = add nuw i32 %10029, %10030"
"  %10031 = add nuw i32 %10029, %10030"
"  %10031 = add nuw i32 %10029, %10030" -> "  %10035 = and i32 %10031, -65536""  %10031 = add nuw i32 %10029, %10030" -> "  %10033 = and i32 %10031, 65535"
"  %10032 = lshr i32 %10028, 16"
"  %10032 = lshr i32 %10028, 16" -> "  %10034 = add nuw nsw i32 %10032, %10033"
"  %10033 = and i32 %10031, 65535"
"  %10033 = and i32 %10031, 65535" -> "  %10034 = add nuw nsw i32 %10032, %10033"
"  %10034 = add nuw nsw i32 %10032, %10033"
"  %10034 = add nuw nsw i32 %10032, %10033" -> "  %10036 = add nuw i32 %10034, %10035"
"  %10035 = and i32 %10031, -65536"
"  %10035 = and i32 %10031, -65536" -> "  %10036 = add nuw i32 %10034, %10035"
"  %10036 = add nuw i32 %10034, %10035"
"  %10036 = add nuw i32 %10034, %10035" -> "  %10044 = add nuw i32 %10036, %10043"
"  %10037 = and i32 %9987, 65535"
"  %10037 = and i32 %9987, 65535" -> "  %10039 = add nuw nsw i32 %10037, %10038"
"  %10038 = and i32 %10019, 65532"
"  %10038 = and i32 %10019, 65532" -> "  %10039 = add nuw nsw i32 %10037, %10038"
"  %10039 = add nuw nsw i32 %10037, %10038"
"  %10039 = add nuw nsw i32 %10037, %10038" -> "  %10050 = and i32 %10039, 65535""  %10039 = add nuw nsw i32 %10037, %10038" -> "  %10046 = lshr i32 %10039, 16"
"  %10040 = and i32 %10028, 65535"
"  %10040 = and i32 %10028, 65535" -> "  %10042 = add nuw nsw i32 %10041, %10040"
"  %10041 = lshr i32 %9987, 16"
"  %10041 = lshr i32 %9987, 16" -> "  %10042 = add nuw nsw i32 %10041, %10040"
"  %10042 = add nuw nsw i32 %10041, %10040"
"  %10042 = add nuw nsw i32 %10041, %10040" -> "  %10045 = and i32 %10042, 65535""  %10042 = add nuw nsw i32 %10041, %10040" -> "  %10043 = lshr i32 %10042, 16"
"  %10043 = lshr i32 %10042, 16"
"  %10043 = lshr i32 %10042, 16" -> "  %10044 = add nuw i32 %10036, %10043"
"  %10044 = add nuw i32 %10036, %10043"
"  %10044 = add nuw i32 %10036, %10043" -> "  %10049 = add nuw i32 %10044, %10048"
"  %10045 = and i32 %10042, 65535"
"  %10045 = and i32 %10042, 65535" -> "  %10047 = add nuw nsw i32 %10046, %10045"
"  %10046 = lshr i32 %10039, 16"
"  %10046 = lshr i32 %10039, 16" -> "  %10047 = add nuw nsw i32 %10046, %10045"
"  %10047 = add nuw nsw i32 %10046, %10045"
"  %10047 = add nuw nsw i32 %10046, %10045" -> "  %10053 = and i32 %10047, 65535""  %10047 = add nuw nsw i32 %10046, %10045" -> "  %10048 = lshr i32 %10047, 16"
"  %10048 = lshr i32 %10047, 16"
"  %10048 = lshr i32 %10047, 16" -> "  %10049 = add nuw i32 %10044, %10048"
"  %10049 = add nuw i32 %10044, %10048"
"  %10049 = add nuw i32 %10044, %10048" -> "  %10062 = and i32 %10049, -65536""  %10049 = add nuw i32 %10044, %10048" -> "  %10060 = and i32 %10049, 65535"
"  %10050 = and i32 %10039, 65535"
"  %10050 = and i32 %10039, 65535" -> "  %10052 = add nuw nsw i32 %10051, %10050"
"  %10051 = and i32 %10018, 65535"
"  %10051 = and i32 %10018, 65535" -> "  %10052 = add nuw nsw i32 %10051, %10050"
"  %10052 = add nuw nsw i32 %10051, %10050"
"  %10052 = add nuw nsw i32 %10051, %10050" -> "  %10092 = and i32 %10052, 65535""  %10052 = add nuw nsw i32 %10051, %10050" -> "  %10056 = lshr i32 %10052, 16"
"  %10053 = and i32 %10047, 65535"
"  %10053 = and i32 %10047, 65535" -> "  %10055 = add nuw nsw i32 %10053, %10054"
"  %10054 = lshr i32 %10018, 16"
"  %10054 = lshr i32 %10018, 16" -> "  %10055 = add nuw nsw i32 %10053, %10054"
"  %10055 = add nuw nsw i32 %10053, %10054"
"  %10055 = add nuw nsw i32 %10053, %10054" -> "  %10059 = lshr i32 %10055, 16""  %10055 = add nuw nsw i32 %10053, %10054" -> "  %10057 = and i32 %10055, 65535"
"  %10056 = lshr i32 %10052, 16"
"  %10056 = lshr i32 %10052, 16" -> "  %10058 = add nuw nsw i32 %10057, %10056"
"  %10057 = and i32 %10055, 65535"
"  %10057 = and i32 %10055, 65535" -> "  %10058 = add nuw nsw i32 %10057, %10056"
"  %10058 = add nuw nsw i32 %10057, %10056"
"  %10058 = add nuw nsw i32 %10057, %10056" -> "  %10099 = and i32 %10058, 65535""  %10058 = add nuw nsw i32 %10057, %10056" -> "  %10064 = lshr i32 %10058, 16"
"  %10059 = lshr i32 %10055, 16"
"  %10059 = lshr i32 %10055, 16" -> "  %10061 = add nuw nsw i32 %10059, %10060"
"  %10060 = and i32 %10049, 65535"
"  %10060 = and i32 %10049, 65535" -> "  %10061 = add nuw nsw i32 %10059, %10060"
"  %10061 = add nuw nsw i32 %10059, %10060"
"  %10061 = add nuw nsw i32 %10059, %10060" -> "  %10063 = add nuw i32 %10061, %10062"
"  %10062 = and i32 %10049, -65536"
"  %10062 = and i32 %10049, -65536" -> "  %10063 = add nuw i32 %10061, %10062"
"  %10063 = add nuw i32 %10061, %10062"
"  %10063 = add nuw i32 %10061, %10062" -> "  %10065 = add nuw i32 %10063, %10064"
"  %10064 = lshr i32 %10058, 16"
"  %10064 = lshr i32 %10058, 16" -> "  %10065 = add nuw i32 %10063, %10064"
"  %10065 = add nuw i32 %10063, %10064"
"  %10065 = add nuw i32 %10063, %10064" -> "  %10103 = add nuw i32 %10065, %10102"
"  %10066 = and i32 %9933, 65532"
"  %10066 = and i32 %9933, 65532" -> "  %10068 = add nuw nsw i32 %10067, %10066"
"  %10067 = and i32 %9918, 65535"
"  %10067 = and i32 %9918, 65535" -> "  %10068 = add nuw nsw i32 %10067, %10066"
"  %10068 = add nuw nsw i32 %10067, %10066"
"  %10068 = add nuw nsw i32 %10067, %10066" -> "  %10229 = and i32 %10068, 65535""  %10068 = add nuw nsw i32 %10067, %10066" -> "  %10072 = lshr i32 %10068, 16"
"  %10069 = and i32 %9943, 65535"
"  %10069 = and i32 %9943, 65535" -> "  %10071 = add nuw nsw i32 %10070, %10069"
"  %10070 = and i32 %9924, 65535"
"  %10070 = and i32 %9924, 65535" -> "  %10071 = add nuw nsw i32 %10070, %10069"
"  %10071 = add nuw nsw i32 %10070, %10069"
"  %10071 = add nuw nsw i32 %10070, %10069" -> "  %10085 = lshr i32 %10071, 16""  %10071 = add nuw nsw i32 %10070, %10069" -> "  %10073 = and i32 %10071, 65535"
"  %10072 = lshr i32 %10068, 16"
"  %10072 = lshr i32 %10068, 16" -> "  %10074 = add nuw nsw i32 %10073, %10072"
"  %10073 = and i32 %10071, 65535"
"  %10073 = and i32 %10071, 65535" -> "  %10074 = add nuw nsw i32 %10073, %10072"
"  %10074 = add nuw nsw i32 %10073, %10072"
"  %10074 = add nuw nsw i32 %10073, %10072" -> "  %10232 = and i32 %10074, 65535""  %10074 = add nuw nsw i32 %10073, %10072" -> "  %10087 = lshr i32 %10074, 16"
"  %10075 = and i32 %10008, 65535"
"  %10075 = and i32 %10008, 65535" -> "  %10077 = add nuw nsw i32 %10076, %10075"
"  %10076 = and i32 %9931, 65535"
"  %10076 = and i32 %9931, 65535" -> "  %10077 = add nuw nsw i32 %10076, %10075"
"  %10077 = add nuw nsw i32 %10076, %10075"
"  %10077 = add nuw nsw i32 %10076, %10075" -> "  %10084 = and i32 %10077, 65535""  %10077 = add nuw nsw i32 %10076, %10075" -> "  %10081 = lshr i32 %10077, 16"
"  %10078 = and i32 %10016, 65535"
"  %10078 = and i32 %10016, 65535" -> "  %10080 = add nuw nsw i32 %10079, %10078"
"  %10079 = lshr i32 %9931, 16"
"  %10079 = lshr i32 %9931, 16" -> "  %10080 = add nuw nsw i32 %10079, %10078"
"  %10080 = add nuw nsw i32 %10079, %10078"
"  %10080 = add nuw nsw i32 %10079, %10078" -> "  %10093 = lshr i32 %10080, 16""  %10080 = add nuw nsw i32 %10079, %10078" -> "  %10082 = and i32 %10080, 65535"
"  %10081 = lshr i32 %10077, 16"
"  %10081 = lshr i32 %10077, 16" -> "  %10083 = add nuw nsw i32 %10082, %10081"
"  %10082 = and i32 %10080, 65535"
"  %10082 = and i32 %10080, 65535" -> "  %10083 = add nuw nsw i32 %10082, %10081"
"  %10083 = add nuw nsw i32 %10082, %10081"
"  %10083 = add nuw nsw i32 %10082, %10081" -> "  %10095 = lshr i32 %10083, 16""  %10083 = add nuw nsw i32 %10082, %10081" -> "  %10090 = and i32 %10083, 65535"
"  %10084 = and i32 %10077, 65535"
"  %10084 = and i32 %10077, 65535" -> "  %10086 = add nuw nsw i32 %10084, %10085"
"  %10085 = lshr i32 %10071, 16"
"  %10085 = lshr i32 %10071, 16" -> "  %10086 = add nuw nsw i32 %10084, %10085"
"  %10086 = add nuw nsw i32 %10084, %10085"
"  %10086 = add nuw nsw i32 %10084, %10085" -> "  %10088 = add nuw nsw i32 %10086, %10087"
"  %10087 = lshr i32 %10074, 16"
"  %10087 = lshr i32 %10074, 16" -> "  %10088 = add nuw nsw i32 %10086, %10087"
"  %10088 = add nuw nsw i32 %10086, %10087"
"  %10088 = add nuw nsw i32 %10086, %10087" -> "  %10240 = and i32 %10088, 65535""  %10088 = add nuw nsw i32 %10086, %10087" -> "  %10089 = lshr i32 %10088, 16"
"  %10089 = lshr i32 %10088, 16"
"  %10089 = lshr i32 %10088, 16" -> "  %10091 = add nuw nsw i32 %10089, %10090"
"  %10090 = and i32 %10083, 65535"
"  %10090 = and i32 %10083, 65535" -> "  %10091 = add nuw nsw i32 %10089, %10090"
"  %10091 = add nuw nsw i32 %10089, %10090"
"  %10091 = add nuw nsw i32 %10089, %10090" -> "  %10243 = and i32 %10091, 65535""  %10091 = add nuw nsw i32 %10089, %10090" -> "  %10097 = lshr i32 %10091, 16"
"  %10092 = and i32 %10052, 65535"
"  %10092 = and i32 %10052, 65535" -> "  %10094 = add nuw nsw i32 %10092, %10093"
"  %10093 = lshr i32 %10080, 16"
"  %10093 = lshr i32 %10080, 16" -> "  %10094 = add nuw nsw i32 %10092, %10093"
"  %10094 = add nuw nsw i32 %10092, %10093"
"  %10094 = add nuw nsw i32 %10092, %10093" -> "  %10096 = add nuw nsw i32 %10094, %10095"
"  %10095 = lshr i32 %10083, 16"
"  %10095 = lshr i32 %10083, 16" -> "  %10096 = add nuw nsw i32 %10094, %10095"
"  %10096 = add nuw nsw i32 %10094, %10095"
"  %10096 = add nuw nsw i32 %10094, %10095" -> "  %10098 = add nuw nsw i32 %10096, %10097"
"  %10097 = lshr i32 %10091, 16"
"  %10097 = lshr i32 %10091, 16" -> "  %10098 = add nuw nsw i32 %10096, %10097"
"  %10098 = add nuw nsw i32 %10096, %10097"
"  %10098 = add nuw nsw i32 %10096, %10097" -> "  %10391 = and i32 %10098, 65535""  %10098 = add nuw nsw i32 %10096, %10097" -> "  %10100 = lshr i32 %10098, 16"
"  %10099 = and i32 %10058, 65535"
"  %10099 = and i32 %10058, 65535" -> "  %10101 = add nuw nsw i32 %10100, %10099"
"  %10100 = lshr i32 %10098, 16"
"  %10100 = lshr i32 %10098, 16" -> "  %10101 = add nuw nsw i32 %10100, %10099"
"  %10101 = add nuw nsw i32 %10100, %10099"
"  %10101 = add nuw nsw i32 %10100, %10099" -> "  %10394 = and i32 %10101, 65535""  %10101 = add nuw nsw i32 %10100, %10099" -> "  %10102 = lshr i32 %10101, 16"
"  %10102 = lshr i32 %10101, 16"
"  %10102 = lshr i32 %10101, 16" -> "  %10103 = add nuw i32 %10065, %10102"
"  %10103 = add nuw i32 %10065, %10102"
"  %10103 = add nuw i32 %10065, %10102" -> "  %10400 = and i32 %10103, 65535""  %10103 = add nuw i32 %10065, %10102" -> "  %10403 = lshr i32 %10103, 16"
"  %10104 = mul nuw nsw i32 %9798, 17857"
"  %10104 = mul nuw nsw i32 %9798, 17857" -> "  %10228 = and i32 %10104, 65535""  %10104 = mul nuw nsw i32 %9798, 17857" -> "  %10105 = lshr i32 %10104, 16"
"  %10105 = lshr i32 %10104, 16"
"  %10105 = lshr i32 %10104, 16" -> "  %10108 = add nuw nsw i32 %10107, %10105"
"  %10106 = mul nuw nsw i32 %9799, 17857"
"  %10106 = mul nuw nsw i32 %9799, 17857" -> "  %10109 = and i32 %10106, 2147418112""  %10106 = mul nuw nsw i32 %9799, 17857" -> "  %10107 = and i32 %10106, 65535"
"  %10107 = and i32 %10106, 65535"
"  %10107 = and i32 %10106, 65535" -> "  %10108 = add nuw nsw i32 %10107, %10105"
"  %10108 = add nuw nsw i32 %10107, %10105"
"  %10108 = add nuw nsw i32 %10107, %10105" -> "  %10110 = add nuw nsw i32 %10108, %10109"
"  %10109 = and i32 %10106, 2147418112"
"  %10109 = and i32 %10106, 2147418112" -> "  %10110 = add nuw nsw i32 %10108, %10109"
"  %10110 = add nuw nsw i32 %10108, %10109"
"  %10110 = add nuw nsw i32 %10108, %10109" -> "  %10114 = lshr i32 %10110, 16""  %10110 = add nuw nsw i32 %10108, %10109" -> "  %10112 = and i32 %10110, 65535"
"  %10111 = mul nuw i32 %9798, 46547"
"  %10111 = mul nuw i32 %9798, 46547" -> "  %10113 = add nuw i32 %10112, %10111"
"  %10112 = and i32 %10110, 65535"
"  %10112 = and i32 %10110, 65535" -> "  %10113 = add nuw i32 %10112, %10111"
"  %10113 = add nuw i32 %10112, %10111"
"  %10113 = add nuw i32 %10112, %10111" -> "  %10231 = and i32 %10113, 65535""  %10113 = add nuw i32 %10112, %10111" -> "  %10117 = lshr i32 %10113, 16"
"  %10114 = lshr i32 %10110, 16"
"  %10114 = lshr i32 %10110, 16" -> "  %10116 = add nuw i32 %10114, %10115"
"  %10115 = mul nuw i32 %9799, 46547"
"  %10115 = mul nuw i32 %9799, 46547" -> "  %10116 = add nuw i32 %10114, %10115"
"  %10116 = add nuw i32 %10114, %10115"
"  %10116 = add nuw i32 %10114, %10115" -> "  %10120 = and i32 %10116, -65536""  %10116 = add nuw i32 %10114, %10115" -> "  %10118 = and i32 %10116, 65535"
"  %10117 = lshr i32 %10113, 16"
"  %10117 = lshr i32 %10113, 16" -> "  %10119 = add nuw nsw i32 %10118, %10117"
"  %10118 = and i32 %10116, 65535"
"  %10118 = and i32 %10116, 65535" -> "  %10119 = add nuw nsw i32 %10118, %10117"
"  %10119 = add nuw nsw i32 %10118, %10117"
"  %10119 = add nuw nsw i32 %10118, %10117" -> "  %10121 = add nuw i32 %10119, %10120"
"  %10120 = and i32 %10116, -65536"
"  %10120 = and i32 %10116, -65536" -> "  %10121 = add nuw i32 %10119, %10120"
"  %10121 = add nuw i32 %10119, %10120"
"  %10121 = add nuw i32 %10119, %10120" -> "  %10144 = lshr i32 %10121, 16""  %10121 = add nuw i32 %10119, %10120" -> "  %10140 = and i32 %10121, 65535"
"  %10122 = mul nuw nsw i32 %9819, 17857"
"  %10122 = mul nuw nsw i32 %9819, 17857" -> "  %10141 = and i32 %10122, 65535""  %10122 = mul nuw nsw i32 %9819, 17857" -> "  %10123 = lshr i32 %10122, 16"
"  %10123 = lshr i32 %10122, 16"
"  %10123 = lshr i32 %10122, 16" -> "  %10126 = add nuw nsw i32 %10125, %10123"
"  %10124 = mul nuw nsw i32 %9818, 17857"
"  %10124 = mul nuw nsw i32 %9818, 17857" -> "  %10127 = and i32 %10124, 2147418112""  %10124 = mul nuw nsw i32 %9818, 17857" -> "  %10125 = and i32 %10124, 65535"
"  %10125 = and i32 %10124, 65535"
"  %10125 = and i32 %10124, 65535" -> "  %10126 = add nuw nsw i32 %10125, %10123"
"  %10126 = add nuw nsw i32 %10125, %10123"
"  %10126 = add nuw nsw i32 %10125, %10123" -> "  %10128 = add nuw nsw i32 %10126, %10127"
"  %10127 = and i32 %10124, 2147418112"
"  %10127 = and i32 %10124, 2147418112" -> "  %10128 = add nuw nsw i32 %10126, %10127"
"  %10128 = add nuw nsw i32 %10126, %10127"
"  %10128 = add nuw nsw i32 %10126, %10127" -> "  %10132 = lshr i32 %10128, 16""  %10128 = add nuw nsw i32 %10126, %10127" -> "  %10130 = and i32 %10128, 65535"
"  %10129 = mul nuw i32 %9819, 46547"
"  %10129 = mul nuw i32 %9819, 46547" -> "  %10131 = add nuw i32 %10130, %10129"
"  %10130 = and i32 %10128, 65535"
"  %10130 = and i32 %10128, 65535" -> "  %10131 = add nuw i32 %10130, %10129"
"  %10131 = add nuw i32 %10130, %10129"
"  %10131 = add nuw i32 %10130, %10129" -> "  %10143 = and i32 %10131, 65535""  %10131 = add nuw i32 %10130, %10129" -> "  %10135 = lshr i32 %10131, 16"
"  %10132 = lshr i32 %10128, 16"
"  %10132 = lshr i32 %10128, 16" -> "  %10134 = add nuw i32 %10132, %10133"
"  %10133 = mul nuw i32 %9818, 46547"
"  %10133 = mul nuw i32 %9818, 46547" -> "  %10134 = add nuw i32 %10132, %10133"
"  %10134 = add nuw i32 %10132, %10133"
"  %10134 = add nuw i32 %10132, %10133" -> "  %10138 = and i32 %10134, -65536""  %10134 = add nuw i32 %10132, %10133" -> "  %10136 = and i32 %10134, 65535"
"  %10135 = lshr i32 %10131, 16"
"  %10135 = lshr i32 %10131, 16" -> "  %10137 = add nuw nsw i32 %10135, %10136"
"  %10136 = and i32 %10134, 65535"
"  %10136 = and i32 %10134, 65535" -> "  %10137 = add nuw nsw i32 %10135, %10136"
"  %10137 = add nuw nsw i32 %10135, %10136"
"  %10137 = add nuw nsw i32 %10135, %10136" -> "  %10139 = add nuw i32 %10137, %10138"
"  %10138 = and i32 %10134, -65536"
"  %10138 = and i32 %10134, -65536" -> "  %10139 = add nuw i32 %10137, %10138"
"  %10139 = add nuw i32 %10137, %10138"
"  %10139 = add nuw i32 %10137, %10138" -> "  %10147 = add nuw i32 %10139, %10146"
"  %10140 = and i32 %10121, 65535"
"  %10140 = and i32 %10121, 65535" -> "  %10142 = add nuw nsw i32 %10140, %10141"
"  %10141 = and i32 %10122, 65535"
"  %10141 = and i32 %10122, 65535" -> "  %10142 = add nuw nsw i32 %10140, %10141"
"  %10142 = add nuw nsw i32 %10140, %10141"
"  %10142 = add nuw nsw i32 %10140, %10141" -> "  %10168 = and i32 %10142, 65535""  %10142 = add nuw nsw i32 %10140, %10141" -> "  %10149 = lshr i32 %10142, 16"
"  %10143 = and i32 %10131, 65535"
"  %10143 = and i32 %10131, 65535" -> "  %10145 = add nuw nsw i32 %10143, %10144"
"  %10144 = lshr i32 %10121, 16"
"  %10144 = lshr i32 %10121, 16" -> "  %10145 = add nuw nsw i32 %10143, %10144"
"  %10145 = add nuw nsw i32 %10143, %10144"
"  %10145 = add nuw nsw i32 %10143, %10144" -> "  %10148 = and i32 %10145, 65535""  %10145 = add nuw nsw i32 %10143, %10144" -> "  %10146 = lshr i32 %10145, 16"
"  %10146 = lshr i32 %10145, 16"
"  %10146 = lshr i32 %10145, 16" -> "  %10147 = add nuw i32 %10139, %10146"
"  %10147 = add nuw i32 %10139, %10146"
"  %10147 = add nuw i32 %10139, %10146" -> "  %10152 = add nuw i32 %10147, %10151"
"  %10148 = and i32 %10145, 65535"
"  %10148 = and i32 %10145, 65535" -> "  %10150 = add nuw nsw i32 %10148, %10149"
"  %10149 = lshr i32 %10142, 16"
"  %10149 = lshr i32 %10142, 16" -> "  %10150 = add nuw nsw i32 %10148, %10149"
"  %10150 = add nuw nsw i32 %10148, %10149"
"  %10150 = add nuw nsw i32 %10148, %10149" -> "  %10171 = and i32 %10150, 65535""  %10150 = add nuw nsw i32 %10148, %10149" -> "  %10151 = lshr i32 %10150, 16"
"  %10151 = lshr i32 %10150, 16"
"  %10151 = lshr i32 %10150, 16" -> "  %10152 = add nuw i32 %10147, %10151"
"  %10152 = add nuw i32 %10147, %10151"
"  %10152 = add nuw i32 %10147, %10151" -> "  %10203 = lshr i32 %10152, 16""  %10152 = add nuw i32 %10147, %10151" -> "  %10199 = and i32 %10152, 65535"
"  %10153 = mul nuw nsw i32 %9798, 31112"
"  %10153 = mul nuw nsw i32 %9798, 31112" -> "  %10169 = and i32 %10153, 65528""  %10153 = mul nuw nsw i32 %9798, 31112" -> "  %10154 = lshr i32 %10153, 16"
"  %10154 = lshr i32 %10153, 16"
"  %10154 = lshr i32 %10153, 16" -> "  %10156 = add nuw nsw i32 %10155, %10154"
"  %10155 = mul nuw nsw i32 %9799, 31112"
"  %10155 = mul nuw nsw i32 %9799, 31112" -> "  %10156 = add nuw nsw i32 %10155, %10154"
"  %10156 = add nuw nsw i32 %10155, %10154"
"  %10156 = add nuw nsw i32 %10155, %10154" -> "  %10160 = lshr i32 %10156, 16""  %10156 = add nuw nsw i32 %10155, %10154" -> "  %10158 = and i32 %10156, 65535"
"  %10157 = mul nuw i32 %9798, 42170"
"  %10157 = mul nuw i32 %9798, 42170" -> "  %10159 = add nuw i32 %10158, %10157"
"  %10158 = and i32 %10156, 65535"
"  %10158 = and i32 %10156, 65535" -> "  %10159 = add nuw i32 %10158, %10157"
"  %10159 = add nuw i32 %10158, %10157"
"  %10159 = add nuw i32 %10158, %10157" -> "  %10172 = and i32 %10159, 65535""  %10159 = add nuw i32 %10158, %10157" -> "  %10163 = lshr i32 %10159, 16"
"  %10160 = lshr i32 %10156, 16"
"  %10160 = lshr i32 %10156, 16" -> "  %10162 = add nuw i32 %10160, %10161"
"  %10161 = mul nuw i32 %9799, 42170"
"  %10161 = mul nuw i32 %9799, 42170" -> "  %10162 = add nuw i32 %10160, %10161"
"  %10162 = add nuw i32 %10160, %10161"
"  %10162 = add nuw i32 %10160, %10161" -> "  %10166 = and i32 %10162, -65536""  %10162 = add nuw i32 %10160, %10161" -> "  %10164 = and i32 %10162, 65535"
"  %10163 = lshr i32 %10159, 16"
"  %10163 = lshr i32 %10159, 16" -> "  %10165 = add nuw nsw i32 %10163, %10164"
"  %10164 = and i32 %10162, 65535"
"  %10164 = and i32 %10162, 65535" -> "  %10165 = add nuw nsw i32 %10163, %10164"
"  %10165 = add nuw nsw i32 %10163, %10164"
"  %10165 = add nuw nsw i32 %10163, %10164" -> "  %10167 = add nuw i32 %10165, %10166"
"  %10166 = and i32 %10162, -65536"
"  %10166 = and i32 %10162, -65536" -> "  %10167 = add nuw i32 %10165, %10166"
"  %10167 = add nuw i32 %10165, %10166"
"  %10167 = add nuw i32 %10165, %10166" -> "  %10175 = add nuw i32 %10167, %10174"
"  %10168 = and i32 %10142, 65535"
"  %10168 = and i32 %10142, 65535" -> "  %10170 = add nuw nsw i32 %10168, %10169"
"  %10169 = and i32 %10153, 65528"
"  %10169 = and i32 %10153, 65528" -> "  %10170 = add nuw nsw i32 %10168, %10169"
"  %10170 = add nuw nsw i32 %10168, %10169"
"  %10170 = add nuw nsw i32 %10168, %10169" -> "  %10239 = and i32 %10170, 65535""  %10170 = add nuw nsw i32 %10168, %10169" -> "  %10177 = lshr i32 %10170, 16"
"  %10171 = and i32 %10150, 65535"
"  %10171 = and i32 %10150, 65535" -> "  %10173 = add nuw nsw i32 %10171, %10172"
"  %10172 = and i32 %10159, 65535"
"  %10172 = and i32 %10159, 65535" -> "  %10173 = add nuw nsw i32 %10171, %10172"
"  %10173 = add nuw nsw i32 %10171, %10172"
"  %10173 = add nuw nsw i32 %10171, %10172" -> "  %10176 = and i32 %10173, 65535""  %10173 = add nuw nsw i32 %10171, %10172" -> "  %10174 = lshr i32 %10173, 16"
"  %10174 = lshr i32 %10173, 16"
"  %10174 = lshr i32 %10173, 16" -> "  %10175 = add nuw i32 %10167, %10174"
"  %10175 = add nuw i32 %10167, %10174"
"  %10175 = add nuw i32 %10167, %10174" -> "  %10180 = add nuw i32 %10175, %10179"
"  %10176 = and i32 %10173, 65535"
"  %10176 = and i32 %10173, 65535" -> "  %10178 = add nuw nsw i32 %10176, %10177"
"  %10177 = lshr i32 %10170, 16"
"  %10177 = lshr i32 %10170, 16" -> "  %10178 = add nuw nsw i32 %10176, %10177"
"  %10178 = add nuw nsw i32 %10176, %10177"
"  %10178 = add nuw nsw i32 %10176, %10177" -> "  %10242 = and i32 %10178, 65535""  %10178 = add nuw nsw i32 %10176, %10177" -> "  %10179 = lshr i32 %10178, 16"
"  %10179 = lshr i32 %10178, 16"
"  %10179 = lshr i32 %10178, 16" -> "  %10180 = add nuw i32 %10175, %10179"
"  %10180 = add nuw i32 %10175, %10179"
"  %10180 = add nuw i32 %10175, %10179" -> "  %10216 = lshr i32 %10180, 16""  %10180 = add nuw i32 %10175, %10179" -> "  %10213 = and i32 %10180, 65535"
"  %10181 = mul nuw nsw i32 %9819, 31112"
"  %10181 = mul nuw nsw i32 %9819, 31112" -> "  %10200 = and i32 %10181, 65528""  %10181 = mul nuw nsw i32 %9819, 31112" -> "  %10182 = lshr i32 %10181, 16"
"  %10182 = lshr i32 %10181, 16"
"  %10182 = lshr i32 %10181, 16" -> "  %10185 = add nuw nsw i32 %10184, %10182"
"  %10183 = mul nuw nsw i32 %9818, 31112"
"  %10183 = mul nuw nsw i32 %9818, 31112" -> "  %10186 = and i32 %10183, 2147418112""  %10183 = mul nuw nsw i32 %9818, 31112" -> "  %10184 = and i32 %10183, 65528"
"  %10184 = and i32 %10183, 65528"
"  %10184 = and i32 %10183, 65528" -> "  %10185 = add nuw nsw i32 %10184, %10182"
"  %10185 = add nuw nsw i32 %10184, %10182"
"  %10185 = add nuw nsw i32 %10184, %10182" -> "  %10187 = add nuw nsw i32 %10185, %10186"
"  %10186 = and i32 %10183, 2147418112"
"  %10186 = and i32 %10183, 2147418112" -> "  %10187 = add nuw nsw i32 %10185, %10186"
"  %10187 = add nuw nsw i32 %10185, %10186"
"  %10187 = add nuw nsw i32 %10185, %10186" -> "  %10191 = lshr i32 %10187, 16""  %10187 = add nuw nsw i32 %10185, %10186" -> "  %10189 = and i32 %10187, 65535"
"  %10188 = mul nuw i32 %9819, 42170"
"  %10188 = mul nuw i32 %9819, 42170" -> "  %10190 = add nuw i32 %10189, %10188"
"  %10189 = and i32 %10187, 65535"
"  %10189 = and i32 %10187, 65535" -> "  %10190 = add nuw i32 %10189, %10188"
"  %10190 = add nuw i32 %10189, %10188"
"  %10190 = add nuw i32 %10189, %10188" -> "  %10202 = and i32 %10190, 65535""  %10190 = add nuw i32 %10189, %10188" -> "  %10194 = lshr i32 %10190, 16"
"  %10191 = lshr i32 %10187, 16"
"  %10191 = lshr i32 %10187, 16" -> "  %10193 = add nuw i32 %10191, %10192"
"  %10192 = mul nuw i32 %9818, 42170"
"  %10192 = mul nuw i32 %9818, 42170" -> "  %10193 = add nuw i32 %10191, %10192"
"  %10193 = add nuw i32 %10191, %10192"
"  %10193 = add nuw i32 %10191, %10192" -> "  %10197 = and i32 %10193, -65536""  %10193 = add nuw i32 %10191, %10192" -> "  %10195 = and i32 %10193, 65535"
"  %10194 = lshr i32 %10190, 16"
"  %10194 = lshr i32 %10190, 16" -> "  %10196 = add nuw nsw i32 %10194, %10195"
"  %10195 = and i32 %10193, 65535"
"  %10195 = and i32 %10193, 65535" -> "  %10196 = add nuw nsw i32 %10194, %10195"
"  %10196 = add nuw nsw i32 %10194, %10195"
"  %10196 = add nuw nsw i32 %10194, %10195" -> "  %10198 = add nuw i32 %10196, %10197"
"  %10197 = and i32 %10193, -65536"
"  %10197 = and i32 %10193, -65536" -> "  %10198 = add nuw i32 %10196, %10197"
"  %10198 = add nuw i32 %10196, %10197"
"  %10198 = add nuw i32 %10196, %10197" -> "  %10206 = add nuw i32 %10198, %10205"
"  %10199 = and i32 %10152, 65535"
"  %10199 = and i32 %10152, 65535" -> "  %10201 = add nuw nsw i32 %10199, %10200"
"  %10200 = and i32 %10181, 65528"
"  %10200 = and i32 %10181, 65528" -> "  %10201 = add nuw nsw i32 %10199, %10200"
"  %10201 = add nuw nsw i32 %10199, %10200"
"  %10201 = add nuw nsw i32 %10199, %10200" -> "  %10212 = and i32 %10201, 65535""  %10201 = add nuw nsw i32 %10199, %10200" -> "  %10208 = lshr i32 %10201, 16"
"  %10202 = and i32 %10190, 65535"
"  %10202 = and i32 %10190, 65535" -> "  %10204 = add nuw nsw i32 %10203, %10202"
"  %10203 = lshr i32 %10152, 16"
"  %10203 = lshr i32 %10152, 16" -> "  %10204 = add nuw nsw i32 %10203, %10202"
"  %10204 = add nuw nsw i32 %10203, %10202"
"  %10204 = add nuw nsw i32 %10203, %10202" -> "  %10207 = and i32 %10204, 65535""  %10204 = add nuw nsw i32 %10203, %10202" -> "  %10205 = lshr i32 %10204, 16"
"  %10205 = lshr i32 %10204, 16"
"  %10205 = lshr i32 %10204, 16" -> "  %10206 = add nuw i32 %10198, %10205"
"  %10206 = add nuw i32 %10198, %10205"
"  %10206 = add nuw i32 %10198, %10205" -> "  %10211 = add nuw i32 %10206, %10210"
"  %10207 = and i32 %10204, 65535"
"  %10207 = and i32 %10204, 65535" -> "  %10209 = add nuw nsw i32 %10208, %10207"
"  %10208 = lshr i32 %10201, 16"
"  %10208 = lshr i32 %10201, 16" -> "  %10209 = add nuw nsw i32 %10208, %10207"
"  %10209 = add nuw nsw i32 %10208, %10207"
"  %10209 = add nuw nsw i32 %10208, %10207" -> "  %10215 = and i32 %10209, 65535""  %10209 = add nuw nsw i32 %10208, %10207" -> "  %10210 = lshr i32 %10209, 16"
"  %10210 = lshr i32 %10209, 16"
"  %10210 = lshr i32 %10209, 16" -> "  %10211 = add nuw i32 %10206, %10210"
"  %10211 = add nuw i32 %10206, %10210"
"  %10211 = add nuw i32 %10206, %10210" -> "  %10224 = and i32 %10211, -65536""  %10211 = add nuw i32 %10206, %10210" -> "  %10222 = and i32 %10211, 65535"
"  %10212 = and i32 %10201, 65535"
"  %10212 = and i32 %10201, 65535" -> "  %10214 = add nuw nsw i32 %10213, %10212"
"  %10213 = and i32 %10180, 65535"
"  %10213 = and i32 %10180, 65535" -> "  %10214 = add nuw nsw i32 %10213, %10212"
"  %10214 = add nuw nsw i32 %10213, %10212"
"  %10214 = add nuw nsw i32 %10213, %10212" -> "  %10254 = and i32 %10214, 65535""  %10214 = add nuw nsw i32 %10213, %10212" -> "  %10218 = lshr i32 %10214, 16"
"  %10215 = and i32 %10209, 65535"
"  %10215 = and i32 %10209, 65535" -> "  %10217 = add nuw nsw i32 %10216, %10215"
"  %10216 = lshr i32 %10180, 16"
"  %10216 = lshr i32 %10180, 16" -> "  %10217 = add nuw nsw i32 %10216, %10215"
"  %10217 = add nuw nsw i32 %10216, %10215"
"  %10217 = add nuw nsw i32 %10216, %10215" -> "  %10221 = lshr i32 %10217, 16""  %10217 = add nuw nsw i32 %10216, %10215" -> "  %10219 = and i32 %10217, 65535"
"  %10218 = lshr i32 %10214, 16"
"  %10218 = lshr i32 %10214, 16" -> "  %10220 = add nuw nsw i32 %10218, %10219"
"  %10219 = and i32 %10217, 65535"
"  %10219 = and i32 %10217, 65535" -> "  %10220 = add nuw nsw i32 %10218, %10219"
"  %10220 = add nuw nsw i32 %10218, %10219"
"  %10220 = add nuw nsw i32 %10218, %10219" -> "  %10261 = and i32 %10220, 65535""  %10220 = add nuw nsw i32 %10218, %10219" -> "  %10226 = lshr i32 %10220, 16"
"  %10221 = lshr i32 %10217, 16"
"  %10221 = lshr i32 %10217, 16" -> "  %10223 = add nuw nsw i32 %10221, %10222"
"  %10222 = and i32 %10211, 65535"
"  %10222 = and i32 %10211, 65535" -> "  %10223 = add nuw nsw i32 %10221, %10222"
"  %10223 = add nuw nsw i32 %10221, %10222"
"  %10223 = add nuw nsw i32 %10221, %10222" -> "  %10225 = add nuw i32 %10223, %10224"
"  %10224 = and i32 %10211, -65536"
"  %10224 = and i32 %10211, -65536" -> "  %10225 = add nuw i32 %10223, %10224"
"  %10225 = add nuw i32 %10223, %10224"
"  %10225 = add nuw i32 %10223, %10224" -> "  %10227 = add nuw i32 %10225, %10226"
"  %10226 = lshr i32 %10220, 16"
"  %10226 = lshr i32 %10220, 16" -> "  %10227 = add nuw i32 %10225, %10226"
"  %10227 = add nuw i32 %10225, %10226"
"  %10227 = add nuw i32 %10225, %10226" -> "  %10265 = add nuw i32 %10227, %10264"
"  %10228 = and i32 %10104, 65535"
"  %10228 = and i32 %10104, 65535" -> "  %10230 = add nuw nsw i32 %10229, %10228"
"  %10229 = and i32 %10068, 65535"
"  %10229 = and i32 %10068, 65535" -> "  %10230 = add nuw nsw i32 %10229, %10228"
"  %10230 = add nuw nsw i32 %10229, %10228"
"  %10230 = add nuw nsw i32 %10229, %10228" -> "  %10493 = and i32 %10230, 65535""  %10230 = add nuw nsw i32 %10229, %10228" -> "  %10234 = lshr i32 %10230, 16"
"  %10231 = and i32 %10113, 65535"
"  %10231 = and i32 %10113, 65535" -> "  %10233 = add nuw nsw i32 %10232, %10231"
"  %10232 = and i32 %10074, 65535"
"  %10232 = and i32 %10074, 65535" -> "  %10233 = add nuw nsw i32 %10232, %10231"
"  %10233 = add nuw nsw i32 %10232, %10231"
"  %10233 = add nuw nsw i32 %10232, %10231" -> "  %10237 = lshr i32 %10233, 16""  %10233 = add nuw nsw i32 %10232, %10231" -> "  %10235 = and i32 %10233, 65535"
"  %10234 = lshr i32 %10230, 16"
"  %10234 = lshr i32 %10230, 16" -> "  %10236 = add nuw nsw i32 %10235, %10234"
"  %10235 = and i32 %10233, 65535"
"  %10235 = and i32 %10233, 65535" -> "  %10236 = add nuw nsw i32 %10235, %10234"
"  %10236 = add nuw nsw i32 %10235, %10234"
"  %10236 = add nuw nsw i32 %10235, %10234" -> "  %10496 = and i32 %10236, 65535""  %10236 = add nuw nsw i32 %10235, %10234" -> "  %10238 = lshr i32 %10236, 16"
"  %10237 = lshr i32 %10233, 16"
"  %10237 = lshr i32 %10233, 16" -> "  %10249 = add nuw nsw i32 %10238, %10237"
"  %10238 = lshr i32 %10236, 16"
"  %10238 = lshr i32 %10236, 16" -> "  %10249 = add nuw nsw i32 %10238, %10237"
"  %10239 = and i32 %10170, 65535"
"  %10239 = and i32 %10170, 65535" -> "  %10241 = add nuw nsw i32 %10240, %10239"
"  %10240 = and i32 %10088, 65535"
"  %10240 = and i32 %10088, 65535" -> "  %10241 = add nuw nsw i32 %10240, %10239"
"  %10241 = add nuw nsw i32 %10240, %10239"
"  %10241 = add nuw nsw i32 %10240, %10239" -> "  %10248 = and i32 %10241, 65535""  %10241 = add nuw nsw i32 %10240, %10239" -> "  %10245 = lshr i32 %10241, 16"
"  %10242 = and i32 %10178, 65535"
"  %10242 = and i32 %10178, 65535" -> "  %10244 = add nuw nsw i32 %10243, %10242"
"  %10243 = and i32 %10091, 65535"
"  %10243 = and i32 %10091, 65535" -> "  %10244 = add nuw nsw i32 %10243, %10242"
"  %10244 = add nuw nsw i32 %10243, %10242"
"  %10244 = add nuw nsw i32 %10243, %10242" -> "  %10255 = lshr i32 %10244, 16""  %10244 = add nuw nsw i32 %10243, %10242" -> "  %10246 = and i32 %10244, 65535"
"  %10245 = lshr i32 %10241, 16"
"  %10245 = lshr i32 %10241, 16" -> "  %10247 = add nuw nsw i32 %10246, %10245"
"  %10246 = and i32 %10244, 65535"
"  %10246 = and i32 %10244, 65535" -> "  %10247 = add nuw nsw i32 %10246, %10245"
"  %10247 = add nuw nsw i32 %10246, %10245"
"  %10247 = add nuw nsw i32 %10246, %10245" -> "  %10257 = lshr i32 %10247, 16""  %10247 = add nuw nsw i32 %10246, %10245" -> "  %10252 = and i32 %10247, 65535"
"  %10248 = and i32 %10241, 65535"
"  %10248 = and i32 %10241, 65535" -> "  %10250 = add nuw nsw i32 %10249, %10248"
"  %10249 = add nuw nsw i32 %10238, %10237"
"  %10249 = add nuw nsw i32 %10238, %10237" -> "  %10250 = add nuw nsw i32 %10249, %10248"
"  %10250 = add nuw nsw i32 %10249, %10248"
"  %10250 = add nuw nsw i32 %10249, %10248" -> "  %10502 = and i32 %10250, 65535""  %10250 = add nuw nsw i32 %10249, %10248" -> "  %10251 = lshr i32 %10250, 16"
"  %10251 = lshr i32 %10250, 16"
"  %10251 = lshr i32 %10250, 16" -> "  %10253 = add nuw nsw i32 %10252, %10251"
"  %10252 = and i32 %10247, 65535"
"  %10252 = and i32 %10247, 65535" -> "  %10253 = add nuw nsw i32 %10252, %10251"
"  %10253 = add nuw nsw i32 %10252, %10251"
"  %10253 = add nuw nsw i32 %10252, %10251" -> "  %10505 = and i32 %10253, 65535""  %10253 = add nuw nsw i32 %10252, %10251" -> "  %10259 = lshr i32 %10253, 16"
"  %10254 = and i32 %10214, 65535"
"  %10254 = and i32 %10214, 65535" -> "  %10256 = add nuw nsw i32 %10255, %10254"
"  %10255 = lshr i32 %10244, 16"
"  %10255 = lshr i32 %10244, 16" -> "  %10256 = add nuw nsw i32 %10255, %10254"
"  %10256 = add nuw nsw i32 %10255, %10254"
"  %10256 = add nuw nsw i32 %10255, %10254" -> "  %10258 = add nuw nsw i32 %10256, %10257"
"  %10257 = lshr i32 %10247, 16"
"  %10257 = lshr i32 %10247, 16" -> "  %10258 = add nuw nsw i32 %10256, %10257"
"  %10258 = add nuw nsw i32 %10256, %10257"
"  %10258 = add nuw nsw i32 %10256, %10257" -> "  %10260 = add nuw nsw i32 %10258, %10259"
"  %10259 = lshr i32 %10253, 16"
"  %10259 = lshr i32 %10253, 16" -> "  %10260 = add nuw nsw i32 %10258, %10259"
"  %10260 = add nuw nsw i32 %10258, %10259"
"  %10260 = add nuw nsw i32 %10258, %10259" -> "  %10429 = and i32 %10260, 65535""  %10260 = add nuw nsw i32 %10258, %10259" -> "  %10262 = lshr i32 %10260, 16"
"  %10261 = and i32 %10220, 65535"
"  %10261 = and i32 %10220, 65535" -> "  %10263 = add nuw nsw i32 %10262, %10261"
"  %10262 = lshr i32 %10260, 16"
"  %10262 = lshr i32 %10260, 16" -> "  %10263 = add nuw nsw i32 %10262, %10261"
"  %10263 = add nuw nsw i32 %10262, %10261"
"  %10263 = add nuw nsw i32 %10262, %10261" -> "  %10432 = and i32 %10263, 65535""  %10263 = add nuw nsw i32 %10262, %10261" -> "  %10264 = lshr i32 %10263, 16"
"  %10264 = lshr i32 %10263, 16"
"  %10264 = lshr i32 %10263, 16" -> "  %10265 = add nuw i32 %10227, %10264"
"  %10265 = add nuw i32 %10227, %10264"
"  %10265 = add nuw i32 %10227, %10264" -> "  %10437 = and i32 %10265, 65535""  %10265 = add nuw i32 %10227, %10264" -> "  %10440 = lshr i32 %10265, 16"
"  %10266 = mul nuw nsw i32 %9932, 17857"
"  %10266 = mul nuw nsw i32 %9932, 17857" -> "  %10390 = and i32 %10266, 65535""  %10266 = mul nuw nsw i32 %9932, 17857" -> "  %10267 = lshr i32 %10266, 16"
"  %10267 = lshr i32 %10266, 16"
"  %10267 = lshr i32 %10266, 16" -> "  %10270 = add nuw nsw i32 %10269, %10267"
"  %10268 = mul nuw nsw i32 %9935, 17857"
"  %10268 = mul nuw nsw i32 %9935, 17857" -> "  %10271 = and i32 %10268, 2147418112""  %10268 = mul nuw nsw i32 %9935, 17857" -> "  %10269 = and i32 %10268, 65535"
"  %10269 = and i32 %10268, 65535"
"  %10269 = and i32 %10268, 65535" -> "  %10270 = add nuw nsw i32 %10269, %10267"
"  %10270 = add nuw nsw i32 %10269, %10267"
"  %10270 = add nuw nsw i32 %10269, %10267" -> "  %10272 = add nuw nsw i32 %10270, %10271"
"  %10271 = and i32 %10268, 2147418112"
"  %10271 = and i32 %10268, 2147418112" -> "  %10272 = add nuw nsw i32 %10270, %10271"
"  %10272 = add nuw nsw i32 %10270, %10271"
"  %10272 = add nuw nsw i32 %10270, %10271" -> "  %10274 = and i32 %10272, 65535""  %10272 = add nuw nsw i32 %10270, %10271" -> "  %10276 = lshr i32 %10272, 16"
"  %10273 = mul nuw i32 %9932, 46547"
"  %10273 = mul nuw i32 %9932, 46547" -> "  %10275 = add nuw i32 %10274, %10273"
"  %10274 = and i32 %10272, 65535"
"  %10274 = and i32 %10272, 65535" -> "  %10275 = add nuw i32 %10274, %10273"
"  %10275 = add nuw i32 %10274, %10273"
"  %10275 = add nuw i32 %10274, %10273" -> "  %10393 = and i32 %10275, 65535""  %10275 = add nuw i32 %10274, %10273" -> "  %10279 = lshr i32 %10275, 16"
"  %10276 = lshr i32 %10272, 16"
"  %10276 = lshr i32 %10272, 16" -> "  %10278 = add nuw i32 %10276, %10277"
"  %10277 = mul nuw i32 %9935, 46547"
"  %10277 = mul nuw i32 %9935, 46547" -> "  %10278 = add nuw i32 %10276, %10277"
"  %10278 = add nuw i32 %10276, %10277"
"  %10278 = add nuw i32 %10276, %10277" -> "  %10282 = and i32 %10278, -65536""  %10278 = add nuw i32 %10276, %10277" -> "  %10280 = and i32 %10278, 65535"
"  %10279 = lshr i32 %10275, 16"
"  %10279 = lshr i32 %10275, 16" -> "  %10281 = add nuw nsw i32 %10280, %10279"
"  %10280 = and i32 %10278, 65535"
"  %10280 = and i32 %10278, 65535" -> "  %10281 = add nuw nsw i32 %10280, %10279"
"  %10281 = add nuw nsw i32 %10280, %10279"
"  %10281 = add nuw nsw i32 %10280, %10279" -> "  %10283 = add nuw i32 %10281, %10282"
"  %10282 = and i32 %10278, -65536"
"  %10282 = and i32 %10278, -65536" -> "  %10283 = add nuw i32 %10281, %10282"
"  %10283 = add nuw i32 %10281, %10282"
"  %10283 = add nuw i32 %10281, %10282" -> "  %10306 = lshr i32 %10283, 16""  %10283 = add nuw i32 %10281, %10282" -> "  %10302 = and i32 %10283, 65535"
"  %10284 = mul nuw nsw i32 %9952, 17857"
"  %10284 = mul nuw nsw i32 %9952, 17857" -> "  %10303 = and i32 %10284, 65535""  %10284 = mul nuw nsw i32 %9952, 17857" -> "  %10285 = lshr i32 %10284, 16"
"  %10285 = lshr i32 %10284, 16"
"  %10285 = lshr i32 %10284, 16" -> "  %10288 = add nuw nsw i32 %10287, %10285"
"  %10286 = mul nuw nsw i32 %9953, 17857"
"  %10286 = mul nuw nsw i32 %9953, 17857" -> "  %10289 = and i32 %10286, 2147418112""  %10286 = mul nuw nsw i32 %9953, 17857" -> "  %10287 = and i32 %10286, 65535"
"  %10287 = and i32 %10286, 65535"
"  %10287 = and i32 %10286, 65535" -> "  %10288 = add nuw nsw i32 %10287, %10285"
"  %10288 = add nuw nsw i32 %10287, %10285"
"  %10288 = add nuw nsw i32 %10287, %10285" -> "  %10290 = add nuw nsw i32 %10288, %10289"
"  %10289 = and i32 %10286, 2147418112"
"  %10289 = and i32 %10286, 2147418112" -> "  %10290 = add nuw nsw i32 %10288, %10289"
"  %10290 = add nuw nsw i32 %10288, %10289"
"  %10290 = add nuw nsw i32 %10288, %10289" -> "  %10294 = lshr i32 %10290, 16""  %10290 = add nuw nsw i32 %10288, %10289" -> "  %10292 = and i32 %10290, 65535"
"  %10291 = mul nuw i32 %9952, 46547"
"  %10291 = mul nuw i32 %9952, 46547" -> "  %10293 = add nuw i32 %10292, %10291"
"  %10292 = and i32 %10290, 65535"
"  %10292 = and i32 %10290, 65535" -> "  %10293 = add nuw i32 %10292, %10291"
"  %10293 = add nuw i32 %10292, %10291"
"  %10293 = add nuw i32 %10292, %10291" -> "  %10305 = and i32 %10293, 65535""  %10293 = add nuw i32 %10292, %10291" -> "  %10297 = lshr i32 %10293, 16"
"  %10294 = lshr i32 %10290, 16"
"  %10294 = lshr i32 %10290, 16" -> "  %10296 = add nuw i32 %10294, %10295"
"  %10295 = mul nuw i32 %9953, 46547"
"  %10295 = mul nuw i32 %9953, 46547" -> "  %10296 = add nuw i32 %10294, %10295"
"  %10296 = add nuw i32 %10294, %10295"
"  %10296 = add nuw i32 %10294, %10295" -> "  %10300 = and i32 %10296, -65536""  %10296 = add nuw i32 %10294, %10295" -> "  %10298 = and i32 %10296, 65535"
"  %10297 = lshr i32 %10293, 16"
"  %10297 = lshr i32 %10293, 16" -> "  %10299 = add nuw nsw i32 %10297, %10298"
"  %10298 = and i32 %10296, 65535"
"  %10298 = and i32 %10296, 65535" -> "  %10299 = add nuw nsw i32 %10297, %10298"
"  %10299 = add nuw nsw i32 %10297, %10298"
"  %10299 = add nuw nsw i32 %10297, %10298" -> "  %10301 = add nuw i32 %10299, %10300"
"  %10300 = and i32 %10296, -65536"
"  %10300 = and i32 %10296, -65536" -> "  %10301 = add nuw i32 %10299, %10300"
"  %10301 = add nuw i32 %10299, %10300"
"  %10301 = add nuw i32 %10299, %10300" -> "  %10309 = add nuw i32 %10301, %10308"
"  %10302 = and i32 %10283, 65535"
"  %10302 = and i32 %10283, 65535" -> "  %10304 = add nuw nsw i32 %10302, %10303"
"  %10303 = and i32 %10284, 65535"
"  %10303 = and i32 %10284, 65535" -> "  %10304 = add nuw nsw i32 %10302, %10303"
"  %10304 = add nuw nsw i32 %10302, %10303"
"  %10304 = add nuw nsw i32 %10302, %10303" -> "  %10330 = and i32 %10304, 65535""  %10304 = add nuw nsw i32 %10302, %10303" -> "  %10311 = lshr i32 %10304, 16"
"  %10305 = and i32 %10293, 65535"
"  %10305 = and i32 %10293, 65535" -> "  %10307 = add nuw nsw i32 %10306, %10305"
"  %10306 = lshr i32 %10283, 16"
"  %10306 = lshr i32 %10283, 16" -> "  %10307 = add nuw nsw i32 %10306, %10305"
"  %10307 = add nuw nsw i32 %10306, %10305"
"  %10307 = add nuw nsw i32 %10306, %10305" -> "  %10310 = and i32 %10307, 65535""  %10307 = add nuw nsw i32 %10306, %10305" -> "  %10308 = lshr i32 %10307, 16"
"  %10308 = lshr i32 %10307, 16"
"  %10308 = lshr i32 %10307, 16" -> "  %10309 = add nuw i32 %10301, %10308"
"  %10309 = add nuw i32 %10301, %10308"
"  %10309 = add nuw i32 %10301, %10308" -> "  %10314 = add nuw i32 %10309, %10313"
"  %10310 = and i32 %10307, 65535"
"  %10310 = and i32 %10307, 65535" -> "  %10312 = add nuw nsw i32 %10310, %10311"
"  %10311 = lshr i32 %10304, 16"
"  %10311 = lshr i32 %10304, 16" -> "  %10312 = add nuw nsw i32 %10310, %10311"
"  %10312 = add nuw nsw i32 %10310, %10311"
"  %10312 = add nuw nsw i32 %10310, %10311" -> "  %10333 = and i32 %10312, 65535""  %10312 = add nuw nsw i32 %10310, %10311" -> "  %10313 = lshr i32 %10312, 16"
"  %10313 = lshr i32 %10312, 16"
"  %10313 = lshr i32 %10312, 16" -> "  %10314 = add nuw i32 %10309, %10313"
"  %10314 = add nuw i32 %10309, %10313"
"  %10314 = add nuw i32 %10309, %10313" -> "  %10365 = lshr i32 %10314, 16""  %10314 = add nuw i32 %10309, %10313" -> "  %10361 = and i32 %10314, 65535"
"  %10315 = mul nuw nsw i32 %9932, 31112"
"  %10315 = mul nuw nsw i32 %9932, 31112" -> "  %10331 = and i32 %10315, 65528""  %10315 = mul nuw nsw i32 %9932, 31112" -> "  %10316 = lshr i32 %10315, 16"
"  %10316 = lshr i32 %10315, 16"
"  %10316 = lshr i32 %10315, 16" -> "  %10318 = add nuw nsw i32 %10317, %10316"
"  %10317 = mul nuw nsw i32 %9935, 31112"
"  %10317 = mul nuw nsw i32 %9935, 31112" -> "  %10318 = add nuw nsw i32 %10317, %10316"
"  %10318 = add nuw nsw i32 %10317, %10316"
"  %10318 = add nuw nsw i32 %10317, %10316" -> "  %10322 = lshr i32 %10318, 16""  %10318 = add nuw nsw i32 %10317, %10316" -> "  %10320 = and i32 %10318, 65535"
"  %10319 = mul nuw i32 %9932, 42170"
"  %10319 = mul nuw i32 %9932, 42170" -> "  %10321 = add nuw i32 %10320, %10319"
"  %10320 = and i32 %10318, 65535"
"  %10320 = and i32 %10318, 65535" -> "  %10321 = add nuw i32 %10320, %10319"
"  %10321 = add nuw i32 %10320, %10319"
"  %10321 = add nuw i32 %10320, %10319" -> "  %10334 = and i32 %10321, 65535""  %10321 = add nuw i32 %10320, %10319" -> "  %10325 = lshr i32 %10321, 16"
"  %10322 = lshr i32 %10318, 16"
"  %10322 = lshr i32 %10318, 16" -> "  %10324 = add nuw i32 %10322, %10323"
"  %10323 = mul nuw i32 %9935, 42170"
"  %10323 = mul nuw i32 %9935, 42170" -> "  %10324 = add nuw i32 %10322, %10323"
"  %10324 = add nuw i32 %10322, %10323"
"  %10324 = add nuw i32 %10322, %10323" -> "  %10328 = and i32 %10324, -65536""  %10324 = add nuw i32 %10322, %10323" -> "  %10326 = and i32 %10324, 65535"
"  %10325 = lshr i32 %10321, 16"
"  %10325 = lshr i32 %10321, 16" -> "  %10327 = add nuw nsw i32 %10325, %10326"
"  %10326 = and i32 %10324, 65535"
"  %10326 = and i32 %10324, 65535" -> "  %10327 = add nuw nsw i32 %10325, %10326"
"  %10327 = add nuw nsw i32 %10325, %10326"
"  %10327 = add nuw nsw i32 %10325, %10326" -> "  %10329 = add nuw i32 %10327, %10328"
"  %10328 = and i32 %10324, -65536"
"  %10328 = and i32 %10324, -65536" -> "  %10329 = add nuw i32 %10327, %10328"
"  %10329 = add nuw i32 %10327, %10328"
"  %10329 = add nuw i32 %10327, %10328" -> "  %10337 = add nuw i32 %10329, %10336"
"  %10330 = and i32 %10304, 65535"
"  %10330 = and i32 %10304, 65535" -> "  %10332 = add nuw nsw i32 %10330, %10331"
"  %10331 = and i32 %10315, 65528"
"  %10331 = and i32 %10315, 65528" -> "  %10332 = add nuw nsw i32 %10330, %10331"
"  %10332 = add nuw nsw i32 %10330, %10331"
"  %10332 = add nuw nsw i32 %10330, %10331" -> "  %10399 = and i32 %10332, 65535""  %10332 = add nuw nsw i32 %10330, %10331" -> "  %10339 = lshr i32 %10332, 16"
"  %10333 = and i32 %10312, 65535"
"  %10333 = and i32 %10312, 65535" -> "  %10335 = add nuw nsw i32 %10333, %10334"
"  %10334 = and i32 %10321, 65535"
"  %10334 = and i32 %10321, 65535" -> "  %10335 = add nuw nsw i32 %10333, %10334"
"  %10335 = add nuw nsw i32 %10333, %10334"
"  %10335 = add nuw nsw i32 %10333, %10334" -> "  %10338 = and i32 %10335, 65535""  %10335 = add nuw nsw i32 %10333, %10334" -> "  %10336 = lshr i32 %10335, 16"
"  %10336 = lshr i32 %10335, 16"
"  %10336 = lshr i32 %10335, 16" -> "  %10337 = add nuw i32 %10329, %10336"
"  %10337 = add nuw i32 %10329, %10336"
"  %10337 = add nuw i32 %10329, %10336" -> "  %10342 = add nuw i32 %10337, %10341"
"  %10338 = and i32 %10335, 65535"
"  %10338 = and i32 %10335, 65535" -> "  %10340 = add nuw nsw i32 %10338, %10339"
"  %10339 = lshr i32 %10332, 16"
"  %10339 = lshr i32 %10332, 16" -> "  %10340 = add nuw nsw i32 %10338, %10339"
"  %10340 = add nuw nsw i32 %10338, %10339"
"  %10340 = add nuw nsw i32 %10338, %10339" -> "  %10402 = and i32 %10340, 65535""  %10340 = add nuw nsw i32 %10338, %10339" -> "  %10341 = lshr i32 %10340, 16"
"  %10341 = lshr i32 %10340, 16"
"  %10341 = lshr i32 %10340, 16" -> "  %10342 = add nuw i32 %10337, %10341"
"  %10342 = add nuw i32 %10337, %10341"
"  %10342 = add nuw i32 %10337, %10341" -> "  %10378 = lshr i32 %10342, 16""  %10342 = add nuw i32 %10337, %10341" -> "  %10375 = and i32 %10342, 65535"
"  %10343 = mul nuw nsw i32 %9952, 31112"
"  %10343 = mul nuw nsw i32 %9952, 31112" -> "  %10362 = and i32 %10343, 65528""  %10343 = mul nuw nsw i32 %9952, 31112" -> "  %10344 = lshr i32 %10343, 16"
"  %10344 = lshr i32 %10343, 16"
"  %10344 = lshr i32 %10343, 16" -> "  %10347 = add nuw nsw i32 %10346, %10344"
"  %10345 = mul nuw nsw i32 %9953, 31112"
"  %10345 = mul nuw nsw i32 %9953, 31112" -> "  %10348 = and i32 %10345, 2147418112""  %10345 = mul nuw nsw i32 %9953, 31112" -> "  %10346 = and i32 %10345, 65528"
"  %10346 = and i32 %10345, 65528"
"  %10346 = and i32 %10345, 65528" -> "  %10347 = add nuw nsw i32 %10346, %10344"
"  %10347 = add nuw nsw i32 %10346, %10344"
"  %10347 = add nuw nsw i32 %10346, %10344" -> "  %10349 = add nuw nsw i32 %10347, %10348"
"  %10348 = and i32 %10345, 2147418112"
"  %10348 = and i32 %10345, 2147418112" -> "  %10349 = add nuw nsw i32 %10347, %10348"
"  %10349 = add nuw nsw i32 %10347, %10348"
"  %10349 = add nuw nsw i32 %10347, %10348" -> "  %10353 = lshr i32 %10349, 16""  %10349 = add nuw nsw i32 %10347, %10348" -> "  %10351 = and i32 %10349, 65535"
"  %10350 = mul nuw i32 %9952, 42170"
"  %10350 = mul nuw i32 %9952, 42170" -> "  %10352 = add nuw i32 %10351, %10350"
"  %10351 = and i32 %10349, 65535"
"  %10351 = and i32 %10349, 65535" -> "  %10352 = add nuw i32 %10351, %10350"
"  %10352 = add nuw i32 %10351, %10350"
"  %10352 = add nuw i32 %10351, %10350" -> "  %10364 = and i32 %10352, 65535""  %10352 = add nuw i32 %10351, %10350" -> "  %10356 = lshr i32 %10352, 16"
"  %10353 = lshr i32 %10349, 16"
"  %10353 = lshr i32 %10349, 16" -> "  %10355 = add nuw i32 %10353, %10354"
"  %10354 = mul nuw i32 %9953, 42170"
"  %10354 = mul nuw i32 %9953, 42170" -> "  %10355 = add nuw i32 %10353, %10354"
"  %10355 = add nuw i32 %10353, %10354"
"  %10355 = add nuw i32 %10353, %10354" -> "  %10359 = and i32 %10355, -65536""  %10355 = add nuw i32 %10353, %10354" -> "  %10357 = and i32 %10355, 65535"
"  %10356 = lshr i32 %10352, 16"
"  %10356 = lshr i32 %10352, 16" -> "  %10358 = add nuw nsw i32 %10356, %10357"
"  %10357 = and i32 %10355, 65535"
"  %10357 = and i32 %10355, 65535" -> "  %10358 = add nuw nsw i32 %10356, %10357"
"  %10358 = add nuw nsw i32 %10356, %10357"
"  %10358 = add nuw nsw i32 %10356, %10357" -> "  %10360 = add nuw i32 %10358, %10359"
"  %10359 = and i32 %10355, -65536"
"  %10359 = and i32 %10355, -65536" -> "  %10360 = add nuw i32 %10358, %10359"
"  %10360 = add nuw i32 %10358, %10359"
"  %10360 = add nuw i32 %10358, %10359" -> "  %10368 = add nuw i32 %10360, %10367"
"  %10361 = and i32 %10314, 65535"
"  %10361 = and i32 %10314, 65535" -> "  %10363 = add nuw nsw i32 %10361, %10362"
"  %10362 = and i32 %10343, 65528"
"  %10362 = and i32 %10343, 65528" -> "  %10363 = add nuw nsw i32 %10361, %10362"
"  %10363 = add nuw nsw i32 %10361, %10362"
"  %10363 = add nuw nsw i32 %10361, %10362" -> "  %10374 = and i32 %10363, 65535""  %10363 = add nuw nsw i32 %10361, %10362" -> "  %10370 = lshr i32 %10363, 16"
"  %10364 = and i32 %10352, 65535"
"  %10364 = and i32 %10352, 65535" -> "  %10366 = add nuw nsw i32 %10365, %10364"
"  %10365 = lshr i32 %10314, 16"
"  %10365 = lshr i32 %10314, 16" -> "  %10366 = add nuw nsw i32 %10365, %10364"
"  %10366 = add nuw nsw i32 %10365, %10364"
"  %10366 = add nuw nsw i32 %10365, %10364" -> "  %10369 = and i32 %10366, 65535""  %10366 = add nuw nsw i32 %10365, %10364" -> "  %10367 = lshr i32 %10366, 16"
"  %10367 = lshr i32 %10366, 16"
"  %10367 = lshr i32 %10366, 16" -> "  %10368 = add nuw i32 %10360, %10367"
"  %10368 = add nuw i32 %10360, %10367"
"  %10368 = add nuw i32 %10360, %10367" -> "  %10373 = add nuw i32 %10368, %10372"
"  %10369 = and i32 %10366, 65535"
"  %10369 = and i32 %10366, 65535" -> "  %10371 = add nuw nsw i32 %10369, %10370"
"  %10370 = lshr i32 %10363, 16"
"  %10370 = lshr i32 %10363, 16" -> "  %10371 = add nuw nsw i32 %10369, %10370"
"  %10371 = add nuw nsw i32 %10369, %10370"
"  %10371 = add nuw nsw i32 %10369, %10370" -> "  %10377 = and i32 %10371, 65535""  %10371 = add nuw nsw i32 %10369, %10370" -> "  %10372 = lshr i32 %10371, 16"
"  %10372 = lshr i32 %10371, 16"
"  %10372 = lshr i32 %10371, 16" -> "  %10373 = add nuw i32 %10368, %10372"
"  %10373 = add nuw i32 %10368, %10372"
"  %10373 = add nuw i32 %10368, %10372" -> "  %10386 = and i32 %10373, -65536""  %10373 = add nuw i32 %10368, %10372" -> "  %10384 = and i32 %10373, 65535"
"  %10374 = and i32 %10363, 65535"
"  %10374 = and i32 %10363, 65535" -> "  %10376 = add nuw nsw i32 %10375, %10374"
"  %10375 = and i32 %10342, 65535"
"  %10375 = and i32 %10342, 65535" -> "  %10376 = add nuw nsw i32 %10375, %10374"
"  %10376 = add nuw nsw i32 %10375, %10374"
"  %10376 = add nuw nsw i32 %10375, %10374" -> "  %10416 = and i32 %10376, 65535""  %10376 = add nuw nsw i32 %10375, %10374" -> "  %10380 = lshr i32 %10376, 16"
"  %10377 = and i32 %10371, 65535"
"  %10377 = and i32 %10371, 65535" -> "  %10379 = add nuw nsw i32 %10377, %10378"
"  %10378 = lshr i32 %10342, 16"
"  %10378 = lshr i32 %10342, 16" -> "  %10379 = add nuw nsw i32 %10377, %10378"
"  %10379 = add nuw nsw i32 %10377, %10378"
"  %10379 = add nuw nsw i32 %10377, %10378" -> "  %10383 = lshr i32 %10379, 16""  %10379 = add nuw nsw i32 %10377, %10378" -> "  %10381 = and i32 %10379, 65535"
"  %10380 = lshr i32 %10376, 16"
"  %10380 = lshr i32 %10376, 16" -> "  %10382 = add nuw nsw i32 %10381, %10380"
"  %10381 = and i32 %10379, 65535"
"  %10381 = and i32 %10379, 65535" -> "  %10382 = add nuw nsw i32 %10381, %10380"
"  %10382 = add nuw nsw i32 %10381, %10380"
"  %10382 = add nuw nsw i32 %10381, %10380" -> "  %10423 = and i32 %10382, 65535""  %10382 = add nuw nsw i32 %10381, %10380" -> "  %10388 = lshr i32 %10382, 16"
"  %10383 = lshr i32 %10379, 16"
"  %10383 = lshr i32 %10379, 16" -> "  %10385 = add nuw nsw i32 %10383, %10384"
"  %10384 = and i32 %10373, 65535"
"  %10384 = and i32 %10373, 65535" -> "  %10385 = add nuw nsw i32 %10383, %10384"
"  %10385 = add nuw nsw i32 %10383, %10384"
"  %10385 = add nuw nsw i32 %10383, %10384" -> "  %10387 = add nuw i32 %10385, %10386"
"  %10386 = and i32 %10373, -65536"
"  %10386 = and i32 %10373, -65536" -> "  %10387 = add nuw i32 %10385, %10386"
"  %10387 = add nuw i32 %10385, %10386"
"  %10387 = add nuw i32 %10385, %10386" -> "  %10389 = add nuw i32 %10387, %10388"
"  %10388 = lshr i32 %10382, 16"
"  %10388 = lshr i32 %10382, 16" -> "  %10389 = add nuw i32 %10387, %10388"
"  %10389 = add nuw i32 %10387, %10388"
"  %10389 = add nuw i32 %10387, %10388" -> "  %10427 = add nuw i32 %10389, %10426"
"  %10390 = and i32 %10266, 65535"
"  %10390 = and i32 %10266, 65535" -> "  %10392 = add nuw nsw i32 %10391, %10390"
"  %10391 = and i32 %10098, 65535"
"  %10391 = and i32 %10098, 65535" -> "  %10392 = add nuw nsw i32 %10391, %10390"
"  %10392 = add nuw nsw i32 %10391, %10390"
"  %10392 = add nuw nsw i32 %10391, %10390" -> "  %10428 = and i32 %10392, 65535""  %10392 = add nuw nsw i32 %10391, %10390" -> "  %10396 = lshr i32 %10392, 16"
"  %10393 = and i32 %10275, 65535"
"  %10393 = and i32 %10275, 65535" -> "  %10395 = add nuw nsw i32 %10394, %10393"
"  %10394 = and i32 %10101, 65535"
"  %10394 = and i32 %10101, 65535" -> "  %10395 = add nuw nsw i32 %10394, %10393"
"  %10395 = add nuw nsw i32 %10394, %10393"
"  %10395 = add nuw nsw i32 %10394, %10393" -> "  %10409 = lshr i32 %10395, 16""  %10395 = add nuw nsw i32 %10394, %10393" -> "  %10397 = and i32 %10395, 65535"
"  %10396 = lshr i32 %10392, 16"
"  %10396 = lshr i32 %10392, 16" -> "  %10398 = add nuw nsw i32 %10397, %10396"
"  %10397 = and i32 %10395, 65535"
"  %10397 = and i32 %10395, 65535" -> "  %10398 = add nuw nsw i32 %10397, %10396"
"  %10398 = add nuw nsw i32 %10397, %10396"
"  %10398 = add nuw nsw i32 %10397, %10396" -> "  %10431 = and i32 %10398, 65535""  %10398 = add nuw nsw i32 %10397, %10396" -> "  %10411 = lshr i32 %10398, 16"
"  %10399 = and i32 %10332, 65535"
"  %10399 = and i32 %10332, 65535" -> "  %10401 = add nuw nsw i32 %10400, %10399"
"  %10400 = and i32 %10103, 65535"
"  %10400 = and i32 %10103, 65535" -> "  %10401 = add nuw nsw i32 %10400, %10399"
"  %10401 = add nuw nsw i32 %10400, %10399"
"  %10401 = add nuw nsw i32 %10400, %10399" -> "  %10408 = and i32 %10401, 65535""  %10401 = add nuw nsw i32 %10400, %10399" -> "  %10405 = lshr i32 %10401, 16"
"  %10402 = and i32 %10340, 65535"
"  %10402 = and i32 %10340, 65535" -> "  %10404 = add nuw nsw i32 %10403, %10402"
"  %10403 = lshr i32 %10103, 16"
"  %10403 = lshr i32 %10103, 16" -> "  %10404 = add nuw nsw i32 %10403, %10402"
"  %10404 = add nuw nsw i32 %10403, %10402"
"  %10404 = add nuw nsw i32 %10403, %10402" -> "  %10417 = lshr i32 %10404, 16""  %10404 = add nuw nsw i32 %10403, %10402" -> "  %10406 = and i32 %10404, 65535"
"  %10405 = lshr i32 %10401, 16"
"  %10405 = lshr i32 %10401, 16" -> "  %10407 = add nuw nsw i32 %10406, %10405"
"  %10406 = and i32 %10404, 65535"
"  %10406 = and i32 %10404, 65535" -> "  %10407 = add nuw nsw i32 %10406, %10405"
"  %10407 = add nuw nsw i32 %10406, %10405"
"  %10407 = add nuw nsw i32 %10406, %10405" -> "  %10419 = lshr i32 %10407, 16""  %10407 = add nuw nsw i32 %10406, %10405" -> "  %10414 = and i32 %10407, 65535"
"  %10408 = and i32 %10401, 65535"
"  %10408 = and i32 %10401, 65535" -> "  %10410 = add nuw nsw i32 %10408, %10409"
"  %10409 = lshr i32 %10395, 16"
"  %10409 = lshr i32 %10395, 16" -> "  %10410 = add nuw nsw i32 %10408, %10409"
"  %10410 = add nuw nsw i32 %10408, %10409"
"  %10410 = add nuw nsw i32 %10408, %10409" -> "  %10412 = add nuw nsw i32 %10410, %10411"
"  %10411 = lshr i32 %10398, 16"
"  %10411 = lshr i32 %10398, 16" -> "  %10412 = add nuw nsw i32 %10410, %10411"
"  %10412 = add nuw nsw i32 %10410, %10411"
"  %10412 = add nuw nsw i32 %10410, %10411" -> "  %10438 = and i32 %10412, 65535""  %10412 = add nuw nsw i32 %10410, %10411" -> "  %10413 = lshr i32 %10412, 16"
"  %10413 = lshr i32 %10412, 16"
"  %10413 = lshr i32 %10412, 16" -> "  %10415 = add nuw nsw i32 %10413, %10414"
"  %10414 = and i32 %10407, 65535"
"  %10414 = and i32 %10407, 65535" -> "  %10415 = add nuw nsw i32 %10413, %10414"
"  %10415 = add nuw nsw i32 %10413, %10414"
"  %10415 = add nuw nsw i32 %10413, %10414" -> "  %10441 = and i32 %10415, 65535""  %10415 = add nuw nsw i32 %10413, %10414" -> "  %10421 = lshr i32 %10415, 16"
"  %10416 = and i32 %10376, 65535"
"  %10416 = and i32 %10376, 65535" -> "  %10418 = add nuw nsw i32 %10417, %10416"
"  %10417 = lshr i32 %10404, 16"
"  %10417 = lshr i32 %10404, 16" -> "  %10418 = add nuw nsw i32 %10417, %10416"
"  %10418 = add nuw nsw i32 %10417, %10416"
"  %10418 = add nuw nsw i32 %10417, %10416" -> "  %10420 = add nuw nsw i32 %10418, %10419"
"  %10419 = lshr i32 %10407, 16"
"  %10419 = lshr i32 %10407, 16" -> "  %10420 = add nuw nsw i32 %10418, %10419"
"  %10420 = add nuw nsw i32 %10418, %10419"
"  %10420 = add nuw nsw i32 %10418, %10419" -> "  %10422 = add nuw nsw i32 %10420, %10421"
"  %10421 = lshr i32 %10415, 16"
"  %10421 = lshr i32 %10415, 16" -> "  %10422 = add nuw nsw i32 %10420, %10421"
"  %10422 = add nuw nsw i32 %10420, %10421"
"  %10422 = add nuw nsw i32 %10420, %10421" -> "  %10455 = and i32 %10422, 65535""  %10422 = add nuw nsw i32 %10420, %10421" -> "  %10424 = lshr i32 %10422, 16"
"  %10423 = and i32 %10382, 65535"
"  %10423 = and i32 %10382, 65535" -> "  %10425 = add nuw nsw i32 %10424, %10423"
"  %10424 = lshr i32 %10422, 16"
"  %10424 = lshr i32 %10422, 16" -> "  %10425 = add nuw nsw i32 %10424, %10423"
"  %10425 = add nuw nsw i32 %10424, %10423"
"  %10425 = add nuw nsw i32 %10424, %10423" -> "  %10462 = and i32 %10425, 65535""  %10425 = add nuw nsw i32 %10424, %10423" -> "  %10426 = lshr i32 %10425, 16"
"  %10426 = lshr i32 %10425, 16"
"  %10426 = lshr i32 %10425, 16" -> "  %10427 = add nuw i32 %10389, %10426"
"  %10427 = add nuw i32 %10389, %10426"
"  %10427 = add nuw i32 %10389, %10426" -> "  %10465 = add nuw i32 %10427, %10464"
"  %10428 = and i32 %10392, 65535"
"  %10428 = and i32 %10392, 65535" -> "  %10430 = add nuw nsw i32 %10429, %10428"
"  %10429 = and i32 %10260, 65535"
"  %10429 = and i32 %10260, 65535" -> "  %10430 = add nuw nsw i32 %10429, %10428"
"  %10430 = add nuw nsw i32 %10429, %10428"
"  %10430 = add nuw nsw i32 %10429, %10428" -> "  %10539 = and i32 %10430, 65535""  %10430 = add nuw nsw i32 %10429, %10428" -> "  %10434 = lshr i32 %10430, 16"
"  %10431 = and i32 %10398, 65535"
"  %10431 = and i32 %10398, 65535" -> "  %10433 = add nuw nsw i32 %10432, %10431"
"  %10432 = and i32 %10263, 65535"
"  %10432 = and i32 %10263, 65535" -> "  %10433 = add nuw nsw i32 %10432, %10431"
"  %10433 = add nuw nsw i32 %10432, %10431"
"  %10433 = add nuw nsw i32 %10432, %10431" -> "  %10447 = lshr i32 %10433, 16""  %10433 = add nuw nsw i32 %10432, %10431" -> "  %10435 = and i32 %10433, 65535"
"  %10434 = lshr i32 %10430, 16"
"  %10434 = lshr i32 %10430, 16" -> "  %10436 = add nuw nsw i32 %10435, %10434"
"  %10435 = and i32 %10433, 65535"
"  %10435 = and i32 %10433, 65535" -> "  %10436 = add nuw nsw i32 %10435, %10434"
"  %10436 = add nuw nsw i32 %10435, %10434"
"  %10436 = add nuw nsw i32 %10435, %10434" -> "  %10543 = and i32 %10436, 65535""  %10436 = add nuw nsw i32 %10435, %10434" -> "  %10448 = lshr i32 %10436, 16"
"  %10437 = and i32 %10265, 65535"
"  %10437 = and i32 %10265, 65535" -> "  %10439 = add nuw nsw i32 %10437, %10438"
"  %10438 = and i32 %10412, 65535"
"  %10438 = and i32 %10412, 65535" -> "  %10439 = add nuw nsw i32 %10437, %10438"
"  %10439 = add nuw nsw i32 %10437, %10438"
"  %10439 = add nuw nsw i32 %10437, %10438" -> "  %10446 = and i32 %10439, 65535""  %10439 = add nuw nsw i32 %10437, %10438" -> "  %10443 = lshr i32 %10439, 16"
"  %10440 = lshr i32 %10265, 16"
"  %10440 = lshr i32 %10265, 16" -> "  %10442 = add nuw nsw i32 %10441, %10440"
"  %10441 = and i32 %10415, 65535"
"  %10441 = and i32 %10415, 65535" -> "  %10442 = add nuw nsw i32 %10441, %10440"
"  %10442 = add nuw nsw i32 %10441, %10440"
"  %10442 = add nuw nsw i32 %10441, %10440" -> "  %10454 = lshr i32 %10442, 16""  %10442 = add nuw nsw i32 %10441, %10440" -> "  %10444 = and i32 %10442, 65535"
"  %10443 = lshr i32 %10439, 16"
"  %10443 = lshr i32 %10439, 16" -> "  %10445 = add nuw nsw i32 %10444, %10443"
"  %10444 = and i32 %10442, 65535"
"  %10444 = and i32 %10442, 65535" -> "  %10445 = add nuw nsw i32 %10444, %10443"
"  %10445 = add nuw nsw i32 %10444, %10443"
"  %10445 = add nuw nsw i32 %10444, %10443" -> "  %10457 = lshr i32 %10445, 16""  %10445 = add nuw nsw i32 %10444, %10443" -> "  %10452 = and i32 %10445, 65535"
"  %10446 = and i32 %10439, 65535"
"  %10446 = and i32 %10439, 65535" -> "  %10450 = add nuw nsw i32 %10449, %10446"
"  %10447 = lshr i32 %10433, 16"
"  %10447 = lshr i32 %10433, 16" -> "  %10449 = add nuw nsw i32 %10448, %10447"
"  %10448 = lshr i32 %10436, 16"
"  %10448 = lshr i32 %10436, 16" -> "  %10449 = add nuw nsw i32 %10448, %10447"
"  %10449 = add nuw nsw i32 %10448, %10447"
"  %10449 = add nuw nsw i32 %10448, %10447" -> "  %10450 = add nuw nsw i32 %10449, %10446"
"  %10450 = add nuw nsw i32 %10449, %10446"
"  %10450 = add nuw nsw i32 %10449, %10446" -> "  %10544 = and i32 %10450, 65535""  %10450 = add nuw nsw i32 %10449, %10446" -> "  %10451 = lshr i32 %10450, 16"
"  %10451 = lshr i32 %10450, 16"
"  %10451 = lshr i32 %10450, 16" -> "  %10453 = add nuw nsw i32 %10452, %10451"
"  %10452 = and i32 %10445, 65535"
"  %10452 = and i32 %10445, 65535" -> "  %10453 = add nuw nsw i32 %10452, %10451"
"  %10453 = add nuw nsw i32 %10452, %10451"
"  %10453 = add nuw nsw i32 %10452, %10451" -> "  %10549 = and i32 %10453, 65535""  %10453 = add nuw nsw i32 %10452, %10451" -> "  %10459 = lshr i32 %10453, 16"
"  %10454 = lshr i32 %10442, 16"
"  %10454 = lshr i32 %10442, 16" -> "  %10456 = add nuw nsw i32 %10454, %10455"
"  %10455 = and i32 %10422, 65535"
"  %10455 = and i32 %10422, 65535" -> "  %10456 = add nuw nsw i32 %10454, %10455"
"  %10456 = add nuw nsw i32 %10454, %10455"
"  %10456 = add nuw nsw i32 %10454, %10455" -> "  %10458 = add nuw nsw i32 %10456, %10457"
"  %10457 = lshr i32 %10445, 16"
"  %10457 = lshr i32 %10445, 16" -> "  %10458 = add nuw nsw i32 %10456, %10457"
"  %10458 = add nuw nsw i32 %10456, %10457"
"  %10458 = add nuw nsw i32 %10456, %10457" -> "  %10460 = add nuw nsw i32 %10458, %10459"
"  %10459 = lshr i32 %10453, 16"
"  %10459 = lshr i32 %10453, 16" -> "  %10460 = add nuw nsw i32 %10458, %10459"
"  %10460 = add nuw nsw i32 %10458, %10459"
"  %10460 = add nuw nsw i32 %10458, %10459" -> "  %10552 = and i32 %10460, 65535""  %10460 = add nuw nsw i32 %10458, %10459" -> "  %10461 = lshr i32 %10460, 16"
"  %10461 = lshr i32 %10460, 16"
"  %10461 = lshr i32 %10460, 16" -> "  %10463 = add nuw nsw i32 %10461, %10462"
"  %10462 = and i32 %10425, 65535"
"  %10462 = and i32 %10425, 65535" -> "  %10463 = add nuw nsw i32 %10461, %10462"
"  %10463 = add nuw nsw i32 %10461, %10462"
"  %10463 = add nuw nsw i32 %10461, %10462" -> "  %10555 = and i32 %10463, 65535""  %10463 = add nuw nsw i32 %10461, %10462" -> "  %10464 = lshr i32 %10463, 16"
"  %10464 = lshr i32 %10463, 16"
"  %10464 = lshr i32 %10463, 16" -> "  %10465 = add nuw i32 %10427, %10464"
"  %10465 = add nuw i32 %10427, %10464"
"  %10465 = add nuw i32 %10427, %10464" -> "  %10559 = add nuw i32 %10465, %10558"
"  %10466 = and i32 %9762, 65535"
"  %10466 = and i32 %9762, 65535" -> "  %10468 = add nuw nsw i32 %10466, %10467"
"  %10467 = and i32 %9800, 65532"
"  %10467 = and i32 %9800, 65532" -> "  %10468 = add nuw nsw i32 %10466, %10467"
"  %10468 = add nuw nsw i32 %10466, %10467"
"  %10468 = add nuw nsw i32 %10466, %10467" -> "  %11217 = and i32 %10468, 65535""  %10468 = add nuw nsw i32 %10466, %10467" -> "  %10472 = lshr i32 %10468, 16"
"  %10469 = and i32 %9768, 65535"
"  %10469 = and i32 %9768, 65535" -> "  %10471 = add nuw nsw i32 %10469, %10470"
"  %10470 = and i32 %9809, 65535"
"  %10470 = and i32 %9809, 65535" -> "  %10471 = add nuw nsw i32 %10469, %10470"
"  %10471 = add nuw nsw i32 %10469, %10470"
"  %10471 = add nuw nsw i32 %10469, %10470" -> "  %10475 = lshr i32 %10471, 16""  %10471 = add nuw nsw i32 %10469, %10470" -> "  %10473 = and i32 %10471, 65535"
"  %10472 = lshr i32 %10468, 16"
"  %10472 = lshr i32 %10468, 16" -> "  %10474 = add nuw nsw i32 %10473, %10472"
"  %10473 = and i32 %10471, 65535"
"  %10473 = and i32 %10471, 65535" -> "  %10474 = add nuw nsw i32 %10473, %10472"
"  %10474 = add nuw nsw i32 %10473, %10472"
"  %10474 = add nuw nsw i32 %10473, %10472" -> "  %11220 = and i32 %10474, 65535""  %10474 = add nuw nsw i32 %10473, %10472" -> "  %10476 = lshr i32 %10474, 16"
"  %10475 = lshr i32 %10471, 16"
"  %10475 = lshr i32 %10471, 16" -> "  %10477 = add nuw nsw i32 %10476, %10475"
"  %10476 = lshr i32 %10474, 16"
"  %10476 = lshr i32 %10474, 16" -> "  %10477 = add nuw nsw i32 %10476, %10475"
"  %10477 = add nuw nsw i32 %10476, %10475"
"  %10477 = add nuw nsw i32 %10476, %10475" -> "  %10488 = add nuw nsw i32 %10477, %10487"
"  %10478 = and i32 %9782, 65535"
"  %10478 = and i32 %9782, 65535" -> "  %10480 = add nuw nsw i32 %10478, %10479"
"  %10479 = and i32 %9874, 65535"
"  %10479 = and i32 %9874, 65535" -> "  %10480 = add nuw nsw i32 %10478, %10479"
"  %10480 = add nuw nsw i32 %10478, %10479"
"  %10480 = add nuw nsw i32 %10478, %10479" -> "  %10487 = and i32 %10480, 65535""  %10480 = add nuw nsw i32 %10478, %10479" -> "  %10484 = lshr i32 %10480, 16"
"  %10481 = and i32 %9785, 65535"
"  %10481 = and i32 %9785, 65535" -> "  %10483 = add nuw nsw i32 %10481, %10482"
"  %10482 = and i32 %9882, 65535"
"  %10482 = and i32 %9882, 65535" -> "  %10483 = add nuw nsw i32 %10481, %10482"
"  %10483 = add nuw nsw i32 %10481, %10482"
"  %10483 = add nuw nsw i32 %10481, %10482" -> "  %10523 = lshr i32 %10483, 16""  %10483 = add nuw nsw i32 %10481, %10482" -> "  %10485 = and i32 %10483, 65535"
"  %10484 = lshr i32 %10480, 16"
"  %10484 = lshr i32 %10480, 16" -> "  %10486 = add nuw nsw i32 %10485, %10484"
"  %10485 = and i32 %10483, 65535"
"  %10485 = and i32 %10483, 65535" -> "  %10486 = add nuw nsw i32 %10485, %10484"
"  %10486 = add nuw nsw i32 %10485, %10484"
"  %10486 = add nuw nsw i32 %10485, %10484" -> "  %10524 = lshr i32 %10486, 16""  %10486 = add nuw nsw i32 %10485, %10484" -> "  %10490 = and i32 %10486, 65535"
"  %10487 = and i32 %10480, 65535"
"  %10487 = and i32 %10480, 65535" -> "  %10488 = add nuw nsw i32 %10477, %10487"
"  %10488 = add nuw nsw i32 %10477, %10487"
"  %10488 = add nuw nsw i32 %10477, %10487" -> "  %11229 = and i32 %10488, 65535""  %10488 = add nuw nsw i32 %10477, %10487" -> "  %10489 = lshr i32 %10488, 16"
"  %10489 = lshr i32 %10488, 16"
"  %10489 = lshr i32 %10488, 16" -> "  %10491 = add nuw nsw i32 %10490, %10489"
"  %10490 = and i32 %10486, 65535"
"  %10490 = and i32 %10486, 65535" -> "  %10491 = add nuw nsw i32 %10490, %10489"
"  %10491 = add nuw nsw i32 %10490, %10489"
"  %10491 = add nuw nsw i32 %10490, %10489" -> "  %11232 = and i32 %10491, 65535""  %10491 = add nuw nsw i32 %10490, %10489" -> "  %10525 = lshr i32 %10491, 16"
"  %10492 = and i32 %9792, 65535"
"  %10492 = and i32 %9792, 65535" -> "  %10494 = add nuw nsw i32 %10492, %10493"
"  %10493 = and i32 %10230, 65535"
"  %10493 = and i32 %10230, 65535" -> "  %10494 = add nuw nsw i32 %10492, %10493"
"  %10494 = add nuw nsw i32 %10492, %10493"
"  %10494 = add nuw nsw i32 %10492, %10493" -> "  %10522 = and i32 %10494, 65535""  %10494 = add nuw nsw i32 %10492, %10493" -> "  %10498 = lshr i32 %10494, 16"
"  %10495 = and i32 %9795, 65535"
"  %10495 = and i32 %9795, 65535" -> "  %10497 = add nuw nsw i32 %10495, %10496"
"  %10496 = and i32 %10236, 65535"
"  %10496 = and i32 %10236, 65535" -> "  %10497 = add nuw nsw i32 %10495, %10496"
"  %10497 = add nuw nsw i32 %10495, %10496"
"  %10497 = add nuw nsw i32 %10495, %10496" -> "  %10514 = lshr i32 %10497, 16""  %10497 = add nuw nsw i32 %10495, %10496" -> "  %10499 = and i32 %10497, 65535"
"  %10498 = lshr i32 %10494, 16"
"  %10498 = lshr i32 %10494, 16" -> "  %10500 = add nuw nsw i32 %10499, %10498"
"  %10499 = and i32 %10497, 65535"
"  %10499 = and i32 %10497, 65535" -> "  %10500 = add nuw nsw i32 %10499, %10498"
"  %10500 = add nuw nsw i32 %10499, %10498"
"  %10500 = add nuw nsw i32 %10499, %10498" -> "  %10529 = and i32 %10500, 65535""  %10500 = add nuw nsw i32 %10499, %10498" -> "  %10515 = lshr i32 %10500, 16"
"  %10501 = and i32 %9797, 65535"
"  %10501 = and i32 %9797, 65535" -> "  %10503 = add nuw nsw i32 %10502, %10501"
"  %10502 = and i32 %10250, 65535"
"  %10502 = and i32 %10250, 65535" -> "  %10503 = add nuw nsw i32 %10502, %10501"
"  %10503 = add nuw nsw i32 %10502, %10501"
"  %10503 = add nuw nsw i32 %10502, %10501" -> "  %10513 = and i32 %10503, 65535""  %10503 = add nuw nsw i32 %10502, %10501" -> "  %10507 = lshr i32 %10503, 16"
"  %10504 = lshr i32 %9797, 16"
"  %10504 = lshr i32 %9797, 16" -> "  %10506 = add nuw nsw i32 %10505, %10504"
"  %10505 = and i32 %10253, 65535"
"  %10505 = and i32 %10253, 65535" -> "  %10506 = add nuw nsw i32 %10505, %10504"
"  %10506 = add nuw nsw i32 %10505, %10504"
"  %10506 = add nuw nsw i32 %10505, %10504" -> "  %10510 = lshr i32 %10506, 16""  %10506 = add nuw nsw i32 %10505, %10504" -> "  %10508 = and i32 %10506, 65535"
"  %10507 = lshr i32 %10503, 16"
"  %10507 = lshr i32 %10503, 16" -> "  %10509 = add nuw nsw i32 %10508, %10507"
"  %10508 = and i32 %10506, 65535"
"  %10508 = and i32 %10506, 65535" -> "  %10509 = add nuw nsw i32 %10508, %10507"
"  %10509 = add nuw nsw i32 %10508, %10507"
"  %10509 = add nuw nsw i32 %10508, %10507" -> "  %10518 = and i32 %10509, 65535""  %10509 = add nuw nsw i32 %10508, %10507" -> "  %10511 = lshr i32 %10509, 16"
"  %10510 = lshr i32 %10506, 16"
"  %10510 = lshr i32 %10506, 16" -> "  %10512 = add nuw nsw i32 %10511, %10510"
"  %10511 = lshr i32 %10509, 16"
"  %10511 = lshr i32 %10509, 16" -> "  %10512 = add nuw nsw i32 %10511, %10510"
"  %10512 = add nuw nsw i32 %10511, %10510"
"  %10512 = add nuw nsw i32 %10511, %10510" -> "  %10540 = add nuw nsw i32 %10512, %10539"
"  %10513 = and i32 %10503, 65535"
"  %10513 = and i32 %10503, 65535" -> "  %10517 = add nuw nsw i32 %10516, %10513"
"  %10514 = lshr i32 %10497, 16"
"  %10514 = lshr i32 %10497, 16" -> "  %10516 = add nuw nsw i32 %10515, %10514"
"  %10515 = lshr i32 %10500, 16"
"  %10515 = lshr i32 %10500, 16" -> "  %10516 = add nuw nsw i32 %10515, %10514"
"  %10516 = add nuw nsw i32 %10515, %10514"
"  %10516 = add nuw nsw i32 %10515, %10514" -> "  %10517 = add nuw nsw i32 %10516, %10513"
"  %10517 = add nuw nsw i32 %10516, %10513"
"  %10517 = add nuw nsw i32 %10516, %10513" -> "  %10532 = and i32 %10517, 65535""  %10517 = add nuw nsw i32 %10516, %10513" -> "  %10519 = lshr i32 %10517, 16"
"  %10518 = and i32 %10509, 65535"
"  %10518 = and i32 %10509, 65535" -> "  %10520 = add nuw nsw i32 %10518, %10519"
"  %10519 = lshr i32 %10517, 16"
"  %10519 = lshr i32 %10517, 16" -> "  %10520 = add nuw nsw i32 %10518, %10519"
"  %10520 = add nuw nsw i32 %10518, %10519"
"  %10520 = add nuw nsw i32 %10518, %10519" -> "  %10535 = and i32 %10520, 65535""  %10520 = add nuw nsw i32 %10518, %10519" -> "  %10521 = lshr i32 %10520, 16"
"  %10521 = lshr i32 %10520, 16"
"  %10521 = lshr i32 %10520, 16" -> "  %10541 = add nuw nsw i32 %10540, %10521"
"  %10522 = and i32 %10494, 65535"
"  %10522 = and i32 %10494, 65535" -> "  %10527 = add nuw nsw i32 %10526, %10522"
"  %10523 = lshr i32 %10483, 16"
"  %10523 = lshr i32 %10483, 16" -> "  %10526 = add nuw nsw i32 %10524, %10523"
"  %10524 = lshr i32 %10486, 16"
"  %10524 = lshr i32 %10486, 16" -> "  %10526 = add nuw nsw i32 %10524, %10523"
"  %10525 = lshr i32 %10491, 16"
"  %10525 = lshr i32 %10491, 16" -> "  %10528 = add nuw nsw i32 %10527, %10525"
"  %10526 = add nuw nsw i32 %10524, %10523"
"  %10526 = add nuw nsw i32 %10524, %10523" -> "  %10527 = add nuw nsw i32 %10526, %10522"
"  %10527 = add nuw nsw i32 %10526, %10522"
"  %10527 = add nuw nsw i32 %10526, %10522" -> "  %10528 = add nuw nsw i32 %10527, %10525"
"  %10528 = add nuw nsw i32 %10527, %10525"
"  %10528 = add nuw nsw i32 %10527, %10525" -> "  %11243 = and i32 %10528, 65535""  %10528 = add nuw nsw i32 %10527, %10525" -> "  %10530 = lshr i32 %10528, 16"
"  %10529 = and i32 %10500, 65535"
"  %10529 = and i32 %10500, 65535" -> "  %10531 = add nuw nsw i32 %10529, %10530"
"  %10530 = lshr i32 %10528, 16"
"  %10530 = lshr i32 %10528, 16" -> "  %10531 = add nuw nsw i32 %10529, %10530"
"  %10531 = add nuw nsw i32 %10529, %10530"
"  %10531 = add nuw nsw i32 %10529, %10530" -> "  %11246 = and i32 %10531, 65535""  %10531 = add nuw nsw i32 %10529, %10530" -> "  %10533 = lshr i32 %10531, 16"
"  %10532 = and i32 %10517, 65535"
"  %10532 = and i32 %10517, 65535" -> "  %10534 = add nuw nsw i32 %10532, %10533"
"  %10533 = lshr i32 %10531, 16"
"  %10533 = lshr i32 %10531, 16" -> "  %10534 = add nuw nsw i32 %10532, %10533"
"  %10534 = add nuw nsw i32 %10532, %10533"
"  %10534 = add nuw nsw i32 %10532, %10533" -> "  %11255 = and i32 %10534, 65535""  %10534 = add nuw nsw i32 %10532, %10533" -> "  %10536 = lshr i32 %10534, 16"
"  %10535 = and i32 %10520, 65535"
"  %10535 = and i32 %10520, 65535" -> "  %10537 = add nuw nsw i32 %10535, %10536"
"  %10536 = lshr i32 %10534, 16"
"  %10536 = lshr i32 %10534, 16" -> "  %10537 = add nuw nsw i32 %10535, %10536"
"  %10537 = add nuw nsw i32 %10535, %10536"
"  %10537 = add nuw nsw i32 %10535, %10536" -> "  %11258 = and i32 %10537, 65535""  %10537 = add nuw nsw i32 %10535, %10536" -> "  %10538 = lshr i32 %10537, 16"
"  %10538 = lshr i32 %10537, 16"
"  %10538 = lshr i32 %10537, 16" -> "  %10542 = add nuw nsw i32 %10541, %10538"
"  %10539 = and i32 %10430, 65535"
"  %10539 = and i32 %10430, 65535" -> "  %10540 = add nuw nsw i32 %10512, %10539"
"  %10540 = add nuw nsw i32 %10512, %10539"
"  %10540 = add nuw nsw i32 %10512, %10539" -> "  %10541 = add nuw nsw i32 %10540, %10521"
"  %10541 = add nuw nsw i32 %10540, %10521"
"  %10541 = add nuw nsw i32 %10540, %10521" -> "  %10542 = add nuw nsw i32 %10541, %10538"
"  %10542 = add nuw nsw i32 %10541, %10538"
"  %10542 = add nuw nsw i32 %10541, %10538" -> "  %11971 = and i32 %10542, 65535""  %10542 = add nuw nsw i32 %10541, %10538" -> "  %10545 = lshr i32 %10542, 16"
"  %10543 = and i32 %10436, 65535"
"  %10543 = and i32 %10436, 65535" -> "  %10546 = add nuw nsw i32 %10545, %10543"
"  %10544 = and i32 %10450, 65535"
"  %10544 = and i32 %10450, 65535" -> "  %10548 = add nuw nsw i32 %10547, %10544"
"  %10545 = lshr i32 %10542, 16"
"  %10545 = lshr i32 %10542, 16" -> "  %10546 = add nuw nsw i32 %10545, %10543"
"  %10546 = add nuw nsw i32 %10545, %10543"
"  %10546 = add nuw nsw i32 %10545, %10543" -> "  %11974 = and i32 %10546, 65535""  %10546 = add nuw nsw i32 %10545, %10543" -> "  %10547 = lshr i32 %10546, 16"
"  %10547 = lshr i32 %10546, 16"
"  %10547 = lshr i32 %10546, 16" -> "  %10548 = add nuw nsw i32 %10547, %10544"
"  %10548 = add nuw nsw i32 %10547, %10544"
"  %10548 = add nuw nsw i32 %10547, %10544" -> "  %11980 = and i32 %10548, 65535""  %10548 = add nuw nsw i32 %10547, %10544" -> "  %10550 = lshr i32 %10548, 16"
"  %10549 = and i32 %10453, 65535"
"  %10549 = and i32 %10453, 65535" -> "  %10551 = add nuw nsw i32 %10550, %10549"
"  %10550 = lshr i32 %10548, 16"
"  %10550 = lshr i32 %10548, 16" -> "  %10551 = add nuw nsw i32 %10550, %10549"
"  %10551 = add nuw nsw i32 %10550, %10549"
"  %10551 = add nuw nsw i32 %10550, %10549" -> "  %11983 = and i32 %10551, 65535""  %10551 = add nuw nsw i32 %10550, %10549" -> "  %10553 = lshr i32 %10551, 16"
"  %10552 = and i32 %10460, 65535"
"  %10552 = and i32 %10460, 65535" -> "  %10554 = add nuw nsw i32 %10553, %10552"
"  %10553 = lshr i32 %10551, 16"
"  %10553 = lshr i32 %10551, 16" -> "  %10554 = add nuw nsw i32 %10553, %10552"
"  %10554 = add nuw nsw i32 %10553, %10552"
"  %10554 = add nuw nsw i32 %10553, %10552" -> "  %11997 = and i32 %10554, 65535""  %10554 = add nuw nsw i32 %10553, %10552" -> "  %10556 = lshr i32 %10554, 16"
"  %10555 = and i32 %10463, 65535"
"  %10555 = and i32 %10463, 65535" -> "  %10557 = add nuw nsw i32 %10556, %10555"
"  %10556 = lshr i32 %10554, 16"
"  %10556 = lshr i32 %10554, 16" -> "  %10557 = add nuw nsw i32 %10556, %10555"
"  %10557 = add nuw nsw i32 %10556, %10555"
"  %10557 = add nuw nsw i32 %10556, %10555" -> "  %12000 = and i32 %10557, 65535""  %10557 = add nuw nsw i32 %10556, %10555" -> "  %10558 = lshr i32 %10557, 16"
"  %10558 = lshr i32 %10557, 16"
"  %10558 = lshr i32 %10557, 16" -> "  %10559 = add nuw i32 %10465, %10558"
"  %10559 = add nuw i32 %10465, %10558"
"  %10559 = add nuw i32 %10465, %10558" -> "  %12006 = and i32 %10559, 65535""  %10559 = add nuw i32 %10465, %10558" -> "  %12009 = lshr i32 %10559, 16"
"  %10560 = mul nuw i32 %9136, 42779"
"  %10560 = mul nuw i32 %9136, 42779" -> "  %11218 = and i32 %10560, 65535""  %10560 = mul nuw i32 %9136, 42779" -> "  %10561 = lshr i32 %10560, 16"
"  %10561 = lshr i32 %10560, 16"
"  %10561 = lshr i32 %10560, 16" -> "  %10564 = add nuw nsw i32 %10563, %10561"
"  %10562 = mul nuw i32 %9137, 42779"
"  %10562 = mul nuw i32 %9137, 42779" -> "  %10565 = and i32 %10562, -65536""  %10562 = mul nuw i32 %9137, 42779" -> "  %10563 = and i32 %10562, 65535"
"  %10563 = and i32 %10562, 65535"
"  %10563 = and i32 %10562, 65535" -> "  %10564 = add nuw nsw i32 %10563, %10561"
"  %10564 = add nuw nsw i32 %10563, %10561"
"  %10564 = add nuw nsw i32 %10563, %10561" -> "  %10566 = add nuw i32 %10564, %10565"
"  %10565 = and i32 %10562, -65536"
"  %10565 = and i32 %10562, -65536" -> "  %10566 = add nuw i32 %10564, %10565"
"  %10566 = add nuw i32 %10564, %10565"
"  %10566 = add nuw i32 %10564, %10565" -> "  %10570 = lshr i32 %10566, 16""  %10566 = add nuw i32 %10564, %10565" -> "  %10568 = and i32 %10566, 65535"
"  %10567 = mul nuw nsw i32 %9136, 9871"
"  %10567 = mul nuw nsw i32 %9136, 9871" -> "  %10569 = add nuw nsw i32 %10568, %10567"
"  %10568 = and i32 %10566, 65535"
"  %10568 = and i32 %10566, 65535" -> "  %10569 = add nuw nsw i32 %10568, %10567"
"  %10569 = add nuw nsw i32 %10568, %10567"
"  %10569 = add nuw nsw i32 %10568, %10567" -> "  %11221 = and i32 %10569, 65535""  %10569 = add nuw nsw i32 %10568, %10567" -> "  %10573 = lshr i32 %10569, 16"
"  %10570 = lshr i32 %10566, 16"
"  %10570 = lshr i32 %10566, 16" -> "  %10572 = add nuw nsw i32 %10570, %10571"
"  %10571 = mul nuw nsw i32 %9137, 9871"
"  %10571 = mul nuw nsw i32 %9137, 9871" -> "  %10572 = add nuw nsw i32 %10570, %10571"
"  %10572 = add nuw nsw i32 %10570, %10571"
"  %10572 = add nuw nsw i32 %10570, %10571" -> "  %10576 = and i32 %10572, 2147418112""  %10572 = add nuw nsw i32 %10570, %10571" -> "  %10574 = and i32 %10572, 65535"
"  %10573 = lshr i32 %10569, 16"
"  %10573 = lshr i32 %10569, 16" -> "  %10575 = add nuw nsw i32 %10573, %10574"
"  %10574 = and i32 %10572, 65535"
"  %10574 = and i32 %10572, 65535" -> "  %10575 = add nuw nsw i32 %10573, %10574"
"  %10575 = add nuw nsw i32 %10573, %10574"
"  %10575 = add nuw nsw i32 %10573, %10574" -> "  %10577 = add nuw nsw i32 %10575, %10576"
"  %10576 = and i32 %10572, 2147418112"
"  %10576 = and i32 %10572, 2147418112" -> "  %10577 = add nuw nsw i32 %10575, %10576"
"  %10577 = add nuw nsw i32 %10575, %10576"
"  %10577 = add nuw nsw i32 %10575, %10576" -> "  %10596 = and i32 %10577, 65535""  %10577 = add nuw nsw i32 %10575, %10576" -> "  %10600 = lshr i32 %10577, 16"
"  %10578 = mul nuw i32 %9156, 42779"
"  %10578 = mul nuw i32 %9156, 42779" -> "  %10597 = and i32 %10578, 65535""  %10578 = mul nuw i32 %9156, 42779" -> "  %10579 = lshr i32 %10578, 16"
"  %10579 = lshr i32 %10578, 16"
"  %10579 = lshr i32 %10578, 16" -> "  %10582 = add nuw nsw i32 %10581, %10579"
"  %10580 = mul nuw i32 %9159, 42779"
"  %10580 = mul nuw i32 %9159, 42779" -> "  %10583 = and i32 %10580, -65536""  %10580 = mul nuw i32 %9159, 42779" -> "  %10581 = and i32 %10580, 65535"
"  %10581 = and i32 %10580, 65535"
"  %10581 = and i32 %10580, 65535" -> "  %10582 = add nuw nsw i32 %10581, %10579"
"  %10582 = add nuw nsw i32 %10581, %10579"
"  %10582 = add nuw nsw i32 %10581, %10579" -> "  %10584 = add nuw i32 %10582, %10583"
"  %10583 = and i32 %10580, -65536"
"  %10583 = and i32 %10580, -65536" -> "  %10584 = add nuw i32 %10582, %10583"
"  %10584 = add nuw i32 %10582, %10583"
"  %10584 = add nuw i32 %10582, %10583" -> "  %10588 = lshr i32 %10584, 16""  %10584 = add nuw i32 %10582, %10583" -> "  %10586 = and i32 %10584, 65535"
"  %10585 = mul nuw nsw i32 %9156, 9871"
"  %10585 = mul nuw nsw i32 %9156, 9871" -> "  %10587 = add nuw nsw i32 %10586, %10585"
"  %10586 = and i32 %10584, 65535"
"  %10586 = and i32 %10584, 65535" -> "  %10587 = add nuw nsw i32 %10586, %10585"
"  %10587 = add nuw nsw i32 %10586, %10585"
"  %10587 = add nuw nsw i32 %10586, %10585" -> "  %10599 = and i32 %10587, 65535""  %10587 = add nuw nsw i32 %10586, %10585" -> "  %10591 = lshr i32 %10587, 16"
"  %10588 = lshr i32 %10584, 16"
"  %10588 = lshr i32 %10584, 16" -> "  %10590 = add nuw nsw i32 %10588, %10589"
"  %10589 = mul nuw nsw i32 %9159, 9871"
"  %10589 = mul nuw nsw i32 %9159, 9871" -> "  %10590 = add nuw nsw i32 %10588, %10589"
"  %10590 = add nuw nsw i32 %10588, %10589"
"  %10590 = add nuw nsw i32 %10588, %10589" -> "  %10594 = and i32 %10590, 2147418112""  %10590 = add nuw nsw i32 %10588, %10589" -> "  %10592 = and i32 %10590, 65535"
"  %10591 = lshr i32 %10587, 16"
"  %10591 = lshr i32 %10587, 16" -> "  %10593 = add nuw nsw i32 %10592, %10591"
"  %10592 = and i32 %10590, 65535"
"  %10592 = and i32 %10590, 65535" -> "  %10593 = add nuw nsw i32 %10592, %10591"
"  %10593 = add nuw nsw i32 %10592, %10591"
"  %10593 = add nuw nsw i32 %10592, %10591" -> "  %10595 = add nuw nsw i32 %10593, %10594"
"  %10594 = and i32 %10590, 2147418112"
"  %10594 = and i32 %10590, 2147418112" -> "  %10595 = add nuw nsw i32 %10593, %10594"
"  %10595 = add nuw nsw i32 %10593, %10594"
"  %10595 = add nuw nsw i32 %10593, %10594" -> "  %10603 = add nuw nsw i32 %10595, %10602"
"  %10596 = and i32 %10577, 65535"
"  %10596 = and i32 %10577, 65535" -> "  %10598 = add nuw nsw i32 %10596, %10597"
"  %10597 = and i32 %10578, 65535"
"  %10597 = and i32 %10578, 65535" -> "  %10598 = add nuw nsw i32 %10596, %10597"
"  %10598 = add nuw nsw i32 %10596, %10597"
"  %10598 = add nuw nsw i32 %10596, %10597" -> "  %10627 = and i32 %10598, 65535""  %10598 = add nuw nsw i32 %10596, %10597" -> "  %10605 = lshr i32 %10598, 16"
"  %10599 = and i32 %10587, 65535"
"  %10599 = and i32 %10587, 65535" -> "  %10601 = add nuw nsw i32 %10599, %10600"
"  %10600 = lshr i32 %10577, 16"
"  %10600 = lshr i32 %10577, 16" -> "  %10601 = add nuw nsw i32 %10599, %10600"
"  %10601 = add nuw nsw i32 %10599, %10600"
"  %10601 = add nuw nsw i32 %10599, %10600" -> "  %10604 = and i32 %10601, 65535""  %10601 = add nuw nsw i32 %10599, %10600" -> "  %10602 = lshr i32 %10601, 16"
"  %10602 = lshr i32 %10601, 16"
"  %10602 = lshr i32 %10601, 16" -> "  %10603 = add nuw nsw i32 %10595, %10602"
"  %10603 = add nuw nsw i32 %10595, %10602"
"  %10603 = add nuw nsw i32 %10595, %10602" -> "  %10608 = add nuw nsw i32 %10603, %10607"
"  %10604 = and i32 %10601, 65535"
"  %10604 = and i32 %10601, 65535" -> "  %10606 = add nuw nsw i32 %10604, %10605"
"  %10605 = lshr i32 %10598, 16"
"  %10605 = lshr i32 %10598, 16" -> "  %10606 = add nuw nsw i32 %10604, %10605"
"  %10606 = add nuw nsw i32 %10604, %10605"
"  %10606 = add nuw nsw i32 %10604, %10605" -> "  %10630 = and i32 %10606, 65535""  %10606 = add nuw nsw i32 %10604, %10605" -> "  %10607 = lshr i32 %10606, 16"
"  %10607 = lshr i32 %10606, 16"
"  %10607 = lshr i32 %10606, 16" -> "  %10608 = add nuw nsw i32 %10603, %10607"
"  %10608 = add nuw nsw i32 %10603, %10607"
"  %10608 = add nuw nsw i32 %10603, %10607" -> "  %10662 = lshr i32 %10608, 16""  %10608 = add nuw nsw i32 %10603, %10607" -> "  %10658 = and i32 %10608, 65535"
"  %10609 = mul nuw nsw i32 %9136, 24315"
"  %10609 = mul nuw nsw i32 %9136, 24315" -> "  %10628 = and i32 %10609, 65535""  %10609 = mul nuw nsw i32 %9136, 24315" -> "  %10610 = lshr i32 %10609, 16"
"  %10610 = lshr i32 %10609, 16"
"  %10610 = lshr i32 %10609, 16" -> "  %10613 = add nuw nsw i32 %10612, %10610"
"  %10611 = mul nuw nsw i32 %9137, 24315"
"  %10611 = mul nuw nsw i32 %9137, 24315" -> "  %10614 = and i32 %10611, 2147418112""  %10611 = mul nuw nsw i32 %9137, 24315" -> "  %10612 = and i32 %10611, 65535"
"  %10612 = and i32 %10611, 65535"
"  %10612 = and i32 %10611, 65535" -> "  %10613 = add nuw nsw i32 %10612, %10610"
"  %10613 = add nuw nsw i32 %10612, %10610"
"  %10613 = add nuw nsw i32 %10612, %10610" -> "  %10615 = add nuw nsw i32 %10613, %10614"
"  %10614 = and i32 %10611, 2147418112"
"  %10614 = and i32 %10611, 2147418112" -> "  %10615 = add nuw nsw i32 %10613, %10614"
"  %10615 = add nuw nsw i32 %10613, %10614"
"  %10615 = add nuw nsw i32 %10613, %10614" -> "  %10619 = lshr i32 %10615, 16""  %10615 = add nuw nsw i32 %10613, %10614" -> "  %10617 = and i32 %10615, 65535"
"  %10616 = mul nuw nsw i32 %9136, 29744"
"  %10616 = mul nuw nsw i32 %9136, 29744" -> "  %10618 = add nuw nsw i32 %10617, %10616"
"  %10617 = and i32 %10615, 65535"
"  %10617 = and i32 %10615, 65535" -> "  %10618 = add nuw nsw i32 %10617, %10616"
"  %10618 = add nuw nsw i32 %10617, %10616"
"  %10618 = add nuw nsw i32 %10617, %10616" -> "  %10631 = and i32 %10618, 65535""  %10618 = add nuw nsw i32 %10617, %10616" -> "  %10622 = lshr i32 %10618, 16"
"  %10619 = lshr i32 %10615, 16"
"  %10619 = lshr i32 %10615, 16" -> "  %10621 = add nuw nsw i32 %10619, %10620"
"  %10620 = mul nuw nsw i32 %9137, 29744"
"  %10620 = mul nuw nsw i32 %9137, 29744" -> "  %10621 = add nuw nsw i32 %10619, %10620"
"  %10621 = add nuw nsw i32 %10619, %10620"
"  %10621 = add nuw nsw i32 %10619, %10620" -> "  %10625 = and i32 %10621, 2147418112""  %10621 = add nuw nsw i32 %10619, %10620" -> "  %10623 = and i32 %10621, 65535"
"  %10622 = lshr i32 %10618, 16"
"  %10622 = lshr i32 %10618, 16" -> "  %10624 = add nuw nsw i32 %10622, %10623"
"  %10623 = and i32 %10621, 65535"
"  %10623 = and i32 %10621, 65535" -> "  %10624 = add nuw nsw i32 %10622, %10623"
"  %10624 = add nuw nsw i32 %10622, %10623"
"  %10624 = add nuw nsw i32 %10622, %10623" -> "  %10626 = add nuw nsw i32 %10624, %10625"
"  %10625 = and i32 %10621, 2147418112"
"  %10625 = and i32 %10621, 2147418112" -> "  %10626 = add nuw nsw i32 %10624, %10625"
"  %10626 = add nuw nsw i32 %10624, %10625"
"  %10626 = add nuw nsw i32 %10624, %10625" -> "  %10634 = add nuw nsw i32 %10626, %10633"
"  %10627 = and i32 %10598, 65535"
"  %10627 = and i32 %10598, 65535" -> "  %10629 = add nuw nsw i32 %10627, %10628"
"  %10628 = and i32 %10609, 65535"
"  %10628 = and i32 %10609, 65535" -> "  %10629 = add nuw nsw i32 %10627, %10628"
"  %10629 = add nuw nsw i32 %10627, %10628"
"  %10629 = add nuw nsw i32 %10627, %10628" -> "  %11230 = and i32 %10629, 65535""  %10629 = add nuw nsw i32 %10627, %10628" -> "  %10636 = lshr i32 %10629, 16"
"  %10630 = and i32 %10606, 65535"
"  %10630 = and i32 %10606, 65535" -> "  %10632 = add nuw nsw i32 %10630, %10631"
"  %10631 = and i32 %10618, 65535"
"  %10631 = and i32 %10618, 65535" -> "  %10632 = add nuw nsw i32 %10630, %10631"
"  %10632 = add nuw nsw i32 %10630, %10631"
"  %10632 = add nuw nsw i32 %10630, %10631" -> "  %10635 = and i32 %10632, 65535""  %10632 = add nuw nsw i32 %10630, %10631" -> "  %10633 = lshr i32 %10632, 16"
"  %10633 = lshr i32 %10632, 16"
"  %10633 = lshr i32 %10632, 16" -> "  %10634 = add nuw nsw i32 %10626, %10633"
"  %10634 = add nuw nsw i32 %10626, %10633"
"  %10634 = add nuw nsw i32 %10626, %10633" -> "  %10639 = add nuw nsw i32 %10634, %10638"
"  %10635 = and i32 %10632, 65535"
"  %10635 = and i32 %10632, 65535" -> "  %10637 = add nuw nsw i32 %10635, %10636"
"  %10636 = lshr i32 %10629, 16"
"  %10636 = lshr i32 %10629, 16" -> "  %10637 = add nuw nsw i32 %10635, %10636"
"  %10637 = add nuw nsw i32 %10635, %10636"
"  %10637 = add nuw nsw i32 %10635, %10636" -> "  %11233 = and i32 %10637, 65535""  %10637 = add nuw nsw i32 %10635, %10636" -> "  %10638 = lshr i32 %10637, 16"
"  %10638 = lshr i32 %10637, 16"
"  %10638 = lshr i32 %10637, 16" -> "  %10639 = add nuw nsw i32 %10634, %10638"
"  %10639 = add nuw nsw i32 %10634, %10638"
"  %10639 = add nuw nsw i32 %10634, %10638" -> "  %10675 = lshr i32 %10639, 16""  %10639 = add nuw nsw i32 %10634, %10638" -> "  %10672 = and i32 %10639, 65535"
"  %10640 = mul nuw nsw i32 %9156, 24315"
"  %10640 = mul nuw nsw i32 %9156, 24315" -> "  %10659 = and i32 %10640, 65535""  %10640 = mul nuw nsw i32 %9156, 24315" -> "  %10641 = lshr i32 %10640, 16"
"  %10641 = lshr i32 %10640, 16"
"  %10641 = lshr i32 %10640, 16" -> "  %10644 = add nuw nsw i32 %10643, %10641"
"  %10642 = mul nuw nsw i32 %9159, 24315"
"  %10642 = mul nuw nsw i32 %9159, 24315" -> "  %10645 = and i32 %10642, 2147418112""  %10642 = mul nuw nsw i32 %9159, 24315" -> "  %10643 = and i32 %10642, 65535"
"  %10643 = and i32 %10642, 65535"
"  %10643 = and i32 %10642, 65535" -> "  %10644 = add nuw nsw i32 %10643, %10641"
"  %10644 = add nuw nsw i32 %10643, %10641"
"  %10644 = add nuw nsw i32 %10643, %10641" -> "  %10646 = add nuw nsw i32 %10644, %10645"
"  %10645 = and i32 %10642, 2147418112"
"  %10645 = and i32 %10642, 2147418112" -> "  %10646 = add nuw nsw i32 %10644, %10645"
"  %10646 = add nuw nsw i32 %10644, %10645"
"  %10646 = add nuw nsw i32 %10644, %10645" -> "  %10650 = lshr i32 %10646, 16""  %10646 = add nuw nsw i32 %10644, %10645" -> "  %10648 = and i32 %10646, 65535"
"  %10647 = mul nuw nsw i32 %9156, 29744"
"  %10647 = mul nuw nsw i32 %9156, 29744" -> "  %10649 = add nuw nsw i32 %10648, %10647"
"  %10648 = and i32 %10646, 65535"
"  %10648 = and i32 %10646, 65535" -> "  %10649 = add nuw nsw i32 %10648, %10647"
"  %10649 = add nuw nsw i32 %10648, %10647"
"  %10649 = add nuw nsw i32 %10648, %10647" -> "  %10661 = and i32 %10649, 65535""  %10649 = add nuw nsw i32 %10648, %10647" -> "  %10653 = lshr i32 %10649, 16"
"  %10650 = lshr i32 %10646, 16"
"  %10650 = lshr i32 %10646, 16" -> "  %10652 = add nuw nsw i32 %10650, %10651"
"  %10651 = mul nuw nsw i32 %9159, 29744"
"  %10651 = mul nuw nsw i32 %9159, 29744" -> "  %10652 = add nuw nsw i32 %10650, %10651"
"  %10652 = add nuw nsw i32 %10650, %10651"
"  %10652 = add nuw nsw i32 %10650, %10651" -> "  %10656 = and i32 %10652, 2147418112""  %10652 = add nuw nsw i32 %10650, %10651" -> "  %10654 = and i32 %10652, 65535"
"  %10653 = lshr i32 %10649, 16"
"  %10653 = lshr i32 %10649, 16" -> "  %10655 = add nuw nsw i32 %10653, %10654"
"  %10654 = and i32 %10652, 65535"
"  %10654 = and i32 %10652, 65535" -> "  %10655 = add nuw nsw i32 %10653, %10654"
"  %10655 = add nuw nsw i32 %10653, %10654"
"  %10655 = add nuw nsw i32 %10653, %10654" -> "  %10657 = add nuw nsw i32 %10655, %10656"
"  %10656 = and i32 %10652, 2147418112"
"  %10656 = and i32 %10652, 2147418112" -> "  %10657 = add nuw nsw i32 %10655, %10656"
"  %10657 = add nuw nsw i32 %10655, %10656"
"  %10657 = add nuw nsw i32 %10655, %10656" -> "  %10665 = add nuw nsw i32 %10657, %10664"
"  %10658 = and i32 %10608, 65535"
"  %10658 = and i32 %10608, 65535" -> "  %10660 = add nuw nsw i32 %10658, %10659"
"  %10659 = and i32 %10640, 65535"
"  %10659 = and i32 %10640, 65535" -> "  %10660 = add nuw nsw i32 %10658, %10659"
"  %10660 = add nuw nsw i32 %10658, %10659"
"  %10660 = add nuw nsw i32 %10658, %10659" -> "  %10671 = and i32 %10660, 65535""  %10660 = add nuw nsw i32 %10658, %10659" -> "  %10667 = lshr i32 %10660, 16"
"  %10661 = and i32 %10649, 65535"
"  %10661 = and i32 %10649, 65535" -> "  %10663 = add nuw nsw i32 %10662, %10661"
"  %10662 = lshr i32 %10608, 16"
"  %10662 = lshr i32 %10608, 16" -> "  %10663 = add nuw nsw i32 %10662, %10661"
"  %10663 = add nuw nsw i32 %10662, %10661"
"  %10663 = add nuw nsw i32 %10662, %10661" -> "  %10666 = and i32 %10663, 65535""  %10663 = add nuw nsw i32 %10662, %10661" -> "  %10664 = lshr i32 %10663, 16"
"  %10664 = lshr i32 %10663, 16"
"  %10664 = lshr i32 %10663, 16" -> "  %10665 = add nuw nsw i32 %10657, %10664"
"  %10665 = add nuw nsw i32 %10657, %10664"
"  %10665 = add nuw nsw i32 %10657, %10664" -> "  %10670 = add nuw nsw i32 %10665, %10669"
"  %10666 = and i32 %10663, 65535"
"  %10666 = and i32 %10663, 65535" -> "  %10668 = add nuw nsw i32 %10667, %10666"
"  %10667 = lshr i32 %10660, 16"
"  %10667 = lshr i32 %10660, 16" -> "  %10668 = add nuw nsw i32 %10667, %10666"
"  %10668 = add nuw nsw i32 %10667, %10666"
"  %10668 = add nuw nsw i32 %10667, %10666" -> "  %10674 = and i32 %10668, 65535""  %10668 = add nuw nsw i32 %10667, %10666" -> "  %10669 = lshr i32 %10668, 16"
"  %10669 = lshr i32 %10668, 16"
"  %10669 = lshr i32 %10668, 16" -> "  %10670 = add nuw nsw i32 %10665, %10669"
"  %10670 = add nuw nsw i32 %10665, %10669"
"  %10670 = add nuw nsw i32 %10665, %10669" -> "  %10682 = add nuw nsw i32 %10670, %10680"
"  %10671 = and i32 %10660, 65535"
"  %10671 = and i32 %10660, 65535" -> "  %10673 = add nuw nsw i32 %10672, %10671"
"  %10672 = and i32 %10639, 65535"
"  %10672 = and i32 %10639, 65535" -> "  %10673 = add nuw nsw i32 %10672, %10671"
"  %10673 = add nuw nsw i32 %10672, %10671"
"  %10673 = add nuw nsw i32 %10672, %10671" -> "  %10812 = and i32 %10673, 65535""  %10673 = add nuw nsw i32 %10672, %10671" -> "  %10677 = lshr i32 %10673, 16"
"  %10674 = and i32 %10668, 65535"
"  %10674 = and i32 %10668, 65535" -> "  %10676 = add nuw nsw i32 %10675, %10674"
"  %10675 = lshr i32 %10639, 16"
"  %10675 = lshr i32 %10639, 16" -> "  %10676 = add nuw nsw i32 %10675, %10674"
"  %10676 = add nuw nsw i32 %10675, %10674"
"  %10676 = add nuw nsw i32 %10675, %10674" -> "  %10680 = lshr i32 %10676, 16""  %10676 = add nuw nsw i32 %10675, %10674" -> "  %10678 = and i32 %10676, 65535"
"  %10677 = lshr i32 %10673, 16"
"  %10677 = lshr i32 %10673, 16" -> "  %10679 = add nuw nsw i32 %10677, %10678"
"  %10678 = and i32 %10676, 65535"
"  %10678 = and i32 %10676, 65535" -> "  %10679 = add nuw nsw i32 %10677, %10678"
"  %10679 = add nuw nsw i32 %10677, %10678"
"  %10679 = add nuw nsw i32 %10677, %10678" -> "  %10815 = and i32 %10679, 65535""  %10679 = add nuw nsw i32 %10677, %10678" -> "  %10681 = lshr i32 %10679, 16"
"  %10680 = lshr i32 %10676, 16"
"  %10680 = lshr i32 %10676, 16" -> "  %10682 = add nuw nsw i32 %10670, %10680"
"  %10681 = lshr i32 %10679, 16"
"  %10681 = lshr i32 %10679, 16" -> "  %10683 = add nuw nsw i32 %10682, %10681"
"  %10682 = add nuw nsw i32 %10670, %10680"
"  %10682 = add nuw nsw i32 %10670, %10680" -> "  %10683 = add nuw nsw i32 %10682, %10681"
"  %10683 = add nuw nsw i32 %10682, %10681"
"  %10683 = add nuw nsw i32 %10682, %10681" -> "  %10823 = and i32 %10683, 65535""  %10683 = add nuw nsw i32 %10682, %10681" -> "  %10826 = lshr i32 %10683, 16"
"  %10684 = mul nuw i32 %9270, 42779"
"  %10684 = mul nuw i32 %9270, 42779" -> "  %10811 = and i32 %10684, 65535""  %10684 = mul nuw i32 %9270, 42779" -> "  %10685 = lshr i32 %10684, 16"
"  %10685 = lshr i32 %10684, 16"
"  %10685 = lshr i32 %10684, 16" -> "  %10688 = add nuw nsw i32 %10687, %10685"
"  %10686 = mul nuw i32 %9273, 42779"
"  %10686 = mul nuw i32 %9273, 42779" -> "  %10689 = and i32 %10686, -65536""  %10686 = mul nuw i32 %9273, 42779" -> "  %10687 = and i32 %10686, 65535"
"  %10687 = and i32 %10686, 65535"
"  %10687 = and i32 %10686, 65535" -> "  %10688 = add nuw nsw i32 %10687, %10685"
"  %10688 = add nuw nsw i32 %10687, %10685"
"  %10688 = add nuw nsw i32 %10687, %10685" -> "  %10690 = add nuw i32 %10688, %10689"
"  %10689 = and i32 %10686, -65536"
"  %10689 = and i32 %10686, -65536" -> "  %10690 = add nuw i32 %10688, %10689"
"  %10690 = add nuw i32 %10688, %10689"
"  %10690 = add nuw i32 %10688, %10689" -> "  %10694 = lshr i32 %10690, 16""  %10690 = add nuw i32 %10688, %10689" -> "  %10692 = and i32 %10690, 65535"
"  %10691 = mul nuw nsw i32 %9270, 9871"
"  %10691 = mul nuw nsw i32 %9270, 9871" -> "  %10693 = add nuw nsw i32 %10692, %10691"
"  %10692 = and i32 %10690, 65535"
"  %10692 = and i32 %10690, 65535" -> "  %10693 = add nuw nsw i32 %10692, %10691"
"  %10693 = add nuw nsw i32 %10692, %10691"
"  %10693 = add nuw nsw i32 %10692, %10691" -> "  %10814 = and i32 %10693, 65535""  %10693 = add nuw nsw i32 %10692, %10691" -> "  %10697 = lshr i32 %10693, 16"
"  %10694 = lshr i32 %10690, 16"
"  %10694 = lshr i32 %10690, 16" -> "  %10696 = add nuw nsw i32 %10694, %10695"
"  %10695 = mul nuw nsw i32 %9273, 9871"
"  %10695 = mul nuw nsw i32 %9273, 9871" -> "  %10696 = add nuw nsw i32 %10694, %10695"
"  %10696 = add nuw nsw i32 %10694, %10695"
"  %10696 = add nuw nsw i32 %10694, %10695" -> "  %10700 = and i32 %10696, 2147418112""  %10696 = add nuw nsw i32 %10694, %10695" -> "  %10698 = and i32 %10696, 65535"
"  %10697 = lshr i32 %10693, 16"
"  %10697 = lshr i32 %10693, 16" -> "  %10699 = add nuw nsw i32 %10697, %10698"
"  %10698 = and i32 %10696, 65535"
"  %10698 = and i32 %10696, 65535" -> "  %10699 = add nuw nsw i32 %10697, %10698"
"  %10699 = add nuw nsw i32 %10697, %10698"
"  %10699 = add nuw nsw i32 %10697, %10698" -> "  %10701 = add nuw nsw i32 %10699, %10700"
"  %10700 = and i32 %10696, 2147418112"
"  %10700 = and i32 %10696, 2147418112" -> "  %10701 = add nuw nsw i32 %10699, %10700"
"  %10701 = add nuw nsw i32 %10699, %10700"
"  %10701 = add nuw nsw i32 %10699, %10700" -> "  %10724 = lshr i32 %10701, 16""  %10701 = add nuw nsw i32 %10699, %10700" -> "  %10720 = and i32 %10701, 65535"
"  %10702 = mul nuw i32 %9290, 42779"
"  %10702 = mul nuw i32 %9290, 42779" -> "  %10721 = and i32 %10702, 65535""  %10702 = mul nuw i32 %9290, 42779" -> "  %10703 = lshr i32 %10702, 16"
"  %10703 = lshr i32 %10702, 16"
"  %10703 = lshr i32 %10702, 16" -> "  %10706 = add nuw nsw i32 %10705, %10703"
"  %10704 = mul nuw i32 %9293, 42779"
"  %10704 = mul nuw i32 %9293, 42779" -> "  %10707 = and i32 %10704, -65536""  %10704 = mul nuw i32 %9293, 42779" -> "  %10705 = and i32 %10704, 65535"
"  %10705 = and i32 %10704, 65535"
"  %10705 = and i32 %10704, 65535" -> "  %10706 = add nuw nsw i32 %10705, %10703"
"  %10706 = add nuw nsw i32 %10705, %10703"
"  %10706 = add nuw nsw i32 %10705, %10703" -> "  %10708 = add nuw i32 %10706, %10707"
"  %10707 = and i32 %10704, -65536"
"  %10707 = and i32 %10704, -65536" -> "  %10708 = add nuw i32 %10706, %10707"
"  %10708 = add nuw i32 %10706, %10707"
"  %10708 = add nuw i32 %10706, %10707" -> "  %10712 = lshr i32 %10708, 16""  %10708 = add nuw i32 %10706, %10707" -> "  %10710 = and i32 %10708, 65535"
"  %10709 = mul nuw nsw i32 %9290, 9871"
"  %10709 = mul nuw nsw i32 %9290, 9871" -> "  %10711 = add nuw nsw i32 %10710, %10709"
"  %10710 = and i32 %10708, 65535"
"  %10710 = and i32 %10708, 65535" -> "  %10711 = add nuw nsw i32 %10710, %10709"
"  %10711 = add nuw nsw i32 %10710, %10709"
"  %10711 = add nuw nsw i32 %10710, %10709" -> "  %10723 = and i32 %10711, 65535""  %10711 = add nuw nsw i32 %10710, %10709" -> "  %10715 = lshr i32 %10711, 16"
"  %10712 = lshr i32 %10708, 16"
"  %10712 = lshr i32 %10708, 16" -> "  %10714 = add nuw nsw i32 %10712, %10713"
"  %10713 = mul nuw nsw i32 %9293, 9871"
"  %10713 = mul nuw nsw i32 %9293, 9871" -> "  %10714 = add nuw nsw i32 %10712, %10713"
"  %10714 = add nuw nsw i32 %10712, %10713"
"  %10714 = add nuw nsw i32 %10712, %10713" -> "  %10718 = and i32 %10714, 2147418112""  %10714 = add nuw nsw i32 %10712, %10713" -> "  %10716 = and i32 %10714, 65535"
"  %10715 = lshr i32 %10711, 16"
"  %10715 = lshr i32 %10711, 16" -> "  %10717 = add nuw nsw i32 %10715, %10716"
"  %10716 = and i32 %10714, 65535"
"  %10716 = and i32 %10714, 65535" -> "  %10717 = add nuw nsw i32 %10715, %10716"
"  %10717 = add nuw nsw i32 %10715, %10716"
"  %10717 = add nuw nsw i32 %10715, %10716" -> "  %10719 = add nuw nsw i32 %10717, %10718"
"  %10718 = and i32 %10714, 2147418112"
"  %10718 = and i32 %10714, 2147418112" -> "  %10719 = add nuw nsw i32 %10717, %10718"
"  %10719 = add nuw nsw i32 %10717, %10718"
"  %10719 = add nuw nsw i32 %10717, %10718" -> "  %10727 = add nuw nsw i32 %10719, %10726"
"  %10720 = and i32 %10701, 65535"
"  %10720 = and i32 %10701, 65535" -> "  %10722 = add nuw nsw i32 %10720, %10721"
"  %10721 = and i32 %10702, 65535"
"  %10721 = and i32 %10702, 65535" -> "  %10722 = add nuw nsw i32 %10720, %10721"
"  %10722 = add nuw nsw i32 %10720, %10721"
"  %10722 = add nuw nsw i32 %10720, %10721" -> "  %10751 = and i32 %10722, 65535""  %10722 = add nuw nsw i32 %10720, %10721" -> "  %10729 = lshr i32 %10722, 16"
"  %10723 = and i32 %10711, 65535"
"  %10723 = and i32 %10711, 65535" -> "  %10725 = add nuw nsw i32 %10723, %10724"
"  %10724 = lshr i32 %10701, 16"
"  %10724 = lshr i32 %10701, 16" -> "  %10725 = add nuw nsw i32 %10723, %10724"
"  %10725 = add nuw nsw i32 %10723, %10724"
"  %10725 = add nuw nsw i32 %10723, %10724" -> "  %10728 = and i32 %10725, 65535""  %10725 = add nuw nsw i32 %10723, %10724" -> "  %10726 = lshr i32 %10725, 16"
"  %10726 = lshr i32 %10725, 16"
"  %10726 = lshr i32 %10725, 16" -> "  %10727 = add nuw nsw i32 %10719, %10726"
"  %10727 = add nuw nsw i32 %10719, %10726"
"  %10727 = add nuw nsw i32 %10719, %10726" -> "  %10732 = add nuw nsw i32 %10727, %10731"
"  %10728 = and i32 %10725, 65535"
"  %10728 = and i32 %10725, 65535" -> "  %10730 = add nuw nsw i32 %10728, %10729"
"  %10729 = lshr i32 %10722, 16"
"  %10729 = lshr i32 %10722, 16" -> "  %10730 = add nuw nsw i32 %10728, %10729"
"  %10730 = add nuw nsw i32 %10728, %10729"
"  %10730 = add nuw nsw i32 %10728, %10729" -> "  %10755 = and i32 %10730, 65535""  %10730 = add nuw nsw i32 %10728, %10729" -> "  %10731 = lshr i32 %10730, 16"
"  %10731 = lshr i32 %10730, 16"
"  %10731 = lshr i32 %10730, 16" -> "  %10732 = add nuw nsw i32 %10727, %10731"
"  %10732 = add nuw nsw i32 %10727, %10731"
"  %10732 = add nuw nsw i32 %10727, %10731" -> "  %10782 = and i32 %10732, 65535""  %10732 = add nuw nsw i32 %10727, %10731" -> "  %10786 = lshr i32 %10732, 16"
"  %10733 = mul nuw nsw i32 %9270, 24315"
"  %10733 = mul nuw nsw i32 %9270, 24315" -> "  %10734 = lshr i32 %10733, 16""  %10733 = mul nuw nsw i32 %9270, 24315" -> "  %10752 = and i32 %10733, 65535"
"  %10734 = lshr i32 %10733, 16"
"  %10734 = lshr i32 %10733, 16" -> "  %10737 = add nuw nsw i32 %10736, %10734"
"  %10735 = mul nuw nsw i32 %9273, 24315"
"  %10735 = mul nuw nsw i32 %9273, 24315" -> "  %10738 = and i32 %10735, 2147418112""  %10735 = mul nuw nsw i32 %9273, 24315" -> "  %10736 = and i32 %10735, 65535"
"  %10736 = and i32 %10735, 65535"
"  %10736 = and i32 %10735, 65535" -> "  %10737 = add nuw nsw i32 %10736, %10734"
"  %10737 = add nuw nsw i32 %10736, %10734"
"  %10737 = add nuw nsw i32 %10736, %10734" -> "  %10739 = add nuw nsw i32 %10737, %10738"
"  %10738 = and i32 %10735, 2147418112"
"  %10738 = and i32 %10735, 2147418112" -> "  %10739 = add nuw nsw i32 %10737, %10738"
"  %10739 = add nuw nsw i32 %10737, %10738"
"  %10739 = add nuw nsw i32 %10737, %10738" -> "  %10743 = lshr i32 %10739, 16""  %10739 = add nuw nsw i32 %10737, %10738" -> "  %10741 = and i32 %10739, 65535"
"  %10740 = mul nuw nsw i32 %9270, 29744"
"  %10740 = mul nuw nsw i32 %9270, 29744" -> "  %10742 = add nuw nsw i32 %10741, %10740"
"  %10741 = and i32 %10739, 65535"
"  %10741 = and i32 %10739, 65535" -> "  %10742 = add nuw nsw i32 %10741, %10740"
"  %10742 = add nuw nsw i32 %10741, %10740"
"  %10742 = add nuw nsw i32 %10741, %10740" -> "  %10754 = and i32 %10742, 65535""  %10742 = add nuw nsw i32 %10741, %10740" -> "  %10746 = lshr i32 %10742, 16"
"  %10743 = lshr i32 %10739, 16"
"  %10743 = lshr i32 %10739, 16" -> "  %10745 = add nuw nsw i32 %10743, %10744"
"  %10744 = mul nuw nsw i32 %9273, 29744"
"  %10744 = mul nuw nsw i32 %9273, 29744" -> "  %10745 = add nuw nsw i32 %10743, %10744"
"  %10745 = add nuw nsw i32 %10743, %10744"
"  %10745 = add nuw nsw i32 %10743, %10744" -> "  %10749 = and i32 %10745, 2147418112""  %10745 = add nuw nsw i32 %10743, %10744" -> "  %10747 = and i32 %10745, 65535"
"  %10746 = lshr i32 %10742, 16"
"  %10746 = lshr i32 %10742, 16" -> "  %10748 = add nuw nsw i32 %10746, %10747"
"  %10747 = and i32 %10745, 65535"
"  %10747 = and i32 %10745, 65535" -> "  %10748 = add nuw nsw i32 %10746, %10747"
"  %10748 = add nuw nsw i32 %10746, %10747"
"  %10748 = add nuw nsw i32 %10746, %10747" -> "  %10750 = add nuw nsw i32 %10748, %10749"
"  %10749 = and i32 %10745, 2147418112"
"  %10749 = and i32 %10745, 2147418112" -> "  %10750 = add nuw nsw i32 %10748, %10749"
"  %10750 = add nuw nsw i32 %10748, %10749"
"  %10750 = add nuw nsw i32 %10748, %10749" -> "  %10758 = add nuw nsw i32 %10750, %10757"
"  %10751 = and i32 %10722, 65535"
"  %10751 = and i32 %10722, 65535" -> "  %10753 = add nuw nsw i32 %10751, %10752"
"  %10752 = and i32 %10733, 65535"
"  %10752 = and i32 %10733, 65535" -> "  %10753 = add nuw nsw i32 %10751, %10752"
"  %10753 = add nuw nsw i32 %10751, %10752"
"  %10753 = add nuw nsw i32 %10751, %10752" -> "  %10822 = and i32 %10753, 65535""  %10753 = add nuw nsw i32 %10751, %10752" -> "  %10760 = lshr i32 %10753, 16"
"  %10754 = and i32 %10742, 65535"
"  %10754 = and i32 %10742, 65535" -> "  %10756 = add nuw nsw i32 %10755, %10754"
"  %10755 = and i32 %10730, 65535"
"  %10755 = and i32 %10730, 65535" -> "  %10756 = add nuw nsw i32 %10755, %10754"
"  %10756 = add nuw nsw i32 %10755, %10754"
"  %10756 = add nuw nsw i32 %10755, %10754" -> "  %10759 = and i32 %10756, 65535""  %10756 = add nuw nsw i32 %10755, %10754" -> "  %10757 = lshr i32 %10756, 16"
"  %10757 = lshr i32 %10756, 16"
"  %10757 = lshr i32 %10756, 16" -> "  %10758 = add nuw nsw i32 %10750, %10757"
"  %10758 = add nuw nsw i32 %10750, %10757"
"  %10758 = add nuw nsw i32 %10750, %10757" -> "  %10763 = add nuw nsw i32 %10758, %10762"
"  %10759 = and i32 %10756, 65535"
"  %10759 = and i32 %10756, 65535" -> "  %10761 = add nuw nsw i32 %10759, %10760"
"  %10760 = lshr i32 %10753, 16"
"  %10760 = lshr i32 %10753, 16" -> "  %10761 = add nuw nsw i32 %10759, %10760"
"  %10761 = add nuw nsw i32 %10759, %10760"
"  %10761 = add nuw nsw i32 %10759, %10760" -> "  %10825 = and i32 %10761, 65535""  %10761 = add nuw nsw i32 %10759, %10760" -> "  %10762 = lshr i32 %10761, 16"
"  %10762 = lshr i32 %10761, 16"
"  %10762 = lshr i32 %10761, 16" -> "  %10763 = add nuw nsw i32 %10758, %10762"
"  %10763 = add nuw nsw i32 %10758, %10762"
"  %10763 = add nuw nsw i32 %10758, %10762" -> "  %10799 = lshr i32 %10763, 16""  %10763 = add nuw nsw i32 %10758, %10762" -> "  %10796 = and i32 %10763, 65535"
"  %10764 = mul nuw nsw i32 %9290, 24315"
"  %10764 = mul nuw nsw i32 %9290, 24315" -> "  %10783 = and i32 %10764, 65535""  %10764 = mul nuw nsw i32 %9290, 24315" -> "  %10765 = lshr i32 %10764, 16"
"  %10765 = lshr i32 %10764, 16"
"  %10765 = lshr i32 %10764, 16" -> "  %10768 = add nuw nsw i32 %10767, %10765"
"  %10766 = mul nuw nsw i32 %9293, 24315"
"  %10766 = mul nuw nsw i32 %9293, 24315" -> "  %10769 = and i32 %10766, 2147418112""  %10766 = mul nuw nsw i32 %9293, 24315" -> "  %10767 = and i32 %10766, 65535"
"  %10767 = and i32 %10766, 65535"
"  %10767 = and i32 %10766, 65535" -> "  %10768 = add nuw nsw i32 %10767, %10765"
"  %10768 = add nuw nsw i32 %10767, %10765"
"  %10768 = add nuw nsw i32 %10767, %10765" -> "  %10770 = add nuw nsw i32 %10768, %10769"
"  %10769 = and i32 %10766, 2147418112"
"  %10769 = and i32 %10766, 2147418112" -> "  %10770 = add nuw nsw i32 %10768, %10769"
"  %10770 = add nuw nsw i32 %10768, %10769"
"  %10770 = add nuw nsw i32 %10768, %10769" -> "  %10774 = lshr i32 %10770, 16""  %10770 = add nuw nsw i32 %10768, %10769" -> "  %10772 = and i32 %10770, 65535"
"  %10771 = mul nuw nsw i32 %9290, 29744"
"  %10771 = mul nuw nsw i32 %9290, 29744" -> "  %10773 = add nuw nsw i32 %10772, %10771"
"  %10772 = and i32 %10770, 65535"
"  %10772 = and i32 %10770, 65535" -> "  %10773 = add nuw nsw i32 %10772, %10771"
"  %10773 = add nuw nsw i32 %10772, %10771"
"  %10773 = add nuw nsw i32 %10772, %10771" -> "  %10785 = and i32 %10773, 65535""  %10773 = add nuw nsw i32 %10772, %10771" -> "  %10777 = lshr i32 %10773, 16"
"  %10774 = lshr i32 %10770, 16"
"  %10774 = lshr i32 %10770, 16" -> "  %10776 = add nuw nsw i32 %10774, %10775"
"  %10775 = mul nuw nsw i32 %9293, 29744"
"  %10775 = mul nuw nsw i32 %9293, 29744" -> "  %10776 = add nuw nsw i32 %10774, %10775"
"  %10776 = add nuw nsw i32 %10774, %10775"
"  %10776 = add nuw nsw i32 %10774, %10775" -> "  %10780 = and i32 %10776, 2147418112""  %10776 = add nuw nsw i32 %10774, %10775" -> "  %10778 = and i32 %10776, 65535"
"  %10777 = lshr i32 %10773, 16"
"  %10777 = lshr i32 %10773, 16" -> "  %10779 = add nuw nsw i32 %10777, %10778"
"  %10778 = and i32 %10776, 65535"
"  %10778 = and i32 %10776, 65535" -> "  %10779 = add nuw nsw i32 %10777, %10778"
"  %10779 = add nuw nsw i32 %10777, %10778"
"  %10779 = add nuw nsw i32 %10777, %10778" -> "  %10781 = add nuw nsw i32 %10779, %10780"
"  %10780 = and i32 %10776, 2147418112"
"  %10780 = and i32 %10776, 2147418112" -> "  %10781 = add nuw nsw i32 %10779, %10780"
"  %10781 = add nuw nsw i32 %10779, %10780"
"  %10781 = add nuw nsw i32 %10779, %10780" -> "  %10789 = add nuw nsw i32 %10781, %10788"
"  %10782 = and i32 %10732, 65535"
"  %10782 = and i32 %10732, 65535" -> "  %10784 = add nuw nsw i32 %10782, %10783"
"  %10783 = and i32 %10764, 65535"
"  %10783 = and i32 %10764, 65535" -> "  %10784 = add nuw nsw i32 %10782, %10783"
"  %10784 = add nuw nsw i32 %10782, %10783"
"  %10784 = add nuw nsw i32 %10782, %10783" -> "  %10795 = and i32 %10784, 65535""  %10784 = add nuw nsw i32 %10782, %10783" -> "  %10791 = lshr i32 %10784, 16"
"  %10785 = and i32 %10773, 65535"
"  %10785 = and i32 %10773, 65535" -> "  %10787 = add nuw nsw i32 %10786, %10785"
"  %10786 = lshr i32 %10732, 16"
"  %10786 = lshr i32 %10732, 16" -> "  %10787 = add nuw nsw i32 %10786, %10785"
"  %10787 = add nuw nsw i32 %10786, %10785"
"  %10787 = add nuw nsw i32 %10786, %10785" -> "  %10790 = and i32 %10787, 65535""  %10787 = add nuw nsw i32 %10786, %10785" -> "  %10788 = lshr i32 %10787, 16"
"  %10788 = lshr i32 %10787, 16"
"  %10788 = lshr i32 %10787, 16" -> "  %10789 = add nuw nsw i32 %10781, %10788"
"  %10789 = add nuw nsw i32 %10781, %10788"
"  %10789 = add nuw nsw i32 %10781, %10788" -> "  %10794 = add nuw nsw i32 %10789, %10793"
"  %10790 = and i32 %10787, 65535"
"  %10790 = and i32 %10787, 65535" -> "  %10792 = add nuw nsw i32 %10790, %10791"
"  %10791 = lshr i32 %10784, 16"
"  %10791 = lshr i32 %10784, 16" -> "  %10792 = add nuw nsw i32 %10790, %10791"
"  %10792 = add nuw nsw i32 %10790, %10791"
"  %10792 = add nuw nsw i32 %10790, %10791" -> "  %10798 = and i32 %10792, 65535""  %10792 = add nuw nsw i32 %10790, %10791" -> "  %10793 = lshr i32 %10792, 16"
"  %10793 = lshr i32 %10792, 16"
"  %10793 = lshr i32 %10792, 16" -> "  %10794 = add nuw nsw i32 %10789, %10793"
"  %10794 = add nuw nsw i32 %10789, %10793"
"  %10794 = add nuw nsw i32 %10789, %10793" -> "  %10807 = and i32 %10794, 2147418112""  %10794 = add nuw nsw i32 %10789, %10793" -> "  %10805 = and i32 %10794, 65535"
"  %10795 = and i32 %10784, 65535"
"  %10795 = and i32 %10784, 65535" -> "  %10797 = add nuw nsw i32 %10796, %10795"
"  %10796 = and i32 %10763, 65535"
"  %10796 = and i32 %10763, 65535" -> "  %10797 = add nuw nsw i32 %10796, %10795"
"  %10797 = add nuw nsw i32 %10796, %10795"
"  %10797 = add nuw nsw i32 %10796, %10795" -> "  %10837 = and i32 %10797, 65535""  %10797 = add nuw nsw i32 %10796, %10795" -> "  %10801 = lshr i32 %10797, 16"
"  %10798 = and i32 %10792, 65535"
"  %10798 = and i32 %10792, 65535" -> "  %10800 = add nuw nsw i32 %10798, %10799"
"  %10799 = lshr i32 %10763, 16"
"  %10799 = lshr i32 %10763, 16" -> "  %10800 = add nuw nsw i32 %10798, %10799"
"  %10800 = add nuw nsw i32 %10798, %10799"
"  %10800 = add nuw nsw i32 %10798, %10799" -> "  %10804 = lshr i32 %10800, 16""  %10800 = add nuw nsw i32 %10798, %10799" -> "  %10802 = and i32 %10800, 65535"
"  %10801 = lshr i32 %10797, 16"
"  %10801 = lshr i32 %10797, 16" -> "  %10803 = add nuw nsw i32 %10802, %10801"
"  %10802 = and i32 %10800, 65535"
"  %10802 = and i32 %10800, 65535" -> "  %10803 = add nuw nsw i32 %10802, %10801"
"  %10803 = add nuw nsw i32 %10802, %10801"
"  %10803 = add nuw nsw i32 %10802, %10801" -> "  %10844 = and i32 %10803, 65535""  %10803 = add nuw nsw i32 %10802, %10801" -> "  %10809 = lshr i32 %10803, 16"
"  %10804 = lshr i32 %10800, 16"
"  %10804 = lshr i32 %10800, 16" -> "  %10806 = add nuw nsw i32 %10804, %10805"
"  %10805 = and i32 %10794, 65535"
"  %10805 = and i32 %10794, 65535" -> "  %10806 = add nuw nsw i32 %10804, %10805"
"  %10806 = add nuw nsw i32 %10804, %10805"
"  %10806 = add nuw nsw i32 %10804, %10805" -> "  %10808 = add nuw nsw i32 %10806, %10807"
"  %10807 = and i32 %10794, 2147418112"
"  %10807 = and i32 %10794, 2147418112" -> "  %10808 = add nuw nsw i32 %10806, %10807"
"  %10808 = add nuw nsw i32 %10806, %10807"
"  %10808 = add nuw nsw i32 %10806, %10807" -> "  %10810 = add nuw nsw i32 %10808, %10809"
"  %10809 = lshr i32 %10803, 16"
"  %10809 = lshr i32 %10803, 16" -> "  %10810 = add nuw nsw i32 %10808, %10809"
"  %10810 = add nuw nsw i32 %10808, %10809"
"  %10810 = add nuw nsw i32 %10808, %10809" -> "  %10848 = add nuw nsw i32 %10810, %10847"
"  %10811 = and i32 %10684, 65535"
"  %10811 = and i32 %10684, 65535" -> "  %10813 = add nuw nsw i32 %10812, %10811"
"  %10812 = and i32 %10673, 65535"
"  %10812 = and i32 %10673, 65535" -> "  %10813 = add nuw nsw i32 %10812, %10811"
"  %10813 = add nuw nsw i32 %10812, %10811"
"  %10813 = add nuw nsw i32 %10812, %10811" -> "  %10977 = and i32 %10813, 65535""  %10813 = add nuw nsw i32 %10812, %10811" -> "  %10817 = lshr i32 %10813, 16"
"  %10814 = and i32 %10693, 65535"
"  %10814 = and i32 %10693, 65535" -> "  %10816 = add nuw nsw i32 %10814, %10815"
"  %10815 = and i32 %10679, 65535"
"  %10815 = and i32 %10679, 65535" -> "  %10816 = add nuw nsw i32 %10814, %10815"
"  %10816 = add nuw nsw i32 %10814, %10815"
"  %10816 = add nuw nsw i32 %10814, %10815" -> "  %10820 = lshr i32 %10816, 16""  %10816 = add nuw nsw i32 %10814, %10815" -> "  %10818 = and i32 %10816, 65535"
"  %10817 = lshr i32 %10813, 16"
"  %10817 = lshr i32 %10813, 16" -> "  %10819 = add nuw nsw i32 %10818, %10817"
"  %10818 = and i32 %10816, 65535"
"  %10818 = and i32 %10816, 65535" -> "  %10819 = add nuw nsw i32 %10818, %10817"
"  %10819 = add nuw nsw i32 %10818, %10817"
"  %10819 = add nuw nsw i32 %10818, %10817" -> "  %10980 = and i32 %10819, 65535""  %10819 = add nuw nsw i32 %10818, %10817" -> "  %10821 = lshr i32 %10819, 16"
"  %10820 = lshr i32 %10816, 16"
"  %10820 = lshr i32 %10816, 16" -> "  %10832 = add nuw nsw i32 %10821, %10820"
"  %10821 = lshr i32 %10819, 16"
"  %10821 = lshr i32 %10819, 16" -> "  %10832 = add nuw nsw i32 %10821, %10820"
"  %10822 = and i32 %10753, 65535"
"  %10822 = and i32 %10753, 65535" -> "  %10824 = add nuw nsw i32 %10822, %10823"
"  %10823 = and i32 %10683, 65535"
"  %10823 = and i32 %10683, 65535" -> "  %10824 = add nuw nsw i32 %10822, %10823"
"  %10824 = add nuw nsw i32 %10822, %10823"
"  %10824 = add nuw nsw i32 %10822, %10823" -> "  %10831 = and i32 %10824, 65535""  %10824 = add nuw nsw i32 %10822, %10823" -> "  %10828 = lshr i32 %10824, 16"
"  %10825 = and i32 %10761, 65535"
"  %10825 = and i32 %10761, 65535" -> "  %10827 = add nuw nsw i32 %10825, %10826"
"  %10826 = lshr i32 %10683, 16"
"  %10826 = lshr i32 %10683, 16" -> "  %10827 = add nuw nsw i32 %10825, %10826"
"  %10827 = add nuw nsw i32 %10825, %10826"
"  %10827 = add nuw nsw i32 %10825, %10826" -> "  %10838 = lshr i32 %10827, 16""  %10827 = add nuw nsw i32 %10825, %10826" -> "  %10829 = and i32 %10827, 65535"
"  %10828 = lshr i32 %10824, 16"
"  %10828 = lshr i32 %10824, 16" -> "  %10830 = add nuw nsw i32 %10829, %10828"
"  %10829 = and i32 %10827, 65535"
"  %10829 = and i32 %10827, 65535" -> "  %10830 = add nuw nsw i32 %10829, %10828"
"  %10830 = add nuw nsw i32 %10829, %10828"
"  %10830 = add nuw nsw i32 %10829, %10828" -> "  %10840 = lshr i32 %10830, 16""  %10830 = add nuw nsw i32 %10829, %10828" -> "  %10835 = and i32 %10830, 65535"
"  %10831 = and i32 %10824, 65535"
"  %10831 = and i32 %10824, 65535" -> "  %10833 = add nuw nsw i32 %10832, %10831"
"  %10832 = add nuw nsw i32 %10821, %10820"
"  %10832 = add nuw nsw i32 %10821, %10820" -> "  %10833 = add nuw nsw i32 %10832, %10831"
"  %10833 = add nuw nsw i32 %10832, %10831"
"  %10833 = add nuw nsw i32 %10832, %10831" -> "  %10988 = and i32 %10833, 65535""  %10833 = add nuw nsw i32 %10832, %10831" -> "  %10834 = lshr i32 %10833, 16"
"  %10834 = lshr i32 %10833, 16"
"  %10834 = lshr i32 %10833, 16" -> "  %10836 = add nuw nsw i32 %10835, %10834"
"  %10835 = and i32 %10830, 65535"
"  %10835 = and i32 %10830, 65535" -> "  %10836 = add nuw nsw i32 %10835, %10834"
"  %10836 = add nuw nsw i32 %10835, %10834"
"  %10836 = add nuw nsw i32 %10835, %10834" -> "  %10991 = and i32 %10836, 65535""  %10836 = add nuw nsw i32 %10835, %10834" -> "  %10842 = lshr i32 %10836, 16"
"  %10837 = and i32 %10797, 65535"
"  %10837 = and i32 %10797, 65535" -> "  %10839 = add nuw nsw i32 %10837, %10838"
"  %10838 = lshr i32 %10827, 16"
"  %10838 = lshr i32 %10827, 16" -> "  %10839 = add nuw nsw i32 %10837, %10838"
"  %10839 = add nuw nsw i32 %10837, %10838"
"  %10839 = add nuw nsw i32 %10837, %10838" -> "  %10841 = add nuw nsw i32 %10839, %10840"
"  %10840 = lshr i32 %10830, 16"
"  %10840 = lshr i32 %10830, 16" -> "  %10841 = add nuw nsw i32 %10839, %10840"
"  %10841 = add nuw nsw i32 %10839, %10840"
"  %10841 = add nuw nsw i32 %10839, %10840" -> "  %10843 = add nuw nsw i32 %10841, %10842"
"  %10842 = lshr i32 %10836, 16"
"  %10842 = lshr i32 %10836, 16" -> "  %10843 = add nuw nsw i32 %10841, %10842"
"  %10843 = add nuw nsw i32 %10841, %10842"
"  %10843 = add nuw nsw i32 %10841, %10842" -> "  %11142 = and i32 %10843, 65535""  %10843 = add nuw nsw i32 %10841, %10842" -> "  %10845 = lshr i32 %10843, 16"
"  %10844 = and i32 %10803, 65535"
"  %10844 = and i32 %10803, 65535" -> "  %10846 = add nuw nsw i32 %10845, %10844"
"  %10845 = lshr i32 %10843, 16"
"  %10845 = lshr i32 %10843, 16" -> "  %10846 = add nuw nsw i32 %10845, %10844"
"  %10846 = add nuw nsw i32 %10845, %10844"
"  %10846 = add nuw nsw i32 %10845, %10844" -> "  %11145 = and i32 %10846, 65535""  %10846 = add nuw nsw i32 %10845, %10844" -> "  %10847 = lshr i32 %10846, 16"
"  %10847 = lshr i32 %10846, 16"
"  %10847 = lshr i32 %10846, 16" -> "  %10848 = add nuw nsw i32 %10810, %10847"
"  %10848 = add nuw nsw i32 %10810, %10847"
"  %10848 = add nuw nsw i32 %10810, %10847" -> "  %11151 = and i32 %10848, 65535""  %10848 = add nuw nsw i32 %10810, %10847" -> "  %11154 = lshr i32 %10848, 16"
"  %10849 = mul nuw nsw i32 %9136, 4087"
"  %10849 = mul nuw nsw i32 %9136, 4087" -> "  %10976 = and i32 %10849, 65535""  %10849 = mul nuw nsw i32 %9136, 4087" -> "  %10850 = lshr i32 %10849, 16"
"  %10850 = lshr i32 %10849, 16"
"  %10850 = lshr i32 %10849, 16" -> "  %10853 = add nuw nsw i32 %10852, %10850"
"  %10851 = mul nuw nsw i32 %9137, 4087"
"  %10851 = mul nuw nsw i32 %9137, 4087" -> "  %10854 = and i32 %10851, 268369920""  %10851 = mul nuw nsw i32 %9137, 4087" -> "  %10852 = and i32 %10851, 65535"
"  %10852 = and i32 %10851, 65535"
"  %10852 = and i32 %10851, 65535" -> "  %10853 = add nuw nsw i32 %10852, %10850"
"  %10853 = add nuw nsw i32 %10852, %10850"
"  %10853 = add nuw nsw i32 %10852, %10850" -> "  %10855 = add nuw nsw i32 %10853, %10854"
"  %10854 = and i32 %10851, 268369920"
"  %10854 = and i32 %10851, 268369920" -> "  %10855 = add nuw nsw i32 %10853, %10854"
"  %10855 = add nuw nsw i32 %10853, %10854"
"  %10855 = add nuw nsw i32 %10853, %10854" -> "  %10859 = lshr i32 %10855, 16""  %10855 = add nuw nsw i32 %10853, %10854" -> "  %10857 = and i32 %10855, 65535"
"  %10856 = mul nuw nsw i32 %9136, 11561"
"  %10856 = mul nuw nsw i32 %9136, 11561" -> "  %10858 = add nuw nsw i32 %10857, %10856"
"  %10857 = and i32 %10855, 65535"
"  %10857 = and i32 %10855, 65535" -> "  %10858 = add nuw nsw i32 %10857, %10856"
"  %10858 = add nuw nsw i32 %10857, %10856"
"  %10858 = add nuw nsw i32 %10857, %10856" -> "  %10979 = and i32 %10858, 65535""  %10858 = add nuw nsw i32 %10857, %10856" -> "  %10862 = lshr i32 %10858, 16"
"  %10859 = lshr i32 %10855, 16"
"  %10859 = lshr i32 %10855, 16" -> "  %10861 = add nuw nsw i32 %10859, %10860"
"  %10860 = mul nuw nsw i32 %9137, 11561"
"  %10860 = mul nuw nsw i32 %9137, 11561" -> "  %10861 = add nuw nsw i32 %10859, %10860"
"  %10861 = add nuw nsw i32 %10859, %10860"
"  %10861 = add nuw nsw i32 %10859, %10860" -> "  %10865 = and i32 %10861, 2147418112""  %10861 = add nuw nsw i32 %10859, %10860" -> "  %10863 = and i32 %10861, 65535"
"  %10862 = lshr i32 %10858, 16"
"  %10862 = lshr i32 %10858, 16" -> "  %10864 = add nuw nsw i32 %10862, %10863"
"  %10863 = and i32 %10861, 65535"
"  %10863 = and i32 %10861, 65535" -> "  %10864 = add nuw nsw i32 %10862, %10863"
"  %10864 = add nuw nsw i32 %10862, %10863"
"  %10864 = add nuw nsw i32 %10862, %10863" -> "  %10866 = add nuw nsw i32 %10864, %10865"
"  %10865 = and i32 %10861, 2147418112"
"  %10865 = and i32 %10861, 2147418112" -> "  %10866 = add nuw nsw i32 %10864, %10865"
"  %10866 = add nuw nsw i32 %10864, %10865"
"  %10866 = add nuw nsw i32 %10864, %10865" -> "  %10889 = lshr i32 %10866, 16""  %10866 = add nuw nsw i32 %10864, %10865" -> "  %10885 = and i32 %10866, 65535"
"  %10867 = mul nuw nsw i32 %9156, 4087"
"  %10867 = mul nuw nsw i32 %9156, 4087" -> "  %10886 = and i32 %10867, 65535""  %10867 = mul nuw nsw i32 %9156, 4087" -> "  %10868 = lshr i32 %10867, 16"
"  %10868 = lshr i32 %10867, 16"
"  %10868 = lshr i32 %10867, 16" -> "  %10871 = add nuw nsw i32 %10870, %10868"
"  %10869 = mul nuw nsw i32 %9159, 4087"
"  %10869 = mul nuw nsw i32 %9159, 4087" -> "  %10872 = and i32 %10869, 268369920""  %10869 = mul nuw nsw i32 %9159, 4087" -> "  %10870 = and i32 %10869, 65535"
"  %10870 = and i32 %10869, 65535"
"  %10870 = and i32 %10869, 65535" -> "  %10871 = add nuw nsw i32 %10870, %10868"
"  %10871 = add nuw nsw i32 %10870, %10868"
"  %10871 = add nuw nsw i32 %10870, %10868" -> "  %10873 = add nuw nsw i32 %10871, %10872"
"  %10872 = and i32 %10869, 268369920"
"  %10872 = and i32 %10869, 268369920" -> "  %10873 = add nuw nsw i32 %10871, %10872"
"  %10873 = add nuw nsw i32 %10871, %10872"
"  %10873 = add nuw nsw i32 %10871, %10872" -> "  %10877 = lshr i32 %10873, 16""  %10873 = add nuw nsw i32 %10871, %10872" -> "  %10875 = and i32 %10873, 65535"
"  %10874 = mul nuw nsw i32 %9156, 11561"
"  %10874 = mul nuw nsw i32 %9156, 11561" -> "  %10876 = add nuw nsw i32 %10875, %10874"
"  %10875 = and i32 %10873, 65535"
"  %10875 = and i32 %10873, 65535" -> "  %10876 = add nuw nsw i32 %10875, %10874"
"  %10876 = add nuw nsw i32 %10875, %10874"
"  %10876 = add nuw nsw i32 %10875, %10874" -> "  %10888 = and i32 %10876, 65535""  %10876 = add nuw nsw i32 %10875, %10874" -> "  %10880 = lshr i32 %10876, 16"
"  %10877 = lshr i32 %10873, 16"
"  %10877 = lshr i32 %10873, 16" -> "  %10879 = add nuw nsw i32 %10877, %10878"
"  %10878 = mul nuw nsw i32 %9159, 11561"
"  %10878 = mul nuw nsw i32 %9159, 11561" -> "  %10879 = add nuw nsw i32 %10877, %10878"
"  %10879 = add nuw nsw i32 %10877, %10878"
"  %10879 = add nuw nsw i32 %10877, %10878" -> "  %10883 = and i32 %10879, 2147418112""  %10879 = add nuw nsw i32 %10877, %10878" -> "  %10881 = and i32 %10879, 65535"
"  %10880 = lshr i32 %10876, 16"
"  %10880 = lshr i32 %10876, 16" -> "  %10882 = add nuw nsw i32 %10880, %10881"
"  %10881 = and i32 %10879, 65535"
"  %10881 = and i32 %10879, 65535" -> "  %10882 = add nuw nsw i32 %10880, %10881"
"  %10882 = add nuw nsw i32 %10880, %10881"
"  %10882 = add nuw nsw i32 %10880, %10881" -> "  %10884 = add nuw nsw i32 %10882, %10883"
"  %10883 = and i32 %10879, 2147418112"
"  %10883 = and i32 %10879, 2147418112" -> "  %10884 = add nuw nsw i32 %10882, %10883"
"  %10884 = add nuw nsw i32 %10882, %10883"
"  %10884 = add nuw nsw i32 %10882, %10883" -> "  %10892 = add nuw nsw i32 %10884, %10891"
"  %10885 = and i32 %10866, 65535"
"  %10885 = and i32 %10866, 65535" -> "  %10887 = add nuw nsw i32 %10885, %10886"
"  %10886 = and i32 %10867, 65535"
"  %10886 = and i32 %10867, 65535" -> "  %10887 = add nuw nsw i32 %10885, %10886"
"  %10887 = add nuw nsw i32 %10885, %10886"
"  %10887 = add nuw nsw i32 %10885, %10886" -> "  %10916 = and i32 %10887, 65535""  %10887 = add nuw nsw i32 %10885, %10886" -> "  %10894 = lshr i32 %10887, 16"
"  %10888 = and i32 %10876, 65535"
"  %10888 = and i32 %10876, 65535" -> "  %10890 = add nuw nsw i32 %10888, %10889"
"  %10889 = lshr i32 %10866, 16"
"  %10889 = lshr i32 %10866, 16" -> "  %10890 = add nuw nsw i32 %10888, %10889"
"  %10890 = add nuw nsw i32 %10888, %10889"
"  %10890 = add nuw nsw i32 %10888, %10889" -> "  %10893 = and i32 %10890, 65535""  %10890 = add nuw nsw i32 %10888, %10889" -> "  %10891 = lshr i32 %10890, 16"
"  %10891 = lshr i32 %10890, 16"
"  %10891 = lshr i32 %10890, 16" -> "  %10892 = add nuw nsw i32 %10884, %10891"
"  %10892 = add nuw nsw i32 %10884, %10891"
"  %10892 = add nuw nsw i32 %10884, %10891" -> "  %10897 = add nuw nsw i32 %10892, %10896"
"  %10893 = and i32 %10890, 65535"
"  %10893 = and i32 %10890, 65535" -> "  %10895 = add nuw nsw i32 %10893, %10894"
"  %10894 = lshr i32 %10887, 16"
"  %10894 = lshr i32 %10887, 16" -> "  %10895 = add nuw nsw i32 %10893, %10894"
"  %10895 = add nuw nsw i32 %10893, %10894"
"  %10895 = add nuw nsw i32 %10893, %10894" -> "  %10920 = and i32 %10895, 65535""  %10895 = add nuw nsw i32 %10893, %10894" -> "  %10896 = lshr i32 %10895, 16"
"  %10896 = lshr i32 %10895, 16"
"  %10896 = lshr i32 %10895, 16" -> "  %10897 = add nuw nsw i32 %10892, %10896"
"  %10897 = add nuw nsw i32 %10892, %10896"
"  %10897 = add nuw nsw i32 %10892, %10896" -> "  %10947 = and i32 %10897, 65535""  %10897 = add nuw nsw i32 %10892, %10896" -> "  %10951 = lshr i32 %10897, 16"
"  %10898 = mul nuw nsw i32 %9136, 21884"
"  %10898 = mul nuw nsw i32 %9136, 21884" -> "  %10899 = lshr i32 %10898, 16""  %10898 = mul nuw nsw i32 %9136, 21884" -> "  %10917 = and i32 %10898, 65532"
"  %10899 = lshr i32 %10898, 16"
"  %10899 = lshr i32 %10898, 16" -> "  %10902 = add nuw nsw i32 %10901, %10899"
"  %10900 = mul nuw nsw i32 %9137, 21884"
"  %10900 = mul nuw nsw i32 %9137, 21884" -> "  %10903 = and i32 %10900, 2147418112""  %10900 = mul nuw nsw i32 %9137, 21884" -> "  %10901 = and i32 %10900, 65532"
"  %10901 = and i32 %10900, 65532"
"  %10901 = and i32 %10900, 65532" -> "  %10902 = add nuw nsw i32 %10901, %10899"
"  %10902 = add nuw nsw i32 %10901, %10899"
"  %10902 = add nuw nsw i32 %10901, %10899" -> "  %10904 = add nuw nsw i32 %10902, %10903"
"  %10903 = and i32 %10900, 2147418112"
"  %10903 = and i32 %10900, 2147418112" -> "  %10904 = add nuw nsw i32 %10902, %10903"
"  %10904 = add nuw nsw i32 %10902, %10903"
"  %10904 = add nuw nsw i32 %10902, %10903" -> "  %10908 = lshr i32 %10904, 16""  %10904 = add nuw nsw i32 %10902, %10903" -> "  %10906 = and i32 %10904, 65535"
"  %10905 = mul nuw i32 %9136, 36786"
"  %10905 = mul nuw i32 %9136, 36786" -> "  %10907 = add nuw i32 %10906, %10905"
"  %10906 = and i32 %10904, 65535"
"  %10906 = and i32 %10904, 65535" -> "  %10907 = add nuw i32 %10906, %10905"
"  %10907 = add nuw i32 %10906, %10905"
"  %10907 = add nuw i32 %10906, %10905" -> "  %10919 = and i32 %10907, 65535""  %10907 = add nuw i32 %10906, %10905" -> "  %10911 = lshr i32 %10907, 16"
"  %10908 = lshr i32 %10904, 16"
"  %10908 = lshr i32 %10904, 16" -> "  %10910 = add nuw i32 %10908, %10909"
"  %10909 = mul nuw i32 %9137, 36786"
"  %10909 = mul nuw i32 %9137, 36786" -> "  %10910 = add nuw i32 %10908, %10909"
"  %10910 = add nuw i32 %10908, %10909"
"  %10910 = add nuw i32 %10908, %10909" -> "  %10914 = and i32 %10910, -65536""  %10910 = add nuw i32 %10908, %10909" -> "  %10912 = and i32 %10910, 65535"
"  %10911 = lshr i32 %10907, 16"
"  %10911 = lshr i32 %10907, 16" -> "  %10913 = add nuw nsw i32 %10911, %10912"
"  %10912 = and i32 %10910, 65535"
"  %10912 = and i32 %10910, 65535" -> "  %10913 = add nuw nsw i32 %10911, %10912"
"  %10913 = add nuw nsw i32 %10911, %10912"
"  %10913 = add nuw nsw i32 %10911, %10912" -> "  %10915 = add nuw i32 %10913, %10914"
"  %10914 = and i32 %10910, -65536"
"  %10914 = and i32 %10910, -65536" -> "  %10915 = add nuw i32 %10913, %10914"
"  %10915 = add nuw i32 %10913, %10914"
"  %10915 = add nuw i32 %10913, %10914" -> "  %10923 = add nuw i32 %10915, %10922"
"  %10916 = and i32 %10887, 65535"
"  %10916 = and i32 %10887, 65535" -> "  %10918 = add nuw nsw i32 %10916, %10917"
"  %10917 = and i32 %10898, 65532"
"  %10917 = and i32 %10898, 65532" -> "  %10918 = add nuw nsw i32 %10916, %10917"
"  %10918 = add nuw nsw i32 %10916, %10917"
"  %10918 = add nuw nsw i32 %10916, %10917" -> "  %10987 = and i32 %10918, 65535""  %10918 = add nuw nsw i32 %10916, %10917" -> "  %10925 = lshr i32 %10918, 16"
"  %10919 = and i32 %10907, 65535"
"  %10919 = and i32 %10907, 65535" -> "  %10921 = add nuw nsw i32 %10920, %10919"
"  %10920 = and i32 %10895, 65535"
"  %10920 = and i32 %10895, 65535" -> "  %10921 = add nuw nsw i32 %10920, %10919"
"  %10921 = add nuw nsw i32 %10920, %10919"
"  %10921 = add nuw nsw i32 %10920, %10919" -> "  %10924 = and i32 %10921, 65535""  %10921 = add nuw nsw i32 %10920, %10919" -> "  %10922 = lshr i32 %10921, 16"
"  %10922 = lshr i32 %10921, 16"
"  %10922 = lshr i32 %10921, 16" -> "  %10923 = add nuw i32 %10915, %10922"
"  %10923 = add nuw i32 %10915, %10922"
"  %10923 = add nuw i32 %10915, %10922" -> "  %10928 = add nuw i32 %10923, %10927"
"  %10924 = and i32 %10921, 65535"
"  %10924 = and i32 %10921, 65535" -> "  %10926 = add nuw nsw i32 %10924, %10925"
"  %10925 = lshr i32 %10918, 16"
"  %10925 = lshr i32 %10918, 16" -> "  %10926 = add nuw nsw i32 %10924, %10925"
"  %10926 = add nuw nsw i32 %10924, %10925"
"  %10926 = add nuw nsw i32 %10924, %10925" -> "  %10990 = and i32 %10926, 65535""  %10926 = add nuw nsw i32 %10924, %10925" -> "  %10927 = lshr i32 %10926, 16"
"  %10927 = lshr i32 %10926, 16"
"  %10927 = lshr i32 %10926, 16" -> "  %10928 = add nuw i32 %10923, %10927"
"  %10928 = add nuw i32 %10923, %10927"
"  %10928 = add nuw i32 %10923, %10927" -> "  %10964 = lshr i32 %10928, 16""  %10928 = add nuw i32 %10923, %10927" -> "  %10961 = and i32 %10928, 65535"
"  %10929 = mul nuw nsw i32 %9156, 21884"
"  %10929 = mul nuw nsw i32 %9156, 21884" -> "  %10948 = and i32 %10929, 65532""  %10929 = mul nuw nsw i32 %9156, 21884" -> "  %10930 = lshr i32 %10929, 16"
"  %10930 = lshr i32 %10929, 16"
"  %10930 = lshr i32 %10929, 16" -> "  %10933 = add nuw nsw i32 %10932, %10930"
"  %10931 = mul nuw nsw i32 %9159, 21884"
"  %10931 = mul nuw nsw i32 %9159, 21884" -> "  %10934 = and i32 %10931, 2147418112""  %10931 = mul nuw nsw i32 %9159, 21884" -> "  %10932 = and i32 %10931, 65532"
"  %10932 = and i32 %10931, 65532"
"  %10932 = and i32 %10931, 65532" -> "  %10933 = add nuw nsw i32 %10932, %10930"
"  %10933 = add nuw nsw i32 %10932, %10930"
"  %10933 = add nuw nsw i32 %10932, %10930" -> "  %10935 = add nuw nsw i32 %10933, %10934"
"  %10934 = and i32 %10931, 2147418112"
"  %10934 = and i32 %10931, 2147418112" -> "  %10935 = add nuw nsw i32 %10933, %10934"
"  %10935 = add nuw nsw i32 %10933, %10934"
"  %10935 = add nuw nsw i32 %10933, %10934" -> "  %10939 = lshr i32 %10935, 16""  %10935 = add nuw nsw i32 %10933, %10934" -> "  %10937 = and i32 %10935, 65535"
"  %10936 = mul nuw i32 %9156, 36786"
"  %10936 = mul nuw i32 %9156, 36786" -> "  %10938 = add nuw i32 %10937, %10936"
"  %10937 = and i32 %10935, 65535"
"  %10937 = and i32 %10935, 65535" -> "  %10938 = add nuw i32 %10937, %10936"
"  %10938 = add nuw i32 %10937, %10936"
"  %10938 = add nuw i32 %10937, %10936" -> "  %10950 = and i32 %10938, 65535""  %10938 = add nuw i32 %10937, %10936" -> "  %10942 = lshr i32 %10938, 16"
"  %10939 = lshr i32 %10935, 16"
"  %10939 = lshr i32 %10935, 16" -> "  %10941 = add nuw i32 %10939, %10940"
"  %10940 = mul nuw i32 %9159, 36786"
"  %10940 = mul nuw i32 %9159, 36786" -> "  %10941 = add nuw i32 %10939, %10940"
"  %10941 = add nuw i32 %10939, %10940"
"  %10941 = add nuw i32 %10939, %10940" -> "  %10945 = and i32 %10941, -65536""  %10941 = add nuw i32 %10939, %10940" -> "  %10943 = and i32 %10941, 65535"
"  %10942 = lshr i32 %10938, 16"
"  %10942 = lshr i32 %10938, 16" -> "  %10944 = add nuw nsw i32 %10942, %10943"
"  %10943 = and i32 %10941, 65535"
"  %10943 = and i32 %10941, 65535" -> "  %10944 = add nuw nsw i32 %10942, %10943"
"  %10944 = add nuw nsw i32 %10942, %10943"
"  %10944 = add nuw nsw i32 %10942, %10943" -> "  %10946 = add nuw i32 %10944, %10945"
"  %10945 = and i32 %10941, -65536"
"  %10945 = and i32 %10941, -65536" -> "  %10946 = add nuw i32 %10944, %10945"
"  %10946 = add nuw i32 %10944, %10945"
"  %10946 = add nuw i32 %10944, %10945" -> "  %10954 = add nuw i32 %10946, %10953"
"  %10947 = and i32 %10897, 65535"
"  %10947 = and i32 %10897, 65535" -> "  %10949 = add nuw nsw i32 %10947, %10948"
"  %10948 = and i32 %10929, 65532"
"  %10948 = and i32 %10929, 65532" -> "  %10949 = add nuw nsw i32 %10947, %10948"
"  %10949 = add nuw nsw i32 %10947, %10948"
"  %10949 = add nuw nsw i32 %10947, %10948" -> "  %10960 = and i32 %10949, 65535""  %10949 = add nuw nsw i32 %10947, %10948" -> "  %10956 = lshr i32 %10949, 16"
"  %10950 = and i32 %10938, 65535"
"  %10950 = and i32 %10938, 65535" -> "  %10952 = add nuw nsw i32 %10951, %10950"
"  %10951 = lshr i32 %10897, 16"
"  %10951 = lshr i32 %10897, 16" -> "  %10952 = add nuw nsw i32 %10951, %10950"
"  %10952 = add nuw nsw i32 %10951, %10950"
"  %10952 = add nuw nsw i32 %10951, %10950" -> "  %10955 = and i32 %10952, 65535""  %10952 = add nuw nsw i32 %10951, %10950" -> "  %10953 = lshr i32 %10952, 16"
"  %10953 = lshr i32 %10952, 16"
"  %10953 = lshr i32 %10952, 16" -> "  %10954 = add nuw i32 %10946, %10953"
"  %10954 = add nuw i32 %10946, %10953"
"  %10954 = add nuw i32 %10946, %10953" -> "  %10959 = add nuw i32 %10954, %10958"
"  %10955 = and i32 %10952, 65535"
"  %10955 = and i32 %10952, 65535" -> "  %10957 = add nuw nsw i32 %10955, %10956"
"  %10956 = lshr i32 %10949, 16"
"  %10956 = lshr i32 %10949, 16" -> "  %10957 = add nuw nsw i32 %10955, %10956"
"  %10957 = add nuw nsw i32 %10955, %10956"
"  %10957 = add nuw nsw i32 %10955, %10956" -> "  %10963 = and i32 %10957, 65535""  %10957 = add nuw nsw i32 %10955, %10956" -> "  %10958 = lshr i32 %10957, 16"
"  %10958 = lshr i32 %10957, 16"
"  %10958 = lshr i32 %10957, 16" -> "  %10959 = add nuw i32 %10954, %10958"
"  %10959 = add nuw i32 %10954, %10958"
"  %10959 = add nuw i32 %10954, %10958" -> "  %10972 = and i32 %10959, -65536""  %10959 = add nuw i32 %10954, %10958" -> "  %10970 = and i32 %10959, 65535"
"  %10960 = and i32 %10949, 65535"
"  %10960 = and i32 %10949, 65535" -> "  %10962 = add nuw nsw i32 %10961, %10960"
"  %10961 = and i32 %10928, 65535"
"  %10961 = and i32 %10928, 65535" -> "  %10962 = add nuw nsw i32 %10961, %10960"
"  %10962 = add nuw nsw i32 %10961, %10960"
"  %10962 = add nuw nsw i32 %10961, %10960" -> "  %11002 = and i32 %10962, 65535""  %10962 = add nuw nsw i32 %10961, %10960" -> "  %10966 = lshr i32 %10962, 16"
"  %10963 = and i32 %10957, 65535"
"  %10963 = and i32 %10957, 65535" -> "  %10965 = add nuw nsw i32 %10963, %10964"
"  %10964 = lshr i32 %10928, 16"
"  %10964 = lshr i32 %10928, 16" -> "  %10965 = add nuw nsw i32 %10963, %10964"
"  %10965 = add nuw nsw i32 %10963, %10964"
"  %10965 = add nuw nsw i32 %10963, %10964" -> "  %10969 = lshr i32 %10965, 16""  %10965 = add nuw nsw i32 %10963, %10964" -> "  %10967 = and i32 %10965, 65535"
"  %10966 = lshr i32 %10962, 16"
"  %10966 = lshr i32 %10962, 16" -> "  %10968 = add nuw nsw i32 %10967, %10966"
"  %10967 = and i32 %10965, 65535"
"  %10967 = and i32 %10965, 65535" -> "  %10968 = add nuw nsw i32 %10967, %10966"
"  %10968 = add nuw nsw i32 %10967, %10966"
"  %10968 = add nuw nsw i32 %10967, %10966" -> "  %11009 = and i32 %10968, 65535""  %10968 = add nuw nsw i32 %10967, %10966" -> "  %10974 = lshr i32 %10968, 16"
"  %10969 = lshr i32 %10965, 16"
"  %10969 = lshr i32 %10965, 16" -> "  %10971 = add nuw nsw i32 %10969, %10970"
"  %10970 = and i32 %10959, 65535"
"  %10970 = and i32 %10959, 65535" -> "  %10971 = add nuw nsw i32 %10969, %10970"
"  %10971 = add nuw nsw i32 %10969, %10970"
"  %10971 = add nuw nsw i32 %10969, %10970" -> "  %10973 = add nuw i32 %10971, %10972"
"  %10972 = and i32 %10959, -65536"
"  %10972 = and i32 %10959, -65536" -> "  %10973 = add nuw i32 %10971, %10972"
"  %10973 = add nuw i32 %10971, %10972"
"  %10973 = add nuw i32 %10971, %10972" -> "  %10975 = add nuw i32 %10973, %10974"
"  %10974 = lshr i32 %10968, 16"
"  %10974 = lshr i32 %10968, 16" -> "  %10975 = add nuw i32 %10973, %10974"
"  %10975 = add nuw i32 %10973, %10974"
"  %10975 = add nuw i32 %10973, %10974" -> "  %11013 = add nuw i32 %10975, %11012"
"  %10976 = and i32 %10849, 65535"
"  %10976 = and i32 %10849, 65535" -> "  %10978 = add nuw nsw i32 %10977, %10976"
"  %10977 = and i32 %10813, 65535"
"  %10977 = and i32 %10813, 65535" -> "  %10978 = add nuw nsw i32 %10977, %10976"
"  %10978 = add nuw nsw i32 %10977, %10976"
"  %10978 = add nuw nsw i32 %10977, %10976" -> "  %11244 = and i32 %10978, 65535""  %10978 = add nuw nsw i32 %10977, %10976" -> "  %10982 = lshr i32 %10978, 16"
"  %10979 = and i32 %10858, 65535"
"  %10979 = and i32 %10858, 65535" -> "  %10981 = add nuw nsw i32 %10980, %10979"
"  %10980 = and i32 %10819, 65535"
"  %10980 = and i32 %10819, 65535" -> "  %10981 = add nuw nsw i32 %10980, %10979"
"  %10981 = add nuw nsw i32 %10980, %10979"
"  %10981 = add nuw nsw i32 %10980, %10979" -> "  %10985 = lshr i32 %10981, 16""  %10981 = add nuw nsw i32 %10980, %10979" -> "  %10983 = and i32 %10981, 65535"
"  %10982 = lshr i32 %10978, 16"
"  %10982 = lshr i32 %10978, 16" -> "  %10984 = add nuw nsw i32 %10983, %10982"
"  %10983 = and i32 %10981, 65535"
"  %10983 = and i32 %10981, 65535" -> "  %10984 = add nuw nsw i32 %10983, %10982"
"  %10984 = add nuw nsw i32 %10983, %10982"
"  %10984 = add nuw nsw i32 %10983, %10982" -> "  %11247 = and i32 %10984, 65535""  %10984 = add nuw nsw i32 %10983, %10982" -> "  %10986 = lshr i32 %10984, 16"
"  %10985 = lshr i32 %10981, 16"
"  %10985 = lshr i32 %10981, 16" -> "  %10997 = add nuw nsw i32 %10986, %10985"
"  %10986 = lshr i32 %10984, 16"
"  %10986 = lshr i32 %10984, 16" -> "  %10997 = add nuw nsw i32 %10986, %10985"
"  %10987 = and i32 %10918, 65535"
"  %10987 = and i32 %10918, 65535" -> "  %10989 = add nuw nsw i32 %10988, %10987"
"  %10988 = and i32 %10833, 65535"
"  %10988 = and i32 %10833, 65535" -> "  %10989 = add nuw nsw i32 %10988, %10987"
"  %10989 = add nuw nsw i32 %10988, %10987"
"  %10989 = add nuw nsw i32 %10988, %10987" -> "  %10996 = and i32 %10989, 65535""  %10989 = add nuw nsw i32 %10988, %10987" -> "  %10993 = lshr i32 %10989, 16"
"  %10990 = and i32 %10926, 65535"
"  %10990 = and i32 %10926, 65535" -> "  %10992 = add nuw nsw i32 %10991, %10990"
"  %10991 = and i32 %10836, 65535"
"  %10991 = and i32 %10836, 65535" -> "  %10992 = add nuw nsw i32 %10991, %10990"
"  %10992 = add nuw nsw i32 %10991, %10990"
"  %10992 = add nuw nsw i32 %10991, %10990" -> "  %11003 = lshr i32 %10992, 16""  %10992 = add nuw nsw i32 %10991, %10990" -> "  %10994 = and i32 %10992, 65535"
"  %10993 = lshr i32 %10989, 16"
"  %10993 = lshr i32 %10989, 16" -> "  %10995 = add nuw nsw i32 %10994, %10993"
"  %10994 = and i32 %10992, 65535"
"  %10994 = and i32 %10992, 65535" -> "  %10995 = add nuw nsw i32 %10994, %10993"
"  %10995 = add nuw nsw i32 %10994, %10993"
"  %10995 = add nuw nsw i32 %10994, %10993" -> "  %11005 = lshr i32 %10995, 16""  %10995 = add nuw nsw i32 %10994, %10993" -> "  %11000 = and i32 %10995, 65535"
"  %10996 = and i32 %10989, 65535"
"  %10996 = and i32 %10989, 65535" -> "  %10998 = add nuw nsw i32 %10997, %10996"
"  %10997 = add nuw nsw i32 %10986, %10985"
"  %10997 = add nuw nsw i32 %10986, %10985" -> "  %10998 = add nuw nsw i32 %10997, %10996"
"  %10998 = add nuw nsw i32 %10997, %10996"
"  %10998 = add nuw nsw i32 %10997, %10996" -> "  %11256 = and i32 %10998, 65535""  %10998 = add nuw nsw i32 %10997, %10996" -> "  %10999 = lshr i32 %10998, 16"
"  %10999 = lshr i32 %10998, 16"
"  %10999 = lshr i32 %10998, 16" -> "  %11001 = add nuw nsw i32 %11000, %10999"
"  %11000 = and i32 %10995, 65535"
"  %11000 = and i32 %10995, 65535" -> "  %11001 = add nuw nsw i32 %11000, %10999"
"  %11001 = add nuw nsw i32 %11000, %10999"
"  %11001 = add nuw nsw i32 %11000, %10999" -> "  %11259 = and i32 %11001, 65535""  %11001 = add nuw nsw i32 %11000, %10999" -> "  %11007 = lshr i32 %11001, 16"
"  %11002 = and i32 %10962, 65535"
"  %11002 = and i32 %10962, 65535" -> "  %11004 = add nuw nsw i32 %11003, %11002"
"  %11003 = lshr i32 %10992, 16"
"  %11003 = lshr i32 %10992, 16" -> "  %11004 = add nuw nsw i32 %11003, %11002"
"  %11004 = add nuw nsw i32 %11003, %11002"
"  %11004 = add nuw nsw i32 %11003, %11002" -> "  %11006 = add nuw nsw i32 %11004, %11005"
"  %11005 = lshr i32 %10995, 16"
"  %11005 = lshr i32 %10995, 16" -> "  %11006 = add nuw nsw i32 %11004, %11005"
"  %11006 = add nuw nsw i32 %11004, %11005"
"  %11006 = add nuw nsw i32 %11004, %11005" -> "  %11008 = add nuw nsw i32 %11006, %11007"
"  %11007 = lshr i32 %11001, 16"
"  %11007 = lshr i32 %11001, 16" -> "  %11008 = add nuw nsw i32 %11006, %11007"
"  %11008 = add nuw nsw i32 %11006, %11007"
"  %11008 = add nuw nsw i32 %11006, %11007" -> "  %11180 = and i32 %11008, 65535""  %11008 = add nuw nsw i32 %11006, %11007" -> "  %11010 = lshr i32 %11008, 16"
"  %11009 = and i32 %10968, 65535"
"  %11009 = and i32 %10968, 65535" -> "  %11011 = add nuw nsw i32 %11010, %11009"
"  %11010 = lshr i32 %11008, 16"
"  %11010 = lshr i32 %11008, 16" -> "  %11011 = add nuw nsw i32 %11010, %11009"
"  %11011 = add nuw nsw i32 %11010, %11009"
"  %11011 = add nuw nsw i32 %11010, %11009" -> "  %11183 = and i32 %11011, 65535""  %11011 = add nuw nsw i32 %11010, %11009" -> "  %11012 = lshr i32 %11011, 16"
"  %11012 = lshr i32 %11011, 16"
"  %11012 = lshr i32 %11011, 16" -> "  %11013 = add nuw i32 %10975, %11012"
"  %11013 = add nuw i32 %10975, %11012"
"  %11013 = add nuw i32 %10975, %11012" -> "  %11189 = and i32 %11013, 65535""  %11013 = add nuw i32 %10975, %11012" -> "  %11192 = lshr i32 %11013, 16"
"  %11014 = mul nuw nsw i32 %9270, 4087"
"  %11014 = mul nuw nsw i32 %9270, 4087" -> "  %11141 = and i32 %11014, 65535""  %11014 = mul nuw nsw i32 %9270, 4087" -> "  %11015 = lshr i32 %11014, 16"
"  %11015 = lshr i32 %11014, 16"
"  %11015 = lshr i32 %11014, 16" -> "  %11018 = add nuw nsw i32 %11017, %11015"
"  %11016 = mul nuw nsw i32 %9273, 4087"
"  %11016 = mul nuw nsw i32 %9273, 4087" -> "  %11019 = and i32 %11016, 268369920""  %11016 = mul nuw nsw i32 %9273, 4087" -> "  %11017 = and i32 %11016, 65535"
"  %11017 = and i32 %11016, 65535"
"  %11017 = and i32 %11016, 65535" -> "  %11018 = add nuw nsw i32 %11017, %11015"
"  %11018 = add nuw nsw i32 %11017, %11015"
"  %11018 = add nuw nsw i32 %11017, %11015" -> "  %11020 = add nuw nsw i32 %11018, %11019"
"  %11019 = and i32 %11016, 268369920"
"  %11019 = and i32 %11016, 268369920" -> "  %11020 = add nuw nsw i32 %11018, %11019"
"  %11020 = add nuw nsw i32 %11018, %11019"
"  %11020 = add nuw nsw i32 %11018, %11019" -> "  %11024 = lshr i32 %11020, 16""  %11020 = add nuw nsw i32 %11018, %11019" -> "  %11022 = and i32 %11020, 65535"
"  %11021 = mul nuw nsw i32 %9270, 11561"
"  %11021 = mul nuw nsw i32 %9270, 11561" -> "  %11023 = add nuw nsw i32 %11022, %11021"
"  %11022 = and i32 %11020, 65535"
"  %11022 = and i32 %11020, 65535" -> "  %11023 = add nuw nsw i32 %11022, %11021"
"  %11023 = add nuw nsw i32 %11022, %11021"
"  %11023 = add nuw nsw i32 %11022, %11021" -> "  %11144 = and i32 %11023, 65535""  %11023 = add nuw nsw i32 %11022, %11021" -> "  %11027 = lshr i32 %11023, 16"
"  %11024 = lshr i32 %11020, 16"
"  %11024 = lshr i32 %11020, 16" -> "  %11026 = add nuw nsw i32 %11024, %11025"
"  %11025 = mul nuw nsw i32 %9273, 11561"
"  %11025 = mul nuw nsw i32 %9273, 11561" -> "  %11026 = add nuw nsw i32 %11024, %11025"
"  %11026 = add nuw nsw i32 %11024, %11025"
"  %11026 = add nuw nsw i32 %11024, %11025" -> "  %11030 = and i32 %11026, 2147418112""  %11026 = add nuw nsw i32 %11024, %11025" -> "  %11028 = and i32 %11026, 65535"
"  %11027 = lshr i32 %11023, 16"
"  %11027 = lshr i32 %11023, 16" -> "  %11029 = add nuw nsw i32 %11027, %11028"
"  %11028 = and i32 %11026, 65535"
"  %11028 = and i32 %11026, 65535" -> "  %11029 = add nuw nsw i32 %11027, %11028"
"  %11029 = add nuw nsw i32 %11027, %11028"
"  %11029 = add nuw nsw i32 %11027, %11028" -> "  %11031 = add nuw nsw i32 %11029, %11030"
"  %11030 = and i32 %11026, 2147418112"
"  %11030 = and i32 %11026, 2147418112" -> "  %11031 = add nuw nsw i32 %11029, %11030"
"  %11031 = add nuw nsw i32 %11029, %11030"
"  %11031 = add nuw nsw i32 %11029, %11030" -> "  %11054 = lshr i32 %11031, 16""  %11031 = add nuw nsw i32 %11029, %11030" -> "  %11050 = and i32 %11031, 65535"
"  %11032 = mul nuw nsw i32 %9290, 4087"
"  %11032 = mul nuw nsw i32 %9290, 4087" -> "  %11051 = and i32 %11032, 65535""  %11032 = mul nuw nsw i32 %9290, 4087" -> "  %11033 = lshr i32 %11032, 16"
"  %11033 = lshr i32 %11032, 16"
"  %11033 = lshr i32 %11032, 16" -> "  %11036 = add nuw nsw i32 %11035, %11033"
"  %11034 = mul nuw nsw i32 %9293, 4087"
"  %11034 = mul nuw nsw i32 %9293, 4087" -> "  %11037 = and i32 %11034, 268369920""  %11034 = mul nuw nsw i32 %9293, 4087" -> "  %11035 = and i32 %11034, 65535"
"  %11035 = and i32 %11034, 65535"
"  %11035 = and i32 %11034, 65535" -> "  %11036 = add nuw nsw i32 %11035, %11033"
"  %11036 = add nuw nsw i32 %11035, %11033"
"  %11036 = add nuw nsw i32 %11035, %11033" -> "  %11038 = add nuw nsw i32 %11036, %11037"
"  %11037 = and i32 %11034, 268369920"
"  %11037 = and i32 %11034, 268369920" -> "  %11038 = add nuw nsw i32 %11036, %11037"
"  %11038 = add nuw nsw i32 %11036, %11037"
"  %11038 = add nuw nsw i32 %11036, %11037" -> "  %11042 = lshr i32 %11038, 16""  %11038 = add nuw nsw i32 %11036, %11037" -> "  %11040 = and i32 %11038, 65535"
"  %11039 = mul nuw nsw i32 %9290, 11561"
"  %11039 = mul nuw nsw i32 %9290, 11561" -> "  %11041 = add nuw nsw i32 %11040, %11039"
"  %11040 = and i32 %11038, 65535"
"  %11040 = and i32 %11038, 65535" -> "  %11041 = add nuw nsw i32 %11040, %11039"
"  %11041 = add nuw nsw i32 %11040, %11039"
"  %11041 = add nuw nsw i32 %11040, %11039" -> "  %11053 = and i32 %11041, 65535""  %11041 = add nuw nsw i32 %11040, %11039" -> "  %11045 = lshr i32 %11041, 16"
"  %11042 = lshr i32 %11038, 16"
"  %11042 = lshr i32 %11038, 16" -> "  %11044 = add nuw nsw i32 %11042, %11043"
"  %11043 = mul nuw nsw i32 %9293, 11561"
"  %11043 = mul nuw nsw i32 %9293, 11561" -> "  %11044 = add nuw nsw i32 %11042, %11043"
"  %11044 = add nuw nsw i32 %11042, %11043"
"  %11044 = add nuw nsw i32 %11042, %11043" -> "  %11048 = and i32 %11044, 2147418112""  %11044 = add nuw nsw i32 %11042, %11043" -> "  %11046 = and i32 %11044, 65535"
"  %11045 = lshr i32 %11041, 16"
"  %11045 = lshr i32 %11041, 16" -> "  %11047 = add nuw nsw i32 %11045, %11046"
"  %11046 = and i32 %11044, 65535"
"  %11046 = and i32 %11044, 65535" -> "  %11047 = add nuw nsw i32 %11045, %11046"
"  %11047 = add nuw nsw i32 %11045, %11046"
"  %11047 = add nuw nsw i32 %11045, %11046" -> "  %11049 = add nuw nsw i32 %11047, %11048"
"  %11048 = and i32 %11044, 2147418112"
"  %11048 = and i32 %11044, 2147418112" -> "  %11049 = add nuw nsw i32 %11047, %11048"
"  %11049 = add nuw nsw i32 %11047, %11048"
"  %11049 = add nuw nsw i32 %11047, %11048" -> "  %11057 = add nuw nsw i32 %11049, %11056"
"  %11050 = and i32 %11031, 65535"
"  %11050 = and i32 %11031, 65535" -> "  %11052 = add nuw nsw i32 %11050, %11051"
"  %11051 = and i32 %11032, 65535"
"  %11051 = and i32 %11032, 65535" -> "  %11052 = add nuw nsw i32 %11050, %11051"
"  %11052 = add nuw nsw i32 %11050, %11051"
"  %11052 = add nuw nsw i32 %11050, %11051" -> "  %11081 = and i32 %11052, 65535""  %11052 = add nuw nsw i32 %11050, %11051" -> "  %11059 = lshr i32 %11052, 16"
"  %11053 = and i32 %11041, 65535"
"  %11053 = and i32 %11041, 65535" -> "  %11055 = add nuw nsw i32 %11053, %11054"
"  %11054 = lshr i32 %11031, 16"
"  %11054 = lshr i32 %11031, 16" -> "  %11055 = add nuw nsw i32 %11053, %11054"
"  %11055 = add nuw nsw i32 %11053, %11054"
"  %11055 = add nuw nsw i32 %11053, %11054" -> "  %11058 = and i32 %11055, 65535""  %11055 = add nuw nsw i32 %11053, %11054" -> "  %11056 = lshr i32 %11055, 16"
"  %11056 = lshr i32 %11055, 16"
"  %11056 = lshr i32 %11055, 16" -> "  %11057 = add nuw nsw i32 %11049, %11056"
"  %11057 = add nuw nsw i32 %11049, %11056"
"  %11057 = add nuw nsw i32 %11049, %11056" -> "  %11062 = add nuw nsw i32 %11057, %11061"
"  %11058 = and i32 %11055, 65535"
"  %11058 = and i32 %11055, 65535" -> "  %11060 = add nuw nsw i32 %11058, %11059"
"  %11059 = lshr i32 %11052, 16"
"  %11059 = lshr i32 %11052, 16" -> "  %11060 = add nuw nsw i32 %11058, %11059"
"  %11060 = add nuw nsw i32 %11058, %11059"
"  %11060 = add nuw nsw i32 %11058, %11059" -> "  %11085 = and i32 %11060, 65535""  %11060 = add nuw nsw i32 %11058, %11059" -> "  %11061 = lshr i32 %11060, 16"
"  %11061 = lshr i32 %11060, 16"
"  %11061 = lshr i32 %11060, 16" -> "  %11062 = add nuw nsw i32 %11057, %11061"
"  %11062 = add nuw nsw i32 %11057, %11061"
"  %11062 = add nuw nsw i32 %11057, %11061" -> "  %11112 = and i32 %11062, 65535""  %11062 = add nuw nsw i32 %11057, %11061" -> "  %11116 = lshr i32 %11062, 16"
"  %11063 = mul nuw nsw i32 %9270, 21884"
"  %11063 = mul nuw nsw i32 %9270, 21884" -> "  %11064 = lshr i32 %11063, 16""  %11063 = mul nuw nsw i32 %9270, 21884" -> "  %11082 = and i32 %11063, 65532"
"  %11064 = lshr i32 %11063, 16"
"  %11064 = lshr i32 %11063, 16" -> "  %11067 = add nuw nsw i32 %11066, %11064"
"  %11065 = mul nuw nsw i32 %9273, 21884"
"  %11065 = mul nuw nsw i32 %9273, 21884" -> "  %11068 = and i32 %11065, 2147418112""  %11065 = mul nuw nsw i32 %9273, 21884" -> "  %11066 = and i32 %11065, 65532"
"  %11066 = and i32 %11065, 65532"
"  %11066 = and i32 %11065, 65532" -> "  %11067 = add nuw nsw i32 %11066, %11064"
"  %11067 = add nuw nsw i32 %11066, %11064"
"  %11067 = add nuw nsw i32 %11066, %11064" -> "  %11069 = add nuw nsw i32 %11067, %11068"
"  %11068 = and i32 %11065, 2147418112"
"  %11068 = and i32 %11065, 2147418112" -> "  %11069 = add nuw nsw i32 %11067, %11068"
"  %11069 = add nuw nsw i32 %11067, %11068"
"  %11069 = add nuw nsw i32 %11067, %11068" -> "  %11073 = lshr i32 %11069, 16""  %11069 = add nuw nsw i32 %11067, %11068" -> "  %11071 = and i32 %11069, 65535"
"  %11070 = mul nuw i32 %9270, 36786"
"  %11070 = mul nuw i32 %9270, 36786" -> "  %11072 = add nuw i32 %11071, %11070"
"  %11071 = and i32 %11069, 65535"
"  %11071 = and i32 %11069, 65535" -> "  %11072 = add nuw i32 %11071, %11070"
"  %11072 = add nuw i32 %11071, %11070"
"  %11072 = add nuw i32 %11071, %11070" -> "  %11084 = and i32 %11072, 65535""  %11072 = add nuw i32 %11071, %11070" -> "  %11076 = lshr i32 %11072, 16"
"  %11073 = lshr i32 %11069, 16"
"  %11073 = lshr i32 %11069, 16" -> "  %11075 = add nuw i32 %11073, %11074"
"  %11074 = mul nuw i32 %9273, 36786"
"  %11074 = mul nuw i32 %9273, 36786" -> "  %11075 = add nuw i32 %11073, %11074"
"  %11075 = add nuw i32 %11073, %11074"
"  %11075 = add nuw i32 %11073, %11074" -> "  %11079 = and i32 %11075, -65536""  %11075 = add nuw i32 %11073, %11074" -> "  %11077 = and i32 %11075, 65535"
"  %11076 = lshr i32 %11072, 16"
"  %11076 = lshr i32 %11072, 16" -> "  %11078 = add nuw nsw i32 %11076, %11077"
"  %11077 = and i32 %11075, 65535"
"  %11077 = and i32 %11075, 65535" -> "  %11078 = add nuw nsw i32 %11076, %11077"
"  %11078 = add nuw nsw i32 %11076, %11077"
"  %11078 = add nuw nsw i32 %11076, %11077" -> "  %11080 = add nuw i32 %11078, %11079"
"  %11079 = and i32 %11075, -65536"
"  %11079 = and i32 %11075, -65536" -> "  %11080 = add nuw i32 %11078, %11079"
"  %11080 = add nuw i32 %11078, %11079"
"  %11080 = add nuw i32 %11078, %11079" -> "  %11088 = add nuw i32 %11080, %11087"
"  %11081 = and i32 %11052, 65535"
"  %11081 = and i32 %11052, 65535" -> "  %11083 = add nuw nsw i32 %11081, %11082"
"  %11082 = and i32 %11063, 65532"
"  %11082 = and i32 %11063, 65532" -> "  %11083 = add nuw nsw i32 %11081, %11082"
"  %11083 = add nuw nsw i32 %11081, %11082"
"  %11083 = add nuw nsw i32 %11081, %11082" -> "  %11150 = and i32 %11083, 65535""  %11083 = add nuw nsw i32 %11081, %11082" -> "  %11090 = lshr i32 %11083, 16"
"  %11084 = and i32 %11072, 65535"
"  %11084 = and i32 %11072, 65535" -> "  %11086 = add nuw nsw i32 %11085, %11084"
"  %11085 = and i32 %11060, 65535"
"  %11085 = and i32 %11060, 65535" -> "  %11086 = add nuw nsw i32 %11085, %11084"
"  %11086 = add nuw nsw i32 %11085, %11084"
"  %11086 = add nuw nsw i32 %11085, %11084" -> "  %11089 = and i32 %11086, 65535""  %11086 = add nuw nsw i32 %11085, %11084" -> "  %11087 = lshr i32 %11086, 16"
"  %11087 = lshr i32 %11086, 16"
"  %11087 = lshr i32 %11086, 16" -> "  %11088 = add nuw i32 %11080, %11087"
"  %11088 = add nuw i32 %11080, %11087"
"  %11088 = add nuw i32 %11080, %11087" -> "  %11093 = add nuw i32 %11088, %11092"
"  %11089 = and i32 %11086, 65535"
"  %11089 = and i32 %11086, 65535" -> "  %11091 = add nuw nsw i32 %11089, %11090"
"  %11090 = lshr i32 %11083, 16"
"  %11090 = lshr i32 %11083, 16" -> "  %11091 = add nuw nsw i32 %11089, %11090"
"  %11091 = add nuw nsw i32 %11089, %11090"
"  %11091 = add nuw nsw i32 %11089, %11090" -> "  %11153 = and i32 %11091, 65535""  %11091 = add nuw nsw i32 %11089, %11090" -> "  %11092 = lshr i32 %11091, 16"
"  %11092 = lshr i32 %11091, 16"
"  %11092 = lshr i32 %11091, 16" -> "  %11093 = add nuw i32 %11088, %11092"
"  %11093 = add nuw i32 %11088, %11092"
"  %11093 = add nuw i32 %11088, %11092" -> "  %11129 = lshr i32 %11093, 16""  %11093 = add nuw i32 %11088, %11092" -> "  %11126 = and i32 %11093, 65535"
"  %11094 = mul nuw nsw i32 %9290, 21884"
"  %11094 = mul nuw nsw i32 %9290, 21884" -> "  %11113 = and i32 %11094, 65532""  %11094 = mul nuw nsw i32 %9290, 21884" -> "  %11095 = lshr i32 %11094, 16"
"  %11095 = lshr i32 %11094, 16"
"  %11095 = lshr i32 %11094, 16" -> "  %11098 = add nuw nsw i32 %11097, %11095"
"  %11096 = mul nuw nsw i32 %9293, 21884"
"  %11096 = mul nuw nsw i32 %9293, 21884" -> "  %11099 = and i32 %11096, 2147418112""  %11096 = mul nuw nsw i32 %9293, 21884" -> "  %11097 = and i32 %11096, 65532"
"  %11097 = and i32 %11096, 65532"
"  %11097 = and i32 %11096, 65532" -> "  %11098 = add nuw nsw i32 %11097, %11095"
"  %11098 = add nuw nsw i32 %11097, %11095"
"  %11098 = add nuw nsw i32 %11097, %11095" -> "  %11100 = add nuw nsw i32 %11098, %11099"
"  %11099 = and i32 %11096, 2147418112"
"  %11099 = and i32 %11096, 2147418112" -> "  %11100 = add nuw nsw i32 %11098, %11099"
"  %11100 = add nuw nsw i32 %11098, %11099"
"  %11100 = add nuw nsw i32 %11098, %11099" -> "  %11104 = lshr i32 %11100, 16""  %11100 = add nuw nsw i32 %11098, %11099" -> "  %11102 = and i32 %11100, 65535"
"  %11101 = mul nuw i32 %9290, 36786"
"  %11101 = mul nuw i32 %9290, 36786" -> "  %11103 = add nuw i32 %11102, %11101"
"  %11102 = and i32 %11100, 65535"
"  %11102 = and i32 %11100, 65535" -> "  %11103 = add nuw i32 %11102, %11101"
"  %11103 = add nuw i32 %11102, %11101"
"  %11103 = add nuw i32 %11102, %11101" -> "  %11115 = and i32 %11103, 65535""  %11103 = add nuw i32 %11102, %11101" -> "  %11107 = lshr i32 %11103, 16"
"  %11104 = lshr i32 %11100, 16"
"  %11104 = lshr i32 %11100, 16" -> "  %11106 = add nuw i32 %11104, %11105"
"  %11105 = mul nuw i32 %9293, 36786"
"  %11105 = mul nuw i32 %9293, 36786" -> "  %11106 = add nuw i32 %11104, %11105"
"  %11106 = add nuw i32 %11104, %11105"
"  %11106 = add nuw i32 %11104, %11105" -> "  %11110 = and i32 %11106, -65536""  %11106 = add nuw i32 %11104, %11105" -> "  %11108 = and i32 %11106, 65535"
"  %11107 = lshr i32 %11103, 16"
"  %11107 = lshr i32 %11103, 16" -> "  %11109 = add nuw nsw i32 %11107, %11108"
"  %11108 = and i32 %11106, 65535"
"  %11108 = and i32 %11106, 65535" -> "  %11109 = add nuw nsw i32 %11107, %11108"
"  %11109 = add nuw nsw i32 %11107, %11108"
"  %11109 = add nuw nsw i32 %11107, %11108" -> "  %11111 = add nuw i32 %11109, %11110"
"  %11110 = and i32 %11106, -65536"
"  %11110 = and i32 %11106, -65536" -> "  %11111 = add nuw i32 %11109, %11110"
"  %11111 = add nuw i32 %11109, %11110"
"  %11111 = add nuw i32 %11109, %11110" -> "  %11119 = add nuw i32 %11111, %11118"
"  %11112 = and i32 %11062, 65535"
"  %11112 = and i32 %11062, 65535" -> "  %11114 = add nuw nsw i32 %11112, %11113"
"  %11113 = and i32 %11094, 65532"
"  %11113 = and i32 %11094, 65532" -> "  %11114 = add nuw nsw i32 %11112, %11113"
"  %11114 = add nuw nsw i32 %11112, %11113"
"  %11114 = add nuw nsw i32 %11112, %11113" -> "  %11125 = and i32 %11114, 65535""  %11114 = add nuw nsw i32 %11112, %11113" -> "  %11121 = lshr i32 %11114, 16"
"  %11115 = and i32 %11103, 65535"
"  %11115 = and i32 %11103, 65535" -> "  %11117 = add nuw nsw i32 %11116, %11115"
"  %11116 = lshr i32 %11062, 16"
"  %11116 = lshr i32 %11062, 16" -> "  %11117 = add nuw nsw i32 %11116, %11115"
"  %11117 = add nuw nsw i32 %11116, %11115"
"  %11117 = add nuw nsw i32 %11116, %11115" -> "  %11120 = and i32 %11117, 65535""  %11117 = add nuw nsw i32 %11116, %11115" -> "  %11118 = lshr i32 %11117, 16"
"  %11118 = lshr i32 %11117, 16"
"  %11118 = lshr i32 %11117, 16" -> "  %11119 = add nuw i32 %11111, %11118"
"  %11119 = add nuw i32 %11111, %11118"
"  %11119 = add nuw i32 %11111, %11118" -> "  %11124 = add nuw i32 %11119, %11123"
"  %11120 = and i32 %11117, 65535"
"  %11120 = and i32 %11117, 65535" -> "  %11122 = add nuw nsw i32 %11120, %11121"
"  %11121 = lshr i32 %11114, 16"
"  %11121 = lshr i32 %11114, 16" -> "  %11122 = add nuw nsw i32 %11120, %11121"
"  %11122 = add nuw nsw i32 %11120, %11121"
"  %11122 = add nuw nsw i32 %11120, %11121" -> "  %11128 = and i32 %11122, 65535""  %11122 = add nuw nsw i32 %11120, %11121" -> "  %11123 = lshr i32 %11122, 16"
"  %11123 = lshr i32 %11122, 16"
"  %11123 = lshr i32 %11122, 16" -> "  %11124 = add nuw i32 %11119, %11123"
"  %11124 = add nuw i32 %11119, %11123"
"  %11124 = add nuw i32 %11119, %11123" -> "  %11137 = and i32 %11124, -65536""  %11124 = add nuw i32 %11119, %11123" -> "  %11135 = and i32 %11124, 65535"
"  %11125 = and i32 %11114, 65535"
"  %11125 = and i32 %11114, 65535" -> "  %11127 = add nuw nsw i32 %11126, %11125"
"  %11126 = and i32 %11093, 65535"
"  %11126 = and i32 %11093, 65535" -> "  %11127 = add nuw nsw i32 %11126, %11125"
"  %11127 = add nuw nsw i32 %11126, %11125"
"  %11127 = add nuw nsw i32 %11126, %11125" -> "  %11167 = and i32 %11127, 65535""  %11127 = add nuw nsw i32 %11126, %11125" -> "  %11131 = lshr i32 %11127, 16"
"  %11128 = and i32 %11122, 65535"
"  %11128 = and i32 %11122, 65535" -> "  %11130 = add nuw nsw i32 %11128, %11129"
"  %11129 = lshr i32 %11093, 16"
"  %11129 = lshr i32 %11093, 16" -> "  %11130 = add nuw nsw i32 %11128, %11129"
"  %11130 = add nuw nsw i32 %11128, %11129"
"  %11130 = add nuw nsw i32 %11128, %11129" -> "  %11134 = lshr i32 %11130, 16""  %11130 = add nuw nsw i32 %11128, %11129" -> "  %11132 = and i32 %11130, 65535"
"  %11131 = lshr i32 %11127, 16"
"  %11131 = lshr i32 %11127, 16" -> "  %11133 = add nuw nsw i32 %11132, %11131"
"  %11132 = and i32 %11130, 65535"
"  %11132 = and i32 %11130, 65535" -> "  %11133 = add nuw nsw i32 %11132, %11131"
"  %11133 = add nuw nsw i32 %11132, %11131"
"  %11133 = add nuw nsw i32 %11132, %11131" -> "  %11174 = and i32 %11133, 65535""  %11133 = add nuw nsw i32 %11132, %11131" -> "  %11139 = lshr i32 %11133, 16"
"  %11134 = lshr i32 %11130, 16"
"  %11134 = lshr i32 %11130, 16" -> "  %11136 = add nuw nsw i32 %11134, %11135"
"  %11135 = and i32 %11124, 65535"
"  %11135 = and i32 %11124, 65535" -> "  %11136 = add nuw nsw i32 %11134, %11135"
"  %11136 = add nuw nsw i32 %11134, %11135"
"  %11136 = add nuw nsw i32 %11134, %11135" -> "  %11138 = add nuw i32 %11136, %11137"
"  %11137 = and i32 %11124, -65536"
"  %11137 = and i32 %11124, -65536" -> "  %11138 = add nuw i32 %11136, %11137"
"  %11138 = add nuw i32 %11136, %11137"
"  %11138 = add nuw i32 %11136, %11137" -> "  %11140 = add nuw i32 %11138, %11139"
"  %11139 = lshr i32 %11133, 16"
"  %11139 = lshr i32 %11133, 16" -> "  %11140 = add nuw i32 %11138, %11139"
"  %11140 = add nuw i32 %11138, %11139"
"  %11140 = add nuw i32 %11138, %11139" -> "  %11178 = add nuw i32 %11140, %11177"
"  %11141 = and i32 %11014, 65535"
"  %11141 = and i32 %11014, 65535" -> "  %11143 = add nuw nsw i32 %11142, %11141"
"  %11142 = and i32 %10843, 65535"
"  %11142 = and i32 %10843, 65535" -> "  %11143 = add nuw nsw i32 %11142, %11141"
"  %11143 = add nuw nsw i32 %11142, %11141"
"  %11143 = add nuw nsw i32 %11142, %11141" -> "  %11179 = and i32 %11143, 65535""  %11143 = add nuw nsw i32 %11142, %11141" -> "  %11147 = lshr i32 %11143, 16"
"  %11144 = and i32 %11023, 65535"
"  %11144 = and i32 %11023, 65535" -> "  %11146 = add nuw nsw i32 %11145, %11144"
"  %11145 = and i32 %10846, 65535"
"  %11145 = and i32 %10846, 65535" -> "  %11146 = add nuw nsw i32 %11145, %11144"
"  %11146 = add nuw nsw i32 %11145, %11144"
"  %11146 = add nuw nsw i32 %11145, %11144" -> "  %11160 = lshr i32 %11146, 16""  %11146 = add nuw nsw i32 %11145, %11144" -> "  %11148 = and i32 %11146, 65535"
"  %11147 = lshr i32 %11143, 16"
"  %11147 = lshr i32 %11143, 16" -> "  %11149 = add nuw nsw i32 %11148, %11147"
"  %11148 = and i32 %11146, 65535"
"  %11148 = and i32 %11146, 65535" -> "  %11149 = add nuw nsw i32 %11148, %11147"
"  %11149 = add nuw nsw i32 %11148, %11147"
"  %11149 = add nuw nsw i32 %11148, %11147" -> "  %11182 = and i32 %11149, 65535""  %11149 = add nuw nsw i32 %11148, %11147" -> "  %11162 = lshr i32 %11149, 16"
"  %11150 = and i32 %11083, 65535"
"  %11150 = and i32 %11083, 65535" -> "  %11152 = add nuw nsw i32 %11151, %11150"
"  %11151 = and i32 %10848, 65535"
"  %11151 = and i32 %10848, 65535" -> "  %11152 = add nuw nsw i32 %11151, %11150"
"  %11152 = add nuw nsw i32 %11151, %11150"
"  %11152 = add nuw nsw i32 %11151, %11150" -> "  %11159 = and i32 %11152, 65535""  %11152 = add nuw nsw i32 %11151, %11150" -> "  %11156 = lshr i32 %11152, 16"
"  %11153 = and i32 %11091, 65535"
"  %11153 = and i32 %11091, 65535" -> "  %11155 = add nuw nsw i32 %11154, %11153"
"  %11154 = lshr i32 %10848, 16"
"  %11154 = lshr i32 %10848, 16" -> "  %11155 = add nuw nsw i32 %11154, %11153"
"  %11155 = add nuw nsw i32 %11154, %11153"
"  %11155 = add nuw nsw i32 %11154, %11153" -> "  %11168 = lshr i32 %11155, 16""  %11155 = add nuw nsw i32 %11154, %11153" -> "  %11157 = and i32 %11155, 65535"
"  %11156 = lshr i32 %11152, 16"
"  %11156 = lshr i32 %11152, 16" -> "  %11158 = add nuw nsw i32 %11156, %11157"
"  %11157 = and i32 %11155, 65535"
"  %11157 = and i32 %11155, 65535" -> "  %11158 = add nuw nsw i32 %11156, %11157"
"  %11158 = add nuw nsw i32 %11156, %11157"
"  %11158 = add nuw nsw i32 %11156, %11157" -> "  %11170 = lshr i32 %11158, 16""  %11158 = add nuw nsw i32 %11156, %11157" -> "  %11165 = and i32 %11158, 65535"
"  %11159 = and i32 %11152, 65535"
"  %11159 = and i32 %11152, 65535" -> "  %11161 = add nuw nsw i32 %11159, %11160"
"  %11160 = lshr i32 %11146, 16"
"  %11160 = lshr i32 %11146, 16" -> "  %11161 = add nuw nsw i32 %11159, %11160"
"  %11161 = add nuw nsw i32 %11159, %11160"
"  %11161 = add nuw nsw i32 %11159, %11160" -> "  %11163 = add nuw nsw i32 %11161, %11162"
"  %11162 = lshr i32 %11149, 16"
"  %11162 = lshr i32 %11149, 16" -> "  %11163 = add nuw nsw i32 %11161, %11162"
"  %11163 = add nuw nsw i32 %11161, %11162"
"  %11163 = add nuw nsw i32 %11161, %11162" -> "  %11188 = and i32 %11163, 65535""  %11163 = add nuw nsw i32 %11161, %11162" -> "  %11164 = lshr i32 %11163, 16"
"  %11164 = lshr i32 %11163, 16"
"  %11164 = lshr i32 %11163, 16" -> "  %11166 = add nuw nsw i32 %11164, %11165"
"  %11165 = and i32 %11158, 65535"
"  %11165 = and i32 %11158, 65535" -> "  %11166 = add nuw nsw i32 %11164, %11165"
"  %11166 = add nuw nsw i32 %11164, %11165"
"  %11166 = add nuw nsw i32 %11164, %11165" -> "  %11191 = and i32 %11166, 65535""  %11166 = add nuw nsw i32 %11164, %11165" -> "  %11172 = lshr i32 %11166, 16"
"  %11167 = and i32 %11127, 65535"
"  %11167 = and i32 %11127, 65535" -> "  %11169 = add nuw nsw i32 %11168, %11167"
"  %11168 = lshr i32 %11155, 16"
"  %11168 = lshr i32 %11155, 16" -> "  %11169 = add nuw nsw i32 %11168, %11167"
"  %11169 = add nuw nsw i32 %11168, %11167"
"  %11169 = add nuw nsw i32 %11168, %11167" -> "  %11171 = add nuw nsw i32 %11169, %11170"
"  %11170 = lshr i32 %11158, 16"
"  %11170 = lshr i32 %11158, 16" -> "  %11171 = add nuw nsw i32 %11169, %11170"
"  %11171 = add nuw nsw i32 %11169, %11170"
"  %11171 = add nuw nsw i32 %11169, %11170" -> "  %11173 = add nuw nsw i32 %11171, %11172"
"  %11172 = lshr i32 %11166, 16"
"  %11172 = lshr i32 %11166, 16" -> "  %11173 = add nuw nsw i32 %11171, %11172"
"  %11173 = add nuw nsw i32 %11171, %11172"
"  %11173 = add nuw nsw i32 %11171, %11172" -> "  %11205 = and i32 %11173, 65535""  %11173 = add nuw nsw i32 %11171, %11172" -> "  %11175 = lshr i32 %11173, 16"
"  %11174 = and i32 %11133, 65535"
"  %11174 = and i32 %11133, 65535" -> "  %11176 = add nuw nsw i32 %11175, %11174"
"  %11175 = lshr i32 %11173, 16"
"  %11175 = lshr i32 %11173, 16" -> "  %11176 = add nuw nsw i32 %11175, %11174"
"  %11176 = add nuw nsw i32 %11175, %11174"
"  %11176 = add nuw nsw i32 %11175, %11174" -> "  %11212 = and i32 %11176, 65535""  %11176 = add nuw nsw i32 %11175, %11174" -> "  %11177 = lshr i32 %11176, 16"
"  %11177 = lshr i32 %11176, 16"
"  %11177 = lshr i32 %11176, 16" -> "  %11178 = add nuw i32 %11140, %11177"
"  %11178 = add nuw i32 %11140, %11177"
"  %11178 = add nuw i32 %11140, %11177" -> "  %11216 = add nuw i32 %11178, %11215"
"  %11179 = and i32 %11143, 65535"
"  %11179 = and i32 %11143, 65535" -> "  %11181 = add nuw nsw i32 %11180, %11179"
"  %11180 = and i32 %11008, 65535"
"  %11180 = and i32 %11008, 65535" -> "  %11181 = add nuw nsw i32 %11180, %11179"
"  %11181 = add nuw nsw i32 %11180, %11179"
"  %11181 = add nuw nsw i32 %11180, %11179" -> "  %11289 = and i32 %11181, 65535""  %11181 = add nuw nsw i32 %11180, %11179" -> "  %11185 = lshr i32 %11181, 16"
"  %11182 = and i32 %11149, 65535"
"  %11182 = and i32 %11149, 65535" -> "  %11184 = add nuw nsw i32 %11183, %11182"
"  %11183 = and i32 %11011, 65535"
"  %11183 = and i32 %11011, 65535" -> "  %11184 = add nuw nsw i32 %11183, %11182"
"  %11184 = add nuw nsw i32 %11183, %11182"
"  %11184 = add nuw nsw i32 %11183, %11182" -> "  %11198 = lshr i32 %11184, 16""  %11184 = add nuw nsw i32 %11183, %11182" -> "  %11186 = and i32 %11184, 65535"
"  %11185 = lshr i32 %11181, 16"
"  %11185 = lshr i32 %11181, 16" -> "  %11187 = add nuw nsw i32 %11186, %11185"
"  %11186 = and i32 %11184, 65535"
"  %11186 = and i32 %11184, 65535" -> "  %11187 = add nuw nsw i32 %11186, %11185"
"  %11187 = add nuw nsw i32 %11186, %11185"
"  %11187 = add nuw nsw i32 %11186, %11185" -> "  %11294 = and i32 %11187, 65535""  %11187 = add nuw nsw i32 %11186, %11185" -> "  %11199 = lshr i32 %11187, 16"
"  %11188 = and i32 %11163, 65535"
"  %11188 = and i32 %11163, 65535" -> "  %11190 = add nuw nsw i32 %11189, %11188"
"  %11189 = and i32 %11013, 65535"
"  %11189 = and i32 %11013, 65535" -> "  %11190 = add nuw nsw i32 %11189, %11188"
"  %11190 = add nuw nsw i32 %11189, %11188"
"  %11190 = add nuw nsw i32 %11189, %11188" -> "  %11197 = and i32 %11190, 65535""  %11190 = add nuw nsw i32 %11189, %11188" -> "  %11194 = lshr i32 %11190, 16"
"  %11191 = and i32 %11166, 65535"
"  %11191 = and i32 %11166, 65535" -> "  %11193 = add nuw nsw i32 %11191, %11192"
"  %11192 = lshr i32 %11013, 16"
"  %11192 = lshr i32 %11013, 16" -> "  %11193 = add nuw nsw i32 %11191, %11192"
"  %11193 = add nuw nsw i32 %11191, %11192"
"  %11193 = add nuw nsw i32 %11191, %11192" -> "  %11206 = lshr i32 %11193, 16""  %11193 = add nuw nsw i32 %11191, %11192" -> "  %11195 = and i32 %11193, 65535"
"  %11194 = lshr i32 %11190, 16"
"  %11194 = lshr i32 %11190, 16" -> "  %11196 = add nuw nsw i32 %11195, %11194"
"  %11195 = and i32 %11193, 65535"
"  %11195 = and i32 %11193, 65535" -> "  %11196 = add nuw nsw i32 %11195, %11194"
"  %11196 = add nuw nsw i32 %11195, %11194"
"  %11196 = add nuw nsw i32 %11195, %11194" -> "  %11208 = lshr i32 %11196, 16""  %11196 = add nuw nsw i32 %11195, %11194" -> "  %11203 = and i32 %11196, 65535"
"  %11197 = and i32 %11190, 65535"
"  %11197 = and i32 %11190, 65535" -> "  %11201 = add nuw nsw i32 %11200, %11197"
"  %11198 = lshr i32 %11184, 16"
"  %11198 = lshr i32 %11184, 16" -> "  %11200 = add nuw nsw i32 %11199, %11198"
"  %11199 = lshr i32 %11187, 16"
"  %11199 = lshr i32 %11187, 16" -> "  %11200 = add nuw nsw i32 %11199, %11198"
"  %11200 = add nuw nsw i32 %11199, %11198"
"  %11200 = add nuw nsw i32 %11199, %11198" -> "  %11201 = add nuw nsw i32 %11200, %11197"
"  %11201 = add nuw nsw i32 %11200, %11197"
"  %11201 = add nuw nsw i32 %11200, %11197" -> "  %11297 = and i32 %11201, 65535""  %11201 = add nuw nsw i32 %11200, %11197" -> "  %11202 = lshr i32 %11201, 16"
"  %11202 = lshr i32 %11201, 16"
"  %11202 = lshr i32 %11201, 16" -> "  %11204 = add nuw nsw i32 %11203, %11202"
"  %11203 = and i32 %11196, 65535"
"  %11203 = and i32 %11196, 65535" -> "  %11204 = add nuw nsw i32 %11203, %11202"
"  %11204 = add nuw nsw i32 %11203, %11202"
"  %11204 = add nuw nsw i32 %11203, %11202" -> "  %11301 = and i32 %11204, 65535""  %11204 = add nuw nsw i32 %11203, %11202" -> "  %11210 = lshr i32 %11204, 16"
"  %11205 = and i32 %11173, 65535"
"  %11205 = and i32 %11173, 65535" -> "  %11207 = add nuw nsw i32 %11206, %11205"
"  %11206 = lshr i32 %11193, 16"
"  %11206 = lshr i32 %11193, 16" -> "  %11207 = add nuw nsw i32 %11206, %11205"
"  %11207 = add nuw nsw i32 %11206, %11205"
"  %11207 = add nuw nsw i32 %11206, %11205" -> "  %11209 = add nuw nsw i32 %11207, %11208"
"  %11208 = lshr i32 %11196, 16"
"  %11208 = lshr i32 %11196, 16" -> "  %11209 = add nuw nsw i32 %11207, %11208"
"  %11209 = add nuw nsw i32 %11207, %11208"
"  %11209 = add nuw nsw i32 %11207, %11208" -> "  %11211 = add nuw nsw i32 %11209, %11210"
"  %11210 = lshr i32 %11204, 16"
"  %11210 = lshr i32 %11204, 16" -> "  %11211 = add nuw nsw i32 %11209, %11210"
"  %11211 = add nuw nsw i32 %11209, %11210"
"  %11211 = add nuw nsw i32 %11209, %11210" -> "  %11304 = and i32 %11211, 65535""  %11211 = add nuw nsw i32 %11209, %11210" -> "  %11213 = lshr i32 %11211, 16"
"  %11212 = and i32 %11176, 65535"
"  %11212 = and i32 %11176, 65535" -> "  %11214 = add nuw nsw i32 %11213, %11212"
"  %11213 = lshr i32 %11211, 16"
"  %11213 = lshr i32 %11211, 16" -> "  %11214 = add nuw nsw i32 %11213, %11212"
"  %11214 = add nuw nsw i32 %11213, %11212"
"  %11214 = add nuw nsw i32 %11213, %11212" -> "  %11307 = and i32 %11214, 65535""  %11214 = add nuw nsw i32 %11213, %11212" -> "  %11215 = lshr i32 %11214, 16"
"  %11215 = lshr i32 %11214, 16"
"  %11215 = lshr i32 %11214, 16" -> "  %11216 = add nuw i32 %11178, %11215"
"  %11216 = add nuw i32 %11178, %11215"
"  %11216 = add nuw i32 %11178, %11215" -> "  %11310 = add nuw i32 %11216, %11309"
"  %11217 = and i32 %10468, 65535"
"  %11217 = and i32 %10468, 65535" -> "  %11219 = add nuw nsw i32 %11217, %11218"
"  %11218 = and i32 %10560, 65535"
"  %11218 = and i32 %10560, 65535" -> "  %11219 = add nuw nsw i32 %11217, %11218"
"  %11219 = add nuw nsw i32 %11217, %11218"
"  %11219 = add nuw nsw i32 %11217, %11218" -> "  %11223 = lshr i32 %11219, 16"
"  %11220 = and i32 %10474, 65535"
"  %11220 = and i32 %10474, 65535" -> "  %11222 = add nuw nsw i32 %11220, %11221"
"  %11221 = and i32 %10569, 65535"
"  %11221 = and i32 %10569, 65535" -> "  %11222 = add nuw nsw i32 %11220, %11221"
"  %11222 = add nuw nsw i32 %11220, %11221"
"  %11222 = add nuw nsw i32 %11220, %11221" -> "  %11226 = lshr i32 %11222, 16""  %11222 = add nuw nsw i32 %11220, %11221" -> "  %11224 = and i32 %11222, 65535"
"  %11223 = lshr i32 %11219, 16"
"  %11223 = lshr i32 %11219, 16" -> "  %11225 = add nuw nsw i32 %11224, %11223"
"  %11224 = and i32 %11222, 65535"
"  %11224 = and i32 %11222, 65535" -> "  %11225 = add nuw nsw i32 %11224, %11223"
"  %11225 = add nuw nsw i32 %11224, %11223"
"  %11225 = add nuw nsw i32 %11224, %11223" -> "  %11227 = lshr i32 %11225, 16"
"  %11226 = lshr i32 %11222, 16"
"  %11226 = lshr i32 %11222, 16" -> "  %11228 = add nuw nsw i32 %11227, %11226"
"  %11227 = lshr i32 %11225, 16"
"  %11227 = lshr i32 %11225, 16" -> "  %11228 = add nuw nsw i32 %11227, %11226"
"  %11228 = add nuw nsw i32 %11227, %11226"
"  %11228 = add nuw nsw i32 %11227, %11226" -> "  %11239 = add nuw nsw i32 %11228, %11238"
"  %11229 = and i32 %10488, 65535"
"  %11229 = and i32 %10488, 65535" -> "  %11231 = add nuw nsw i32 %11229, %11230"
"  %11230 = and i32 %10629, 65535"
"  %11230 = and i32 %10629, 65535" -> "  %11231 = add nuw nsw i32 %11229, %11230"
"  %11231 = add nuw nsw i32 %11229, %11230"
"  %11231 = add nuw nsw i32 %11229, %11230" -> "  %11238 = and i32 %11231, 65535""  %11231 = add nuw nsw i32 %11229, %11230" -> "  %11235 = lshr i32 %11231, 16"
"  %11232 = and i32 %10491, 65535"
"  %11232 = and i32 %10491, 65535" -> "  %11234 = add nuw nsw i32 %11232, %11233"
"  %11233 = and i32 %10637, 65535"
"  %11233 = and i32 %10637, 65535" -> "  %11234 = add nuw nsw i32 %11232, %11233"
"  %11234 = add nuw nsw i32 %11232, %11233"
"  %11234 = add nuw nsw i32 %11232, %11233" -> "  %11273 = lshr i32 %11234, 16""  %11234 = add nuw nsw i32 %11232, %11233" -> "  %11236 = and i32 %11234, 65535"
"  %11235 = lshr i32 %11231, 16"
"  %11235 = lshr i32 %11231, 16" -> "  %11237 = add nuw nsw i32 %11236, %11235"
"  %11236 = and i32 %11234, 65535"
"  %11236 = and i32 %11234, 65535" -> "  %11237 = add nuw nsw i32 %11236, %11235"
"  %11237 = add nuw nsw i32 %11236, %11235"
"  %11237 = add nuw nsw i32 %11236, %11235" -> "  %11241 = and i32 %11237, 65535""  %11237 = add nuw nsw i32 %11236, %11235" -> "  %11274 = lshr i32 %11237, 16"
"  %11238 = and i32 %11231, 65535"
"  %11238 = and i32 %11231, 65535" -> "  %11239 = add nuw nsw i32 %11228, %11238"
"  %11239 = add nuw nsw i32 %11228, %11238"
"  %11239 = add nuw nsw i32 %11228, %11238" -> "  %11240 = lshr i32 %11239, 16"
"  %11240 = lshr i32 %11239, 16"
"  %11240 = lshr i32 %11239, 16" -> "  %11242 = add nuw nsw i32 %11241, %11240"
"  %11241 = and i32 %11237, 65535"
"  %11241 = and i32 %11237, 65535" -> "  %11242 = add nuw nsw i32 %11241, %11240"
"  %11242 = add nuw nsw i32 %11241, %11240"
"  %11242 = add nuw nsw i32 %11241, %11240" -> "  %11275 = lshr i32 %11242, 16"
"  %11243 = and i32 %10528, 65535"
"  %11243 = and i32 %10528, 65535" -> "  %11245 = add nuw nsw i32 %11243, %11244"
"  %11244 = and i32 %10978, 65535"
"  %11244 = and i32 %10978, 65535" -> "  %11245 = add nuw nsw i32 %11243, %11244"
"  %11245 = add nuw nsw i32 %11243, %11244"
"  %11245 = add nuw nsw i32 %11243, %11244" -> "  %11272 = and i32 %11245, 65535""  %11245 = add nuw nsw i32 %11243, %11244" -> "  %11249 = lshr i32 %11245, 16"
"  %11246 = and i32 %10531, 65535"
"  %11246 = and i32 %10531, 65535" -> "  %11248 = add nuw nsw i32 %11246, %11247"
"  %11247 = and i32 %10984, 65535"
"  %11247 = and i32 %10984, 65535" -> "  %11248 = add nuw nsw i32 %11246, %11247"
"  %11248 = add nuw nsw i32 %11246, %11247"
"  %11248 = add nuw nsw i32 %11246, %11247" -> "  %11252 = lshr i32 %11248, 16""  %11248 = add nuw nsw i32 %11246, %11247" -> "  %11250 = and i32 %11248, 65535"
"  %11249 = lshr i32 %11245, 16"
"  %11249 = lshr i32 %11245, 16" -> "  %11251 = add nuw nsw i32 %11250, %11249"
"  %11250 = and i32 %11248, 65535"
"  %11250 = and i32 %11248, 65535" -> "  %11251 = add nuw nsw i32 %11250, %11249"
"  %11251 = add nuw nsw i32 %11250, %11249"
"  %11251 = add nuw nsw i32 %11250, %11249" -> "  %11279 = and i32 %11251, 65535""  %11251 = add nuw nsw i32 %11250, %11249" -> "  %11253 = lshr i32 %11251, 16"
"  %11252 = lshr i32 %11248, 16"
"  %11252 = lshr i32 %11248, 16" -> "  %11254 = add nuw nsw i32 %11253, %11252"
"  %11253 = lshr i32 %11251, 16"
"  %11253 = lshr i32 %11251, 16" -> "  %11254 = add nuw nsw i32 %11253, %11252"
"  %11254 = add nuw nsw i32 %11253, %11252"
"  %11254 = add nuw nsw i32 %11253, %11252" -> "  %11267 = add nuw nsw i32 %11254, %11266"
"  %11255 = and i32 %10534, 65535"
"  %11255 = and i32 %10534, 65535" -> "  %11257 = add nuw nsw i32 %11255, %11256"
"  %11256 = and i32 %10998, 65535"
"  %11256 = and i32 %10998, 65535" -> "  %11257 = add nuw nsw i32 %11255, %11256"
"  %11257 = add nuw nsw i32 %11255, %11256"
"  %11257 = add nuw nsw i32 %11255, %11256" -> "  %11266 = and i32 %11257, 65535""  %11257 = add nuw nsw i32 %11255, %11256" -> "  %11261 = lshr i32 %11257, 16"
"  %11258 = and i32 %10537, 65535"
"  %11258 = and i32 %10537, 65535" -> "  %11260 = add nuw nsw i32 %11258, %11259"
"  %11259 = and i32 %11001, 65535"
"  %11259 = and i32 %11001, 65535" -> "  %11260 = add nuw nsw i32 %11258, %11259"
"  %11260 = add nuw nsw i32 %11258, %11259"
"  %11260 = add nuw nsw i32 %11258, %11259" -> "  %11264 = lshr i32 %11260, 16""  %11260 = add nuw nsw i32 %11258, %11259" -> "  %11262 = and i32 %11260, 65535"
"  %11261 = lshr i32 %11257, 16"
"  %11261 = lshr i32 %11257, 16" -> "  %11263 = add nuw nsw i32 %11262, %11261"
"  %11262 = and i32 %11260, 65535"
"  %11262 = and i32 %11260, 65535" -> "  %11263 = add nuw nsw i32 %11262, %11261"
"  %11263 = add nuw nsw i32 %11262, %11261"
"  %11263 = add nuw nsw i32 %11262, %11261" -> "  %11268 = and i32 %11263, 65535""  %11263 = add nuw nsw i32 %11262, %11261" -> "  %11265 = lshr i32 %11263, 16"
"  %11264 = lshr i32 %11260, 16"
"  %11264 = lshr i32 %11260, 16" -> "  %11290 = add nuw nsw i32 %11264, %11289"
"  %11265 = lshr i32 %11263, 16"
"  %11265 = lshr i32 %11263, 16" -> "  %11291 = add nuw nsw i32 %11290, %11265"
"  %11266 = and i32 %11257, 65535"
"  %11266 = and i32 %11257, 65535" -> "  %11267 = add nuw nsw i32 %11254, %11266"
"  %11267 = add nuw nsw i32 %11254, %11266"
"  %11267 = add nuw nsw i32 %11254, %11266" -> "  %11282 = and i32 %11267, 65535""  %11267 = add nuw nsw i32 %11254, %11266" -> "  %11269 = lshr i32 %11267, 16"
"  %11268 = and i32 %11263, 65535"
"  %11268 = and i32 %11263, 65535" -> "  %11270 = add nuw nsw i32 %11268, %11269"
"  %11269 = lshr i32 %11267, 16"
"  %11269 = lshr i32 %11267, 16" -> "  %11270 = add nuw nsw i32 %11268, %11269"
"  %11270 = add nuw nsw i32 %11268, %11269"
"  %11270 = add nuw nsw i32 %11268, %11269" -> "  %11285 = and i32 %11270, 65535""  %11270 = add nuw nsw i32 %11268, %11269" -> "  %11271 = lshr i32 %11270, 16"
"  %11271 = lshr i32 %11270, 16"
"  %11271 = lshr i32 %11270, 16" -> "  %11292 = add nuw nsw i32 %11291, %11271"
"  %11272 = and i32 %11245, 65535"
"  %11272 = and i32 %11245, 65535" -> "  %11277 = add nuw nsw i32 %11276, %11272"
"  %11273 = lshr i32 %11234, 16"
"  %11273 = lshr i32 %11234, 16" -> "  %11276 = add nuw nsw i32 %11274, %11273"
"  %11274 = lshr i32 %11237, 16"
"  %11274 = lshr i32 %11237, 16" -> "  %11276 = add nuw nsw i32 %11274, %11273"
"  %11275 = lshr i32 %11242, 16"
"  %11275 = lshr i32 %11242, 16" -> "  %11278 = add nuw nsw i32 %11277, %11275"
"  %11276 = add nuw nsw i32 %11274, %11273"
"  %11276 = add nuw nsw i32 %11274, %11273" -> "  %11277 = add nuw nsw i32 %11276, %11272"
"  %11277 = add nuw nsw i32 %11276, %11272"
"  %11277 = add nuw nsw i32 %11276, %11272" -> "  %11278 = add nuw nsw i32 %11277, %11275"
"  %11278 = add nuw nsw i32 %11277, %11275"
"  %11278 = add nuw nsw i32 %11277, %11275" -> "  %11280 = lshr i32 %11278, 16"
"  %11279 = and i32 %11251, 65535"
"  %11279 = and i32 %11251, 65535" -> "  %11281 = add nuw nsw i32 %11280, %11279"
"  %11280 = lshr i32 %11278, 16"
"  %11280 = lshr i32 %11278, 16" -> "  %11281 = add nuw nsw i32 %11280, %11279"
"  %11281 = add nuw nsw i32 %11280, %11279"
"  %11281 = add nuw nsw i32 %11280, %11279" -> "  %11283 = lshr i32 %11281, 16"
"  %11282 = and i32 %11267, 65535"
"  %11282 = and i32 %11267, 65535" -> "  %11284 = add nuw nsw i32 %11282, %11283"
"  %11283 = lshr i32 %11281, 16"
"  %11283 = lshr i32 %11281, 16" -> "  %11284 = add nuw nsw i32 %11282, %11283"
"  %11284 = add nuw nsw i32 %11282, %11283"
"  %11284 = add nuw nsw i32 %11282, %11283" -> "  %11286 = lshr i32 %11284, 16"
"  %11285 = and i32 %11270, 65535"
"  %11285 = and i32 %11270, 65535" -> "  %11287 = add nuw nsw i32 %11285, %11286"
"  %11286 = lshr i32 %11284, 16"
"  %11286 = lshr i32 %11284, 16" -> "  %11287 = add nuw nsw i32 %11285, %11286"
"  %11287 = add nuw nsw i32 %11285, %11286"
"  %11287 = add nuw nsw i32 %11285, %11286" -> "  %11288 = lshr i32 %11287, 16"
"  %11288 = lshr i32 %11287, 16"
"  %11288 = lshr i32 %11287, 16" -> "  %11293 = add nuw nsw i32 %11292, %11288"
"  %11289 = and i32 %11181, 65535"
"  %11289 = and i32 %11181, 65535" -> "  %11290 = add nuw nsw i32 %11264, %11289"
"  %11290 = add nuw nsw i32 %11264, %11289"
"  %11290 = add nuw nsw i32 %11264, %11289" -> "  %11291 = add nuw nsw i32 %11290, %11265"
"  %11291 = add nuw nsw i32 %11290, %11265"
"  %11291 = add nuw nsw i32 %11290, %11265" -> "  %11292 = add nuw nsw i32 %11291, %11271"
"  %11292 = add nuw nsw i32 %11291, %11271"
"  %11292 = add nuw nsw i32 %11291, %11271" -> "  %11293 = add nuw nsw i32 %11292, %11288"
"  %11293 = add nuw nsw i32 %11292, %11288"
"  %11293 = add nuw nsw i32 %11292, %11288" -> "  %12065 = and i32 %11293, 65535""  %11293 = add nuw nsw i32 %11292, %11288" -> "  %11295 = lshr i32 %11293, 16"
"  %11294 = and i32 %11187, 65535"
"  %11294 = and i32 %11187, 65535" -> "  %11296 = add nuw nsw i32 %11295, %11294"
"  %11295 = lshr i32 %11293, 16"
"  %11295 = lshr i32 %11293, 16" -> "  %11296 = add nuw nsw i32 %11295, %11294"
"  %11296 = add nuw nsw i32 %11295, %11294"
"  %11296 = add nuw nsw i32 %11295, %11294" -> "  %12068 = and i32 %11296, 65535""  %11296 = add nuw nsw i32 %11295, %11294" -> "  %11298 = lshr i32 %11296, 16"
"  %11297 = and i32 %11201, 65535"
"  %11297 = and i32 %11201, 65535" -> "  %11299 = add nuw nsw i32 %11298, %11297"
"  %11298 = lshr i32 %11296, 16"
"  %11298 = lshr i32 %11296, 16" -> "  %11299 = add nuw nsw i32 %11298, %11297"
"  %11299 = add nuw nsw i32 %11298, %11297"
"  %11299 = add nuw nsw i32 %11298, %11297" -> "  %12074 = and i32 %11299, 65535""  %11299 = add nuw nsw i32 %11298, %11297" -> "  %11300 = lshr i32 %11299, 16"
"  %11300 = lshr i32 %11299, 16"
"  %11300 = lshr i32 %11299, 16" -> "  %11302 = add nuw nsw i32 %11300, %11301"
"  %11301 = and i32 %11204, 65535"
"  %11301 = and i32 %11204, 65535" -> "  %11302 = add nuw nsw i32 %11300, %11301"
"  %11302 = add nuw nsw i32 %11300, %11301"
"  %11302 = add nuw nsw i32 %11300, %11301" -> "  %12077 = and i32 %11302, 65535""  %11302 = add nuw nsw i32 %11300, %11301" -> "  %11303 = lshr i32 %11302, 16"
"  %11303 = lshr i32 %11302, 16"
"  %11303 = lshr i32 %11302, 16" -> "  %11305 = add nuw nsw i32 %11303, %11304"
"  %11304 = and i32 %11211, 65535"
"  %11304 = and i32 %11211, 65535" -> "  %11305 = add nuw nsw i32 %11303, %11304"
"  %11305 = add nuw nsw i32 %11303, %11304"
"  %11305 = add nuw nsw i32 %11303, %11304" -> "  %12091 = and i32 %11305, 65535""  %11305 = add nuw nsw i32 %11303, %11304" -> "  %11306 = lshr i32 %11305, 16"
"  %11306 = lshr i32 %11305, 16"
"  %11306 = lshr i32 %11305, 16" -> "  %11308 = add nuw nsw i32 %11306, %11307"
"  %11307 = and i32 %11214, 65535"
"  %11307 = and i32 %11214, 65535" -> "  %11308 = add nuw nsw i32 %11306, %11307"
"  %11308 = add nuw nsw i32 %11306, %11307"
"  %11308 = add nuw nsw i32 %11306, %11307" -> "  %12094 = and i32 %11308, 65535""  %11308 = add nuw nsw i32 %11306, %11307" -> "  %11309 = lshr i32 %11308, 16"
"  %11309 = lshr i32 %11308, 16"
"  %11309 = lshr i32 %11308, 16" -> "  %11310 = add nuw i32 %11216, %11309"
"  %11310 = add nuw i32 %11216, %11309"
"  %11310 = add nuw i32 %11216, %11309" -> "  %12100 = and i32 %11310, 65535""  %11310 = add nuw i32 %11216, %11309" -> "  %12103 = lshr i32 %11310, 16"
"  %11311 = mul nuw i32 %9798, 42779"
"  %11311 = mul nuw i32 %9798, 42779" -> "  %11972 = and i32 %11311, 65535""  %11311 = mul nuw i32 %9798, 42779" -> "  %11312 = lshr i32 %11311, 16"
"  %11312 = lshr i32 %11311, 16"
"  %11312 = lshr i32 %11311, 16" -> "  %11315 = add nuw nsw i32 %11314, %11312"
"  %11313 = mul nuw i32 %9799, 42779"
"  %11313 = mul nuw i32 %9799, 42779" -> "  %11316 = and i32 %11313, -65536""  %11313 = mul nuw i32 %9799, 42779" -> "  %11314 = and i32 %11313, 65535"
"  %11314 = and i32 %11313, 65535"
"  %11314 = and i32 %11313, 65535" -> "  %11315 = add nuw nsw i32 %11314, %11312"
"  %11315 = add nuw nsw i32 %11314, %11312"
"  %11315 = add nuw nsw i32 %11314, %11312" -> "  %11317 = add nuw i32 %11315, %11316"
"  %11316 = and i32 %11313, -65536"
"  %11316 = and i32 %11313, -65536" -> "  %11317 = add nuw i32 %11315, %11316"
"  %11317 = add nuw i32 %11315, %11316"
"  %11317 = add nuw i32 %11315, %11316" -> "  %11321 = lshr i32 %11317, 16""  %11317 = add nuw i32 %11315, %11316" -> "  %11319 = and i32 %11317, 65535"
"  %11318 = mul nuw nsw i32 %9798, 9871"
"  %11318 = mul nuw nsw i32 %9798, 9871" -> "  %11320 = add nuw nsw i32 %11319, %11318"
"  %11319 = and i32 %11317, 65535"
"  %11319 = and i32 %11317, 65535" -> "  %11320 = add nuw nsw i32 %11319, %11318"
"  %11320 = add nuw nsw i32 %11319, %11318"
"  %11320 = add nuw nsw i32 %11319, %11318" -> "  %11975 = and i32 %11320, 65535""  %11320 = add nuw nsw i32 %11319, %11318" -> "  %11324 = lshr i32 %11320, 16"
"  %11321 = lshr i32 %11317, 16"
"  %11321 = lshr i32 %11317, 16" -> "  %11323 = add nuw nsw i32 %11321, %11322"
"  %11322 = mul nuw nsw i32 %9799, 9871"
"  %11322 = mul nuw nsw i32 %9799, 9871" -> "  %11323 = add nuw nsw i32 %11321, %11322"
"  %11323 = add nuw nsw i32 %11321, %11322"
"  %11323 = add nuw nsw i32 %11321, %11322" -> "  %11327 = and i32 %11323, 2147418112""  %11323 = add nuw nsw i32 %11321, %11322" -> "  %11325 = and i32 %11323, 65535"
"  %11324 = lshr i32 %11320, 16"
"  %11324 = lshr i32 %11320, 16" -> "  %11326 = add nuw nsw i32 %11324, %11325"
"  %11325 = and i32 %11323, 65535"
"  %11325 = and i32 %11323, 65535" -> "  %11326 = add nuw nsw i32 %11324, %11325"
"  %11326 = add nuw nsw i32 %11324, %11325"
"  %11326 = add nuw nsw i32 %11324, %11325" -> "  %11328 = add nuw nsw i32 %11326, %11327"
"  %11327 = and i32 %11323, 2147418112"
"  %11327 = and i32 %11323, 2147418112" -> "  %11328 = add nuw nsw i32 %11326, %11327"
"  %11328 = add nuw nsw i32 %11326, %11327"
"  %11328 = add nuw nsw i32 %11326, %11327" -> "  %11351 = lshr i32 %11328, 16""  %11328 = add nuw nsw i32 %11326, %11327" -> "  %11347 = and i32 %11328, 65535"
"  %11329 = mul nuw i32 %9819, 42779"
"  %11329 = mul nuw i32 %9819, 42779" -> "  %11348 = and i32 %11329, 65535""  %11329 = mul nuw i32 %9819, 42779" -> "  %11330 = lshr i32 %11329, 16"
"  %11330 = lshr i32 %11329, 16"
"  %11330 = lshr i32 %11329, 16" -> "  %11333 = add nuw nsw i32 %11332, %11330"
"  %11331 = mul nuw i32 %9818, 42779"
"  %11331 = mul nuw i32 %9818, 42779" -> "  %11334 = and i32 %11331, -65536""  %11331 = mul nuw i32 %9818, 42779" -> "  %11332 = and i32 %11331, 65535"
"  %11332 = and i32 %11331, 65535"
"  %11332 = and i32 %11331, 65535" -> "  %11333 = add nuw nsw i32 %11332, %11330"
"  %11333 = add nuw nsw i32 %11332, %11330"
"  %11333 = add nuw nsw i32 %11332, %11330" -> "  %11335 = add nuw i32 %11333, %11334"
"  %11334 = and i32 %11331, -65536"
"  %11334 = and i32 %11331, -65536" -> "  %11335 = add nuw i32 %11333, %11334"
"  %11335 = add nuw i32 %11333, %11334"
"  %11335 = add nuw i32 %11333, %11334" -> "  %11339 = lshr i32 %11335, 16""  %11335 = add nuw i32 %11333, %11334" -> "  %11337 = and i32 %11335, 65535"
"  %11336 = mul nuw nsw i32 %9819, 9871"
"  %11336 = mul nuw nsw i32 %9819, 9871" -> "  %11338 = add nuw nsw i32 %11337, %11336"
"  %11337 = and i32 %11335, 65535"
"  %11337 = and i32 %11335, 65535" -> "  %11338 = add nuw nsw i32 %11337, %11336"
"  %11338 = add nuw nsw i32 %11337, %11336"
"  %11338 = add nuw nsw i32 %11337, %11336" -> "  %11350 = and i32 %11338, 65535""  %11338 = add nuw nsw i32 %11337, %11336" -> "  %11342 = lshr i32 %11338, 16"
"  %11339 = lshr i32 %11335, 16"
"  %11339 = lshr i32 %11335, 16" -> "  %11341 = add nuw nsw i32 %11339, %11340"
"  %11340 = mul nuw nsw i32 %9818, 9871"
"  %11340 = mul nuw nsw i32 %9818, 9871" -> "  %11341 = add nuw nsw i32 %11339, %11340"
"  %11341 = add nuw nsw i32 %11339, %11340"
"  %11341 = add nuw nsw i32 %11339, %11340" -> "  %11345 = and i32 %11341, 2147418112""  %11341 = add nuw nsw i32 %11339, %11340" -> "  %11343 = and i32 %11341, 65535"
"  %11342 = lshr i32 %11338, 16"
"  %11342 = lshr i32 %11338, 16" -> "  %11344 = add nuw nsw i32 %11342, %11343"
"  %11343 = and i32 %11341, 65535"
"  %11343 = and i32 %11341, 65535" -> "  %11344 = add nuw nsw i32 %11342, %11343"
"  %11344 = add nuw nsw i32 %11342, %11343"
"  %11344 = add nuw nsw i32 %11342, %11343" -> "  %11346 = add nuw nsw i32 %11344, %11345"
"  %11345 = and i32 %11341, 2147418112"
"  %11345 = and i32 %11341, 2147418112" -> "  %11346 = add nuw nsw i32 %11344, %11345"
"  %11346 = add nuw nsw i32 %11344, %11345"
"  %11346 = add nuw nsw i32 %11344, %11345" -> "  %11354 = add nuw nsw i32 %11346, %11353"
"  %11347 = and i32 %11328, 65535"
"  %11347 = and i32 %11328, 65535" -> "  %11349 = add nuw nsw i32 %11347, %11348"
"  %11348 = and i32 %11329, 65535"
"  %11348 = and i32 %11329, 65535" -> "  %11349 = add nuw nsw i32 %11347, %11348"
"  %11349 = add nuw nsw i32 %11347, %11348"
"  %11349 = add nuw nsw i32 %11347, %11348" -> "  %11378 = and i32 %11349, 65535""  %11349 = add nuw nsw i32 %11347, %11348" -> "  %11356 = lshr i32 %11349, 16"
"  %11350 = and i32 %11338, 65535"
"  %11350 = and i32 %11338, 65535" -> "  %11352 = add nuw nsw i32 %11350, %11351"
"  %11351 = lshr i32 %11328, 16"
"  %11351 = lshr i32 %11328, 16" -> "  %11352 = add nuw nsw i32 %11350, %11351"
"  %11352 = add nuw nsw i32 %11350, %11351"
"  %11352 = add nuw nsw i32 %11350, %11351" -> "  %11355 = and i32 %11352, 65535""  %11352 = add nuw nsw i32 %11350, %11351" -> "  %11353 = lshr i32 %11352, 16"
"  %11353 = lshr i32 %11352, 16"
"  %11353 = lshr i32 %11352, 16" -> "  %11354 = add nuw nsw i32 %11346, %11353"
"  %11354 = add nuw nsw i32 %11346, %11353"
"  %11354 = add nuw nsw i32 %11346, %11353" -> "  %11359 = add nuw nsw i32 %11354, %11358"
"  %11355 = and i32 %11352, 65535"
"  %11355 = and i32 %11352, 65535" -> "  %11357 = add nuw nsw i32 %11355, %11356"
"  %11356 = lshr i32 %11349, 16"
"  %11356 = lshr i32 %11349, 16" -> "  %11357 = add nuw nsw i32 %11355, %11356"
"  %11357 = add nuw nsw i32 %11355, %11356"
"  %11357 = add nuw nsw i32 %11355, %11356" -> "  %11381 = and i32 %11357, 65535""  %11357 = add nuw nsw i32 %11355, %11356" -> "  %11358 = lshr i32 %11357, 16"
"  %11358 = lshr i32 %11357, 16"
"  %11358 = lshr i32 %11357, 16" -> "  %11359 = add nuw nsw i32 %11354, %11358"
"  %11359 = add nuw nsw i32 %11354, %11358"
"  %11359 = add nuw nsw i32 %11354, %11358" -> "  %11409 = and i32 %11359, 65535""  %11359 = add nuw nsw i32 %11354, %11358" -> "  %11413 = lshr i32 %11359, 16"
"  %11360 = mul nuw nsw i32 %9798, 24315"
"  %11360 = mul nuw nsw i32 %9798, 24315" -> "  %11379 = and i32 %11360, 65535""  %11360 = mul nuw nsw i32 %9798, 24315" -> "  %11361 = lshr i32 %11360, 16"
"  %11361 = lshr i32 %11360, 16"
"  %11361 = lshr i32 %11360, 16" -> "  %11364 = add nuw nsw i32 %11363, %11361"
"  %11362 = mul nuw nsw i32 %9799, 24315"
"  %11362 = mul nuw nsw i32 %9799, 24315" -> "  %11365 = and i32 %11362, 2147418112""  %11362 = mul nuw nsw i32 %9799, 24315" -> "  %11363 = and i32 %11362, 65535"
"  %11363 = and i32 %11362, 65535"
"  %11363 = and i32 %11362, 65535" -> "  %11364 = add nuw nsw i32 %11363, %11361"
"  %11364 = add nuw nsw i32 %11363, %11361"
"  %11364 = add nuw nsw i32 %11363, %11361" -> "  %11366 = add nuw nsw i32 %11364, %11365"
"  %11365 = and i32 %11362, 2147418112"
"  %11365 = and i32 %11362, 2147418112" -> "  %11366 = add nuw nsw i32 %11364, %11365"
"  %11366 = add nuw nsw i32 %11364, %11365"
"  %11366 = add nuw nsw i32 %11364, %11365" -> "  %11370 = lshr i32 %11366, 16""  %11366 = add nuw nsw i32 %11364, %11365" -> "  %11368 = and i32 %11366, 65535"
"  %11367 = mul nuw nsw i32 %9798, 29744"
"  %11367 = mul nuw nsw i32 %9798, 29744" -> "  %11369 = add nuw nsw i32 %11368, %11367"
"  %11368 = and i32 %11366, 65535"
"  %11368 = and i32 %11366, 65535" -> "  %11369 = add nuw nsw i32 %11368, %11367"
"  %11369 = add nuw nsw i32 %11368, %11367"
"  %11369 = add nuw nsw i32 %11368, %11367" -> "  %11382 = and i32 %11369, 65535""  %11369 = add nuw nsw i32 %11368, %11367" -> "  %11373 = lshr i32 %11369, 16"
"  %11370 = lshr i32 %11366, 16"
"  %11370 = lshr i32 %11366, 16" -> "  %11372 = add nuw nsw i32 %11370, %11371"
"  %11371 = mul nuw nsw i32 %9799, 29744"
"  %11371 = mul nuw nsw i32 %9799, 29744" -> "  %11372 = add nuw nsw i32 %11370, %11371"
"  %11372 = add nuw nsw i32 %11370, %11371"
"  %11372 = add nuw nsw i32 %11370, %11371" -> "  %11376 = and i32 %11372, 2147418112""  %11372 = add nuw nsw i32 %11370, %11371" -> "  %11374 = and i32 %11372, 65535"
"  %11373 = lshr i32 %11369, 16"
"  %11373 = lshr i32 %11369, 16" -> "  %11375 = add nuw nsw i32 %11373, %11374"
"  %11374 = and i32 %11372, 65535"
"  %11374 = and i32 %11372, 65535" -> "  %11375 = add nuw nsw i32 %11373, %11374"
"  %11375 = add nuw nsw i32 %11373, %11374"
"  %11375 = add nuw nsw i32 %11373, %11374" -> "  %11377 = add nuw nsw i32 %11375, %11376"
"  %11376 = and i32 %11372, 2147418112"
"  %11376 = and i32 %11372, 2147418112" -> "  %11377 = add nuw nsw i32 %11375, %11376"
"  %11377 = add nuw nsw i32 %11375, %11376"
"  %11377 = add nuw nsw i32 %11375, %11376" -> "  %11385 = add nuw nsw i32 %11377, %11384"
"  %11378 = and i32 %11349, 65535"
"  %11378 = and i32 %11349, 65535" -> "  %11380 = add nuw nsw i32 %11378, %11379"
"  %11379 = and i32 %11360, 65535"
"  %11379 = and i32 %11360, 65535" -> "  %11380 = add nuw nsw i32 %11378, %11379"
"  %11380 = add nuw nsw i32 %11378, %11379"
"  %11380 = add nuw nsw i32 %11378, %11379" -> "  %11981 = and i32 %11380, 65535""  %11380 = add nuw nsw i32 %11378, %11379" -> "  %11387 = lshr i32 %11380, 16"
"  %11381 = and i32 %11357, 65535"
"  %11381 = and i32 %11357, 65535" -> "  %11383 = add nuw nsw i32 %11381, %11382"
"  %11382 = and i32 %11369, 65535"
"  %11382 = and i32 %11369, 65535" -> "  %11383 = add nuw nsw i32 %11381, %11382"
"  %11383 = add nuw nsw i32 %11381, %11382"
"  %11383 = add nuw nsw i32 %11381, %11382" -> "  %11386 = and i32 %11383, 65535""  %11383 = add nuw nsw i32 %11381, %11382" -> "  %11384 = lshr i32 %11383, 16"
"  %11384 = lshr i32 %11383, 16"
"  %11384 = lshr i32 %11383, 16" -> "  %11385 = add nuw nsw i32 %11377, %11384"
"  %11385 = add nuw nsw i32 %11377, %11384"
"  %11385 = add nuw nsw i32 %11377, %11384" -> "  %11390 = add nuw nsw i32 %11385, %11389"
"  %11386 = and i32 %11383, 65535"
"  %11386 = and i32 %11383, 65535" -> "  %11388 = add nuw nsw i32 %11386, %11387"
"  %11387 = lshr i32 %11380, 16"
"  %11387 = lshr i32 %11380, 16" -> "  %11388 = add nuw nsw i32 %11386, %11387"
"  %11388 = add nuw nsw i32 %11386, %11387"
"  %11388 = add nuw nsw i32 %11386, %11387" -> "  %11984 = and i32 %11388, 65535""  %11388 = add nuw nsw i32 %11386, %11387" -> "  %11389 = lshr i32 %11388, 16"
"  %11389 = lshr i32 %11388, 16"
"  %11389 = lshr i32 %11388, 16" -> "  %11390 = add nuw nsw i32 %11385, %11389"
"  %11390 = add nuw nsw i32 %11385, %11389"
"  %11390 = add nuw nsw i32 %11385, %11389" -> "  %11423 = and i32 %11390, 65535""  %11390 = add nuw nsw i32 %11385, %11389" -> "  %11426 = lshr i32 %11390, 16"
"  %11391 = mul nuw nsw i32 %9819, 24315"
"  %11391 = mul nuw nsw i32 %9819, 24315" -> "  %11410 = and i32 %11391, 65535""  %11391 = mul nuw nsw i32 %9819, 24315" -> "  %11392 = lshr i32 %11391, 16"
"  %11392 = lshr i32 %11391, 16"
"  %11392 = lshr i32 %11391, 16" -> "  %11395 = add nuw nsw i32 %11394, %11392"
"  %11393 = mul nuw nsw i32 %9818, 24315"
"  %11393 = mul nuw nsw i32 %9818, 24315" -> "  %11396 = and i32 %11393, 2147418112""  %11393 = mul nuw nsw i32 %9818, 24315" -> "  %11394 = and i32 %11393, 65535"
"  %11394 = and i32 %11393, 65535"
"  %11394 = and i32 %11393, 65535" -> "  %11395 = add nuw nsw i32 %11394, %11392"
"  %11395 = add nuw nsw i32 %11394, %11392"
"  %11395 = add nuw nsw i32 %11394, %11392" -> "  %11397 = add nuw nsw i32 %11395, %11396"
"  %11396 = and i32 %11393, 2147418112"
"  %11396 = and i32 %11393, 2147418112" -> "  %11397 = add nuw nsw i32 %11395, %11396"
"  %11397 = add nuw nsw i32 %11395, %11396"
"  %11397 = add nuw nsw i32 %11395, %11396" -> "  %11399 = and i32 %11397, 65535""  %11397 = add nuw nsw i32 %11395, %11396" -> "  %11401 = lshr i32 %11397, 16"
"  %11398 = mul nuw nsw i32 %9819, 29744"
"  %11398 = mul nuw nsw i32 %9819, 29744" -> "  %11400 = add nuw nsw i32 %11399, %11398"
"  %11399 = and i32 %11397, 65535"
"  %11399 = and i32 %11397, 65535" -> "  %11400 = add nuw nsw i32 %11399, %11398"
"  %11400 = add nuw nsw i32 %11399, %11398"
"  %11400 = add nuw nsw i32 %11399, %11398" -> "  %11412 = and i32 %11400, 65535""  %11400 = add nuw nsw i32 %11399, %11398" -> "  %11404 = lshr i32 %11400, 16"
"  %11401 = lshr i32 %11397, 16"
"  %11401 = lshr i32 %11397, 16" -> "  %11403 = add nuw nsw i32 %11401, %11402"
"  %11402 = mul nuw nsw i32 %9818, 29744"
"  %11402 = mul nuw nsw i32 %9818, 29744" -> "  %11403 = add nuw nsw i32 %11401, %11402"
"  %11403 = add nuw nsw i32 %11401, %11402"
"  %11403 = add nuw nsw i32 %11401, %11402" -> "  %11407 = and i32 %11403, 2147418112""  %11403 = add nuw nsw i32 %11401, %11402" -> "  %11405 = and i32 %11403, 65535"
"  %11404 = lshr i32 %11400, 16"
"  %11404 = lshr i32 %11400, 16" -> "  %11406 = add nuw nsw i32 %11405, %11404"
"  %11405 = and i32 %11403, 65535"
"  %11405 = and i32 %11403, 65535" -> "  %11406 = add nuw nsw i32 %11405, %11404"
"  %11406 = add nuw nsw i32 %11405, %11404"
"  %11406 = add nuw nsw i32 %11405, %11404" -> "  %11408 = add nuw nsw i32 %11406, %11407"
"  %11407 = and i32 %11403, 2147418112"
"  %11407 = and i32 %11403, 2147418112" -> "  %11408 = add nuw nsw i32 %11406, %11407"
"  %11408 = add nuw nsw i32 %11406, %11407"
"  %11408 = add nuw nsw i32 %11406, %11407" -> "  %11416 = add nuw nsw i32 %11408, %11415"
"  %11409 = and i32 %11359, 65535"
"  %11409 = and i32 %11359, 65535" -> "  %11411 = add nuw nsw i32 %11409, %11410"
"  %11410 = and i32 %11391, 65535"
"  %11410 = and i32 %11391, 65535" -> "  %11411 = add nuw nsw i32 %11409, %11410"
"  %11411 = add nuw nsw i32 %11409, %11410"
"  %11411 = add nuw nsw i32 %11409, %11410" -> "  %11422 = and i32 %11411, 65535""  %11411 = add nuw nsw i32 %11409, %11410" -> "  %11418 = lshr i32 %11411, 16"
"  %11412 = and i32 %11400, 65535"
"  %11412 = and i32 %11400, 65535" -> "  %11414 = add nuw nsw i32 %11413, %11412"
"  %11413 = lshr i32 %11359, 16"
"  %11413 = lshr i32 %11359, 16" -> "  %11414 = add nuw nsw i32 %11413, %11412"
"  %11414 = add nuw nsw i32 %11413, %11412"
"  %11414 = add nuw nsw i32 %11413, %11412" -> "  %11417 = and i32 %11414, 65535""  %11414 = add nuw nsw i32 %11413, %11412" -> "  %11415 = lshr i32 %11414, 16"
"  %11415 = lshr i32 %11414, 16"
"  %11415 = lshr i32 %11414, 16" -> "  %11416 = add nuw nsw i32 %11408, %11415"
"  %11416 = add nuw nsw i32 %11408, %11415"
"  %11416 = add nuw nsw i32 %11408, %11415" -> "  %11421 = add nuw nsw i32 %11416, %11420"
"  %11417 = and i32 %11414, 65535"
"  %11417 = and i32 %11414, 65535" -> "  %11419 = add nuw nsw i32 %11417, %11418"
"  %11418 = lshr i32 %11411, 16"
"  %11418 = lshr i32 %11411, 16" -> "  %11419 = add nuw nsw i32 %11417, %11418"
"  %11419 = add nuw nsw i32 %11417, %11418"
"  %11419 = add nuw nsw i32 %11417, %11418" -> "  %11425 = and i32 %11419, 65535""  %11419 = add nuw nsw i32 %11417, %11418" -> "  %11420 = lshr i32 %11419, 16"
"  %11420 = lshr i32 %11419, 16"
"  %11420 = lshr i32 %11419, 16" -> "  %11421 = add nuw nsw i32 %11416, %11420"
"  %11421 = add nuw nsw i32 %11416, %11420"
"  %11421 = add nuw nsw i32 %11416, %11420" -> "  %11434 = and i32 %11421, 2147418112""  %11421 = add nuw nsw i32 %11416, %11420" -> "  %11432 = and i32 %11421, 65535"
"  %11422 = and i32 %11411, 65535"
"  %11422 = and i32 %11411, 65535" -> "  %11424 = add nuw nsw i32 %11423, %11422"
"  %11423 = and i32 %11390, 65535"
"  %11423 = and i32 %11390, 65535" -> "  %11424 = add nuw nsw i32 %11423, %11422"
"  %11424 = add nuw nsw i32 %11423, %11422"
"  %11424 = add nuw nsw i32 %11423, %11422" -> "  %11565 = and i32 %11424, 65535""  %11424 = add nuw nsw i32 %11423, %11422" -> "  %11428 = lshr i32 %11424, 16"
"  %11425 = and i32 %11419, 65535"
"  %11425 = and i32 %11419, 65535" -> "  %11427 = add nuw nsw i32 %11425, %11426"
"  %11426 = lshr i32 %11390, 16"
"  %11426 = lshr i32 %11390, 16" -> "  %11427 = add nuw nsw i32 %11425, %11426"
"  %11427 = add nuw nsw i32 %11425, %11426"
"  %11427 = add nuw nsw i32 %11425, %11426" -> "  %11431 = lshr i32 %11427, 16""  %11427 = add nuw nsw i32 %11425, %11426" -> "  %11429 = and i32 %11427, 65535"
"  %11428 = lshr i32 %11424, 16"
"  %11428 = lshr i32 %11424, 16" -> "  %11430 = add nuw nsw i32 %11429, %11428"
"  %11429 = and i32 %11427, 65535"
"  %11429 = and i32 %11427, 65535" -> "  %11430 = add nuw nsw i32 %11429, %11428"
"  %11430 = add nuw nsw i32 %11429, %11428"
"  %11430 = add nuw nsw i32 %11429, %11428" -> "  %11569 = and i32 %11430, 65535""  %11430 = add nuw nsw i32 %11429, %11428" -> "  %11436 = lshr i32 %11430, 16"
"  %11431 = lshr i32 %11427, 16"
"  %11431 = lshr i32 %11427, 16" -> "  %11433 = add nuw nsw i32 %11431, %11432"
"  %11432 = and i32 %11421, 65535"
"  %11432 = and i32 %11421, 65535" -> "  %11433 = add nuw nsw i32 %11431, %11432"
"  %11433 = add nuw nsw i32 %11431, %11432"
"  %11433 = add nuw nsw i32 %11431, %11432" -> "  %11435 = add nuw nsw i32 %11433, %11434"
"  %11434 = and i32 %11421, 2147418112"
"  %11434 = and i32 %11421, 2147418112" -> "  %11435 = add nuw nsw i32 %11433, %11434"
"  %11435 = add nuw nsw i32 %11433, %11434"
"  %11435 = add nuw nsw i32 %11433, %11434" -> "  %11437 = add nuw nsw i32 %11435, %11436"
"  %11436 = lshr i32 %11430, 16"
"  %11436 = lshr i32 %11430, 16" -> "  %11437 = add nuw nsw i32 %11435, %11436"
"  %11437 = add nuw nsw i32 %11435, %11436"
"  %11437 = add nuw nsw i32 %11435, %11436" -> "  %11574 = and i32 %11437, 65535""  %11437 = add nuw nsw i32 %11435, %11436" -> "  %11577 = lshr i32 %11437, 16"
"  %11438 = mul nuw i32 %9932, 42779"
"  %11438 = mul nuw i32 %9932, 42779" -> "  %11566 = and i32 %11438, 65535""  %11438 = mul nuw i32 %9932, 42779" -> "  %11439 = lshr i32 %11438, 16"
"  %11439 = lshr i32 %11438, 16"
"  %11439 = lshr i32 %11438, 16" -> "  %11442 = add nuw nsw i32 %11441, %11439"
"  %11440 = mul nuw i32 %9935, 42779"
"  %11440 = mul nuw i32 %9935, 42779" -> "  %11443 = and i32 %11440, -65536""  %11440 = mul nuw i32 %9935, 42779" -> "  %11441 = and i32 %11440, 65535"
"  %11441 = and i32 %11440, 65535"
"  %11441 = and i32 %11440, 65535" -> "  %11442 = add nuw nsw i32 %11441, %11439"
"  %11442 = add nuw nsw i32 %11441, %11439"
"  %11442 = add nuw nsw i32 %11441, %11439" -> "  %11444 = add nuw i32 %11442, %11443"
"  %11443 = and i32 %11440, -65536"
"  %11443 = and i32 %11440, -65536" -> "  %11444 = add nuw i32 %11442, %11443"
"  %11444 = add nuw i32 %11442, %11443"
"  %11444 = add nuw i32 %11442, %11443" -> "  %11448 = lshr i32 %11444, 16""  %11444 = add nuw i32 %11442, %11443" -> "  %11446 = and i32 %11444, 65535"
"  %11445 = mul nuw nsw i32 %9932, 9871"
"  %11445 = mul nuw nsw i32 %9932, 9871" -> "  %11447 = add nuw nsw i32 %11446, %11445"
"  %11446 = and i32 %11444, 65535"
"  %11446 = and i32 %11444, 65535" -> "  %11447 = add nuw nsw i32 %11446, %11445"
"  %11447 = add nuw nsw i32 %11446, %11445"
"  %11447 = add nuw nsw i32 %11446, %11445" -> "  %11568 = and i32 %11447, 65535""  %11447 = add nuw nsw i32 %11446, %11445" -> "  %11451 = lshr i32 %11447, 16"
"  %11448 = lshr i32 %11444, 16"
"  %11448 = lshr i32 %11444, 16" -> "  %11450 = add nuw nsw i32 %11448, %11449"
"  %11449 = mul nuw nsw i32 %9935, 9871"
"  %11449 = mul nuw nsw i32 %9935, 9871" -> "  %11450 = add nuw nsw i32 %11448, %11449"
"  %11450 = add nuw nsw i32 %11448, %11449"
"  %11450 = add nuw nsw i32 %11448, %11449" -> "  %11454 = and i32 %11450, 2147418112""  %11450 = add nuw nsw i32 %11448, %11449" -> "  %11452 = and i32 %11450, 65535"
"  %11451 = lshr i32 %11447, 16"
"  %11451 = lshr i32 %11447, 16" -> "  %11453 = add nuw nsw i32 %11451, %11452"
"  %11452 = and i32 %11450, 65535"
"  %11452 = and i32 %11450, 65535" -> "  %11453 = add nuw nsw i32 %11451, %11452"
"  %11453 = add nuw nsw i32 %11451, %11452"
"  %11453 = add nuw nsw i32 %11451, %11452" -> "  %11455 = add nuw nsw i32 %11453, %11454"
"  %11454 = and i32 %11450, 2147418112"
"  %11454 = and i32 %11450, 2147418112" -> "  %11455 = add nuw nsw i32 %11453, %11454"
"  %11455 = add nuw nsw i32 %11453, %11454"
"  %11455 = add nuw nsw i32 %11453, %11454" -> "  %11478 = lshr i32 %11455, 16""  %11455 = add nuw nsw i32 %11453, %11454" -> "  %11474 = and i32 %11455, 65535"
"  %11456 = mul nuw i32 %9952, 42779"
"  %11456 = mul nuw i32 %9952, 42779" -> "  %11475 = and i32 %11456, 65535""  %11456 = mul nuw i32 %9952, 42779" -> "  %11457 = lshr i32 %11456, 16"
"  %11457 = lshr i32 %11456, 16"
"  %11457 = lshr i32 %11456, 16" -> "  %11460 = add nuw nsw i32 %11459, %11457"
"  %11458 = mul nuw i32 %9953, 42779"
"  %11458 = mul nuw i32 %9953, 42779" -> "  %11461 = and i32 %11458, -65536""  %11458 = mul nuw i32 %9953, 42779" -> "  %11459 = and i32 %11458, 65535"
"  %11459 = and i32 %11458, 65535"
"  %11459 = and i32 %11458, 65535" -> "  %11460 = add nuw nsw i32 %11459, %11457"
"  %11460 = add nuw nsw i32 %11459, %11457"
"  %11460 = add nuw nsw i32 %11459, %11457" -> "  %11462 = add nuw i32 %11460, %11461"
"  %11461 = and i32 %11458, -65536"
"  %11461 = and i32 %11458, -65536" -> "  %11462 = add nuw i32 %11460, %11461"
"  %11462 = add nuw i32 %11460, %11461"
"  %11462 = add nuw i32 %11460, %11461" -> "  %11466 = lshr i32 %11462, 16""  %11462 = add nuw i32 %11460, %11461" -> "  %11464 = and i32 %11462, 65535"
"  %11463 = mul nuw nsw i32 %9952, 9871"
"  %11463 = mul nuw nsw i32 %9952, 9871" -> "  %11465 = add nuw nsw i32 %11464, %11463"
"  %11464 = and i32 %11462, 65535"
"  %11464 = and i32 %11462, 65535" -> "  %11465 = add nuw nsw i32 %11464, %11463"
"  %11465 = add nuw nsw i32 %11464, %11463"
"  %11465 = add nuw nsw i32 %11464, %11463" -> "  %11477 = and i32 %11465, 65535""  %11465 = add nuw nsw i32 %11464, %11463" -> "  %11469 = lshr i32 %11465, 16"
"  %11466 = lshr i32 %11462, 16"
"  %11466 = lshr i32 %11462, 16" -> "  %11468 = add nuw nsw i32 %11466, %11467"
"  %11467 = mul nuw nsw i32 %9953, 9871"
"  %11467 = mul nuw nsw i32 %9953, 9871" -> "  %11468 = add nuw nsw i32 %11466, %11467"
"  %11468 = add nuw nsw i32 %11466, %11467"
"  %11468 = add nuw nsw i32 %11466, %11467" -> "  %11472 = and i32 %11468, 2147418112""  %11468 = add nuw nsw i32 %11466, %11467" -> "  %11470 = and i32 %11468, 65535"
"  %11469 = lshr i32 %11465, 16"
"  %11469 = lshr i32 %11465, 16" -> "  %11471 = add nuw nsw i32 %11469, %11470"
"  %11470 = and i32 %11468, 65535"
"  %11470 = and i32 %11468, 65535" -> "  %11471 = add nuw nsw i32 %11469, %11470"
"  %11471 = add nuw nsw i32 %11469, %11470"
"  %11471 = add nuw nsw i32 %11469, %11470" -> "  %11473 = add nuw nsw i32 %11471, %11472"
"  %11472 = and i32 %11468, 2147418112"
"  %11472 = and i32 %11468, 2147418112" -> "  %11473 = add nuw nsw i32 %11471, %11472"
"  %11473 = add nuw nsw i32 %11471, %11472"
"  %11473 = add nuw nsw i32 %11471, %11472" -> "  %11481 = add nuw nsw i32 %11473, %11480"
"  %11474 = and i32 %11455, 65535"
"  %11474 = and i32 %11455, 65535" -> "  %11476 = add nuw nsw i32 %11474, %11475"
"  %11475 = and i32 %11456, 65535"
"  %11475 = and i32 %11456, 65535" -> "  %11476 = add nuw nsw i32 %11474, %11475"
"  %11476 = add nuw nsw i32 %11474, %11475"
"  %11476 = add nuw nsw i32 %11474, %11475" -> "  %11505 = and i32 %11476, 65535""  %11476 = add nuw nsw i32 %11474, %11475" -> "  %11483 = lshr i32 %11476, 16"
"  %11477 = and i32 %11465, 65535"
"  %11477 = and i32 %11465, 65535" -> "  %11479 = add nuw nsw i32 %11478, %11477"
"  %11478 = lshr i32 %11455, 16"
"  %11478 = lshr i32 %11455, 16" -> "  %11479 = add nuw nsw i32 %11478, %11477"
"  %11479 = add nuw nsw i32 %11478, %11477"
"  %11479 = add nuw nsw i32 %11478, %11477" -> "  %11482 = and i32 %11479, 65535""  %11479 = add nuw nsw i32 %11478, %11477" -> "  %11480 = lshr i32 %11479, 16"
"  %11480 = lshr i32 %11479, 16"
"  %11480 = lshr i32 %11479, 16" -> "  %11481 = add nuw nsw i32 %11473, %11480"
"  %11481 = add nuw nsw i32 %11473, %11480"
"  %11481 = add nuw nsw i32 %11473, %11480" -> "  %11486 = add nuw nsw i32 %11481, %11485"
"  %11482 = and i32 %11479, 65535"
"  %11482 = and i32 %11479, 65535" -> "  %11484 = add nuw nsw i32 %11482, %11483"
"  %11483 = lshr i32 %11476, 16"
"  %11483 = lshr i32 %11476, 16" -> "  %11484 = add nuw nsw i32 %11482, %11483"
"  %11484 = add nuw nsw i32 %11482, %11483"
"  %11484 = add nuw nsw i32 %11482, %11483" -> "  %11508 = and i32 %11484, 65535""  %11484 = add nuw nsw i32 %11482, %11483" -> "  %11485 = lshr i32 %11484, 16"
"  %11485 = lshr i32 %11484, 16"
"  %11485 = lshr i32 %11484, 16" -> "  %11486 = add nuw nsw i32 %11481, %11485"
"  %11486 = add nuw nsw i32 %11481, %11485"
"  %11486 = add nuw nsw i32 %11481, %11485" -> "  %11540 = lshr i32 %11486, 16""  %11486 = add nuw nsw i32 %11481, %11485" -> "  %11536 = and i32 %11486, 65535"
"  %11487 = mul nuw nsw i32 %9932, 24315"
"  %11487 = mul nuw nsw i32 %9932, 24315" -> "  %11506 = and i32 %11487, 65535""  %11487 = mul nuw nsw i32 %9932, 24315" -> "  %11488 = lshr i32 %11487, 16"
"  %11488 = lshr i32 %11487, 16"
"  %11488 = lshr i32 %11487, 16" -> "  %11491 = add nuw nsw i32 %11490, %11488"
"  %11489 = mul nuw nsw i32 %9935, 24315"
"  %11489 = mul nuw nsw i32 %9935, 24315" -> "  %11492 = and i32 %11489, 2147418112""  %11489 = mul nuw nsw i32 %9935, 24315" -> "  %11490 = and i32 %11489, 65535"
"  %11490 = and i32 %11489, 65535"
"  %11490 = and i32 %11489, 65535" -> "  %11491 = add nuw nsw i32 %11490, %11488"
"  %11491 = add nuw nsw i32 %11490, %11488"
"  %11491 = add nuw nsw i32 %11490, %11488" -> "  %11493 = add nuw nsw i32 %11491, %11492"
"  %11492 = and i32 %11489, 2147418112"
"  %11492 = and i32 %11489, 2147418112" -> "  %11493 = add nuw nsw i32 %11491, %11492"
"  %11493 = add nuw nsw i32 %11491, %11492"
"  %11493 = add nuw nsw i32 %11491, %11492" -> "  %11497 = lshr i32 %11493, 16""  %11493 = add nuw nsw i32 %11491, %11492" -> "  %11495 = and i32 %11493, 65535"
"  %11494 = mul nuw nsw i32 %9932, 29744"
"  %11494 = mul nuw nsw i32 %9932, 29744" -> "  %11496 = add nuw nsw i32 %11495, %11494"
"  %11495 = and i32 %11493, 65535"
"  %11495 = and i32 %11493, 65535" -> "  %11496 = add nuw nsw i32 %11495, %11494"
"  %11496 = add nuw nsw i32 %11495, %11494"
"  %11496 = add nuw nsw i32 %11495, %11494" -> "  %11509 = and i32 %11496, 65535""  %11496 = add nuw nsw i32 %11495, %11494" -> "  %11500 = lshr i32 %11496, 16"
"  %11497 = lshr i32 %11493, 16"
"  %11497 = lshr i32 %11493, 16" -> "  %11499 = add nuw nsw i32 %11497, %11498"
"  %11498 = mul nuw nsw i32 %9935, 29744"
"  %11498 = mul nuw nsw i32 %9935, 29744" -> "  %11499 = add nuw nsw i32 %11497, %11498"
"  %11499 = add nuw nsw i32 %11497, %11498"
"  %11499 = add nuw nsw i32 %11497, %11498" -> "  %11503 = and i32 %11499, 2147418112""  %11499 = add nuw nsw i32 %11497, %11498" -> "  %11501 = and i32 %11499, 65535"
"  %11500 = lshr i32 %11496, 16"
"  %11500 = lshr i32 %11496, 16" -> "  %11502 = add nuw nsw i32 %11500, %11501"
"  %11501 = and i32 %11499, 65535"
"  %11501 = and i32 %11499, 65535" -> "  %11502 = add nuw nsw i32 %11500, %11501"
"  %11502 = add nuw nsw i32 %11500, %11501"
"  %11502 = add nuw nsw i32 %11500, %11501" -> "  %11504 = add nuw nsw i32 %11502, %11503"
"  %11503 = and i32 %11499, 2147418112"
"  %11503 = and i32 %11499, 2147418112" -> "  %11504 = add nuw nsw i32 %11502, %11503"
"  %11504 = add nuw nsw i32 %11502, %11503"
"  %11504 = add nuw nsw i32 %11502, %11503" -> "  %11512 = add nuw nsw i32 %11504, %11511"
"  %11505 = and i32 %11476, 65535"
"  %11505 = and i32 %11476, 65535" -> "  %11507 = add nuw nsw i32 %11505, %11506"
"  %11506 = and i32 %11487, 65535"
"  %11506 = and i32 %11487, 65535" -> "  %11507 = add nuw nsw i32 %11505, %11506"
"  %11507 = add nuw nsw i32 %11505, %11506"
"  %11507 = add nuw nsw i32 %11505, %11506" -> "  %11575 = and i32 %11507, 65535""  %11507 = add nuw nsw i32 %11505, %11506" -> "  %11514 = lshr i32 %11507, 16"
"  %11508 = and i32 %11484, 65535"
"  %11508 = and i32 %11484, 65535" -> "  %11510 = add nuw nsw i32 %11508, %11509"
"  %11509 = and i32 %11496, 65535"
"  %11509 = and i32 %11496, 65535" -> "  %11510 = add nuw nsw i32 %11508, %11509"
"  %11510 = add nuw nsw i32 %11508, %11509"
"  %11510 = add nuw nsw i32 %11508, %11509" -> "  %11513 = and i32 %11510, 65535""  %11510 = add nuw nsw i32 %11508, %11509" -> "  %11511 = lshr i32 %11510, 16"
"  %11511 = lshr i32 %11510, 16"
"  %11511 = lshr i32 %11510, 16" -> "  %11512 = add nuw nsw i32 %11504, %11511"
"  %11512 = add nuw nsw i32 %11504, %11511"
"  %11512 = add nuw nsw i32 %11504, %11511" -> "  %11517 = add nuw nsw i32 %11512, %11516"
"  %11513 = and i32 %11510, 65535"
"  %11513 = and i32 %11510, 65535" -> "  %11515 = add nuw nsw i32 %11513, %11514"
"  %11514 = lshr i32 %11507, 16"
"  %11514 = lshr i32 %11507, 16" -> "  %11515 = add nuw nsw i32 %11513, %11514"
"  %11515 = add nuw nsw i32 %11513, %11514"
"  %11515 = add nuw nsw i32 %11513, %11514" -> "  %11578 = and i32 %11515, 65535""  %11515 = add nuw nsw i32 %11513, %11514" -> "  %11516 = lshr i32 %11515, 16"
"  %11516 = lshr i32 %11515, 16"
"  %11516 = lshr i32 %11515, 16" -> "  %11517 = add nuw nsw i32 %11512, %11516"
"  %11517 = add nuw nsw i32 %11512, %11516"
"  %11517 = add nuw nsw i32 %11512, %11516" -> "  %11553 = lshr i32 %11517, 16""  %11517 = add nuw nsw i32 %11512, %11516" -> "  %11550 = and i32 %11517, 65535"
"  %11518 = mul nuw nsw i32 %9952, 24315"
"  %11518 = mul nuw nsw i32 %9952, 24315" -> "  %11537 = and i32 %11518, 65535""  %11518 = mul nuw nsw i32 %9952, 24315" -> "  %11519 = lshr i32 %11518, 16"
"  %11519 = lshr i32 %11518, 16"
"  %11519 = lshr i32 %11518, 16" -> "  %11522 = add nuw nsw i32 %11521, %11519"
"  %11520 = mul nuw nsw i32 %9953, 24315"
"  %11520 = mul nuw nsw i32 %9953, 24315" -> "  %11523 = and i32 %11520, 2147418112""  %11520 = mul nuw nsw i32 %9953, 24315" -> "  %11521 = and i32 %11520, 65535"
"  %11521 = and i32 %11520, 65535"
"  %11521 = and i32 %11520, 65535" -> "  %11522 = add nuw nsw i32 %11521, %11519"
"  %11522 = add nuw nsw i32 %11521, %11519"
"  %11522 = add nuw nsw i32 %11521, %11519" -> "  %11524 = add nuw nsw i32 %11522, %11523"
"  %11523 = and i32 %11520, 2147418112"
"  %11523 = and i32 %11520, 2147418112" -> "  %11524 = add nuw nsw i32 %11522, %11523"
"  %11524 = add nuw nsw i32 %11522, %11523"
"  %11524 = add nuw nsw i32 %11522, %11523" -> "  %11528 = lshr i32 %11524, 16""  %11524 = add nuw nsw i32 %11522, %11523" -> "  %11526 = and i32 %11524, 65535"
"  %11525 = mul nuw nsw i32 %9952, 29744"
"  %11525 = mul nuw nsw i32 %9952, 29744" -> "  %11527 = add nuw nsw i32 %11526, %11525"
"  %11526 = and i32 %11524, 65535"
"  %11526 = and i32 %11524, 65535" -> "  %11527 = add nuw nsw i32 %11526, %11525"
"  %11527 = add nuw nsw i32 %11526, %11525"
"  %11527 = add nuw nsw i32 %11526, %11525" -> "  %11539 = and i32 %11527, 65535""  %11527 = add nuw nsw i32 %11526, %11525" -> "  %11531 = lshr i32 %11527, 16"
"  %11528 = lshr i32 %11524, 16"
"  %11528 = lshr i32 %11524, 16" -> "  %11530 = add nuw nsw i32 %11528, %11529"
"  %11529 = mul nuw nsw i32 %9953, 29744"
"  %11529 = mul nuw nsw i32 %9953, 29744" -> "  %11530 = add nuw nsw i32 %11528, %11529"
"  %11530 = add nuw nsw i32 %11528, %11529"
"  %11530 = add nuw nsw i32 %11528, %11529" -> "  %11534 = and i32 %11530, 2147418112""  %11530 = add nuw nsw i32 %11528, %11529" -> "  %11532 = and i32 %11530, 65535"
"  %11531 = lshr i32 %11527, 16"
"  %11531 = lshr i32 %11527, 16" -> "  %11533 = add nuw nsw i32 %11531, %11532"
"  %11532 = and i32 %11530, 65535"
"  %11532 = and i32 %11530, 65535" -> "  %11533 = add nuw nsw i32 %11531, %11532"
"  %11533 = add nuw nsw i32 %11531, %11532"
"  %11533 = add nuw nsw i32 %11531, %11532" -> "  %11535 = add nuw nsw i32 %11533, %11534"
"  %11534 = and i32 %11530, 2147418112"
"  %11534 = and i32 %11530, 2147418112" -> "  %11535 = add nuw nsw i32 %11533, %11534"
"  %11535 = add nuw nsw i32 %11533, %11534"
"  %11535 = add nuw nsw i32 %11533, %11534" -> "  %11543 = add nuw nsw i32 %11535, %11542"
"  %11536 = and i32 %11486, 65535"
"  %11536 = and i32 %11486, 65535" -> "  %11538 = add nuw nsw i32 %11536, %11537"
"  %11537 = and i32 %11518, 65535"
"  %11537 = and i32 %11518, 65535" -> "  %11538 = add nuw nsw i32 %11536, %11537"
"  %11538 = add nuw nsw i32 %11536, %11537"
"  %11538 = add nuw nsw i32 %11536, %11537" -> "  %11549 = and i32 %11538, 65535""  %11538 = add nuw nsw i32 %11536, %11537" -> "  %11545 = lshr i32 %11538, 16"
"  %11539 = and i32 %11527, 65535"
"  %11539 = and i32 %11527, 65535" -> "  %11541 = add nuw nsw i32 %11540, %11539"
"  %11540 = lshr i32 %11486, 16"
"  %11540 = lshr i32 %11486, 16" -> "  %11541 = add nuw nsw i32 %11540, %11539"
"  %11541 = add nuw nsw i32 %11540, %11539"
"  %11541 = add nuw nsw i32 %11540, %11539" -> "  %11544 = and i32 %11541, 65535""  %11541 = add nuw nsw i32 %11540, %11539" -> "  %11542 = lshr i32 %11541, 16"
"  %11542 = lshr i32 %11541, 16"
"  %11542 = lshr i32 %11541, 16" -> "  %11543 = add nuw nsw i32 %11535, %11542"
"  %11543 = add nuw nsw i32 %11535, %11542"
"  %11543 = add nuw nsw i32 %11535, %11542" -> "  %11548 = add nuw nsw i32 %11543, %11547"
"  %11544 = and i32 %11541, 65535"
"  %11544 = and i32 %11541, 65535" -> "  %11546 = add nuw nsw i32 %11545, %11544"
"  %11545 = lshr i32 %11538, 16"
"  %11545 = lshr i32 %11538, 16" -> "  %11546 = add nuw nsw i32 %11545, %11544"
"  %11546 = add nuw nsw i32 %11545, %11544"
"  %11546 = add nuw nsw i32 %11545, %11544" -> "  %11552 = and i32 %11546, 65535""  %11546 = add nuw nsw i32 %11545, %11544" -> "  %11547 = lshr i32 %11546, 16"
"  %11547 = lshr i32 %11546, 16"
"  %11547 = lshr i32 %11546, 16" -> "  %11548 = add nuw nsw i32 %11543, %11547"
"  %11548 = add nuw nsw i32 %11543, %11547"
"  %11548 = add nuw nsw i32 %11543, %11547" -> "  %11561 = and i32 %11548, 2147418112""  %11548 = add nuw nsw i32 %11543, %11547" -> "  %11559 = and i32 %11548, 65535"
"  %11549 = and i32 %11538, 65535"
"  %11549 = and i32 %11538, 65535" -> "  %11551 = add nuw nsw i32 %11550, %11549"
"  %11550 = and i32 %11517, 65535"
"  %11550 = and i32 %11517, 65535" -> "  %11551 = add nuw nsw i32 %11550, %11549"
"  %11551 = add nuw nsw i32 %11550, %11549"
"  %11551 = add nuw nsw i32 %11550, %11549" -> "  %11592 = and i32 %11551, 65535""  %11551 = add nuw nsw i32 %11550, %11549" -> "  %11555 = lshr i32 %11551, 16"
"  %11552 = and i32 %11546, 65535"
"  %11552 = and i32 %11546, 65535" -> "  %11554 = add nuw nsw i32 %11553, %11552"
"  %11553 = lshr i32 %11517, 16"
"  %11553 = lshr i32 %11517, 16" -> "  %11554 = add nuw nsw i32 %11553, %11552"
"  %11554 = add nuw nsw i32 %11553, %11552"
"  %11554 = add nuw nsw i32 %11553, %11552" -> "  %11558 = lshr i32 %11554, 16""  %11554 = add nuw nsw i32 %11553, %11552" -> "  %11556 = and i32 %11554, 65535"
"  %11555 = lshr i32 %11551, 16"
"  %11555 = lshr i32 %11551, 16" -> "  %11557 = add nuw nsw i32 %11555, %11556"
"  %11556 = and i32 %11554, 65535"
"  %11556 = and i32 %11554, 65535" -> "  %11557 = add nuw nsw i32 %11555, %11556"
"  %11557 = add nuw nsw i32 %11555, %11556"
"  %11557 = add nuw nsw i32 %11555, %11556" -> "  %11599 = and i32 %11557, 65535""  %11557 = add nuw nsw i32 %11555, %11556" -> "  %11563 = lshr i32 %11557, 16"
"  %11558 = lshr i32 %11554, 16"
"  %11558 = lshr i32 %11554, 16" -> "  %11560 = add nuw nsw i32 %11558, %11559"
"  %11559 = and i32 %11548, 65535"
"  %11559 = and i32 %11548, 65535" -> "  %11560 = add nuw nsw i32 %11558, %11559"
"  %11560 = add nuw nsw i32 %11558, %11559"
"  %11560 = add nuw nsw i32 %11558, %11559" -> "  %11562 = add nuw nsw i32 %11560, %11561"
"  %11561 = and i32 %11548, 2147418112"
"  %11561 = and i32 %11548, 2147418112" -> "  %11562 = add nuw nsw i32 %11560, %11561"
"  %11562 = add nuw nsw i32 %11560, %11561"
"  %11562 = add nuw nsw i32 %11560, %11561" -> "  %11564 = add nuw nsw i32 %11562, %11563"
"  %11563 = lshr i32 %11557, 16"
"  %11563 = lshr i32 %11557, 16" -> "  %11564 = add nuw nsw i32 %11562, %11563"
"  %11564 = add nuw nsw i32 %11562, %11563"
"  %11564 = add nuw nsw i32 %11562, %11563" -> "  %11602 = add nuw nsw i32 %11564, %11601"
"  %11565 = and i32 %11424, 65535"
"  %11565 = and i32 %11424, 65535" -> "  %11567 = add nuw nsw i32 %11565, %11566"
"  %11566 = and i32 %11438, 65535"
"  %11566 = and i32 %11438, 65535" -> "  %11567 = add nuw nsw i32 %11565, %11566"
"  %11567 = add nuw nsw i32 %11565, %11566"
"  %11567 = add nuw nsw i32 %11565, %11566" -> "  %11731 = and i32 %11567, 65535""  %11567 = add nuw nsw i32 %11565, %11566" -> "  %11571 = lshr i32 %11567, 16"
"  %11568 = and i32 %11447, 65535"
"  %11568 = and i32 %11447, 65535" -> "  %11570 = add nuw nsw i32 %11569, %11568"
"  %11569 = and i32 %11430, 65535"
"  %11569 = and i32 %11430, 65535" -> "  %11570 = add nuw nsw i32 %11569, %11568"
"  %11570 = add nuw nsw i32 %11569, %11568"
"  %11570 = add nuw nsw i32 %11569, %11568" -> "  %11584 = lshr i32 %11570, 16""  %11570 = add nuw nsw i32 %11569, %11568" -> "  %11572 = and i32 %11570, 65535"
"  %11571 = lshr i32 %11567, 16"
"  %11571 = lshr i32 %11567, 16" -> "  %11573 = add nuw nsw i32 %11572, %11571"
"  %11572 = and i32 %11570, 65535"
"  %11572 = and i32 %11570, 65535" -> "  %11573 = add nuw nsw i32 %11572, %11571"
"  %11573 = add nuw nsw i32 %11572, %11571"
"  %11573 = add nuw nsw i32 %11572, %11571" -> "  %11734 = and i32 %11573, 65535""  %11573 = add nuw nsw i32 %11572, %11571" -> "  %11585 = lshr i32 %11573, 16"
"  %11574 = and i32 %11437, 65535"
"  %11574 = and i32 %11437, 65535" -> "  %11576 = add nuw nsw i32 %11574, %11575"
"  %11575 = and i32 %11507, 65535"
"  %11575 = and i32 %11507, 65535" -> "  %11576 = add nuw nsw i32 %11574, %11575"
"  %11576 = add nuw nsw i32 %11574, %11575"
"  %11576 = add nuw nsw i32 %11574, %11575" -> "  %11583 = and i32 %11576, 65535""  %11576 = add nuw nsw i32 %11574, %11575" -> "  %11580 = lshr i32 %11576, 16"
"  %11577 = lshr i32 %11437, 16"
"  %11577 = lshr i32 %11437, 16" -> "  %11579 = add nuw nsw i32 %11577, %11578"
"  %11578 = and i32 %11515, 65535"
"  %11578 = and i32 %11515, 65535" -> "  %11579 = add nuw nsw i32 %11577, %11578"
"  %11579 = add nuw nsw i32 %11577, %11578"
"  %11579 = add nuw nsw i32 %11577, %11578" -> "  %11591 = lshr i32 %11579, 16""  %11579 = add nuw nsw i32 %11577, %11578" -> "  %11581 = and i32 %11579, 65535"
"  %11580 = lshr i32 %11576, 16"
"  %11580 = lshr i32 %11576, 16" -> "  %11582 = add nuw nsw i32 %11581, %11580"
"  %11581 = and i32 %11579, 65535"
"  %11581 = and i32 %11579, 65535" -> "  %11582 = add nuw nsw i32 %11581, %11580"
"  %11582 = add nuw nsw i32 %11581, %11580"
"  %11582 = add nuw nsw i32 %11581, %11580" -> "  %11594 = lshr i32 %11582, 16""  %11582 = add nuw nsw i32 %11581, %11580" -> "  %11589 = and i32 %11582, 65535"
"  %11583 = and i32 %11576, 65535"
"  %11583 = and i32 %11576, 65535" -> "  %11586 = add nuw nsw i32 %11583, %11584"
"  %11584 = lshr i32 %11570, 16"
"  %11584 = lshr i32 %11570, 16" -> "  %11586 = add nuw nsw i32 %11583, %11584"
"  %11585 = lshr i32 %11573, 16"
"  %11585 = lshr i32 %11573, 16" -> "  %11587 = add nuw nsw i32 %11586, %11585"
"  %11586 = add nuw nsw i32 %11583, %11584"
"  %11586 = add nuw nsw i32 %11583, %11584" -> "  %11587 = add nuw nsw i32 %11586, %11585"
"  %11587 = add nuw nsw i32 %11586, %11585"
"  %11587 = add nuw nsw i32 %11586, %11585" -> "  %11741 = and i32 %11587, 65535""  %11587 = add nuw nsw i32 %11586, %11585" -> "  %11588 = lshr i32 %11587, 16"
"  %11588 = lshr i32 %11587, 16"
"  %11588 = lshr i32 %11587, 16" -> "  %11590 = add nuw nsw i32 %11588, %11589"
"  %11589 = and i32 %11582, 65535"
"  %11589 = and i32 %11582, 65535" -> "  %11590 = add nuw nsw i32 %11588, %11589"
"  %11590 = add nuw nsw i32 %11588, %11589"
"  %11590 = add nuw nsw i32 %11588, %11589" -> "  %11745 = and i32 %11590, 65535""  %11590 = add nuw nsw i32 %11588, %11589" -> "  %11596 = lshr i32 %11590, 16"
"  %11591 = lshr i32 %11579, 16"
"  %11591 = lshr i32 %11579, 16" -> "  %11593 = add nuw nsw i32 %11592, %11591"
"  %11592 = and i32 %11551, 65535"
"  %11592 = and i32 %11551, 65535" -> "  %11593 = add nuw nsw i32 %11592, %11591"
"  %11593 = add nuw nsw i32 %11592, %11591"
"  %11593 = add nuw nsw i32 %11592, %11591" -> "  %11595 = add nuw nsw i32 %11593, %11594"
"  %11594 = lshr i32 %11582, 16"
"  %11594 = lshr i32 %11582, 16" -> "  %11595 = add nuw nsw i32 %11593, %11594"
"  %11595 = add nuw nsw i32 %11593, %11594"
"  %11595 = add nuw nsw i32 %11593, %11594" -> "  %11597 = add nuw nsw i32 %11595, %11596"
"  %11596 = lshr i32 %11590, 16"
"  %11596 = lshr i32 %11590, 16" -> "  %11597 = add nuw nsw i32 %11595, %11596"
"  %11597 = add nuw nsw i32 %11595, %11596"
"  %11597 = add nuw nsw i32 %11595, %11596" -> "  %11896 = and i32 %11597, 65535""  %11597 = add nuw nsw i32 %11595, %11596" -> "  %11598 = lshr i32 %11597, 16"
"  %11598 = lshr i32 %11597, 16"
"  %11598 = lshr i32 %11597, 16" -> "  %11600 = add nuw nsw i32 %11598, %11599"
"  %11599 = and i32 %11557, 65535"
"  %11599 = and i32 %11557, 65535" -> "  %11600 = add nuw nsw i32 %11598, %11599"
"  %11600 = add nuw nsw i32 %11598, %11599"
"  %11600 = add nuw nsw i32 %11598, %11599" -> "  %11899 = and i32 %11600, 65535""  %11600 = add nuw nsw i32 %11598, %11599" -> "  %11601 = lshr i32 %11600, 16"
"  %11601 = lshr i32 %11600, 16"
"  %11601 = lshr i32 %11600, 16" -> "  %11602 = add nuw nsw i32 %11564, %11601"
"  %11602 = add nuw nsw i32 %11564, %11601"
"  %11602 = add nuw nsw i32 %11564, %11601" -> "  %11904 = and i32 %11602, 65535""  %11602 = add nuw nsw i32 %11564, %11601" -> "  %11907 = lshr i32 %11602, 16"
"  %11603 = mul nuw nsw i32 %9798, 4087"
"  %11603 = mul nuw nsw i32 %9798, 4087" -> "  %11730 = and i32 %11603, 65535""  %11603 = mul nuw nsw i32 %9798, 4087" -> "  %11604 = lshr i32 %11603, 16"
"  %11604 = lshr i32 %11603, 16"
"  %11604 = lshr i32 %11603, 16" -> "  %11607 = add nuw nsw i32 %11606, %11604"
"  %11605 = mul nuw nsw i32 %9799, 4087"
"  %11605 = mul nuw nsw i32 %9799, 4087" -> "  %11608 = and i32 %11605, 268369920""  %11605 = mul nuw nsw i32 %9799, 4087" -> "  %11606 = and i32 %11605, 65535"
"  %11606 = and i32 %11605, 65535"
"  %11606 = and i32 %11605, 65535" -> "  %11607 = add nuw nsw i32 %11606, %11604"
"  %11607 = add nuw nsw i32 %11606, %11604"
"  %11607 = add nuw nsw i32 %11606, %11604" -> "  %11609 = add nuw nsw i32 %11607, %11608"
"  %11608 = and i32 %11605, 268369920"
"  %11608 = and i32 %11605, 268369920" -> "  %11609 = add nuw nsw i32 %11607, %11608"
"  %11609 = add nuw nsw i32 %11607, %11608"
"  %11609 = add nuw nsw i32 %11607, %11608" -> "  %11613 = lshr i32 %11609, 16""  %11609 = add nuw nsw i32 %11607, %11608" -> "  %11611 = and i32 %11609, 65535"
"  %11610 = mul nuw nsw i32 %9798, 11561"
"  %11610 = mul nuw nsw i32 %9798, 11561" -> "  %11612 = add nuw nsw i32 %11611, %11610"
"  %11611 = and i32 %11609, 65535"
"  %11611 = and i32 %11609, 65535" -> "  %11612 = add nuw nsw i32 %11611, %11610"
"  %11612 = add nuw nsw i32 %11611, %11610"
"  %11612 = add nuw nsw i32 %11611, %11610" -> "  %11733 = and i32 %11612, 65535""  %11612 = add nuw nsw i32 %11611, %11610" -> "  %11616 = lshr i32 %11612, 16"
"  %11613 = lshr i32 %11609, 16"
"  %11613 = lshr i32 %11609, 16" -> "  %11615 = add nuw nsw i32 %11613, %11614"
"  %11614 = mul nuw nsw i32 %9799, 11561"
"  %11614 = mul nuw nsw i32 %9799, 11561" -> "  %11615 = add nuw nsw i32 %11613, %11614"
"  %11615 = add nuw nsw i32 %11613, %11614"
"  %11615 = add nuw nsw i32 %11613, %11614" -> "  %11619 = and i32 %11615, 2147418112""  %11615 = add nuw nsw i32 %11613, %11614" -> "  %11617 = and i32 %11615, 65535"
"  %11616 = lshr i32 %11612, 16"
"  %11616 = lshr i32 %11612, 16" -> "  %11618 = add nuw nsw i32 %11616, %11617"
"  %11617 = and i32 %11615, 65535"
"  %11617 = and i32 %11615, 65535" -> "  %11618 = add nuw nsw i32 %11616, %11617"
"  %11618 = add nuw nsw i32 %11616, %11617"
"  %11618 = add nuw nsw i32 %11616, %11617" -> "  %11620 = add nuw nsw i32 %11618, %11619"
"  %11619 = and i32 %11615, 2147418112"
"  %11619 = and i32 %11615, 2147418112" -> "  %11620 = add nuw nsw i32 %11618, %11619"
"  %11620 = add nuw nsw i32 %11618, %11619"
"  %11620 = add nuw nsw i32 %11618, %11619" -> "  %11643 = lshr i32 %11620, 16""  %11620 = add nuw nsw i32 %11618, %11619" -> "  %11639 = and i32 %11620, 65535"
"  %11621 = mul nuw nsw i32 %9819, 4087"
"  %11621 = mul nuw nsw i32 %9819, 4087" -> "  %11640 = and i32 %11621, 65535""  %11621 = mul nuw nsw i32 %9819, 4087" -> "  %11622 = lshr i32 %11621, 16"
"  %11622 = lshr i32 %11621, 16"
"  %11622 = lshr i32 %11621, 16" -> "  %11625 = add nuw nsw i32 %11624, %11622"
"  %11623 = mul nuw nsw i32 %9818, 4087"
"  %11623 = mul nuw nsw i32 %9818, 4087" -> "  %11626 = and i32 %11623, 268369920""  %11623 = mul nuw nsw i32 %9818, 4087" -> "  %11624 = and i32 %11623, 65535"
"  %11624 = and i32 %11623, 65535"
"  %11624 = and i32 %11623, 65535" -> "  %11625 = add nuw nsw i32 %11624, %11622"
"  %11625 = add nuw nsw i32 %11624, %11622"
"  %11625 = add nuw nsw i32 %11624, %11622" -> "  %11627 = add nuw nsw i32 %11625, %11626"
"  %11626 = and i32 %11623, 268369920"
"  %11626 = and i32 %11623, 268369920" -> "  %11627 = add nuw nsw i32 %11625, %11626"
"  %11627 = add nuw nsw i32 %11625, %11626"
"  %11627 = add nuw nsw i32 %11625, %11626" -> "  %11631 = lshr i32 %11627, 16""  %11627 = add nuw nsw i32 %11625, %11626" -> "  %11629 = and i32 %11627, 65535"
"  %11628 = mul nuw nsw i32 %9819, 11561"
"  %11628 = mul nuw nsw i32 %9819, 11561" -> "  %11630 = add nuw nsw i32 %11629, %11628"
"  %11629 = and i32 %11627, 65535"
"  %11629 = and i32 %11627, 65535" -> "  %11630 = add nuw nsw i32 %11629, %11628"
"  %11630 = add nuw nsw i32 %11629, %11628"
"  %11630 = add nuw nsw i32 %11629, %11628" -> "  %11642 = and i32 %11630, 65535""  %11630 = add nuw nsw i32 %11629, %11628" -> "  %11634 = lshr i32 %11630, 16"
"  %11631 = lshr i32 %11627, 16"
"  %11631 = lshr i32 %11627, 16" -> "  %11633 = add nuw nsw i32 %11631, %11632"
"  %11632 = mul nuw nsw i32 %9818, 11561"
"  %11632 = mul nuw nsw i32 %9818, 11561" -> "  %11633 = add nuw nsw i32 %11631, %11632"
"  %11633 = add nuw nsw i32 %11631, %11632"
"  %11633 = add nuw nsw i32 %11631, %11632" -> "  %11637 = and i32 %11633, 2147418112""  %11633 = add nuw nsw i32 %11631, %11632" -> "  %11635 = and i32 %11633, 65535"
"  %11634 = lshr i32 %11630, 16"
"  %11634 = lshr i32 %11630, 16" -> "  %11636 = add nuw nsw i32 %11634, %11635"
"  %11635 = and i32 %11633, 65535"
"  %11635 = and i32 %11633, 65535" -> "  %11636 = add nuw nsw i32 %11634, %11635"
"  %11636 = add nuw nsw i32 %11634, %11635"
"  %11636 = add nuw nsw i32 %11634, %11635" -> "  %11638 = add nuw nsw i32 %11636, %11637"
"  %11637 = and i32 %11633, 2147418112"
"  %11637 = and i32 %11633, 2147418112" -> "  %11638 = add nuw nsw i32 %11636, %11637"
"  %11638 = add nuw nsw i32 %11636, %11637"
"  %11638 = add nuw nsw i32 %11636, %11637" -> "  %11646 = add nuw nsw i32 %11638, %11645"
"  %11639 = and i32 %11620, 65535"
"  %11639 = and i32 %11620, 65535" -> "  %11641 = add nuw nsw i32 %11639, %11640"
"  %11640 = and i32 %11621, 65535"
"  %11640 = and i32 %11621, 65535" -> "  %11641 = add nuw nsw i32 %11639, %11640"
"  %11641 = add nuw nsw i32 %11639, %11640"
"  %11641 = add nuw nsw i32 %11639, %11640" -> "  %11670 = and i32 %11641, 65535""  %11641 = add nuw nsw i32 %11639, %11640" -> "  %11648 = lshr i32 %11641, 16"
"  %11642 = and i32 %11630, 65535"
"  %11642 = and i32 %11630, 65535" -> "  %11644 = add nuw nsw i32 %11642, %11643"
"  %11643 = lshr i32 %11620, 16"
"  %11643 = lshr i32 %11620, 16" -> "  %11644 = add nuw nsw i32 %11642, %11643"
"  %11644 = add nuw nsw i32 %11642, %11643"
"  %11644 = add nuw nsw i32 %11642, %11643" -> "  %11647 = and i32 %11644, 65535""  %11644 = add nuw nsw i32 %11642, %11643" -> "  %11645 = lshr i32 %11644, 16"
"  %11645 = lshr i32 %11644, 16"
"  %11645 = lshr i32 %11644, 16" -> "  %11646 = add nuw nsw i32 %11638, %11645"
"  %11646 = add nuw nsw i32 %11638, %11645"
"  %11646 = add nuw nsw i32 %11638, %11645" -> "  %11651 = add nuw nsw i32 %11646, %11650"
"  %11647 = and i32 %11644, 65535"
"  %11647 = and i32 %11644, 65535" -> "  %11649 = add nuw nsw i32 %11647, %11648"
"  %11648 = lshr i32 %11641, 16"
"  %11648 = lshr i32 %11641, 16" -> "  %11649 = add nuw nsw i32 %11647, %11648"
"  %11649 = add nuw nsw i32 %11647, %11648"
"  %11649 = add nuw nsw i32 %11647, %11648" -> "  %11673 = and i32 %11649, 65535""  %11649 = add nuw nsw i32 %11647, %11648" -> "  %11650 = lshr i32 %11649, 16"
"  %11650 = lshr i32 %11649, 16"
"  %11650 = lshr i32 %11649, 16" -> "  %11651 = add nuw nsw i32 %11646, %11650"
"  %11651 = add nuw nsw i32 %11646, %11650"
"  %11651 = add nuw nsw i32 %11646, %11650" -> "  %11705 = lshr i32 %11651, 16""  %11651 = add nuw nsw i32 %11646, %11650" -> "  %11701 = and i32 %11651, 65535"
"  %11652 = mul nuw nsw i32 %9798, 21884"
"  %11652 = mul nuw nsw i32 %9798, 21884" -> "  %11671 = and i32 %11652, 65532""  %11652 = mul nuw nsw i32 %9798, 21884" -> "  %11653 = lshr i32 %11652, 16"
"  %11653 = lshr i32 %11652, 16"
"  %11653 = lshr i32 %11652, 16" -> "  %11656 = add nuw nsw i32 %11655, %11653"
"  %11654 = mul nuw nsw i32 %9799, 21884"
"  %11654 = mul nuw nsw i32 %9799, 21884" -> "  %11657 = and i32 %11654, 2147418112""  %11654 = mul nuw nsw i32 %9799, 21884" -> "  %11655 = and i32 %11654, 65532"
"  %11655 = and i32 %11654, 65532"
"  %11655 = and i32 %11654, 65532" -> "  %11656 = add nuw nsw i32 %11655, %11653"
"  %11656 = add nuw nsw i32 %11655, %11653"
"  %11656 = add nuw nsw i32 %11655, %11653" -> "  %11658 = add nuw nsw i32 %11656, %11657"
"  %11657 = and i32 %11654, 2147418112"
"  %11657 = and i32 %11654, 2147418112" -> "  %11658 = add nuw nsw i32 %11656, %11657"
"  %11658 = add nuw nsw i32 %11656, %11657"
"  %11658 = add nuw nsw i32 %11656, %11657" -> "  %11662 = lshr i32 %11658, 16""  %11658 = add nuw nsw i32 %11656, %11657" -> "  %11660 = and i32 %11658, 65535"
"  %11659 = mul nuw i32 %9798, 36786"
"  %11659 = mul nuw i32 %9798, 36786" -> "  %11661 = add nuw i32 %11660, %11659"
"  %11660 = and i32 %11658, 65535"
"  %11660 = and i32 %11658, 65535" -> "  %11661 = add nuw i32 %11660, %11659"
"  %11661 = add nuw i32 %11660, %11659"
"  %11661 = add nuw i32 %11660, %11659" -> "  %11674 = and i32 %11661, 65535""  %11661 = add nuw i32 %11660, %11659" -> "  %11665 = lshr i32 %11661, 16"
"  %11662 = lshr i32 %11658, 16"
"  %11662 = lshr i32 %11658, 16" -> "  %11664 = add nuw i32 %11662, %11663"
"  %11663 = mul nuw i32 %9799, 36786"
"  %11663 = mul nuw i32 %9799, 36786" -> "  %11664 = add nuw i32 %11662, %11663"
"  %11664 = add nuw i32 %11662, %11663"
"  %11664 = add nuw i32 %11662, %11663" -> "  %11668 = and i32 %11664, -65536""  %11664 = add nuw i32 %11662, %11663" -> "  %11666 = and i32 %11664, 65535"
"  %11665 = lshr i32 %11661, 16"
"  %11665 = lshr i32 %11661, 16" -> "  %11667 = add nuw nsw i32 %11665, %11666"
"  %11666 = and i32 %11664, 65535"
"  %11666 = and i32 %11664, 65535" -> "  %11667 = add nuw nsw i32 %11665, %11666"
"  %11667 = add nuw nsw i32 %11665, %11666"
"  %11667 = add nuw nsw i32 %11665, %11666" -> "  %11669 = add nuw i32 %11667, %11668"
"  %11668 = and i32 %11664, -65536"
"  %11668 = and i32 %11664, -65536" -> "  %11669 = add nuw i32 %11667, %11668"
"  %11669 = add nuw i32 %11667, %11668"
"  %11669 = add nuw i32 %11667, %11668" -> "  %11677 = add nuw i32 %11669, %11676"
"  %11670 = and i32 %11641, 65535"
"  %11670 = and i32 %11641, 65535" -> "  %11672 = add nuw nsw i32 %11670, %11671"
"  %11671 = and i32 %11652, 65532"
"  %11671 = and i32 %11652, 65532" -> "  %11672 = add nuw nsw i32 %11670, %11671"
"  %11672 = add nuw nsw i32 %11670, %11671"
"  %11672 = add nuw nsw i32 %11670, %11671" -> "  %11742 = and i32 %11672, 65535""  %11672 = add nuw nsw i32 %11670, %11671" -> "  %11679 = lshr i32 %11672, 16"
"  %11673 = and i32 %11649, 65535"
"  %11673 = and i32 %11649, 65535" -> "  %11675 = add nuw nsw i32 %11673, %11674"
"  %11674 = and i32 %11661, 65535"
"  %11674 = and i32 %11661, 65535" -> "  %11675 = add nuw nsw i32 %11673, %11674"
"  %11675 = add nuw nsw i32 %11673, %11674"
"  %11675 = add nuw nsw i32 %11673, %11674" -> "  %11678 = and i32 %11675, 65535""  %11675 = add nuw nsw i32 %11673, %11674" -> "  %11676 = lshr i32 %11675, 16"
"  %11676 = lshr i32 %11675, 16"
"  %11676 = lshr i32 %11675, 16" -> "  %11677 = add nuw i32 %11669, %11676"
"  %11677 = add nuw i32 %11669, %11676"
"  %11677 = add nuw i32 %11669, %11676" -> "  %11682 = add nuw i32 %11677, %11681"
"  %11678 = and i32 %11675, 65535"
"  %11678 = and i32 %11675, 65535" -> "  %11680 = add nuw nsw i32 %11678, %11679"
"  %11679 = lshr i32 %11672, 16"
"  %11679 = lshr i32 %11672, 16" -> "  %11680 = add nuw nsw i32 %11678, %11679"
"  %11680 = add nuw nsw i32 %11678, %11679"
"  %11680 = add nuw nsw i32 %11678, %11679" -> "  %11744 = and i32 %11680, 65535""  %11680 = add nuw nsw i32 %11678, %11679" -> "  %11681 = lshr i32 %11680, 16"
"  %11681 = lshr i32 %11680, 16"
"  %11681 = lshr i32 %11680, 16" -> "  %11682 = add nuw i32 %11677, %11681"
"  %11682 = add nuw i32 %11677, %11681"
"  %11682 = add nuw i32 %11677, %11681" -> "  %11718 = lshr i32 %11682, 16""  %11682 = add nuw i32 %11677, %11681" -> "  %11715 = and i32 %11682, 65535"
"  %11683 = mul nuw nsw i32 %9819, 21884"
"  %11683 = mul nuw nsw i32 %9819, 21884" -> "  %11702 = and i32 %11683, 65532""  %11683 = mul nuw nsw i32 %9819, 21884" -> "  %11684 = lshr i32 %11683, 16"
"  %11684 = lshr i32 %11683, 16"
"  %11684 = lshr i32 %11683, 16" -> "  %11687 = add nuw nsw i32 %11686, %11684"
"  %11685 = mul nuw nsw i32 %9818, 21884"
"  %11685 = mul nuw nsw i32 %9818, 21884" -> "  %11688 = and i32 %11685, 2147418112""  %11685 = mul nuw nsw i32 %9818, 21884" -> "  %11686 = and i32 %11685, 65532"
"  %11686 = and i32 %11685, 65532"
"  %11686 = and i32 %11685, 65532" -> "  %11687 = add nuw nsw i32 %11686, %11684"
"  %11687 = add nuw nsw i32 %11686, %11684"
"  %11687 = add nuw nsw i32 %11686, %11684" -> "  %11689 = add nuw nsw i32 %11687, %11688"
"  %11688 = and i32 %11685, 2147418112"
"  %11688 = and i32 %11685, 2147418112" -> "  %11689 = add nuw nsw i32 %11687, %11688"
"  %11689 = add nuw nsw i32 %11687, %11688"
"  %11689 = add nuw nsw i32 %11687, %11688" -> "  %11693 = lshr i32 %11689, 16""  %11689 = add nuw nsw i32 %11687, %11688" -> "  %11691 = and i32 %11689, 65535"
"  %11690 = mul nuw i32 %9819, 36786"
"  %11690 = mul nuw i32 %9819, 36786" -> "  %11692 = add nuw i32 %11691, %11690"
"  %11691 = and i32 %11689, 65535"
"  %11691 = and i32 %11689, 65535" -> "  %11692 = add nuw i32 %11691, %11690"
"  %11692 = add nuw i32 %11691, %11690"
"  %11692 = add nuw i32 %11691, %11690" -> "  %11704 = and i32 %11692, 65535""  %11692 = add nuw i32 %11691, %11690" -> "  %11696 = lshr i32 %11692, 16"
"  %11693 = lshr i32 %11689, 16"
"  %11693 = lshr i32 %11689, 16" -> "  %11695 = add nuw i32 %11693, %11694"
"  %11694 = mul nuw i32 %9818, 36786"
"  %11694 = mul nuw i32 %9818, 36786" -> "  %11695 = add nuw i32 %11693, %11694"
"  %11695 = add nuw i32 %11693, %11694"
"  %11695 = add nuw i32 %11693, %11694" -> "  %11699 = and i32 %11695, -65536""  %11695 = add nuw i32 %11693, %11694" -> "  %11697 = and i32 %11695, 65535"
"  %11696 = lshr i32 %11692, 16"
"  %11696 = lshr i32 %11692, 16" -> "  %11698 = add nuw nsw i32 %11696, %11697"
"  %11697 = and i32 %11695, 65535"
"  %11697 = and i32 %11695, 65535" -> "  %11698 = add nuw nsw i32 %11696, %11697"
"  %11698 = add nuw nsw i32 %11696, %11697"
"  %11698 = add nuw nsw i32 %11696, %11697" -> "  %11700 = add nuw i32 %11698, %11699"
"  %11699 = and i32 %11695, -65536"
"  %11699 = and i32 %11695, -65536" -> "  %11700 = add nuw i32 %11698, %11699"
"  %11700 = add nuw i32 %11698, %11699"
"  %11700 = add nuw i32 %11698, %11699" -> "  %11708 = add nuw i32 %11700, %11707"
"  %11701 = and i32 %11651, 65535"
"  %11701 = and i32 %11651, 65535" -> "  %11703 = add nuw nsw i32 %11701, %11702"
"  %11702 = and i32 %11683, 65532"
"  %11702 = and i32 %11683, 65532" -> "  %11703 = add nuw nsw i32 %11701, %11702"
"  %11703 = add nuw nsw i32 %11701, %11702"
"  %11703 = add nuw nsw i32 %11701, %11702" -> "  %11714 = and i32 %11703, 65535""  %11703 = add nuw nsw i32 %11701, %11702" -> "  %11710 = lshr i32 %11703, 16"
"  %11704 = and i32 %11692, 65535"
"  %11704 = and i32 %11692, 65535" -> "  %11706 = add nuw nsw i32 %11705, %11704"
"  %11705 = lshr i32 %11651, 16"
"  %11705 = lshr i32 %11651, 16" -> "  %11706 = add nuw nsw i32 %11705, %11704"
"  %11706 = add nuw nsw i32 %11705, %11704"
"  %11706 = add nuw nsw i32 %11705, %11704" -> "  %11709 = and i32 %11706, 65535""  %11706 = add nuw nsw i32 %11705, %11704" -> "  %11707 = lshr i32 %11706, 16"
"  %11707 = lshr i32 %11706, 16"
"  %11707 = lshr i32 %11706, 16" -> "  %11708 = add nuw i32 %11700, %11707"
"  %11708 = add nuw i32 %11700, %11707"
"  %11708 = add nuw i32 %11700, %11707" -> "  %11713 = add nuw i32 %11708, %11712"
"  %11709 = and i32 %11706, 65535"
"  %11709 = and i32 %11706, 65535" -> "  %11711 = add nuw nsw i32 %11710, %11709"
"  %11710 = lshr i32 %11703, 16"
"  %11710 = lshr i32 %11703, 16" -> "  %11711 = add nuw nsw i32 %11710, %11709"
"  %11711 = add nuw nsw i32 %11710, %11709"
"  %11711 = add nuw nsw i32 %11710, %11709" -> "  %11717 = and i32 %11711, 65535""  %11711 = add nuw nsw i32 %11710, %11709" -> "  %11712 = lshr i32 %11711, 16"
"  %11712 = lshr i32 %11711, 16"
"  %11712 = lshr i32 %11711, 16" -> "  %11713 = add nuw i32 %11708, %11712"
"  %11713 = add nuw i32 %11708, %11712"
"  %11713 = add nuw i32 %11708, %11712" -> "  %11726 = and i32 %11713, -65536""  %11713 = add nuw i32 %11708, %11712" -> "  %11724 = and i32 %11713, 65535"
"  %11714 = and i32 %11703, 65535"
"  %11714 = and i32 %11703, 65535" -> "  %11716 = add nuw nsw i32 %11715, %11714"
"  %11715 = and i32 %11682, 65535"
"  %11715 = and i32 %11682, 65535" -> "  %11716 = add nuw nsw i32 %11715, %11714"
"  %11716 = add nuw nsw i32 %11715, %11714"
"  %11716 = add nuw nsw i32 %11715, %11714" -> "  %11757 = and i32 %11716, 65535""  %11716 = add nuw nsw i32 %11715, %11714" -> "  %11720 = lshr i32 %11716, 16"
"  %11717 = and i32 %11711, 65535"
"  %11717 = and i32 %11711, 65535" -> "  %11719 = add nuw nsw i32 %11718, %11717"
"  %11718 = lshr i32 %11682, 16"
"  %11718 = lshr i32 %11682, 16" -> "  %11719 = add nuw nsw i32 %11718, %11717"
"  %11719 = add nuw nsw i32 %11718, %11717"
"  %11719 = add nuw nsw i32 %11718, %11717" -> "  %11723 = lshr i32 %11719, 16""  %11719 = add nuw nsw i32 %11718, %11717" -> "  %11721 = and i32 %11719, 65535"
"  %11720 = lshr i32 %11716, 16"
"  %11720 = lshr i32 %11716, 16" -> "  %11722 = add nuw nsw i32 %11720, %11721"
"  %11721 = and i32 %11719, 65535"
"  %11721 = and i32 %11719, 65535" -> "  %11722 = add nuw nsw i32 %11720, %11721"
"  %11722 = add nuw nsw i32 %11720, %11721"
"  %11722 = add nuw nsw i32 %11720, %11721" -> "  %11764 = and i32 %11722, 65535""  %11722 = add nuw nsw i32 %11720, %11721" -> "  %11728 = lshr i32 %11722, 16"
"  %11723 = lshr i32 %11719, 16"
"  %11723 = lshr i32 %11719, 16" -> "  %11725 = add nuw nsw i32 %11723, %11724"
"  %11724 = and i32 %11713, 65535"
"  %11724 = and i32 %11713, 65535" -> "  %11725 = add nuw nsw i32 %11723, %11724"
"  %11725 = add nuw nsw i32 %11723, %11724"
"  %11725 = add nuw nsw i32 %11723, %11724" -> "  %11727 = add nuw i32 %11725, %11726"
"  %11726 = and i32 %11713, -65536"
"  %11726 = and i32 %11713, -65536" -> "  %11727 = add nuw i32 %11725, %11726"
"  %11727 = add nuw i32 %11725, %11726"
"  %11727 = add nuw i32 %11725, %11726" -> "  %11729 = add nuw i32 %11727, %11728"
"  %11728 = lshr i32 %11722, 16"
"  %11728 = lshr i32 %11722, 16" -> "  %11729 = add nuw i32 %11727, %11728"
"  %11729 = add nuw i32 %11727, %11728"
"  %11729 = add nuw i32 %11727, %11728" -> "  %11767 = add nuw i32 %11729, %11766"
"  %11730 = and i32 %11603, 65535"
"  %11730 = and i32 %11603, 65535" -> "  %11732 = add nuw nsw i32 %11731, %11730"
"  %11731 = and i32 %11567, 65535"
"  %11731 = and i32 %11567, 65535" -> "  %11732 = add nuw nsw i32 %11731, %11730"
"  %11732 = add nuw nsw i32 %11731, %11730"
"  %11732 = add nuw nsw i32 %11731, %11730" -> "  %11998 = and i32 %11732, 65535""  %11732 = add nuw nsw i32 %11731, %11730" -> "  %11736 = lshr i32 %11732, 16"
"  %11733 = and i32 %11612, 65535"
"  %11733 = and i32 %11612, 65535" -> "  %11735 = add nuw nsw i32 %11734, %11733"
"  %11734 = and i32 %11573, 65535"
"  %11734 = and i32 %11573, 65535" -> "  %11735 = add nuw nsw i32 %11734, %11733"
"  %11735 = add nuw nsw i32 %11734, %11733"
"  %11735 = add nuw nsw i32 %11734, %11733" -> "  %11739 = lshr i32 %11735, 16""  %11735 = add nuw nsw i32 %11734, %11733" -> "  %11737 = and i32 %11735, 65535"
"  %11736 = lshr i32 %11732, 16"
"  %11736 = lshr i32 %11732, 16" -> "  %11738 = add nuw nsw i32 %11737, %11736"
"  %11737 = and i32 %11735, 65535"
"  %11737 = and i32 %11735, 65535" -> "  %11738 = add nuw nsw i32 %11737, %11736"
"  %11738 = add nuw nsw i32 %11737, %11736"
"  %11738 = add nuw nsw i32 %11737, %11736" -> "  %12001 = and i32 %11738, 65535""  %11738 = add nuw nsw i32 %11737, %11736" -> "  %11740 = lshr i32 %11738, 16"
"  %11739 = lshr i32 %11735, 16"
"  %11739 = lshr i32 %11735, 16" -> "  %11751 = add nuw nsw i32 %11740, %11739"
"  %11740 = lshr i32 %11738, 16"
"  %11740 = lshr i32 %11738, 16" -> "  %11751 = add nuw nsw i32 %11740, %11739"
"  %11741 = and i32 %11587, 65535"
"  %11741 = and i32 %11587, 65535" -> "  %11743 = add nuw nsw i32 %11741, %11742"
"  %11742 = and i32 %11672, 65535"
"  %11742 = and i32 %11672, 65535" -> "  %11743 = add nuw nsw i32 %11741, %11742"
"  %11743 = add nuw nsw i32 %11741, %11742"
"  %11743 = add nuw nsw i32 %11741, %11742" -> "  %11750 = and i32 %11743, 65535""  %11743 = add nuw nsw i32 %11741, %11742" -> "  %11747 = lshr i32 %11743, 16"
"  %11744 = and i32 %11680, 65535"
"  %11744 = and i32 %11680, 65535" -> "  %11746 = add nuw nsw i32 %11745, %11744"
"  %11745 = and i32 %11590, 65535"
"  %11745 = and i32 %11590, 65535" -> "  %11746 = add nuw nsw i32 %11745, %11744"
"  %11746 = add nuw nsw i32 %11745, %11744"
"  %11746 = add nuw nsw i32 %11745, %11744" -> "  %11756 = lshr i32 %11746, 16""  %11746 = add nuw nsw i32 %11745, %11744" -> "  %11748 = and i32 %11746, 65535"
"  %11747 = lshr i32 %11743, 16"
"  %11747 = lshr i32 %11743, 16" -> "  %11749 = add nuw nsw i32 %11748, %11747"
"  %11748 = and i32 %11746, 65535"
"  %11748 = and i32 %11746, 65535" -> "  %11749 = add nuw nsw i32 %11748, %11747"
"  %11749 = add nuw nsw i32 %11748, %11747"
"  %11749 = add nuw nsw i32 %11748, %11747" -> "  %11759 = lshr i32 %11749, 16""  %11749 = add nuw nsw i32 %11748, %11747" -> "  %11754 = and i32 %11749, 65535"
"  %11750 = and i32 %11743, 65535"
"  %11750 = and i32 %11743, 65535" -> "  %11752 = add nuw nsw i32 %11751, %11750"
"  %11751 = add nuw nsw i32 %11740, %11739"
"  %11751 = add nuw nsw i32 %11740, %11739" -> "  %11752 = add nuw nsw i32 %11751, %11750"
"  %11752 = add nuw nsw i32 %11751, %11750"
"  %11752 = add nuw nsw i32 %11751, %11750" -> "  %12007 = and i32 %11752, 65535""  %11752 = add nuw nsw i32 %11751, %11750" -> "  %11753 = lshr i32 %11752, 16"
"  %11753 = lshr i32 %11752, 16"
"  %11753 = lshr i32 %11752, 16" -> "  %11755 = add nuw nsw i32 %11754, %11753"
"  %11754 = and i32 %11749, 65535"
"  %11754 = and i32 %11749, 65535" -> "  %11755 = add nuw nsw i32 %11754, %11753"
"  %11755 = add nuw nsw i32 %11754, %11753"
"  %11755 = add nuw nsw i32 %11754, %11753" -> "  %12010 = and i32 %11755, 65535""  %11755 = add nuw nsw i32 %11754, %11753" -> "  %11761 = lshr i32 %11755, 16"
"  %11756 = lshr i32 %11746, 16"
"  %11756 = lshr i32 %11746, 16" -> "  %11758 = add nuw nsw i32 %11756, %11757"
"  %11757 = and i32 %11716, 65535"
"  %11757 = and i32 %11716, 65535" -> "  %11758 = add nuw nsw i32 %11756, %11757"
"  %11758 = add nuw nsw i32 %11756, %11757"
"  %11758 = add nuw nsw i32 %11756, %11757" -> "  %11760 = add nuw nsw i32 %11758, %11759"
"  %11759 = lshr i32 %11749, 16"
"  %11759 = lshr i32 %11749, 16" -> "  %11760 = add nuw nsw i32 %11758, %11759"
"  %11760 = add nuw nsw i32 %11758, %11759"
"  %11760 = add nuw nsw i32 %11758, %11759" -> "  %11762 = add nuw nsw i32 %11760, %11761"
"  %11761 = lshr i32 %11755, 16"
"  %11761 = lshr i32 %11755, 16" -> "  %11762 = add nuw nsw i32 %11760, %11761"
"  %11762 = add nuw nsw i32 %11760, %11761"
"  %11762 = add nuw nsw i32 %11760, %11761" -> "  %11934 = and i32 %11762, 65535""  %11762 = add nuw nsw i32 %11760, %11761" -> "  %11763 = lshr i32 %11762, 16"
"  %11763 = lshr i32 %11762, 16"
"  %11763 = lshr i32 %11762, 16" -> "  %11765 = add nuw nsw i32 %11763, %11764"
"  %11764 = and i32 %11722, 65535"
"  %11764 = and i32 %11722, 65535" -> "  %11765 = add nuw nsw i32 %11763, %11764"
"  %11765 = add nuw nsw i32 %11763, %11764"
"  %11765 = add nuw nsw i32 %11763, %11764" -> "  %11937 = and i32 %11765, 65535""  %11765 = add nuw nsw i32 %11763, %11764" -> "  %11766 = lshr i32 %11765, 16"
"  %11766 = lshr i32 %11765, 16"
"  %11766 = lshr i32 %11765, 16" -> "  %11767 = add nuw i32 %11729, %11766"
"  %11767 = add nuw i32 %11729, %11766"
"  %11767 = add nuw i32 %11729, %11766" -> "  %11943 = and i32 %11767, 65535""  %11767 = add nuw i32 %11729, %11766" -> "  %11946 = lshr i32 %11767, 16"
"  %11768 = mul nuw nsw i32 %9932, 4087"
"  %11768 = mul nuw nsw i32 %9932, 4087" -> "  %11895 = and i32 %11768, 65535""  %11768 = mul nuw nsw i32 %9932, 4087" -> "  %11769 = lshr i32 %11768, 16"
"  %11769 = lshr i32 %11768, 16"
"  %11769 = lshr i32 %11768, 16" -> "  %11772 = add nuw nsw i32 %11771, %11769"
"  %11770 = mul nuw nsw i32 %9935, 4087"
"  %11770 = mul nuw nsw i32 %9935, 4087" -> "  %11773 = and i32 %11770, 268369920""  %11770 = mul nuw nsw i32 %9935, 4087" -> "  %11771 = and i32 %11770, 65535"
"  %11771 = and i32 %11770, 65535"
"  %11771 = and i32 %11770, 65535" -> "  %11772 = add nuw nsw i32 %11771, %11769"
"  %11772 = add nuw nsw i32 %11771, %11769"
"  %11772 = add nuw nsw i32 %11771, %11769" -> "  %11774 = add nuw nsw i32 %11772, %11773"
"  %11773 = and i32 %11770, 268369920"
"  %11773 = and i32 %11770, 268369920" -> "  %11774 = add nuw nsw i32 %11772, %11773"
"  %11774 = add nuw nsw i32 %11772, %11773"
"  %11774 = add nuw nsw i32 %11772, %11773" -> "  %11778 = lshr i32 %11774, 16""  %11774 = add nuw nsw i32 %11772, %11773" -> "  %11776 = and i32 %11774, 65535"
"  %11775 = mul nuw nsw i32 %9932, 11561"
"  %11775 = mul nuw nsw i32 %9932, 11561" -> "  %11777 = add nuw nsw i32 %11776, %11775"
"  %11776 = and i32 %11774, 65535"
"  %11776 = and i32 %11774, 65535" -> "  %11777 = add nuw nsw i32 %11776, %11775"
"  %11777 = add nuw nsw i32 %11776, %11775"
"  %11777 = add nuw nsw i32 %11776, %11775" -> "  %11898 = and i32 %11777, 65535""  %11777 = add nuw nsw i32 %11776, %11775" -> "  %11781 = lshr i32 %11777, 16"
"  %11778 = lshr i32 %11774, 16"
"  %11778 = lshr i32 %11774, 16" -> "  %11780 = add nuw nsw i32 %11778, %11779"
"  %11779 = mul nuw nsw i32 %9935, 11561"
"  %11779 = mul nuw nsw i32 %9935, 11561" -> "  %11780 = add nuw nsw i32 %11778, %11779"
"  %11780 = add nuw nsw i32 %11778, %11779"
"  %11780 = add nuw nsw i32 %11778, %11779" -> "  %11784 = and i32 %11780, 2147418112""  %11780 = add nuw nsw i32 %11778, %11779" -> "  %11782 = and i32 %11780, 65535"
"  %11781 = lshr i32 %11777, 16"
"  %11781 = lshr i32 %11777, 16" -> "  %11783 = add nuw nsw i32 %11781, %11782"
"  %11782 = and i32 %11780, 65535"
"  %11782 = and i32 %11780, 65535" -> "  %11783 = add nuw nsw i32 %11781, %11782"
"  %11783 = add nuw nsw i32 %11781, %11782"
"  %11783 = add nuw nsw i32 %11781, %11782" -> "  %11785 = add nuw nsw i32 %11783, %11784"
"  %11784 = and i32 %11780, 2147418112"
"  %11784 = and i32 %11780, 2147418112" -> "  %11785 = add nuw nsw i32 %11783, %11784"
"  %11785 = add nuw nsw i32 %11783, %11784"
"  %11785 = add nuw nsw i32 %11783, %11784" -> "  %11808 = lshr i32 %11785, 16""  %11785 = add nuw nsw i32 %11783, %11784" -> "  %11804 = and i32 %11785, 65535"
"  %11786 = mul nuw nsw i32 %9952, 4087"
"  %11786 = mul nuw nsw i32 %9952, 4087" -> "  %11805 = and i32 %11786, 65535""  %11786 = mul nuw nsw i32 %9952, 4087" -> "  %11787 = lshr i32 %11786, 16"
"  %11787 = lshr i32 %11786, 16"
"  %11787 = lshr i32 %11786, 16" -> "  %11790 = add nuw nsw i32 %11789, %11787"
"  %11788 = mul nuw nsw i32 %9953, 4087"
"  %11788 = mul nuw nsw i32 %9953, 4087" -> "  %11791 = and i32 %11788, 268369920""  %11788 = mul nuw nsw i32 %9953, 4087" -> "  %11789 = and i32 %11788, 65535"
"  %11789 = and i32 %11788, 65535"
"  %11789 = and i32 %11788, 65535" -> "  %11790 = add nuw nsw i32 %11789, %11787"
"  %11790 = add nuw nsw i32 %11789, %11787"
"  %11790 = add nuw nsw i32 %11789, %11787" -> "  %11792 = add nuw nsw i32 %11790, %11791"
"  %11791 = and i32 %11788, 268369920"
"  %11791 = and i32 %11788, 268369920" -> "  %11792 = add nuw nsw i32 %11790, %11791"
"  %11792 = add nuw nsw i32 %11790, %11791"
"  %11792 = add nuw nsw i32 %11790, %11791" -> "  %11796 = lshr i32 %11792, 16""  %11792 = add nuw nsw i32 %11790, %11791" -> "  %11794 = and i32 %11792, 65535"
"  %11793 = mul nuw nsw i32 %9952, 11561"
"  %11793 = mul nuw nsw i32 %9952, 11561" -> "  %11795 = add nuw nsw i32 %11794, %11793"
"  %11794 = and i32 %11792, 65535"
"  %11794 = and i32 %11792, 65535" -> "  %11795 = add nuw nsw i32 %11794, %11793"
"  %11795 = add nuw nsw i32 %11794, %11793"
"  %11795 = add nuw nsw i32 %11794, %11793" -> "  %11807 = and i32 %11795, 65535""  %11795 = add nuw nsw i32 %11794, %11793" -> "  %11799 = lshr i32 %11795, 16"
"  %11796 = lshr i32 %11792, 16"
"  %11796 = lshr i32 %11792, 16" -> "  %11798 = add nuw nsw i32 %11796, %11797"
"  %11797 = mul nuw nsw i32 %9953, 11561"
"  %11797 = mul nuw nsw i32 %9953, 11561" -> "  %11798 = add nuw nsw i32 %11796, %11797"
"  %11798 = add nuw nsw i32 %11796, %11797"
"  %11798 = add nuw nsw i32 %11796, %11797" -> "  %11802 = and i32 %11798, 2147418112""  %11798 = add nuw nsw i32 %11796, %11797" -> "  %11800 = and i32 %11798, 65535"
"  %11799 = lshr i32 %11795, 16"
"  %11799 = lshr i32 %11795, 16" -> "  %11801 = add nuw nsw i32 %11799, %11800"
"  %11800 = and i32 %11798, 65535"
"  %11800 = and i32 %11798, 65535" -> "  %11801 = add nuw nsw i32 %11799, %11800"
"  %11801 = add nuw nsw i32 %11799, %11800"
"  %11801 = add nuw nsw i32 %11799, %11800" -> "  %11803 = add nuw nsw i32 %11801, %11802"
"  %11802 = and i32 %11798, 2147418112"
"  %11802 = and i32 %11798, 2147418112" -> "  %11803 = add nuw nsw i32 %11801, %11802"
"  %11803 = add nuw nsw i32 %11801, %11802"
"  %11803 = add nuw nsw i32 %11801, %11802" -> "  %11811 = add nuw nsw i32 %11803, %11810"
"  %11804 = and i32 %11785, 65535"
"  %11804 = and i32 %11785, 65535" -> "  %11806 = add nuw nsw i32 %11804, %11805"
"  %11805 = and i32 %11786, 65535"
"  %11805 = and i32 %11786, 65535" -> "  %11806 = add nuw nsw i32 %11804, %11805"
"  %11806 = add nuw nsw i32 %11804, %11805"
"  %11806 = add nuw nsw i32 %11804, %11805" -> "  %11835 = and i32 %11806, 65535""  %11806 = add nuw nsw i32 %11804, %11805" -> "  %11813 = lshr i32 %11806, 16"
"  %11807 = and i32 %11795, 65535"
"  %11807 = and i32 %11795, 65535" -> "  %11809 = add nuw nsw i32 %11808, %11807"
"  %11808 = lshr i32 %11785, 16"
"  %11808 = lshr i32 %11785, 16" -> "  %11809 = add nuw nsw i32 %11808, %11807"
"  %11809 = add nuw nsw i32 %11808, %11807"
"  %11809 = add nuw nsw i32 %11808, %11807" -> "  %11812 = and i32 %11809, 65535""  %11809 = add nuw nsw i32 %11808, %11807" -> "  %11810 = lshr i32 %11809, 16"
"  %11810 = lshr i32 %11809, 16"
"  %11810 = lshr i32 %11809, 16" -> "  %11811 = add nuw nsw i32 %11803, %11810"
"  %11811 = add nuw nsw i32 %11803, %11810"
"  %11811 = add nuw nsw i32 %11803, %11810" -> "  %11816 = add nuw nsw i32 %11811, %11815"
"  %11812 = and i32 %11809, 65535"
"  %11812 = and i32 %11809, 65535" -> "  %11814 = add nuw nsw i32 %11812, %11813"
"  %11813 = lshr i32 %11806, 16"
"  %11813 = lshr i32 %11806, 16" -> "  %11814 = add nuw nsw i32 %11812, %11813"
"  %11814 = add nuw nsw i32 %11812, %11813"
"  %11814 = add nuw nsw i32 %11812, %11813" -> "  %11838 = and i32 %11814, 65535""  %11814 = add nuw nsw i32 %11812, %11813" -> "  %11815 = lshr i32 %11814, 16"
"  %11815 = lshr i32 %11814, 16"
"  %11815 = lshr i32 %11814, 16" -> "  %11816 = add nuw nsw i32 %11811, %11815"
"  %11816 = add nuw nsw i32 %11811, %11815"
"  %11816 = add nuw nsw i32 %11811, %11815" -> "  %11870 = lshr i32 %11816, 16""  %11816 = add nuw nsw i32 %11811, %11815" -> "  %11866 = and i32 %11816, 65535"
"  %11817 = mul nuw nsw i32 %9932, 21884"
"  %11817 = mul nuw nsw i32 %9932, 21884" -> "  %11836 = and i32 %11817, 65532""  %11817 = mul nuw nsw i32 %9932, 21884" -> "  %11818 = lshr i32 %11817, 16"
"  %11818 = lshr i32 %11817, 16"
"  %11818 = lshr i32 %11817, 16" -> "  %11821 = add nuw nsw i32 %11820, %11818"
"  %11819 = mul nuw nsw i32 %9935, 21884"
"  %11819 = mul nuw nsw i32 %9935, 21884" -> "  %11822 = and i32 %11819, 2147418112""  %11819 = mul nuw nsw i32 %9935, 21884" -> "  %11820 = and i32 %11819, 65532"
"  %11820 = and i32 %11819, 65532"
"  %11820 = and i32 %11819, 65532" -> "  %11821 = add nuw nsw i32 %11820, %11818"
"  %11821 = add nuw nsw i32 %11820, %11818"
"  %11821 = add nuw nsw i32 %11820, %11818" -> "  %11823 = add nuw nsw i32 %11821, %11822"
"  %11822 = and i32 %11819, 2147418112"
"  %11822 = and i32 %11819, 2147418112" -> "  %11823 = add nuw nsw i32 %11821, %11822"
"  %11823 = add nuw nsw i32 %11821, %11822"
"  %11823 = add nuw nsw i32 %11821, %11822" -> "  %11827 = lshr i32 %11823, 16""  %11823 = add nuw nsw i32 %11821, %11822" -> "  %11825 = and i32 %11823, 65535"
"  %11824 = mul nuw i32 %9932, 36786"
"  %11824 = mul nuw i32 %9932, 36786" -> "  %11826 = add nuw i32 %11825, %11824"
"  %11825 = and i32 %11823, 65535"
"  %11825 = and i32 %11823, 65535" -> "  %11826 = add nuw i32 %11825, %11824"
"  %11826 = add nuw i32 %11825, %11824"
"  %11826 = add nuw i32 %11825, %11824" -> "  %11839 = and i32 %11826, 65535""  %11826 = add nuw i32 %11825, %11824" -> "  %11830 = lshr i32 %11826, 16"
"  %11827 = lshr i32 %11823, 16"
"  %11827 = lshr i32 %11823, 16" -> "  %11829 = add nuw i32 %11827, %11828"
"  %11828 = mul nuw i32 %9935, 36786"
"  %11828 = mul nuw i32 %9935, 36786" -> "  %11829 = add nuw i32 %11827, %11828"
"  %11829 = add nuw i32 %11827, %11828"
"  %11829 = add nuw i32 %11827, %11828" -> "  %11833 = and i32 %11829, -65536""  %11829 = add nuw i32 %11827, %11828" -> "  %11831 = and i32 %11829, 65535"
"  %11830 = lshr i32 %11826, 16"
"  %11830 = lshr i32 %11826, 16" -> "  %11832 = add nuw nsw i32 %11830, %11831"
"  %11831 = and i32 %11829, 65535"
"  %11831 = and i32 %11829, 65535" -> "  %11832 = add nuw nsw i32 %11830, %11831"
"  %11832 = add nuw nsw i32 %11830, %11831"
"  %11832 = add nuw nsw i32 %11830, %11831" -> "  %11834 = add nuw i32 %11832, %11833"
"  %11833 = and i32 %11829, -65536"
"  %11833 = and i32 %11829, -65536" -> "  %11834 = add nuw i32 %11832, %11833"
"  %11834 = add nuw i32 %11832, %11833"
"  %11834 = add nuw i32 %11832, %11833" -> "  %11842 = add nuw i32 %11834, %11841"
"  %11835 = and i32 %11806, 65535"
"  %11835 = and i32 %11806, 65535" -> "  %11837 = add nuw nsw i32 %11835, %11836"
"  %11836 = and i32 %11817, 65532"
"  %11836 = and i32 %11817, 65532" -> "  %11837 = add nuw nsw i32 %11835, %11836"
"  %11837 = add nuw nsw i32 %11835, %11836"
"  %11837 = add nuw nsw i32 %11835, %11836" -> "  %11905 = and i32 %11837, 65535""  %11837 = add nuw nsw i32 %11835, %11836" -> "  %11844 = lshr i32 %11837, 16"
"  %11838 = and i32 %11814, 65535"
"  %11838 = and i32 %11814, 65535" -> "  %11840 = add nuw nsw i32 %11838, %11839"
"  %11839 = and i32 %11826, 65535"
"  %11839 = and i32 %11826, 65535" -> "  %11840 = add nuw nsw i32 %11838, %11839"
"  %11840 = add nuw nsw i32 %11838, %11839"
"  %11840 = add nuw nsw i32 %11838, %11839" -> "  %11843 = and i32 %11840, 65535""  %11840 = add nuw nsw i32 %11838, %11839" -> "  %11841 = lshr i32 %11840, 16"
"  %11841 = lshr i32 %11840, 16"
"  %11841 = lshr i32 %11840, 16" -> "  %11842 = add nuw i32 %11834, %11841"
"  %11842 = add nuw i32 %11834, %11841"
"  %11842 = add nuw i32 %11834, %11841" -> "  %11847 = add nuw i32 %11842, %11846"
"  %11843 = and i32 %11840, 65535"
"  %11843 = and i32 %11840, 65535" -> "  %11845 = add nuw nsw i32 %11843, %11844"
"  %11844 = lshr i32 %11837, 16"
"  %11844 = lshr i32 %11837, 16" -> "  %11845 = add nuw nsw i32 %11843, %11844"
"  %11845 = add nuw nsw i32 %11843, %11844"
"  %11845 = add nuw nsw i32 %11843, %11844" -> "  %11908 = and i32 %11845, 65535""  %11845 = add nuw nsw i32 %11843, %11844" -> "  %11846 = lshr i32 %11845, 16"
"  %11846 = lshr i32 %11845, 16"
"  %11846 = lshr i32 %11845, 16" -> "  %11847 = add nuw i32 %11842, %11846"
"  %11847 = add nuw i32 %11842, %11846"
"  %11847 = add nuw i32 %11842, %11846" -> "  %11883 = lshr i32 %11847, 16""  %11847 = add nuw i32 %11842, %11846" -> "  %11880 = and i32 %11847, 65535"
"  %11848 = mul nuw nsw i32 %9952, 21884"
"  %11848 = mul nuw nsw i32 %9952, 21884" -> "  %11867 = and i32 %11848, 65532""  %11848 = mul nuw nsw i32 %9952, 21884" -> "  %11849 = lshr i32 %11848, 16"
"  %11849 = lshr i32 %11848, 16"
"  %11849 = lshr i32 %11848, 16" -> "  %11852 = add nuw nsw i32 %11851, %11849"
"  %11850 = mul nuw nsw i32 %9953, 21884"
"  %11850 = mul nuw nsw i32 %9953, 21884" -> "  %11853 = and i32 %11850, 2147418112""  %11850 = mul nuw nsw i32 %9953, 21884" -> "  %11851 = and i32 %11850, 65532"
"  %11851 = and i32 %11850, 65532"
"  %11851 = and i32 %11850, 65532" -> "  %11852 = add nuw nsw i32 %11851, %11849"
"  %11852 = add nuw nsw i32 %11851, %11849"
"  %11852 = add nuw nsw i32 %11851, %11849" -> "  %11854 = add nuw nsw i32 %11852, %11853"
"  %11853 = and i32 %11850, 2147418112"
"  %11853 = and i32 %11850, 2147418112" -> "  %11854 = add nuw nsw i32 %11852, %11853"
"  %11854 = add nuw nsw i32 %11852, %11853"
"  %11854 = add nuw nsw i32 %11852, %11853" -> "  %11858 = lshr i32 %11854, 16""  %11854 = add nuw nsw i32 %11852, %11853" -> "  %11856 = and i32 %11854, 65535"
"  %11855 = mul nuw i32 %9952, 36786"
"  %11855 = mul nuw i32 %9952, 36786" -> "  %11857 = add nuw i32 %11856, %11855"
"  %11856 = and i32 %11854, 65535"
"  %11856 = and i32 %11854, 65535" -> "  %11857 = add nuw i32 %11856, %11855"
"  %11857 = add nuw i32 %11856, %11855"
"  %11857 = add nuw i32 %11856, %11855" -> "  %11869 = and i32 %11857, 65535""  %11857 = add nuw i32 %11856, %11855" -> "  %11861 = lshr i32 %11857, 16"
"  %11858 = lshr i32 %11854, 16"
"  %11858 = lshr i32 %11854, 16" -> "  %11860 = add nuw i32 %11858, %11859"
"  %11859 = mul nuw i32 %9953, 36786"
"  %11859 = mul nuw i32 %9953, 36786" -> "  %11860 = add nuw i32 %11858, %11859"
"  %11860 = add nuw i32 %11858, %11859"
"  %11860 = add nuw i32 %11858, %11859" -> "  %11864 = and i32 %11860, -65536""  %11860 = add nuw i32 %11858, %11859" -> "  %11862 = and i32 %11860, 65535"
"  %11861 = lshr i32 %11857, 16"
"  %11861 = lshr i32 %11857, 16" -> "  %11863 = add nuw nsw i32 %11861, %11862"
"  %11862 = and i32 %11860, 65535"
"  %11862 = and i32 %11860, 65535" -> "  %11863 = add nuw nsw i32 %11861, %11862"
"  %11863 = add nuw nsw i32 %11861, %11862"
"  %11863 = add nuw nsw i32 %11861, %11862" -> "  %11865 = add nuw i32 %11863, %11864"
"  %11864 = and i32 %11860, -65536"
"  %11864 = and i32 %11860, -65536" -> "  %11865 = add nuw i32 %11863, %11864"
"  %11865 = add nuw i32 %11863, %11864"
"  %11865 = add nuw i32 %11863, %11864" -> "  %11873 = add nuw i32 %11865, %11872"
"  %11866 = and i32 %11816, 65535"
"  %11866 = and i32 %11816, 65535" -> "  %11868 = add nuw nsw i32 %11866, %11867"
"  %11867 = and i32 %11848, 65532"
"  %11867 = and i32 %11848, 65532" -> "  %11868 = add nuw nsw i32 %11866, %11867"
"  %11868 = add nuw nsw i32 %11866, %11867"
"  %11868 = add nuw nsw i32 %11866, %11867" -> "  %11879 = and i32 %11868, 65535""  %11868 = add nuw nsw i32 %11866, %11867" -> "  %11875 = lshr i32 %11868, 16"
"  %11869 = and i32 %11857, 65535"
"  %11869 = and i32 %11857, 65535" -> "  %11871 = add nuw nsw i32 %11870, %11869"
"  %11870 = lshr i32 %11816, 16"
"  %11870 = lshr i32 %11816, 16" -> "  %11871 = add nuw nsw i32 %11870, %11869"
"  %11871 = add nuw nsw i32 %11870, %11869"
"  %11871 = add nuw nsw i32 %11870, %11869" -> "  %11874 = and i32 %11871, 65535""  %11871 = add nuw nsw i32 %11870, %11869" -> "  %11872 = lshr i32 %11871, 16"
"  %11872 = lshr i32 %11871, 16"
"  %11872 = lshr i32 %11871, 16" -> "  %11873 = add nuw i32 %11865, %11872"
"  %11873 = add nuw i32 %11865, %11872"
"  %11873 = add nuw i32 %11865, %11872" -> "  %11878 = add nuw i32 %11873, %11877"
"  %11874 = and i32 %11871, 65535"
"  %11874 = and i32 %11871, 65535" -> "  %11876 = add nuw nsw i32 %11875, %11874"
"  %11875 = lshr i32 %11868, 16"
"  %11875 = lshr i32 %11868, 16" -> "  %11876 = add nuw nsw i32 %11875, %11874"
"  %11876 = add nuw nsw i32 %11875, %11874"
"  %11876 = add nuw nsw i32 %11875, %11874" -> "  %11882 = and i32 %11876, 65535""  %11876 = add nuw nsw i32 %11875, %11874" -> "  %11877 = lshr i32 %11876, 16"
"  %11877 = lshr i32 %11876, 16"
"  %11877 = lshr i32 %11876, 16" -> "  %11878 = add nuw i32 %11873, %11877"
"  %11878 = add nuw i32 %11873, %11877"
"  %11878 = add nuw i32 %11873, %11877" -> "  %11891 = and i32 %11878, -65536""  %11878 = add nuw i32 %11873, %11877" -> "  %11889 = and i32 %11878, 65535"
"  %11879 = and i32 %11868, 65535"
"  %11879 = and i32 %11868, 65535" -> "  %11881 = add nuw nsw i32 %11880, %11879"
"  %11880 = and i32 %11847, 65535"
"  %11880 = and i32 %11847, 65535" -> "  %11881 = add nuw nsw i32 %11880, %11879"
"  %11881 = add nuw nsw i32 %11880, %11879"
"  %11881 = add nuw nsw i32 %11880, %11879" -> "  %11922 = and i32 %11881, 65535""  %11881 = add nuw nsw i32 %11880, %11879" -> "  %11885 = lshr i32 %11881, 16"
"  %11882 = and i32 %11876, 65535"
"  %11882 = and i32 %11876, 65535" -> "  %11884 = add nuw nsw i32 %11883, %11882"
"  %11883 = lshr i32 %11847, 16"
"  %11883 = lshr i32 %11847, 16" -> "  %11884 = add nuw nsw i32 %11883, %11882"
"  %11884 = add nuw nsw i32 %11883, %11882"
"  %11884 = add nuw nsw i32 %11883, %11882" -> "  %11888 = lshr i32 %11884, 16""  %11884 = add nuw nsw i32 %11883, %11882" -> "  %11886 = and i32 %11884, 65535"
"  %11885 = lshr i32 %11881, 16"
"  %11885 = lshr i32 %11881, 16" -> "  %11887 = add nuw nsw i32 %11885, %11886"
"  %11886 = and i32 %11884, 65535"
"  %11886 = and i32 %11884, 65535" -> "  %11887 = add nuw nsw i32 %11885, %11886"
"  %11887 = add nuw nsw i32 %11885, %11886"
"  %11887 = add nuw nsw i32 %11885, %11886" -> "  %11929 = and i32 %11887, 65535""  %11887 = add nuw nsw i32 %11885, %11886" -> "  %11893 = lshr i32 %11887, 16"
"  %11888 = lshr i32 %11884, 16"
"  %11888 = lshr i32 %11884, 16" -> "  %11890 = add nuw nsw i32 %11888, %11889"
"  %11889 = and i32 %11878, 65535"
"  %11889 = and i32 %11878, 65535" -> "  %11890 = add nuw nsw i32 %11888, %11889"
"  %11890 = add nuw nsw i32 %11888, %11889"
"  %11890 = add nuw nsw i32 %11888, %11889" -> "  %11892 = add nuw i32 %11890, %11891"
"  %11891 = and i32 %11878, -65536"
"  %11891 = and i32 %11878, -65536" -> "  %11892 = add nuw i32 %11890, %11891"
"  %11892 = add nuw i32 %11890, %11891"
"  %11892 = add nuw i32 %11890, %11891" -> "  %11894 = add nuw i32 %11892, %11893"
"  %11893 = lshr i32 %11887, 16"
"  %11893 = lshr i32 %11887, 16" -> "  %11894 = add nuw i32 %11892, %11893"
"  %11894 = add nuw i32 %11892, %11893"
"  %11894 = add nuw i32 %11892, %11893" -> "  %11932 = add nuw i32 %11894, %11931"
"  %11895 = and i32 %11768, 65535"
"  %11895 = and i32 %11768, 65535" -> "  %11897 = add nuw nsw i32 %11896, %11895"
"  %11896 = and i32 %11597, 65535"
"  %11896 = and i32 %11597, 65535" -> "  %11897 = add nuw nsw i32 %11896, %11895"
"  %11897 = add nuw nsw i32 %11896, %11895"
"  %11897 = add nuw nsw i32 %11896, %11895" -> "  %11933 = and i32 %11897, 65535""  %11897 = add nuw nsw i32 %11896, %11895" -> "  %11901 = lshr i32 %11897, 16"
"  %11898 = and i32 %11777, 65535"
"  %11898 = and i32 %11777, 65535" -> "  %11900 = add nuw nsw i32 %11899, %11898"
"  %11899 = and i32 %11600, 65535"
"  %11899 = and i32 %11600, 65535" -> "  %11900 = add nuw nsw i32 %11899, %11898"
"  %11900 = add nuw nsw i32 %11899, %11898"
"  %11900 = add nuw nsw i32 %11899, %11898" -> "  %11914 = lshr i32 %11900, 16""  %11900 = add nuw nsw i32 %11899, %11898" -> "  %11902 = and i32 %11900, 65535"
"  %11901 = lshr i32 %11897, 16"
"  %11901 = lshr i32 %11897, 16" -> "  %11903 = add nuw nsw i32 %11902, %11901"
"  %11902 = and i32 %11900, 65535"
"  %11902 = and i32 %11900, 65535" -> "  %11903 = add nuw nsw i32 %11902, %11901"
"  %11903 = add nuw nsw i32 %11902, %11901"
"  %11903 = add nuw nsw i32 %11902, %11901" -> "  %11936 = and i32 %11903, 65535""  %11903 = add nuw nsw i32 %11902, %11901" -> "  %11916 = lshr i32 %11903, 16"
"  %11904 = and i32 %11602, 65535"
"  %11904 = and i32 %11602, 65535" -> "  %11906 = add nuw nsw i32 %11904, %11905"
"  %11905 = and i32 %11837, 65535"
"  %11905 = and i32 %11837, 65535" -> "  %11906 = add nuw nsw i32 %11904, %11905"
"  %11906 = add nuw nsw i32 %11904, %11905"
"  %11906 = add nuw nsw i32 %11904, %11905" -> "  %11913 = and i32 %11906, 65535""  %11906 = add nuw nsw i32 %11904, %11905" -> "  %11910 = lshr i32 %11906, 16"
"  %11907 = lshr i32 %11602, 16"
"  %11907 = lshr i32 %11602, 16" -> "  %11909 = add nuw nsw i32 %11907, %11908"
"  %11908 = and i32 %11845, 65535"
"  %11908 = and i32 %11845, 65535" -> "  %11909 = add nuw nsw i32 %11907, %11908"
"  %11909 = add nuw nsw i32 %11907, %11908"
"  %11909 = add nuw nsw i32 %11907, %11908" -> "  %11921 = lshr i32 %11909, 16""  %11909 = add nuw nsw i32 %11907, %11908" -> "  %11911 = and i32 %11909, 65535"
"  %11910 = lshr i32 %11906, 16"
"  %11910 = lshr i32 %11906, 16" -> "  %11912 = add nuw nsw i32 %11911, %11910"
"  %11911 = and i32 %11909, 65535"
"  %11911 = and i32 %11909, 65535" -> "  %11912 = add nuw nsw i32 %11911, %11910"
"  %11912 = add nuw nsw i32 %11911, %11910"
"  %11912 = add nuw nsw i32 %11911, %11910" -> "  %11924 = lshr i32 %11912, 16""  %11912 = add nuw nsw i32 %11911, %11910" -> "  %11919 = and i32 %11912, 65535"
"  %11913 = and i32 %11906, 65535"
"  %11913 = and i32 %11906, 65535" -> "  %11915 = add nuw nsw i32 %11913, %11914"
"  %11914 = lshr i32 %11900, 16"
"  %11914 = lshr i32 %11900, 16" -> "  %11915 = add nuw nsw i32 %11913, %11914"
"  %11915 = add nuw nsw i32 %11913, %11914"
"  %11915 = add nuw nsw i32 %11913, %11914" -> "  %11917 = add nuw nsw i32 %11915, %11916"
"  %11916 = lshr i32 %11903, 16"
"  %11916 = lshr i32 %11903, 16" -> "  %11917 = add nuw nsw i32 %11915, %11916"
"  %11917 = add nuw nsw i32 %11915, %11916"
"  %11917 = add nuw nsw i32 %11915, %11916" -> "  %11942 = and i32 %11917, 65535""  %11917 = add nuw nsw i32 %11915, %11916" -> "  %11918 = lshr i32 %11917, 16"
"  %11918 = lshr i32 %11917, 16"
"  %11918 = lshr i32 %11917, 16" -> "  %11920 = add nuw nsw i32 %11918, %11919"
"  %11919 = and i32 %11912, 65535"
"  %11919 = and i32 %11912, 65535" -> "  %11920 = add nuw nsw i32 %11918, %11919"
"  %11920 = add nuw nsw i32 %11918, %11919"
"  %11920 = add nuw nsw i32 %11918, %11919" -> "  %11945 = and i32 %11920, 65535""  %11920 = add nuw nsw i32 %11918, %11919" -> "  %11926 = lshr i32 %11920, 16"
"  %11921 = lshr i32 %11909, 16"
"  %11921 = lshr i32 %11909, 16" -> "  %11923 = add nuw nsw i32 %11921, %11922"
"  %11922 = and i32 %11881, 65535"
"  %11922 = and i32 %11881, 65535" -> "  %11923 = add nuw nsw i32 %11921, %11922"
"  %11923 = add nuw nsw i32 %11921, %11922"
"  %11923 = add nuw nsw i32 %11921, %11922" -> "  %11925 = add nuw nsw i32 %11923, %11924"
"  %11924 = lshr i32 %11912, 16"
"  %11924 = lshr i32 %11912, 16" -> "  %11925 = add nuw nsw i32 %11923, %11924"
"  %11925 = add nuw nsw i32 %11923, %11924"
"  %11925 = add nuw nsw i32 %11923, %11924" -> "  %11927 = add nuw nsw i32 %11925, %11926"
"  %11926 = lshr i32 %11920, 16"
"  %11926 = lshr i32 %11920, 16" -> "  %11927 = add nuw nsw i32 %11925, %11926"
"  %11927 = add nuw nsw i32 %11925, %11926"
"  %11927 = add nuw nsw i32 %11925, %11926" -> "  %11959 = and i32 %11927, 65535""  %11927 = add nuw nsw i32 %11925, %11926" -> "  %11928 = lshr i32 %11927, 16"
"  %11928 = lshr i32 %11927, 16"
"  %11928 = lshr i32 %11927, 16" -> "  %11930 = add nuw nsw i32 %11928, %11929"
"  %11929 = and i32 %11887, 65535"
"  %11929 = and i32 %11887, 65535" -> "  %11930 = add nuw nsw i32 %11928, %11929"
"  %11930 = add nuw nsw i32 %11928, %11929"
"  %11930 = add nuw nsw i32 %11928, %11929" -> "  %11966 = and i32 %11930, 65535""  %11930 = add nuw nsw i32 %11928, %11929" -> "  %11931 = lshr i32 %11930, 16"
"  %11931 = lshr i32 %11930, 16"
"  %11931 = lshr i32 %11930, 16" -> "  %11932 = add nuw i32 %11894, %11931"
"  %11932 = add nuw i32 %11894, %11931"
"  %11932 = add nuw i32 %11894, %11931" -> "  %11970 = add nuw i32 %11932, %11969"
"  %11933 = and i32 %11897, 65535"
"  %11933 = and i32 %11897, 65535" -> "  %11935 = add nuw nsw i32 %11934, %11933"
"  %11934 = and i32 %11762, 65535"
"  %11934 = and i32 %11762, 65535" -> "  %11935 = add nuw nsw i32 %11934, %11933"
"  %11935 = add nuw nsw i32 %11934, %11933"
"  %11935 = add nuw nsw i32 %11934, %11933" -> "  %12043 = and i32 %11935, 65535""  %11935 = add nuw nsw i32 %11934, %11933" -> "  %11939 = lshr i32 %11935, 16"
"  %11936 = and i32 %11903, 65535"
"  %11936 = and i32 %11903, 65535" -> "  %11938 = add nuw nsw i32 %11937, %11936"
"  %11937 = and i32 %11765, 65535"
"  %11937 = and i32 %11765, 65535" -> "  %11938 = add nuw nsw i32 %11937, %11936"
"  %11938 = add nuw nsw i32 %11937, %11936"
"  %11938 = add nuw nsw i32 %11937, %11936" -> "  %11952 = lshr i32 %11938, 16""  %11938 = add nuw nsw i32 %11937, %11936" -> "  %11940 = and i32 %11938, 65535"
"  %11939 = lshr i32 %11935, 16"
"  %11939 = lshr i32 %11935, 16" -> "  %11941 = add nuw nsw i32 %11940, %11939"
"  %11940 = and i32 %11938, 65535"
"  %11940 = and i32 %11938, 65535" -> "  %11941 = add nuw nsw i32 %11940, %11939"
"  %11941 = add nuw nsw i32 %11940, %11939"
"  %11941 = add nuw nsw i32 %11940, %11939" -> "  %12048 = and i32 %11941, 65535""  %11941 = add nuw nsw i32 %11940, %11939" -> "  %11954 = lshr i32 %11941, 16"
"  %11942 = and i32 %11917, 65535"
"  %11942 = and i32 %11917, 65535" -> "  %11944 = add nuw nsw i32 %11943, %11942"
"  %11943 = and i32 %11767, 65535"
"  %11943 = and i32 %11767, 65535" -> "  %11944 = add nuw nsw i32 %11943, %11942"
"  %11944 = add nuw nsw i32 %11943, %11942"
"  %11944 = add nuw nsw i32 %11943, %11942" -> "  %11951 = and i32 %11944, 65535""  %11944 = add nuw nsw i32 %11943, %11942" -> "  %11948 = lshr i32 %11944, 16"
"  %11945 = and i32 %11920, 65535"
"  %11945 = and i32 %11920, 65535" -> "  %11947 = add nuw nsw i32 %11945, %11946"
"  %11946 = lshr i32 %11767, 16"
"  %11946 = lshr i32 %11767, 16" -> "  %11947 = add nuw nsw i32 %11945, %11946"
"  %11947 = add nuw nsw i32 %11945, %11946"
"  %11947 = add nuw nsw i32 %11945, %11946" -> "  %11960 = lshr i32 %11947, 16""  %11947 = add nuw nsw i32 %11945, %11946" -> "  %11949 = and i32 %11947, 65535"
"  %11948 = lshr i32 %11944, 16"
"  %11948 = lshr i32 %11944, 16" -> "  %11950 = add nuw nsw i32 %11949, %11948"
"  %11949 = and i32 %11947, 65535"
"  %11949 = and i32 %11947, 65535" -> "  %11950 = add nuw nsw i32 %11949, %11948"
"  %11950 = add nuw nsw i32 %11949, %11948"
"  %11950 = add nuw nsw i32 %11949, %11948" -> "  %11962 = lshr i32 %11950, 16""  %11950 = add nuw nsw i32 %11949, %11948" -> "  %11957 = and i32 %11950, 65535"
"  %11951 = and i32 %11944, 65535"
"  %11951 = and i32 %11944, 65535" -> "  %11953 = add nuw nsw i32 %11951, %11952"
"  %11952 = lshr i32 %11938, 16"
"  %11952 = lshr i32 %11938, 16" -> "  %11953 = add nuw nsw i32 %11951, %11952"
"  %11953 = add nuw nsw i32 %11951, %11952"
"  %11953 = add nuw nsw i32 %11951, %11952" -> "  %11955 = add nuw nsw i32 %11953, %11954"
"  %11954 = lshr i32 %11941, 16"
"  %11954 = lshr i32 %11941, 16" -> "  %11955 = add nuw nsw i32 %11953, %11954"
"  %11955 = add nuw nsw i32 %11953, %11954"
"  %11955 = add nuw nsw i32 %11953, %11954" -> "  %12049 = and i32 %11955, 65535""  %11955 = add nuw nsw i32 %11953, %11954" -> "  %11956 = lshr i32 %11955, 16"
"  %11956 = lshr i32 %11955, 16"
"  %11956 = lshr i32 %11955, 16" -> "  %11958 = add nuw nsw i32 %11957, %11956"
"  %11957 = and i32 %11950, 65535"
"  %11957 = and i32 %11950, 65535" -> "  %11958 = add nuw nsw i32 %11957, %11956"
"  %11958 = add nuw nsw i32 %11957, %11956"
"  %11958 = add nuw nsw i32 %11957, %11956" -> "  %12055 = and i32 %11958, 65535""  %11958 = add nuw nsw i32 %11957, %11956" -> "  %11964 = lshr i32 %11958, 16"
"  %11959 = and i32 %11927, 65535"
"  %11959 = and i32 %11927, 65535" -> "  %11961 = add nuw nsw i32 %11960, %11959"
"  %11960 = lshr i32 %11947, 16"
"  %11960 = lshr i32 %11947, 16" -> "  %11961 = add nuw nsw i32 %11960, %11959"
"  %11961 = add nuw nsw i32 %11960, %11959"
"  %11961 = add nuw nsw i32 %11960, %11959" -> "  %11963 = add nuw nsw i32 %11961, %11962"
"  %11962 = lshr i32 %11950, 16"
"  %11962 = lshr i32 %11950, 16" -> "  %11963 = add nuw nsw i32 %11961, %11962"
"  %11963 = add nuw nsw i32 %11961, %11962"
"  %11963 = add nuw nsw i32 %11961, %11962" -> "  %11965 = add nuw nsw i32 %11963, %11964"
"  %11964 = lshr i32 %11958, 16"
"  %11964 = lshr i32 %11958, 16" -> "  %11965 = add nuw nsw i32 %11963, %11964"
"  %11965 = add nuw nsw i32 %11963, %11964"
"  %11965 = add nuw nsw i32 %11963, %11964" -> "  %12058 = and i32 %11965, 65535""  %11965 = add nuw nsw i32 %11963, %11964" -> "  %11967 = lshr i32 %11965, 16"
"  %11966 = and i32 %11930, 65535"
"  %11966 = and i32 %11930, 65535" -> "  %11968 = add nuw nsw i32 %11967, %11966"
"  %11967 = lshr i32 %11965, 16"
"  %11967 = lshr i32 %11965, 16" -> "  %11968 = add nuw nsw i32 %11967, %11966"
"  %11968 = add nuw nsw i32 %11967, %11966"
"  %11968 = add nuw nsw i32 %11967, %11966" -> "  %12061 = and i32 %11968, 65535""  %11968 = add nuw nsw i32 %11967, %11966" -> "  %11969 = lshr i32 %11968, 16"
"  %11969 = lshr i32 %11968, 16"
"  %11969 = lshr i32 %11968, 16" -> "  %11970 = add nuw i32 %11932, %11969"
"  %11970 = add nuw i32 %11932, %11969"
"  %11970 = add nuw i32 %11932, %11969" -> "  %12064 = add nuw i32 %11970, %12063"
"  %11971 = and i32 %10542, 65535"
"  %11971 = and i32 %10542, 65535" -> "  %11973 = add nuw nsw i32 %11971, %11972"
"  %11972 = and i32 %11311, 65535"
"  %11972 = and i32 %11311, 65535" -> "  %11973 = add nuw nsw i32 %11971, %11972"
"  %11973 = add nuw nsw i32 %11971, %11972"
"  %11973 = add nuw nsw i32 %11971, %11972" -> "  %12066 = and i32 %11973, 65535""  %11973 = add nuw nsw i32 %11971, %11972" -> "  %11977 = lshr i32 %11973, 16"
"  %11974 = and i32 %10546, 65535"
"  %11974 = and i32 %10546, 65535" -> "  %11976 = add nuw nsw i32 %11974, %11975"
"  %11975 = and i32 %11320, 65535"
"  %11975 = and i32 %11320, 65535" -> "  %11976 = add nuw nsw i32 %11974, %11975"
"  %11976 = add nuw nsw i32 %11974, %11975"
"  %11976 = add nuw nsw i32 %11974, %11975" -> "  %11990 = lshr i32 %11976, 16""  %11976 = add nuw nsw i32 %11974, %11975" -> "  %11978 = and i32 %11976, 65535"
"  %11977 = lshr i32 %11973, 16"
"  %11977 = lshr i32 %11973, 16" -> "  %11979 = add nuw nsw i32 %11978, %11977"
"  %11978 = and i32 %11976, 65535"
"  %11978 = and i32 %11976, 65535" -> "  %11979 = add nuw nsw i32 %11978, %11977"
"  %11979 = add nuw nsw i32 %11978, %11977"
"  %11979 = add nuw nsw i32 %11978, %11977" -> "  %12069 = and i32 %11979, 65535""  %11979 = add nuw nsw i32 %11978, %11977" -> "  %11991 = lshr i32 %11979, 16"
"  %11980 = and i32 %10548, 65535"
"  %11980 = and i32 %10548, 65535" -> "  %11982 = add nuw nsw i32 %11980, %11981"
"  %11981 = and i32 %11380, 65535"
"  %11981 = and i32 %11380, 65535" -> "  %11982 = add nuw nsw i32 %11980, %11981"
"  %11982 = add nuw nsw i32 %11980, %11981"
"  %11982 = add nuw nsw i32 %11980, %11981" -> "  %11989 = and i32 %11982, 65535""  %11982 = add nuw nsw i32 %11980, %11981" -> "  %11986 = lshr i32 %11982, 16"
"  %11983 = and i32 %10551, 65535"
"  %11983 = and i32 %10551, 65535" -> "  %11985 = add nuw nsw i32 %11983, %11984"
"  %11984 = and i32 %11388, 65535"
"  %11984 = and i32 %11388, 65535" -> "  %11985 = add nuw nsw i32 %11983, %11984"
"  %11985 = add nuw nsw i32 %11983, %11984"
"  %11985 = add nuw nsw i32 %11983, %11984" -> "  %12027 = lshr i32 %11985, 16""  %11985 = add nuw nsw i32 %11983, %11984" -> "  %11987 = and i32 %11985, 65535"
"  %11986 = lshr i32 %11982, 16"
"  %11986 = lshr i32 %11982, 16" -> "  %11988 = add nuw nsw i32 %11987, %11986"
"  %11987 = and i32 %11985, 65535"
"  %11987 = and i32 %11985, 65535" -> "  %11988 = add nuw nsw i32 %11987, %11986"
"  %11988 = add nuw nsw i32 %11987, %11986"
"  %11988 = add nuw nsw i32 %11987, %11986" -> "  %12028 = lshr i32 %11988, 16""  %11988 = add nuw nsw i32 %11987, %11986" -> "  %11995 = and i32 %11988, 65535"
"  %11989 = and i32 %11982, 65535"
"  %11989 = and i32 %11982, 65535" -> "  %11993 = add nuw nsw i32 %11992, %11989"
"  %11990 = lshr i32 %11976, 16"
"  %11990 = lshr i32 %11976, 16" -> "  %11992 = add nuw nsw i32 %11991, %11990"
"  %11991 = lshr i32 %11979, 16"
"  %11991 = lshr i32 %11979, 16" -> "  %11992 = add nuw nsw i32 %11991, %11990"
"  %11992 = add nuw nsw i32 %11991, %11990"
"  %11992 = add nuw nsw i32 %11991, %11990" -> "  %11993 = add nuw nsw i32 %11992, %11989"
"  %11993 = add nuw nsw i32 %11992, %11989"
"  %11993 = add nuw nsw i32 %11992, %11989" -> "  %12075 = and i32 %11993, 65535""  %11993 = add nuw nsw i32 %11992, %11989" -> "  %11994 = lshr i32 %11993, 16"
"  %11994 = lshr i32 %11993, 16"
"  %11994 = lshr i32 %11993, 16" -> "  %11996 = add nuw nsw i32 %11995, %11994"
"  %11995 = and i32 %11988, 65535"
"  %11995 = and i32 %11988, 65535" -> "  %11996 = add nuw nsw i32 %11995, %11994"
"  %11996 = add nuw nsw i32 %11995, %11994"
"  %11996 = add nuw nsw i32 %11995, %11994" -> "  %12078 = and i32 %11996, 65535""  %11996 = add nuw nsw i32 %11995, %11994" -> "  %12029 = lshr i32 %11996, 16"
"  %11997 = and i32 %10554, 65535"
"  %11997 = and i32 %10554, 65535" -> "  %11999 = add nuw nsw i32 %11997, %11998"
"  %11998 = and i32 %11732, 65535"
"  %11998 = and i32 %11732, 65535" -> "  %11999 = add nuw nsw i32 %11997, %11998"
"  %11999 = add nuw nsw i32 %11997, %11998"
"  %11999 = add nuw nsw i32 %11997, %11998" -> "  %12026 = and i32 %11999, 65535""  %11999 = add nuw nsw i32 %11997, %11998" -> "  %12003 = lshr i32 %11999, 16"
"  %12000 = and i32 %10557, 65535"
"  %12000 = and i32 %10557, 65535" -> "  %12002 = add nuw nsw i32 %12000, %12001"
"  %12001 = and i32 %11738, 65535"
"  %12001 = and i32 %11738, 65535" -> "  %12002 = add nuw nsw i32 %12000, %12001"
"  %12002 = add nuw nsw i32 %12000, %12001"
"  %12002 = add nuw nsw i32 %12000, %12001" -> "  %12018 = lshr i32 %12002, 16""  %12002 = add nuw nsw i32 %12000, %12001" -> "  %12004 = and i32 %12002, 65535"
"  %12003 = lshr i32 %11999, 16"
"  %12003 = lshr i32 %11999, 16" -> "  %12005 = add nuw nsw i32 %12004, %12003"
"  %12004 = and i32 %12002, 65535"
"  %12004 = and i32 %12002, 65535" -> "  %12005 = add nuw nsw i32 %12004, %12003"
"  %12005 = add nuw nsw i32 %12004, %12003"
"  %12005 = add nuw nsw i32 %12004, %12003" -> "  %12033 = and i32 %12005, 65535""  %12005 = add nuw nsw i32 %12004, %12003" -> "  %12020 = lshr i32 %12005, 16"
"  %12006 = and i32 %10559, 65535"
"  %12006 = and i32 %10559, 65535" -> "  %12008 = add nuw nsw i32 %12006, %12007"
"  %12007 = and i32 %11752, 65535"
"  %12007 = and i32 %11752, 65535" -> "  %12008 = add nuw nsw i32 %12006, %12007"
"  %12008 = add nuw nsw i32 %12006, %12007"
"  %12008 = add nuw nsw i32 %12006, %12007" -> "  %12017 = and i32 %12008, 65535""  %12008 = add nuw nsw i32 %12006, %12007" -> "  %12012 = lshr i32 %12008, 16"
"  %12009 = lshr i32 %10559, 16"
"  %12009 = lshr i32 %10559, 16" -> "  %12011 = add nuw nsw i32 %12009, %12010"
"  %12010 = and i32 %11755, 65535"
"  %12010 = and i32 %11755, 65535" -> "  %12011 = add nuw nsw i32 %12009, %12010"
"  %12011 = add nuw nsw i32 %12009, %12010"
"  %12011 = add nuw nsw i32 %12009, %12010" -> "  %12015 = lshr i32 %12011, 16""  %12011 = add nuw nsw i32 %12009, %12010" -> "  %12013 = and i32 %12011, 65535"
"  %12012 = lshr i32 %12008, 16"
"  %12012 = lshr i32 %12008, 16" -> "  %12014 = add nuw nsw i32 %12013, %12012"
"  %12013 = and i32 %12011, 65535"
"  %12013 = and i32 %12011, 65535" -> "  %12014 = add nuw nsw i32 %12013, %12012"
"  %12014 = add nuw nsw i32 %12013, %12012"
"  %12014 = add nuw nsw i32 %12013, %12012" -> "  %12022 = and i32 %12014, 65535""  %12014 = add nuw nsw i32 %12013, %12012" -> "  %12016 = lshr i32 %12014, 16"
"  %12015 = lshr i32 %12011, 16"
"  %12015 = lshr i32 %12011, 16" -> "  %12044 = add nuw nsw i32 %12015, %12043"
"  %12016 = lshr i32 %12014, 16"
"  %12016 = lshr i32 %12014, 16" -> "  %12045 = add nuw nsw i32 %12044, %12016"
"  %12017 = and i32 %12008, 65535"
"  %12017 = and i32 %12008, 65535" -> "  %12019 = add nuw nsw i32 %12017, %12018"
"  %12018 = lshr i32 %12002, 16"
"  %12018 = lshr i32 %12002, 16" -> "  %12019 = add nuw nsw i32 %12017, %12018"
"  %12019 = add nuw nsw i32 %12017, %12018"
"  %12019 = add nuw nsw i32 %12017, %12018" -> "  %12021 = add nuw nsw i32 %12019, %12020"
"  %12020 = lshr i32 %12005, 16"
"  %12020 = lshr i32 %12005, 16" -> "  %12021 = add nuw nsw i32 %12019, %12020"
"  %12021 = add nuw nsw i32 %12019, %12020"
"  %12021 = add nuw nsw i32 %12019, %12020" -> "  %12036 = and i32 %12021, 65535""  %12021 = add nuw nsw i32 %12019, %12020" -> "  %12023 = lshr i32 %12021, 16"
"  %12022 = and i32 %12014, 65535"
"  %12022 = and i32 %12014, 65535" -> "  %12024 = add nuw nsw i32 %12023, %12022"
"  %12023 = lshr i32 %12021, 16"
"  %12023 = lshr i32 %12021, 16" -> "  %12024 = add nuw nsw i32 %12023, %12022"
"  %12024 = add nuw nsw i32 %12023, %12022"
"  %12024 = add nuw nsw i32 %12023, %12022" -> "  %12039 = and i32 %12024, 65535""  %12024 = add nuw nsw i32 %12023, %12022" -> "  %12025 = lshr i32 %12024, 16"
"  %12025 = lshr i32 %12024, 16"
"  %12025 = lshr i32 %12024, 16" -> "  %12046 = add nuw nsw i32 %12045, %12025"
"  %12026 = and i32 %11999, 65535"
"  %12026 = and i32 %11999, 65535" -> "  %12031 = add nuw nsw i32 %12030, %12026"
"  %12027 = lshr i32 %11985, 16"
"  %12027 = lshr i32 %11985, 16" -> "  %12030 = add nuw nsw i32 %12028, %12027"
"  %12028 = lshr i32 %11988, 16"
"  %12028 = lshr i32 %11988, 16" -> "  %12030 = add nuw nsw i32 %12028, %12027"
"  %12029 = lshr i32 %11996, 16"
"  %12029 = lshr i32 %11996, 16" -> "  %12032 = add nuw nsw i32 %12031, %12029"
"  %12030 = add nuw nsw i32 %12028, %12027"
"  %12030 = add nuw nsw i32 %12028, %12027" -> "  %12031 = add nuw nsw i32 %12030, %12026"
"  %12031 = add nuw nsw i32 %12030, %12026"
"  %12031 = add nuw nsw i32 %12030, %12026" -> "  %12032 = add nuw nsw i32 %12031, %12029"
"  %12032 = add nuw nsw i32 %12031, %12029"
"  %12032 = add nuw nsw i32 %12031, %12029" -> "  %12092 = and i32 %12032, 65535""  %12032 = add nuw nsw i32 %12031, %12029" -> "  %12034 = lshr i32 %12032, 16"
"  %12033 = and i32 %12005, 65535"
"  %12033 = and i32 %12005, 65535" -> "  %12035 = add nuw nsw i32 %12033, %12034"
"  %12034 = lshr i32 %12032, 16"
"  %12034 = lshr i32 %12032, 16" -> "  %12035 = add nuw nsw i32 %12033, %12034"
"  %12035 = add nuw nsw i32 %12033, %12034"
"  %12035 = add nuw nsw i32 %12033, %12034" -> "  %12095 = and i32 %12035, 65535""  %12035 = add nuw nsw i32 %12033, %12034" -> "  %12037 = lshr i32 %12035, 16"
"  %12036 = and i32 %12021, 65535"
"  %12036 = and i32 %12021, 65535" -> "  %12038 = add nuw nsw i32 %12036, %12037"
"  %12037 = lshr i32 %12035, 16"
"  %12037 = lshr i32 %12035, 16" -> "  %12038 = add nuw nsw i32 %12036, %12037"
"  %12038 = add nuw nsw i32 %12036, %12037"
"  %12038 = add nuw nsw i32 %12036, %12037" -> "  %12101 = and i32 %12038, 65535""  %12038 = add nuw nsw i32 %12036, %12037" -> "  %12040 = lshr i32 %12038, 16"
"  %12039 = and i32 %12024, 65535"
"  %12039 = and i32 %12024, 65535" -> "  %12041 = add nuw nsw i32 %12039, %12040"
"  %12040 = lshr i32 %12038, 16"
"  %12040 = lshr i32 %12038, 16" -> "  %12041 = add nuw nsw i32 %12039, %12040"
"  %12041 = add nuw nsw i32 %12039, %12040"
"  %12041 = add nuw nsw i32 %12039, %12040" -> "  %12104 = and i32 %12041, 65535""  %12041 = add nuw nsw i32 %12039, %12040" -> "  %12042 = lshr i32 %12041, 16"
"  %12042 = lshr i32 %12041, 16"
"  %12042 = lshr i32 %12041, 16" -> "  %12047 = add nuw nsw i32 %12046, %12042"
"  %12043 = and i32 %11935, 65535"
"  %12043 = and i32 %11935, 65535" -> "  %12044 = add nuw nsw i32 %12015, %12043"
"  %12044 = add nuw nsw i32 %12015, %12043"
"  %12044 = add nuw nsw i32 %12015, %12043" -> "  %12045 = add nuw nsw i32 %12044, %12016"
"  %12045 = add nuw nsw i32 %12044, %12016"
"  %12045 = add nuw nsw i32 %12044, %12016" -> "  %12046 = add nuw nsw i32 %12045, %12025"
"  %12046 = add nuw nsw i32 %12045, %12025"
"  %12046 = add nuw nsw i32 %12045, %12025" -> "  %12047 = add nuw nsw i32 %12046, %12042"
"  %12047 = add nuw nsw i32 %12046, %12042"
"  %12047 = add nuw nsw i32 %12046, %12042" -> "  %12139 = and i32 %12047, 65535""  %12047 = add nuw nsw i32 %12046, %12042" -> "  %12050 = lshr i32 %12047, 16"
"  %12048 = and i32 %11941, 65535"
"  %12048 = and i32 %11941, 65535" -> "  %12051 = add nuw nsw i32 %12050, %12048"
"  %12049 = and i32 %11955, 65535"
"  %12049 = and i32 %11955, 65535" -> "  %12053 = add nuw nsw i32 %12052, %12049"
"  %12050 = lshr i32 %12047, 16"
"  %12050 = lshr i32 %12047, 16" -> "  %12051 = add nuw nsw i32 %12050, %12048"
"  %12051 = add nuw nsw i32 %12050, %12048"
"  %12051 = add nuw nsw i32 %12050, %12048" -> "  %12138 = and i32 %12051, 65535""  %12051 = add nuw nsw i32 %12050, %12048" -> "  %12052 = lshr i32 %12051, 16"
"  %12052 = lshr i32 %12051, 16"
"  %12052 = lshr i32 %12051, 16" -> "  %12053 = add nuw nsw i32 %12052, %12049"
"  %12053 = add nuw nsw i32 %12052, %12049"
"  %12053 = add nuw nsw i32 %12052, %12049" -> "  %12144 = and i32 %12053, 65535""  %12053 = add nuw nsw i32 %12052, %12049" -> "  %12054 = lshr i32 %12053, 16"
"  %12054 = lshr i32 %12053, 16"
"  %12054 = lshr i32 %12053, 16" -> "  %12056 = add nuw nsw i32 %12054, %12055"
"  %12055 = and i32 %11958, 65535"
"  %12055 = and i32 %11958, 65535" -> "  %12056 = add nuw nsw i32 %12054, %12055"
"  %12056 = add nuw nsw i32 %12054, %12055"
"  %12056 = add nuw nsw i32 %12054, %12055" -> "  %12150 = and i32 %12056, 65535""  %12056 = add nuw nsw i32 %12054, %12055" -> "  %12057 = lshr i32 %12056, 16"
"  %12057 = lshr i32 %12056, 16"
"  %12057 = lshr i32 %12056, 16" -> "  %12059 = add nuw nsw i32 %12057, %12058"
"  %12058 = and i32 %11965, 65535"
"  %12058 = and i32 %11965, 65535" -> "  %12059 = add nuw nsw i32 %12057, %12058"
"  %12059 = add nuw nsw i32 %12057, %12058"
"  %12059 = add nuw nsw i32 %12057, %12058" -> "  %12154 = and i32 %12059, 65535""  %12059 = add nuw nsw i32 %12057, %12058" -> "  %12060 = lshr i32 %12059, 16"
"  %12060 = lshr i32 %12059, 16"
"  %12060 = lshr i32 %12059, 16" -> "  %12062 = add nuw nsw i32 %12060, %12061"
"  %12061 = and i32 %11968, 65535"
"  %12061 = and i32 %11968, 65535" -> "  %12062 = add nuw nsw i32 %12060, %12061"
"  %12062 = add nuw nsw i32 %12060, %12061"
"  %12062 = add nuw nsw i32 %12060, %12061" -> "  %12158 = and i32 %12062, 65535""  %12062 = add nuw nsw i32 %12060, %12061" -> "  %12063 = lshr i32 %12062, 16"
"  %12063 = lshr i32 %12062, 16"
"  %12063 = lshr i32 %12062, 16" -> "  %12064 = add nuw i32 %11970, %12063"
"  %12064 = add nuw i32 %11970, %12063"
"  %12064 = add nuw i32 %11970, %12063" -> "  %12163 = add nuw i32 %12064, %12162"
"  %12065 = and i32 %11293, 65535"
"  %12065 = and i32 %11293, 65535" -> "  %12067 = add nuw nsw i32 %12065, %12066"
"  %12066 = and i32 %11973, 65535"
"  %12066 = and i32 %11973, 65535" -> "  %12067 = add nuw nsw i32 %12065, %12066"
"  %12067 = add nuw nsw i32 %12065, %12066"
"  %12067 = add nuw nsw i32 %12065, %12066" -> "  %12071 = lshr i32 %12067, 16"
"  %12068 = and i32 %11296, 65535"
"  %12068 = and i32 %11296, 65535" -> "  %12070 = add nuw nsw i32 %12068, %12069"
"  %12069 = and i32 %11979, 65535"
"  %12069 = and i32 %11979, 65535" -> "  %12070 = add nuw nsw i32 %12068, %12069"
"  %12070 = add nuw nsw i32 %12068, %12069"
"  %12070 = add nuw nsw i32 %12068, %12069" -> "  %12084 = lshr i32 %12070, 16""  %12070 = add nuw nsw i32 %12068, %12069" -> "  %12072 = and i32 %12070, 65535"
"  %12071 = lshr i32 %12067, 16"
"  %12071 = lshr i32 %12067, 16" -> "  %12073 = add nuw nsw i32 %12072, %12071"
"  %12072 = and i32 %12070, 65535"
"  %12072 = and i32 %12070, 65535" -> "  %12073 = add nuw nsw i32 %12072, %12071"
"  %12073 = add nuw nsw i32 %12072, %12071"
"  %12073 = add nuw nsw i32 %12072, %12071" -> "  %12086 = lshr i32 %12073, 16"
"  %12074 = and i32 %11299, 65535"
"  %12074 = and i32 %11299, 65535" -> "  %12076 = add nuw nsw i32 %12074, %12075"
"  %12075 = and i32 %11993, 65535"
"  %12075 = and i32 %11993, 65535" -> "  %12076 = add nuw nsw i32 %12074, %12075"
"  %12076 = add nuw nsw i32 %12074, %12075"
"  %12076 = add nuw nsw i32 %12074, %12075" -> "  %12083 = and i32 %12076, 65535""  %12076 = add nuw nsw i32 %12074, %12075" -> "  %12080 = lshr i32 %12076, 16"
"  %12077 = and i32 %11302, 65535"
"  %12077 = and i32 %11302, 65535" -> "  %12079 = add nuw nsw i32 %12077, %12078"
"  %12078 = and i32 %11996, 65535"
"  %12078 = and i32 %11996, 65535" -> "  %12079 = add nuw nsw i32 %12077, %12078"
"  %12079 = add nuw nsw i32 %12077, %12078"
"  %12079 = add nuw nsw i32 %12077, %12078" -> "  %12121 = lshr i32 %12079, 16""  %12079 = add nuw nsw i32 %12077, %12078" -> "  %12081 = and i32 %12079, 65535"
"  %12080 = lshr i32 %12076, 16"
"  %12080 = lshr i32 %12076, 16" -> "  %12082 = add nuw nsw i32 %12081, %12080"
"  %12081 = and i32 %12079, 65535"
"  %12081 = and i32 %12079, 65535" -> "  %12082 = add nuw nsw i32 %12081, %12080"
"  %12082 = add nuw nsw i32 %12081, %12080"
"  %12082 = add nuw nsw i32 %12081, %12080" -> "  %12123 = lshr i32 %12082, 16""  %12082 = add nuw nsw i32 %12081, %12080" -> "  %12089 = and i32 %12082, 65535"
"  %12083 = and i32 %12076, 65535"
"  %12083 = and i32 %12076, 65535" -> "  %12085 = add nuw nsw i32 %12083, %12084"
"  %12084 = lshr i32 %12070, 16"
"  %12084 = lshr i32 %12070, 16" -> "  %12085 = add nuw nsw i32 %12083, %12084"
"  %12085 = add nuw nsw i32 %12083, %12084"
"  %12085 = add nuw nsw i32 %12083, %12084" -> "  %12087 = add nuw nsw i32 %12085, %12086"
"  %12086 = lshr i32 %12073, 16"
"  %12086 = lshr i32 %12073, 16" -> "  %12087 = add nuw nsw i32 %12085, %12086"
"  %12087 = add nuw nsw i32 %12085, %12086"
"  %12087 = add nuw nsw i32 %12085, %12086" -> "  %12088 = lshr i32 %12087, 16"
"  %12088 = lshr i32 %12087, 16"
"  %12088 = lshr i32 %12087, 16" -> "  %12090 = add nuw nsw i32 %12089, %12088"
"  %12089 = and i32 %12082, 65535"
"  %12089 = and i32 %12082, 65535" -> "  %12090 = add nuw nsw i32 %12089, %12088"
"  %12090 = add nuw nsw i32 %12089, %12088"
"  %12090 = add nuw nsw i32 %12089, %12088" -> "  %12125 = lshr i32 %12090, 16"
"  %12091 = and i32 %11305, 65535"
"  %12091 = and i32 %11305, 65535" -> "  %12093 = add nuw nsw i32 %12091, %12092"
"  %12092 = and i32 %12032, 65535"
"  %12092 = and i32 %12032, 65535" -> "  %12093 = add nuw nsw i32 %12091, %12092"
"  %12093 = add nuw nsw i32 %12091, %12092"
"  %12093 = add nuw nsw i32 %12091, %12092" -> "  %12120 = and i32 %12093, 65535""  %12093 = add nuw nsw i32 %12091, %12092" -> "  %12097 = lshr i32 %12093, 16"
"  %12094 = and i32 %11308, 65535"
"  %12094 = and i32 %11308, 65535" -> "  %12096 = add nuw nsw i32 %12094, %12095"
"  %12095 = and i32 %12035, 65535"
"  %12095 = and i32 %12035, 65535" -> "  %12096 = add nuw nsw i32 %12094, %12095"
"  %12096 = add nuw nsw i32 %12094, %12095"
"  %12096 = add nuw nsw i32 %12094, %12095" -> "  %12112 = lshr i32 %12096, 16""  %12096 = add nuw nsw i32 %12094, %12095" -> "  %12098 = and i32 %12096, 65535"
"  %12097 = lshr i32 %12093, 16"
"  %12097 = lshr i32 %12093, 16" -> "  %12099 = add nuw nsw i32 %12098, %12097"
"  %12098 = and i32 %12096, 65535"
"  %12098 = and i32 %12096, 65535" -> "  %12099 = add nuw nsw i32 %12098, %12097"
"  %12099 = add nuw nsw i32 %12098, %12097"
"  %12099 = add nuw nsw i32 %12098, %12097" -> "  %12127 = and i32 %12099, 65535""  %12099 = add nuw nsw i32 %12098, %12097" -> "  %12114 = lshr i32 %12099, 16"
"  %12100 = and i32 %11310, 65535"
"  %12100 = and i32 %11310, 65535" -> "  %12102 = add nuw nsw i32 %12100, %12101"
"  %12101 = and i32 %12038, 65535"
"  %12101 = and i32 %12038, 65535" -> "  %12102 = add nuw nsw i32 %12100, %12101"
"  %12102 = add nuw nsw i32 %12100, %12101"
"  %12102 = add nuw nsw i32 %12100, %12101" -> "  %12111 = and i32 %12102, 65535""  %12102 = add nuw nsw i32 %12100, %12101" -> "  %12106 = lshr i32 %12102, 16"
"  %12103 = lshr i32 %11310, 16"
"  %12103 = lshr i32 %11310, 16" -> "  %12105 = add nuw nsw i32 %12104, %12103"
"  %12104 = and i32 %12041, 65535"
"  %12104 = and i32 %12041, 65535" -> "  %12105 = add nuw nsw i32 %12104, %12103"
"  %12105 = add nuw nsw i32 %12104, %12103"
"  %12105 = add nuw nsw i32 %12104, %12103" -> "  %12109 = lshr i32 %12105, 16""  %12105 = add nuw nsw i32 %12104, %12103" -> "  %12107 = and i32 %12105, 65535"
"  %12106 = lshr i32 %12102, 16"
"  %12106 = lshr i32 %12102, 16" -> "  %12108 = add nuw nsw i32 %12107, %12106"
"  %12107 = and i32 %12105, 65535"
"  %12107 = and i32 %12105, 65535" -> "  %12108 = add nuw nsw i32 %12107, %12106"
"  %12108 = add nuw nsw i32 %12107, %12106"
"  %12108 = add nuw nsw i32 %12107, %12106" -> "  %12116 = and i32 %12108, 65535""  %12108 = add nuw nsw i32 %12107, %12106" -> "  %12110 = lshr i32 %12108, 16"
"  %12109 = lshr i32 %12105, 16"
"  %12109 = lshr i32 %12105, 16" -> "  %12140 = add nuw nsw i32 %12139, %12109"
"  %12110 = lshr i32 %12108, 16"
"  %12110 = lshr i32 %12108, 16" -> "  %12141 = add nuw nsw i32 %12140, %12110"
"  %12111 = and i32 %12102, 65535"
"  %12111 = and i32 %12102, 65535" -> "  %12113 = add nuw nsw i32 %12111, %12112"
"  %12112 = lshr i32 %12096, 16"
"  %12112 = lshr i32 %12096, 16" -> "  %12113 = add nuw nsw i32 %12111, %12112"
"  %12113 = add nuw nsw i32 %12111, %12112"
"  %12113 = add nuw nsw i32 %12111, %12112" -> "  %12115 = add nuw nsw i32 %12113, %12114"
"  %12114 = lshr i32 %12099, 16"
"  %12114 = lshr i32 %12099, 16" -> "  %12115 = add nuw nsw i32 %12113, %12114"
"  %12115 = add nuw nsw i32 %12113, %12114"
"  %12115 = add nuw nsw i32 %12113, %12114" -> "  %12130 = and i32 %12115, 65535""  %12115 = add nuw nsw i32 %12113, %12114" -> "  %12117 = lshr i32 %12115, 16"
"  %12116 = and i32 %12108, 65535"
"  %12116 = and i32 %12108, 65535" -> "  %12118 = add nuw nsw i32 %12117, %12116"
"  %12117 = lshr i32 %12115, 16"
"  %12117 = lshr i32 %12115, 16" -> "  %12118 = add nuw nsw i32 %12117, %12116"
"  %12118 = add nuw nsw i32 %12117, %12116"
"  %12118 = add nuw nsw i32 %12117, %12116" -> "  %12133 = and i32 %12118, 65535""  %12118 = add nuw nsw i32 %12117, %12116" -> "  %12119 = lshr i32 %12118, 16"
"  %12119 = lshr i32 %12118, 16"
"  %12119 = lshr i32 %12118, 16" -> "  %12142 = add nuw nsw i32 %12141, %12119"
"  %12120 = and i32 %12093, 65535"
"  %12120 = and i32 %12093, 65535" -> "  %12122 = add nuw nsw i32 %12120, %12121"
"  %12121 = lshr i32 %12079, 16"
"  %12121 = lshr i32 %12079, 16" -> "  %12122 = add nuw nsw i32 %12120, %12121"
"  %12122 = add nuw nsw i32 %12120, %12121"
"  %12122 = add nuw nsw i32 %12120, %12121" -> "  %12124 = add nuw nsw i32 %12122, %12123"
"  %12123 = lshr i32 %12082, 16"
"  %12123 = lshr i32 %12082, 16" -> "  %12124 = add nuw nsw i32 %12122, %12123"
"  %12124 = add nuw nsw i32 %12122, %12123"
"  %12124 = add nuw nsw i32 %12122, %12123" -> "  %12126 = add nuw nsw i32 %12124, %12125"
"  %12125 = lshr i32 %12090, 16"
"  %12125 = lshr i32 %12090, 16" -> "  %12126 = add nuw nsw i32 %12124, %12125"
"  %12126 = add nuw nsw i32 %12124, %12125"
"  %12126 = add nuw nsw i32 %12124, %12125" -> "  %12128 = lshr i32 %12126, 16"
"  %12127 = and i32 %12099, 65535"
"  %12127 = and i32 %12099, 65535" -> "  %12129 = add nuw nsw i32 %12128, %12127"
"  %12128 = lshr i32 %12126, 16"
"  %12128 = lshr i32 %12126, 16" -> "  %12129 = add nuw nsw i32 %12128, %12127"
"  %12129 = add nuw nsw i32 %12128, %12127"
"  %12129 = add nuw nsw i32 %12128, %12127" -> "  %12131 = lshr i32 %12129, 16"
"  %12130 = and i32 %12115, 65535"
"  %12130 = and i32 %12115, 65535" -> "  %12132 = add nuw nsw i32 %12130, %12131"
"  %12131 = lshr i32 %12129, 16"
"  %12131 = lshr i32 %12129, 16" -> "  %12132 = add nuw nsw i32 %12130, %12131"
"  %12132 = add nuw nsw i32 %12130, %12131"
"  %12132 = add nuw nsw i32 %12130, %12131" -> "  %12134 = lshr i32 %12132, 16"
"  %12133 = and i32 %12118, 65535"
"  %12133 = and i32 %12118, 65535" -> "  %12135 = add nuw nsw i32 %12134, %12133"
"  %12134 = lshr i32 %12132, 16"
"  %12134 = lshr i32 %12132, 16" -> "  %12135 = add nuw nsw i32 %12134, %12133"
"  %12135 = add nuw nsw i32 %12134, %12133"
"  %12135 = add nuw nsw i32 %12134, %12133" -> "  %12137 = lshr i32 %12135, 16""  %12135 = add nuw nsw i32 %12134, %12133" -> "  %12136 = lshr i32 %12135, 15"
"  %12136 = lshr i32 %12135, 15"
"  %12136 = lshr i32 %12135, 15" -> "  %12185 = and i32 %12136, 1"
"  %12137 = lshr i32 %12135, 16"
"  %12137 = lshr i32 %12135, 16" -> "  %12143 = add nuw nsw i32 %12142, %12137"
"  %12138 = and i32 %12051, 65535"
"  %12138 = and i32 %12051, 65535" -> "  %12146 = add nuw nsw i32 %12145, %12138"
"  %12139 = and i32 %12047, 65535"
"  %12139 = and i32 %12047, 65535" -> "  %12140 = add nuw nsw i32 %12139, %12109"
"  %12140 = add nuw nsw i32 %12139, %12109"
"  %12140 = add nuw nsw i32 %12139, %12109" -> "  %12141 = add nuw nsw i32 %12140, %12110"
"  %12141 = add nuw nsw i32 %12140, %12110"
"  %12141 = add nuw nsw i32 %12140, %12110" -> "  %12142 = add nuw nsw i32 %12141, %12119"
"  %12142 = add nuw nsw i32 %12141, %12119"
"  %12142 = add nuw nsw i32 %12141, %12119" -> "  %12143 = add nuw nsw i32 %12142, %12137"
"  %12143 = add nuw nsw i32 %12142, %12137"
"  %12143 = add nuw nsw i32 %12142, %12137" -> "  %12186 = shl nuw nsw i32 %12143, 1""  %12143 = add nuw nsw i32 %12142, %12137" -> "  %12172 = lshr i32 %12143, 15""  %12143 = add nuw nsw i32 %12142, %12137" -> "  %12145 = lshr i32 %12143, 16"
"  %12144 = and i32 %12053, 65535"
"  %12144 = and i32 %12053, 65535" -> "  %12149 = add nuw nsw i32 %12148, %12144"
"  %12145 = lshr i32 %12143, 16"
"  %12145 = lshr i32 %12143, 16" -> "  %12146 = add nuw nsw i32 %12145, %12138"
"  %12146 = add nuw nsw i32 %12145, %12138"
"  %12146 = add nuw nsw i32 %12145, %12138" -> "  %12174 = shl nuw nsw i32 %12146, 1""  %12146 = add nuw nsw i32 %12145, %12138" -> "  %12148 = lshr i32 %12146, 16""  %12146 = add nuw nsw i32 %12145, %12138" -> "  %12147 = lshr i32 %12146, 15"
"  %12147 = lshr i32 %12146, 15"
"  %12147 = lshr i32 %12146, 15" -> "  %12168 = and i32 %12147, 1"
"  %12148 = lshr i32 %12146, 16"
"  %12148 = lshr i32 %12146, 16" -> "  %12149 = add nuw nsw i32 %12148, %12144"
"  %12149 = add nuw nsw i32 %12148, %12144"
"  %12149 = add nuw nsw i32 %12148, %12144" -> "  %12169 = shl nuw nsw i32 %12149, 1""  %12149 = add nuw nsw i32 %12148, %12144" -> "  %12152 = lshr i32 %12149, 16""  %12149 = add nuw nsw i32 %12148, %12144" -> "  %12151 = lshr i32 %12149, 15"
"  %12150 = and i32 %12056, 65535"
"  %12150 = and i32 %12056, 65535" -> "  %12153 = add nuw nsw i32 %12152, %12150"
"  %12151 = lshr i32 %12149, 15"
"  %12151 = lshr i32 %12149, 15" -> "  %12164 = and i32 %12151, 1"
"  %12152 = lshr i32 %12149, 16"
"  %12152 = lshr i32 %12149, 16" -> "  %12153 = add nuw nsw i32 %12152, %12150"
"  %12153 = add nuw nsw i32 %12152, %12150"
"  %12153 = add nuw nsw i32 %12152, %12150" -> "  %12165 = shl nuw nsw i32 %12153, 1""  %12153 = add nuw nsw i32 %12152, %12150" -> "  %12156 = lshr i32 %12153, 16""  %12153 = add nuw nsw i32 %12152, %12150" -> "  %12155 = lshr i32 %12153, 15"
"  %12154 = and i32 %12059, 65535"
"  %12154 = and i32 %12059, 65535" -> "  %12157 = add nuw nsw i32 %12156, %12154"
"  %12155 = lshr i32 %12153, 15"
"  %12155 = lshr i32 %12153, 15" -> "  %12181 = and i32 %12155, 1"
"  %12156 = lshr i32 %12153, 16"
"  %12156 = lshr i32 %12153, 16" -> "  %12157 = add nuw nsw i32 %12156, %12154"
"  %12157 = add nuw nsw i32 %12156, %12154"
"  %12157 = add nuw nsw i32 %12156, %12154" -> "  %12383 = lshr i32 %12157, 15""  %12157 = add nuw nsw i32 %12156, %12154" -> "  %12182 = shl nuw nsw i32 %12157, 1""  %12157 = add nuw nsw i32 %12156, %12154" -> "  %12159 = lshr i32 %12157, 16"
"  %12158 = and i32 %12062, 65535"
"  %12158 = and i32 %12062, 65535" -> "  %12160 = add nuw nsw i32 %12159, %12158"
"  %12159 = lshr i32 %12157, 16"
"  %12159 = lshr i32 %12157, 16" -> "  %12160 = add nuw nsw i32 %12159, %12158"
"  %12160 = add nuw nsw i32 %12159, %12158"
"  %12160 = add nuw nsw i32 %12159, %12158" -> "  %12385 = shl nuw nsw i32 %12160, 1""  %12160 = add nuw nsw i32 %12159, %12158" -> "  %12162 = lshr i32 %12160, 16""  %12160 = add nuw nsw i32 %12159, %12158" -> "  %12161 = lshr i32 %12160, 15"
"  %12161 = lshr i32 %12160, 15"
"  %12161 = lshr i32 %12160, 15" -> "  %12177 = and i32 %12161, 1"
"  %12162 = lshr i32 %12160, 16"
"  %12162 = lshr i32 %12160, 16" -> "  %12163 = add nuw i32 %12064, %12162"
"  %12163 = add nuw i32 %12064, %12162"
"  %12163 = add nuw i32 %12064, %12162" -> "  %12406 = lshr i32 %12163, 15""  %12163 = add nuw i32 %12064, %12162" -> "  %12178 = shl i32 %12163, 1"
"  %12164 = and i32 %12151, 1"
"  %12164 = and i32 %12151, 1" -> "  %12167 = or i32 %12166, %12164"
"  %12165 = shl nuw nsw i32 %12153, 1"
"  %12165 = shl nuw nsw i32 %12153, 1" -> "  %12166 = and i32 %12165, 65534"
"  %12166 = and i32 %12165, 65534"
"  %12166 = and i32 %12165, 65534" -> "  %12167 = or i32 %12166, %12164"
"  %12167 = or i32 %12166, %12164"
"  %12167 = or i32 %12166, %12164" -> "  %12338 = mul nuw nsw i32 %12167, 1146""  %12167 = or i32 %12166, %12164" -> "  %12277 = mul nuw i32 %12167, 63663""  %12167 = or i32 %12166, %12164" -> "  %12273 = mul nuw nsw i32 %12167, 7935""  %12167 = or i32 %12166, %12164" -> "  %12246 = mul nuw i32 %12167, 34017""  %12167 = or i32 %12166, %12164" -> "  %12242 = mul nuw nsw i32 %12167, 17399"
"  %12168 = and i32 %12147, 1"
"  %12168 = and i32 %12147, 1" -> "  %12171 = or i32 %12170, %12168"
"  %12169 = shl nuw nsw i32 %12149, 1"
"  %12169 = shl nuw nsw i32 %12149, 1" -> "  %12170 = and i32 %12169, 65534"
"  %12170 = and i32 %12169, 65534"
"  %12170 = and i32 %12169, 65534" -> "  %12171 = or i32 %12170, %12168"
"  %12171 = or i32 %12170, %12168"
"  %12171 = or i32 %12170, %12168" -> "  %12336 = mul nuw nsw i32 %12171, 1146""  %12171 = or i32 %12170, %12168" -> "  %12335 = mul nuw i32 %12171, 43563""  %12171 = or i32 %12170, %12168" -> "  %12268 = mul nuw i32 %12171, 63663""  %12171 = or i32 %12170, %12168" -> "  %12266 = mul nuw nsw i32 %12171, 7935""  %12171 = or i32 %12170, %12168" -> "  %12237 = mul nuw i32 %12171, 34017""  %12171 = or i32 %12170, %12168" -> "  %12235 = mul nuw nsw i32 %12171, 17399"
"  %12172 = lshr i32 %12143, 15"
"  %12172 = lshr i32 %12143, 15" -> "  %12173 = and i32 %12172, 1"
"  %12173 = and i32 %12172, 1"
"  %12173 = and i32 %12172, 1" -> "  %12176 = or i32 %12175, %12173"
"  %12174 = shl nuw nsw i32 %12146, 1"
"  %12174 = shl nuw nsw i32 %12146, 1" -> "  %12175 = and i32 %12174, 65534"
"  %12175 = and i32 %12174, 65534"
"  %12175 = and i32 %12174, 65534" -> "  %12176 = or i32 %12175, %12173"
"  %12176 = or i32 %12175, %12173"
"  %12176 = or i32 %12175, %12173" -> "  %12211 = mul nuw nsw i32 %12176, 7935""  %12176 = or i32 %12175, %12173" -> "  %12331 = mul nuw nsw i32 %12176, 13953""  %12176 = or i32 %12175, %12173" -> "  %12321 = mul nuw i32 %12176, 43563""  %12176 = or i32 %12175, %12173" -> "  %12317 = mul nuw nsw i32 %12176, 1146""  %12176 = or i32 %12175, %12173" -> "  %12215 = mul nuw i32 %12176, 63663""  %12176 = or i32 %12175, %12173" -> "  %12200 = mul nuw i32 %12176, 34017""  %12176 = or i32 %12175, %12173" -> "  %12196 = mul nuw nsw i32 %12176, 17399"
"  %12177 = and i32 %12161, 1"
"  %12177 = and i32 %12161, 1" -> "  %12180 = or i32 %12179, %12177"
"  %12178 = shl i32 %12163, 1"
"  %12178 = shl i32 %12163, 1" -> "  %12179 = and i32 %12178, 65534"
"  %12179 = and i32 %12178, 65534"
"  %12179 = and i32 %12178, 65534" -> "  %12180 = or i32 %12179, %12177"
"  %12180 = or i32 %12179, %12177"
"  %12180 = or i32 %12179, %12177" -> "  %12409 = mul nuw i32 %12180, 34017""  %12180 = or i32 %12179, %12177" -> "  %12410 = mul nuw nsw i32 %12180, 17399"
"  %12181 = and i32 %12155, 1"
"  %12181 = and i32 %12155, 1" -> "  %12184 = or i32 %12183, %12181"
"  %12182 = shl nuw nsw i32 %12157, 1"
"  %12182 = shl nuw nsw i32 %12157, 1" -> "  %12183 = and i32 %12182, 65534"
"  %12183 = and i32 %12182, 65534"
"  %12183 = and i32 %12182, 65534" -> "  %12184 = or i32 %12183, %12181"
"  %12184 = or i32 %12183, %12181"
"  %12184 = or i32 %12183, %12181" -> "  %12376 = mul nuw nsw i32 %12184, 17399""  %12184 = or i32 %12183, %12181" -> "  %12378 = mul nuw i32 %12184, 34017""  %12184 = or i32 %12183, %12181" -> "  %12399 = mul nuw nsw i32 %12184, 7935""  %12184 = or i32 %12183, %12181" -> "  %12401 = mul nuw i32 %12184, 63663"
"  %12185 = and i32 %12136, 1"
"  %12185 = and i32 %12136, 1" -> "  %12188 = or i32 %12187, %12185"
"  %12186 = shl nuw nsw i32 %12143, 1"
"  %12186 = shl nuw nsw i32 %12143, 1" -> "  %12187 = and i32 %12186, 65534"
"  %12187 = and i32 %12186, 65534"
"  %12187 = and i32 %12186, 65534" -> "  %12188 = or i32 %12187, %12185"
"  %12188 = or i32 %12187, %12185"
"  %12188 = or i32 %12187, %12185" -> "  %12207 = mul nuw nsw i32 %12188, 7935""  %12188 = or i32 %12187, %12185" -> "  %12330 = mul nuw i32 %12188, 58377""  %12188 = or i32 %12187, %12185" -> "  %12328 = mul nuw nsw i32 %12188, 13953""  %12188 = or i32 %12187, %12185" -> "  %12312 = mul nuw i32 %12188, 43563""  %12188 = or i32 %12187, %12185" -> "  %12310 = mul nuw nsw i32 %12188, 1146""  %12188 = or i32 %12187, %12185" -> "  %12209 = mul nuw i32 %12188, 63663""  %12188 = or i32 %12187, %12185" -> "  %12191 = mul nuw i32 %12188, 34017""  %12188 = or i32 %12187, %12185" -> "  %12189 = mul nuw nsw i32 %12188, 17399"
"  %12189 = mul nuw nsw i32 %12188, 17399"
"  %12189 = mul nuw nsw i32 %12188, 17399" -> "  %12449 = and i32 %12189, 65535""  %12189 = mul nuw nsw i32 %12188, 17399" -> "  %12190 = lshr i32 %12189, 16"
"  %12190 = lshr i32 %12189, 16"
"  %12190 = lshr i32 %12189, 16" -> "  %12193 = add nuw nsw i32 %12190, %12192"
"  %12191 = mul nuw i32 %12188, 34017"
"  %12191 = mul nuw i32 %12188, 34017" -> "  %12194 = and i32 %12191, -65536""  %12191 = mul nuw i32 %12188, 34017" -> "  %12192 = and i32 %12191, 65535"
"  %12192 = and i32 %12191, 65535"
"  %12192 = and i32 %12191, 65535" -> "  %12193 = add nuw nsw i32 %12190, %12192"
"  %12193 = add nuw nsw i32 %12190, %12192"
"  %12193 = add nuw nsw i32 %12190, %12192" -> "  %12195 = add nuw i32 %12193, %12194"
"  %12194 = and i32 %12191, -65536"
"  %12194 = and i32 %12191, -65536" -> "  %12195 = add nuw i32 %12193, %12194"
"  %12195 = add nuw i32 %12193, %12194"
"  %12195 = add nuw i32 %12193, %12194" -> "  %12199 = lshr i32 %12195, 16""  %12195 = add nuw i32 %12193, %12194" -> "  %12197 = and i32 %12195, 65535"
"  %12196 = mul nuw nsw i32 %12176, 17399"
"  %12196 = mul nuw nsw i32 %12176, 17399" -> "  %12198 = add nuw nsw i32 %12197, %12196"
"  %12197 = and i32 %12195, 65535"
"  %12197 = and i32 %12195, 65535" -> "  %12198 = add nuw nsw i32 %12197, %12196"
"  %12198 = add nuw nsw i32 %12197, %12196"
"  %12198 = add nuw nsw i32 %12197, %12196" -> "  %12451 = and i32 %12198, 65535""  %12198 = add nuw nsw i32 %12197, %12196" -> "  %12202 = lshr i32 %12198, 16"
"  %12199 = lshr i32 %12195, 16"
"  %12199 = lshr i32 %12195, 16" -> "  %12201 = add nuw i32 %12199, %12200"
"  %12200 = mul nuw i32 %12176, 34017"
"  %12200 = mul nuw i32 %12176, 34017" -> "  %12201 = add nuw i32 %12199, %12200"
"  %12201 = add nuw i32 %12199, %12200"
"  %12201 = add nuw i32 %12199, %12200" -> "  %12205 = and i32 %12201, -65536""  %12201 = add nuw i32 %12199, %12200" -> "  %12203 = and i32 %12201, 65535"
"  %12202 = lshr i32 %12198, 16"
"  %12202 = lshr i32 %12198, 16" -> "  %12204 = add nuw nsw i32 %12202, %12203"
"  %12203 = and i32 %12201, 65535"
"  %12203 = and i32 %12201, 65535" -> "  %12204 = add nuw nsw i32 %12202, %12203"
"  %12204 = add nuw nsw i32 %12202, %12203"
"  %12204 = add nuw nsw i32 %12202, %12203" -> "  %12206 = add nuw i32 %12204, %12205"
"  %12205 = and i32 %12201, -65536"
"  %12205 = and i32 %12201, -65536" -> "  %12206 = add nuw i32 %12204, %12205"
"  %12206 = add nuw i32 %12204, %12205"
"  %12206 = add nuw i32 %12204, %12205" -> "  %12222 = and i32 %12206, 65535""  %12206 = add nuw i32 %12204, %12205" -> "  %12225 = lshr i32 %12206, 16"
"  %12207 = mul nuw nsw i32 %12188, 7935"
"  %12207 = mul nuw nsw i32 %12188, 7935" -> "  %12223 = and i32 %12207, 65535""  %12207 = mul nuw nsw i32 %12188, 7935" -> "  %12208 = lshr i32 %12207, 16"
"  %12208 = lshr i32 %12207, 16"
"  %12208 = lshr i32 %12207, 16" -> "  %12210 = add i32 %12208, %12209"
"  %12209 = mul nuw i32 %12188, 63663"
"  %12209 = mul nuw i32 %12188, 63663" -> "  %12210 = add i32 %12208, %12209"
"  %12210 = add i32 %12208, %12209"
"  %12210 = add i32 %12208, %12209" -> "  %12214 = lshr i32 %12210, 16""  %12210 = add i32 %12208, %12209" -> "  %12212 = and i32 %12210, 65535"
"  %12211 = mul nuw nsw i32 %12176, 7935"
"  %12211 = mul nuw nsw i32 %12176, 7935" -> "  %12213 = add nuw nsw i32 %12212, %12211"
"  %12212 = and i32 %12210, 65535"
"  %12212 = and i32 %12210, 65535" -> "  %12213 = add nuw nsw i32 %12212, %12211"
"  %12213 = add nuw nsw i32 %12212, %12211"
"  %12213 = add nuw nsw i32 %12212, %12211" -> "  %12226 = and i32 %12213, 65535""  %12213 = add nuw nsw i32 %12212, %12211" -> "  %12217 = lshr i32 %12213, 16"
"  %12214 = lshr i32 %12210, 16"
"  %12214 = lshr i32 %12210, 16" -> "  %12216 = add i32 %12214, %12215"
"  %12215 = mul nuw i32 %12176, 63663"
"  %12215 = mul nuw i32 %12176, 63663" -> "  %12216 = add i32 %12214, %12215"
"  %12216 = add i32 %12214, %12215"
"  %12216 = add i32 %12214, %12215" -> "  %12220 = and i32 %12216, -65536""  %12216 = add i32 %12214, %12215" -> "  %12218 = and i32 %12216, 65535"
"  %12217 = lshr i32 %12213, 16"
"  %12217 = lshr i32 %12213, 16" -> "  %12219 = add nuw nsw i32 %12218, %12217"
"  %12218 = and i32 %12216, 65535"
"  %12218 = and i32 %12216, 65535" -> "  %12219 = add nuw nsw i32 %12218, %12217"
"  %12219 = add nuw nsw i32 %12218, %12217"
"  %12219 = add nuw nsw i32 %12218, %12217" -> "  %12221 = add i32 %12219, %12220"
"  %12220 = and i32 %12216, -65536"
"  %12220 = and i32 %12216, -65536" -> "  %12221 = add i32 %12219, %12220"
"  %12221 = add i32 %12219, %12220"
"  %12221 = add i32 %12219, %12220" -> "  %12229 = add i32 %12221, %12228"
"  %12222 = and i32 %12206, 65535"
"  %12222 = and i32 %12206, 65535" -> "  %12224 = add nuw nsw i32 %12222, %12223"
"  %12223 = and i32 %12207, 65535"
"  %12223 = and i32 %12207, 65535" -> "  %12224 = add nuw nsw i32 %12222, %12223"
"  %12224 = add nuw nsw i32 %12222, %12223"
"  %12224 = add nuw nsw i32 %12222, %12223" -> "  %12253 = and i32 %12224, 65535""  %12224 = add nuw nsw i32 %12222, %12223" -> "  %12231 = lshr i32 %12224, 16"
"  %12225 = lshr i32 %12206, 16"
"  %12225 = lshr i32 %12206, 16" -> "  %12227 = add nuw nsw i32 %12225, %12226"
"  %12226 = and i32 %12213, 65535"
"  %12226 = and i32 %12213, 65535" -> "  %12227 = add nuw nsw i32 %12225, %12226"
"  %12227 = add nuw nsw i32 %12225, %12226"
"  %12227 = add nuw nsw i32 %12225, %12226" -> "  %12230 = and i32 %12227, 65535""  %12227 = add nuw nsw i32 %12225, %12226" -> "  %12228 = lshr i32 %12227, 16"
"  %12228 = lshr i32 %12227, 16"
"  %12228 = lshr i32 %12227, 16" -> "  %12229 = add i32 %12221, %12228"
"  %12229 = add i32 %12221, %12228"
"  %12229 = add i32 %12221, %12228" -> "  %12234 = add i32 %12229, %12233"
"  %12230 = and i32 %12227, 65535"
"  %12230 = and i32 %12227, 65535" -> "  %12232 = add nuw nsw i32 %12230, %12231"
"  %12231 = lshr i32 %12224, 16"
"  %12231 = lshr i32 %12224, 16" -> "  %12232 = add nuw nsw i32 %12230, %12231"
"  %12232 = add nuw nsw i32 %12230, %12231"
"  %12232 = add nuw nsw i32 %12230, %12231" -> "  %12256 = and i32 %12232, 65535""  %12232 = add nuw nsw i32 %12230, %12231" -> "  %12233 = lshr i32 %12232, 16"
"  %12233 = lshr i32 %12232, 16"
"  %12233 = lshr i32 %12232, 16" -> "  %12234 = add i32 %12229, %12233"
"  %12234 = add i32 %12229, %12233"
"  %12234 = add i32 %12229, %12233" -> "  %12288 = lshr i32 %12234, 16""  %12234 = add i32 %12229, %12233" -> "  %12284 = and i32 %12234, 65535"
"  %12235 = mul nuw nsw i32 %12171, 17399"
"  %12235 = mul nuw nsw i32 %12171, 17399" -> "  %12254 = and i32 %12235, 65535""  %12235 = mul nuw nsw i32 %12171, 17399" -> "  %12236 = lshr i32 %12235, 16"
"  %12236 = lshr i32 %12235, 16"
"  %12236 = lshr i32 %12235, 16" -> "  %12239 = add nuw nsw i32 %12236, %12238"
"  %12237 = mul nuw i32 %12171, 34017"
"  %12237 = mul nuw i32 %12171, 34017" -> "  %12240 = and i32 %12237, -65536""  %12237 = mul nuw i32 %12171, 34017" -> "  %12238 = and i32 %12237, 65535"
"  %12238 = and i32 %12237, 65535"
"  %12238 = and i32 %12237, 65535" -> "  %12239 = add nuw nsw i32 %12236, %12238"
"  %12239 = add nuw nsw i32 %12236, %12238"
"  %12239 = add nuw nsw i32 %12236, %12238" -> "  %12241 = add i32 %12239, %12240"
"  %12240 = and i32 %12237, -65536"
"  %12240 = and i32 %12237, -65536" -> "  %12241 = add i32 %12239, %12240"
"  %12241 = add i32 %12239, %12240"
"  %12241 = add i32 %12239, %12240" -> "  %12245 = lshr i32 %12241, 16""  %12241 = add i32 %12239, %12240" -> "  %12243 = and i32 %12241, 65535"
"  %12242 = mul nuw nsw i32 %12167, 17399"
"  %12242 = mul nuw nsw i32 %12167, 17399" -> "  %12244 = add nuw i32 %12243, %12242"
"  %12243 = and i32 %12241, 65535"
"  %12243 = and i32 %12241, 65535" -> "  %12244 = add nuw i32 %12243, %12242"
"  %12244 = add nuw i32 %12243, %12242"
"  %12244 = add nuw i32 %12243, %12242" -> "  %12257 = and i32 %12244, 65535""  %12244 = add nuw i32 %12243, %12242" -> "  %12248 = lshr i32 %12244, 16"
"  %12245 = lshr i32 %12241, 16"
"  %12245 = lshr i32 %12241, 16" -> "  %12247 = add i32 %12245, %12246"
"  %12246 = mul nuw i32 %12167, 34017"
"  %12246 = mul nuw i32 %12167, 34017" -> "  %12247 = add i32 %12245, %12246"
"  %12247 = add i32 %12245, %12246"
"  %12247 = add i32 %12245, %12246" -> "  %12251 = and i32 %12247, -65536""  %12247 = add i32 %12245, %12246" -> "  %12249 = and i32 %12247, 65535"
"  %12248 = lshr i32 %12244, 16"
"  %12248 = lshr i32 %12244, 16" -> "  %12250 = add nuw nsw i32 %12248, %12249"
"  %12249 = and i32 %12247, 65535"
"  %12249 = and i32 %12247, 65535" -> "  %12250 = add nuw nsw i32 %12248, %12249"
"  %12250 = add nuw nsw i32 %12248, %12249"
"  %12250 = add nuw nsw i32 %12248, %12249" -> "  %12252 = add i32 %12250, %12251"
"  %12251 = and i32 %12247, -65536"
"  %12251 = and i32 %12247, -65536" -> "  %12252 = add i32 %12250, %12251"
"  %12252 = add i32 %12250, %12251"
"  %12252 = add i32 %12250, %12251" -> "  %12260 = add i32 %12252, %12259"
"  %12253 = and i32 %12224, 65535"
"  %12253 = and i32 %12224, 65535" -> "  %12255 = add nuw nsw i32 %12253, %12254"
"  %12254 = and i32 %12235, 65535"
"  %12254 = and i32 %12235, 65535" -> "  %12255 = add nuw nsw i32 %12253, %12254"
"  %12255 = add nuw nsw i32 %12253, %12254"
"  %12255 = add nuw nsw i32 %12253, %12254" -> "  %12455 = and i32 %12255, 65535""  %12255 = add nuw nsw i32 %12253, %12254" -> "  %12262 = lshr i32 %12255, 16"
"  %12256 = and i32 %12232, 65535"
"  %12256 = and i32 %12232, 65535" -> "  %12258 = add nuw nsw i32 %12256, %12257"
"  %12257 = and i32 %12244, 65535"
"  %12257 = and i32 %12244, 65535" -> "  %12258 = add nuw nsw i32 %12256, %12257"
"  %12258 = add nuw nsw i32 %12256, %12257"
"  %12258 = add nuw nsw i32 %12256, %12257" -> "  %12261 = and i32 %12258, 65535""  %12258 = add nuw nsw i32 %12256, %12257" -> "  %12259 = lshr i32 %12258, 16"
"  %12259 = lshr i32 %12258, 16"
"  %12259 = lshr i32 %12258, 16" -> "  %12260 = add i32 %12252, %12259"
"  %12260 = add i32 %12252, %12259"
"  %12260 = add i32 %12252, %12259" -> "  %12265 = add i32 %12260, %12264"
"  %12261 = and i32 %12258, 65535"
"  %12261 = and i32 %12258, 65535" -> "  %12263 = add nuw nsw i32 %12261, %12262"
"  %12262 = lshr i32 %12255, 16"
"  %12262 = lshr i32 %12255, 16" -> "  %12263 = add nuw nsw i32 %12261, %12262"
"  %12263 = add nuw nsw i32 %12261, %12262"
"  %12263 = add nuw nsw i32 %12261, %12262" -> "  %12459 = and i32 %12263, 65535""  %12263 = add nuw nsw i32 %12261, %12262" -> "  %12264 = lshr i32 %12263, 16"
"  %12264 = lshr i32 %12263, 16"
"  %12264 = lshr i32 %12263, 16" -> "  %12265 = add i32 %12260, %12264"
"  %12265 = add i32 %12260, %12264"
"  %12265 = add i32 %12260, %12264" -> "  %12301 = lshr i32 %12265, 16""  %12265 = add i32 %12260, %12264" -> "  %12298 = and i32 %12265, 65535"
"  %12266 = mul nuw nsw i32 %12171, 7935"
"  %12266 = mul nuw nsw i32 %12171, 7935" -> "  %12285 = and i32 %12266, 65535""  %12266 = mul nuw nsw i32 %12171, 7935" -> "  %12267 = lshr i32 %12266, 16"
"  %12267 = lshr i32 %12266, 16"
"  %12267 = lshr i32 %12266, 16" -> "  %12270 = add nuw nsw i32 %12267, %12269"
"  %12268 = mul nuw i32 %12171, 63663"
"  %12268 = mul nuw i32 %12171, 63663" -> "  %12271 = and i32 %12268, -65536""  %12268 = mul nuw i32 %12171, 63663" -> "  %12269 = and i32 %12268, 65535"
"  %12269 = and i32 %12268, 65535"
"  %12269 = and i32 %12268, 65535" -> "  %12270 = add nuw nsw i32 %12267, %12269"
"  %12270 = add nuw nsw i32 %12267, %12269"
"  %12270 = add nuw nsw i32 %12267, %12269" -> "  %12272 = add i32 %12270, %12271"
"  %12271 = and i32 %12268, -65536"
"  %12271 = and i32 %12268, -65536" -> "  %12272 = add i32 %12270, %12271"
"  %12272 = add i32 %12270, %12271"
"  %12272 = add i32 %12270, %12271" -> "  %12276 = lshr i32 %12272, 16""  %12272 = add i32 %12270, %12271" -> "  %12274 = and i32 %12272, 65535"
"  %12273 = mul nuw nsw i32 %12167, 7935"
"  %12273 = mul nuw nsw i32 %12167, 7935" -> "  %12275 = add nuw nsw i32 %12274, %12273"
"  %12274 = and i32 %12272, 65535"
"  %12274 = and i32 %12272, 65535" -> "  %12275 = add nuw nsw i32 %12274, %12273"
"  %12275 = add nuw nsw i32 %12274, %12273"
"  %12275 = add nuw nsw i32 %12274, %12273" -> "  %12287 = and i32 %12275, 65535""  %12275 = add nuw nsw i32 %12274, %12273" -> "  %12279 = lshr i32 %12275, 16"
"  %12276 = lshr i32 %12272, 16"
"  %12276 = lshr i32 %12272, 16" -> "  %12278 = add i32 %12276, %12277"
"  %12277 = mul nuw i32 %12167, 63663"
"  %12277 = mul nuw i32 %12167, 63663" -> "  %12278 = add i32 %12276, %12277"
"  %12278 = add i32 %12276, %12277"
"  %12278 = add i32 %12276, %12277" -> "  %12282 = and i32 %12278, -65536""  %12278 = add i32 %12276, %12277" -> "  %12280 = and i32 %12278, 65535"
"  %12279 = lshr i32 %12275, 16"
"  %12279 = lshr i32 %12275, 16" -> "  %12281 = add nuw nsw i32 %12279, %12280"
"  %12280 = and i32 %12278, 65535"
"  %12280 = and i32 %12278, 65535" -> "  %12281 = add nuw nsw i32 %12279, %12280"
"  %12281 = add nuw nsw i32 %12279, %12280"
"  %12281 = add nuw nsw i32 %12279, %12280" -> "  %12283 = add i32 %12281, %12282"
"  %12282 = and i32 %12278, -65536"
"  %12282 = and i32 %12278, -65536" -> "  %12283 = add i32 %12281, %12282"
"  %12283 = add i32 %12281, %12282"
"  %12283 = add i32 %12281, %12282" -> "  %12291 = add i32 %12283, %12290"
"  %12284 = and i32 %12234, 65535"
"  %12284 = and i32 %12234, 65535" -> "  %12286 = add nuw nsw i32 %12284, %12285"
"  %12285 = and i32 %12266, 65535"
"  %12285 = and i32 %12266, 65535" -> "  %12286 = add nuw nsw i32 %12284, %12285"
"  %12286 = add nuw nsw i32 %12284, %12285"
"  %12286 = add nuw nsw i32 %12284, %12285" -> "  %12297 = and i32 %12286, 65535""  %12286 = add nuw nsw i32 %12284, %12285" -> "  %12293 = lshr i32 %12286, 16"
"  %12287 = and i32 %12275, 65535"
"  %12287 = and i32 %12275, 65535" -> "  %12289 = add nuw nsw i32 %12288, %12287"
"  %12288 = lshr i32 %12234, 16"
"  %12288 = lshr i32 %12234, 16" -> "  %12289 = add nuw nsw i32 %12288, %12287"
"  %12289 = add nuw nsw i32 %12288, %12287"
"  %12289 = add nuw nsw i32 %12288, %12287" -> "  %12292 = and i32 %12289, 65535""  %12289 = add nuw nsw i32 %12288, %12287" -> "  %12290 = lshr i32 %12289, 16"
"  %12290 = lshr i32 %12289, 16"
"  %12290 = lshr i32 %12289, 16" -> "  %12291 = add i32 %12283, %12290"
"  %12291 = add i32 %12283, %12290"
"  %12291 = add i32 %12283, %12290" -> "  %12296 = add i32 %12291, %12295"
"  %12292 = and i32 %12289, 65535"
"  %12292 = and i32 %12289, 65535" -> "  %12294 = add nuw nsw i32 %12292, %12293"
"  %12293 = lshr i32 %12286, 16"
"  %12293 = lshr i32 %12286, 16" -> "  %12294 = add nuw nsw i32 %12292, %12293"
"  %12294 = add nuw nsw i32 %12292, %12293"
"  %12294 = add nuw nsw i32 %12292, %12293" -> "  %12300 = and i32 %12294, 65535""  %12294 = add nuw nsw i32 %12292, %12293" -> "  %12295 = lshr i32 %12294, 16"
"  %12295 = lshr i32 %12294, 16"
"  %12295 = lshr i32 %12294, 16" -> "  %12296 = add i32 %12291, %12295"
"  %12296 = add i32 %12291, %12295"
"  %12296 = add i32 %12291, %12295" -> "  %12308 = add i32 %12296, %12306"
"  %12297 = and i32 %12286, 65535"
"  %12297 = and i32 %12286, 65535" -> "  %12299 = add nuw nsw i32 %12298, %12297"
"  %12298 = and i32 %12265, 65535"
"  %12298 = and i32 %12265, 65535" -> "  %12299 = add nuw nsw i32 %12298, %12297"
"  %12299 = add nuw nsw i32 %12298, %12297"
"  %12299 = add nuw nsw i32 %12298, %12297" -> "  %12355 = and i32 %12299, 65535""  %12299 = add nuw nsw i32 %12298, %12297" -> "  %12303 = lshr i32 %12299, 16"
"  %12300 = and i32 %12294, 65535"
"  %12300 = and i32 %12294, 65535" -> "  %12302 = add nuw nsw i32 %12301, %12300"
"  %12301 = lshr i32 %12265, 16"
"  %12301 = lshr i32 %12265, 16" -> "  %12302 = add nuw nsw i32 %12301, %12300"
"  %12302 = add nuw nsw i32 %12301, %12300"
"  %12302 = add nuw nsw i32 %12301, %12300" -> "  %12306 = lshr i32 %12302, 16""  %12302 = add nuw nsw i32 %12301, %12300" -> "  %12304 = and i32 %12302, 65535"
"  %12303 = lshr i32 %12299, 16"
"  %12303 = lshr i32 %12299, 16" -> "  %12305 = add nuw nsw i32 %12304, %12303"
"  %12304 = and i32 %12302, 65535"
"  %12304 = and i32 %12302, 65535" -> "  %12305 = add nuw nsw i32 %12304, %12303"
"  %12305 = add nuw nsw i32 %12304, %12303"
"  %12305 = add nuw nsw i32 %12304, %12303" -> "  %12358 = and i32 %12305, 65535""  %12305 = add nuw nsw i32 %12304, %12303" -> "  %12307 = lshr i32 %12305, 16"
"  %12306 = lshr i32 %12302, 16"
"  %12306 = lshr i32 %12302, 16" -> "  %12308 = add i32 %12296, %12306"
"  %12307 = lshr i32 %12305, 16"
"  %12307 = lshr i32 %12305, 16" -> "  %12309 = add i32 %12308, %12307"
"  %12308 = add i32 %12296, %12306"
"  %12308 = add i32 %12296, %12306" -> "  %12309 = add i32 %12308, %12307"
"  %12309 = add i32 %12308, %12307"
"  %12309 = add i32 %12308, %12307" -> "  %12365 = and i32 %12309, 65535""  %12309 = add i32 %12308, %12307" -> "  %12345 = lshr i32 %12309, 16"
"  %12310 = mul nuw nsw i32 %12188, 1146"
"  %12310 = mul nuw nsw i32 %12188, 1146" -> "  %12356 = and i32 %12310, 65534""  %12310 = mul nuw nsw i32 %12188, 1146" -> "  %12311 = lshr i32 %12310, 16"
"  %12311 = lshr i32 %12310, 16"
"  %12311 = lshr i32 %12310, 16" -> "  %12314 = add nuw nsw i32 %12311, %12313"
"  %12312 = mul nuw i32 %12188, 43563"
"  %12312 = mul nuw i32 %12188, 43563" -> "  %12315 = and i32 %12312, -65536""  %12312 = mul nuw i32 %12188, 43563" -> "  %12313 = and i32 %12312, 65535"
"  %12313 = and i32 %12312, 65535"
"  %12313 = and i32 %12312, 65535" -> "  %12314 = add nuw nsw i32 %12311, %12313"
"  %12314 = add nuw nsw i32 %12311, %12313"
"  %12314 = add nuw nsw i32 %12311, %12313" -> "  %12316 = add i32 %12314, %12315"
"  %12315 = and i32 %12312, -65536"
"  %12315 = and i32 %12312, -65536" -> "  %12316 = add i32 %12314, %12315"
"  %12316 = add i32 %12314, %12315"
"  %12316 = add i32 %12314, %12315" -> "  %12320 = lshr i32 %12316, 16""  %12316 = add i32 %12314, %12315" -> "  %12318 = and i32 %12316, 65535"
"  %12317 = mul nuw nsw i32 %12176, 1146"
"  %12317 = mul nuw nsw i32 %12176, 1146" -> "  %12319 = add nuw nsw i32 %12318, %12317"
"  %12318 = and i32 %12316, 65535"
"  %12318 = and i32 %12316, 65535" -> "  %12319 = add nuw nsw i32 %12318, %12317"
"  %12319 = add nuw nsw i32 %12318, %12317"
"  %12319 = add nuw nsw i32 %12318, %12317" -> "  %12359 = and i32 %12319, 65535""  %12319 = add nuw nsw i32 %12318, %12317" -> "  %12323 = lshr i32 %12319, 16"
"  %12320 = lshr i32 %12316, 16"
"  %12320 = lshr i32 %12316, 16" -> "  %12322 = add i32 %12320, %12321"
"  %12321 = mul nuw i32 %12176, 43563"
"  %12321 = mul nuw i32 %12176, 43563" -> "  %12322 = add i32 %12320, %12321"
"  %12322 = add i32 %12320, %12321"
"  %12322 = add i32 %12320, %12321" -> "  %12326 = and i32 %12322, -65536""  %12322 = add i32 %12320, %12321" -> "  %12324 = and i32 %12322, 65535"
"  %12323 = lshr i32 %12319, 16"
"  %12323 = lshr i32 %12319, 16" -> "  %12325 = add nuw nsw i32 %12323, %12324"
"  %12324 = and i32 %12322, 65535"
"  %12324 = and i32 %12322, 65535" -> "  %12325 = add nuw nsw i32 %12323, %12324"
"  %12325 = add nuw nsw i32 %12323, %12324"
"  %12325 = add nuw nsw i32 %12323, %12324" -> "  %12327 = add i32 %12325, %12326"
"  %12326 = and i32 %12322, -65536"
"  %12326 = and i32 %12322, -65536" -> "  %12327 = add i32 %12325, %12326"
"  %12327 = add i32 %12325, %12326"
"  %12327 = add i32 %12325, %12326" -> "  %12339 = lshr i32 %12327, 16""  %12327 = add i32 %12325, %12326" -> "  %12332 = and i32 %12327, 65535"
"  %12328 = mul nuw nsw i32 %12188, 13953"
"  %12328 = mul nuw nsw i32 %12188, 13953" -> "  %12333 = and i32 %12328, 65535""  %12328 = mul nuw nsw i32 %12188, 13953" -> "  %12329 = lshr i32 %12328, 16"
"  %12329 = lshr i32 %12328, 16"
"  %12329 = lshr i32 %12328, 16" -> "  %12346 = add i32 %12329, %12330"
"  %12330 = mul nuw i32 %12188, 58377"
"  %12330 = mul nuw i32 %12188, 58377" -> "  %12346 = add i32 %12329, %12330"
"  %12331 = mul nuw nsw i32 %12176, 13953"
"  %12331 = mul nuw nsw i32 %12176, 13953" -> "  %12347 = add i32 %12346, %12331"
"  %12332 = and i32 %12327, 65535"
"  %12332 = and i32 %12327, 65535" -> "  %12334 = add nuw nsw i32 %12332, %12333"
"  %12333 = and i32 %12328, 65535"
"  %12333 = and i32 %12328, 65535" -> "  %12334 = add nuw nsw i32 %12332, %12333"
"  %12334 = add nuw nsw i32 %12332, %12333"
"  %12334 = add nuw nsw i32 %12332, %12333" -> "  %12341 = and i32 %12334, 65535""  %12334 = add nuw nsw i32 %12332, %12333" -> "  %12340 = lshr i32 %12334, 16"
"  %12335 = mul nuw i32 %12171, 43563"
"  %12335 = mul nuw i32 %12171, 43563" -> "  %12348 = add i32 %12347, %12335"
"  %12336 = mul nuw nsw i32 %12171, 1146"
"  %12336 = mul nuw nsw i32 %12171, 1146" -> "  %12342 = and i32 %12336, 65534""  %12336 = mul nuw nsw i32 %12171, 1146" -> "  %12337 = lshr i32 %12336, 16"
"  %12337 = lshr i32 %12336, 16"
"  %12337 = lshr i32 %12336, 16" -> "  %12349 = add i32 %12348, %12337"
"  %12338 = mul nuw nsw i32 %12167, 1146"
"  %12338 = mul nuw nsw i32 %12167, 1146" -> "  %12350 = add i32 %12349, %12338"
"  %12339 = lshr i32 %12327, 16"
"  %12339 = lshr i32 %12327, 16" -> "  %12351 = add i32 %12350, %12339"
"  %12340 = lshr i32 %12334, 16"
"  %12340 = lshr i32 %12334, 16" -> "  %12352 = add i32 %12351, %12340"
"  %12341 = and i32 %12334, 65535"
"  %12341 = and i32 %12334, 65535" -> "  %12343 = add nuw nsw i32 %12341, %12342"
"  %12342 = and i32 %12336, 65534"
"  %12342 = and i32 %12336, 65534" -> "  %12343 = add nuw nsw i32 %12341, %12342"
"  %12343 = add nuw nsw i32 %12341, %12342"
"  %12343 = add nuw nsw i32 %12341, %12342" -> "  %12364 = and i32 %12343, 65535""  %12343 = add nuw nsw i32 %12341, %12342" -> "  %12344 = lshr i32 %12343, 16"
"  %12344 = lshr i32 %12343, 16"
"  %12344 = lshr i32 %12343, 16" -> "  %12353 = add i32 %12352, %12344"
"  %12345 = lshr i32 %12309, 16"
"  %12345 = lshr i32 %12309, 16" -> "  %12354 = add i32 %12353, %12345"
"  %12346 = add i32 %12329, %12330"
"  %12346 = add i32 %12329, %12330" -> "  %12347 = add i32 %12346, %12331"
"  %12347 = add i32 %12346, %12331"
"  %12347 = add i32 %12346, %12331" -> "  %12348 = add i32 %12347, %12335"
"  %12348 = add i32 %12347, %12335"
"  %12348 = add i32 %12347, %12335" -> "  %12349 = add i32 %12348, %12337"
"  %12349 = add i32 %12348, %12337"
"  %12349 = add i32 %12348, %12337" -> "  %12350 = add i32 %12349, %12338"
"  %12350 = add i32 %12349, %12338"
"  %12350 = add i32 %12349, %12338" -> "  %12351 = add i32 %12350, %12339"
"  %12351 = add i32 %12350, %12339"
"  %12351 = add i32 %12350, %12339" -> "  %12352 = add i32 %12351, %12340"
"  %12352 = add i32 %12351, %12340"
"  %12352 = add i32 %12351, %12340" -> "  %12353 = add i32 %12352, %12344"
"  %12353 = add i32 %12352, %12344"
"  %12353 = add i32 %12352, %12344" -> "  %12354 = add i32 %12353, %12345"
"  %12354 = add i32 %12353, %12345"
"  %12354 = add i32 %12353, %12345" -> "  %12368 = add i32 %12354, %12367"
"  %12355 = and i32 %12299, 65535"
"  %12355 = and i32 %12299, 65535" -> "  %12357 = add nuw nsw i32 %12355, %12356"
"  %12356 = and i32 %12310, 65534"
"  %12356 = and i32 %12310, 65534" -> "  %12357 = add nuw nsw i32 %12355, %12356"
"  %12357 = add nuw nsw i32 %12355, %12356"
"  %12357 = add nuw nsw i32 %12355, %12356" -> "  %12419 = and i32 %12357, 65535""  %12357 = add nuw nsw i32 %12355, %12356" -> "  %12361 = lshr i32 %12357, 16"
"  %12358 = and i32 %12305, 65535"
"  %12358 = and i32 %12305, 65535" -> "  %12360 = add nuw nsw i32 %12358, %12359"
"  %12359 = and i32 %12319, 65535"
"  %12359 = and i32 %12319, 65535" -> "  %12360 = add nuw nsw i32 %12358, %12359"
"  %12360 = add nuw nsw i32 %12358, %12359"
"  %12360 = add nuw nsw i32 %12358, %12359" -> "  %12370 = lshr i32 %12360, 16""  %12360 = add nuw nsw i32 %12358, %12359" -> "  %12362 = and i32 %12360, 65535"
"  %12361 = lshr i32 %12357, 16"
"  %12361 = lshr i32 %12357, 16" -> "  %12363 = add nuw nsw i32 %12362, %12361"
"  %12362 = and i32 %12360, 65535"
"  %12362 = and i32 %12360, 65535" -> "  %12363 = add nuw nsw i32 %12362, %12361"
"  %12363 = add nuw nsw i32 %12362, %12361"
"  %12363 = add nuw nsw i32 %12362, %12361" -> "  %12422 = and i32 %12363, 65535""  %12363 = add nuw nsw i32 %12362, %12361" -> "  %12372 = lshr i32 %12363, 16"
"  %12364 = and i32 %12343, 65535"
"  %12364 = and i32 %12343, 65535" -> "  %12366 = add nuw nsw i32 %12365, %12364"
"  %12365 = and i32 %12309, 65535"
"  %12365 = and i32 %12309, 65535" -> "  %12366 = add nuw nsw i32 %12365, %12364"
"  %12366 = add nuw nsw i32 %12365, %12364"
"  %12366 = add nuw nsw i32 %12365, %12364" -> "  %12369 = and i32 %12366, 65535""  %12366 = add nuw nsw i32 %12365, %12364" -> "  %12367 = lshr i32 %12366, 16"
"  %12367 = lshr i32 %12366, 16"
"  %12367 = lshr i32 %12366, 16" -> "  %12368 = add i32 %12354, %12367"
"  %12368 = add i32 %12354, %12367"
"  %12368 = add i32 %12354, %12367" -> "  %12375 = add i32 %12368, %12374"
"  %12369 = and i32 %12366, 65535"
"  %12369 = and i32 %12366, 65535" -> "  %12371 = add nuw nsw i32 %12369, %12370"
"  %12370 = lshr i32 %12360, 16"
"  %12370 = lshr i32 %12360, 16" -> "  %12371 = add nuw nsw i32 %12369, %12370"
"  %12371 = add nuw nsw i32 %12369, %12370"
"  %12371 = add nuw nsw i32 %12369, %12370" -> "  %12373 = add nuw nsw i32 %12371, %12372"
"  %12372 = lshr i32 %12363, 16"
"  %12372 = lshr i32 %12363, 16" -> "  %12373 = add nuw nsw i32 %12371, %12372"
"  %12373 = add nuw nsw i32 %12371, %12372"
"  %12373 = add nuw nsw i32 %12371, %12372" -> "  %12431 = and i32 %12373, 65535""  %12373 = add nuw nsw i32 %12371, %12372" -> "  %12374 = lshr i32 %12373, 16"
"  %12374 = lshr i32 %12373, 16"
"  %12374 = lshr i32 %12373, 16" -> "  %12375 = add i32 %12368, %12374"
"  %12375 = add i32 %12368, %12374"
"  %12375 = add i32 %12368, %12374" -> "  %12433 = and i32 %12375, 65535"
"  %12376 = mul nuw nsw i32 %12184, 17399"
"  %12376 = mul nuw nsw i32 %12184, 17399" -> "  %12418 = and i32 %12376, 65535""  %12376 = mul nuw nsw i32 %12184, 17399" -> "  %12377 = lshr i32 %12376, 16"
"  %12377 = lshr i32 %12376, 16"
"  %12377 = lshr i32 %12376, 16" -> "  %12380 = add nuw nsw i32 %12377, %12379"
"  %12378 = mul nuw i32 %12184, 34017"
"  %12378 = mul nuw i32 %12184, 34017" -> "  %12381 = and i32 %12378, -65536""  %12378 = mul nuw i32 %12184, 34017" -> "  %12379 = and i32 %12378, 65535"
"  %12379 = and i32 %12378, 65535"
"  %12379 = and i32 %12378, 65535" -> "  %12380 = add nuw nsw i32 %12377, %12379"
"  %12380 = add nuw nsw i32 %12377, %12379"
"  %12380 = add nuw nsw i32 %12377, %12379" -> "  %12382 = add i32 %12380, %12381"
"  %12381 = and i32 %12378, -65536"
"  %12381 = and i32 %12378, -65536" -> "  %12382 = add i32 %12380, %12381"
"  %12382 = add i32 %12380, %12381"
"  %12382 = add i32 %12380, %12381" -> "  %12391 = lshr i32 %12382, 16""  %12382 = add i32 %12380, %12381" -> "  %12389 = and i32 %12382, 65535"
"  %12383 = lshr i32 %12157, 15"
"  %12383 = lshr i32 %12157, 15" -> "  %12384 = and i32 %12383, 1"
"  %12384 = and i32 %12383, 1"
"  %12384 = and i32 %12383, 1" -> "  %12387 = or i32 %12386, %12384"
"  %12385 = shl nuw nsw i32 %12160, 1"
"  %12385 = shl nuw nsw i32 %12160, 1" -> "  %12386 = and i32 %12385, 65534"
"  %12386 = and i32 %12385, 65534"
"  %12386 = and i32 %12385, 65534" -> "  %12387 = or i32 %12386, %12384"
"  %12387 = or i32 %12386, %12384"
"  %12387 = or i32 %12386, %12384" -> "  %12402 = mul nuw nsw i32 %12387, 7935""  %12387 = or i32 %12386, %12384" -> "  %12392 = mul nuw i32 %12387, 34017""  %12387 = or i32 %12386, %12384" -> "  %12388 = mul nuw nsw i32 %12387, 17399"
"  %12388 = mul nuw nsw i32 %12387, 17399"
"  %12388 = mul nuw nsw i32 %12387, 17399" -> "  %12390 = add nuw nsw i32 %12389, %12388"
"  %12389 = and i32 %12382, 65535"
"  %12389 = and i32 %12382, 65535" -> "  %12390 = add nuw nsw i32 %12389, %12388"
"  %12390 = add nuw nsw i32 %12389, %12388"
"  %12390 = add nuw nsw i32 %12389, %12388" -> "  %12421 = and i32 %12390, 65535""  %12390 = add nuw nsw i32 %12389, %12388" -> "  %12394 = lshr i32 %12390, 16"
"  %12391 = lshr i32 %12382, 16"
"  %12391 = lshr i32 %12382, 16" -> "  %12393 = add nuw i32 %12391, %12392"
"  %12392 = mul nuw i32 %12387, 34017"
"  %12392 = mul nuw i32 %12387, 34017" -> "  %12393 = add nuw i32 %12391, %12392"
"  %12393 = add nuw i32 %12391, %12392"
"  %12393 = add nuw i32 %12391, %12392" -> "  %12397 = and i32 %12393, -65536""  %12393 = add nuw i32 %12391, %12392" -> "  %12395 = and i32 %12393, 65535"
"  %12394 = lshr i32 %12390, 16"
"  %12394 = lshr i32 %12390, 16" -> "  %12396 = add nuw nsw i32 %12394, %12395"
"  %12395 = and i32 %12393, 65535"
"  %12395 = and i32 %12393, 65535" -> "  %12396 = add nuw nsw i32 %12394, %12395"
"  %12396 = add nuw nsw i32 %12394, %12395"
"  %12396 = add nuw nsw i32 %12394, %12395" -> "  %12398 = add nuw i32 %12396, %12397"
"  %12397 = and i32 %12393, -65536"
"  %12397 = and i32 %12393, -65536" -> "  %12398 = add nuw i32 %12396, %12397"
"  %12398 = add nuw i32 %12396, %12397"
"  %12398 = add nuw i32 %12396, %12397" -> "  %12412 = lshr i32 %12398, 16""  %12398 = add nuw i32 %12396, %12397" -> "  %12403 = and i32 %12398, 65535"
"  %12399 = mul nuw nsw i32 %12184, 7935"
"  %12399 = mul nuw nsw i32 %12184, 7935" -> "  %12404 = and i32 %12399, 65535""  %12399 = mul nuw nsw i32 %12184, 7935" -> "  %12400 = lshr i32 %12399, 16"
"  %12400 = lshr i32 %12399, 16"
"  %12400 = lshr i32 %12399, 16" -> "  %12438 = add i32 %12400, %12401"
"  %12401 = mul nuw i32 %12184, 63663"
"  %12401 = mul nuw i32 %12184, 63663" -> "  %12438 = add i32 %12400, %12401"
"  %12402 = mul nuw nsw i32 %12387, 7935"
"  %12402 = mul nuw nsw i32 %12387, 7935" -> "  %12439 = add i32 %12438, %12402"
"  %12403 = and i32 %12398, 65535"
"  %12403 = and i32 %12398, 65535" -> "  %12405 = add nuw nsw i32 %12403, %12404"
"  %12404 = and i32 %12399, 65535"
"  %12404 = and i32 %12399, 65535" -> "  %12405 = add nuw nsw i32 %12403, %12404"
"  %12405 = add nuw nsw i32 %12403, %12404"
"  %12405 = add nuw nsw i32 %12403, %12404" -> "  %12414 = and i32 %12405, 65535""  %12405 = add nuw nsw i32 %12403, %12404" -> "  %12413 = lshr i32 %12405, 16"
"  %12406 = lshr i32 %12163, 15"
"  %12406 = lshr i32 %12163, 15" -> "  %12407 = and i32 %12406, 65535"
"  %12407 = and i32 %12406, 65535"
"  %12407 = and i32 %12406, 65535" -> "  %12408 = mul nuw nsw i32 %12407, 17399"
"  %12408 = mul nuw nsw i32 %12407, 17399"
"  %12408 = mul nuw nsw i32 %12407, 17399" -> "  %12440 = add i32 %12439, %12408"
"  %12409 = mul nuw i32 %12180, 34017"
"  %12409 = mul nuw i32 %12180, 34017" -> "  %12441 = add i32 %12440, %12409"
"  %12410 = mul nuw nsw i32 %12180, 17399"
"  %12410 = mul nuw nsw i32 %12180, 17399" -> "  %12415 = and i32 %12410, 65535""  %12410 = mul nuw nsw i32 %12180, 17399" -> "  %12411 = lshr i32 %12410, 16"
"  %12411 = lshr i32 %12410, 16"
"  %12411 = lshr i32 %12410, 16" -> "  %12442 = add i32 %12441, %12411"
"  %12412 = lshr i32 %12398, 16"
"  %12412 = lshr i32 %12398, 16" -> "  %12443 = add i32 %12442, %12412"
"  %12413 = lshr i32 %12405, 16"
"  %12413 = lshr i32 %12405, 16" -> "  %12444 = add i32 %12443, %12413"
"  %12414 = and i32 %12405, 65535"
"  %12414 = and i32 %12405, 65535" -> "  %12416 = add nuw nsw i32 %12414, %12415"
"  %12415 = and i32 %12410, 65535"
"  %12415 = and i32 %12410, 65535" -> "  %12416 = add nuw nsw i32 %12414, %12415"
"  %12416 = add nuw nsw i32 %12414, %12415"
"  %12416 = add nuw nsw i32 %12414, %12415" -> "  %12430 = and i32 %12416, 65535""  %12416 = add nuw nsw i32 %12414, %12415" -> "  %12417 = lshr i32 %12416, 16"
"  %12417 = lshr i32 %12416, 16"
"  %12417 = lshr i32 %12416, 16" -> "  %12445 = add i32 %12444, %12417"
"  %12418 = and i32 %12376, 65535"
"  %12418 = and i32 %12376, 65535" -> "  %12420 = add nuw nsw i32 %12419, %12418"
"  %12419 = and i32 %12357, 65535"
"  %12419 = and i32 %12357, 65535" -> "  %12420 = add nuw nsw i32 %12419, %12418"
"  %12420 = add nuw nsw i32 %12419, %12418"
"  %12420 = add nuw nsw i32 %12419, %12418" -> "  %12464 = and i32 %12420, 65535""  %12420 = add nuw nsw i32 %12419, %12418" -> "  %12424 = lshr i32 %12420, 16"
"  %12421 = and i32 %12390, 65535"
"  %12421 = and i32 %12390, 65535" -> "  %12423 = add nuw nsw i32 %12422, %12421"
"  %12422 = and i32 %12363, 65535"
"  %12422 = and i32 %12363, 65535" -> "  %12423 = add nuw nsw i32 %12422, %12421"
"  %12423 = add nuw nsw i32 %12422, %12421"
"  %12423 = add nuw nsw i32 %12422, %12421" -> "  %12427 = lshr i32 %12423, 16""  %12423 = add nuw nsw i32 %12422, %12421" -> "  %12425 = and i32 %12423, 65535"
"  %12424 = lshr i32 %12420, 16"
"  %12424 = lshr i32 %12420, 16" -> "  %12426 = add nuw nsw i32 %12425, %12424"
"  %12425 = and i32 %12423, 65535"
"  %12425 = and i32 %12423, 65535" -> "  %12426 = add nuw nsw i32 %12425, %12424"
"  %12426 = add nuw nsw i32 %12425, %12424"
"  %12426 = add nuw nsw i32 %12425, %12424" -> "  %12467 = and i32 %12426, 65535""  %12426 = add nuw nsw i32 %12425, %12424" -> "  %12428 = lshr i32 %12426, 16"
"  %12427 = lshr i32 %12423, 16"
"  %12427 = lshr i32 %12423, 16" -> "  %12429 = add nuw nsw i32 %12428, %12427"
"  %12428 = lshr i32 %12426, 16"
"  %12428 = lshr i32 %12426, 16" -> "  %12429 = add nuw nsw i32 %12428, %12427"
"  %12429 = add nuw nsw i32 %12428, %12427"
"  %12429 = add nuw nsw i32 %12428, %12427" -> "  %12436 = add nuw nsw i32 %12429, %12435"
"  %12430 = and i32 %12416, 65535"
"  %12430 = and i32 %12416, 65535" -> "  %12432 = add nuw nsw i32 %12431, %12430"
"  %12431 = and i32 %12373, 65535"
"  %12431 = and i32 %12373, 65535" -> "  %12432 = add nuw nsw i32 %12431, %12430"
"  %12432 = add nuw nsw i32 %12431, %12430"
"  %12432 = add nuw nsw i32 %12431, %12430" -> "  %12435 = and i32 %12432, 65535""  %12432 = add nuw nsw i32 %12431, %12430" -> "  %12434 = lshr i32 %12432, 16"
"  %12433 = and i32 %12375, 65535"
"  %12433 = and i32 %12375, 65535" -> "  %12446 = add i32 %12445, %12433"
"  %12434 = lshr i32 %12432, 16"
"  %12434 = lshr i32 %12432, 16" -> "  %12447 = add i32 %12446, %12434"
"  %12435 = and i32 %12432, 65535"
"  %12435 = and i32 %12432, 65535" -> "  %12436 = add nuw nsw i32 %12429, %12435"
"  %12436 = add nuw nsw i32 %12429, %12435"
"  %12436 = add nuw nsw i32 %12429, %12435" -> "  %12471 = and i32 %12436, 65535""  %12436 = add nuw nsw i32 %12429, %12435" -> "  %12437 = lshr i32 %12436, 16"
"  %12437 = lshr i32 %12436, 16"
"  %12437 = lshr i32 %12436, 16" -> "  %12448 = add i32 %12447, %12437"
"  %12438 = add i32 %12400, %12401"
"  %12438 = add i32 %12400, %12401" -> "  %12439 = add i32 %12438, %12402"
"  %12439 = add i32 %12438, %12402"
"  %12439 = add i32 %12438, %12402" -> "  %12440 = add i32 %12439, %12408"
"  %12440 = add i32 %12439, %12408"
"  %12440 = add i32 %12439, %12408" -> "  %12441 = add i32 %12440, %12409"
"  %12441 = add i32 %12440, %12409"
"  %12441 = add i32 %12440, %12409" -> "  %12442 = add i32 %12441, %12411"
"  %12442 = add i32 %12441, %12411"
"  %12442 = add i32 %12441, %12411" -> "  %12443 = add i32 %12442, %12412"
"  %12443 = add i32 %12442, %12412"
"  %12443 = add i32 %12442, %12412" -> "  %12444 = add i32 %12443, %12413"
"  %12444 = add i32 %12443, %12413"
"  %12444 = add i32 %12443, %12413" -> "  %12445 = add i32 %12444, %12417"
"  %12445 = add i32 %12444, %12417"
"  %12445 = add i32 %12444, %12417" -> "  %12446 = add i32 %12445, %12433"
"  %12446 = add i32 %12445, %12433"
"  %12446 = add i32 %12445, %12433" -> "  %12447 = add i32 %12446, %12434"
"  %12447 = add i32 %12446, %12434"
"  %12447 = add i32 %12446, %12434" -> "  %12448 = add i32 %12447, %12437"
"  %12448 = add i32 %12447, %12437"
"  %12448 = add i32 %12447, %12437" -> "  %12513 = xor i32 %12448, 65535"
"  %12449 = and i32 %12189, 65535"
"  %12449 = and i32 %12189, 65535" -> "  %12450 = sub nuw nsw i32 65536, %12449"
"  %12450 = sub nuw nsw i32 65536, %12449"
"  %12450 = sub nuw nsw i32 65536, %12449" -> "  %12475 = and i32 %12450, 65535""  %12450 = sub nuw nsw i32 65536, %12449" -> "  %12453 = lshr i32 %12450, 16"
"  %12451 = and i32 %12198, 65535"
"  %12451 = and i32 %12198, 65535" -> "  %12452 = xor i32 %12451, 65535"
"  %12452 = xor i32 %12451, 65535"
"  %12452 = xor i32 %12451, 65535" -> "  %12454 = add nuw nsw i32 %12452, %12453"
"  %12453 = lshr i32 %12450, 16"
"  %12453 = lshr i32 %12450, 16" -> "  %12454 = add nuw nsw i32 %12452, %12453"
"  %12454 = add nuw nsw i32 %12452, %12453"
"  %12454 = add nuw nsw i32 %12452, %12453" -> "  %12477 = and i32 %12454, 65535""  %12454 = add nuw nsw i32 %12452, %12453" -> "  %12457 = lshr i32 %12454, 16"
"  %12455 = and i32 %12255, 65535"
"  %12455 = and i32 %12255, 65535" -> "  %12456 = xor i32 %12455, 65535"
"  %12456 = xor i32 %12455, 65535"
"  %12456 = xor i32 %12455, 65535" -> "  %12458 = add nuw nsw i32 %12456, %12457"
"  %12457 = lshr i32 %12454, 16"
"  %12457 = lshr i32 %12454, 16" -> "  %12458 = add nuw nsw i32 %12456, %12457"
"  %12458 = add nuw nsw i32 %12456, %12457"
"  %12458 = add nuw nsw i32 %12456, %12457" -> "  %12485 = and i32 %12458, 65535""  %12458 = add nuw nsw i32 %12456, %12457" -> "  %12461 = lshr i32 %12458, 16"
"  %12459 = and i32 %12263, 65535"
"  %12459 = and i32 %12263, 65535" -> "  %12460 = xor i32 %12459, 65535"
"  %12460 = xor i32 %12459, 65535"
"  %12460 = xor i32 %12459, 65535" -> "  %12462 = add nuw nsw i32 %12460, %12461"
"  %12461 = lshr i32 %12458, 16"
"  %12461 = lshr i32 %12458, 16" -> "  %12462 = add nuw nsw i32 %12460, %12461"
"  %12462 = add nuw nsw i32 %12460, %12461"
"  %12462 = add nuw nsw i32 %12460, %12461" -> "  %12487 = and i32 %12462, 65535""  %12462 = add nuw nsw i32 %12460, %12461" -> "  %12463 = lshr i32 %12462, 16"
"  %12463 = lshr i32 %12462, 16"
"  %12463 = lshr i32 %12462, 16" -> "  %12466 = add nuw nsw i32 %12465, %12463"
"  %12464 = and i32 %12420, 65535"
"  %12464 = and i32 %12420, 65535" -> "  %12465 = xor i32 %12464, 65535"
"  %12465 = xor i32 %12464, 65535"
"  %12465 = xor i32 %12464, 65535" -> "  %12466 = add nuw nsw i32 %12465, %12463"
"  %12466 = add nuw nsw i32 %12465, %12463"
"  %12466 = add nuw nsw i32 %12465, %12463" -> "  %12502 = and i32 %12466, 65535""  %12466 = add nuw nsw i32 %12465, %12463" -> "  %12469 = lshr i32 %12466, 16"
"  %12467 = and i32 %12426, 65535"
"  %12467 = and i32 %12426, 65535" -> "  %12468 = xor i32 %12467, 65535"
"  %12468 = xor i32 %12467, 65535"
"  %12468 = xor i32 %12467, 65535" -> "  %12470 = add nuw nsw i32 %12468, %12469"
"  %12469 = lshr i32 %12466, 16"
"  %12469 = lshr i32 %12466, 16" -> "  %12470 = add nuw nsw i32 %12468, %12469"
"  %12470 = add nuw nsw i32 %12468, %12469"
"  %12470 = add nuw nsw i32 %12468, %12469" -> "  %12504 = and i32 %12470, 65535""  %12470 = add nuw nsw i32 %12468, %12469" -> "  %12473 = lshr i32 %12470, 16"
"  %12471 = and i32 %12436, 65535"
"  %12471 = and i32 %12436, 65535" -> "  %12472 = xor i32 %12471, 65535"
"  %12472 = xor i32 %12471, 65535"
"  %12472 = xor i32 %12471, 65535" -> "  %12474 = add nuw nsw i32 %12472, %12473"
"  %12473 = lshr i32 %12470, 16"
"  %12473 = lshr i32 %12470, 16" -> "  %12474 = add nuw nsw i32 %12472, %12473"
"  %12474 = add nuw nsw i32 %12472, %12473"
"  %12474 = add nuw nsw i32 %12472, %12473" -> "  %12527 = add i32 %12526, %12474""  %12474 = add nuw nsw i32 %12472, %12473" -> "  %12511 = and i32 %12474, 65535"
"  %12475 = and i32 %12450, 65535"
"  %12475 = and i32 %12450, 65535" -> "  %12476 = add nuw nsw i32 %12475, %9136"
"  %12476 = add nuw nsw i32 %12475, %9136"
"  %12476 = add nuw nsw i32 %12475, %9136" -> "  %12534 = and i32 %12476, 65535""  %12476 = add nuw nsw i32 %12475, %9136" -> "  %12479 = lshr i32 %12476, 16"
"  %12477 = and i32 %12454, 65535"
"  %12477 = and i32 %12454, 65535" -> "  %12478 = add nuw nsw i32 %12477, %9137"
"  %12478 = add nuw nsw i32 %12477, %9137"
"  %12478 = add nuw nsw i32 %12477, %9137" -> "  %12482 = lshr i32 %12478, 16""  %12478 = add nuw nsw i32 %12477, %9137" -> "  %12480 = and i32 %12478, 65535"
"  %12479 = lshr i32 %12476, 16"
"  %12479 = lshr i32 %12476, 16" -> "  %12481 = add nuw nsw i32 %12480, %12479"
"  %12480 = and i32 %12478, 65535"
"  %12480 = and i32 %12478, 65535" -> "  %12481 = add nuw nsw i32 %12480, %12479"
"  %12481 = add nuw nsw i32 %12480, %12479"
"  %12481 = add nuw nsw i32 %12480, %12479" -> "  %12535 = and i32 %12481, 65535""  %12481 = add nuw nsw i32 %12480, %12479" -> "  %12483 = lshr i32 %12481, 16"
"  %12482 = lshr i32 %12478, 16"
"  %12482 = lshr i32 %12478, 16" -> "  %12484 = add nuw nsw i32 %12483, %12482"
"  %12483 = lshr i32 %12481, 16"
"  %12483 = lshr i32 %12481, 16" -> "  %12484 = add nuw nsw i32 %12483, %12482"
"  %12484 = add nuw nsw i32 %12483, %12482"
"  %12484 = add nuw nsw i32 %12483, %12482" -> "  %12496 = add nuw nsw i32 %12484, %12495"
"  %12485 = and i32 %12458, 65535"
"  %12485 = and i32 %12458, 65535" -> "  %12486 = add nuw nsw i32 %12485, %9156"
"  %12486 = add nuw nsw i32 %12485, %9156"
"  %12486 = add nuw nsw i32 %12485, %9156" -> "  %12495 = and i32 %12486, 65535""  %12486 = add nuw nsw i32 %12485, %9156" -> "  %12489 = lshr i32 %12486, 16"
"  %12487 = and i32 %12462, 65535"
"  %12487 = and i32 %12462, 65535" -> "  %12488 = add nuw nsw i32 %12487, %9159"
"  %12488 = add nuw nsw i32 %12487, %9159"
"  %12488 = add nuw nsw i32 %12487, %9159" -> "  %12492 = lshr i32 %12488, 16""  %12488 = add nuw nsw i32 %12487, %9159" -> "  %12490 = and i32 %12488, 65535"
"  %12489 = lshr i32 %12486, 16"
"  %12489 = lshr i32 %12486, 16" -> "  %12491 = add nuw nsw i32 %12490, %12489"
"  %12490 = and i32 %12488, 65535"
"  %12490 = and i32 %12488, 65535" -> "  %12491 = add nuw nsw i32 %12490, %12489"
"  %12491 = add nuw nsw i32 %12490, %12489"
"  %12491 = add nuw nsw i32 %12490, %12489" -> "  %12497 = and i32 %12491, 65535""  %12491 = add nuw nsw i32 %12490, %12489" -> "  %12493 = lshr i32 %12491, 16"
"  %12492 = lshr i32 %12488, 16"
"  %12492 = lshr i32 %12488, 16" -> "  %12494 = add nuw nsw i32 %12493, %12492"
"  %12493 = lshr i32 %12491, 16"
"  %12493 = lshr i32 %12491, 16" -> "  %12494 = add nuw nsw i32 %12493, %12492"
"  %12494 = add nuw nsw i32 %12493, %12492"
"  %12494 = add nuw nsw i32 %12493, %12492" -> "  %12501 = add nuw nsw i32 %12494, %12500"
"  %12495 = and i32 %12486, 65535"
"  %12495 = and i32 %12486, 65535" -> "  %12496 = add nuw nsw i32 %12484, %12495"
"  %12496 = add nuw nsw i32 %12484, %12495"
"  %12496 = add nuw nsw i32 %12484, %12495" -> "  %12553 = and i32 %12496, 65535""  %12496 = add nuw nsw i32 %12484, %12495" -> "  %12498 = lshr i32 %12496, 16"
"  %12497 = and i32 %12491, 65535"
"  %12497 = and i32 %12491, 65535" -> "  %12499 = add nuw nsw i32 %12497, %12498"
"  %12498 = lshr i32 %12496, 16"
"  %12498 = lshr i32 %12496, 16" -> "  %12499 = add nuw nsw i32 %12497, %12498"
"  %12499 = add nuw nsw i32 %12497, %12498"
"  %12499 = add nuw nsw i32 %12497, %12498" -> "  %12554 = and i32 %12499, 65535""  %12499 = add nuw nsw i32 %12497, %12498" -> "  %12500 = lshr i32 %12499, 16"
"  %12500 = lshr i32 %12499, 16"
"  %12500 = lshr i32 %12499, 16" -> "  %12501 = add nuw nsw i32 %12494, %12500"
"  %12501 = add nuw nsw i32 %12494, %12500"
"  %12501 = add nuw nsw i32 %12494, %12500" -> "  %12519 = add nuw nsw i32 %12501, %12518"
"  %12502 = and i32 %12466, 65535"
"  %12502 = and i32 %12466, 65535" -> "  %12503 = add nuw nsw i32 %12502, %9270"
"  %12503 = add nuw nsw i32 %12502, %9270"
"  %12503 = add nuw nsw i32 %12502, %9270" -> "  %12518 = and i32 %12503, 65535""  %12503 = add nuw nsw i32 %12502, %9270" -> "  %12506 = lshr i32 %12503, 16"
"  %12504 = and i32 %12470, 65535"
"  %12504 = and i32 %12470, 65535" -> "  %12505 = add nuw nsw i32 %12504, %9273"
"  %12505 = add nuw nsw i32 %12504, %9273"
"  %12505 = add nuw nsw i32 %12504, %9273" -> "  %12509 = lshr i32 %12505, 16""  %12505 = add nuw nsw i32 %12504, %9273" -> "  %12507 = and i32 %12505, 65535"
"  %12506 = lshr i32 %12503, 16"
"  %12506 = lshr i32 %12503, 16" -> "  %12508 = add nuw nsw i32 %12507, %12506"
"  %12507 = and i32 %12505, 65535"
"  %12507 = and i32 %12505, 65535" -> "  %12508 = add nuw nsw i32 %12507, %12506"
"  %12508 = add nuw nsw i32 %12507, %12506"
"  %12508 = add nuw nsw i32 %12507, %12506" -> "  %12520 = and i32 %12508, 65535""  %12508 = add nuw nsw i32 %12507, %12506" -> "  %12510 = lshr i32 %12508, 16"
"  %12509 = lshr i32 %12505, 16"
"  %12509 = lshr i32 %12505, 16" -> "  %12516 = add nuw nsw i32 %12510, %12509"
"  %12510 = lshr i32 %12508, 16"
"  %12510 = lshr i32 %12508, 16" -> "  %12516 = add nuw nsw i32 %12510, %12509"
"  %12511 = and i32 %12474, 65535"
"  %12511 = and i32 %12474, 65535" -> "  %12512 = add nuw nsw i32 %12511, %9290"
"  %12512 = add nuw nsw i32 %12511, %9290"
"  %12512 = add nuw nsw i32 %12511, %9290" -> "  %12529 = add i32 %12528, %12512""  %12512 = add nuw nsw i32 %12511, %9290" -> "  %12515 = and i32 %12512, 65535"
"  %12513 = xor i32 %12448, 65535"
"  %12513 = xor i32 %12448, 65535" -> "  %12514 = add i32 %12513, %8931"
"  %12514 = add i32 %12513, %8931"
"  %12514 = add i32 %12513, %8931" -> "  %12526 = shl i32 %12514, 16"
"  %12515 = and i32 %12512, 65535"
"  %12515 = and i32 %12512, 65535" -> "  %12517 = add nuw nsw i32 %12516, %12515"
"  %12516 = add nuw nsw i32 %12510, %12509"
"  %12516 = add nuw nsw i32 %12510, %12509" -> "  %12517 = add nuw nsw i32 %12516, %12515"
"  %12517 = add nuw nsw i32 %12516, %12515"
"  %12517 = add nuw nsw i32 %12516, %12515" -> "  %12531 = add i32 %12530, %12517""  %12517 = add nuw nsw i32 %12516, %12515" -> "  %12524 = and i32 %12517, 65535"
"  %12518 = and i32 %12503, 65535"
"  %12518 = and i32 %12503, 65535" -> "  %12519 = add nuw nsw i32 %12501, %12518"
"  %12519 = add nuw nsw i32 %12501, %12518"
"  %12519 = add nuw nsw i32 %12501, %12518" -> "  %12657 = and i32 %12519, 65535""  %12519 = add nuw nsw i32 %12501, %12518" -> "  %12521 = lshr i32 %12519, 16"
"  %12520 = and i32 %12508, 65535"
"  %12520 = and i32 %12508, 65535" -> "  %12522 = add nuw nsw i32 %12520, %12521"
"  %12521 = lshr i32 %12519, 16"
"  %12521 = lshr i32 %12519, 16" -> "  %12522 = add nuw nsw i32 %12520, %12521"
"  %12522 = add nuw nsw i32 %12520, %12521"
"  %12522 = add nuw nsw i32 %12520, %12521" -> "  %12660 = and i32 %12522, 65535""  %12522 = add nuw nsw i32 %12520, %12521" -> "  %12523 = lshr i32 %12522, 16"
"  %12523 = lshr i32 %12522, 16"
"  %12523 = lshr i32 %12522, 16" -> "  %12525 = add nuw nsw i32 %12524, %12523"
"  %12524 = and i32 %12517, 65535"
"  %12524 = and i32 %12517, 65535" -> "  %12525 = add nuw nsw i32 %12524, %12523"
"  %12525 = add nuw nsw i32 %12524, %12523"
"  %12525 = add nuw nsw i32 %12524, %12523" -> "  %12533 = add i32 %12525, %12532"
"  %12526 = shl i32 %12514, 16"
"  %12526 = shl i32 %12514, 16" -> "  %12527 = add i32 %12526, %12474"
"  %12527 = add i32 %12526, %12474"
"  %12527 = add i32 %12526, %12474" -> "  %12528 = and i32 %12527, -65536"
"  %12528 = and i32 %12527, -65536"
"  %12528 = and i32 %12527, -65536" -> "  %12529 = add i32 %12528, %12512"
"  %12529 = add i32 %12528, %12512"
"  %12529 = add i32 %12528, %12512" -> "  %12530 = and i32 %12529, -65536"
"  %12530 = and i32 %12529, -65536"
"  %12530 = and i32 %12529, -65536" -> "  %12531 = add i32 %12530, %12517"
"  %12531 = add i32 %12530, %12517"
"  %12531 = add i32 %12530, %12517" -> "  %12532 = and i32 %12531, -65536"
"  %12532 = and i32 %12531, -65536"
"  %12532 = and i32 %12531, -65536" -> "  %12533 = add i32 %12525, %12532"
"  %12533 = add i32 %12525, %12532"
"  %12533 = add i32 %12525, %12532" -> "  %12683 = and i32 %12533, 65535""  %12533 = add i32 %12525, %12532" -> "  %12686 = lshr i32 %12533, 16"
"  %12534 = and i32 %12476, 65535"
"  %12534 = and i32 %12476, 65535" -> "  %12687 = mul nuw i32 %12686, %12534""  %12534 = and i32 %12476, 65535" -> "  %12684 = mul nuw i32 %12683, %12534""  %12534 = and i32 %12476, 65535" -> "  %12661 = mul nuw i32 %12660, %12534""  %12534 = and i32 %12476, 65535" -> "  %12658 = mul nuw i32 %12657, %12534""  %12534 = and i32 %12476, 65535" -> "  %12557 = mul nuw i32 %12554, %12534""  %12534 = and i32 %12476, 65535" -> "  %12555 = mul nuw i32 %12553, %12534""  %12534 = and i32 %12476, 65535" -> "  %12538 = mul nuw i32 %12535, %12534""  %12534 = and i32 %12476, 65535" -> "  %12536 = mul nuw i32 %12534, %12534""  %12534 = and i32 %12476, 65535" -> "  %12536 = mul nuw i32 %12534, %12534"
"  %12535 = and i32 %12481, 65535"
"  %12535 = and i32 %12481, 65535" -> "  %12703 = mul nuw i32 %12686, %12535""  %12535 = and i32 %12481, 65535" -> "  %12690 = mul nuw i32 %12683, %12535""  %12535 = and i32 %12481, 65535" -> "  %12677 = mul nuw i32 %12660, %12535""  %12535 = and i32 %12481, 65535" -> "  %12664 = mul nuw i32 %12657, %12535""  %12535 = and i32 %12481, 65535" -> "  %12570 = mul nuw i32 %12554, %12535""  %12535 = and i32 %12481, 65535" -> "  %12560 = mul nuw i32 %12553, %12535""  %12535 = and i32 %12481, 65535" -> "  %12538 = mul nuw i32 %12535, %12534""  %12535 = and i32 %12481, 65535" -> "  %12546 = mul nuw i32 %12535, %12535""  %12535 = and i32 %12481, 65535" -> "  %12546 = mul nuw i32 %12535, %12535"
"  %12536 = mul nuw i32 %12534, %12534"
"  %12536 = mul nuw i32 %12534, %12534" -> "  %13153 = and i32 %12536, 65535""  %12536 = mul nuw i32 %12534, %12534" -> "  %12537 = lshr i32 %12536, 16"
"  %12537 = lshr i32 %12536, 16"
"  %12537 = lshr i32 %12536, 16" -> "  %12540 = add nuw nsw i32 %12539, %12537"
"  %12538 = mul nuw i32 %12535, %12534"
"  %12538 = mul nuw i32 %12535, %12534" -> "  %12544 = add nuw i32 %12543, %12538""  %12538 = mul nuw i32 %12535, %12534" -> "  %12541 = and i32 %12538, -65536""  %12538 = mul nuw i32 %12535, %12534" -> "  %12539 = and i32 %12538, 65535"
"  %12539 = and i32 %12538, 65535"
"  %12539 = and i32 %12538, 65535" -> "  %12540 = add nuw nsw i32 %12539, %12537"
"  %12540 = add nuw nsw i32 %12539, %12537"
"  %12540 = add nuw nsw i32 %12539, %12537" -> "  %12542 = add nuw i32 %12540, %12541"
"  %12541 = and i32 %12538, -65536"
"  %12541 = and i32 %12538, -65536" -> "  %12542 = add nuw i32 %12540, %12541"
"  %12542 = add nuw i32 %12540, %12541"
"  %12542 = add nuw i32 %12540, %12541" -> "  %12545 = lshr i32 %12542, 16""  %12542 = add nuw i32 %12540, %12541" -> "  %12543 = and i32 %12542, 65535"
"  %12543 = and i32 %12542, 65535"
"  %12543 = and i32 %12542, 65535" -> "  %12544 = add nuw i32 %12543, %12538"
"  %12544 = add nuw i32 %12543, %12538"
"  %12544 = add nuw i32 %12543, %12538" -> "  %13156 = and i32 %12544, 65535""  %12544 = add nuw i32 %12543, %12538" -> "  %12548 = lshr i32 %12544, 16"
"  %12545 = lshr i32 %12542, 16"
"  %12545 = lshr i32 %12542, 16" -> "  %12547 = add nuw i32 %12545, %12546"
"  %12546 = mul nuw i32 %12535, %12535"
"  %12546 = mul nuw i32 %12535, %12535" -> "  %12547 = add nuw i32 %12545, %12546"
"  %12547 = add nuw i32 %12545, %12546"
"  %12547 = add nuw i32 %12545, %12546" -> "  %12551 = and i32 %12547, -65536""  %12547 = add nuw i32 %12545, %12546" -> "  %12549 = and i32 %12547, 65535"
"  %12548 = lshr i32 %12544, 16"
"  %12548 = lshr i32 %12544, 16" -> "  %12550 = add nuw nsw i32 %12549, %12548"
"  %12549 = and i32 %12547, 65535"
"  %12549 = and i32 %12547, 65535" -> "  %12550 = add nuw nsw i32 %12549, %12548"
"  %12550 = add nuw nsw i32 %12549, %12548"
"  %12550 = add nuw nsw i32 %12549, %12548" -> "  %12552 = add i32 %12550, %12551"
"  %12551 = and i32 %12547, -65536"
"  %12551 = and i32 %12547, -65536" -> "  %12552 = add i32 %12550, %12551"
"  %12552 = add i32 %12550, %12551"
"  %12552 = add i32 %12550, %12551" -> "  %12579 = and i32 %12552, 65535""  %12552 = add i32 %12550, %12551" -> "  %12577 = lshr i32 %12552, 16"
"  %12553 = and i32 %12496, 65535"
"  %12553 = and i32 %12496, 65535" -> "  %12761 = mul nuw i32 %12686, %12553""  %12553 = and i32 %12496, 65535" -> "  %12759 = mul nuw i32 %12683, %12553""  %12553 = and i32 %12496, 65535" -> "  %12727 = mul nuw i32 %12660, %12553""  %12553 = and i32 %12496, 65535" -> "  %12725 = mul nuw i32 %12657, %12553""  %12553 = and i32 %12496, 65535" -> "  %12613 = mul nuw i32 %12554, %12553""  %12553 = and i32 %12496, 65535" -> "  %12560 = mul nuw i32 %12553, %12535""  %12553 = and i32 %12496, 65535" -> "  %12555 = mul nuw i32 %12553, %12534""  %12553 = and i32 %12496, 65535" -> "  %12611 = mul nuw i32 %12553, %12553""  %12553 = and i32 %12496, 65535" -> "  %12611 = mul nuw i32 %12553, %12553"
"  %12554 = and i32 %12499, 65535"
"  %12554 = and i32 %12499, 65535" -> "  %12771 = mul nuw i32 %12686, %12554""  %12554 = and i32 %12499, 65535" -> "  %12762 = mul nuw i32 %12683, %12554""  %12554 = and i32 %12499, 65535" -> "  %12740 = mul nuw i32 %12660, %12554""  %12554 = and i32 %12499, 65535" -> "  %12730 = mul nuw i32 %12657, %12554""  %12554 = and i32 %12499, 65535" -> "  %12613 = mul nuw i32 %12554, %12553""  %12554 = and i32 %12499, 65535" -> "  %12570 = mul nuw i32 %12554, %12535""  %12554 = and i32 %12499, 65535" -> "  %12557 = mul nuw i32 %12554, %12534""  %12554 = and i32 %12499, 65535" -> "  %12621 = mul nuw i32 %12554, %12554""  %12554 = and i32 %12499, 65535" -> "  %12621 = mul nuw i32 %12554, %12554"
"  %12555 = mul nuw i32 %12553, %12534"
"  %12555 = mul nuw i32 %12553, %12534" -> "  %12580 = and i32 %12555, 65535""  %12555 = mul nuw i32 %12553, %12534" -> "  %12556 = lshr i32 %12555, 16"
"  %12556 = lshr i32 %12555, 16"
"  %12556 = lshr i32 %12555, 16" -> "  %12559 = add nuw nsw i32 %12558, %12556""  %12556 = lshr i32 %12555, 16" -> "  %12561 = add nuw i32 %12556, %12560"
"  %12557 = mul nuw i32 %12554, %12534"
"  %12557 = mul nuw i32 %12554, %12534" -> "  %12563 = add nuw i32 %12557, %12562""  %12557 = mul nuw i32 %12554, %12534" -> "  %12564 = and i32 %12557, -65536""  %12557 = mul nuw i32 %12554, %12534" -> "  %12558 = and i32 %12557, 65535"
"  %12558 = and i32 %12557, 65535"
"  %12558 = and i32 %12557, 65535" -> "  %12559 = add nuw nsw i32 %12558, %12556"
"  %12559 = add nuw nsw i32 %12558, %12556"
"  %12559 = add nuw nsw i32 %12558, %12556" -> "  %12565 = add nuw i32 %12559, %12564"
"  %12560 = mul nuw i32 %12553, %12535"
"  %12560 = mul nuw i32 %12553, %12535" -> "  %12567 = add nuw i32 %12566, %12560""  %12560 = mul nuw i32 %12553, %12535" -> "  %12561 = add nuw i32 %12556, %12560"
"  %12561 = add nuw i32 %12556, %12560"
"  %12561 = add nuw i32 %12556, %12560" -> "  %12592 = lshr i32 %12561, 16""  %12561 = add nuw i32 %12556, %12560" -> "  %12562 = and i32 %12561, 65535"
"  %12562 = and i32 %12561, 65535"
"  %12562 = and i32 %12561, 65535" -> "  %12563 = add nuw i32 %12557, %12562"
"  %12563 = add nuw i32 %12557, %12562"
"  %12563 = add nuw i32 %12557, %12562" -> "  %12602 = and i32 %12563, 65535""  %12563 = add nuw i32 %12557, %12562" -> "  %12594 = lshr i32 %12563, 16"
"  %12564 = and i32 %12557, -65536"
"  %12564 = and i32 %12557, -65536" -> "  %12565 = add nuw i32 %12559, %12564"
"  %12565 = add nuw i32 %12559, %12564"
"  %12565 = add nuw i32 %12559, %12564" -> "  %12568 = lshr i32 %12565, 16""  %12565 = add nuw i32 %12559, %12564" -> "  %12566 = and i32 %12565, 65535"
"  %12566 = and i32 %12565, 65535"
"  %12566 = and i32 %12565, 65535" -> "  %12567 = add nuw i32 %12566, %12560"
"  %12567 = add nuw i32 %12566, %12560"
"  %12567 = add nuw i32 %12566, %12560" -> "  %12576 = and i32 %12567, 65535""  %12567 = add nuw i32 %12566, %12560" -> "  %12569 = lshr i32 %12567, 16"
"  %12568 = lshr i32 %12565, 16"
"  %12568 = lshr i32 %12565, 16" -> "  %12571 = add nuw i32 %12568, %12570"
"  %12569 = lshr i32 %12567, 16"
"  %12569 = lshr i32 %12567, 16" -> "  %12573 = add nuw nsw i32 %12569, %12572"
"  %12570 = mul nuw i32 %12554, %12535"
"  %12570 = mul nuw i32 %12554, %12535" -> "  %12593 = add nuw i32 %12570, %12592""  %12570 = mul nuw i32 %12554, %12535" -> "  %12571 = add nuw i32 %12568, %12570"
"  %12571 = add nuw i32 %12568, %12570"
"  %12571 = add nuw i32 %12568, %12570" -> "  %12574 = and i32 %12571, -65536""  %12571 = add nuw i32 %12568, %12570" -> "  %12572 = and i32 %12571, 65535"
"  %12572 = and i32 %12571, 65535"
"  %12572 = and i32 %12571, 65535" -> "  %12573 = add nuw nsw i32 %12569, %12572"
"  %12573 = add nuw nsw i32 %12569, %12572"
"  %12573 = add nuw nsw i32 %12569, %12572" -> "  %12575 = add i32 %12573, %12574"
"  %12574 = and i32 %12571, -65536"
"  %12574 = and i32 %12571, -65536" -> "  %12575 = add i32 %12573, %12574"
"  %12575 = add i32 %12573, %12574"
"  %12575 = add i32 %12573, %12574" -> "  %12588 = and i32 %12575, -65536""  %12575 = add i32 %12573, %12574" -> "  %12586 = and i32 %12575, 65535"
"  %12576 = and i32 %12567, 65535"
"  %12576 = and i32 %12567, 65535" -> "  %12578 = add nuw nsw i32 %12576, %12577"
"  %12577 = lshr i32 %12552, 16"
"  %12577 = lshr i32 %12552, 16" -> "  %12578 = add nuw nsw i32 %12576, %12577"
"  %12578 = add nuw nsw i32 %12576, %12577"
"  %12578 = add nuw nsw i32 %12576, %12577" -> "  %12585 = lshr i32 %12578, 16""  %12578 = add nuw nsw i32 %12576, %12577" -> "  %12583 = and i32 %12578, 65535"
"  %12579 = and i32 %12552, 65535"
"  %12579 = and i32 %12552, 65535" -> "  %12581 = add nuw nsw i32 %12579, %12580"
"  %12580 = and i32 %12555, 65535"
"  %12580 = and i32 %12555, 65535" -> "  %12600 = add nuw nsw i32 %12599, %12580""  %12580 = and i32 %12555, 65535" -> "  %12581 = add nuw nsw i32 %12579, %12580"
"  %12581 = add nuw nsw i32 %12579, %12580"
"  %12581 = add nuw nsw i32 %12579, %12580" -> "  %12599 = and i32 %12581, 65535""  %12581 = add nuw nsw i32 %12579, %12580" -> "  %12582 = lshr i32 %12581, 16"
"  %12582 = lshr i32 %12581, 16"
"  %12582 = lshr i32 %12581, 16" -> "  %12584 = add nuw nsw i32 %12583, %12582"
"  %12583 = and i32 %12578, 65535"
"  %12583 = and i32 %12578, 65535" -> "  %12584 = add nuw nsw i32 %12583, %12582"
"  %12584 = add nuw nsw i32 %12583, %12582"
"  %12584 = add nuw nsw i32 %12583, %12582" -> "  %12601 = and i32 %12584, 65535""  %12584 = add nuw nsw i32 %12583, %12582" -> "  %12590 = lshr i32 %12584, 16"
"  %12585 = lshr i32 %12578, 16"
"  %12585 = lshr i32 %12578, 16" -> "  %12587 = add nuw nsw i32 %12586, %12585"
"  %12586 = and i32 %12575, 65535"
"  %12586 = and i32 %12575, 65535" -> "  %12587 = add nuw nsw i32 %12586, %12585"
"  %12587 = add nuw nsw i32 %12586, %12585"
"  %12587 = add nuw nsw i32 %12586, %12585" -> "  %12589 = add i32 %12587, %12588"
"  %12588 = and i32 %12575, -65536"
"  %12588 = and i32 %12575, -65536" -> "  %12589 = add i32 %12587, %12588"
"  %12589 = add i32 %12587, %12588"
"  %12589 = add i32 %12587, %12588" -> "  %12591 = add i32 %12589, %12590"
"  %12590 = lshr i32 %12584, 16"
"  %12590 = lshr i32 %12584, 16" -> "  %12591 = add i32 %12589, %12590"
"  %12591 = add i32 %12589, %12590"
"  %12591 = add i32 %12589, %12590" -> "  %12632 = lshr i32 %12591, 16""  %12591 = add i32 %12589, %12590" -> "  %12628 = and i32 %12591, 65535"
"  %12592 = lshr i32 %12561, 16"
"  %12592 = lshr i32 %12561, 16" -> "  %12593 = add nuw i32 %12570, %12592"
"  %12593 = add nuw i32 %12570, %12592"
"  %12593 = add nuw i32 %12570, %12592" -> "  %12597 = and i32 %12593, -65536""  %12593 = add nuw i32 %12570, %12592" -> "  %12595 = and i32 %12593, 65535"
"  %12594 = lshr i32 %12563, 16"
"  %12594 = lshr i32 %12563, 16" -> "  %12596 = add nuw nsw i32 %12594, %12595"
"  %12595 = and i32 %12593, 65535"
"  %12595 = and i32 %12593, 65535" -> "  %12596 = add nuw nsw i32 %12594, %12595"
"  %12596 = add nuw nsw i32 %12594, %12595"
"  %12596 = add nuw nsw i32 %12594, %12595" -> "  %12598 = add i32 %12596, %12597"
"  %12597 = and i32 %12593, -65536"
"  %12597 = and i32 %12593, -65536" -> "  %12598 = add i32 %12596, %12597"
"  %12598 = add i32 %12596, %12597"
"  %12598 = add i32 %12596, %12597" -> "  %12605 = add i32 %12598, %12604"
"  %12599 = and i32 %12581, 65535"
"  %12599 = and i32 %12581, 65535" -> "  %12600 = add nuw nsw i32 %12599, %12580"
"  %12600 = add nuw nsw i32 %12599, %12580"
"  %12600 = add nuw nsw i32 %12599, %12580" -> "  %13173 = and i32 %12600, 65535""  %12600 = add nuw nsw i32 %12599, %12580" -> "  %12607 = lshr i32 %12600, 16"
"  %12601 = and i32 %12584, 65535"
"  %12601 = and i32 %12584, 65535" -> "  %12603 = add nuw nsw i32 %12601, %12602"
"  %12602 = and i32 %12563, 65535"
"  %12602 = and i32 %12563, 65535" -> "  %12603 = add nuw nsw i32 %12601, %12602"
"  %12603 = add nuw nsw i32 %12601, %12602"
"  %12603 = add nuw nsw i32 %12601, %12602" -> "  %12606 = and i32 %12603, 65535""  %12603 = add nuw nsw i32 %12601, %12602" -> "  %12604 = lshr i32 %12603, 16"
"  %12604 = lshr i32 %12603, 16"
"  %12604 = lshr i32 %12603, 16" -> "  %12605 = add i32 %12598, %12604"
"  %12605 = add i32 %12598, %12604"
"  %12605 = add i32 %12598, %12604" -> "  %12610 = add i32 %12605, %12609"
"  %12606 = and i32 %12603, 65535"
"  %12606 = and i32 %12603, 65535" -> "  %12608 = add nuw nsw i32 %12606, %12607"
"  %12607 = lshr i32 %12600, 16"
"  %12607 = lshr i32 %12600, 16" -> "  %12608 = add nuw nsw i32 %12606, %12607"
"  %12608 = add nuw nsw i32 %12606, %12607"
"  %12608 = add nuw nsw i32 %12606, %12607" -> "  %13176 = and i32 %12608, 65535""  %12608 = add nuw nsw i32 %12606, %12607" -> "  %12609 = lshr i32 %12608, 16"
"  %12609 = lshr i32 %12608, 16"
"  %12609 = lshr i32 %12608, 16" -> "  %12610 = add i32 %12605, %12609"
"  %12610 = add i32 %12605, %12609"
"  %12610 = add i32 %12605, %12609" -> "  %12645 = lshr i32 %12610, 16""  %12610 = add i32 %12605, %12609" -> "  %12642 = and i32 %12610, 65535"
"  %12611 = mul nuw i32 %12553, %12553"
"  %12611 = mul nuw i32 %12553, %12553" -> "  %12612 = lshr i32 %12611, 16""  %12611 = mul nuw i32 %12553, %12553" -> "  %12629 = and i32 %12611, 65535"
"  %12612 = lshr i32 %12611, 16"
"  %12612 = lshr i32 %12611, 16" -> "  %12615 = add nuw nsw i32 %12614, %12612"
"  %12613 = mul nuw i32 %12554, %12553"
"  %12613 = mul nuw i32 %12554, %12553" -> "  %12619 = add nuw i32 %12618, %12613""  %12613 = mul nuw i32 %12554, %12553" -> "  %12616 = and i32 %12613, -65536""  %12613 = mul nuw i32 %12554, %12553" -> "  %12614 = and i32 %12613, 65535"
"  %12614 = and i32 %12613, 65535"
"  %12614 = and i32 %12613, 65535" -> "  %12615 = add nuw nsw i32 %12614, %12612"
"  %12615 = add nuw nsw i32 %12614, %12612"
"  %12615 = add nuw nsw i32 %12614, %12612" -> "  %12617 = add nuw i32 %12615, %12616"
"  %12616 = and i32 %12613, -65536"
"  %12616 = and i32 %12613, -65536" -> "  %12617 = add nuw i32 %12615, %12616"
"  %12617 = add nuw i32 %12615, %12616"
"  %12617 = add nuw i32 %12615, %12616" -> "  %12620 = lshr i32 %12617, 16""  %12617 = add nuw i32 %12615, %12616" -> "  %12618 = and i32 %12617, 65535"
"  %12618 = and i32 %12617, 65535"
"  %12618 = and i32 %12617, 65535" -> "  %12619 = add nuw i32 %12618, %12613"
"  %12619 = add nuw i32 %12618, %12613"
"  %12619 = add nuw i32 %12618, %12613" -> "  %12631 = and i32 %12619, 65535""  %12619 = add nuw i32 %12618, %12613" -> "  %12623 = lshr i32 %12619, 16"
"  %12620 = lshr i32 %12617, 16"
"  %12620 = lshr i32 %12617, 16" -> "  %12622 = add nuw i32 %12620, %12621"
"  %12621 = mul nuw i32 %12554, %12554"
"  %12621 = mul nuw i32 %12554, %12554" -> "  %12622 = add nuw i32 %12620, %12621"
"  %12622 = add nuw i32 %12620, %12621"
"  %12622 = add nuw i32 %12620, %12621" -> "  %12626 = and i32 %12622, -65536""  %12622 = add nuw i32 %12620, %12621" -> "  %12624 = and i32 %12622, 65535"
"  %12623 = lshr i32 %12619, 16"
"  %12623 = lshr i32 %12619, 16" -> "  %12625 = add nuw nsw i32 %12623, %12624"
"  %12624 = and i32 %12622, 65535"
"  %12624 = and i32 %12622, 65535" -> "  %12625 = add nuw nsw i32 %12623, %12624"
"  %12625 = add nuw nsw i32 %12623, %12624"
"  %12625 = add nuw nsw i32 %12623, %12624" -> "  %12627 = add i32 %12625, %12626"
"  %12626 = and i32 %12622, -65536"
"  %12626 = and i32 %12622, -65536" -> "  %12627 = add i32 %12625, %12626"
"  %12627 = add i32 %12625, %12626"
"  %12627 = add i32 %12625, %12626" -> "  %12635 = add i32 %12627, %12634"
"  %12628 = and i32 %12591, 65535"
"  %12628 = and i32 %12591, 65535" -> "  %12630 = add nuw nsw i32 %12628, %12629"
"  %12629 = and i32 %12611, 65535"
"  %12629 = and i32 %12611, 65535" -> "  %12630 = add nuw nsw i32 %12628, %12629"
"  %12630 = add nuw nsw i32 %12628, %12629"
"  %12630 = add nuw nsw i32 %12628, %12629" -> "  %12641 = and i32 %12630, 65535""  %12630 = add nuw nsw i32 %12628, %12629" -> "  %12637 = lshr i32 %12630, 16"
"  %12631 = and i32 %12619, 65535"
"  %12631 = and i32 %12619, 65535" -> "  %12633 = add nuw nsw i32 %12632, %12631"
"  %12632 = lshr i32 %12591, 16"
"  %12632 = lshr i32 %12591, 16" -> "  %12633 = add nuw nsw i32 %12632, %12631"
"  %12633 = add nuw nsw i32 %12632, %12631"
"  %12633 = add nuw nsw i32 %12632, %12631" -> "  %12636 = and i32 %12633, 65535""  %12633 = add nuw nsw i32 %12632, %12631" -> "  %12634 = lshr i32 %12633, 16"
"  %12634 = lshr i32 %12633, 16"
"  %12634 = lshr i32 %12633, 16" -> "  %12635 = add i32 %12627, %12634"
"  %12635 = add i32 %12627, %12634"
"  %12635 = add i32 %12627, %12634" -> "  %12640 = add i32 %12635, %12639"
"  %12636 = and i32 %12633, 65535"
"  %12636 = and i32 %12633, 65535" -> "  %12638 = add nuw nsw i32 %12637, %12636"
"  %12637 = lshr i32 %12630, 16"
"  %12637 = lshr i32 %12630, 16" -> "  %12638 = add nuw nsw i32 %12637, %12636"
"  %12638 = add nuw nsw i32 %12637, %12636"
"  %12638 = add nuw nsw i32 %12637, %12636" -> "  %12644 = and i32 %12638, 65535""  %12638 = add nuw nsw i32 %12637, %12636" -> "  %12639 = lshr i32 %12638, 16"
"  %12639 = lshr i32 %12638, 16"
"  %12639 = lshr i32 %12638, 16" -> "  %12640 = add i32 %12635, %12639"
"  %12640 = add i32 %12635, %12639"
"  %12640 = add i32 %12635, %12639" -> "  %12653 = and i32 %12640, -65536""  %12640 = add i32 %12635, %12639" -> "  %12651 = and i32 %12640, 65535"
"  %12641 = and i32 %12630, 65535"
"  %12641 = and i32 %12630, 65535" -> "  %12643 = add nuw nsw i32 %12642, %12641"
"  %12642 = and i32 %12610, 65535"
"  %12642 = and i32 %12610, 65535" -> "  %12643 = add nuw nsw i32 %12642, %12641"
"  %12643 = add nuw nsw i32 %12642, %12641"
"  %12643 = add nuw nsw i32 %12642, %12641" -> "  %12810 = and i32 %12643, 65535""  %12643 = add nuw nsw i32 %12642, %12641" -> "  %12647 = lshr i32 %12643, 16"
"  %12644 = and i32 %12638, 65535"
"  %12644 = and i32 %12638, 65535" -> "  %12646 = add nuw nsw i32 %12644, %12645"
"  %12645 = lshr i32 %12610, 16"
"  %12645 = lshr i32 %12610, 16" -> "  %12646 = add nuw nsw i32 %12644, %12645"
"  %12646 = add nuw nsw i32 %12644, %12645"
"  %12646 = add nuw nsw i32 %12644, %12645" -> "  %12650 = lshr i32 %12646, 16""  %12646 = add nuw nsw i32 %12644, %12645" -> "  %12648 = and i32 %12646, 65535"
"  %12647 = lshr i32 %12643, 16"
"  %12647 = lshr i32 %12643, 16" -> "  %12649 = add nuw nsw i32 %12648, %12647"
"  %12648 = and i32 %12646, 65535"
"  %12648 = and i32 %12646, 65535" -> "  %12649 = add nuw nsw i32 %12648, %12647"
"  %12649 = add nuw nsw i32 %12648, %12647"
"  %12649 = add nuw nsw i32 %12648, %12647" -> "  %12807 = and i32 %12649, 65535""  %12649 = add nuw nsw i32 %12648, %12647" -> "  %12655 = lshr i32 %12649, 16"
"  %12650 = lshr i32 %12646, 16"
"  %12650 = lshr i32 %12646, 16" -> "  %12652 = add nuw nsw i32 %12650, %12651"
"  %12651 = and i32 %12640, 65535"
"  %12651 = and i32 %12640, 65535" -> "  %12652 = add nuw nsw i32 %12650, %12651"
"  %12652 = add nuw nsw i32 %12650, %12651"
"  %12652 = add nuw nsw i32 %12650, %12651" -> "  %12654 = add i32 %12652, %12653"
"  %12653 = and i32 %12640, -65536"
"  %12653 = and i32 %12640, -65536" -> "  %12654 = add i32 %12652, %12653"
"  %12654 = add i32 %12652, %12653"
"  %12654 = add i32 %12652, %12653" -> "  %12656 = add i32 %12654, %12655"
"  %12655 = lshr i32 %12649, 16"
"  %12655 = lshr i32 %12649, 16" -> "  %12656 = add i32 %12654, %12655"
"  %12656 = add i32 %12654, %12655"
"  %12656 = add i32 %12654, %12655" -> "  %12819 = and i32 %12656, 65535""  %12656 = add i32 %12654, %12655" -> "  %12822 = lshr i32 %12656, 16"
"  %12657 = and i32 %12519, 65535"
"  %12657 = and i32 %12519, 65535" -> "  %12977 = mul nuw i32 %12686, %12657""  %12657 = and i32 %12519, 65535" -> "  %12975 = mul nuw i32 %12683, %12657""  %12657 = and i32 %12519, 65535" -> "  %12960 = mul nuw i32 %12660, %12657""  %12657 = and i32 %12519, 65535" -> "  %12730 = mul nuw i32 %12657, %12554""  %12657 = and i32 %12519, 65535" -> "  %12725 = mul nuw i32 %12657, %12553""  %12657 = and i32 %12519, 65535" -> "  %12664 = mul nuw i32 %12657, %12535""  %12657 = and i32 %12519, 65535" -> "  %12658 = mul nuw i32 %12657, %12534""  %12657 = and i32 %12519, 65535" -> "  %12958 = mul nuw i32 %12657, %12657""  %12657 = and i32 %12519, 65535" -> "  %12958 = mul nuw i32 %12657, %12657"
"  %12658 = mul nuw i32 %12657, %12534"
"  %12658 = mul nuw i32 %12657, %12534" -> "  %12809 = and i32 %12658, 65535""  %12658 = mul nuw i32 %12657, %12534" -> "  %12659 = lshr i32 %12658, 16"
"  %12659 = lshr i32 %12658, 16"
"  %12659 = lshr i32 %12658, 16" -> "  %12663 = add nuw nsw i32 %12662, %12659""  %12659 = lshr i32 %12658, 16" -> "  %12666 = add nuw nsw i32 %12659, %12665"
"  %12660 = and i32 %12522, 65535"
"  %12660 = and i32 %12522, 65535" -> "  %12993 = mul nuw i32 %12686, %12660""  %12660 = and i32 %12522, 65535" -> "  %12980 = mul nuw i32 %12683, %12660""  %12660 = and i32 %12522, 65535" -> "  %12960 = mul nuw i32 %12660, %12657""  %12660 = and i32 %12522, 65535" -> "  %12740 = mul nuw i32 %12660, %12554""  %12660 = and i32 %12522, 65535" -> "  %12727 = mul nuw i32 %12660, %12553""  %12660 = and i32 %12522, 65535" -> "  %12677 = mul nuw i32 %12660, %12535""  %12660 = and i32 %12522, 65535" -> "  %12661 = mul nuw i32 %12660, %12534""  %12660 = and i32 %12522, 65535" -> "  %12968 = mul nuw i32 %12660, %12660""  %12660 = and i32 %12522, 65535" -> "  %12968 = mul nuw i32 %12660, %12660"
"  %12661 = mul nuw i32 %12660, %12534"
"  %12661 = mul nuw i32 %12660, %12534" -> "  %12670 = add nuw i32 %12661, %12669""  %12661 = mul nuw i32 %12660, %12534" -> "  %12671 = and i32 %12661, -65536""  %12661 = mul nuw i32 %12660, %12534" -> "  %12662 = and i32 %12661, 65535"
"  %12662 = and i32 %12661, 65535"
"  %12662 = and i32 %12661, 65535" -> "  %12663 = add nuw nsw i32 %12662, %12659"
"  %12663 = add nuw nsw i32 %12662, %12659"
"  %12663 = add nuw nsw i32 %12662, %12659" -> "  %12672 = add nuw i32 %12663, %12671"
"  %12664 = mul nuw i32 %12657, %12535"
"  %12664 = mul nuw i32 %12657, %12535" -> "  %12674 = add nuw i32 %12673, %12664""  %12664 = mul nuw i32 %12657, %12535" -> "  %12667 = and i32 %12664, -65536""  %12664 = mul nuw i32 %12657, %12535" -> "  %12665 = and i32 %12664, 65535"
"  %12665 = and i32 %12664, 65535"
"  %12665 = and i32 %12664, 65535" -> "  %12666 = add nuw nsw i32 %12659, %12665"
"  %12666 = add nuw nsw i32 %12659, %12665"
"  %12666 = add nuw nsw i32 %12659, %12665" -> "  %12668 = add nuw i32 %12666, %12667"
"  %12667 = and i32 %12664, -65536"
"  %12667 = and i32 %12664, -65536" -> "  %12668 = add nuw i32 %12666, %12667"
"  %12668 = add nuw i32 %12666, %12667"
"  %12668 = add nuw i32 %12666, %12667" -> "  %12844 = lshr i32 %12668, 16""  %12668 = add nuw i32 %12666, %12667" -> "  %12669 = and i32 %12668, 65535"
"  %12669 = and i32 %12668, 65535"
"  %12669 = and i32 %12668, 65535" -> "  %12670 = add nuw i32 %12661, %12669"
"  %12670 = add nuw i32 %12661, %12669"
"  %12670 = add nuw i32 %12661, %12669" -> "  %12846 = lshr i32 %12670, 16""  %12670 = add nuw i32 %12661, %12669" -> "  %12923 = and i32 %12670, 65535"
"  %12671 = and i32 %12661, -65536"
"  %12671 = and i32 %12661, -65536" -> "  %12672 = add nuw i32 %12663, %12671"
"  %12672 = add nuw i32 %12663, %12671"
"  %12672 = add nuw i32 %12663, %12671" -> "  %12675 = lshr i32 %12672, 16""  %12672 = add nuw i32 %12663, %12671" -> "  %12673 = and i32 %12672, 65535"
"  %12673 = and i32 %12672, 65535"
"  %12673 = and i32 %12672, 65535" -> "  %12674 = add nuw i32 %12673, %12664"
"  %12674 = add nuw i32 %12673, %12664"
"  %12674 = add nuw i32 %12673, %12664" -> "  %12806 = and i32 %12674, 65535""  %12674 = add nuw i32 %12673, %12664" -> "  %12676 = lshr i32 %12674, 16"
"  %12675 = lshr i32 %12672, 16"
"  %12675 = lshr i32 %12672, 16" -> "  %12678 = add nuw i32 %12675, %12677"
"  %12676 = lshr i32 %12674, 16"
"  %12676 = lshr i32 %12674, 16" -> "  %12680 = add nuw nsw i32 %12676, %12679"
"  %12677 = mul nuw i32 %12660, %12535"
"  %12677 = mul nuw i32 %12660, %12535" -> "  %12845 = add nuw i32 %12677, %12844""  %12677 = mul nuw i32 %12660, %12535" -> "  %12678 = add nuw i32 %12675, %12677"
"  %12678 = add nuw i32 %12675, %12677"
"  %12678 = add nuw i32 %12675, %12677" -> "  %12681 = and i32 %12678, -65536""  %12678 = add nuw i32 %12675, %12677" -> "  %12679 = and i32 %12678, 65535"
"  %12679 = and i32 %12678, 65535"
"  %12679 = and i32 %12678, 65535" -> "  %12680 = add nuw nsw i32 %12676, %12679"
"  %12680 = add nuw nsw i32 %12676, %12679"
"  %12680 = add nuw nsw i32 %12676, %12679" -> "  %12682 = add i32 %12680, %12681"
"  %12681 = and i32 %12678, -65536"
"  %12681 = and i32 %12678, -65536" -> "  %12682 = add i32 %12680, %12681"
"  %12682 = add i32 %12680, %12681"
"  %12682 = add i32 %12680, %12681" -> "  %12713 = and i32 %12682, 65535""  %12682 = add i32 %12680, %12681" -> "  %12710 = lshr i32 %12682, 16"
"  %12683 = and i32 %12533, 65535"
"  %12683 = and i32 %12533, 65535" -> "  %12980 = mul nuw i32 %12683, %12660""  %12683 = and i32 %12533, 65535" -> "  %12975 = mul nuw i32 %12683, %12657""  %12683 = and i32 %12533, 65535" -> "  %12762 = mul nuw i32 %12683, %12554""  %12683 = and i32 %12533, 65535" -> "  %12759 = mul nuw i32 %12683, %12553""  %12683 = and i32 %12533, 65535" -> "  %12690 = mul nuw i32 %12683, %12535""  %12683 = and i32 %12533, 65535" -> "  %12684 = mul nuw i32 %12683, %12534""  %12683 = and i32 %12533, 65535" -> "  %13033 = mul nuw i32 %12686, %12683""  %12683 = and i32 %12533, 65535" -> "  %13031 = mul nuw i32 %12683, %12683""  %12683 = and i32 %12533, 65535" -> "  %13031 = mul nuw i32 %12683, %12683"
"  %12684 = mul nuw i32 %12683, %12534"
"  %12684 = mul nuw i32 %12683, %12534" -> "  %12685 = lshr i32 %12684, 16""  %12684 = mul nuw i32 %12683, %12534" -> "  %12712 = and i32 %12684, 65535"
"  %12685 = lshr i32 %12684, 16"
"  %12685 = lshr i32 %12684, 16" -> "  %12692 = add nuw nsw i32 %12685, %12691""  %12685 = lshr i32 %12684, 16" -> "  %12689 = add nuw nsw i32 %12685, %12688"
"  %12686 = lshr i32 %12533, 16"
"  %12686 = lshr i32 %12533, 16" -> "  %12993 = mul nuw i32 %12686, %12660""  %12686 = lshr i32 %12533, 16" -> "  %12977 = mul nuw i32 %12686, %12657""  %12686 = lshr i32 %12533, 16" -> "  %12771 = mul nuw i32 %12686, %12554""  %12686 = lshr i32 %12533, 16" -> "  %12761 = mul nuw i32 %12686, %12553""  %12686 = lshr i32 %12533, 16" -> "  %12703 = mul nuw i32 %12686, %12535""  %12686 = lshr i32 %12533, 16" -> "  %12687 = mul nuw i32 %12686, %12534""  %12686 = lshr i32 %12533, 16" -> "  %13033 = mul nuw i32 %12686, %12683""  %12686 = lshr i32 %12533, 16" -> "  %13041 = mul nuw i32 %12686, %12686""  %12686 = lshr i32 %12533, 16" -> "  %13041 = mul nuw i32 %12686, %12686"
"  %12687 = mul nuw i32 %12686, %12534"
"  %12687 = mul nuw i32 %12686, %12534" -> "  %12696 = add nuw i32 %12695, %12687""  %12687 = mul nuw i32 %12686, %12534" -> "  %12697 = and i32 %12687, -65536""  %12687 = mul nuw i32 %12686, %12534" -> "  %12688 = and i32 %12687, 65535"
"  %12688 = and i32 %12687, 65535"
"  %12688 = and i32 %12687, 65535" -> "  %12689 = add nuw nsw i32 %12685, %12688"
"  %12689 = add nuw nsw i32 %12685, %12688"
"  %12689 = add nuw nsw i32 %12685, %12688" -> "  %12698 = add nuw i32 %12689, %12697"
"  %12690 = mul nuw i32 %12683, %12535"
"  %12690 = mul nuw i32 %12683, %12535" -> "  %12700 = add nuw i32 %12699, %12690""  %12690 = mul nuw i32 %12683, %12535" -> "  %12693 = and i32 %12690, -65536""  %12690 = mul nuw i32 %12683, %12535" -> "  %12691 = and i32 %12690, 65535"
"  %12691 = and i32 %12690, 65535"
"  %12691 = and i32 %12690, 65535" -> "  %12692 = add nuw nsw i32 %12685, %12691"
"  %12692 = add nuw nsw i32 %12685, %12691"
"  %12692 = add nuw nsw i32 %12685, %12691" -> "  %12694 = add nuw i32 %12692, %12693"
"  %12693 = and i32 %12690, -65536"
"  %12693 = and i32 %12690, -65536" -> "  %12694 = add nuw i32 %12692, %12693"
"  %12694 = add nuw i32 %12692, %12693"
"  %12694 = add nuw i32 %12692, %12693" -> "  %12870 = lshr i32 %12694, 16""  %12694 = add nuw i32 %12692, %12693" -> "  %12695 = and i32 %12694, 65535"
"  %12695 = and i32 %12694, 65535"
"  %12695 = and i32 %12694, 65535" -> "  %12696 = add nuw i32 %12695, %12687"
"  %12696 = add nuw i32 %12695, %12687"
"  %12696 = add nuw i32 %12695, %12687" -> "  %12872 = lshr i32 %12696, 16""  %12696 = add nuw i32 %12695, %12687" -> "  %12880 = and i32 %12696, 65535"
"  %12697 = and i32 %12687, -65536"
"  %12697 = and i32 %12687, -65536" -> "  %12698 = add nuw i32 %12689, %12697"
"  %12698 = add nuw i32 %12689, %12697"
"  %12698 = add nuw i32 %12689, %12697" -> "  %12701 = lshr i32 %12698, 16""  %12698 = add nuw i32 %12689, %12697" -> "  %12699 = and i32 %12698, 65535"
"  %12699 = and i32 %12698, 65535"
"  %12699 = and i32 %12698, 65535" -> "  %12700 = add nuw i32 %12699, %12690"
"  %12700 = add nuw i32 %12699, %12690"
"  %12700 = add nuw i32 %12699, %12690" -> "  %12709 = and i32 %12700, 65535""  %12700 = add nuw i32 %12699, %12690" -> "  %12702 = lshr i32 %12700, 16"
"  %12701 = lshr i32 %12698, 16"
"  %12701 = lshr i32 %12698, 16" -> "  %12704 = add nuw i32 %12701, %12703"
"  %12702 = lshr i32 %12700, 16"
"  %12702 = lshr i32 %12700, 16" -> "  %12706 = add nuw nsw i32 %12705, %12702"
"  %12703 = mul nuw i32 %12686, %12535"
"  %12703 = mul nuw i32 %12686, %12535" -> "  %12871 = add nuw i32 %12870, %12703""  %12703 = mul nuw i32 %12686, %12535" -> "  %12704 = add nuw i32 %12701, %12703"
"  %12704 = add nuw i32 %12701, %12703"
"  %12704 = add nuw i32 %12701, %12703" -> "  %12707 = and i32 %12704, -65536""  %12704 = add nuw i32 %12701, %12703" -> "  %12705 = and i32 %12704, 65535"
"  %12705 = and i32 %12704, 65535"
"  %12705 = and i32 %12704, 65535" -> "  %12706 = add nuw nsw i32 %12705, %12702"
"  %12706 = add nuw nsw i32 %12705, %12702"
"  %12706 = add nuw nsw i32 %12705, %12702" -> "  %12708 = add i32 %12706, %12707"
"  %12707 = and i32 %12704, -65536"
"  %12707 = and i32 %12704, -65536" -> "  %12708 = add i32 %12706, %12707"
"  %12708 = add i32 %12706, %12707"
"  %12708 = add i32 %12706, %12707" -> "  %12721 = and i32 %12708, -65536""  %12708 = add i32 %12706, %12707" -> "  %12719 = and i32 %12708, 65535"
"  %12709 = and i32 %12700, 65535"
"  %12709 = and i32 %12700, 65535" -> "  %12711 = add nuw nsw i32 %12709, %12710"
"  %12710 = lshr i32 %12682, 16"
"  %12710 = lshr i32 %12682, 16" -> "  %12711 = add nuw nsw i32 %12709, %12710"
"  %12711 = add nuw nsw i32 %12709, %12710"
"  %12711 = add nuw nsw i32 %12709, %12710" -> "  %12718 = lshr i32 %12711, 16""  %12711 = add nuw nsw i32 %12709, %12710" -> "  %12716 = and i32 %12711, 65535"
"  %12712 = and i32 %12684, 65535"
"  %12712 = and i32 %12684, 65535" -> "  %12714 = add nuw nsw i32 %12713, %12712""  %12712 = and i32 %12684, 65535" -> "  %12878 = add nuw nsw i32 %12712, %12877"
"  %12713 = and i32 %12682, 65535"
"  %12713 = and i32 %12682, 65535" -> "  %12714 = add nuw nsw i32 %12713, %12712"
"  %12714 = add nuw nsw i32 %12713, %12712"
"  %12714 = add nuw nsw i32 %12713, %12712" -> "  %12752 = and i32 %12714, 65535""  %12714 = add nuw nsw i32 %12713, %12712" -> "  %12715 = lshr i32 %12714, 16"
"  %12715 = lshr i32 %12714, 16"
"  %12715 = lshr i32 %12714, 16" -> "  %12717 = add nuw nsw i32 %12716, %12715"
"  %12716 = and i32 %12711, 65535"
"  %12716 = and i32 %12711, 65535" -> "  %12717 = add nuw nsw i32 %12716, %12715"
"  %12717 = add nuw nsw i32 %12716, %12715"
"  %12717 = add nuw nsw i32 %12716, %12715" -> "  %12746 = and i32 %12717, 65535""  %12717 = add nuw nsw i32 %12716, %12715" -> "  %12723 = lshr i32 %12717, 16"
"  %12718 = lshr i32 %12711, 16"
"  %12718 = lshr i32 %12711, 16" -> "  %12720 = add nuw nsw i32 %12719, %12718"
"  %12719 = and i32 %12708, 65535"
"  %12719 = and i32 %12708, 65535" -> "  %12720 = add nuw nsw i32 %12719, %12718"
"  %12720 = add nuw nsw i32 %12719, %12718"
"  %12720 = add nuw nsw i32 %12719, %12718" -> "  %12722 = add i32 %12720, %12721"
"  %12721 = and i32 %12708, -65536"
"  %12721 = and i32 %12708, -65536" -> "  %12722 = add i32 %12720, %12721"
"  %12722 = add i32 %12720, %12721"
"  %12722 = add i32 %12720, %12721" -> "  %12724 = add i32 %12722, %12723"
"  %12723 = lshr i32 %12717, 16"
"  %12723 = lshr i32 %12717, 16" -> "  %12724 = add i32 %12722, %12723"
"  %12724 = add i32 %12722, %12723"
"  %12724 = add i32 %12722, %12723" -> "  %12783 = and i32 %12724, 65535""  %12724 = add i32 %12722, %12723" -> "  %12778 = lshr i32 %12724, 16"
"  %12725 = mul nuw i32 %12657, %12553"
"  %12725 = mul nuw i32 %12657, %12553" -> "  %12751 = and i32 %12725, 65535""  %12725 = mul nuw i32 %12657, %12553" -> "  %12726 = lshr i32 %12725, 16"
"  %12726 = lshr i32 %12725, 16"
"  %12726 = lshr i32 %12725, 16" -> "  %12729 = add nuw nsw i32 %12728, %12726""  %12726 = lshr i32 %12725, 16" -> "  %12731 = add nuw i32 %12726, %12730"
"  %12727 = mul nuw i32 %12660, %12553"
"  %12727 = mul nuw i32 %12660, %12553" -> "  %12733 = add nuw i32 %12727, %12732""  %12727 = mul nuw i32 %12660, %12553" -> "  %12734 = and i32 %12727, -65536""  %12727 = mul nuw i32 %12660, %12553" -> "  %12728 = and i32 %12727, 65535"
"  %12728 = and i32 %12727, 65535"
"  %12728 = and i32 %12727, 65535" -> "  %12729 = add nuw nsw i32 %12728, %12726"
"  %12729 = add nuw nsw i32 %12728, %12726"
"  %12729 = add nuw nsw i32 %12728, %12726" -> "  %12735 = add nuw i32 %12729, %12734"
"  %12730 = mul nuw i32 %12657, %12554"
"  %12730 = mul nuw i32 %12657, %12554" -> "  %12737 = add nuw i32 %12736, %12730""  %12730 = mul nuw i32 %12657, %12554" -> "  %12731 = add nuw i32 %12726, %12730"
"  %12731 = add nuw i32 %12726, %12730"
"  %12731 = add nuw i32 %12726, %12730" -> "  %12851 = lshr i32 %12731, 16""  %12731 = add nuw i32 %12726, %12730" -> "  %12732 = and i32 %12731, 65535"
"  %12732 = and i32 %12731, 65535"
"  %12732 = and i32 %12731, 65535" -> "  %12733 = add nuw i32 %12727, %12732"
"  %12733 = add nuw i32 %12727, %12732"
"  %12733 = add nuw i32 %12727, %12732" -> "  %12853 = lshr i32 %12733, 16""  %12733 = add nuw i32 %12727, %12732" -> "  %12860 = and i32 %12733, 65535"
"  %12734 = and i32 %12727, -65536"
"  %12734 = and i32 %12727, -65536" -> "  %12735 = add nuw i32 %12729, %12734"
"  %12735 = add nuw i32 %12729, %12734"
"  %12735 = add nuw i32 %12729, %12734" -> "  %12738 = lshr i32 %12735, 16""  %12735 = add nuw i32 %12729, %12734" -> "  %12736 = and i32 %12735, 65535"
"  %12736 = and i32 %12735, 65535"
"  %12736 = and i32 %12735, 65535" -> "  %12737 = add nuw i32 %12736, %12730"
"  %12737 = add nuw i32 %12736, %12730"
"  %12737 = add nuw i32 %12736, %12730" -> "  %12747 = and i32 %12737, 65535""  %12737 = add nuw i32 %12736, %12730" -> "  %12739 = lshr i32 %12737, 16"
"  %12738 = lshr i32 %12735, 16"
"  %12738 = lshr i32 %12735, 16" -> "  %12741 = add nuw i32 %12738, %12740"
"  %12739 = lshr i32 %12737, 16"
"  %12739 = lshr i32 %12737, 16" -> "  %12743 = add nuw nsw i32 %12739, %12742"
"  %12740 = mul nuw i32 %12660, %12554"
"  %12740 = mul nuw i32 %12660, %12554" -> "  %12852 = add nuw i32 %12740, %12851""  %12740 = mul nuw i32 %12660, %12554" -> "  %12741 = add nuw i32 %12738, %12740"
"  %12741 = add nuw i32 %12738, %12740"
"  %12741 = add nuw i32 %12738, %12740" -> "  %12744 = and i32 %12741, -65536""  %12741 = add nuw i32 %12738, %12740" -> "  %12742 = and i32 %12741, 65535"
"  %12742 = and i32 %12741, 65535"
"  %12742 = and i32 %12741, 65535" -> "  %12743 = add nuw nsw i32 %12739, %12742"
"  %12743 = add nuw nsw i32 %12739, %12742"
"  %12743 = add nuw nsw i32 %12739, %12742" -> "  %12745 = add i32 %12743, %12744"
"  %12744 = and i32 %12741, -65536"
"  %12744 = and i32 %12741, -65536" -> "  %12745 = add i32 %12743, %12744"
"  %12745 = add i32 %12743, %12744"
"  %12745 = add i32 %12743, %12744" -> "  %12750 = add i32 %12745, %12749"
"  %12746 = and i32 %12717, 65535"
"  %12746 = and i32 %12717, 65535" -> "  %12748 = add nuw nsw i32 %12746, %12747"
"  %12747 = and i32 %12737, 65535"
"  %12747 = and i32 %12737, 65535" -> "  %12748 = add nuw nsw i32 %12746, %12747"
"  %12748 = add nuw nsw i32 %12746, %12747"
"  %12748 = add nuw nsw i32 %12746, %12747" -> "  %12753 = and i32 %12748, 65535""  %12748 = add nuw nsw i32 %12746, %12747" -> "  %12749 = lshr i32 %12748, 16"
"  %12749 = lshr i32 %12748, 16"
"  %12749 = lshr i32 %12748, 16" -> "  %12750 = add i32 %12745, %12749"
"  %12750 = add i32 %12745, %12749"
"  %12750 = add i32 %12745, %12749" -> "  %12758 = add i32 %12750, %12757"
"  %12751 = and i32 %12725, 65535"
"  %12751 = and i32 %12725, 65535" -> "  %12859 = add nuw nsw i32 %12858, %12751""  %12751 = and i32 %12725, 65535" -> "  %12754 = add nuw nsw i32 %12752, %12751"
"  %12752 = and i32 %12714, 65535"
"  %12752 = and i32 %12714, 65535" -> "  %12754 = add nuw nsw i32 %12752, %12751"
"  %12753 = and i32 %12748, 65535"
"  %12753 = and i32 %12748, 65535" -> "  %12756 = add nuw nsw i32 %12753, %12755"
"  %12754 = add nuw nsw i32 %12752, %12751"
"  %12754 = add nuw nsw i32 %12752, %12751" -> "  %12818 = and i32 %12754, 65535""  %12754 = add nuw nsw i32 %12752, %12751" -> "  %12755 = lshr i32 %12754, 16"
"  %12755 = lshr i32 %12754, 16"
"  %12755 = lshr i32 %12754, 16" -> "  %12756 = add nuw nsw i32 %12753, %12755"
"  %12756 = add nuw nsw i32 %12753, %12755"
"  %12756 = add nuw nsw i32 %12753, %12755" -> "  %12821 = and i32 %12756, 65535""  %12756 = add nuw nsw i32 %12753, %12755" -> "  %12757 = lshr i32 %12756, 16"
"  %12757 = lshr i32 %12756, 16"
"  %12757 = lshr i32 %12756, 16" -> "  %12758 = add i32 %12750, %12757"
"  %12758 = add i32 %12750, %12757"
"  %12758 = add i32 %12750, %12757" -> "  %12794 = lshr i32 %12758, 16""  %12758 = add i32 %12750, %12757" -> "  %12791 = and i32 %12758, 65535"
"  %12759 = mul nuw i32 %12683, %12553"
"  %12759 = mul nuw i32 %12683, %12553" -> "  %12782 = and i32 %12759, 65535""  %12759 = mul nuw i32 %12683, %12553" -> "  %12760 = lshr i32 %12759, 16"
"  %12760 = lshr i32 %12759, 16"
"  %12760 = lshr i32 %12759, 16" -> "  %12766 = add nuw i32 %12760, %12761""  %12760 = lshr i32 %12759, 16" -> "  %12763 = add nuw i32 %12760, %12762"
"  %12761 = mul nuw i32 %12686, %12553"
"  %12761 = mul nuw i32 %12686, %12553" -> "  %12766 = add nuw i32 %12760, %12761""  %12761 = mul nuw i32 %12686, %12553" -> "  %12765 = add nuw i32 %12764, %12761"
"  %12762 = mul nuw i32 %12683, %12554"
"  %12762 = mul nuw i32 %12683, %12554" -> "  %12768 = add nuw i32 %12767, %12762""  %12762 = mul nuw i32 %12683, %12554" -> "  %12763 = add nuw i32 %12760, %12762"
"  %12763 = add nuw i32 %12760, %12762"
"  %12763 = add nuw i32 %12760, %12762" -> "  %12889 = lshr i32 %12763, 16""  %12763 = add nuw i32 %12760, %12762" -> "  %12764 = and i32 %12763, 65535"
"  %12764 = and i32 %12763, 65535"
"  %12764 = and i32 %12763, 65535" -> "  %12765 = add nuw i32 %12764, %12761"
"  %12765 = add nuw i32 %12764, %12761"
"  %12765 = add nuw i32 %12764, %12761" -> "  %12899 = and i32 %12765, 65535""  %12765 = add nuw i32 %12764, %12761" -> "  %12891 = lshr i32 %12765, 16"
"  %12766 = add nuw i32 %12760, %12761"
"  %12766 = add nuw i32 %12760, %12761" -> "  %12769 = lshr i32 %12766, 16""  %12766 = add nuw i32 %12760, %12761" -> "  %12767 = and i32 %12766, 65535"
"  %12767 = and i32 %12766, 65535"
"  %12767 = and i32 %12766, 65535" -> "  %12768 = add nuw i32 %12767, %12762"
"  %12768 = add nuw i32 %12767, %12762"
"  %12768 = add nuw i32 %12767, %12762" -> "  %12777 = and i32 %12768, 65535""  %12768 = add nuw i32 %12767, %12762" -> "  %12770 = lshr i32 %12768, 16"
"  %12769 = lshr i32 %12766, 16"
"  %12769 = lshr i32 %12766, 16" -> "  %12772 = add nuw i32 %12769, %12771"
"  %12770 = lshr i32 %12768, 16"
"  %12770 = lshr i32 %12768, 16" -> "  %12774 = add nuw nsw i32 %12770, %12773"
"  %12771 = mul nuw i32 %12686, %12554"
"  %12771 = mul nuw i32 %12686, %12554" -> "  %12890 = add nuw i32 %12889, %12771""  %12771 = mul nuw i32 %12686, %12554" -> "  %12772 = add nuw i32 %12769, %12771"
"  %12772 = add nuw i32 %12769, %12771"
"  %12772 = add nuw i32 %12769, %12771" -> "  %12775 = and i32 %12772, -65536""  %12772 = add nuw i32 %12769, %12771" -> "  %12773 = and i32 %12772, 65535"
"  %12773 = and i32 %12772, 65535"
"  %12773 = and i32 %12772, 65535" -> "  %12774 = add nuw nsw i32 %12770, %12773"
"  %12774 = add nuw nsw i32 %12770, %12773"
"  %12774 = add nuw nsw i32 %12770, %12773" -> "  %12776 = add i32 %12774, %12775"
"  %12775 = and i32 %12772, -65536"
"  %12775 = and i32 %12772, -65536" -> "  %12776 = add i32 %12774, %12775"
"  %12776 = add i32 %12774, %12775"
"  %12776 = add i32 %12774, %12775" -> "  %12781 = add i32 %12776, %12780"
"  %12777 = and i32 %12768, 65535"
"  %12777 = and i32 %12768, 65535" -> "  %12779 = add nuw nsw i32 %12778, %12777"
"  %12778 = lshr i32 %12724, 16"
"  %12778 = lshr i32 %12724, 16" -> "  %12779 = add nuw nsw i32 %12778, %12777"
"  %12779 = add nuw nsw i32 %12778, %12777"
"  %12779 = add nuw nsw i32 %12778, %12777" -> "  %12784 = and i32 %12779, 65535""  %12779 = add nuw nsw i32 %12778, %12777" -> "  %12780 = lshr i32 %12779, 16"
"  %12780 = lshr i32 %12779, 16"
"  %12780 = lshr i32 %12779, 16" -> "  %12781 = add i32 %12776, %12780"
"  %12781 = add i32 %12776, %12780"
"  %12781 = add i32 %12776, %12780" -> "  %12789 = add i32 %12781, %12788"
"  %12782 = and i32 %12759, 65535"
"  %12782 = and i32 %12759, 65535" -> "  %12897 = add nuw nsw i32 %12896, %12782""  %12782 = and i32 %12759, 65535" -> "  %12785 = add nuw nsw i32 %12783, %12782"
"  %12783 = and i32 %12724, 65535"
"  %12783 = and i32 %12724, 65535" -> "  %12785 = add nuw nsw i32 %12783, %12782"
"  %12784 = and i32 %12779, 65535"
"  %12784 = and i32 %12779, 65535" -> "  %12787 = add nuw nsw i32 %12784, %12786"
"  %12785 = add nuw nsw i32 %12783, %12782"
"  %12785 = add nuw nsw i32 %12783, %12782" -> "  %12790 = and i32 %12785, 65535""  %12785 = add nuw nsw i32 %12783, %12782" -> "  %12786 = lshr i32 %12785, 16"
"  %12786 = lshr i32 %12785, 16"
"  %12786 = lshr i32 %12785, 16" -> "  %12787 = add nuw nsw i32 %12784, %12786"
"  %12787 = add nuw nsw i32 %12784, %12786"
"  %12787 = add nuw nsw i32 %12784, %12786" -> "  %12793 = and i32 %12787, 65535""  %12787 = add nuw nsw i32 %12784, %12786" -> "  %12788 = lshr i32 %12787, 16"
"  %12788 = lshr i32 %12787, 16"
"  %12788 = lshr i32 %12787, 16" -> "  %12789 = add i32 %12781, %12788"
"  %12789 = add i32 %12781, %12788"
"  %12789 = add i32 %12781, %12788" -> "  %12802 = and i32 %12789, -65536""  %12789 = add i32 %12781, %12788" -> "  %12800 = and i32 %12789, 65535"
"  %12790 = and i32 %12785, 65535"
"  %12790 = and i32 %12785, 65535" -> "  %12792 = add nuw nsw i32 %12791, %12790"
"  %12791 = and i32 %12758, 65535"
"  %12791 = and i32 %12758, 65535" -> "  %12792 = add nuw nsw i32 %12791, %12790"
"  %12792 = add nuw nsw i32 %12791, %12790"
"  %12792 = add nuw nsw i32 %12791, %12790" -> "  %12832 = and i32 %12792, 65535""  %12792 = add nuw nsw i32 %12791, %12790" -> "  %12796 = lshr i32 %12792, 16"
"  %12793 = and i32 %12787, 65535"
"  %12793 = and i32 %12787, 65535" -> "  %12795 = add nuw nsw i32 %12793, %12794"
"  %12794 = lshr i32 %12758, 16"
"  %12794 = lshr i32 %12758, 16" -> "  %12795 = add nuw nsw i32 %12793, %12794"
"  %12795 = add nuw nsw i32 %12793, %12794"
"  %12795 = add nuw nsw i32 %12793, %12794" -> "  %12799 = lshr i32 %12795, 16""  %12795 = add nuw nsw i32 %12793, %12794" -> "  %12797 = and i32 %12795, 65535"
"  %12796 = lshr i32 %12792, 16"
"  %12796 = lshr i32 %12792, 16" -> "  %12798 = add nuw nsw i32 %12797, %12796"
"  %12797 = and i32 %12795, 65535"
"  %12797 = and i32 %12795, 65535" -> "  %12798 = add nuw nsw i32 %12797, %12796"
"  %12798 = add nuw nsw i32 %12797, %12796"
"  %12798 = add nuw nsw i32 %12797, %12796" -> "  %12840 = and i32 %12798, 65535""  %12798 = add nuw nsw i32 %12797, %12796" -> "  %12804 = lshr i32 %12798, 16"
"  %12799 = lshr i32 %12795, 16"
"  %12799 = lshr i32 %12795, 16" -> "  %12801 = add nuw nsw i32 %12799, %12800"
"  %12800 = and i32 %12789, 65535"
"  %12800 = and i32 %12789, 65535" -> "  %12801 = add nuw nsw i32 %12799, %12800"
"  %12801 = add nuw nsw i32 %12799, %12800"
"  %12801 = add nuw nsw i32 %12799, %12800" -> "  %12803 = add i32 %12801, %12802"
"  %12802 = and i32 %12789, -65536"
"  %12802 = and i32 %12789, -65536" -> "  %12803 = add i32 %12801, %12802"
"  %12803 = add i32 %12801, %12802"
"  %12803 = add i32 %12801, %12802" -> "  %12805 = add i32 %12803, %12804"
"  %12804 = lshr i32 %12798, 16"
"  %12804 = lshr i32 %12798, 16" -> "  %12805 = add i32 %12803, %12804"
"  %12805 = add i32 %12803, %12804"
"  %12805 = add i32 %12803, %12804" -> "  %12843 = add i32 %12805, %12842"
"  %12806 = and i32 %12674, 65535"
"  %12806 = and i32 %12674, 65535" -> "  %12808 = add nuw nsw i32 %12807, %12806"
"  %12807 = and i32 %12649, 65535"
"  %12807 = and i32 %12649, 65535" -> "  %12808 = add nuw nsw i32 %12807, %12806"
"  %12808 = add nuw nsw i32 %12807, %12806"
"  %12808 = add nuw nsw i32 %12807, %12806" -> "  %12815 = lshr i32 %12808, 16""  %12808 = add nuw nsw i32 %12807, %12806" -> "  %12813 = and i32 %12808, 65535"
"  %12809 = and i32 %12658, 65535"
"  %12809 = and i32 %12658, 65535" -> "  %12922 = add nuw nsw i32 %12921, %12809""  %12809 = and i32 %12658, 65535" -> "  %12811 = add nuw nsw i32 %12810, %12809"
"  %12810 = and i32 %12643, 65535"
"  %12810 = and i32 %12643, 65535" -> "  %12811 = add nuw nsw i32 %12810, %12809"
"  %12811 = add nuw nsw i32 %12810, %12809"
"  %12811 = add nuw nsw i32 %12810, %12809" -> "  %12921 = and i32 %12811, 65535""  %12811 = add nuw nsw i32 %12810, %12809" -> "  %12812 = lshr i32 %12811, 16"
"  %12812 = lshr i32 %12811, 16"
"  %12812 = lshr i32 %12811, 16" -> "  %12814 = add nuw nsw i32 %12813, %12812"
"  %12813 = and i32 %12808, 65535"
"  %12813 = and i32 %12808, 65535" -> "  %12814 = add nuw nsw i32 %12813, %12812"
"  %12814 = add nuw nsw i32 %12813, %12812"
"  %12814 = add nuw nsw i32 %12813, %12812" -> "  %12924 = and i32 %12814, 65535""  %12814 = add nuw nsw i32 %12813, %12812" -> "  %12816 = lshr i32 %12814, 16"
"  %12815 = lshr i32 %12808, 16"
"  %12815 = lshr i32 %12808, 16" -> "  %12817 = add nuw nsw i32 %12816, %12815"
"  %12816 = lshr i32 %12814, 16"
"  %12816 = lshr i32 %12814, 16" -> "  %12817 = add nuw nsw i32 %12816, %12815"
"  %12817 = add nuw nsw i32 %12816, %12815"
"  %12817 = add nuw nsw i32 %12816, %12815" -> "  %12828 = add nuw nsw i32 %12817, %12827"
"  %12818 = and i32 %12754, 65535"
"  %12818 = and i32 %12754, 65535" -> "  %12820 = add nuw nsw i32 %12818, %12819"
"  %12819 = and i32 %12656, 65535"
"  %12819 = and i32 %12656, 65535" -> "  %12820 = add nuw nsw i32 %12818, %12819"
"  %12820 = add nuw nsw i32 %12818, %12819"
"  %12820 = add nuw nsw i32 %12818, %12819" -> "  %12827 = and i32 %12820, 65535""  %12820 = add nuw nsw i32 %12818, %12819" -> "  %12824 = lshr i32 %12820, 16"
"  %12821 = and i32 %12756, 65535"
"  %12821 = and i32 %12756, 65535" -> "  %12823 = add nuw nsw i32 %12821, %12822"
"  %12822 = lshr i32 %12656, 16"
"  %12822 = lshr i32 %12656, 16" -> "  %12823 = add nuw nsw i32 %12821, %12822"
"  %12823 = add nuw nsw i32 %12821, %12822"
"  %12823 = add nuw nsw i32 %12821, %12822" -> "  %12833 = lshr i32 %12823, 16""  %12823 = add nuw nsw i32 %12821, %12822" -> "  %12825 = and i32 %12823, 65535"
"  %12824 = lshr i32 %12820, 16"
"  %12824 = lshr i32 %12820, 16" -> "  %12826 = add nuw nsw i32 %12825, %12824"
"  %12825 = and i32 %12823, 65535"
"  %12825 = and i32 %12823, 65535" -> "  %12826 = add nuw nsw i32 %12825, %12824"
"  %12826 = add nuw nsw i32 %12825, %12824"
"  %12826 = add nuw nsw i32 %12825, %12824" -> "  %12835 = lshr i32 %12826, 16""  %12826 = add nuw nsw i32 %12825, %12824" -> "  %12830 = and i32 %12826, 65535"
"  %12827 = and i32 %12820, 65535"
"  %12827 = and i32 %12820, 65535" -> "  %12828 = add nuw nsw i32 %12817, %12827"
"  %12828 = add nuw nsw i32 %12817, %12827"
"  %12828 = add nuw nsw i32 %12817, %12827" -> "  %12932 = and i32 %12828, 65535""  %12828 = add nuw nsw i32 %12817, %12827" -> "  %12829 = lshr i32 %12828, 16"
"  %12829 = lshr i32 %12828, 16"
"  %12829 = lshr i32 %12828, 16" -> "  %12831 = add nuw nsw i32 %12830, %12829"
"  %12830 = and i32 %12826, 65535"
"  %12830 = and i32 %12826, 65535" -> "  %12831 = add nuw nsw i32 %12830, %12829"
"  %12831 = add nuw nsw i32 %12830, %12829"
"  %12831 = add nuw nsw i32 %12830, %12829" -> "  %12935 = and i32 %12831, 65535""  %12831 = add nuw nsw i32 %12830, %12829" -> "  %12837 = lshr i32 %12831, 16"
"  %12832 = and i32 %12792, 65535"
"  %12832 = and i32 %12792, 65535" -> "  %12834 = add nuw nsw i32 %12832, %12833"
"  %12833 = lshr i32 %12823, 16"
"  %12833 = lshr i32 %12823, 16" -> "  %12834 = add nuw nsw i32 %12832, %12833"
"  %12834 = add nuw nsw i32 %12832, %12833"
"  %12834 = add nuw nsw i32 %12832, %12833" -> "  %12836 = add nuw nsw i32 %12834, %12835"
"  %12835 = lshr i32 %12826, 16"
"  %12835 = lshr i32 %12826, 16" -> "  %12836 = add nuw nsw i32 %12834, %12835"
"  %12836 = add nuw nsw i32 %12834, %12835"
"  %12836 = add nuw nsw i32 %12834, %12835" -> "  %12838 = add nuw nsw i32 %12836, %12837"
"  %12837 = lshr i32 %12831, 16"
"  %12837 = lshr i32 %12831, 16" -> "  %12838 = add nuw nsw i32 %12836, %12837"
"  %12838 = add nuw nsw i32 %12836, %12837"
"  %12838 = add nuw nsw i32 %12836, %12837" -> "  %13078 = and i32 %12838, 65535""  %12838 = add nuw nsw i32 %12836, %12837" -> "  %12839 = lshr i32 %12838, 16"
"  %12839 = lshr i32 %12838, 16"
"  %12839 = lshr i32 %12838, 16" -> "  %12841 = add nuw nsw i32 %12839, %12840"
"  %12840 = and i32 %12798, 65535"
"  %12840 = and i32 %12798, 65535" -> "  %12841 = add nuw nsw i32 %12839, %12840"
"  %12841 = add nuw nsw i32 %12839, %12840"
"  %12841 = add nuw nsw i32 %12839, %12840" -> "  %13081 = and i32 %12841, 65535""  %12841 = add nuw nsw i32 %12839, %12840" -> "  %12842 = lshr i32 %12841, 16"
"  %12842 = lshr i32 %12841, 16"
"  %12842 = lshr i32 %12841, 16" -> "  %12843 = add i32 %12805, %12842"
"  %12843 = add i32 %12805, %12842"
"  %12843 = add i32 %12805, %12842" -> "  %13087 = and i32 %12843, 65535""  %12843 = add i32 %12805, %12842" -> "  %13090 = lshr i32 %12843, 16"
"  %12844 = lshr i32 %12668, 16"
"  %12844 = lshr i32 %12668, 16" -> "  %12845 = add nuw i32 %12677, %12844"
"  %12845 = add nuw i32 %12677, %12844"
"  %12845 = add nuw i32 %12677, %12844" -> "  %12849 = and i32 %12845, -65536""  %12845 = add nuw i32 %12677, %12844" -> "  %12847 = and i32 %12845, 65535"
"  %12846 = lshr i32 %12670, 16"
"  %12846 = lshr i32 %12670, 16" -> "  %12848 = add nuw nsw i32 %12846, %12847"
"  %12847 = and i32 %12845, 65535"
"  %12847 = and i32 %12845, 65535" -> "  %12848 = add nuw nsw i32 %12846, %12847"
"  %12848 = add nuw nsw i32 %12846, %12847"
"  %12848 = add nuw nsw i32 %12846, %12847" -> "  %12850 = add i32 %12848, %12849"
"  %12849 = and i32 %12845, -65536"
"  %12849 = and i32 %12845, -65536" -> "  %12850 = add i32 %12848, %12849"
"  %12850 = add i32 %12848, %12849"
"  %12850 = add i32 %12848, %12849" -> "  %12861 = lshr i32 %12850, 16""  %12850 = add i32 %12848, %12849" -> "  %12858 = and i32 %12850, 65535"
"  %12851 = lshr i32 %12731, 16"
"  %12851 = lshr i32 %12731, 16" -> "  %12852 = add nuw i32 %12740, %12851"
"  %12852 = add nuw i32 %12740, %12851"
"  %12852 = add nuw i32 %12740, %12851" -> "  %12856 = and i32 %12852, -65536""  %12852 = add nuw i32 %12740, %12851" -> "  %12854 = and i32 %12852, 65535"
"  %12853 = lshr i32 %12733, 16"
"  %12853 = lshr i32 %12733, 16" -> "  %12855 = add nuw nsw i32 %12853, %12854"
"  %12854 = and i32 %12852, 65535"
"  %12854 = and i32 %12852, 65535" -> "  %12855 = add nuw nsw i32 %12853, %12854"
"  %12855 = add nuw nsw i32 %12853, %12854"
"  %12855 = add nuw nsw i32 %12853, %12854" -> "  %12857 = add i32 %12855, %12856"
"  %12856 = and i32 %12852, -65536"
"  %12856 = and i32 %12852, -65536" -> "  %12857 = add i32 %12855, %12856"
"  %12857 = add i32 %12855, %12856"
"  %12857 = add i32 %12855, %12856" -> "  %12864 = add i32 %12857, %12863"
"  %12858 = and i32 %12850, 65535"
"  %12858 = and i32 %12850, 65535" -> "  %12859 = add nuw nsw i32 %12858, %12751"
"  %12859 = add nuw nsw i32 %12858, %12751"
"  %12859 = add nuw nsw i32 %12858, %12751" -> "  %12877 = and i32 %12859, 65535""  %12859 = add nuw nsw i32 %12858, %12751" -> "  %12866 = lshr i32 %12859, 16"
"  %12860 = and i32 %12733, 65535"
"  %12860 = and i32 %12733, 65535" -> "  %12862 = add nuw nsw i32 %12861, %12860"
"  %12861 = lshr i32 %12850, 16"
"  %12861 = lshr i32 %12850, 16" -> "  %12862 = add nuw nsw i32 %12861, %12860"
"  %12862 = add nuw nsw i32 %12861, %12860"
"  %12862 = add nuw nsw i32 %12861, %12860" -> "  %12865 = and i32 %12862, 65535""  %12862 = add nuw nsw i32 %12861, %12860" -> "  %12863 = lshr i32 %12862, 16"
"  %12863 = lshr i32 %12862, 16"
"  %12863 = lshr i32 %12862, 16" -> "  %12864 = add i32 %12857, %12863"
"  %12864 = add i32 %12857, %12863"
"  %12864 = add i32 %12857, %12863" -> "  %12869 = add i32 %12864, %12868"
"  %12865 = and i32 %12862, 65535"
"  %12865 = and i32 %12862, 65535" -> "  %12867 = add nuw nsw i32 %12866, %12865"
"  %12866 = lshr i32 %12859, 16"
"  %12866 = lshr i32 %12859, 16" -> "  %12867 = add nuw nsw i32 %12866, %12865"
"  %12867 = add nuw nsw i32 %12866, %12865"
"  %12867 = add nuw nsw i32 %12866, %12865" -> "  %12879 = and i32 %12867, 65535""  %12867 = add nuw nsw i32 %12866, %12865" -> "  %12868 = lshr i32 %12867, 16"
"  %12868 = lshr i32 %12867, 16"
"  %12868 = lshr i32 %12867, 16" -> "  %12869 = add i32 %12864, %12868"
"  %12869 = add i32 %12864, %12868"
"  %12869 = add i32 %12864, %12868" -> "  %12898 = lshr i32 %12869, 16""  %12869 = add i32 %12864, %12868" -> "  %12896 = and i32 %12869, 65535"
"  %12870 = lshr i32 %12694, 16"
"  %12870 = lshr i32 %12694, 16" -> "  %12871 = add nuw i32 %12870, %12703"
"  %12871 = add nuw i32 %12870, %12703"
"  %12871 = add nuw i32 %12870, %12703" -> "  %12875 = and i32 %12871, -65536""  %12871 = add nuw i32 %12870, %12703" -> "  %12873 = and i32 %12871, 65535"
"  %12872 = lshr i32 %12696, 16"
"  %12872 = lshr i32 %12696, 16" -> "  %12874 = add nuw nsw i32 %12872, %12873"
"  %12873 = and i32 %12871, 65535"
"  %12873 = and i32 %12871, 65535" -> "  %12874 = add nuw nsw i32 %12872, %12873"
"  %12874 = add nuw nsw i32 %12872, %12873"
"  %12874 = add nuw nsw i32 %12872, %12873" -> "  %12876 = add i32 %12874, %12875"
"  %12875 = and i32 %12871, -65536"
"  %12875 = and i32 %12871, -65536" -> "  %12876 = add i32 %12874, %12875"
"  %12876 = add i32 %12874, %12875"
"  %12876 = add i32 %12874, %12875" -> "  %12883 = add i32 %12876, %12882"
"  %12877 = and i32 %12859, 65535"
"  %12877 = and i32 %12859, 65535" -> "  %12878 = add nuw nsw i32 %12712, %12877"
"  %12878 = add nuw nsw i32 %12712, %12877"
"  %12878 = add nuw nsw i32 %12712, %12877" -> "  %12931 = and i32 %12878, 65535""  %12878 = add nuw nsw i32 %12712, %12877" -> "  %12885 = lshr i32 %12878, 16"
"  %12879 = and i32 %12867, 65535"
"  %12879 = and i32 %12867, 65535" -> "  %12881 = add nuw nsw i32 %12880, %12879"
"  %12880 = and i32 %12696, 65535"
"  %12880 = and i32 %12696, 65535" -> "  %12881 = add nuw nsw i32 %12880, %12879"
"  %12881 = add nuw nsw i32 %12880, %12879"
"  %12881 = add nuw nsw i32 %12880, %12879" -> "  %12884 = and i32 %12881, 65535""  %12881 = add nuw nsw i32 %12880, %12879" -> "  %12882 = lshr i32 %12881, 16"
"  %12882 = lshr i32 %12881, 16"
"  %12882 = lshr i32 %12881, 16" -> "  %12883 = add i32 %12876, %12882"
"  %12883 = add i32 %12876, %12882"
"  %12883 = add i32 %12876, %12882" -> "  %12888 = add i32 %12883, %12887"
"  %12884 = and i32 %12881, 65535"
"  %12884 = and i32 %12881, 65535" -> "  %12886 = add nuw nsw i32 %12884, %12885"
"  %12885 = lshr i32 %12878, 16"
"  %12885 = lshr i32 %12878, 16" -> "  %12886 = add nuw nsw i32 %12884, %12885"
"  %12886 = add nuw nsw i32 %12884, %12885"
"  %12886 = add nuw nsw i32 %12884, %12885" -> "  %12934 = and i32 %12886, 65535""  %12886 = add nuw nsw i32 %12884, %12885" -> "  %12887 = lshr i32 %12886, 16"
"  %12887 = lshr i32 %12886, 16"
"  %12887 = lshr i32 %12886, 16" -> "  %12888 = add i32 %12883, %12887"
"  %12888 = add i32 %12883, %12887"
"  %12888 = add i32 %12883, %12887" -> "  %12912 = lshr i32 %12888, 16""  %12888 = add i32 %12883, %12887" -> "  %12909 = and i32 %12888, 65535"
"  %12889 = lshr i32 %12763, 16"
"  %12889 = lshr i32 %12763, 16" -> "  %12890 = add nuw i32 %12889, %12771"
"  %12890 = add nuw i32 %12889, %12771"
"  %12890 = add nuw i32 %12889, %12771" -> "  %12894 = and i32 %12890, -65536""  %12890 = add nuw i32 %12889, %12771" -> "  %12892 = and i32 %12890, 65535"
"  %12891 = lshr i32 %12765, 16"
"  %12891 = lshr i32 %12765, 16" -> "  %12893 = add nuw nsw i32 %12892, %12891"
"  %12892 = and i32 %12890, 65535"
"  %12892 = and i32 %12890, 65535" -> "  %12893 = add nuw nsw i32 %12892, %12891"
"  %12893 = add nuw nsw i32 %12892, %12891"
"  %12893 = add nuw nsw i32 %12892, %12891" -> "  %12895 = add i32 %12893, %12894"
"  %12894 = and i32 %12890, -65536"
"  %12894 = and i32 %12890, -65536" -> "  %12895 = add i32 %12893, %12894"
"  %12895 = add i32 %12893, %12894"
"  %12895 = add i32 %12893, %12894" -> "  %12902 = add i32 %12895, %12901"
"  %12896 = and i32 %12869, 65535"
"  %12896 = and i32 %12869, 65535" -> "  %12897 = add nuw nsw i32 %12896, %12782"
"  %12897 = add nuw nsw i32 %12896, %12782"
"  %12897 = add nuw nsw i32 %12896, %12782" -> "  %12908 = and i32 %12897, 65535""  %12897 = add nuw nsw i32 %12896, %12782" -> "  %12904 = lshr i32 %12897, 16"
"  %12898 = lshr i32 %12869, 16"
"  %12898 = lshr i32 %12869, 16" -> "  %12900 = add nuw nsw i32 %12898, %12899"
"  %12899 = and i32 %12765, 65535"
"  %12899 = and i32 %12765, 65535" -> "  %12900 = add nuw nsw i32 %12898, %12899"
"  %12900 = add nuw nsw i32 %12898, %12899"
"  %12900 = add nuw nsw i32 %12898, %12899" -> "  %12903 = and i32 %12900, 65535""  %12900 = add nuw nsw i32 %12898, %12899" -> "  %12901 = lshr i32 %12900, 16"
"  %12901 = lshr i32 %12900, 16"
"  %12901 = lshr i32 %12900, 16" -> "  %12902 = add i32 %12895, %12901"
"  %12902 = add i32 %12895, %12901"
"  %12902 = add i32 %12895, %12901" -> "  %12907 = add i32 %12902, %12906"
"  %12903 = and i32 %12900, 65535"
"  %12903 = and i32 %12900, 65535" -> "  %12905 = add nuw nsw i32 %12903, %12904"
"  %12904 = lshr i32 %12897, 16"
"  %12904 = lshr i32 %12897, 16" -> "  %12905 = add nuw nsw i32 %12903, %12904"
"  %12905 = add nuw nsw i32 %12903, %12904"
"  %12905 = add nuw nsw i32 %12903, %12904" -> "  %12911 = and i32 %12905, 65535""  %12905 = add nuw nsw i32 %12903, %12904" -> "  %12906 = lshr i32 %12905, 16"
"  %12906 = lshr i32 %12905, 16"
"  %12906 = lshr i32 %12905, 16" -> "  %12907 = add i32 %12902, %12906"
"  %12907 = add i32 %12902, %12906"
"  %12907 = add i32 %12902, %12906" -> "  %12915 = add i32 %12907, %12914"
"  %12908 = and i32 %12897, 65535"
"  %12908 = and i32 %12897, 65535" -> "  %12910 = add nuw nsw i32 %12909, %12908"
"  %12909 = and i32 %12888, 65535"
"  %12909 = and i32 %12888, 65535" -> "  %12910 = add nuw nsw i32 %12909, %12908"
"  %12910 = add nuw nsw i32 %12909, %12908"
"  %12910 = add nuw nsw i32 %12909, %12908" -> "  %12946 = and i32 %12910, 65535""  %12910 = add nuw nsw i32 %12909, %12908" -> "  %12917 = lshr i32 %12910, 16"
"  %12911 = and i32 %12905, 65535"
"  %12911 = and i32 %12905, 65535" -> "  %12913 = add nuw nsw i32 %12912, %12911"
"  %12912 = lshr i32 %12888, 16"
"  %12912 = lshr i32 %12888, 16" -> "  %12913 = add nuw nsw i32 %12912, %12911"
"  %12913 = add nuw nsw i32 %12912, %12911"
"  %12913 = add nuw nsw i32 %12912, %12911" -> "  %12916 = and i32 %12913, 65535""  %12913 = add nuw nsw i32 %12912, %12911" -> "  %12914 = lshr i32 %12913, 16"
"  %12914 = lshr i32 %12913, 16"
"  %12914 = lshr i32 %12913, 16" -> "  %12915 = add i32 %12907, %12914"
"  %12915 = add i32 %12907, %12914"
"  %12915 = add i32 %12907, %12914" -> "  %12920 = add i32 %12915, %12919"
"  %12916 = and i32 %12913, 65535"
"  %12916 = and i32 %12913, 65535" -> "  %12918 = add nuw nsw i32 %12916, %12917"
"  %12917 = lshr i32 %12910, 16"
"  %12917 = lshr i32 %12910, 16" -> "  %12918 = add nuw nsw i32 %12916, %12917"
"  %12918 = add nuw nsw i32 %12916, %12917"
"  %12918 = add nuw nsw i32 %12916, %12917" -> "  %12953 = and i32 %12918, 65535""  %12918 = add nuw nsw i32 %12916, %12917" -> "  %12919 = lshr i32 %12918, 16"
"  %12919 = lshr i32 %12918, 16"
"  %12919 = lshr i32 %12918, 16" -> "  %12920 = add i32 %12915, %12919"
"  %12920 = add i32 %12915, %12919"
"  %12920 = add i32 %12915, %12919" -> "  %12957 = add i32 %12920, %12956"
"  %12921 = and i32 %12811, 65535"
"  %12921 = and i32 %12811, 65535" -> "  %12922 = add nuw nsw i32 %12921, %12809"
"  %12922 = add nuw nsw i32 %12921, %12809"
"  %12922 = add nuw nsw i32 %12921, %12809" -> "  %13287 = and i32 %12922, 65535""  %12922 = add nuw nsw i32 %12921, %12809" -> "  %12926 = lshr i32 %12922, 16"
"  %12923 = and i32 %12670, 65535"
"  %12923 = and i32 %12670, 65535" -> "  %12925 = add nuw nsw i32 %12924, %12923"
"  %12924 = and i32 %12814, 65535"
"  %12924 = and i32 %12814, 65535" -> "  %12925 = add nuw nsw i32 %12924, %12923"
"  %12925 = add nuw nsw i32 %12924, %12923"
"  %12925 = add nuw nsw i32 %12924, %12923" -> "  %12929 = lshr i32 %12925, 16""  %12925 = add nuw nsw i32 %12924, %12923" -> "  %12927 = and i32 %12925, 65535"
"  %12926 = lshr i32 %12922, 16"
"  %12926 = lshr i32 %12922, 16" -> "  %12928 = add nuw nsw i32 %12927, %12926"
"  %12927 = and i32 %12925, 65535"
"  %12927 = and i32 %12925, 65535" -> "  %12928 = add nuw nsw i32 %12927, %12926"
"  %12928 = add nuw nsw i32 %12927, %12926"
"  %12928 = add nuw nsw i32 %12927, %12926" -> "  %13290 = and i32 %12928, 65535""  %12928 = add nuw nsw i32 %12927, %12926" -> "  %12930 = lshr i32 %12928, 16"
"  %12929 = lshr i32 %12925, 16"
"  %12929 = lshr i32 %12925, 16" -> "  %12941 = add nuw nsw i32 %12930, %12929"
"  %12930 = lshr i32 %12928, 16"
"  %12930 = lshr i32 %12928, 16" -> "  %12941 = add nuw nsw i32 %12930, %12929"
"  %12931 = and i32 %12878, 65535"
"  %12931 = and i32 %12878, 65535" -> "  %12933 = add nuw nsw i32 %12932, %12931"
"  %12932 = and i32 %12828, 65535"
"  %12932 = and i32 %12828, 65535" -> "  %12933 = add nuw nsw i32 %12932, %12931"
"  %12933 = add nuw nsw i32 %12932, %12931"
"  %12933 = add nuw nsw i32 %12932, %12931" -> "  %12940 = and i32 %12933, 65535""  %12933 = add nuw nsw i32 %12932, %12931" -> "  %12937 = lshr i32 %12933, 16"
"  %12934 = and i32 %12886, 65535"
"  %12934 = and i32 %12886, 65535" -> "  %12936 = add nuw nsw i32 %12935, %12934"
"  %12935 = and i32 %12831, 65535"
"  %12935 = and i32 %12831, 65535" -> "  %12936 = add nuw nsw i32 %12935, %12934"
"  %12936 = add nuw nsw i32 %12935, %12934"
"  %12936 = add nuw nsw i32 %12935, %12934" -> "  %12947 = lshr i32 %12936, 16""  %12936 = add nuw nsw i32 %12935, %12934" -> "  %12938 = and i32 %12936, 65535"
"  %12937 = lshr i32 %12933, 16"
"  %12937 = lshr i32 %12933, 16" -> "  %12939 = add nuw nsw i32 %12938, %12937"
"  %12938 = and i32 %12936, 65535"
"  %12938 = and i32 %12936, 65535" -> "  %12939 = add nuw nsw i32 %12938, %12937"
"  %12939 = add nuw nsw i32 %12938, %12937"
"  %12939 = add nuw nsw i32 %12938, %12937" -> "  %12949 = lshr i32 %12939, 16""  %12939 = add nuw nsw i32 %12938, %12937" -> "  %12944 = and i32 %12939, 65535"
"  %12940 = and i32 %12933, 65535"
"  %12940 = and i32 %12933, 65535" -> "  %12942 = add nuw nsw i32 %12941, %12940"
"  %12941 = add nuw nsw i32 %12930, %12929"
"  %12941 = add nuw nsw i32 %12930, %12929" -> "  %12942 = add nuw nsw i32 %12941, %12940"
"  %12942 = add nuw nsw i32 %12941, %12940"
"  %12942 = add nuw nsw i32 %12941, %12940" -> "  %13307 = and i32 %12942, 65535""  %12942 = add nuw nsw i32 %12941, %12940" -> "  %12943 = lshr i32 %12942, 16"
"  %12943 = lshr i32 %12942, 16"
"  %12943 = lshr i32 %12942, 16" -> "  %12945 = add nuw nsw i32 %12944, %12943"
"  %12944 = and i32 %12939, 65535"
"  %12944 = and i32 %12939, 65535" -> "  %12945 = add nuw nsw i32 %12944, %12943"
"  %12945 = add nuw nsw i32 %12944, %12943"
"  %12945 = add nuw nsw i32 %12944, %12943" -> "  %16558 = add nuw nsw i32 %16557, %12945""  %12945 = add nuw nsw i32 %12944, %12943" -> "  %13310 = and i32 %12945, 65535""  %12945 = add nuw nsw i32 %12944, %12943" -> "  %12951 = lshr i32 %12945, 16"
"  %12946 = and i32 %12910, 65535"
"  %12946 = and i32 %12910, 65535" -> "  %12948 = add nuw nsw i32 %12947, %12946"
"  %12947 = lshr i32 %12936, 16"
"  %12947 = lshr i32 %12936, 16" -> "  %12948 = add nuw nsw i32 %12947, %12946"
"  %12948 = add nuw nsw i32 %12947, %12946"
"  %12948 = add nuw nsw i32 %12947, %12946" -> "  %12950 = add nuw nsw i32 %12948, %12949"
"  %12949 = lshr i32 %12939, 16"
"  %12949 = lshr i32 %12939, 16" -> "  %12950 = add nuw nsw i32 %12948, %12949"
"  %12950 = add nuw nsw i32 %12948, %12949"
"  %12950 = add nuw nsw i32 %12948, %12949" -> "  %12952 = add nuw nsw i32 %12950, %12951"
"  %12951 = lshr i32 %12945, 16"
"  %12951 = lshr i32 %12945, 16" -> "  %12952 = add nuw nsw i32 %12950, %12951"
"  %12952 = add nuw nsw i32 %12950, %12951"
"  %12952 = add nuw nsw i32 %12950, %12951" -> "  %13116 = and i32 %12952, 65535""  %12952 = add nuw nsw i32 %12950, %12951" -> "  %12954 = lshr i32 %12952, 16"
"  %12953 = and i32 %12918, 65535"
"  %12953 = and i32 %12918, 65535" -> "  %12955 = add nuw nsw i32 %12954, %12953"
"  %12954 = lshr i32 %12952, 16"
"  %12954 = lshr i32 %12952, 16" -> "  %12955 = add nuw nsw i32 %12954, %12953"
"  %12955 = add nuw nsw i32 %12954, %12953"
"  %12955 = add nuw nsw i32 %12954, %12953" -> "  %13119 = and i32 %12955, 65535""  %12955 = add nuw nsw i32 %12954, %12953" -> "  %12956 = lshr i32 %12955, 16"
"  %12956 = lshr i32 %12955, 16"
"  %12956 = lshr i32 %12955, 16" -> "  %12957 = add i32 %12920, %12956"
"  %12957 = add i32 %12920, %12956"
"  %12957 = add i32 %12920, %12956" -> "  %13125 = and i32 %12957, 65535""  %12957 = add i32 %12920, %12956" -> "  %13128 = lshr i32 %12957, 16"
"  %12958 = mul nuw i32 %12657, %12657"
"  %12958 = mul nuw i32 %12657, %12657" -> "  %12959 = lshr i32 %12958, 16""  %12958 = mul nuw i32 %12657, %12657" -> "  %13077 = and i32 %12958, 65535"
"  %12959 = lshr i32 %12958, 16"
"  %12959 = lshr i32 %12958, 16" -> "  %12962 = add nuw nsw i32 %12961, %12959"
"  %12960 = mul nuw i32 %12660, %12657"
"  %12960 = mul nuw i32 %12660, %12657" -> "  %12966 = add nuw i32 %12965, %12960""  %12960 = mul nuw i32 %12660, %12657" -> "  %12963 = and i32 %12960, -65536""  %12960 = mul nuw i32 %12660, %12657" -> "  %12961 = and i32 %12960, 65535"
"  %12961 = and i32 %12960, 65535"
"  %12961 = and i32 %12960, 65535" -> "  %12962 = add nuw nsw i32 %12961, %12959"
"  %12962 = add nuw nsw i32 %12961, %12959"
"  %12962 = add nuw nsw i32 %12961, %12959" -> "  %12964 = add nuw i32 %12962, %12963"
"  %12963 = and i32 %12960, -65536"
"  %12963 = and i32 %12960, -65536" -> "  %12964 = add nuw i32 %12962, %12963"
"  %12964 = add nuw i32 %12962, %12963"
"  %12964 = add nuw i32 %12962, %12963" -> "  %12967 = lshr i32 %12964, 16""  %12964 = add nuw i32 %12962, %12963" -> "  %12965 = and i32 %12964, 65535"
"  %12965 = and i32 %12964, 65535"
"  %12965 = and i32 %12964, 65535" -> "  %12966 = add nuw i32 %12965, %12960"
"  %12966 = add nuw i32 %12965, %12960"
"  %12966 = add nuw i32 %12965, %12960" -> "  %13080 = and i32 %12966, 65535""  %12966 = add nuw i32 %12965, %12960" -> "  %12970 = lshr i32 %12966, 16"
"  %12967 = lshr i32 %12964, 16"
"  %12967 = lshr i32 %12964, 16" -> "  %12969 = add nuw i32 %12967, %12968"
"  %12968 = mul nuw i32 %12660, %12660"
"  %12968 = mul nuw i32 %12660, %12660" -> "  %12969 = add nuw i32 %12967, %12968"
"  %12969 = add nuw i32 %12967, %12968"
"  %12969 = add nuw i32 %12967, %12968" -> "  %12973 = and i32 %12969, -65536""  %12969 = add nuw i32 %12967, %12968" -> "  %12971 = and i32 %12969, 65535"
"  %12970 = lshr i32 %12966, 16"
"  %12970 = lshr i32 %12966, 16" -> "  %12972 = add nuw nsw i32 %12970, %12971"
"  %12971 = and i32 %12969, 65535"
"  %12971 = and i32 %12969, 65535" -> "  %12972 = add nuw nsw i32 %12970, %12971"
"  %12972 = add nuw nsw i32 %12970, %12971"
"  %12972 = add nuw nsw i32 %12970, %12971" -> "  %12974 = add i32 %12972, %12973"
"  %12973 = and i32 %12969, -65536"
"  %12973 = and i32 %12969, -65536" -> "  %12974 = add i32 %12972, %12973"
"  %12974 = add i32 %12972, %12973"
"  %12974 = add i32 %12972, %12973" -> "  %13005 = and i32 %12974, 65535""  %12974 = add i32 %12972, %12973" -> "  %13000 = lshr i32 %12974, 16"
"  %12975 = mul nuw i32 %12683, %12657"
"  %12975 = mul nuw i32 %12683, %12657" -> "  %13006 = and i32 %12975, 65535""  %12975 = mul nuw i32 %12683, %12657" -> "  %12976 = lshr i32 %12975, 16"
"  %12976 = lshr i32 %12975, 16"
"  %12976 = lshr i32 %12975, 16" -> "  %12979 = add nuw nsw i32 %12978, %12976""  %12976 = lshr i32 %12975, 16" -> "  %12982 = add nuw nsw i32 %12976, %12981"
"  %12977 = mul nuw i32 %12686, %12657"
"  %12977 = mul nuw i32 %12686, %12657" -> "  %12986 = add nuw i32 %12985, %12977""  %12977 = mul nuw i32 %12686, %12657" -> "  %12987 = and i32 %12977, -65536""  %12977 = mul nuw i32 %12686, %12657" -> "  %12978 = and i32 %12977, 65535"
"  %12978 = and i32 %12977, 65535"
"  %12978 = and i32 %12977, 65535" -> "  %12979 = add nuw nsw i32 %12978, %12976"
"  %12979 = add nuw nsw i32 %12978, %12976"
"  %12979 = add nuw nsw i32 %12978, %12976" -> "  %12988 = add nuw i32 %12979, %12987"
"  %12980 = mul nuw i32 %12683, %12660"
"  %12980 = mul nuw i32 %12683, %12660" -> "  %12990 = add nuw i32 %12989, %12980""  %12980 = mul nuw i32 %12683, %12660" -> "  %12983 = and i32 %12980, -65536""  %12980 = mul nuw i32 %12683, %12660" -> "  %12981 = and i32 %12980, 65535"
"  %12981 = and i32 %12980, 65535"
"  %12981 = and i32 %12980, 65535" -> "  %12982 = add nuw nsw i32 %12976, %12981"
"  %12982 = add nuw nsw i32 %12976, %12981"
"  %12982 = add nuw nsw i32 %12976, %12981" -> "  %12984 = add nuw i32 %12982, %12983"
"  %12983 = and i32 %12980, -65536"
"  %12983 = and i32 %12980, -65536" -> "  %12984 = add nuw i32 %12982, %12983"
"  %12984 = add nuw i32 %12982, %12983"
"  %12984 = add nuw i32 %12982, %12983" -> "  %13012 = lshr i32 %12984, 16""  %12984 = add nuw i32 %12982, %12983" -> "  %12985 = and i32 %12984, 65535"
"  %12985 = and i32 %12984, 65535"
"  %12985 = and i32 %12984, 65535" -> "  %12986 = add nuw i32 %12985, %12977"
"  %12986 = add nuw i32 %12985, %12977"
"  %12986 = add nuw i32 %12985, %12977" -> "  %13022 = and i32 %12986, 65535""  %12986 = add nuw i32 %12985, %12977" -> "  %13014 = lshr i32 %12986, 16"
"  %12987 = and i32 %12977, -65536"
"  %12987 = and i32 %12977, -65536" -> "  %12988 = add nuw i32 %12979, %12987"
"  %12988 = add nuw i32 %12979, %12987"
"  %12988 = add nuw i32 %12979, %12987" -> "  %12991 = lshr i32 %12988, 16""  %12988 = add nuw i32 %12979, %12987" -> "  %12989 = and i32 %12988, 65535"
"  %12989 = and i32 %12988, 65535"
"  %12989 = and i32 %12988, 65535" -> "  %12990 = add nuw i32 %12989, %12980"
"  %12990 = add nuw i32 %12989, %12980"
"  %12990 = add nuw i32 %12989, %12980" -> "  %12999 = and i32 %12990, 65535""  %12990 = add nuw i32 %12989, %12980" -> "  %12992 = lshr i32 %12990, 16"
"  %12991 = lshr i32 %12988, 16"
"  %12991 = lshr i32 %12988, 16" -> "  %12994 = add nuw i32 %12991, %12993"
"  %12992 = lshr i32 %12990, 16"
"  %12992 = lshr i32 %12990, 16" -> "  %12996 = add nuw nsw i32 %12995, %12992"
"  %12993 = mul nuw i32 %12686, %12660"
"  %12993 = mul nuw i32 %12686, %12660" -> "  %13013 = add nuw i32 %13012, %12993""  %12993 = mul nuw i32 %12686, %12660" -> "  %12994 = add nuw i32 %12991, %12993"
"  %12994 = add nuw i32 %12991, %12993"
"  %12994 = add nuw i32 %12991, %12993" -> "  %12997 = and i32 %12994, -65536""  %12994 = add nuw i32 %12991, %12993" -> "  %12995 = and i32 %12994, 65535"
"  %12995 = and i32 %12994, 65535"
"  %12995 = and i32 %12994, 65535" -> "  %12996 = add nuw nsw i32 %12995, %12992"
"  %12996 = add nuw nsw i32 %12995, %12992"
"  %12996 = add nuw nsw i32 %12995, %12992" -> "  %12998 = add i32 %12996, %12997"
"  %12997 = and i32 %12994, -65536"
"  %12997 = and i32 %12994, -65536" -> "  %12998 = add i32 %12996, %12997"
"  %12998 = add i32 %12996, %12997"
"  %12998 = add i32 %12996, %12997" -> "  %13003 = add i32 %12998, %13002"
"  %12999 = and i32 %12990, 65535"
"  %12999 = and i32 %12990, 65535" -> "  %13001 = add nuw nsw i32 %12999, %13000"
"  %13000 = lshr i32 %12974, 16"
"  %13000 = lshr i32 %12974, 16" -> "  %13001 = add nuw nsw i32 %12999, %13000"
"  %13001 = add nuw nsw i32 %12999, %13000"
"  %13001 = add nuw nsw i32 %12999, %13000" -> "  %13004 = and i32 %13001, 65535""  %13001 = add nuw nsw i32 %12999, %13000" -> "  %13002 = lshr i32 %13001, 16"
"  %13002 = lshr i32 %13001, 16"
"  %13002 = lshr i32 %13001, 16" -> "  %13003 = add i32 %12998, %13002"
"  %13003 = add i32 %12998, %13002"
"  %13003 = add i32 %12998, %13002" -> "  %13011 = add i32 %13003, %13010"
"  %13004 = and i32 %13001, 65535"
"  %13004 = and i32 %13001, 65535" -> "  %13009 = add nuw nsw i32 %13004, %13008"
"  %13005 = and i32 %12974, 65535"
"  %13005 = and i32 %12974, 65535" -> "  %13007 = add nuw nsw i32 %13005, %13006"
"  %13006 = and i32 %12975, 65535"
"  %13006 = and i32 %12975, 65535" -> "  %13020 = add nuw nsw i32 %13019, %13006""  %13006 = and i32 %12975, 65535" -> "  %13007 = add nuw nsw i32 %13005, %13006"
"  %13007 = add nuw nsw i32 %13005, %13006"
"  %13007 = add nuw nsw i32 %13005, %13006" -> "  %13019 = and i32 %13007, 65535""  %13007 = add nuw nsw i32 %13005, %13006" -> "  %13008 = lshr i32 %13007, 16"
"  %13008 = lshr i32 %13007, 16"
"  %13008 = lshr i32 %13007, 16" -> "  %13009 = add nuw nsw i32 %13004, %13008"
"  %13009 = add nuw nsw i32 %13004, %13008"
"  %13009 = add nuw nsw i32 %13004, %13008" -> "  %13021 = and i32 %13009, 65535""  %13009 = add nuw nsw i32 %13004, %13008" -> "  %13010 = lshr i32 %13009, 16"
"  %13010 = lshr i32 %13009, 16"
"  %13010 = lshr i32 %13009, 16" -> "  %13011 = add i32 %13003, %13010"
"  %13011 = add i32 %13003, %13010"
"  %13011 = add i32 %13003, %13010" -> "  %13052 = lshr i32 %13011, 16""  %13011 = add i32 %13003, %13010" -> "  %13048 = and i32 %13011, 65535"
"  %13012 = lshr i32 %12984, 16"
"  %13012 = lshr i32 %12984, 16" -> "  %13013 = add nuw i32 %13012, %12993"
"  %13013 = add nuw i32 %13012, %12993"
"  %13013 = add nuw i32 %13012, %12993" -> "  %13017 = and i32 %13013, -65536""  %13013 = add nuw i32 %13012, %12993" -> "  %13015 = and i32 %13013, 65535"
"  %13014 = lshr i32 %12986, 16"
"  %13014 = lshr i32 %12986, 16" -> "  %13016 = add nuw nsw i32 %13015, %13014"
"  %13015 = and i32 %13013, 65535"
"  %13015 = and i32 %13013, 65535" -> "  %13016 = add nuw nsw i32 %13015, %13014"
"  %13016 = add nuw nsw i32 %13015, %13014"
"  %13016 = add nuw nsw i32 %13015, %13014" -> "  %13018 = add i32 %13016, %13017"
"  %13017 = and i32 %13013, -65536"
"  %13017 = and i32 %13013, -65536" -> "  %13018 = add i32 %13016, %13017"
"  %13018 = add i32 %13016, %13017"
"  %13018 = add i32 %13016, %13017" -> "  %13025 = add i32 %13018, %13024"
"  %13019 = and i32 %13007, 65535"
"  %13019 = and i32 %13007, 65535" -> "  %13020 = add nuw nsw i32 %13019, %13006"
"  %13020 = add nuw nsw i32 %13019, %13006"
"  %13020 = add nuw nsw i32 %13019, %13006" -> "  %13086 = and i32 %13020, 65535""  %13020 = add nuw nsw i32 %13019, %13006" -> "  %13027 = lshr i32 %13020, 16"
"  %13021 = and i32 %13009, 65535"
"  %13021 = and i32 %13009, 65535" -> "  %13023 = add nuw nsw i32 %13021, %13022"
"  %13022 = and i32 %12986, 65535"
"  %13022 = and i32 %12986, 65535" -> "  %13023 = add nuw nsw i32 %13021, %13022"
"  %13023 = add nuw nsw i32 %13021, %13022"
"  %13023 = add nuw nsw i32 %13021, %13022" -> "  %13026 = and i32 %13023, 65535""  %13023 = add nuw nsw i32 %13021, %13022" -> "  %13024 = lshr i32 %13023, 16"
"  %13024 = lshr i32 %13023, 16"
"  %13024 = lshr i32 %13023, 16" -> "  %13025 = add i32 %13018, %13024"
"  %13025 = add i32 %13018, %13024"
"  %13025 = add i32 %13018, %13024" -> "  %13030 = add i32 %13025, %13029"
"  %13026 = and i32 %13023, 65535"
"  %13026 = and i32 %13023, 65535" -> "  %13028 = add nuw nsw i32 %13026, %13027"
"  %13027 = lshr i32 %13020, 16"
"  %13027 = lshr i32 %13020, 16" -> "  %13028 = add nuw nsw i32 %13026, %13027"
"  %13028 = add nuw nsw i32 %13026, %13027"
"  %13028 = add nuw nsw i32 %13026, %13027" -> "  %13089 = and i32 %13028, 65535""  %13028 = add nuw nsw i32 %13026, %13027" -> "  %13029 = lshr i32 %13028, 16"
"  %13029 = lshr i32 %13028, 16"
"  %13029 = lshr i32 %13028, 16" -> "  %13030 = add i32 %13025, %13029"
"  %13030 = add i32 %13025, %13029"
"  %13030 = add i32 %13025, %13029" -> "  %13065 = lshr i32 %13030, 16""  %13030 = add i32 %13025, %13029" -> "  %13062 = and i32 %13030, 65535"
"  %13031 = mul nuw i32 %12683, %12683"
"  %13031 = mul nuw i32 %12683, %12683" -> "  %13049 = and i32 %13031, 65535""  %13031 = mul nuw i32 %12683, %12683" -> "  %13032 = lshr i32 %13031, 16"
"  %13032 = lshr i32 %13031, 16"
"  %13032 = lshr i32 %13031, 16" -> "  %13035 = add nuw nsw i32 %13034, %13032"
"  %13033 = mul nuw i32 %12686, %12683"
"  %13033 = mul nuw i32 %12686, %12683" -> "  %13039 = add nuw i32 %13038, %13033""  %13033 = mul nuw i32 %12686, %12683" -> "  %13036 = and i32 %13033, -65536""  %13033 = mul nuw i32 %12686, %12683" -> "  %13034 = and i32 %13033, 65535"
"  %13034 = and i32 %13033, 65535"
"  %13034 = and i32 %13033, 65535" -> "  %13035 = add nuw nsw i32 %13034, %13032"
"  %13035 = add nuw nsw i32 %13034, %13032"
"  %13035 = add nuw nsw i32 %13034, %13032" -> "  %13037 = add nuw i32 %13035, %13036"
"  %13036 = and i32 %13033, -65536"
"  %13036 = and i32 %13033, -65536" -> "  %13037 = add nuw i32 %13035, %13036"
"  %13037 = add nuw i32 %13035, %13036"
"  %13037 = add nuw i32 %13035, %13036" -> "  %13040 = lshr i32 %13037, 16""  %13037 = add nuw i32 %13035, %13036" -> "  %13038 = and i32 %13037, 65535"
"  %13038 = and i32 %13037, 65535"
"  %13038 = and i32 %13037, 65535" -> "  %13039 = add nuw i32 %13038, %13033"
"  %13039 = add nuw i32 %13038, %13033"
"  %13039 = add nuw i32 %13038, %13033" -> "  %13051 = and i32 %13039, 65535""  %13039 = add nuw i32 %13038, %13033" -> "  %13043 = lshr i32 %13039, 16"
"  %13040 = lshr i32 %13037, 16"
"  %13040 = lshr i32 %13037, 16" -> "  %13042 = add nuw i32 %13040, %13041"
"  %13041 = mul nuw i32 %12686, %12686"
"  %13041 = mul nuw i32 %12686, %12686" -> "  %13042 = add nuw i32 %13040, %13041"
"  %13042 = add nuw i32 %13040, %13041"
"  %13042 = add nuw i32 %13040, %13041" -> "  %13046 = and i32 %13042, -65536""  %13042 = add nuw i32 %13040, %13041" -> "  %13044 = and i32 %13042, 65535"
"  %13043 = lshr i32 %13039, 16"
"  %13043 = lshr i32 %13039, 16" -> "  %13045 = add nuw nsw i32 %13043, %13044"
"  %13044 = and i32 %13042, 65535"
"  %13044 = and i32 %13042, 65535" -> "  %13045 = add nuw nsw i32 %13043, %13044"
"  %13045 = add nuw nsw i32 %13043, %13044"
"  %13045 = add nuw nsw i32 %13043, %13044" -> "  %13047 = add i32 %13045, %13046"
"  %13046 = and i32 %13042, -65536"
"  %13046 = and i32 %13042, -65536" -> "  %13047 = add i32 %13045, %13046"
"  %13047 = add i32 %13045, %13046"
"  %13047 = add i32 %13045, %13046" -> "  %13055 = add i32 %13047, %13054"
"  %13048 = and i32 %13011, 65535"
"  %13048 = and i32 %13011, 65535" -> "  %13050 = add nuw nsw i32 %13048, %13049"
"  %13049 = and i32 %13031, 65535"
"  %13049 = and i32 %13031, 65535" -> "  %13050 = add nuw nsw i32 %13048, %13049"
"  %13050 = add nuw nsw i32 %13048, %13049"
"  %13050 = add nuw nsw i32 %13048, %13049" -> "  %13061 = and i32 %13050, 65535""  %13050 = add nuw nsw i32 %13048, %13049" -> "  %13057 = lshr i32 %13050, 16"
"  %13051 = and i32 %13039, 65535"
"  %13051 = and i32 %13039, 65535" -> "  %13053 = add nuw nsw i32 %13052, %13051"
"  %13052 = lshr i32 %13011, 16"
"  %13052 = lshr i32 %13011, 16" -> "  %13053 = add nuw nsw i32 %13052, %13051"
"  %13053 = add nuw nsw i32 %13052, %13051"
"  %13053 = add nuw nsw i32 %13052, %13051" -> "  %13056 = and i32 %13053, 65535""  %13053 = add nuw nsw i32 %13052, %13051" -> "  %13054 = lshr i32 %13053, 16"
"  %13054 = lshr i32 %13053, 16"
"  %13054 = lshr i32 %13053, 16" -> "  %13055 = add i32 %13047, %13054"
"  %13055 = add i32 %13047, %13054"
"  %13055 = add i32 %13047, %13054" -> "  %13060 = add i32 %13055, %13059"
"  %13056 = and i32 %13053, 65535"
"  %13056 = and i32 %13053, 65535" -> "  %13058 = add nuw nsw i32 %13056, %13057"
"  %13057 = lshr i32 %13050, 16"
"  %13057 = lshr i32 %13050, 16" -> "  %13058 = add nuw nsw i32 %13056, %13057"
"  %13058 = add nuw nsw i32 %13056, %13057"
"  %13058 = add nuw nsw i32 %13056, %13057" -> "  %13064 = and i32 %13058, 65535""  %13058 = add nuw nsw i32 %13056, %13057" -> "  %13059 = lshr i32 %13058, 16"
"  %13059 = lshr i32 %13058, 16"
"  %13059 = lshr i32 %13058, 16" -> "  %13060 = add i32 %13055, %13059"
"  %13060 = add i32 %13055, %13059"
"  %13060 = add i32 %13055, %13059" -> "  %13073 = and i32 %13060, -65536""  %13060 = add i32 %13055, %13059" -> "  %13071 = and i32 %13060, 65535"
"  %13061 = and i32 %13050, 65535"
"  %13061 = and i32 %13050, 65535" -> "  %13063 = add nuw nsw i32 %13062, %13061"
"  %13062 = and i32 %13030, 65535"
"  %13062 = and i32 %13030, 65535" -> "  %13063 = add nuw nsw i32 %13062, %13061"
"  %13063 = add nuw nsw i32 %13062, %13061"
"  %13063 = add nuw nsw i32 %13062, %13061" -> "  %13103 = and i32 %13063, 65535""  %13063 = add nuw nsw i32 %13062, %13061" -> "  %13067 = lshr i32 %13063, 16"
"  %13064 = and i32 %13058, 65535"
"  %13064 = and i32 %13058, 65535" -> "  %13066 = add nuw nsw i32 %13064, %13065"
"  %13065 = lshr i32 %13030, 16"
"  %13065 = lshr i32 %13030, 16" -> "  %13066 = add nuw nsw i32 %13064, %13065"
"  %13066 = add nuw nsw i32 %13064, %13065"
"  %13066 = add nuw nsw i32 %13064, %13065" -> "  %13070 = lshr i32 %13066, 16""  %13066 = add nuw nsw i32 %13064, %13065" -> "  %13068 = and i32 %13066, 65535"
"  %13067 = lshr i32 %13063, 16"
"  %13067 = lshr i32 %13063, 16" -> "  %13069 = add nuw nsw i32 %13068, %13067"
"  %13068 = and i32 %13066, 65535"
"  %13068 = and i32 %13066, 65535" -> "  %13069 = add nuw nsw i32 %13068, %13067"
"  %13069 = add nuw nsw i32 %13068, %13067"
"  %13069 = add nuw nsw i32 %13068, %13067" -> "  %13110 = and i32 %13069, 65535""  %13069 = add nuw nsw i32 %13068, %13067" -> "  %13075 = lshr i32 %13069, 16"
"  %13070 = lshr i32 %13066, 16"
"  %13070 = lshr i32 %13066, 16" -> "  %13072 = add nuw nsw i32 %13070, %13071"
"  %13071 = and i32 %13060, 65535"
"  %13071 = and i32 %13060, 65535" -> "  %13072 = add nuw nsw i32 %13070, %13071"
"  %13072 = add nuw nsw i32 %13070, %13071"
"  %13072 = add nuw nsw i32 %13070, %13071" -> "  %13074 = add i32 %13072, %13073"
"  %13073 = and i32 %13060, -65536"
"  %13073 = and i32 %13060, -65536" -> "  %13074 = add i32 %13072, %13073"
"  %13074 = add i32 %13072, %13073"
"  %13074 = add i32 %13072, %13073" -> "  %13076 = add i32 %13074, %13075"
"  %13075 = lshr i32 %13069, 16"
"  %13075 = lshr i32 %13069, 16" -> "  %13076 = add i32 %13074, %13075"
"  %13076 = add i32 %13074, %13075"
"  %13076 = add i32 %13074, %13075" -> "  %13114 = add i32 %13076, %13113"
"  %13077 = and i32 %12958, 65535"
"  %13077 = and i32 %12958, 65535" -> "  %13079 = add nuw nsw i32 %13078, %13077"
"  %13078 = and i32 %12838, 65535"
"  %13078 = and i32 %12838, 65535" -> "  %13079 = add nuw nsw i32 %13078, %13077"
"  %13079 = add nuw nsw i32 %13078, %13077"
"  %13079 = add nuw nsw i32 %13078, %13077" -> "  %13115 = and i32 %13079, 65535""  %13079 = add nuw nsw i32 %13078, %13077" -> "  %13083 = lshr i32 %13079, 16"
"  %13080 = and i32 %12966, 65535"
"  %13080 = and i32 %12966, 65535" -> "  %13082 = add nuw nsw i32 %13081, %13080"
"  %13081 = and i32 %12841, 65535"
"  %13081 = and i32 %12841, 65535" -> "  %13082 = add nuw nsw i32 %13081, %13080"
"  %13082 = add nuw nsw i32 %13081, %13080"
"  %13082 = add nuw nsw i32 %13081, %13080" -> "  %13096 = lshr i32 %13082, 16""  %13082 = add nuw nsw i32 %13081, %13080" -> "  %13084 = and i32 %13082, 65535"
"  %13083 = lshr i32 %13079, 16"
"  %13083 = lshr i32 %13079, 16" -> "  %13085 = add nuw nsw i32 %13084, %13083"
"  %13084 = and i32 %13082, 65535"
"  %13084 = and i32 %13082, 65535" -> "  %13085 = add nuw nsw i32 %13084, %13083"
"  %13085 = add nuw nsw i32 %13084, %13083"
"  %13085 = add nuw nsw i32 %13084, %13083" -> "  %13118 = and i32 %13085, 65535""  %13085 = add nuw nsw i32 %13084, %13083" -> "  %13098 = lshr i32 %13085, 16"
"  %13086 = and i32 %13020, 65535"
"  %13086 = and i32 %13020, 65535" -> "  %13088 = add nuw nsw i32 %13087, %13086"
"  %13087 = and i32 %12843, 65535"
"  %13087 = and i32 %12843, 65535" -> "  %13088 = add nuw nsw i32 %13087, %13086"
"  %13088 = add nuw nsw i32 %13087, %13086"
"  %13088 = add nuw nsw i32 %13087, %13086" -> "  %13095 = and i32 %13088, 65535""  %13088 = add nuw nsw i32 %13087, %13086" -> "  %13092 = lshr i32 %13088, 16"
"  %13089 = and i32 %13028, 65535"
"  %13089 = and i32 %13028, 65535" -> "  %13091 = add nuw nsw i32 %13090, %13089"
"  %13090 = lshr i32 %12843, 16"
"  %13090 = lshr i32 %12843, 16" -> "  %13091 = add nuw nsw i32 %13090, %13089"
"  %13091 = add nuw nsw i32 %13090, %13089"
"  %13091 = add nuw nsw i32 %13090, %13089" -> "  %13104 = lshr i32 %13091, 16""  %13091 = add nuw nsw i32 %13090, %13089" -> "  %13093 = and i32 %13091, 65535"
"  %13092 = lshr i32 %13088, 16"
"  %13092 = lshr i32 %13088, 16" -> "  %13094 = add nuw nsw i32 %13092, %13093"
"  %13093 = and i32 %13091, 65535"
"  %13093 = and i32 %13091, 65535" -> "  %13094 = add nuw nsw i32 %13092, %13093"
"  %13094 = add nuw nsw i32 %13092, %13093"
"  %13094 = add nuw nsw i32 %13092, %13093" -> "  %13106 = lshr i32 %13094, 16""  %13094 = add nuw nsw i32 %13092, %13093" -> "  %13101 = and i32 %13094, 65535"
"  %13095 = and i32 %13088, 65535"
"  %13095 = and i32 %13088, 65535" -> "  %13097 = add nuw nsw i32 %13095, %13096"
"  %13096 = lshr i32 %13082, 16"
"  %13096 = lshr i32 %13082, 16" -> "  %13097 = add nuw nsw i32 %13095, %13096"
"  %13097 = add nuw nsw i32 %13095, %13096"
"  %13097 = add nuw nsw i32 %13095, %13096" -> "  %13099 = add nuw nsw i32 %13097, %13098"
"  %13098 = lshr i32 %13085, 16"
"  %13098 = lshr i32 %13085, 16" -> "  %13099 = add nuw nsw i32 %13097, %13098"
"  %13099 = add nuw nsw i32 %13097, %13098"
"  %13099 = add nuw nsw i32 %13097, %13098" -> "  %13124 = and i32 %13099, 65535""  %13099 = add nuw nsw i32 %13097, %13098" -> "  %13100 = lshr i32 %13099, 16"
"  %13100 = lshr i32 %13099, 16"
"  %13100 = lshr i32 %13099, 16" -> "  %13102 = add nuw nsw i32 %13100, %13101"
"  %13101 = and i32 %13094, 65535"
"  %13101 = and i32 %13094, 65535" -> "  %13102 = add nuw nsw i32 %13100, %13101"
"  %13102 = add nuw nsw i32 %13100, %13101"
"  %13102 = add nuw nsw i32 %13100, %13101" -> "  %13127 = and i32 %13102, 65535""  %13102 = add nuw nsw i32 %13100, %13101" -> "  %13108 = lshr i32 %13102, 16"
"  %13103 = and i32 %13063, 65535"
"  %13103 = and i32 %13063, 65535" -> "  %13105 = add nuw nsw i32 %13104, %13103"
"  %13104 = lshr i32 %13091, 16"
"  %13104 = lshr i32 %13091, 16" -> "  %13105 = add nuw nsw i32 %13104, %13103"
"  %13105 = add nuw nsw i32 %13104, %13103"
"  %13105 = add nuw nsw i32 %13104, %13103" -> "  %13107 = add nuw nsw i32 %13105, %13106"
"  %13106 = lshr i32 %13094, 16"
"  %13106 = lshr i32 %13094, 16" -> "  %13107 = add nuw nsw i32 %13105, %13106"
"  %13107 = add nuw nsw i32 %13105, %13106"
"  %13107 = add nuw nsw i32 %13105, %13106" -> "  %13109 = add nuw nsw i32 %13107, %13108"
"  %13108 = lshr i32 %13102, 16"
"  %13108 = lshr i32 %13102, 16" -> "  %13109 = add nuw nsw i32 %13107, %13108"
"  %13109 = add nuw nsw i32 %13107, %13108"
"  %13109 = add nuw nsw i32 %13107, %13108" -> "  %13141 = and i32 %13109, 65535""  %13109 = add nuw nsw i32 %13107, %13108" -> "  %13111 = lshr i32 %13109, 16"
"  %13110 = and i32 %13069, 65535"
"  %13110 = and i32 %13069, 65535" -> "  %13112 = add nuw nsw i32 %13111, %13110"
"  %13111 = lshr i32 %13109, 16"
"  %13111 = lshr i32 %13109, 16" -> "  %13112 = add nuw nsw i32 %13111, %13110"
"  %13112 = add nuw nsw i32 %13111, %13110"
"  %13112 = add nuw nsw i32 %13111, %13110" -> "  %13149 = and i32 %13112, 65535""  %13112 = add nuw nsw i32 %13111, %13110" -> "  %13113 = lshr i32 %13112, 16"
"  %13113 = lshr i32 %13112, 16"
"  %13113 = lshr i32 %13112, 16" -> "  %13114 = add i32 %13076, %13113"
"  %13114 = add i32 %13076, %13113"
"  %13114 = add i32 %13076, %13113" -> "  %13152 = add i32 %13114, %13151"
"  %13115 = and i32 %13079, 65535"
"  %13115 = and i32 %13079, 65535" -> "  %13117 = add nuw nsw i32 %13116, %13115"
"  %13116 = and i32 %12952, 65535"
"  %13116 = and i32 %12952, 65535" -> "  %13117 = add nuw nsw i32 %13116, %13115"
"  %13117 = add nuw nsw i32 %13116, %13115"
"  %13117 = add nuw nsw i32 %13116, %13115" -> "  %13827 = and i32 %13117, 65535""  %13117 = add nuw nsw i32 %13116, %13115" -> "  %13121 = lshr i32 %13117, 16"
"  %13118 = and i32 %13085, 65535"
"  %13118 = and i32 %13085, 65535" -> "  %13120 = add nuw nsw i32 %13119, %13118"
"  %13119 = and i32 %12955, 65535"
"  %13119 = and i32 %12955, 65535" -> "  %13120 = add nuw nsw i32 %13119, %13118"
"  %13120 = add nuw nsw i32 %13119, %13118"
"  %13120 = add nuw nsw i32 %13119, %13118" -> "  %13134 = lshr i32 %13120, 16""  %13120 = add nuw nsw i32 %13119, %13118" -> "  %13122 = and i32 %13120, 65535"
"  %13121 = lshr i32 %13117, 16"
"  %13121 = lshr i32 %13117, 16" -> "  %13123 = add nuw nsw i32 %13122, %13121"
"  %13122 = and i32 %13120, 65535"
"  %13122 = and i32 %13120, 65535" -> "  %13123 = add nuw nsw i32 %13122, %13121"
"  %13123 = add nuw nsw i32 %13122, %13121"
"  %13123 = add nuw nsw i32 %13122, %13121" -> "  %13828 = and i32 %13123, 65535""  %13123 = add nuw nsw i32 %13122, %13121" -> "  %13135 = lshr i32 %13123, 16"
"  %13124 = and i32 %13099, 65535"
"  %13124 = and i32 %13099, 65535" -> "  %13126 = add nuw nsw i32 %13125, %13124"
"  %13125 = and i32 %12957, 65535"
"  %13125 = and i32 %12957, 65535" -> "  %13126 = add nuw nsw i32 %13125, %13124"
"  %13126 = add nuw nsw i32 %13125, %13124"
"  %13126 = add nuw nsw i32 %13125, %13124" -> "  %13133 = and i32 %13126, 65535""  %13126 = add nuw nsw i32 %13125, %13124" -> "  %13130 = lshr i32 %13126, 16"
"  %13127 = and i32 %13102, 65535"
"  %13127 = and i32 %13102, 65535" -> "  %13129 = add nuw nsw i32 %13127, %13128"
"  %13128 = lshr i32 %12957, 16"
"  %13128 = lshr i32 %12957, 16" -> "  %13129 = add nuw nsw i32 %13127, %13128"
"  %13129 = add nuw nsw i32 %13127, %13128"
"  %13129 = add nuw nsw i32 %13127, %13128" -> "  %13142 = lshr i32 %13129, 16""  %13129 = add nuw nsw i32 %13127, %13128" -> "  %13131 = and i32 %13129, 65535"
"  %13130 = lshr i32 %13126, 16"
"  %13130 = lshr i32 %13126, 16" -> "  %13132 = add nuw nsw i32 %13131, %13130"
"  %13131 = and i32 %13129, 65535"
"  %13131 = and i32 %13129, 65535" -> "  %13132 = add nuw nsw i32 %13131, %13130"
"  %13132 = add nuw nsw i32 %13131, %13130"
"  %13132 = add nuw nsw i32 %13131, %13130" -> "  %13144 = lshr i32 %13132, 16""  %13132 = add nuw nsw i32 %13131, %13130" -> "  %13139 = and i32 %13132, 65535"
"  %13133 = and i32 %13126, 65535"
"  %13133 = and i32 %13126, 65535" -> "  %13137 = add nuw nsw i32 %13136, %13133"
"  %13134 = lshr i32 %13120, 16"
"  %13134 = lshr i32 %13120, 16" -> "  %13136 = add nuw nsw i32 %13135, %13134"
"  %13135 = lshr i32 %13123, 16"
"  %13135 = lshr i32 %13123, 16" -> "  %13136 = add nuw nsw i32 %13135, %13134"
"  %13136 = add nuw nsw i32 %13135, %13134"
"  %13136 = add nuw nsw i32 %13135, %13134" -> "  %13137 = add nuw nsw i32 %13136, %13133"
"  %13137 = add nuw nsw i32 %13136, %13133"
"  %13137 = add nuw nsw i32 %13136, %13133" -> "  %13848 = and i32 %13137, 65535""  %13137 = add nuw nsw i32 %13136, %13133" -> "  %13138 = lshr i32 %13137, 16"
"  %13138 = lshr i32 %13137, 16"
"  %13138 = lshr i32 %13137, 16" -> "  %13140 = add nuw nsw i32 %13139, %13138"
"  %13139 = and i32 %13132, 65535"
"  %13139 = and i32 %13132, 65535" -> "  %13140 = add nuw nsw i32 %13139, %13138"
"  %13140 = add nuw nsw i32 %13139, %13138"
"  %13140 = add nuw nsw i32 %13139, %13138" -> "  %13847 = and i32 %13140, 65535""  %13140 = add nuw nsw i32 %13139, %13138" -> "  %13146 = lshr i32 %13140, 16"
"  %13141 = and i32 %13109, 65535"
"  %13141 = and i32 %13109, 65535" -> "  %13143 = add nuw nsw i32 %13142, %13141"
"  %13142 = lshr i32 %13129, 16"
"  %13142 = lshr i32 %13129, 16" -> "  %13143 = add nuw nsw i32 %13142, %13141"
"  %13143 = add nuw nsw i32 %13142, %13141"
"  %13143 = add nuw nsw i32 %13142, %13141" -> "  %13145 = add nuw nsw i32 %13143, %13144"
"  %13144 = lshr i32 %13132, 16"
"  %13144 = lshr i32 %13132, 16" -> "  %13145 = add nuw nsw i32 %13143, %13144"
"  %13145 = add nuw nsw i32 %13143, %13144"
"  %13145 = add nuw nsw i32 %13143, %13144" -> "  %13147 = add nuw nsw i32 %13145, %13146"
"  %13146 = lshr i32 %13140, 16"
"  %13146 = lshr i32 %13140, 16" -> "  %13147 = add nuw nsw i32 %13145, %13146"
"  %13147 = add nuw nsw i32 %13145, %13146"
"  %13147 = add nuw nsw i32 %13145, %13146" -> "  %13962 = and i32 %13147, 65535""  %13147 = add nuw nsw i32 %13145, %13146" -> "  %13148 = lshr i32 %13147, 16"
"  %13148 = lshr i32 %13147, 16"
"  %13148 = lshr i32 %13147, 16" -> "  %13150 = add nuw nsw i32 %13148, %13149"
"  %13149 = and i32 %13112, 65535"
"  %13149 = and i32 %13112, 65535" -> "  %13150 = add nuw nsw i32 %13148, %13149"
"  %13150 = add nuw nsw i32 %13148, %13149"
"  %13150 = add nuw nsw i32 %13148, %13149" -> "  %13961 = and i32 %13150, 65535""  %13150 = add nuw nsw i32 %13148, %13149" -> "  %13151 = lshr i32 %13150, 16"
"  %13151 = lshr i32 %13150, 16"
"  %13151 = lshr i32 %13150, 16" -> "  %13152 = add i32 %13114, %13151"
"  %13152 = add i32 %13114, %13151"
"  %13152 = add i32 %13114, %13151" -> "  %13981 = and i32 %13152, 65535""  %13152 = add i32 %13114, %13151" -> "  %13982 = lshr i32 %13152, 16"
"  %13153 = and i32 %12536, 65535"
"  %13153 = and i32 %12536, 65535" -> "  %16521 = add nuw nsw i32 %16520, %13153""  %13153 = and i32 %12536, 65535" -> "  %14602 = mul nuw nsw i32 %13153, 9871""  %13153 = and i32 %12536, 65535" -> "  %13459 = mul nuw nsw i32 %13153, 17857""  %13153 = and i32 %12536, 65535" -> "  %13154 = mul nuw i32 %13153, 37996""  %13153 = and i32 %12536, 65535" -> "  %13162 = mul nuw i32 %13153, 45147""  %13153 = and i32 %12536, 65535" -> "  %13209 = mul nuw nsw i32 %13153, 1324""  %13153 = and i32 %12536, 65535" -> "  %13216 = mul nuw i32 %13153, 62728""  %13153 = and i32 %12536, 65535" -> "  %13515 = mul nuw i32 %13153, 42170""  %13153 = and i32 %12536, 65535" -> "  %13508 = mul nuw nsw i32 %13153, 31112""  %13153 = and i32 %12536, 65535" -> "  %13466 = mul nuw i32 %13153, 46547""  %13153 = and i32 %12536, 65535" -> "  %14651 = mul nuw nsw i32 %13153, 29744""  %13153 = and i32 %12536, 65535" -> "  %14644 = mul nuw nsw i32 %13153, 24315""  %13153 = and i32 %12536, 65535" -> "  %14595 = mul nuw i32 %13153, 42779""  %13153 = and i32 %12536, 65535" -> "  %14943 = mul nuw i32 %13153, 36786""  %13153 = and i32 %12536, 65535" -> "  %14936 = mul nuw nsw i32 %13153, 21884""  %13153 = and i32 %12536, 65535" -> "  %14894 = mul nuw nsw i32 %13153, 11561""  %13153 = and i32 %12536, 65535" -> "  %14887 = mul nuw nsw i32 %13153, 4087"
"  %13154 = mul nuw i32 %13153, 37996"
"  %13154 = mul nuw i32 %13153, 37996" -> "  %13155 = lshr i32 %13154, 16"
"  %13155 = lshr i32 %13154, 16"
"  %13155 = lshr i32 %13154, 16" -> "  %13159 = add nuw nsw i32 %13158, %13155"
"  %13156 = and i32 %12544, 65535"
"  %13156 = and i32 %12544, 65535" -> "  %16523 = add nuw nsw i32 %16522, %13156""  %13156 = and i32 %12544, 65535" -> "  %13157 = mul nuw i32 %13156, 37996""  %13156 = and i32 %12544, 65535" -> "  %13166 = mul nuw i32 %13156, 45147""  %13156 = and i32 %12544, 65535" -> "  %13211 = mul nuw nsw i32 %13156, 1324""  %13156 = and i32 %12544, 65535" -> "  %13220 = mul nuw i32 %13156, 62728""  %13156 = and i32 %12544, 65535" -> "  %13519 = mul nuw i32 %13156, 42170""  %13156 = and i32 %12544, 65535" -> "  %13510 = mul nuw nsw i32 %13156, 31112""  %13156 = and i32 %12544, 65535" -> "  %13470 = mul nuw i32 %13156, 46547""  %13156 = and i32 %12544, 65535" -> "  %13461 = mul nuw nsw i32 %13156, 17857""  %13156 = and i32 %12544, 65535" -> "  %14655 = mul nuw nsw i32 %13156, 29744""  %13156 = and i32 %12544, 65535" -> "  %14646 = mul nuw nsw i32 %13156, 24315""  %13156 = and i32 %12544, 65535" -> "  %14606 = mul nuw nsw i32 %13156, 9871""  %13156 = and i32 %12544, 65535" -> "  %14597 = mul nuw i32 %13156, 42779""  %13156 = and i32 %12544, 65535" -> "  %14947 = mul nuw i32 %13156, 36786""  %13156 = and i32 %12544, 65535" -> "  %14938 = mul nuw nsw i32 %13156, 21884""  %13156 = and i32 %12544, 65535" -> "  %14898 = mul nuw nsw i32 %13156, 11561""  %13156 = and i32 %12544, 65535" -> "  %14889 = mul nuw nsw i32 %13156, 4087"
"  %13157 = mul nuw i32 %13156, 37996"
"  %13157 = mul nuw i32 %13156, 37996" -> "  %13160 = and i32 %13157, -65536""  %13157 = mul nuw i32 %13156, 37996" -> "  %13158 = and i32 %13157, 65532"
"  %13158 = and i32 %13157, 65532"
"  %13158 = and i32 %13157, 65532" -> "  %13159 = add nuw nsw i32 %13158, %13155"
"  %13159 = add nuw nsw i32 %13158, %13155"
"  %13159 = add nuw nsw i32 %13158, %13155" -> "  %13161 = add nuw i32 %13159, %13160"
"  %13160 = and i32 %13157, -65536"
"  %13160 = and i32 %13157, -65536" -> "  %13161 = add nuw i32 %13159, %13160"
"  %13161 = add nuw i32 %13159, %13160"
"  %13161 = add nuw i32 %13159, %13160" -> "  %13165 = lshr i32 %13161, 16""  %13161 = add nuw i32 %13159, %13160" -> "  %13163 = and i32 %13161, 65535"
"  %13162 = mul nuw i32 %13153, 45147"
"  %13162 = mul nuw i32 %13153, 45147" -> "  %13164 = add nuw i32 %13163, %13162"
"  %13163 = and i32 %13161, 65535"
"  %13163 = and i32 %13161, 65535" -> "  %13164 = add nuw i32 %13163, %13162"
"  %13164 = add nuw i32 %13163, %13162"
"  %13164 = add nuw i32 %13163, %13162" -> "  %13168 = lshr i32 %13164, 16"
"  %13165 = lshr i32 %13161, 16"
"  %13165 = lshr i32 %13161, 16" -> "  %13167 = add nuw i32 %13165, %13166"
"  %13166 = mul nuw i32 %13156, 45147"
"  %13166 = mul nuw i32 %13156, 45147" -> "  %13167 = add nuw i32 %13165, %13166"
"  %13167 = add nuw i32 %13165, %13166"
"  %13167 = add nuw i32 %13165, %13166" -> "  %13171 = and i32 %13167, -65536""  %13167 = add nuw i32 %13165, %13166" -> "  %13169 = and i32 %13167, 65535"
"  %13168 = lshr i32 %13164, 16"
"  %13168 = lshr i32 %13164, 16" -> "  %13170 = add nuw nsw i32 %13168, %13169"
"  %13169 = and i32 %13167, 65535"
"  %13169 = and i32 %13167, 65535" -> "  %13170 = add nuw nsw i32 %13168, %13169"
"  %13170 = add nuw nsw i32 %13168, %13169"
"  %13170 = add nuw nsw i32 %13168, %13169" -> "  %13172 = add nuw i32 %13170, %13171"
"  %13171 = and i32 %13167, -65536"
"  %13171 = and i32 %13167, -65536" -> "  %13172 = add nuw i32 %13170, %13171"
"  %13172 = add nuw i32 %13170, %13171"
"  %13172 = add nuw i32 %13170, %13171" -> "  %13197 = lshr i32 %13172, 16""  %13172 = add nuw i32 %13170, %13171" -> "  %13193 = and i32 %13172, 65535"
"  %13173 = and i32 %12600, 65535"
"  %13173 = and i32 %12600, 65535" -> "  %16531 = add nuw nsw i32 %16530, %13173""  %13173 = and i32 %12600, 65535" -> "  %14905 = mul nuw nsw i32 %13173, 4087""  %13173 = and i32 %12600, 65535" -> "  %13174 = mul nuw i32 %13173, 37996""  %13173 = and i32 %12600, 65535" -> "  %13182 = mul nuw i32 %13173, 45147""  %13173 = and i32 %12600, 65535" -> "  %13240 = mul nuw nsw i32 %13173, 1324""  %13173 = and i32 %12600, 65535" -> "  %13247 = mul nuw i32 %13173, 62728""  %13173 = and i32 %12600, 65535" -> "  %13546 = mul nuw i32 %13173, 42170""  %13173 = and i32 %12600, 65535" -> "  %13539 = mul nuw nsw i32 %13173, 31112""  %13173 = and i32 %12600, 65535" -> "  %13484 = mul nuw i32 %13173, 46547""  %13173 = and i32 %12600, 65535" -> "  %13477 = mul nuw nsw i32 %13173, 17857""  %13173 = and i32 %12600, 65535" -> "  %14682 = mul nuw nsw i32 %13173, 29744""  %13173 = and i32 %12600, 65535" -> "  %14675 = mul nuw nsw i32 %13173, 24315""  %13173 = and i32 %12600, 65535" -> "  %14620 = mul nuw nsw i32 %13173, 9871""  %13173 = and i32 %12600, 65535" -> "  %14613 = mul nuw i32 %13173, 42779""  %13173 = and i32 %12600, 65535" -> "  %14974 = mul nuw i32 %13173, 36786""  %13173 = and i32 %12600, 65535" -> "  %14967 = mul nuw nsw i32 %13173, 21884""  %13173 = and i32 %12600, 65535" -> "  %14912 = mul nuw nsw i32 %13173, 11561"
"  %13174 = mul nuw i32 %13173, 37996"
"  %13174 = mul nuw i32 %13173, 37996" -> "  %13194 = and i32 %13174, 65532""  %13174 = mul nuw i32 %13173, 37996" -> "  %13175 = lshr i32 %13174, 16"
"  %13175 = lshr i32 %13174, 16"
"  %13175 = lshr i32 %13174, 16" -> "  %13179 = add nuw nsw i32 %13178, %13175"
"  %13176 = and i32 %12608, 65535"
"  %13176 = and i32 %12608, 65535" -> "  %16533 = add nuw nsw i32 %16532, %13176""  %13176 = and i32 %12608, 65535" -> "  %13177 = mul nuw i32 %13176, 37996""  %13176 = and i32 %12608, 65535" -> "  %13186 = mul nuw i32 %13176, 45147""  %13176 = and i32 %12608, 65535" -> "  %13242 = mul nuw nsw i32 %13176, 1324""  %13176 = and i32 %12608, 65535" -> "  %13251 = mul nuw i32 %13176, 62728""  %13176 = and i32 %12608, 65535" -> "  %13550 = mul nuw i32 %13176, 42170""  %13176 = and i32 %12608, 65535" -> "  %13541 = mul nuw nsw i32 %13176, 31112""  %13176 = and i32 %12608, 65535" -> "  %13488 = mul nuw i32 %13176, 46547""  %13176 = and i32 %12608, 65535" -> "  %13479 = mul nuw nsw i32 %13176, 17857""  %13176 = and i32 %12608, 65535" -> "  %14686 = mul nuw nsw i32 %13176, 29744""  %13176 = and i32 %12608, 65535" -> "  %14677 = mul nuw nsw i32 %13176, 24315""  %13176 = and i32 %12608, 65535" -> "  %14624 = mul nuw nsw i32 %13176, 9871""  %13176 = and i32 %12608, 65535" -> "  %14615 = mul nuw i32 %13176, 42779""  %13176 = and i32 %12608, 65535" -> "  %14978 = mul nuw i32 %13176, 36786""  %13176 = and i32 %12608, 65535" -> "  %14969 = mul nuw nsw i32 %13176, 21884""  %13176 = and i32 %12608, 65535" -> "  %14916 = mul nuw nsw i32 %13176, 11561""  %13176 = and i32 %12608, 65535" -> "  %14907 = mul nuw nsw i32 %13176, 4087"
"  %13177 = mul nuw i32 %13176, 37996"
"  %13177 = mul nuw i32 %13176, 37996" -> "  %13180 = and i32 %13177, -65536""  %13177 = mul nuw i32 %13176, 37996" -> "  %13178 = and i32 %13177, 65532"
"  %13178 = and i32 %13177, 65532"
"  %13178 = and i32 %13177, 65532" -> "  %13179 = add nuw nsw i32 %13178, %13175"
"  %13179 = add nuw nsw i32 %13178, %13175"
"  %13179 = add nuw nsw i32 %13178, %13175" -> "  %13181 = add nuw i32 %13179, %13180"
"  %13180 = and i32 %13177, -65536"
"  %13180 = and i32 %13177, -65536" -> "  %13181 = add nuw i32 %13179, %13180"
"  %13181 = add nuw i32 %13179, %13180"
"  %13181 = add nuw i32 %13179, %13180" -> "  %13185 = lshr i32 %13181, 16""  %13181 = add nuw i32 %13179, %13180" -> "  %13183 = and i32 %13181, 65535"
"  %13182 = mul nuw i32 %13173, 45147"
"  %13182 = mul nuw i32 %13173, 45147" -> "  %13184 = add nuw i32 %13183, %13182"
"  %13183 = and i32 %13181, 65535"
"  %13183 = and i32 %13181, 65535" -> "  %13184 = add nuw i32 %13183, %13182"
"  %13184 = add nuw i32 %13183, %13182"
"  %13184 = add nuw i32 %13183, %13182" -> "  %13196 = and i32 %13184, 65535""  %13184 = add nuw i32 %13183, %13182" -> "  %13188 = lshr i32 %13184, 16"
"  %13185 = lshr i32 %13181, 16"
"  %13185 = lshr i32 %13181, 16" -> "  %13187 = add nuw i32 %13185, %13186"
"  %13186 = mul nuw i32 %13176, 45147"
"  %13186 = mul nuw i32 %13176, 45147" -> "  %13187 = add nuw i32 %13185, %13186"
"  %13187 = add nuw i32 %13185, %13186"
"  %13187 = add nuw i32 %13185, %13186" -> "  %13191 = and i32 %13187, -65536""  %13187 = add nuw i32 %13185, %13186" -> "  %13189 = and i32 %13187, 65535"
"  %13188 = lshr i32 %13184, 16"
"  %13188 = lshr i32 %13184, 16" -> "  %13190 = add nuw nsw i32 %13188, %13189"
"  %13189 = and i32 %13187, 65535"
"  %13189 = and i32 %13187, 65535" -> "  %13190 = add nuw nsw i32 %13188, %13189"
"  %13190 = add nuw nsw i32 %13188, %13189"
"  %13190 = add nuw nsw i32 %13188, %13189" -> "  %13192 = add nuw i32 %13190, %13191"
"  %13191 = and i32 %13187, -65536"
"  %13191 = and i32 %13187, -65536" -> "  %13192 = add nuw i32 %13190, %13191"
"  %13192 = add nuw i32 %13190, %13191"
"  %13192 = add nuw i32 %13190, %13191" -> "  %13205 = and i32 %13192, -65536""  %13192 = add nuw i32 %13190, %13191" -> "  %13203 = and i32 %13192, 65535"
"  %13193 = and i32 %13172, 65535"
"  %13193 = and i32 %13172, 65535" -> "  %13195 = add nuw nsw i32 %13193, %13194"
"  %13194 = and i32 %13174, 65532"
"  %13194 = and i32 %13174, 65532" -> "  %13195 = add nuw nsw i32 %13193, %13194"
"  %13195 = add nuw nsw i32 %13193, %13194"
"  %13195 = add nuw nsw i32 %13193, %13194" -> "  %13227 = and i32 %13195, 65535""  %13195 = add nuw nsw i32 %13193, %13194" -> "  %13199 = lshr i32 %13195, 16"
"  %13196 = and i32 %13184, 65535"
"  %13196 = and i32 %13184, 65535" -> "  %13198 = add nuw nsw i32 %13196, %13197"
"  %13197 = lshr i32 %13172, 16"
"  %13197 = lshr i32 %13172, 16" -> "  %13198 = add nuw nsw i32 %13196, %13197"
"  %13198 = add nuw nsw i32 %13196, %13197"
"  %13198 = add nuw nsw i32 %13196, %13197" -> "  %13202 = lshr i32 %13198, 16""  %13198 = add nuw nsw i32 %13196, %13197" -> "  %13200 = and i32 %13198, 65535"
"  %13199 = lshr i32 %13195, 16"
"  %13199 = lshr i32 %13195, 16" -> "  %13201 = add nuw nsw i32 %13200, %13199"
"  %13200 = and i32 %13198, 65535"
"  %13200 = and i32 %13198, 65535" -> "  %13201 = add nuw nsw i32 %13200, %13199"
"  %13201 = add nuw nsw i32 %13200, %13199"
"  %13201 = add nuw nsw i32 %13200, %13199" -> "  %13230 = and i32 %13201, 65535""  %13201 = add nuw nsw i32 %13200, %13199" -> "  %13207 = lshr i32 %13201, 16"
"  %13202 = lshr i32 %13198, 16"
"  %13202 = lshr i32 %13198, 16" -> "  %13204 = add nuw nsw i32 %13203, %13202"
"  %13203 = and i32 %13192, 65535"
"  %13203 = and i32 %13192, 65535" -> "  %13204 = add nuw nsw i32 %13203, %13202"
"  %13204 = add nuw nsw i32 %13203, %13202"
"  %13204 = add nuw nsw i32 %13203, %13202" -> "  %13206 = add nuw i32 %13204, %13205"
"  %13205 = and i32 %13192, -65536"
"  %13205 = and i32 %13192, -65536" -> "  %13206 = add nuw i32 %13204, %13205"
"  %13206 = add nuw i32 %13204, %13205"
"  %13206 = add nuw i32 %13204, %13205" -> "  %13208 = add nuw i32 %13206, %13207"
"  %13207 = lshr i32 %13201, 16"
"  %13207 = lshr i32 %13201, 16" -> "  %13208 = add nuw i32 %13206, %13207"
"  %13208 = add nuw i32 %13206, %13207"
"  %13208 = add nuw i32 %13206, %13207" -> "  %13262 = lshr i32 %13208, 16""  %13208 = add nuw i32 %13206, %13207" -> "  %13258 = and i32 %13208, 65535"
"  %13209 = mul nuw nsw i32 %13153, 1324"
"  %13209 = mul nuw nsw i32 %13153, 1324" -> "  %13228 = and i32 %13209, 65532""  %13209 = mul nuw nsw i32 %13153, 1324" -> "  %13210 = lshr i32 %13209, 16"
"  %13210 = lshr i32 %13209, 16"
"  %13210 = lshr i32 %13209, 16" -> "  %13213 = add nuw nsw i32 %13212, %13210"
"  %13211 = mul nuw nsw i32 %13156, 1324"
"  %13211 = mul nuw nsw i32 %13156, 1324" -> "  %13214 = and i32 %13211, 134152192""  %13211 = mul nuw nsw i32 %13156, 1324" -> "  %13212 = and i32 %13211, 65532"
"  %13212 = and i32 %13211, 65532"
"  %13212 = and i32 %13211, 65532" -> "  %13213 = add nuw nsw i32 %13212, %13210"
"  %13213 = add nuw nsw i32 %13212, %13210"
"  %13213 = add nuw nsw i32 %13212, %13210" -> "  %13215 = add nuw nsw i32 %13213, %13214"
"  %13214 = and i32 %13211, 134152192"
"  %13214 = and i32 %13211, 134152192" -> "  %13215 = add nuw nsw i32 %13213, %13214"
"  %13215 = add nuw nsw i32 %13213, %13214"
"  %13215 = add nuw nsw i32 %13213, %13214" -> "  %13219 = lshr i32 %13215, 16""  %13215 = add nuw nsw i32 %13213, %13214" -> "  %13217 = and i32 %13215, 65535"
"  %13216 = mul nuw i32 %13153, 62728"
"  %13216 = mul nuw i32 %13153, 62728" -> "  %13218 = add nuw i32 %13217, %13216"
"  %13217 = and i32 %13215, 65535"
"  %13217 = and i32 %13215, 65535" -> "  %13218 = add nuw i32 %13217, %13216"
"  %13218 = add nuw i32 %13217, %13216"
"  %13218 = add nuw i32 %13217, %13216" -> "  %13231 = and i32 %13218, 65535""  %13218 = add nuw i32 %13217, %13216" -> "  %13222 = lshr i32 %13218, 16"
"  %13219 = lshr i32 %13215, 16"
"  %13219 = lshr i32 %13215, 16" -> "  %13221 = add nuw i32 %13219, %13220"
"  %13220 = mul nuw i32 %13156, 62728"
"  %13220 = mul nuw i32 %13156, 62728" -> "  %13221 = add nuw i32 %13219, %13220"
"  %13221 = add nuw i32 %13219, %13220"
"  %13221 = add nuw i32 %13219, %13220" -> "  %13225 = and i32 %13221, -65536""  %13221 = add nuw i32 %13219, %13220" -> "  %13223 = and i32 %13221, 65535"
"  %13222 = lshr i32 %13218, 16"
"  %13222 = lshr i32 %13218, 16" -> "  %13224 = add nuw nsw i32 %13222, %13223"
"  %13223 = and i32 %13221, 65535"
"  %13223 = and i32 %13221, 65535" -> "  %13224 = add nuw nsw i32 %13222, %13223"
"  %13224 = add nuw nsw i32 %13222, %13223"
"  %13224 = add nuw nsw i32 %13222, %13223" -> "  %13226 = add nuw i32 %13224, %13225"
"  %13225 = and i32 %13221, -65536"
"  %13225 = and i32 %13221, -65536" -> "  %13226 = add nuw i32 %13224, %13225"
"  %13226 = add nuw i32 %13224, %13225"
"  %13226 = add nuw i32 %13224, %13225" -> "  %13234 = add nuw i32 %13226, %13233"
"  %13227 = and i32 %13195, 65535"
"  %13227 = and i32 %13195, 65535" -> "  %13229 = add nuw nsw i32 %13227, %13228"
"  %13228 = and i32 %13209, 65532"
"  %13228 = and i32 %13209, 65532" -> "  %13229 = add nuw nsw i32 %13227, %13228"
"  %13229 = add nuw nsw i32 %13227, %13228"
"  %13229 = add nuw nsw i32 %13227, %13228" -> "  %13236 = lshr i32 %13229, 16"
"  %13230 = and i32 %13201, 65535"
"  %13230 = and i32 %13201, 65535" -> "  %13232 = add nuw nsw i32 %13230, %13231"
"  %13231 = and i32 %13218, 65535"
"  %13231 = and i32 %13218, 65535" -> "  %13232 = add nuw nsw i32 %13230, %13231"
"  %13232 = add nuw nsw i32 %13230, %13231"
"  %13232 = add nuw nsw i32 %13230, %13231" -> "  %13235 = and i32 %13232, 65535""  %13232 = add nuw nsw i32 %13230, %13231" -> "  %13233 = lshr i32 %13232, 16"
"  %13233 = lshr i32 %13232, 16"
"  %13233 = lshr i32 %13232, 16" -> "  %13234 = add nuw i32 %13226, %13233"
"  %13234 = add nuw i32 %13226, %13233"
"  %13234 = add nuw i32 %13226, %13233" -> "  %13239 = add nuw i32 %13234, %13238"
"  %13235 = and i32 %13232, 65535"
"  %13235 = and i32 %13232, 65535" -> "  %13237 = add nuw nsw i32 %13235, %13236"
"  %13236 = lshr i32 %13229, 16"
"  %13236 = lshr i32 %13229, 16" -> "  %13237 = add nuw nsw i32 %13235, %13236"
"  %13237 = add nuw nsw i32 %13235, %13236"
"  %13237 = add nuw nsw i32 %13235, %13236" -> "  %13238 = lshr i32 %13237, 16"
"  %13238 = lshr i32 %13237, 16"
"  %13238 = lshr i32 %13237, 16" -> "  %13239 = add nuw i32 %13234, %13238"
"  %13239 = add nuw i32 %13234, %13238"
"  %13239 = add nuw i32 %13234, %13238" -> "  %13275 = lshr i32 %13239, 16""  %13239 = add nuw i32 %13234, %13238" -> "  %13272 = and i32 %13239, 65535"
"  %13240 = mul nuw nsw i32 %13173, 1324"
"  %13240 = mul nuw nsw i32 %13173, 1324" -> "  %13259 = and i32 %13240, 65532""  %13240 = mul nuw nsw i32 %13173, 1324" -> "  %13241 = lshr i32 %13240, 16"
"  %13241 = lshr i32 %13240, 16"
"  %13241 = lshr i32 %13240, 16" -> "  %13244 = add nuw nsw i32 %13243, %13241"
"  %13242 = mul nuw nsw i32 %13176, 1324"
"  %13242 = mul nuw nsw i32 %13176, 1324" -> "  %13245 = and i32 %13242, 134152192""  %13242 = mul nuw nsw i32 %13176, 1324" -> "  %13243 = and i32 %13242, 65532"
"  %13243 = and i32 %13242, 65532"
"  %13243 = and i32 %13242, 65532" -> "  %13244 = add nuw nsw i32 %13243, %13241"
"  %13244 = add nuw nsw i32 %13243, %13241"
"  %13244 = add nuw nsw i32 %13243, %13241" -> "  %13246 = add nuw nsw i32 %13244, %13245"
"  %13245 = and i32 %13242, 134152192"
"  %13245 = and i32 %13242, 134152192" -> "  %13246 = add nuw nsw i32 %13244, %13245"
"  %13246 = add nuw nsw i32 %13244, %13245"
"  %13246 = add nuw nsw i32 %13244, %13245" -> "  %13250 = lshr i32 %13246, 16""  %13246 = add nuw nsw i32 %13244, %13245" -> "  %13248 = and i32 %13246, 65535"
"  %13247 = mul nuw i32 %13173, 62728"
"  %13247 = mul nuw i32 %13173, 62728" -> "  %13249 = add nuw i32 %13248, %13247"
"  %13248 = and i32 %13246, 65535"
"  %13248 = and i32 %13246, 65535" -> "  %13249 = add nuw i32 %13248, %13247"
"  %13249 = add nuw i32 %13248, %13247"
"  %13249 = add nuw i32 %13248, %13247" -> "  %13261 = and i32 %13249, 65535""  %13249 = add nuw i32 %13248, %13247" -> "  %13253 = lshr i32 %13249, 16"
"  %13250 = lshr i32 %13246, 16"
"  %13250 = lshr i32 %13246, 16" -> "  %13252 = add nuw i32 %13250, %13251"
"  %13251 = mul nuw i32 %13176, 62728"
"  %13251 = mul nuw i32 %13176, 62728" -> "  %13252 = add nuw i32 %13250, %13251"
"  %13252 = add nuw i32 %13250, %13251"
"  %13252 = add nuw i32 %13250, %13251" -> "  %13256 = and i32 %13252, -65536""  %13252 = add nuw i32 %13250, %13251" -> "  %13254 = and i32 %13252, 65535"
"  %13253 = lshr i32 %13249, 16"
"  %13253 = lshr i32 %13249, 16" -> "  %13255 = add nuw nsw i32 %13253, %13254"
"  %13254 = and i32 %13252, 65535"
"  %13254 = and i32 %13252, 65535" -> "  %13255 = add nuw nsw i32 %13253, %13254"
"  %13255 = add nuw nsw i32 %13253, %13254"
"  %13255 = add nuw nsw i32 %13253, %13254" -> "  %13257 = add nuw i32 %13255, %13256"
"  %13256 = and i32 %13252, -65536"
"  %13256 = and i32 %13252, -65536" -> "  %13257 = add nuw i32 %13255, %13256"
"  %13257 = add nuw i32 %13255, %13256"
"  %13257 = add nuw i32 %13255, %13256" -> "  %13265 = add nuw i32 %13257, %13264"
"  %13258 = and i32 %13208, 65535"
"  %13258 = and i32 %13208, 65535" -> "  %13260 = add nuw nsw i32 %13258, %13259"
"  %13259 = and i32 %13240, 65532"
"  %13259 = and i32 %13240, 65532" -> "  %13260 = add nuw nsw i32 %13258, %13259"
"  %13260 = add nuw nsw i32 %13258, %13259"
"  %13260 = add nuw nsw i32 %13258, %13259" -> "  %13271 = and i32 %13260, 65535""  %13260 = add nuw nsw i32 %13258, %13259" -> "  %13267 = lshr i32 %13260, 16"
"  %13261 = and i32 %13249, 65535"
"  %13261 = and i32 %13249, 65535" -> "  %13263 = add nuw nsw i32 %13262, %13261"
"  %13262 = lshr i32 %13208, 16"
"  %13262 = lshr i32 %13208, 16" -> "  %13263 = add nuw nsw i32 %13262, %13261"
"  %13263 = add nuw nsw i32 %13262, %13261"
"  %13263 = add nuw nsw i32 %13262, %13261" -> "  %13266 = and i32 %13263, 65535""  %13263 = add nuw nsw i32 %13262, %13261" -> "  %13264 = lshr i32 %13263, 16"
"  %13264 = lshr i32 %13263, 16"
"  %13264 = lshr i32 %13263, 16" -> "  %13265 = add nuw i32 %13257, %13264"
"  %13265 = add nuw i32 %13257, %13264"
"  %13265 = add nuw i32 %13257, %13264" -> "  %13270 = add nuw i32 %13265, %13269"
"  %13266 = and i32 %13263, 65535"
"  %13266 = and i32 %13263, 65535" -> "  %13268 = add nuw nsw i32 %13267, %13266"
"  %13267 = lshr i32 %13260, 16"
"  %13267 = lshr i32 %13260, 16" -> "  %13268 = add nuw nsw i32 %13267, %13266"
"  %13268 = add nuw nsw i32 %13267, %13266"
"  %13268 = add nuw nsw i32 %13267, %13266" -> "  %13274 = and i32 %13268, 65535""  %13268 = add nuw nsw i32 %13267, %13266" -> "  %13269 = lshr i32 %13268, 16"
"  %13269 = lshr i32 %13268, 16"
"  %13269 = lshr i32 %13268, 16" -> "  %13270 = add nuw i32 %13265, %13269"
"  %13270 = add nuw i32 %13265, %13269"
"  %13270 = add nuw i32 %13265, %13269" -> "  %13283 = and i32 %13270, -65536""  %13270 = add nuw i32 %13265, %13269" -> "  %13281 = and i32 %13270, 65535"
"  %13271 = and i32 %13260, 65535"
"  %13271 = and i32 %13260, 65535" -> "  %13273 = add nuw nsw i32 %13272, %13271"
"  %13272 = and i32 %13239, 65535"
"  %13272 = and i32 %13239, 65535" -> "  %13273 = add nuw nsw i32 %13272, %13271"
"  %13273 = add nuw nsw i32 %13272, %13271"
"  %13273 = add nuw nsw i32 %13272, %13271" -> "  %13422 = and i32 %13273, 65535""  %13273 = add nuw nsw i32 %13272, %13271" -> "  %13277 = lshr i32 %13273, 16"
"  %13274 = and i32 %13268, 65535"
"  %13274 = and i32 %13268, 65535" -> "  %13276 = add nuw nsw i32 %13274, %13275"
"  %13275 = lshr i32 %13239, 16"
"  %13275 = lshr i32 %13239, 16" -> "  %13276 = add nuw nsw i32 %13274, %13275"
"  %13276 = add nuw nsw i32 %13274, %13275"
"  %13276 = add nuw nsw i32 %13274, %13275" -> "  %13280 = lshr i32 %13276, 16""  %13276 = add nuw nsw i32 %13274, %13275" -> "  %13278 = and i32 %13276, 65535"
"  %13277 = lshr i32 %13273, 16"
"  %13277 = lshr i32 %13273, 16" -> "  %13279 = add nuw nsw i32 %13278, %13277"
"  %13278 = and i32 %13276, 65535"
"  %13278 = and i32 %13276, 65535" -> "  %13279 = add nuw nsw i32 %13278, %13277"
"  %13279 = add nuw nsw i32 %13278, %13277"
"  %13279 = add nuw nsw i32 %13278, %13277" -> "  %13425 = and i32 %13279, 65535""  %13279 = add nuw nsw i32 %13278, %13277" -> "  %13285 = lshr i32 %13279, 16"
"  %13280 = lshr i32 %13276, 16"
"  %13280 = lshr i32 %13276, 16" -> "  %13282 = add nuw nsw i32 %13280, %13281"
"  %13281 = and i32 %13270, 65535"
"  %13281 = and i32 %13270, 65535" -> "  %13282 = add nuw nsw i32 %13280, %13281"
"  %13282 = add nuw nsw i32 %13280, %13281"
"  %13282 = add nuw nsw i32 %13280, %13281" -> "  %13284 = add nuw i32 %13282, %13283"
"  %13283 = and i32 %13270, -65536"
"  %13283 = and i32 %13270, -65536" -> "  %13284 = add nuw i32 %13282, %13283"
"  %13284 = add nuw i32 %13282, %13283"
"  %13284 = add nuw i32 %13282, %13283" -> "  %13286 = add nuw i32 %13284, %13285"
"  %13285 = lshr i32 %13279, 16"
"  %13285 = lshr i32 %13279, 16" -> "  %13286 = add nuw i32 %13284, %13285"
"  %13286 = add nuw i32 %13284, %13285"
"  %13286 = add nuw i32 %13284, %13285" -> "  %13433 = and i32 %13286, 65535""  %13286 = add nuw i32 %13284, %13285" -> "  %13436 = lshr i32 %13286, 16"
"  %13287 = and i32 %12922, 65535"
"  %13287 = and i32 %12922, 65535" -> "  %16547 = add nuw nsw i32 %16546, %13287""  %13287 = and i32 %12922, 65535" -> "  %13288 = mul nuw i32 %13287, 37996""  %13287 = and i32 %12922, 65535" -> "  %13296 = mul nuw i32 %13287, 45147""  %13287 = and i32 %12922, 65535" -> "  %13350 = mul nuw i32 %13287, 62728""  %13287 = and i32 %12922, 65535" -> "  %13343 = mul nuw nsw i32 %13287, 1324""  %13287 = and i32 %12922, 65535" -> "  %13680 = mul nuw i32 %13287, 42170""  %13287 = and i32 %12922, 65535" -> "  %13673 = mul nuw nsw i32 %13287, 31112""  %13287 = and i32 %12922, 65535" -> "  %13631 = mul nuw i32 %13287, 46547""  %13287 = and i32 %12922, 65535" -> "  %13624 = mul nuw nsw i32 %13287, 17857""  %13287 = and i32 %12922, 65535" -> "  %14778 = mul nuw nsw i32 %13287, 29744""  %13287 = and i32 %12922, 65535" -> "  %14771 = mul nuw nsw i32 %13287, 24315""  %13287 = and i32 %12922, 65535" -> "  %14729 = mul nuw nsw i32 %13287, 9871""  %13287 = and i32 %12922, 65535" -> "  %14722 = mul nuw i32 %13287, 42779""  %13287 = and i32 %12922, 65535" -> "  %15108 = mul nuw i32 %13287, 36786""  %13287 = and i32 %12922, 65535" -> "  %15101 = mul nuw nsw i32 %13287, 21884""  %13287 = and i32 %12922, 65535" -> "  %15059 = mul nuw nsw i32 %13287, 11561""  %13287 = and i32 %12922, 65535" -> "  %15052 = mul nuw nsw i32 %13287, 4087"
"  %13288 = mul nuw i32 %13287, 37996"
"  %13288 = mul nuw i32 %13287, 37996" -> "  %13421 = and i32 %13288, 65532""  %13288 = mul nuw i32 %13287, 37996" -> "  %13289 = lshr i32 %13288, 16"
"  %13289 = lshr i32 %13288, 16"
"  %13289 = lshr i32 %13288, 16" -> "  %13293 = add nuw nsw i32 %13292, %13289"
"  %13290 = and i32 %12928, 65535"
"  %13290 = and i32 %12928, 65535" -> "  %16549 = add nuw nsw i32 %16548, %13290""  %13290 = and i32 %12928, 65535" -> "  %13291 = mul nuw i32 %13290, 37996""  %13290 = and i32 %12928, 65535" -> "  %13300 = mul nuw i32 %13290, 45147""  %13290 = and i32 %12928, 65535" -> "  %13354 = mul nuw i32 %13290, 62728""  %13290 = and i32 %12928, 65535" -> "  %13345 = mul nuw nsw i32 %13290, 1324""  %13290 = and i32 %12928, 65535" -> "  %13684 = mul nuw i32 %13290, 42170""  %13290 = and i32 %12928, 65535" -> "  %13675 = mul nuw nsw i32 %13290, 31112""  %13290 = and i32 %12928, 65535" -> "  %13635 = mul nuw i32 %13290, 46547""  %13290 = and i32 %12928, 65535" -> "  %13626 = mul nuw nsw i32 %13290, 17857""  %13290 = and i32 %12928, 65535" -> "  %14782 = mul nuw nsw i32 %13290, 29744""  %13290 = and i32 %12928, 65535" -> "  %14773 = mul nuw nsw i32 %13290, 24315""  %13290 = and i32 %12928, 65535" -> "  %14733 = mul nuw nsw i32 %13290, 9871""  %13290 = and i32 %12928, 65535" -> "  %14724 = mul nuw i32 %13290, 42779""  %13290 = and i32 %12928, 65535" -> "  %15112 = mul nuw i32 %13290, 36786""  %13290 = and i32 %12928, 65535" -> "  %15103 = mul nuw nsw i32 %13290, 21884""  %13290 = and i32 %12928, 65535" -> "  %15063 = mul nuw nsw i32 %13290, 11561""  %13290 = and i32 %12928, 65535" -> "  %15054 = mul nuw nsw i32 %13290, 4087"
"  %13291 = mul nuw i32 %13290, 37996"
"  %13291 = mul nuw i32 %13290, 37996" -> "  %13294 = and i32 %13291, -65536""  %13291 = mul nuw i32 %13290, 37996" -> "  %13292 = and i32 %13291, 65532"
"  %13292 = and i32 %13291, 65532"
"  %13292 = and i32 %13291, 65532" -> "  %13293 = add nuw nsw i32 %13292, %13289"
"  %13293 = add nuw nsw i32 %13292, %13289"
"  %13293 = add nuw nsw i32 %13292, %13289" -> "  %13295 = add nuw i32 %13293, %13294"
"  %13294 = and i32 %13291, -65536"
"  %13294 = and i32 %13291, -65536" -> "  %13295 = add nuw i32 %13293, %13294"
"  %13295 = add nuw i32 %13293, %13294"
"  %13295 = add nuw i32 %13293, %13294" -> "  %13299 = lshr i32 %13295, 16""  %13295 = add nuw i32 %13293, %13294" -> "  %13297 = and i32 %13295, 65535"
"  %13296 = mul nuw i32 %13287, 45147"
"  %13296 = mul nuw i32 %13287, 45147" -> "  %13298 = add nuw i32 %13297, %13296"
"  %13297 = and i32 %13295, 65535"
"  %13297 = and i32 %13295, 65535" -> "  %13298 = add nuw i32 %13297, %13296"
"  %13298 = add nuw i32 %13297, %13296"
"  %13298 = add nuw i32 %13297, %13296" -> "  %13424 = and i32 %13298, 65535""  %13298 = add nuw i32 %13297, %13296" -> "  %13302 = lshr i32 %13298, 16"
"  %13299 = lshr i32 %13295, 16"
"  %13299 = lshr i32 %13295, 16" -> "  %13301 = add nuw i32 %13299, %13300"
"  %13300 = mul nuw i32 %13290, 45147"
"  %13300 = mul nuw i32 %13290, 45147" -> "  %13301 = add nuw i32 %13299, %13300"
"  %13301 = add nuw i32 %13299, %13300"
"  %13301 = add nuw i32 %13299, %13300" -> "  %13305 = and i32 %13301, -65536""  %13301 = add nuw i32 %13299, %13300" -> "  %13303 = and i32 %13301, 65535"
"  %13302 = lshr i32 %13298, 16"
"  %13302 = lshr i32 %13298, 16" -> "  %13304 = add nuw nsw i32 %13302, %13303"
"  %13303 = and i32 %13301, 65535"
"  %13303 = and i32 %13301, 65535" -> "  %13304 = add nuw nsw i32 %13302, %13303"
"  %13304 = add nuw nsw i32 %13302, %13303"
"  %13304 = add nuw nsw i32 %13302, %13303" -> "  %13306 = add nuw i32 %13304, %13305"
"  %13305 = and i32 %13301, -65536"
"  %13305 = and i32 %13301, -65536" -> "  %13306 = add nuw i32 %13304, %13305"
"  %13306 = add nuw i32 %13304, %13305"
"  %13306 = add nuw i32 %13304, %13305" -> "  %13327 = and i32 %13306, 65535""  %13306 = add nuw i32 %13304, %13305" -> "  %13331 = lshr i32 %13306, 16"
"  %13307 = and i32 %12942, 65535"
"  %13307 = and i32 %12942, 65535" -> "  %16556 = add nuw nsw i32 %16555, %13307""  %13307 = and i32 %12942, 65535" -> "  %15070 = mul nuw nsw i32 %13307, 4087""  %13307 = and i32 %12942, 65535" -> "  %13308 = mul nuw i32 %13307, 37996""  %13307 = and i32 %12942, 65535" -> "  %13316 = mul nuw i32 %13307, 45147""  %13307 = and i32 %12942, 65535" -> "  %13374 = mul nuw nsw i32 %13307, 1324""  %13307 = and i32 %12942, 65535" -> "  %13381 = mul nuw i32 %13307, 62728""  %13307 = and i32 %12942, 65535" -> "  %13711 = mul nuw i32 %13307, 42170""  %13307 = and i32 %12942, 65535" -> "  %13704 = mul nuw nsw i32 %13307, 31112""  %13307 = and i32 %12942, 65535" -> "  %13649 = mul nuw i32 %13307, 46547""  %13307 = and i32 %12942, 65535" -> "  %13642 = mul nuw nsw i32 %13307, 17857""  %13307 = and i32 %12942, 65535" -> "  %14809 = mul nuw nsw i32 %13307, 29744""  %13307 = and i32 %12942, 65535" -> "  %14802 = mul nuw nsw i32 %13307, 24315""  %13307 = and i32 %12942, 65535" -> "  %14747 = mul nuw nsw i32 %13307, 9871""  %13307 = and i32 %12942, 65535" -> "  %14740 = mul nuw i32 %13307, 42779""  %13307 = and i32 %12942, 65535" -> "  %15139 = mul nuw i32 %13307, 36786""  %13307 = and i32 %12942, 65535" -> "  %15132 = mul nuw nsw i32 %13307, 21884""  %13307 = and i32 %12942, 65535" -> "  %15077 = mul nuw nsw i32 %13307, 11561"
"  %13308 = mul nuw i32 %13307, 37996"
"  %13308 = mul nuw i32 %13307, 37996" -> "  %13328 = and i32 %13308, 65532""  %13308 = mul nuw i32 %13307, 37996" -> "  %13309 = lshr i32 %13308, 16"
"  %13309 = lshr i32 %13308, 16"
"  %13309 = lshr i32 %13308, 16" -> "  %13313 = add nuw nsw i32 %13312, %13309"
"  %13310 = and i32 %12945, 65535"
"  %13310 = and i32 %12945, 65535" -> "  %13311 = mul nuw i32 %13310, 37996""  %13310 = and i32 %12945, 65535" -> "  %13320 = mul nuw i32 %13310, 45147""  %13310 = and i32 %12945, 65535" -> "  %13376 = mul nuw nsw i32 %13310, 1324""  %13310 = and i32 %12945, 65535" -> "  %13385 = mul nuw i32 %13310, 62728""  %13310 = and i32 %12945, 65535" -> "  %13715 = mul nuw i32 %13310, 42170""  %13310 = and i32 %12945, 65535" -> "  %13706 = mul nuw nsw i32 %13310, 31112""  %13310 = and i32 %12945, 65535" -> "  %13653 = mul nuw i32 %13310, 46547""  %13310 = and i32 %12945, 65535" -> "  %13644 = mul nuw nsw i32 %13310, 17857""  %13310 = and i32 %12945, 65535" -> "  %14751 = mul nuw nsw i32 %13310, 9871""  %13310 = and i32 %12945, 65535" -> "  %14742 = mul nuw i32 %13310, 42779""  %13310 = and i32 %12945, 65535" -> "  %14813 = mul nuw nsw i32 %13310, 29744""  %13310 = and i32 %12945, 65535" -> "  %14804 = mul nuw nsw i32 %13310, 24315""  %13310 = and i32 %12945, 65535" -> "  %15143 = mul nuw i32 %13310, 36786""  %13310 = and i32 %12945, 65535" -> "  %15134 = mul nuw nsw i32 %13310, 21884""  %13310 = and i32 %12945, 65535" -> "  %15081 = mul nuw nsw i32 %13310, 11561""  %13310 = and i32 %12945, 65535" -> "  %15072 = mul nuw nsw i32 %13310, 4087"
"  %13311 = mul nuw i32 %13310, 37996"
"  %13311 = mul nuw i32 %13310, 37996" -> "  %13314 = and i32 %13311, -65536""  %13311 = mul nuw i32 %13310, 37996" -> "  %13312 = and i32 %13311, 65532"
"  %13312 = and i32 %13311, 65532"
"  %13312 = and i32 %13311, 65532" -> "  %13313 = add nuw nsw i32 %13312, %13309"
"  %13313 = add nuw nsw i32 %13312, %13309"
"  %13313 = add nuw nsw i32 %13312, %13309" -> "  %13315 = add nuw i32 %13313, %13314"
"  %13314 = and i32 %13311, -65536"
"  %13314 = and i32 %13311, -65536" -> "  %13315 = add nuw i32 %13313, %13314"
"  %13315 = add nuw i32 %13313, %13314"
"  %13315 = add nuw i32 %13313, %13314" -> "  %13319 = lshr i32 %13315, 16""  %13315 = add nuw i32 %13313, %13314" -> "  %13317 = and i32 %13315, 65535"
"  %13316 = mul nuw i32 %13307, 45147"
"  %13316 = mul nuw i32 %13307, 45147" -> "  %13318 = add nuw i32 %13317, %13316"
"  %13317 = and i32 %13315, 65535"
"  %13317 = and i32 %13315, 65535" -> "  %13318 = add nuw i32 %13317, %13316"
"  %13318 = add nuw i32 %13317, %13316"
"  %13318 = add nuw i32 %13317, %13316" -> "  %13330 = and i32 %13318, 65535""  %13318 = add nuw i32 %13317, %13316" -> "  %13322 = lshr i32 %13318, 16"
"  %13319 = lshr i32 %13315, 16"
"  %13319 = lshr i32 %13315, 16" -> "  %13321 = add nuw i32 %13319, %13320"
"  %13320 = mul nuw i32 %13310, 45147"
"  %13320 = mul nuw i32 %13310, 45147" -> "  %13321 = add nuw i32 %13319, %13320"
"  %13321 = add nuw i32 %13319, %13320"
"  %13321 = add nuw i32 %13319, %13320" -> "  %13325 = and i32 %13321, -65536""  %13321 = add nuw i32 %13319, %13320" -> "  %13323 = and i32 %13321, 65535"
"  %13322 = lshr i32 %13318, 16"
"  %13322 = lshr i32 %13318, 16" -> "  %13324 = add nuw nsw i32 %13322, %13323"
"  %13323 = and i32 %13321, 65535"
"  %13323 = and i32 %13321, 65535" -> "  %13324 = add nuw nsw i32 %13322, %13323"
"  %13324 = add nuw nsw i32 %13322, %13323"
"  %13324 = add nuw nsw i32 %13322, %13323" -> "  %13326 = add nuw i32 %13324, %13325"
"  %13325 = and i32 %13321, -65536"
"  %13325 = and i32 %13321, -65536" -> "  %13326 = add nuw i32 %13324, %13325"
"  %13326 = add nuw i32 %13324, %13325"
"  %13326 = add nuw i32 %13324, %13325" -> "  %13339 = and i32 %13326, -65536""  %13326 = add nuw i32 %13324, %13325" -> "  %13337 = and i32 %13326, 65535"
"  %13327 = and i32 %13306, 65535"
"  %13327 = and i32 %13306, 65535" -> "  %13329 = add nuw nsw i32 %13327, %13328"
"  %13328 = and i32 %13308, 65532"
"  %13328 = and i32 %13308, 65532" -> "  %13329 = add nuw nsw i32 %13327, %13328"
"  %13329 = add nuw nsw i32 %13327, %13328"
"  %13329 = add nuw nsw i32 %13327, %13328" -> "  %13361 = and i32 %13329, 65535""  %13329 = add nuw nsw i32 %13327, %13328" -> "  %13333 = lshr i32 %13329, 16"
"  %13330 = and i32 %13318, 65535"
"  %13330 = and i32 %13318, 65535" -> "  %13332 = add nuw nsw i32 %13330, %13331"
"  %13331 = lshr i32 %13306, 16"
"  %13331 = lshr i32 %13306, 16" -> "  %13332 = add nuw nsw i32 %13330, %13331"
"  %13332 = add nuw nsw i32 %13330, %13331"
"  %13332 = add nuw nsw i32 %13330, %13331" -> "  %13336 = lshr i32 %13332, 16""  %13332 = add nuw nsw i32 %13330, %13331" -> "  %13334 = and i32 %13332, 65535"
"  %13333 = lshr i32 %13329, 16"
"  %13333 = lshr i32 %13329, 16" -> "  %13335 = add nuw nsw i32 %13334, %13333"
"  %13334 = and i32 %13332, 65535"
"  %13334 = and i32 %13332, 65535" -> "  %13335 = add nuw nsw i32 %13334, %13333"
"  %13335 = add nuw nsw i32 %13334, %13333"
"  %13335 = add nuw nsw i32 %13334, %13333" -> "  %13364 = and i32 %13335, 65535""  %13335 = add nuw nsw i32 %13334, %13333" -> "  %13341 = lshr i32 %13335, 16"
"  %13336 = lshr i32 %13332, 16"
"  %13336 = lshr i32 %13332, 16" -> "  %13338 = add nuw nsw i32 %13337, %13336"
"  %13337 = and i32 %13326, 65535"
"  %13337 = and i32 %13326, 65535" -> "  %13338 = add nuw nsw i32 %13337, %13336"
"  %13338 = add nuw nsw i32 %13337, %13336"
"  %13338 = add nuw nsw i32 %13337, %13336" -> "  %13340 = add nuw i32 %13338, %13339"
"  %13339 = and i32 %13326, -65536"
"  %13339 = and i32 %13326, -65536" -> "  %13340 = add nuw i32 %13338, %13339"
"  %13340 = add nuw i32 %13338, %13339"
"  %13340 = add nuw i32 %13338, %13339" -> "  %13342 = add nuw i32 %13340, %13341"
"  %13341 = lshr i32 %13335, 16"
"  %13341 = lshr i32 %13335, 16" -> "  %13342 = add nuw i32 %13340, %13341"
"  %13342 = add nuw i32 %13340, %13341"
"  %13342 = add nuw i32 %13340, %13341" -> "  %13396 = lshr i32 %13342, 16""  %13342 = add nuw i32 %13340, %13341" -> "  %13392 = and i32 %13342, 65535"
"  %13343 = mul nuw nsw i32 %13287, 1324"
"  %13343 = mul nuw nsw i32 %13287, 1324" -> "  %13362 = and i32 %13343, 65532""  %13343 = mul nuw nsw i32 %13287, 1324" -> "  %13344 = lshr i32 %13343, 16"
"  %13344 = lshr i32 %13343, 16"
"  %13344 = lshr i32 %13343, 16" -> "  %13347 = add nuw nsw i32 %13346, %13344"
"  %13345 = mul nuw nsw i32 %13290, 1324"
"  %13345 = mul nuw nsw i32 %13290, 1324" -> "  %13348 = and i32 %13345, 134152192""  %13345 = mul nuw nsw i32 %13290, 1324" -> "  %13346 = and i32 %13345, 65532"
"  %13346 = and i32 %13345, 65532"
"  %13346 = and i32 %13345, 65532" -> "  %13347 = add nuw nsw i32 %13346, %13344"
"  %13347 = add nuw nsw i32 %13346, %13344"
"  %13347 = add nuw nsw i32 %13346, %13344" -> "  %13349 = add nuw nsw i32 %13347, %13348"
"  %13348 = and i32 %13345, 134152192"
"  %13348 = and i32 %13345, 134152192" -> "  %13349 = add nuw nsw i32 %13347, %13348"
"  %13349 = add nuw nsw i32 %13347, %13348"
"  %13349 = add nuw nsw i32 %13347, %13348" -> "  %13353 = lshr i32 %13349, 16""  %13349 = add nuw nsw i32 %13347, %13348" -> "  %13351 = and i32 %13349, 65535"
"  %13350 = mul nuw i32 %13287, 62728"
"  %13350 = mul nuw i32 %13287, 62728" -> "  %13352 = add nuw i32 %13351, %13350"
"  %13351 = and i32 %13349, 65535"
"  %13351 = and i32 %13349, 65535" -> "  %13352 = add nuw i32 %13351, %13350"
"  %13352 = add nuw i32 %13351, %13350"
"  %13352 = add nuw i32 %13351, %13350" -> "  %13365 = and i32 %13352, 65535""  %13352 = add nuw i32 %13351, %13350" -> "  %13356 = lshr i32 %13352, 16"
"  %13353 = lshr i32 %13349, 16"
"  %13353 = lshr i32 %13349, 16" -> "  %13355 = add nuw i32 %13353, %13354"
"  %13354 = mul nuw i32 %13290, 62728"
"  %13354 = mul nuw i32 %13290, 62728" -> "  %13355 = add nuw i32 %13353, %13354"
"  %13355 = add nuw i32 %13353, %13354"
"  %13355 = add nuw i32 %13353, %13354" -> "  %13359 = and i32 %13355, -65536""  %13355 = add nuw i32 %13353, %13354" -> "  %13357 = and i32 %13355, 65535"
"  %13356 = lshr i32 %13352, 16"
"  %13356 = lshr i32 %13352, 16" -> "  %13358 = add nuw nsw i32 %13356, %13357"
"  %13357 = and i32 %13355, 65535"
"  %13357 = and i32 %13355, 65535" -> "  %13358 = add nuw nsw i32 %13356, %13357"
"  %13358 = add nuw nsw i32 %13356, %13357"
"  %13358 = add nuw nsw i32 %13356, %13357" -> "  %13360 = add nuw i32 %13358, %13359"
"  %13359 = and i32 %13355, -65536"
"  %13359 = and i32 %13355, -65536" -> "  %13360 = add nuw i32 %13358, %13359"
"  %13360 = add nuw i32 %13358, %13359"
"  %13360 = add nuw i32 %13358, %13359" -> "  %13368 = add nuw i32 %13360, %13367"
"  %13361 = and i32 %13329, 65535"
"  %13361 = and i32 %13329, 65535" -> "  %13363 = add nuw nsw i32 %13361, %13362"
"  %13362 = and i32 %13343, 65532"
"  %13362 = and i32 %13343, 65532" -> "  %13363 = add nuw nsw i32 %13361, %13362"
"  %13363 = add nuw nsw i32 %13361, %13362"
"  %13363 = add nuw nsw i32 %13361, %13362" -> "  %13432 = and i32 %13363, 65535""  %13363 = add nuw nsw i32 %13361, %13362" -> "  %13370 = lshr i32 %13363, 16"
"  %13364 = and i32 %13335, 65535"
"  %13364 = and i32 %13335, 65535" -> "  %13366 = add nuw nsw i32 %13364, %13365"
"  %13365 = and i32 %13352, 65535"
"  %13365 = and i32 %13352, 65535" -> "  %13366 = add nuw nsw i32 %13364, %13365"
"  %13366 = add nuw nsw i32 %13364, %13365"
"  %13366 = add nuw nsw i32 %13364, %13365" -> "  %13369 = and i32 %13366, 65535""  %13366 = add nuw nsw i32 %13364, %13365" -> "  %13367 = lshr i32 %13366, 16"
"  %13367 = lshr i32 %13366, 16"
"  %13367 = lshr i32 %13366, 16" -> "  %13368 = add nuw i32 %13360, %13367"
"  %13368 = add nuw i32 %13360, %13367"
"  %13368 = add nuw i32 %13360, %13367" -> "  %13373 = add nuw i32 %13368, %13372"
"  %13369 = and i32 %13366, 65535"
"  %13369 = and i32 %13366, 65535" -> "  %13371 = add nuw nsw i32 %13369, %13370"
"  %13370 = lshr i32 %13363, 16"
"  %13370 = lshr i32 %13363, 16" -> "  %13371 = add nuw nsw i32 %13369, %13370"
"  %13371 = add nuw nsw i32 %13369, %13370"
"  %13371 = add nuw nsw i32 %13369, %13370" -> "  %13435 = and i32 %13371, 65535""  %13371 = add nuw nsw i32 %13369, %13370" -> "  %13372 = lshr i32 %13371, 16"
"  %13372 = lshr i32 %13371, 16"
"  %13372 = lshr i32 %13371, 16" -> "  %13373 = add nuw i32 %13368, %13372"
"  %13373 = add nuw i32 %13368, %13372"
"  %13373 = add nuw i32 %13368, %13372" -> "  %13409 = lshr i32 %13373, 16""  %13373 = add nuw i32 %13368, %13372" -> "  %13406 = and i32 %13373, 65535"
"  %13374 = mul nuw nsw i32 %13307, 1324"
"  %13374 = mul nuw nsw i32 %13307, 1324" -> "  %13393 = and i32 %13374, 65532""  %13374 = mul nuw nsw i32 %13307, 1324" -> "  %13375 = lshr i32 %13374, 16"
"  %13375 = lshr i32 %13374, 16"
"  %13375 = lshr i32 %13374, 16" -> "  %13378 = add nuw nsw i32 %13377, %13375"
"  %13376 = mul nuw nsw i32 %13310, 1324"
"  %13376 = mul nuw nsw i32 %13310, 1324" -> "  %13379 = and i32 %13376, 134152192""  %13376 = mul nuw nsw i32 %13310, 1324" -> "  %13377 = and i32 %13376, 65532"
"  %13377 = and i32 %13376, 65532"
"  %13377 = and i32 %13376, 65532" -> "  %13378 = add nuw nsw i32 %13377, %13375"
"  %13378 = add nuw nsw i32 %13377, %13375"
"  %13378 = add nuw nsw i32 %13377, %13375" -> "  %13380 = add nuw nsw i32 %13378, %13379"
"  %13379 = and i32 %13376, 134152192"
"  %13379 = and i32 %13376, 134152192" -> "  %13380 = add nuw nsw i32 %13378, %13379"
"  %13380 = add nuw nsw i32 %13378, %13379"
"  %13380 = add nuw nsw i32 %13378, %13379" -> "  %13384 = lshr i32 %13380, 16""  %13380 = add nuw nsw i32 %13378, %13379" -> "  %13382 = and i32 %13380, 65535"
"  %13381 = mul nuw i32 %13307, 62728"
"  %13381 = mul nuw i32 %13307, 62728" -> "  %13383 = add nuw i32 %13382, %13381"
"  %13382 = and i32 %13380, 65535"
"  %13382 = and i32 %13380, 65535" -> "  %13383 = add nuw i32 %13382, %13381"
"  %13383 = add nuw i32 %13382, %13381"
"  %13383 = add nuw i32 %13382, %13381" -> "  %13395 = and i32 %13383, 65535""  %13383 = add nuw i32 %13382, %13381" -> "  %13387 = lshr i32 %13383, 16"
"  %13384 = lshr i32 %13380, 16"
"  %13384 = lshr i32 %13380, 16" -> "  %13386 = add nuw i32 %13384, %13385"
"  %13385 = mul nuw i32 %13310, 62728"
"  %13385 = mul nuw i32 %13310, 62728" -> "  %13386 = add nuw i32 %13384, %13385"
"  %13386 = add nuw i32 %13384, %13385"
"  %13386 = add nuw i32 %13384, %13385" -> "  %13390 = and i32 %13386, -65536""  %13386 = add nuw i32 %13384, %13385" -> "  %13388 = and i32 %13386, 65535"
"  %13387 = lshr i32 %13383, 16"
"  %13387 = lshr i32 %13383, 16" -> "  %13389 = add nuw nsw i32 %13387, %13388"
"  %13388 = and i32 %13386, 65535"
"  %13388 = and i32 %13386, 65535" -> "  %13389 = add nuw nsw i32 %13387, %13388"
"  %13389 = add nuw nsw i32 %13387, %13388"
"  %13389 = add nuw nsw i32 %13387, %13388" -> "  %13391 = add nuw i32 %13389, %13390"
"  %13390 = and i32 %13386, -65536"
"  %13390 = and i32 %13386, -65536" -> "  %13391 = add nuw i32 %13389, %13390"
"  %13391 = add nuw i32 %13389, %13390"
"  %13391 = add nuw i32 %13389, %13390" -> "  %13399 = add nuw i32 %13391, %13398"
"  %13392 = and i32 %13342, 65535"
"  %13392 = and i32 %13342, 65535" -> "  %13394 = add nuw nsw i32 %13392, %13393"
"  %13393 = and i32 %13374, 65532"
"  %13393 = and i32 %13374, 65532" -> "  %13394 = add nuw nsw i32 %13392, %13393"
"  %13394 = add nuw nsw i32 %13392, %13393"
"  %13394 = add nuw nsw i32 %13392, %13393" -> "  %13405 = and i32 %13394, 65535""  %13394 = add nuw nsw i32 %13392, %13393" -> "  %13401 = lshr i32 %13394, 16"
"  %13395 = and i32 %13383, 65535"
"  %13395 = and i32 %13383, 65535" -> "  %13397 = add nuw nsw i32 %13396, %13395"
"  %13396 = lshr i32 %13342, 16"
"  %13396 = lshr i32 %13342, 16" -> "  %13397 = add nuw nsw i32 %13396, %13395"
"  %13397 = add nuw nsw i32 %13396, %13395"
"  %13397 = add nuw nsw i32 %13396, %13395" -> "  %13400 = and i32 %13397, 65535""  %13397 = add nuw nsw i32 %13396, %13395" -> "  %13398 = lshr i32 %13397, 16"
"  %13398 = lshr i32 %13397, 16"
"  %13398 = lshr i32 %13397, 16" -> "  %13399 = add nuw i32 %13391, %13398"
"  %13399 = add nuw i32 %13391, %13398"
"  %13399 = add nuw i32 %13391, %13398" -> "  %13404 = add nuw i32 %13399, %13403"
"  %13400 = and i32 %13397, 65535"
"  %13400 = and i32 %13397, 65535" -> "  %13402 = add nuw nsw i32 %13400, %13401"
"  %13401 = lshr i32 %13394, 16"
"  %13401 = lshr i32 %13394, 16" -> "  %13402 = add nuw nsw i32 %13400, %13401"
"  %13402 = add nuw nsw i32 %13400, %13401"
"  %13402 = add nuw nsw i32 %13400, %13401" -> "  %13408 = and i32 %13402, 65535""  %13402 = add nuw nsw i32 %13400, %13401" -> "  %13403 = lshr i32 %13402, 16"
"  %13403 = lshr i32 %13402, 16"
"  %13403 = lshr i32 %13402, 16" -> "  %13404 = add nuw i32 %13399, %13403"
"  %13404 = add nuw i32 %13399, %13403"
"  %13404 = add nuw i32 %13399, %13403" -> "  %13417 = and i32 %13404, -65536""  %13404 = add nuw i32 %13399, %13403" -> "  %13415 = and i32 %13404, 65535"
"  %13405 = and i32 %13394, 65535"
"  %13405 = and i32 %13394, 65535" -> "  %13407 = add nuw nsw i32 %13406, %13405"
"  %13406 = and i32 %13373, 65535"
"  %13406 = and i32 %13373, 65535" -> "  %13407 = add nuw nsw i32 %13406, %13405"
"  %13407 = add nuw nsw i32 %13406, %13405"
"  %13407 = add nuw nsw i32 %13406, %13405" -> "  %13447 = and i32 %13407, 65535""  %13407 = add nuw nsw i32 %13406, %13405" -> "  %13411 = lshr i32 %13407, 16"
"  %13408 = and i32 %13402, 65535"
"  %13408 = and i32 %13402, 65535" -> "  %13410 = add nuw nsw i32 %13408, %13409"
"  %13409 = lshr i32 %13373, 16"
"  %13409 = lshr i32 %13373, 16" -> "  %13410 = add nuw nsw i32 %13408, %13409"
"  %13410 = add nuw nsw i32 %13408, %13409"
"  %13410 = add nuw nsw i32 %13408, %13409" -> "  %13414 = lshr i32 %13410, 16""  %13410 = add nuw nsw i32 %13408, %13409" -> "  %13412 = and i32 %13410, 65535"
"  %13411 = lshr i32 %13407, 16"
"  %13411 = lshr i32 %13407, 16" -> "  %13413 = add nuw nsw i32 %13412, %13411"
"  %13412 = and i32 %13410, 65535"
"  %13412 = and i32 %13410, 65535" -> "  %13413 = add nuw nsw i32 %13412, %13411"
"  %13413 = add nuw nsw i32 %13412, %13411"
"  %13413 = add nuw nsw i32 %13412, %13411" -> "  %13454 = and i32 %13413, 65535""  %13413 = add nuw nsw i32 %13412, %13411" -> "  %13419 = lshr i32 %13413, 16"
"  %13414 = lshr i32 %13410, 16"
"  %13414 = lshr i32 %13410, 16" -> "  %13416 = add nuw nsw i32 %13414, %13415"
"  %13415 = and i32 %13404, 65535"
"  %13415 = and i32 %13404, 65535" -> "  %13416 = add nuw nsw i32 %13414, %13415"
"  %13416 = add nuw nsw i32 %13414, %13415"
"  %13416 = add nuw nsw i32 %13414, %13415" -> "  %13418 = add nuw i32 %13416, %13417"
"  %13417 = and i32 %13404, -65536"
"  %13417 = and i32 %13404, -65536" -> "  %13418 = add nuw i32 %13416, %13417"
"  %13418 = add nuw i32 %13416, %13417"
"  %13418 = add nuw i32 %13416, %13417" -> "  %13420 = add nuw i32 %13418, %13419"
"  %13419 = lshr i32 %13413, 16"
"  %13419 = lshr i32 %13413, 16" -> "  %13420 = add nuw i32 %13418, %13419"
"  %13420 = add nuw i32 %13418, %13419"
"  %13420 = add nuw i32 %13418, %13419" -> "  %13458 = add nuw i32 %13420, %13457"
"  %13421 = and i32 %13288, 65532"
"  %13421 = and i32 %13288, 65532" -> "  %13423 = add nuw nsw i32 %13422, %13421"
"  %13422 = and i32 %13273, 65535"
"  %13422 = and i32 %13273, 65535" -> "  %13423 = add nuw nsw i32 %13422, %13421"
"  %13423 = add nuw nsw i32 %13422, %13421"
"  %13423 = add nuw nsw i32 %13422, %13421" -> "  %13587 = and i32 %13423, 65535""  %13423 = add nuw nsw i32 %13422, %13421" -> "  %13427 = lshr i32 %13423, 16"
"  %13424 = and i32 %13298, 65535"
"  %13424 = and i32 %13298, 65535" -> "  %13426 = add nuw nsw i32 %13425, %13424"
"  %13425 = and i32 %13279, 65535"
"  %13425 = and i32 %13279, 65535" -> "  %13426 = add nuw nsw i32 %13425, %13424"
"  %13426 = add nuw nsw i32 %13425, %13424"
"  %13426 = add nuw nsw i32 %13425, %13424" -> "  %13430 = lshr i32 %13426, 16""  %13426 = add nuw nsw i32 %13425, %13424" -> "  %13428 = and i32 %13426, 65535"
"  %13427 = lshr i32 %13423, 16"
"  %13427 = lshr i32 %13423, 16" -> "  %13429 = add nuw nsw i32 %13428, %13427"
"  %13428 = and i32 %13426, 65535"
"  %13428 = and i32 %13426, 65535" -> "  %13429 = add nuw nsw i32 %13428, %13427"
"  %13429 = add nuw nsw i32 %13428, %13427"
"  %13429 = add nuw nsw i32 %13428, %13427" -> "  %13590 = and i32 %13429, 65535""  %13429 = add nuw nsw i32 %13428, %13427" -> "  %13431 = lshr i32 %13429, 16"
"  %13430 = lshr i32 %13426, 16"
"  %13430 = lshr i32 %13426, 16" -> "  %13442 = add nuw nsw i32 %13431, %13430"
"  %13431 = lshr i32 %13429, 16"
"  %13431 = lshr i32 %13429, 16" -> "  %13442 = add nuw nsw i32 %13431, %13430"
"  %13432 = and i32 %13363, 65535"
"  %13432 = and i32 %13363, 65535" -> "  %13434 = add nuw nsw i32 %13432, %13433"
"  %13433 = and i32 %13286, 65535"
"  %13433 = and i32 %13286, 65535" -> "  %13434 = add nuw nsw i32 %13432, %13433"
"  %13434 = add nuw nsw i32 %13432, %13433"
"  %13434 = add nuw nsw i32 %13432, %13433" -> "  %13441 = and i32 %13434, 65535""  %13434 = add nuw nsw i32 %13432, %13433" -> "  %13438 = lshr i32 %13434, 16"
"  %13435 = and i32 %13371, 65535"
"  %13435 = and i32 %13371, 65535" -> "  %13437 = add nuw nsw i32 %13435, %13436"
"  %13436 = lshr i32 %13286, 16"
"  %13436 = lshr i32 %13286, 16" -> "  %13437 = add nuw nsw i32 %13435, %13436"
"  %13437 = add nuw nsw i32 %13435, %13436"
"  %13437 = add nuw nsw i32 %13435, %13436" -> "  %13448 = lshr i32 %13437, 16""  %13437 = add nuw nsw i32 %13435, %13436" -> "  %13439 = and i32 %13437, 65535"
"  %13438 = lshr i32 %13434, 16"
"  %13438 = lshr i32 %13434, 16" -> "  %13440 = add nuw nsw i32 %13439, %13438"
"  %13439 = and i32 %13437, 65535"
"  %13439 = and i32 %13437, 65535" -> "  %13440 = add nuw nsw i32 %13439, %13438"
"  %13440 = add nuw nsw i32 %13439, %13438"
"  %13440 = add nuw nsw i32 %13439, %13438" -> "  %13450 = lshr i32 %13440, 16""  %13440 = add nuw nsw i32 %13439, %13438" -> "  %13445 = and i32 %13440, 65535"
"  %13441 = and i32 %13434, 65535"
"  %13441 = and i32 %13434, 65535" -> "  %13443 = add nuw nsw i32 %13442, %13441"
"  %13442 = add nuw nsw i32 %13431, %13430"
"  %13442 = add nuw nsw i32 %13431, %13430" -> "  %13443 = add nuw nsw i32 %13442, %13441"
"  %13443 = add nuw nsw i32 %13442, %13441"
"  %13443 = add nuw nsw i32 %13442, %13441" -> "  %13598 = and i32 %13443, 65535""  %13443 = add nuw nsw i32 %13442, %13441" -> "  %13444 = lshr i32 %13443, 16"
"  %13444 = lshr i32 %13443, 16"
"  %13444 = lshr i32 %13443, 16" -> "  %13446 = add nuw nsw i32 %13445, %13444"
"  %13445 = and i32 %13440, 65535"
"  %13445 = and i32 %13440, 65535" -> "  %13446 = add nuw nsw i32 %13445, %13444"
"  %13446 = add nuw nsw i32 %13445, %13444"
"  %13446 = add nuw nsw i32 %13445, %13444" -> "  %13601 = and i32 %13446, 65535""  %13446 = add nuw nsw i32 %13445, %13444" -> "  %13452 = lshr i32 %13446, 16"
"  %13447 = and i32 %13407, 65535"
"  %13447 = and i32 %13407, 65535" -> "  %13449 = add nuw nsw i32 %13447, %13448"
"  %13448 = lshr i32 %13437, 16"
"  %13448 = lshr i32 %13437, 16" -> "  %13449 = add nuw nsw i32 %13447, %13448"
"  %13449 = add nuw nsw i32 %13447, %13448"
"  %13449 = add nuw nsw i32 %13447, %13448" -> "  %13451 = add nuw nsw i32 %13449, %13450"
"  %13450 = lshr i32 %13440, 16"
"  %13450 = lshr i32 %13440, 16" -> "  %13451 = add nuw nsw i32 %13449, %13450"
"  %13451 = add nuw nsw i32 %13449, %13450"
"  %13451 = add nuw nsw i32 %13449, %13450" -> "  %13453 = add nuw nsw i32 %13451, %13452"
"  %13452 = lshr i32 %13446, 16"
"  %13452 = lshr i32 %13446, 16" -> "  %13453 = add nuw nsw i32 %13451, %13452"
"  %13453 = add nuw nsw i32 %13451, %13452"
"  %13453 = add nuw nsw i32 %13451, %13452" -> "  %13752 = and i32 %13453, 65535""  %13453 = add nuw nsw i32 %13451, %13452" -> "  %13455 = lshr i32 %13453, 16"
"  %13454 = and i32 %13413, 65535"
"  %13454 = and i32 %13413, 65535" -> "  %13456 = add nuw nsw i32 %13455, %13454"
"  %13455 = lshr i32 %13453, 16"
"  %13455 = lshr i32 %13453, 16" -> "  %13456 = add nuw nsw i32 %13455, %13454"
"  %13456 = add nuw nsw i32 %13455, %13454"
"  %13456 = add nuw nsw i32 %13455, %13454" -> "  %13755 = and i32 %13456, 65535""  %13456 = add nuw nsw i32 %13455, %13454" -> "  %13457 = lshr i32 %13456, 16"
"  %13457 = lshr i32 %13456, 16"
"  %13457 = lshr i32 %13456, 16" -> "  %13458 = add nuw i32 %13420, %13457"
"  %13458 = add nuw i32 %13420, %13457"
"  %13458 = add nuw i32 %13420, %13457" -> "  %13761 = and i32 %13458, 65535""  %13458 = add nuw i32 %13420, %13457" -> "  %13764 = lshr i32 %13458, 16"
"  %13459 = mul nuw nsw i32 %13153, 17857"
"  %13459 = mul nuw nsw i32 %13153, 17857" -> "  %13460 = lshr i32 %13459, 16""  %13459 = mul nuw nsw i32 %13153, 17857" -> "  %13586 = and i32 %13459, 65535"
"  %13460 = lshr i32 %13459, 16"
"  %13460 = lshr i32 %13459, 16" -> "  %13463 = add nuw nsw i32 %13462, %13460"
"  %13461 = mul nuw nsw i32 %13156, 17857"
"  %13461 = mul nuw nsw i32 %13156, 17857" -> "  %13464 = and i32 %13461, 2147418112""  %13461 = mul nuw nsw i32 %13156, 17857" -> "  %13462 = and i32 %13461, 65535"
"  %13462 = and i32 %13461, 65535"
"  %13462 = and i32 %13461, 65535" -> "  %13463 = add nuw nsw i32 %13462, %13460"
"  %13463 = add nuw nsw i32 %13462, %13460"
"  %13463 = add nuw nsw i32 %13462, %13460" -> "  %13465 = add nuw nsw i32 %13463, %13464"
"  %13464 = and i32 %13461, 2147418112"
"  %13464 = and i32 %13461, 2147418112" -> "  %13465 = add nuw nsw i32 %13463, %13464"
"  %13465 = add nuw nsw i32 %13463, %13464"
"  %13465 = add nuw nsw i32 %13463, %13464" -> "  %13469 = lshr i32 %13465, 16""  %13465 = add nuw nsw i32 %13463, %13464" -> "  %13467 = and i32 %13465, 65535"
"  %13466 = mul nuw i32 %13153, 46547"
"  %13466 = mul nuw i32 %13153, 46547" -> "  %13468 = add nuw i32 %13467, %13466"
"  %13467 = and i32 %13465, 65535"
"  %13467 = and i32 %13465, 65535" -> "  %13468 = add nuw i32 %13467, %13466"
"  %13468 = add nuw i32 %13467, %13466"
"  %13468 = add nuw i32 %13467, %13466" -> "  %13589 = and i32 %13468, 65535""  %13468 = add nuw i32 %13467, %13466" -> "  %13472 = lshr i32 %13468, 16"
"  %13469 = lshr i32 %13465, 16"
"  %13469 = lshr i32 %13465, 16" -> "  %13471 = add nuw i32 %13469, %13470"
"  %13470 = mul nuw i32 %13156, 46547"
"  %13470 = mul nuw i32 %13156, 46547" -> "  %13471 = add nuw i32 %13469, %13470"
"  %13471 = add nuw i32 %13469, %13470"
"  %13471 = add nuw i32 %13469, %13470" -> "  %13473 = and i32 %13471, 65535""  %13471 = add nuw i32 %13469, %13470" -> "  %13475 = and i32 %13471, -65536"
"  %13472 = lshr i32 %13468, 16"
"  %13472 = lshr i32 %13468, 16" -> "  %13474 = add nuw nsw i32 %13472, %13473"
"  %13473 = and i32 %13471, 65535"
"  %13473 = and i32 %13471, 65535" -> "  %13474 = add nuw nsw i32 %13472, %13473"
"  %13474 = add nuw nsw i32 %13472, %13473"
"  %13474 = add nuw nsw i32 %13472, %13473" -> "  %13476 = add nuw i32 %13474, %13475"
"  %13475 = and i32 %13471, -65536"
"  %13475 = and i32 %13471, -65536" -> "  %13476 = add nuw i32 %13474, %13475"
"  %13476 = add nuw i32 %13474, %13475"
"  %13476 = add nuw i32 %13474, %13475" -> "  %13499 = lshr i32 %13476, 16""  %13476 = add nuw i32 %13474, %13475" -> "  %13495 = and i32 %13476, 65535"
"  %13477 = mul nuw nsw i32 %13173, 17857"
"  %13477 = mul nuw nsw i32 %13173, 17857" -> "  %13496 = and i32 %13477, 65535""  %13477 = mul nuw nsw i32 %13173, 17857" -> "  %13478 = lshr i32 %13477, 16"
"  %13478 = lshr i32 %13477, 16"
"  %13478 = lshr i32 %13477, 16" -> "  %13481 = add nuw nsw i32 %13480, %13478"
"  %13479 = mul nuw nsw i32 %13176, 17857"
"  %13479 = mul nuw nsw i32 %13176, 17857" -> "  %13482 = and i32 %13479, 2147418112""  %13479 = mul nuw nsw i32 %13176, 17857" -> "  %13480 = and i32 %13479, 65535"
"  %13480 = and i32 %13479, 65535"
"  %13480 = and i32 %13479, 65535" -> "  %13481 = add nuw nsw i32 %13480, %13478"
"  %13481 = add nuw nsw i32 %13480, %13478"
"  %13481 = add nuw nsw i32 %13480, %13478" -> "  %13483 = add nuw nsw i32 %13481, %13482"
"  %13482 = and i32 %13479, 2147418112"
"  %13482 = and i32 %13479, 2147418112" -> "  %13483 = add nuw nsw i32 %13481, %13482"
"  %13483 = add nuw nsw i32 %13481, %13482"
"  %13483 = add nuw nsw i32 %13481, %13482" -> "  %13487 = lshr i32 %13483, 16""  %13483 = add nuw nsw i32 %13481, %13482" -> "  %13485 = and i32 %13483, 65535"
"  %13484 = mul nuw i32 %13173, 46547"
"  %13484 = mul nuw i32 %13173, 46547" -> "  %13486 = add nuw i32 %13485, %13484"
"  %13485 = and i32 %13483, 65535"
"  %13485 = and i32 %13483, 65535" -> "  %13486 = add nuw i32 %13485, %13484"
"  %13486 = add nuw i32 %13485, %13484"
"  %13486 = add nuw i32 %13485, %13484" -> "  %13498 = and i32 %13486, 65535""  %13486 = add nuw i32 %13485, %13484" -> "  %13490 = lshr i32 %13486, 16"
"  %13487 = lshr i32 %13483, 16"
"  %13487 = lshr i32 %13483, 16" -> "  %13489 = add nuw i32 %13487, %13488"
"  %13488 = mul nuw i32 %13176, 46547"
"  %13488 = mul nuw i32 %13176, 46547" -> "  %13489 = add nuw i32 %13487, %13488"
"  %13489 = add nuw i32 %13487, %13488"
"  %13489 = add nuw i32 %13487, %13488" -> "  %13493 = and i32 %13489, -65536""  %13489 = add nuw i32 %13487, %13488" -> "  %13491 = and i32 %13489, 65535"
"  %13490 = lshr i32 %13486, 16"
"  %13490 = lshr i32 %13486, 16" -> "  %13492 = add nuw nsw i32 %13490, %13491"
"  %13491 = and i32 %13489, 65535"
"  %13491 = and i32 %13489, 65535" -> "  %13492 = add nuw nsw i32 %13490, %13491"
"  %13492 = add nuw nsw i32 %13490, %13491"
"  %13492 = add nuw nsw i32 %13490, %13491" -> "  %13494 = add nuw i32 %13492, %13493"
"  %13493 = and i32 %13489, -65536"
"  %13493 = and i32 %13489, -65536" -> "  %13494 = add nuw i32 %13492, %13493"
"  %13494 = add nuw i32 %13492, %13493"
"  %13494 = add nuw i32 %13492, %13493" -> "  %13502 = add nuw i32 %13494, %13501"
"  %13495 = and i32 %13476, 65535"
"  %13495 = and i32 %13476, 65535" -> "  %13497 = add nuw nsw i32 %13495, %13496"
"  %13496 = and i32 %13477, 65535"
"  %13496 = and i32 %13477, 65535" -> "  %13497 = add nuw nsw i32 %13495, %13496"
"  %13497 = add nuw nsw i32 %13495, %13496"
"  %13497 = add nuw nsw i32 %13495, %13496" -> "  %13526 = and i32 %13497, 65535""  %13497 = add nuw nsw i32 %13495, %13496" -> "  %13504 = lshr i32 %13497, 16"
"  %13498 = and i32 %13486, 65535"
"  %13498 = and i32 %13486, 65535" -> "  %13500 = add nuw nsw i32 %13498, %13499"
"  %13499 = lshr i32 %13476, 16"
"  %13499 = lshr i32 %13476, 16" -> "  %13500 = add nuw nsw i32 %13498, %13499"
"  %13500 = add nuw nsw i32 %13498, %13499"
"  %13500 = add nuw nsw i32 %13498, %13499" -> "  %13503 = and i32 %13500, 65535""  %13500 = add nuw nsw i32 %13498, %13499" -> "  %13501 = lshr i32 %13500, 16"
"  %13501 = lshr i32 %13500, 16"
"  %13501 = lshr i32 %13500, 16" -> "  %13502 = add nuw i32 %13494, %13501"
"  %13502 = add nuw i32 %13494, %13501"
"  %13502 = add nuw i32 %13494, %13501" -> "  %13507 = add nuw i32 %13502, %13506"
"  %13503 = and i32 %13500, 65535"
"  %13503 = and i32 %13500, 65535" -> "  %13505 = add nuw nsw i32 %13503, %13504"
"  %13504 = lshr i32 %13497, 16"
"  %13504 = lshr i32 %13497, 16" -> "  %13505 = add nuw nsw i32 %13503, %13504"
"  %13505 = add nuw nsw i32 %13503, %13504"
"  %13505 = add nuw nsw i32 %13503, %13504" -> "  %13529 = and i32 %13505, 65535""  %13505 = add nuw nsw i32 %13503, %13504" -> "  %13506 = lshr i32 %13505, 16"
"  %13506 = lshr i32 %13505, 16"
"  %13506 = lshr i32 %13505, 16" -> "  %13507 = add nuw i32 %13502, %13506"
"  %13507 = add nuw i32 %13502, %13506"
"  %13507 = add nuw i32 %13502, %13506" -> "  %13561 = lshr i32 %13507, 16""  %13507 = add nuw i32 %13502, %13506" -> "  %13557 = and i32 %13507, 65535"
"  %13508 = mul nuw nsw i32 %13153, 31112"
"  %13508 = mul nuw nsw i32 %13153, 31112" -> "  %13527 = and i32 %13508, 65528""  %13508 = mul nuw nsw i32 %13153, 31112" -> "  %13509 = lshr i32 %13508, 16"
"  %13509 = lshr i32 %13508, 16"
"  %13509 = lshr i32 %13508, 16" -> "  %13512 = add nuw nsw i32 %13511, %13509"
"  %13510 = mul nuw nsw i32 %13156, 31112"
"  %13510 = mul nuw nsw i32 %13156, 31112" -> "  %13513 = and i32 %13510, 2147418112""  %13510 = mul nuw nsw i32 %13156, 31112" -> "  %13511 = and i32 %13510, 65528"
"  %13511 = and i32 %13510, 65528"
"  %13511 = and i32 %13510, 65528" -> "  %13512 = add nuw nsw i32 %13511, %13509"
"  %13512 = add nuw nsw i32 %13511, %13509"
"  %13512 = add nuw nsw i32 %13511, %13509" -> "  %13514 = add nuw nsw i32 %13512, %13513"
"  %13513 = and i32 %13510, 2147418112"
"  %13513 = and i32 %13510, 2147418112" -> "  %13514 = add nuw nsw i32 %13512, %13513"
"  %13514 = add nuw nsw i32 %13512, %13513"
"  %13514 = add nuw nsw i32 %13512, %13513" -> "  %13518 = lshr i32 %13514, 16""  %13514 = add nuw nsw i32 %13512, %13513" -> "  %13516 = and i32 %13514, 65535"
"  %13515 = mul nuw i32 %13153, 42170"
"  %13515 = mul nuw i32 %13153, 42170" -> "  %13517 = add nuw i32 %13516, %13515"
"  %13516 = and i32 %13514, 65535"
"  %13516 = and i32 %13514, 65535" -> "  %13517 = add nuw i32 %13516, %13515"
"  %13517 = add nuw i32 %13516, %13515"
"  %13517 = add nuw i32 %13516, %13515" -> "  %13530 = and i32 %13517, 65535""  %13517 = add nuw i32 %13516, %13515" -> "  %13521 = lshr i32 %13517, 16"
"  %13518 = lshr i32 %13514, 16"
"  %13518 = lshr i32 %13514, 16" -> "  %13520 = add nuw i32 %13518, %13519"
"  %13519 = mul nuw i32 %13156, 42170"
"  %13519 = mul nuw i32 %13156, 42170" -> "  %13520 = add nuw i32 %13518, %13519"
"  %13520 = add nuw i32 %13518, %13519"
"  %13520 = add nuw i32 %13518, %13519" -> "  %13524 = and i32 %13520, -65536""  %13520 = add nuw i32 %13518, %13519" -> "  %13522 = and i32 %13520, 65535"
"  %13521 = lshr i32 %13517, 16"
"  %13521 = lshr i32 %13517, 16" -> "  %13523 = add nuw nsw i32 %13521, %13522"
"  %13522 = and i32 %13520, 65535"
"  %13522 = and i32 %13520, 65535" -> "  %13523 = add nuw nsw i32 %13521, %13522"
"  %13523 = add nuw nsw i32 %13521, %13522"
"  %13523 = add nuw nsw i32 %13521, %13522" -> "  %13525 = add nuw i32 %13523, %13524"
"  %13524 = and i32 %13520, -65536"
"  %13524 = and i32 %13520, -65536" -> "  %13525 = add nuw i32 %13523, %13524"
"  %13525 = add nuw i32 %13523, %13524"
"  %13525 = add nuw i32 %13523, %13524" -> "  %13533 = add nuw i32 %13525, %13532"
"  %13526 = and i32 %13497, 65535"
"  %13526 = and i32 %13497, 65535" -> "  %13528 = add nuw nsw i32 %13526, %13527"
"  %13527 = and i32 %13508, 65528"
"  %13527 = and i32 %13508, 65528" -> "  %13528 = add nuw nsw i32 %13526, %13527"
"  %13528 = add nuw nsw i32 %13526, %13527"
"  %13528 = add nuw nsw i32 %13526, %13527" -> "  %13597 = and i32 %13528, 65535""  %13528 = add nuw nsw i32 %13526, %13527" -> "  %13535 = lshr i32 %13528, 16"
"  %13529 = and i32 %13505, 65535"
"  %13529 = and i32 %13505, 65535" -> "  %13531 = add nuw nsw i32 %13529, %13530"
"  %13530 = and i32 %13517, 65535"
"  %13530 = and i32 %13517, 65535" -> "  %13531 = add nuw nsw i32 %13529, %13530"
"  %13531 = add nuw nsw i32 %13529, %13530"
"  %13531 = add nuw nsw i32 %13529, %13530" -> "  %13534 = and i32 %13531, 65535""  %13531 = add nuw nsw i32 %13529, %13530" -> "  %13532 = lshr i32 %13531, 16"
"  %13532 = lshr i32 %13531, 16"
"  %13532 = lshr i32 %13531, 16" -> "  %13533 = add nuw i32 %13525, %13532"
"  %13533 = add nuw i32 %13525, %13532"
"  %13533 = add nuw i32 %13525, %13532" -> "  %13538 = add nuw i32 %13533, %13537"
"  %13534 = and i32 %13531, 65535"
"  %13534 = and i32 %13531, 65535" -> "  %13536 = add nuw nsw i32 %13534, %13535"
"  %13535 = lshr i32 %13528, 16"
"  %13535 = lshr i32 %13528, 16" -> "  %13536 = add nuw nsw i32 %13534, %13535"
"  %13536 = add nuw nsw i32 %13534, %13535"
"  %13536 = add nuw nsw i32 %13534, %13535" -> "  %13600 = and i32 %13536, 65535""  %13536 = add nuw nsw i32 %13534, %13535" -> "  %13537 = lshr i32 %13536, 16"
"  %13537 = lshr i32 %13536, 16"
"  %13537 = lshr i32 %13536, 16" -> "  %13538 = add nuw i32 %13533, %13537"
"  %13538 = add nuw i32 %13533, %13537"
"  %13538 = add nuw i32 %13533, %13537" -> "  %13574 = lshr i32 %13538, 16""  %13538 = add nuw i32 %13533, %13537" -> "  %13571 = and i32 %13538, 65535"
"  %13539 = mul nuw nsw i32 %13173, 31112"
"  %13539 = mul nuw nsw i32 %13173, 31112" -> "  %13558 = and i32 %13539, 65528""  %13539 = mul nuw nsw i32 %13173, 31112" -> "  %13540 = lshr i32 %13539, 16"
"  %13540 = lshr i32 %13539, 16"
"  %13540 = lshr i32 %13539, 16" -> "  %13543 = add nuw nsw i32 %13542, %13540"
"  %13541 = mul nuw nsw i32 %13176, 31112"
"  %13541 = mul nuw nsw i32 %13176, 31112" -> "  %13544 = and i32 %13541, 2147418112""  %13541 = mul nuw nsw i32 %13176, 31112" -> "  %13542 = and i32 %13541, 65528"
"  %13542 = and i32 %13541, 65528"
"  %13542 = and i32 %13541, 65528" -> "  %13543 = add nuw nsw i32 %13542, %13540"
"  %13543 = add nuw nsw i32 %13542, %13540"
"  %13543 = add nuw nsw i32 %13542, %13540" -> "  %13545 = add nuw nsw i32 %13543, %13544"
"  %13544 = and i32 %13541, 2147418112"
"  %13544 = and i32 %13541, 2147418112" -> "  %13545 = add nuw nsw i32 %13543, %13544"
"  %13545 = add nuw nsw i32 %13543, %13544"
"  %13545 = add nuw nsw i32 %13543, %13544" -> "  %13549 = lshr i32 %13545, 16""  %13545 = add nuw nsw i32 %13543, %13544" -> "  %13547 = and i32 %13545, 65535"
"  %13546 = mul nuw i32 %13173, 42170"
"  %13546 = mul nuw i32 %13173, 42170" -> "  %13548 = add nuw i32 %13547, %13546"
"  %13547 = and i32 %13545, 65535"
"  %13547 = and i32 %13545, 65535" -> "  %13548 = add nuw i32 %13547, %13546"
"  %13548 = add nuw i32 %13547, %13546"
"  %13548 = add nuw i32 %13547, %13546" -> "  %13560 = and i32 %13548, 65535""  %13548 = add nuw i32 %13547, %13546" -> "  %13552 = lshr i32 %13548, 16"
"  %13549 = lshr i32 %13545, 16"
"  %13549 = lshr i32 %13545, 16" -> "  %13551 = add nuw i32 %13549, %13550"
"  %13550 = mul nuw i32 %13176, 42170"
"  %13550 = mul nuw i32 %13176, 42170" -> "  %13551 = add nuw i32 %13549, %13550"
"  %13551 = add nuw i32 %13549, %13550"
"  %13551 = add nuw i32 %13549, %13550" -> "  %13555 = and i32 %13551, -65536""  %13551 = add nuw i32 %13549, %13550" -> "  %13553 = and i32 %13551, 65535"
"  %13552 = lshr i32 %13548, 16"
"  %13552 = lshr i32 %13548, 16" -> "  %13554 = add nuw nsw i32 %13552, %13553"
"  %13553 = and i32 %13551, 65535"
"  %13553 = and i32 %13551, 65535" -> "  %13554 = add nuw nsw i32 %13552, %13553"
"  %13554 = add nuw nsw i32 %13552, %13553"
"  %13554 = add nuw nsw i32 %13552, %13553" -> "  %13556 = add nuw i32 %13554, %13555"
"  %13555 = and i32 %13551, -65536"
"  %13555 = and i32 %13551, -65536" -> "  %13556 = add nuw i32 %13554, %13555"
"  %13556 = add nuw i32 %13554, %13555"
"  %13556 = add nuw i32 %13554, %13555" -> "  %13564 = add nuw i32 %13556, %13563"
"  %13557 = and i32 %13507, 65535"
"  %13557 = and i32 %13507, 65535" -> "  %13559 = add nuw nsw i32 %13557, %13558"
"  %13558 = and i32 %13539, 65528"
"  %13558 = and i32 %13539, 65528" -> "  %13559 = add nuw nsw i32 %13557, %13558"
"  %13559 = add nuw nsw i32 %13557, %13558"
"  %13559 = add nuw nsw i32 %13557, %13558" -> "  %13570 = and i32 %13559, 65535""  %13559 = add nuw nsw i32 %13557, %13558" -> "  %13566 = lshr i32 %13559, 16"
"  %13560 = and i32 %13548, 65535"
"  %13560 = and i32 %13548, 65535" -> "  %13562 = add nuw nsw i32 %13561, %13560"
"  %13561 = lshr i32 %13507, 16"
"  %13561 = lshr i32 %13507, 16" -> "  %13562 = add nuw nsw i32 %13561, %13560"
"  %13562 = add nuw nsw i32 %13561, %13560"
"  %13562 = add nuw nsw i32 %13561, %13560" -> "  %13565 = and i32 %13562, 65535""  %13562 = add nuw nsw i32 %13561, %13560" -> "  %13563 = lshr i32 %13562, 16"
"  %13563 = lshr i32 %13562, 16"
"  %13563 = lshr i32 %13562, 16" -> "  %13564 = add nuw i32 %13556, %13563"
"  %13564 = add nuw i32 %13556, %13563"
"  %13564 = add nuw i32 %13556, %13563" -> "  %13569 = add nuw i32 %13564, %13568"
"  %13565 = and i32 %13562, 65535"
"  %13565 = and i32 %13562, 65535" -> "  %13567 = add nuw nsw i32 %13566, %13565"
"  %13566 = lshr i32 %13559, 16"
"  %13566 = lshr i32 %13559, 16" -> "  %13567 = add nuw nsw i32 %13566, %13565"
"  %13567 = add nuw nsw i32 %13566, %13565"
"  %13567 = add nuw nsw i32 %13566, %13565" -> "  %13573 = and i32 %13567, 65535""  %13567 = add nuw nsw i32 %13566, %13565" -> "  %13568 = lshr i32 %13567, 16"
"  %13568 = lshr i32 %13567, 16"
"  %13568 = lshr i32 %13567, 16" -> "  %13569 = add nuw i32 %13564, %13568"
"  %13569 = add nuw i32 %13564, %13568"
"  %13569 = add nuw i32 %13564, %13568" -> "  %13582 = and i32 %13569, -65536""  %13569 = add nuw i32 %13564, %13568" -> "  %13580 = and i32 %13569, 65535"
"  %13570 = and i32 %13559, 65535"
"  %13570 = and i32 %13559, 65535" -> "  %13572 = add nuw nsw i32 %13571, %13570"
"  %13571 = and i32 %13538, 65535"
"  %13571 = and i32 %13538, 65535" -> "  %13572 = add nuw nsw i32 %13571, %13570"
"  %13572 = add nuw nsw i32 %13571, %13570"
"  %13572 = add nuw nsw i32 %13571, %13570" -> "  %13612 = and i32 %13572, 65535""  %13572 = add nuw nsw i32 %13571, %13570" -> "  %13576 = lshr i32 %13572, 16"
"  %13573 = and i32 %13567, 65535"
"  %13573 = and i32 %13567, 65535" -> "  %13575 = add nuw nsw i32 %13574, %13573"
"  %13574 = lshr i32 %13538, 16"
"  %13574 = lshr i32 %13538, 16" -> "  %13575 = add nuw nsw i32 %13574, %13573"
"  %13575 = add nuw nsw i32 %13574, %13573"
"  %13575 = add nuw nsw i32 %13574, %13573" -> "  %13579 = lshr i32 %13575, 16""  %13575 = add nuw nsw i32 %13574, %13573" -> "  %13577 = and i32 %13575, 65535"
"  %13576 = lshr i32 %13572, 16"
"  %13576 = lshr i32 %13572, 16" -> "  %13578 = add nuw nsw i32 %13576, %13577"
"  %13577 = and i32 %13575, 65535"
"  %13577 = and i32 %13575, 65535" -> "  %13578 = add nuw nsw i32 %13576, %13577"
"  %13578 = add nuw nsw i32 %13576, %13577"
"  %13578 = add nuw nsw i32 %13576, %13577" -> "  %13619 = and i32 %13578, 65535""  %13578 = add nuw nsw i32 %13576, %13577" -> "  %13584 = lshr i32 %13578, 16"
"  %13579 = lshr i32 %13575, 16"
"  %13579 = lshr i32 %13575, 16" -> "  %13581 = add nuw nsw i32 %13579, %13580"
"  %13580 = and i32 %13569, 65535"
"  %13580 = and i32 %13569, 65535" -> "  %13581 = add nuw nsw i32 %13579, %13580"
"  %13581 = add nuw nsw i32 %13579, %13580"
"  %13581 = add nuw nsw i32 %13579, %13580" -> "  %13583 = add nuw i32 %13581, %13582"
"  %13582 = and i32 %13569, -65536"
"  %13582 = and i32 %13569, -65536" -> "  %13583 = add nuw i32 %13581, %13582"
"  %13583 = add nuw i32 %13581, %13582"
"  %13583 = add nuw i32 %13581, %13582" -> "  %13585 = add nuw i32 %13583, %13584"
"  %13584 = lshr i32 %13578, 16"
"  %13584 = lshr i32 %13578, 16" -> "  %13585 = add nuw i32 %13583, %13584"
"  %13585 = add nuw i32 %13583, %13584"
"  %13585 = add nuw i32 %13583, %13584" -> "  %13623 = add nuw i32 %13585, %13622"
"  %13586 = and i32 %13459, 65535"
"  %13586 = and i32 %13459, 65535" -> "  %13588 = add nuw nsw i32 %13587, %13586"
"  %13587 = and i32 %13423, 65535"
"  %13587 = and i32 %13423, 65535" -> "  %13588 = add nuw nsw i32 %13587, %13586"
"  %13588 = add nuw nsw i32 %13587, %13586"
"  %13588 = add nuw nsw i32 %13587, %13586" -> "  %13592 = lshr i32 %13588, 16"
"  %13589 = and i32 %13468, 65535"
"  %13589 = and i32 %13468, 65535" -> "  %13591 = add nuw nsw i32 %13590, %13589"
"  %13590 = and i32 %13429, 65535"
"  %13590 = and i32 %13429, 65535" -> "  %13591 = add nuw nsw i32 %13590, %13589"
"  %13591 = add nuw nsw i32 %13590, %13589"
"  %13591 = add nuw nsw i32 %13590, %13589" -> "  %13595 = lshr i32 %13591, 16""  %13591 = add nuw nsw i32 %13590, %13589" -> "  %13593 = and i32 %13591, 65535"
"  %13592 = lshr i32 %13588, 16"
"  %13592 = lshr i32 %13588, 16" -> "  %13594 = add nuw nsw i32 %13593, %13592"
"  %13593 = and i32 %13591, 65535"
"  %13593 = and i32 %13591, 65535" -> "  %13594 = add nuw nsw i32 %13593, %13592"
"  %13594 = add nuw nsw i32 %13593, %13592"
"  %13594 = add nuw nsw i32 %13593, %13592" -> "  %13596 = lshr i32 %13594, 16"
"  %13595 = lshr i32 %13591, 16"
"  %13595 = lshr i32 %13591, 16" -> "  %13607 = add nuw nsw i32 %13596, %13595"
"  %13596 = lshr i32 %13594, 16"
"  %13596 = lshr i32 %13594, 16" -> "  %13607 = add nuw nsw i32 %13596, %13595"
"  %13597 = and i32 %13528, 65535"
"  %13597 = and i32 %13528, 65535" -> "  %13599 = add nuw nsw i32 %13598, %13597"
"  %13598 = and i32 %13443, 65535"
"  %13598 = and i32 %13443, 65535" -> "  %13599 = add nuw nsw i32 %13598, %13597"
"  %13599 = add nuw nsw i32 %13598, %13597"
"  %13599 = add nuw nsw i32 %13598, %13597" -> "  %13606 = and i32 %13599, 65535""  %13599 = add nuw nsw i32 %13598, %13597" -> "  %13603 = lshr i32 %13599, 16"
"  %13600 = and i32 %13536, 65535"
"  %13600 = and i32 %13536, 65535" -> "  %13602 = add nuw nsw i32 %13601, %13600"
"  %13601 = and i32 %13446, 65535"
"  %13601 = and i32 %13446, 65535" -> "  %13602 = add nuw nsw i32 %13601, %13600"
"  %13602 = add nuw nsw i32 %13601, %13600"
"  %13602 = add nuw nsw i32 %13601, %13600" -> "  %13613 = lshr i32 %13602, 16""  %13602 = add nuw nsw i32 %13601, %13600" -> "  %13604 = and i32 %13602, 65535"
"  %13603 = lshr i32 %13599, 16"
"  %13603 = lshr i32 %13599, 16" -> "  %13605 = add nuw nsw i32 %13604, %13603"
"  %13604 = and i32 %13602, 65535"
"  %13604 = and i32 %13602, 65535" -> "  %13605 = add nuw nsw i32 %13604, %13603"
"  %13605 = add nuw nsw i32 %13604, %13603"
"  %13605 = add nuw nsw i32 %13604, %13603" -> "  %13615 = lshr i32 %13605, 16""  %13605 = add nuw nsw i32 %13604, %13603" -> "  %13610 = and i32 %13605, 65535"
"  %13606 = and i32 %13599, 65535"
"  %13606 = and i32 %13599, 65535" -> "  %13608 = add nuw nsw i32 %13607, %13606"
"  %13607 = add nuw nsw i32 %13596, %13595"
"  %13607 = add nuw nsw i32 %13596, %13595" -> "  %13608 = add nuw nsw i32 %13607, %13606"
"  %13608 = add nuw nsw i32 %13607, %13606"
"  %13608 = add nuw nsw i32 %13607, %13606" -> "  %13609 = lshr i32 %13608, 16"
"  %13609 = lshr i32 %13608, 16"
"  %13609 = lshr i32 %13608, 16" -> "  %13611 = add nuw nsw i32 %13610, %13609"
"  %13610 = and i32 %13605, 65535"
"  %13610 = and i32 %13605, 65535" -> "  %13611 = add nuw nsw i32 %13610, %13609"
"  %13611 = add nuw nsw i32 %13610, %13609"
"  %13611 = add nuw nsw i32 %13610, %13609" -> "  %13617 = lshr i32 %13611, 16"
"  %13612 = and i32 %13572, 65535"
"  %13612 = and i32 %13572, 65535" -> "  %13614 = add nuw nsw i32 %13613, %13612"
"  %13613 = lshr i32 %13602, 16"
"  %13613 = lshr i32 %13602, 16" -> "  %13614 = add nuw nsw i32 %13613, %13612"
"  %13614 = add nuw nsw i32 %13613, %13612"
"  %13614 = add nuw nsw i32 %13613, %13612" -> "  %13616 = add nuw nsw i32 %13614, %13615"
"  %13615 = lshr i32 %13605, 16"
"  %13615 = lshr i32 %13605, 16" -> "  %13616 = add nuw nsw i32 %13614, %13615"
"  %13616 = add nuw nsw i32 %13614, %13615"
"  %13616 = add nuw nsw i32 %13614, %13615" -> "  %13618 = add nuw nsw i32 %13616, %13617"
"  %13617 = lshr i32 %13611, 16"
"  %13617 = lshr i32 %13611, 16" -> "  %13618 = add nuw nsw i32 %13616, %13617"
"  %13618 = add nuw nsw i32 %13616, %13617"
"  %13618 = add nuw nsw i32 %13616, %13617" -> "  %13790 = and i32 %13618, 65535""  %13618 = add nuw nsw i32 %13616, %13617" -> "  %13620 = lshr i32 %13618, 16"
"  %13619 = and i32 %13578, 65535"
"  %13619 = and i32 %13578, 65535" -> "  %13621 = add nuw nsw i32 %13620, %13619"
"  %13620 = lshr i32 %13618, 16"
"  %13620 = lshr i32 %13618, 16" -> "  %13621 = add nuw nsw i32 %13620, %13619"
"  %13621 = add nuw nsw i32 %13620, %13619"
"  %13621 = add nuw nsw i32 %13620, %13619" -> "  %13793 = and i32 %13621, 65535""  %13621 = add nuw nsw i32 %13620, %13619" -> "  %13622 = lshr i32 %13621, 16"
"  %13622 = lshr i32 %13621, 16"
"  %13622 = lshr i32 %13621, 16" -> "  %13623 = add nuw i32 %13585, %13622"
"  %13623 = add nuw i32 %13585, %13622"
"  %13623 = add nuw i32 %13585, %13622" -> "  %13799 = and i32 %13623, 65535""  %13623 = add nuw i32 %13585, %13622" -> "  %13802 = lshr i32 %13623, 16"
"  %13624 = mul nuw nsw i32 %13287, 17857"
"  %13624 = mul nuw nsw i32 %13287, 17857" -> "  %13751 = and i32 %13624, 65535""  %13624 = mul nuw nsw i32 %13287, 17857" -> "  %13625 = lshr i32 %13624, 16"
"  %13625 = lshr i32 %13624, 16"
"  %13625 = lshr i32 %13624, 16" -> "  %13628 = add nuw nsw i32 %13627, %13625"
"  %13626 = mul nuw nsw i32 %13290, 17857"
"  %13626 = mul nuw nsw i32 %13290, 17857" -> "  %13629 = and i32 %13626, 2147418112""  %13626 = mul nuw nsw i32 %13290, 17857" -> "  %13627 = and i32 %13626, 65535"
"  %13627 = and i32 %13626, 65535"
"  %13627 = and i32 %13626, 65535" -> "  %13628 = add nuw nsw i32 %13627, %13625"
"  %13628 = add nuw nsw i32 %13627, %13625"
"  %13628 = add nuw nsw i32 %13627, %13625" -> "  %13630 = add nuw nsw i32 %13628, %13629"
"  %13629 = and i32 %13626, 2147418112"
"  %13629 = and i32 %13626, 2147418112" -> "  %13630 = add nuw nsw i32 %13628, %13629"
"  %13630 = add nuw nsw i32 %13628, %13629"
"  %13630 = add nuw nsw i32 %13628, %13629" -> "  %13634 = lshr i32 %13630, 16""  %13630 = add nuw nsw i32 %13628, %13629" -> "  %13632 = and i32 %13630, 65535"
"  %13631 = mul nuw i32 %13287, 46547"
"  %13631 = mul nuw i32 %13287, 46547" -> "  %13633 = add nuw i32 %13632, %13631"
"  %13632 = and i32 %13630, 65535"
"  %13632 = and i32 %13630, 65535" -> "  %13633 = add nuw i32 %13632, %13631"
"  %13633 = add nuw i32 %13632, %13631"
"  %13633 = add nuw i32 %13632, %13631" -> "  %13754 = and i32 %13633, 65535""  %13633 = add nuw i32 %13632, %13631" -> "  %13637 = lshr i32 %13633, 16"
"  %13634 = lshr i32 %13630, 16"
"  %13634 = lshr i32 %13630, 16" -> "  %13636 = add nuw i32 %13634, %13635"
"  %13635 = mul nuw i32 %13290, 46547"
"  %13635 = mul nuw i32 %13290, 46547" -> "  %13636 = add nuw i32 %13634, %13635"
"  %13636 = add nuw i32 %13634, %13635"
"  %13636 = add nuw i32 %13634, %13635" -> "  %13640 = and i32 %13636, -65536""  %13636 = add nuw i32 %13634, %13635" -> "  %13638 = and i32 %13636, 65535"
"  %13637 = lshr i32 %13633, 16"
"  %13637 = lshr i32 %13633, 16" -> "  %13639 = add nuw nsw i32 %13637, %13638"
"  %13638 = and i32 %13636, 65535"
"  %13638 = and i32 %13636, 65535" -> "  %13639 = add nuw nsw i32 %13637, %13638"
"  %13639 = add nuw nsw i32 %13637, %13638"
"  %13639 = add nuw nsw i32 %13637, %13638" -> "  %13641 = add nuw i32 %13639, %13640"
"  %13640 = and i32 %13636, -65536"
"  %13640 = and i32 %13636, -65536" -> "  %13641 = add nuw i32 %13639, %13640"
"  %13641 = add nuw i32 %13639, %13640"
"  %13641 = add nuw i32 %13639, %13640" -> "  %13660 = and i32 %13641, 65535""  %13641 = add nuw i32 %13639, %13640" -> "  %13664 = lshr i32 %13641, 16"
"  %13642 = mul nuw nsw i32 %13307, 17857"
"  %13642 = mul nuw nsw i32 %13307, 17857" -> "  %13661 = and i32 %13642, 65535""  %13642 = mul nuw nsw i32 %13307, 17857" -> "  %13643 = lshr i32 %13642, 16"
"  %13643 = lshr i32 %13642, 16"
"  %13643 = lshr i32 %13642, 16" -> "  %13646 = add nuw nsw i32 %13645, %13643"
"  %13644 = mul nuw nsw i32 %13310, 17857"
"  %13644 = mul nuw nsw i32 %13310, 17857" -> "  %13647 = and i32 %13644, 2147418112""  %13644 = mul nuw nsw i32 %13310, 17857" -> "  %13645 = and i32 %13644, 65535"
"  %13645 = and i32 %13644, 65535"
"  %13645 = and i32 %13644, 65535" -> "  %13646 = add nuw nsw i32 %13645, %13643"
"  %13646 = add nuw nsw i32 %13645, %13643"
"  %13646 = add nuw nsw i32 %13645, %13643" -> "  %13648 = add nuw nsw i32 %13646, %13647"
"  %13647 = and i32 %13644, 2147418112"
"  %13647 = and i32 %13644, 2147418112" -> "  %13648 = add nuw nsw i32 %13646, %13647"
"  %13648 = add nuw nsw i32 %13646, %13647"
"  %13648 = add nuw nsw i32 %13646, %13647" -> "  %13652 = lshr i32 %13648, 16""  %13648 = add nuw nsw i32 %13646, %13647" -> "  %13650 = and i32 %13648, 65535"
"  %13649 = mul nuw i32 %13307, 46547"
"  %13649 = mul nuw i32 %13307, 46547" -> "  %13651 = add nuw i32 %13650, %13649"
"  %13650 = and i32 %13648, 65535"
"  %13650 = and i32 %13648, 65535" -> "  %13651 = add nuw i32 %13650, %13649"
"  %13651 = add nuw i32 %13650, %13649"
"  %13651 = add nuw i32 %13650, %13649" -> "  %13663 = and i32 %13651, 65535""  %13651 = add nuw i32 %13650, %13649" -> "  %13655 = lshr i32 %13651, 16"
"  %13652 = lshr i32 %13648, 16"
"  %13652 = lshr i32 %13648, 16" -> "  %13654 = add nuw i32 %13652, %13653"
"  %13653 = mul nuw i32 %13310, 46547"
"  %13653 = mul nuw i32 %13310, 46547" -> "  %13654 = add nuw i32 %13652, %13653"
"  %13654 = add nuw i32 %13652, %13653"
"  %13654 = add nuw i32 %13652, %13653" -> "  %13658 = and i32 %13654, -65536""  %13654 = add nuw i32 %13652, %13653" -> "  %13656 = and i32 %13654, 65535"
"  %13655 = lshr i32 %13651, 16"
"  %13655 = lshr i32 %13651, 16" -> "  %13657 = add nuw nsw i32 %13655, %13656"
"  %13656 = and i32 %13654, 65535"
"  %13656 = and i32 %13654, 65535" -> "  %13657 = add nuw nsw i32 %13655, %13656"
"  %13657 = add nuw nsw i32 %13655, %13656"
"  %13657 = add nuw nsw i32 %13655, %13656" -> "  %13659 = add nuw i32 %13657, %13658"
"  %13658 = and i32 %13654, -65536"
"  %13658 = and i32 %13654, -65536" -> "  %13659 = add nuw i32 %13657, %13658"
"  %13659 = add nuw i32 %13657, %13658"
"  %13659 = add nuw i32 %13657, %13658" -> "  %13667 = add nuw i32 %13659, %13666"
"  %13660 = and i32 %13641, 65535"
"  %13660 = and i32 %13641, 65535" -> "  %13662 = add nuw nsw i32 %13660, %13661"
"  %13661 = and i32 %13642, 65535"
"  %13661 = and i32 %13642, 65535" -> "  %13662 = add nuw nsw i32 %13660, %13661"
"  %13662 = add nuw nsw i32 %13660, %13661"
"  %13662 = add nuw nsw i32 %13660, %13661" -> "  %13691 = and i32 %13662, 65535""  %13662 = add nuw nsw i32 %13660, %13661" -> "  %13669 = lshr i32 %13662, 16"
"  %13663 = and i32 %13651, 65535"
"  %13663 = and i32 %13651, 65535" -> "  %13665 = add nuw nsw i32 %13663, %13664"
"  %13664 = lshr i32 %13641, 16"
"  %13664 = lshr i32 %13641, 16" -> "  %13665 = add nuw nsw i32 %13663, %13664"
"  %13665 = add nuw nsw i32 %13663, %13664"
"  %13665 = add nuw nsw i32 %13663, %13664" -> "  %13668 = and i32 %13665, 65535""  %13665 = add nuw nsw i32 %13663, %13664" -> "  %13666 = lshr i32 %13665, 16"
"  %13666 = lshr i32 %13665, 16"
"  %13666 = lshr i32 %13665, 16" -> "  %13667 = add nuw i32 %13659, %13666"
"  %13667 = add nuw i32 %13659, %13666"
"  %13667 = add nuw i32 %13659, %13666" -> "  %13672 = add nuw i32 %13667, %13671"
"  %13668 = and i32 %13665, 65535"
"  %13668 = and i32 %13665, 65535" -> "  %13670 = add nuw nsw i32 %13668, %13669"
"  %13669 = lshr i32 %13662, 16"
"  %13669 = lshr i32 %13662, 16" -> "  %13670 = add nuw nsw i32 %13668, %13669"
"  %13670 = add nuw nsw i32 %13668, %13669"
"  %13670 = add nuw nsw i32 %13668, %13669" -> "  %13694 = and i32 %13670, 65535""  %13670 = add nuw nsw i32 %13668, %13669" -> "  %13671 = lshr i32 %13670, 16"
"  %13671 = lshr i32 %13670, 16"
"  %13671 = lshr i32 %13670, 16" -> "  %13672 = add nuw i32 %13667, %13671"
"  %13672 = add nuw i32 %13667, %13671"
"  %13672 = add nuw i32 %13667, %13671" -> "  %13726 = lshr i32 %13672, 16""  %13672 = add nuw i32 %13667, %13671" -> "  %13722 = and i32 %13672, 65535"
"  %13673 = mul nuw nsw i32 %13287, 31112"
"  %13673 = mul nuw nsw i32 %13287, 31112" -> "  %13692 = and i32 %13673, 65528""  %13673 = mul nuw nsw i32 %13287, 31112" -> "  %13674 = lshr i32 %13673, 16"
"  %13674 = lshr i32 %13673, 16"
"  %13674 = lshr i32 %13673, 16" -> "  %13677 = add nuw nsw i32 %13676, %13674"
"  %13675 = mul nuw nsw i32 %13290, 31112"
"  %13675 = mul nuw nsw i32 %13290, 31112" -> "  %13678 = and i32 %13675, 2147418112""  %13675 = mul nuw nsw i32 %13290, 31112" -> "  %13676 = and i32 %13675, 65528"
"  %13676 = and i32 %13675, 65528"
"  %13676 = and i32 %13675, 65528" -> "  %13677 = add nuw nsw i32 %13676, %13674"
"  %13677 = add nuw nsw i32 %13676, %13674"
"  %13677 = add nuw nsw i32 %13676, %13674" -> "  %13679 = add nuw nsw i32 %13677, %13678"
"  %13678 = and i32 %13675, 2147418112"
"  %13678 = and i32 %13675, 2147418112" -> "  %13679 = add nuw nsw i32 %13677, %13678"
"  %13679 = add nuw nsw i32 %13677, %13678"
"  %13679 = add nuw nsw i32 %13677, %13678" -> "  %13683 = lshr i32 %13679, 16""  %13679 = add nuw nsw i32 %13677, %13678" -> "  %13681 = and i32 %13679, 65535"
"  %13680 = mul nuw i32 %13287, 42170"
"  %13680 = mul nuw i32 %13287, 42170" -> "  %13682 = add nuw i32 %13681, %13680"
"  %13681 = and i32 %13679, 65535"
"  %13681 = and i32 %13679, 65535" -> "  %13682 = add nuw i32 %13681, %13680"
"  %13682 = add nuw i32 %13681, %13680"
"  %13682 = add nuw i32 %13681, %13680" -> "  %13695 = and i32 %13682, 65535""  %13682 = add nuw i32 %13681, %13680" -> "  %13686 = lshr i32 %13682, 16"
"  %13683 = lshr i32 %13679, 16"
"  %13683 = lshr i32 %13679, 16" -> "  %13685 = add nuw i32 %13683, %13684"
"  %13684 = mul nuw i32 %13290, 42170"
"  %13684 = mul nuw i32 %13290, 42170" -> "  %13685 = add nuw i32 %13683, %13684"
"  %13685 = add nuw i32 %13683, %13684"
"  %13685 = add nuw i32 %13683, %13684" -> "  %13689 = and i32 %13685, -65536""  %13685 = add nuw i32 %13683, %13684" -> "  %13687 = and i32 %13685, 65535"
"  %13686 = lshr i32 %13682, 16"
"  %13686 = lshr i32 %13682, 16" -> "  %13688 = add nuw nsw i32 %13686, %13687"
"  %13687 = and i32 %13685, 65535"
"  %13687 = and i32 %13685, 65535" -> "  %13688 = add nuw nsw i32 %13686, %13687"
"  %13688 = add nuw nsw i32 %13686, %13687"
"  %13688 = add nuw nsw i32 %13686, %13687" -> "  %13690 = add nuw i32 %13688, %13689"
"  %13689 = and i32 %13685, -65536"
"  %13689 = and i32 %13685, -65536" -> "  %13690 = add nuw i32 %13688, %13689"
"  %13690 = add nuw i32 %13688, %13689"
"  %13690 = add nuw i32 %13688, %13689" -> "  %13698 = add nuw i32 %13690, %13697"
"  %13691 = and i32 %13662, 65535"
"  %13691 = and i32 %13662, 65535" -> "  %13693 = add nuw nsw i32 %13691, %13692"
"  %13692 = and i32 %13673, 65528"
"  %13692 = and i32 %13673, 65528" -> "  %13693 = add nuw nsw i32 %13691, %13692"
"  %13693 = add nuw nsw i32 %13691, %13692"
"  %13693 = add nuw nsw i32 %13691, %13692" -> "  %13760 = and i32 %13693, 65535""  %13693 = add nuw nsw i32 %13691, %13692" -> "  %13700 = lshr i32 %13693, 16"
"  %13694 = and i32 %13670, 65535"
"  %13694 = and i32 %13670, 65535" -> "  %13696 = add nuw nsw i32 %13694, %13695"
"  %13695 = and i32 %13682, 65535"
"  %13695 = and i32 %13682, 65535" -> "  %13696 = add nuw nsw i32 %13694, %13695"
"  %13696 = add nuw nsw i32 %13694, %13695"
"  %13696 = add nuw nsw i32 %13694, %13695" -> "  %13699 = and i32 %13696, 65535""  %13696 = add nuw nsw i32 %13694, %13695" -> "  %13697 = lshr i32 %13696, 16"
"  %13697 = lshr i32 %13696, 16"
"  %13697 = lshr i32 %13696, 16" -> "  %13698 = add nuw i32 %13690, %13697"
"  %13698 = add nuw i32 %13690, %13697"
"  %13698 = add nuw i32 %13690, %13697" -> "  %13703 = add nuw i32 %13698, %13702"
"  %13699 = and i32 %13696, 65535"
"  %13699 = and i32 %13696, 65535" -> "  %13701 = add nuw nsw i32 %13699, %13700"
"  %13700 = lshr i32 %13693, 16"
"  %13700 = lshr i32 %13693, 16" -> "  %13701 = add nuw nsw i32 %13699, %13700"
"  %13701 = add nuw nsw i32 %13699, %13700"
"  %13701 = add nuw nsw i32 %13699, %13700" -> "  %13763 = and i32 %13701, 65535""  %13701 = add nuw nsw i32 %13699, %13700" -> "  %13702 = lshr i32 %13701, 16"
"  %13702 = lshr i32 %13701, 16"
"  %13702 = lshr i32 %13701, 16" -> "  %13703 = add nuw i32 %13698, %13702"
"  %13703 = add nuw i32 %13698, %13702"
"  %13703 = add nuw i32 %13698, %13702" -> "  %13739 = lshr i32 %13703, 16""  %13703 = add nuw i32 %13698, %13702" -> "  %13736 = and i32 %13703, 65535"
"  %13704 = mul nuw nsw i32 %13307, 31112"
"  %13704 = mul nuw nsw i32 %13307, 31112" -> "  %13723 = and i32 %13704, 65528""  %13704 = mul nuw nsw i32 %13307, 31112" -> "  %13705 = lshr i32 %13704, 16"
"  %13705 = lshr i32 %13704, 16"
"  %13705 = lshr i32 %13704, 16" -> "  %13708 = add nuw nsw i32 %13707, %13705"
"  %13706 = mul nuw nsw i32 %13310, 31112"
"  %13706 = mul nuw nsw i32 %13310, 31112" -> "  %13709 = and i32 %13706, 2147418112""  %13706 = mul nuw nsw i32 %13310, 31112" -> "  %13707 = and i32 %13706, 65528"
"  %13707 = and i32 %13706, 65528"
"  %13707 = and i32 %13706, 65528" -> "  %13708 = add nuw nsw i32 %13707, %13705"
"  %13708 = add nuw nsw i32 %13707, %13705"
"  %13708 = add nuw nsw i32 %13707, %13705" -> "  %13710 = add nuw nsw i32 %13708, %13709"
"  %13709 = and i32 %13706, 2147418112"
"  %13709 = and i32 %13706, 2147418112" -> "  %13710 = add nuw nsw i32 %13708, %13709"
"  %13710 = add nuw nsw i32 %13708, %13709"
"  %13710 = add nuw nsw i32 %13708, %13709" -> "  %13714 = lshr i32 %13710, 16""  %13710 = add nuw nsw i32 %13708, %13709" -> "  %13712 = and i32 %13710, 65535"
"  %13711 = mul nuw i32 %13307, 42170"
"  %13711 = mul nuw i32 %13307, 42170" -> "  %13713 = add nuw i32 %13712, %13711"
"  %13712 = and i32 %13710, 65535"
"  %13712 = and i32 %13710, 65535" -> "  %13713 = add nuw i32 %13712, %13711"
"  %13713 = add nuw i32 %13712, %13711"
"  %13713 = add nuw i32 %13712, %13711" -> "  %13725 = and i32 %13713, 65535""  %13713 = add nuw i32 %13712, %13711" -> "  %13717 = lshr i32 %13713, 16"
"  %13714 = lshr i32 %13710, 16"
"  %13714 = lshr i32 %13710, 16" -> "  %13716 = add nuw i32 %13714, %13715"
"  %13715 = mul nuw i32 %13310, 42170"
"  %13715 = mul nuw i32 %13310, 42170" -> "  %13716 = add nuw i32 %13714, %13715"
"  %13716 = add nuw i32 %13714, %13715"
"  %13716 = add nuw i32 %13714, %13715" -> "  %13720 = and i32 %13716, -65536""  %13716 = add nuw i32 %13714, %13715" -> "  %13718 = and i32 %13716, 65535"
"  %13717 = lshr i32 %13713, 16"
"  %13717 = lshr i32 %13713, 16" -> "  %13719 = add nuw nsw i32 %13717, %13718"
"  %13718 = and i32 %13716, 65535"
"  %13718 = and i32 %13716, 65535" -> "  %13719 = add nuw nsw i32 %13717, %13718"
"  %13719 = add nuw nsw i32 %13717, %13718"
"  %13719 = add nuw nsw i32 %13717, %13718" -> "  %13721 = add nuw i32 %13719, %13720"
"  %13720 = and i32 %13716, -65536"
"  %13720 = and i32 %13716, -65536" -> "  %13721 = add nuw i32 %13719, %13720"
"  %13721 = add nuw i32 %13719, %13720"
"  %13721 = add nuw i32 %13719, %13720" -> "  %13729 = add nuw i32 %13721, %13728"
"  %13722 = and i32 %13672, 65535"
"  %13722 = and i32 %13672, 65535" -> "  %13724 = add nuw nsw i32 %13722, %13723"
"  %13723 = and i32 %13704, 65528"
"  %13723 = and i32 %13704, 65528" -> "  %13724 = add nuw nsw i32 %13722, %13723"
"  %13724 = add nuw nsw i32 %13722, %13723"
"  %13724 = add nuw nsw i32 %13722, %13723" -> "  %13735 = and i32 %13724, 65535""  %13724 = add nuw nsw i32 %13722, %13723" -> "  %13731 = lshr i32 %13724, 16"
"  %13725 = and i32 %13713, 65535"
"  %13725 = and i32 %13713, 65535" -> "  %13727 = add nuw nsw i32 %13726, %13725"
"  %13726 = lshr i32 %13672, 16"
"  %13726 = lshr i32 %13672, 16" -> "  %13727 = add nuw nsw i32 %13726, %13725"
"  %13727 = add nuw nsw i32 %13726, %13725"
"  %13727 = add nuw nsw i32 %13726, %13725" -> "  %13730 = and i32 %13727, 65535""  %13727 = add nuw nsw i32 %13726, %13725" -> "  %13728 = lshr i32 %13727, 16"
"  %13728 = lshr i32 %13727, 16"
"  %13728 = lshr i32 %13727, 16" -> "  %13729 = add nuw i32 %13721, %13728"
"  %13729 = add nuw i32 %13721, %13728"
"  %13729 = add nuw i32 %13721, %13728" -> "  %13734 = add nuw i32 %13729, %13733"
"  %13730 = and i32 %13727, 65535"
"  %13730 = and i32 %13727, 65535" -> "  %13732 = add nuw nsw i32 %13731, %13730"
"  %13731 = lshr i32 %13724, 16"
"  %13731 = lshr i32 %13724, 16" -> "  %13732 = add nuw nsw i32 %13731, %13730"
"  %13732 = add nuw nsw i32 %13731, %13730"
"  %13732 = add nuw nsw i32 %13731, %13730" -> "  %13738 = and i32 %13732, 65535""  %13732 = add nuw nsw i32 %13731, %13730" -> "  %13733 = lshr i32 %13732, 16"
"  %13733 = lshr i32 %13732, 16"
"  %13733 = lshr i32 %13732, 16" -> "  %13734 = add nuw i32 %13729, %13733"
"  %13734 = add nuw i32 %13729, %13733"
"  %13734 = add nuw i32 %13729, %13733" -> "  %13747 = and i32 %13734, -65536""  %13734 = add nuw i32 %13729, %13733" -> "  %13745 = and i32 %13734, 65535"
"  %13735 = and i32 %13724, 65535"
"  %13735 = and i32 %13724, 65535" -> "  %13737 = add nuw nsw i32 %13736, %13735"
"  %13736 = and i32 %13703, 65535"
"  %13736 = and i32 %13703, 65535" -> "  %13737 = add nuw nsw i32 %13736, %13735"
"  %13737 = add nuw nsw i32 %13736, %13735"
"  %13737 = add nuw nsw i32 %13736, %13735" -> "  %13777 = and i32 %13737, 65535""  %13737 = add nuw nsw i32 %13736, %13735" -> "  %13741 = lshr i32 %13737, 16"
"  %13738 = and i32 %13732, 65535"
"  %13738 = and i32 %13732, 65535" -> "  %13740 = add nuw nsw i32 %13739, %13738"
"  %13739 = lshr i32 %13703, 16"
"  %13739 = lshr i32 %13703, 16" -> "  %13740 = add nuw nsw i32 %13739, %13738"
"  %13740 = add nuw nsw i32 %13739, %13738"
"  %13740 = add nuw nsw i32 %13739, %13738" -> "  %13744 = lshr i32 %13740, 16""  %13740 = add nuw nsw i32 %13739, %13738" -> "  %13742 = and i32 %13740, 65535"
"  %13741 = lshr i32 %13737, 16"
"  %13741 = lshr i32 %13737, 16" -> "  %13743 = add nuw nsw i32 %13741, %13742"
"  %13742 = and i32 %13740, 65535"
"  %13742 = and i32 %13740, 65535" -> "  %13743 = add nuw nsw i32 %13741, %13742"
"  %13743 = add nuw nsw i32 %13741, %13742"
"  %13743 = add nuw nsw i32 %13741, %13742" -> "  %13784 = and i32 %13743, 65535""  %13743 = add nuw nsw i32 %13741, %13742" -> "  %13749 = lshr i32 %13743, 16"
"  %13744 = lshr i32 %13740, 16"
"  %13744 = lshr i32 %13740, 16" -> "  %13746 = add nuw nsw i32 %13744, %13745"
"  %13745 = and i32 %13734, 65535"
"  %13745 = and i32 %13734, 65535" -> "  %13746 = add nuw nsw i32 %13744, %13745"
"  %13746 = add nuw nsw i32 %13744, %13745"
"  %13746 = add nuw nsw i32 %13744, %13745" -> "  %13748 = add nuw i32 %13746, %13747"
"  %13747 = and i32 %13734, -65536"
"  %13747 = and i32 %13734, -65536" -> "  %13748 = add nuw i32 %13746, %13747"
"  %13748 = add nuw i32 %13746, %13747"
"  %13748 = add nuw i32 %13746, %13747" -> "  %13750 = add nuw i32 %13748, %13749"
"  %13749 = lshr i32 %13743, 16"
"  %13749 = lshr i32 %13743, 16" -> "  %13750 = add nuw i32 %13748, %13749"
"  %13750 = add nuw i32 %13748, %13749"
"  %13750 = add nuw i32 %13748, %13749" -> "  %13788 = add nuw i32 %13750, %13787"
"  %13751 = and i32 %13624, 65535"
"  %13751 = and i32 %13624, 65535" -> "  %13753 = add nuw nsw i32 %13752, %13751"
"  %13752 = and i32 %13453, 65535"
"  %13752 = and i32 %13453, 65535" -> "  %13753 = add nuw nsw i32 %13752, %13751"
"  %13753 = add nuw nsw i32 %13752, %13751"
"  %13753 = add nuw nsw i32 %13752, %13751" -> "  %13789 = and i32 %13753, 65535""  %13753 = add nuw nsw i32 %13752, %13751" -> "  %13757 = lshr i32 %13753, 16"
"  %13754 = and i32 %13633, 65535"
"  %13754 = and i32 %13633, 65535" -> "  %13756 = add nuw nsw i32 %13755, %13754"
"  %13755 = and i32 %13456, 65535"
"  %13755 = and i32 %13456, 65535" -> "  %13756 = add nuw nsw i32 %13755, %13754"
"  %13756 = add nuw nsw i32 %13755, %13754"
"  %13756 = add nuw nsw i32 %13755, %13754" -> "  %13770 = lshr i32 %13756, 16""  %13756 = add nuw nsw i32 %13755, %13754" -> "  %13758 = and i32 %13756, 65535"
"  %13757 = lshr i32 %13753, 16"
"  %13757 = lshr i32 %13753, 16" -> "  %13759 = add nuw nsw i32 %13758, %13757"
"  %13758 = and i32 %13756, 65535"
"  %13758 = and i32 %13756, 65535" -> "  %13759 = add nuw nsw i32 %13758, %13757"
"  %13759 = add nuw nsw i32 %13758, %13757"
"  %13759 = add nuw nsw i32 %13758, %13757" -> "  %13792 = and i32 %13759, 65535""  %13759 = add nuw nsw i32 %13758, %13757" -> "  %13772 = lshr i32 %13759, 16"
"  %13760 = and i32 %13693, 65535"
"  %13760 = and i32 %13693, 65535" -> "  %13762 = add nuw nsw i32 %13761, %13760"
"  %13761 = and i32 %13458, 65535"
"  %13761 = and i32 %13458, 65535" -> "  %13762 = add nuw nsw i32 %13761, %13760"
"  %13762 = add nuw nsw i32 %13761, %13760"
"  %13762 = add nuw nsw i32 %13761, %13760" -> "  %13769 = and i32 %13762, 65535""  %13762 = add nuw nsw i32 %13761, %13760" -> "  %13766 = lshr i32 %13762, 16"
"  %13763 = and i32 %13701, 65535"
"  %13763 = and i32 %13701, 65535" -> "  %13765 = add nuw nsw i32 %13764, %13763"
"  %13764 = lshr i32 %13458, 16"
"  %13764 = lshr i32 %13458, 16" -> "  %13765 = add nuw nsw i32 %13764, %13763"
"  %13765 = add nuw nsw i32 %13764, %13763"
"  %13765 = add nuw nsw i32 %13764, %13763" -> "  %13778 = lshr i32 %13765, 16""  %13765 = add nuw nsw i32 %13764, %13763" -> "  %13767 = and i32 %13765, 65535"
"  %13766 = lshr i32 %13762, 16"
"  %13766 = lshr i32 %13762, 16" -> "  %13768 = add nuw nsw i32 %13767, %13766"
"  %13767 = and i32 %13765, 65535"
"  %13767 = and i32 %13765, 65535" -> "  %13768 = add nuw nsw i32 %13767, %13766"
"  %13768 = add nuw nsw i32 %13767, %13766"
"  %13768 = add nuw nsw i32 %13767, %13766" -> "  %13780 = lshr i32 %13768, 16""  %13768 = add nuw nsw i32 %13767, %13766" -> "  %13775 = and i32 %13768, 65535"
"  %13769 = and i32 %13762, 65535"
"  %13769 = and i32 %13762, 65535" -> "  %13771 = add nuw nsw i32 %13769, %13770"
"  %13770 = lshr i32 %13756, 16"
"  %13770 = lshr i32 %13756, 16" -> "  %13771 = add nuw nsw i32 %13769, %13770"
"  %13771 = add nuw nsw i32 %13769, %13770"
"  %13771 = add nuw nsw i32 %13769, %13770" -> "  %13773 = add nuw nsw i32 %13771, %13772"
"  %13772 = lshr i32 %13759, 16"
"  %13772 = lshr i32 %13759, 16" -> "  %13773 = add nuw nsw i32 %13771, %13772"
"  %13773 = add nuw nsw i32 %13771, %13772"
"  %13773 = add nuw nsw i32 %13771, %13772" -> "  %13798 = and i32 %13773, 65535""  %13773 = add nuw nsw i32 %13771, %13772" -> "  %13774 = lshr i32 %13773, 16"
"  %13774 = lshr i32 %13773, 16"
"  %13774 = lshr i32 %13773, 16" -> "  %13776 = add nuw nsw i32 %13774, %13775"
"  %13775 = and i32 %13768, 65535"
"  %13775 = and i32 %13768, 65535" -> "  %13776 = add nuw nsw i32 %13774, %13775"
"  %13776 = add nuw nsw i32 %13774, %13775"
"  %13776 = add nuw nsw i32 %13774, %13775" -> "  %13801 = and i32 %13776, 65535""  %13776 = add nuw nsw i32 %13774, %13775" -> "  %13782 = lshr i32 %13776, 16"
"  %13777 = and i32 %13737, 65535"
"  %13777 = and i32 %13737, 65535" -> "  %13779 = add nuw nsw i32 %13778, %13777"
"  %13778 = lshr i32 %13765, 16"
"  %13778 = lshr i32 %13765, 16" -> "  %13779 = add nuw nsw i32 %13778, %13777"
"  %13779 = add nuw nsw i32 %13778, %13777"
"  %13779 = add nuw nsw i32 %13778, %13777" -> "  %13781 = add nuw nsw i32 %13779, %13780"
"  %13780 = lshr i32 %13768, 16"
"  %13780 = lshr i32 %13768, 16" -> "  %13781 = add nuw nsw i32 %13779, %13780"
"  %13781 = add nuw nsw i32 %13779, %13780"
"  %13781 = add nuw nsw i32 %13779, %13780" -> "  %13783 = add nuw nsw i32 %13781, %13782"
"  %13782 = lshr i32 %13776, 16"
"  %13782 = lshr i32 %13776, 16" -> "  %13783 = add nuw nsw i32 %13781, %13782"
"  %13783 = add nuw nsw i32 %13781, %13782"
"  %13783 = add nuw nsw i32 %13781, %13782" -> "  %13816 = and i32 %13783, 65535""  %13783 = add nuw nsw i32 %13781, %13782" -> "  %13785 = lshr i32 %13783, 16"
"  %13784 = and i32 %13743, 65535"
"  %13784 = and i32 %13743, 65535" -> "  %13786 = add nuw nsw i32 %13785, %13784"
"  %13785 = lshr i32 %13783, 16"
"  %13785 = lshr i32 %13783, 16" -> "  %13786 = add nuw nsw i32 %13785, %13784"
"  %13786 = add nuw nsw i32 %13785, %13784"
"  %13786 = add nuw nsw i32 %13785, %13784" -> "  %13823 = and i32 %13786, 65535""  %13786 = add nuw nsw i32 %13785, %13784" -> "  %13787 = lshr i32 %13786, 16"
"  %13787 = lshr i32 %13786, 16"
"  %13787 = lshr i32 %13786, 16" -> "  %13788 = add nuw i32 %13750, %13787"
"  %13788 = add nuw i32 %13750, %13787"
"  %13788 = add nuw i32 %13750, %13787" -> "  %13826 = add nuw i32 %13788, %13825"
"  %13789 = and i32 %13753, 65535"
"  %13789 = and i32 %13753, 65535" -> "  %13791 = add nuw nsw i32 %13790, %13789"
"  %13790 = and i32 %13618, 65535"
"  %13790 = and i32 %13618, 65535" -> "  %13791 = add nuw nsw i32 %13790, %13789"
"  %13791 = add nuw nsw i32 %13790, %13789"
"  %13791 = add nuw nsw i32 %13790, %13789" -> "  %14501 = and i32 %13791, 65535""  %13791 = add nuw nsw i32 %13790, %13789" -> "  %13795 = lshr i32 %13791, 16"
"  %13792 = and i32 %13759, 65535"
"  %13792 = and i32 %13759, 65535" -> "  %13794 = add nuw nsw i32 %13793, %13792"
"  %13793 = and i32 %13621, 65535"
"  %13793 = and i32 %13621, 65535" -> "  %13794 = add nuw nsw i32 %13793, %13792"
"  %13794 = add nuw nsw i32 %13793, %13792"
"  %13794 = add nuw nsw i32 %13793, %13792" -> "  %13807 = lshr i32 %13794, 16""  %13794 = add nuw nsw i32 %13793, %13792" -> "  %13796 = and i32 %13794, 65535"
"  %13795 = lshr i32 %13791, 16"
"  %13795 = lshr i32 %13791, 16" -> "  %13797 = add nuw nsw i32 %13796, %13795"
"  %13796 = and i32 %13794, 65535"
"  %13796 = and i32 %13794, 65535" -> "  %13797 = add nuw nsw i32 %13796, %13795"
"  %13797 = add nuw nsw i32 %13796, %13795"
"  %13797 = add nuw nsw i32 %13796, %13795" -> "  %14504 = and i32 %13797, 65535""  %13797 = add nuw nsw i32 %13796, %13795" -> "  %13809 = lshr i32 %13797, 16"
"  %13798 = and i32 %13773, 65535"
"  %13798 = and i32 %13773, 65535" -> "  %13800 = add nuw nsw i32 %13799, %13798"
"  %13799 = and i32 %13623, 65535"
"  %13799 = and i32 %13623, 65535" -> "  %13800 = add nuw nsw i32 %13799, %13798"
"  %13800 = add nuw nsw i32 %13799, %13798"
"  %13800 = add nuw nsw i32 %13799, %13798" -> "  %13808 = and i32 %13800, 65535""  %13800 = add nuw nsw i32 %13799, %13798" -> "  %13804 = lshr i32 %13800, 16"
"  %13801 = and i32 %13776, 65535"
"  %13801 = and i32 %13776, 65535" -> "  %13803 = add nuw nsw i32 %13801, %13802"
"  %13802 = lshr i32 %13623, 16"
"  %13802 = lshr i32 %13623, 16" -> "  %13803 = add nuw nsw i32 %13801, %13802"
"  %13803 = add nuw nsw i32 %13801, %13802"
"  %13803 = add nuw nsw i32 %13801, %13802" -> "  %13815 = lshr i32 %13803, 16""  %13803 = add nuw nsw i32 %13801, %13802" -> "  %13805 = and i32 %13803, 65535"
"  %13804 = lshr i32 %13800, 16"
"  %13804 = lshr i32 %13800, 16" -> "  %13806 = add nuw nsw i32 %13805, %13804"
"  %13805 = and i32 %13803, 65535"
"  %13805 = and i32 %13803, 65535" -> "  %13806 = add nuw nsw i32 %13805, %13804"
"  %13806 = add nuw nsw i32 %13805, %13804"
"  %13806 = add nuw nsw i32 %13805, %13804" -> "  %13813 = and i32 %13806, 65535""  %13806 = add nuw nsw i32 %13805, %13804" -> "  %13817 = lshr i32 %13806, 16"
"  %13807 = lshr i32 %13794, 16"
"  %13807 = lshr i32 %13794, 16" -> "  %13810 = add nuw nsw i32 %13809, %13807"
"  %13808 = and i32 %13800, 65535"
"  %13808 = and i32 %13800, 65535" -> "  %13811 = add nuw nsw i32 %13810, %13808"
"  %13809 = lshr i32 %13797, 16"
"  %13809 = lshr i32 %13797, 16" -> "  %13810 = add nuw nsw i32 %13809, %13807"
"  %13810 = add nuw nsw i32 %13809, %13807"
"  %13810 = add nuw nsw i32 %13809, %13807" -> "  %13811 = add nuw nsw i32 %13810, %13808"
"  %13811 = add nuw nsw i32 %13810, %13808"
"  %13811 = add nuw nsw i32 %13810, %13808" -> "  %14513 = and i32 %13811, 65535""  %13811 = add nuw nsw i32 %13810, %13808" -> "  %13812 = lshr i32 %13811, 16"
"  %13812 = lshr i32 %13811, 16"
"  %13812 = lshr i32 %13811, 16" -> "  %13814 = add nuw nsw i32 %13813, %13812"
"  %13813 = and i32 %13806, 65535"
"  %13813 = and i32 %13806, 65535" -> "  %13814 = add nuw nsw i32 %13813, %13812"
"  %13814 = add nuw nsw i32 %13813, %13812"
"  %13814 = add nuw nsw i32 %13813, %13812" -> "  %14516 = and i32 %13814, 65535""  %13814 = add nuw nsw i32 %13813, %13812" -> "  %13818 = lshr i32 %13814, 16"
"  %13815 = lshr i32 %13803, 16"
"  %13815 = lshr i32 %13803, 16" -> "  %13819 = add nuw nsw i32 %13815, %13816"
"  %13816 = and i32 %13783, 65535"
"  %13816 = and i32 %13783, 65535" -> "  %13819 = add nuw nsw i32 %13815, %13816"
"  %13817 = lshr i32 %13806, 16"
"  %13817 = lshr i32 %13806, 16" -> "  %13820 = add nuw nsw i32 %13819, %13817"
"  %13818 = lshr i32 %13814, 16"
"  %13818 = lshr i32 %13814, 16" -> "  %13821 = add nuw nsw i32 %13820, %13818"
"  %13819 = add nuw nsw i32 %13815, %13816"
"  %13819 = add nuw nsw i32 %13815, %13816" -> "  %13820 = add nuw nsw i32 %13819, %13817"
"  %13820 = add nuw nsw i32 %13819, %13817"
"  %13820 = add nuw nsw i32 %13819, %13817" -> "  %13821 = add nuw nsw i32 %13820, %13818"
"  %13821 = add nuw nsw i32 %13820, %13818"
"  %13821 = add nuw nsw i32 %13820, %13818" -> "  %14527 = and i32 %13821, 65535""  %13821 = add nuw nsw i32 %13820, %13818" -> "  %13822 = lshr i32 %13821, 16"
"  %13822 = lshr i32 %13821, 16"
"  %13822 = lshr i32 %13821, 16" -> "  %13824 = add nuw nsw i32 %13822, %13823"
"  %13823 = and i32 %13786, 65535"
"  %13823 = and i32 %13786, 65535" -> "  %13824 = add nuw nsw i32 %13822, %13823"
"  %13824 = add nuw nsw i32 %13822, %13823"
"  %13824 = add nuw nsw i32 %13822, %13823" -> "  %14530 = and i32 %13824, 65535""  %13824 = add nuw nsw i32 %13822, %13823" -> "  %13825 = lshr i32 %13824, 16"
"  %13825 = lshr i32 %13824, 16"
"  %13825 = lshr i32 %13824, 16" -> "  %13826 = add nuw i32 %13788, %13825"
"  %13826 = add nuw i32 %13788, %13825"
"  %13826 = add nuw i32 %13788, %13825" -> "  %14536 = and i32 %13826, 65535""  %13826 = add nuw i32 %13788, %13825" -> "  %14539 = lshr i32 %13826, 16"
"  %13827 = and i32 %13117, 65535"
"  %13827 = and i32 %13117, 65535" -> "  %15641 = mul nuw nsw i32 %13827, 4087""  %13827 = and i32 %13117, 65535" -> "  %15648 = mul nuw nsw i32 %13827, 11561""  %13827 = and i32 %13117, 65535" -> "  %15690 = mul nuw nsw i32 %13827, 21884""  %13827 = and i32 %13117, 65535" -> "  %15697 = mul nuw i32 %13827, 36786""  %13827 = and i32 %13117, 65535" -> "  %15349 = mul nuw i32 %13827, 42779""  %13827 = and i32 %13117, 65535" -> "  %15356 = mul nuw nsw i32 %13827, 9871""  %13827 = and i32 %13117, 65535" -> "  %15398 = mul nuw nsw i32 %13827, 24315""  %13827 = and i32 %13117, 65535" -> "  %15405 = mul nuw nsw i32 %13827, 29744""  %13827 = and i32 %13117, 65535" -> "  %14133 = mul nuw nsw i32 %13827, 17857""  %13827 = and i32 %13117, 65535" -> "  %14140 = mul nuw i32 %13827, 46547""  %13827 = and i32 %13117, 65535" -> "  %14182 = mul nuw nsw i32 %13827, 31112""  %13827 = and i32 %13117, 65535" -> "  %14189 = mul nuw i32 %13827, 42170""  %13827 = and i32 %13117, 65535" -> "  %13890 = mul nuw i32 %13827, 62728""  %13827 = and i32 %13117, 65535" -> "  %13836 = mul nuw i32 %13827, 45147""  %13827 = and i32 %13117, 65535" -> "  %13829 = mul nuw i32 %13827, 37996""  %13827 = and i32 %13117, 65535" -> "  %13883 = mul nuw nsw i32 %13827, 1324"
"  %13828 = and i32 %13123, 65535"
"  %13828 = and i32 %13123, 65535" -> "  %13831 = mul nuw i32 %13828, 37996""  %13828 = and i32 %13123, 65535" -> "  %13840 = mul nuw i32 %13828, 45147""  %13828 = and i32 %13123, 65535" -> "  %13885 = mul nuw nsw i32 %13828, 1324""  %13828 = and i32 %13123, 65535" -> "  %13894 = mul nuw i32 %13828, 62728""  %13828 = and i32 %13123, 65535" -> "  %14193 = mul nuw i32 %13828, 42170""  %13828 = and i32 %13123, 65535" -> "  %14184 = mul nuw nsw i32 %13828, 31112""  %13828 = and i32 %13123, 65535" -> "  %14144 = mul nuw i32 %13828, 46547""  %13828 = and i32 %13123, 65535" -> "  %14135 = mul nuw nsw i32 %13828, 17857""  %13828 = and i32 %13123, 65535" -> "  %15409 = mul nuw nsw i32 %13828, 29744""  %13828 = and i32 %13123, 65535" -> "  %15400 = mul nuw nsw i32 %13828, 24315""  %13828 = and i32 %13123, 65535" -> "  %15360 = mul nuw nsw i32 %13828, 9871""  %13828 = and i32 %13123, 65535" -> "  %15351 = mul nuw i32 %13828, 42779""  %13828 = and i32 %13123, 65535" -> "  %15701 = mul nuw i32 %13828, 36786""  %13828 = and i32 %13123, 65535" -> "  %15692 = mul nuw nsw i32 %13828, 21884""  %13828 = and i32 %13123, 65535" -> "  %15652 = mul nuw nsw i32 %13828, 11561""  %13828 = and i32 %13123, 65535" -> "  %15643 = mul nuw nsw i32 %13828, 4087"
"  %13829 = mul nuw i32 %13827, 37996"
"  %13829 = mul nuw i32 %13827, 37996" -> "  %14502 = and i32 %13829, 65532""  %13829 = mul nuw i32 %13827, 37996" -> "  %13830 = lshr i32 %13829, 16"
"  %13830 = lshr i32 %13829, 16"
"  %13830 = lshr i32 %13829, 16" -> "  %13833 = add nuw nsw i32 %13832, %13830"
"  %13831 = mul nuw i32 %13828, 37996"
"  %13831 = mul nuw i32 %13828, 37996" -> "  %13834 = and i32 %13831, -65536""  %13831 = mul nuw i32 %13828, 37996" -> "  %13832 = and i32 %13831, 65532"
"  %13832 = and i32 %13831, 65532"
"  %13832 = and i32 %13831, 65532" -> "  %13833 = add nuw nsw i32 %13832, %13830"
"  %13833 = add nuw nsw i32 %13832, %13830"
"  %13833 = add nuw nsw i32 %13832, %13830" -> "  %13835 = add nuw i32 %13833, %13834"
"  %13834 = and i32 %13831, -65536"
"  %13834 = and i32 %13831, -65536" -> "  %13835 = add nuw i32 %13833, %13834"
"  %13835 = add nuw i32 %13833, %13834"
"  %13835 = add nuw i32 %13833, %13834" -> "  %13839 = lshr i32 %13835, 16""  %13835 = add nuw i32 %13833, %13834" -> "  %13837 = and i32 %13835, 65535"
"  %13836 = mul nuw i32 %13827, 45147"
"  %13836 = mul nuw i32 %13827, 45147" -> "  %13838 = add nuw i32 %13837, %13836"
"  %13837 = and i32 %13835, 65535"
"  %13837 = and i32 %13835, 65535" -> "  %13838 = add nuw i32 %13837, %13836"
"  %13838 = add nuw i32 %13837, %13836"
"  %13838 = add nuw i32 %13837, %13836" -> "  %14505 = and i32 %13838, 65535""  %13838 = add nuw i32 %13837, %13836" -> "  %13842 = lshr i32 %13838, 16"
"  %13839 = lshr i32 %13835, 16"
"  %13839 = lshr i32 %13835, 16" -> "  %13841 = add nuw i32 %13839, %13840"
"  %13840 = mul nuw i32 %13828, 45147"
"  %13840 = mul nuw i32 %13828, 45147" -> "  %13841 = add nuw i32 %13839, %13840"
"  %13841 = add nuw i32 %13839, %13840"
"  %13841 = add nuw i32 %13839, %13840" -> "  %13845 = and i32 %13841, -65536""  %13841 = add nuw i32 %13839, %13840" -> "  %13843 = and i32 %13841, 65535"
"  %13842 = lshr i32 %13838, 16"
"  %13842 = lshr i32 %13838, 16" -> "  %13844 = add nuw nsw i32 %13842, %13843"
"  %13843 = and i32 %13841, 65535"
"  %13843 = and i32 %13841, 65535" -> "  %13844 = add nuw nsw i32 %13842, %13843"
"  %13844 = add nuw nsw i32 %13842, %13843"
"  %13844 = add nuw nsw i32 %13842, %13843" -> "  %13846 = add nuw i32 %13844, %13845"
"  %13845 = and i32 %13841, -65536"
"  %13845 = and i32 %13841, -65536" -> "  %13846 = add nuw i32 %13844, %13845"
"  %13846 = add nuw i32 %13844, %13845"
"  %13846 = add nuw i32 %13844, %13845" -> "  %13871 = lshr i32 %13846, 16""  %13846 = add nuw i32 %13844, %13845" -> "  %13867 = and i32 %13846, 65535"
"  %13847 = and i32 %13140, 65535"
"  %13847 = and i32 %13140, 65535" -> "  %13851 = mul nuw i32 %13847, 37996""  %13847 = and i32 %13140, 65535" -> "  %13860 = mul nuw i32 %13847, 45147""  %13847 = and i32 %13140, 65535" -> "  %13916 = mul nuw nsw i32 %13847, 1324""  %13847 = and i32 %13140, 65535" -> "  %13925 = mul nuw i32 %13847, 62728""  %13847 = and i32 %13140, 65535" -> "  %14224 = mul nuw i32 %13847, 42170""  %13847 = and i32 %13140, 65535" -> "  %14215 = mul nuw nsw i32 %13847, 31112""  %13847 = and i32 %13140, 65535" -> "  %14162 = mul nuw i32 %13847, 46547""  %13847 = and i32 %13140, 65535" -> "  %14153 = mul nuw nsw i32 %13847, 17857""  %13847 = and i32 %13140, 65535" -> "  %15440 = mul nuw nsw i32 %13847, 29744""  %13847 = and i32 %13140, 65535" -> "  %15431 = mul nuw nsw i32 %13847, 24315""  %13847 = and i32 %13140, 65535" -> "  %15378 = mul nuw nsw i32 %13847, 9871""  %13847 = and i32 %13140, 65535" -> "  %15369 = mul nuw i32 %13847, 42779""  %13847 = and i32 %13140, 65535" -> "  %15732 = mul nuw i32 %13847, 36786""  %13847 = and i32 %13140, 65535" -> "  %15723 = mul nuw nsw i32 %13847, 21884""  %13847 = and i32 %13140, 65535" -> "  %15670 = mul nuw nsw i32 %13847, 11561""  %13847 = and i32 %13140, 65535" -> "  %15661 = mul nuw nsw i32 %13847, 4087"
"  %13848 = and i32 %13137, 65535"
"  %13848 = and i32 %13137, 65535" -> "  %13849 = mul nuw i32 %13848, 37996""  %13848 = and i32 %13137, 65535" -> "  %13856 = mul nuw i32 %13848, 45147""  %13848 = and i32 %13137, 65535" -> "  %13914 = mul nuw nsw i32 %13848, 1324""  %13848 = and i32 %13137, 65535" -> "  %13921 = mul nuw i32 %13848, 62728""  %13848 = and i32 %13137, 65535" -> "  %14220 = mul nuw i32 %13848, 42170""  %13848 = and i32 %13137, 65535" -> "  %14213 = mul nuw nsw i32 %13848, 31112""  %13848 = and i32 %13137, 65535" -> "  %14158 = mul nuw i32 %13848, 46547""  %13848 = and i32 %13137, 65535" -> "  %14151 = mul nuw nsw i32 %13848, 17857""  %13848 = and i32 %13137, 65535" -> "  %15436 = mul nuw nsw i32 %13848, 29744""  %13848 = and i32 %13137, 65535" -> "  %15429 = mul nuw nsw i32 %13848, 24315""  %13848 = and i32 %13137, 65535" -> "  %15374 = mul nuw nsw i32 %13848, 9871""  %13848 = and i32 %13137, 65535" -> "  %15367 = mul nuw i32 %13848, 42779""  %13848 = and i32 %13137, 65535" -> "  %15728 = mul nuw i32 %13848, 36786""  %13848 = and i32 %13137, 65535" -> "  %15721 = mul nuw nsw i32 %13848, 21884""  %13848 = and i32 %13137, 65535" -> "  %15666 = mul nuw nsw i32 %13848, 11561""  %13848 = and i32 %13137, 65535" -> "  %15659 = mul nuw nsw i32 %13848, 4087"
"  %13849 = mul nuw i32 %13848, 37996"
"  %13849 = mul nuw i32 %13848, 37996" -> "  %13868 = and i32 %13849, 65532""  %13849 = mul nuw i32 %13848, 37996" -> "  %13850 = lshr i32 %13849, 16"
"  %13850 = lshr i32 %13849, 16"
"  %13850 = lshr i32 %13849, 16" -> "  %13853 = add nuw nsw i32 %13852, %13850"
"  %13851 = mul nuw i32 %13847, 37996"
"  %13851 = mul nuw i32 %13847, 37996" -> "  %13854 = and i32 %13851, -65536""  %13851 = mul nuw i32 %13847, 37996" -> "  %13852 = and i32 %13851, 65532"
"  %13852 = and i32 %13851, 65532"
"  %13852 = and i32 %13851, 65532" -> "  %13853 = add nuw nsw i32 %13852, %13850"
"  %13853 = add nuw nsw i32 %13852, %13850"
"  %13853 = add nuw nsw i32 %13852, %13850" -> "  %13855 = add nuw i32 %13853, %13854"
"  %13854 = and i32 %13851, -65536"
"  %13854 = and i32 %13851, -65536" -> "  %13855 = add nuw i32 %13853, %13854"
"  %13855 = add nuw i32 %13853, %13854"
"  %13855 = add nuw i32 %13853, %13854" -> "  %13859 = lshr i32 %13855, 16""  %13855 = add nuw i32 %13853, %13854" -> "  %13857 = and i32 %13855, 65535"
"  %13856 = mul nuw i32 %13848, 45147"
"  %13856 = mul nuw i32 %13848, 45147" -> "  %13858 = add nuw i32 %13857, %13856"
"  %13857 = and i32 %13855, 65535"
"  %13857 = and i32 %13855, 65535" -> "  %13858 = add nuw i32 %13857, %13856"
"  %13858 = add nuw i32 %13857, %13856"
"  %13858 = add nuw i32 %13857, %13856" -> "  %13870 = and i32 %13858, 65535""  %13858 = add nuw i32 %13857, %13856" -> "  %13862 = lshr i32 %13858, 16"
"  %13859 = lshr i32 %13855, 16"
"  %13859 = lshr i32 %13855, 16" -> "  %13861 = add nuw i32 %13859, %13860"
"  %13860 = mul nuw i32 %13847, 45147"
"  %13860 = mul nuw i32 %13847, 45147" -> "  %13861 = add nuw i32 %13859, %13860"
"  %13861 = add nuw i32 %13859, %13860"
"  %13861 = add nuw i32 %13859, %13860" -> "  %13865 = and i32 %13861, -65536""  %13861 = add nuw i32 %13859, %13860" -> "  %13863 = and i32 %13861, 65535"
"  %13862 = lshr i32 %13858, 16"
"  %13862 = lshr i32 %13858, 16" -> "  %13864 = add nuw nsw i32 %13862, %13863"
"  %13863 = and i32 %13861, 65535"
"  %13863 = and i32 %13861, 65535" -> "  %13864 = add nuw nsw i32 %13862, %13863"
"  %13864 = add nuw nsw i32 %13862, %13863"
"  %13864 = add nuw nsw i32 %13862, %13863" -> "  %13866 = add nuw i32 %13864, %13865"
"  %13865 = and i32 %13861, -65536"
"  %13865 = and i32 %13861, -65536" -> "  %13866 = add nuw i32 %13864, %13865"
"  %13866 = add nuw i32 %13864, %13865"
"  %13866 = add nuw i32 %13864, %13865" -> "  %13879 = and i32 %13866, -65536""  %13866 = add nuw i32 %13864, %13865" -> "  %13877 = and i32 %13866, 65535"
"  %13867 = and i32 %13846, 65535"
"  %13867 = and i32 %13846, 65535" -> "  %13869 = add nuw nsw i32 %13867, %13868"
"  %13868 = and i32 %13849, 65532"
"  %13868 = and i32 %13849, 65532" -> "  %13869 = add nuw nsw i32 %13867, %13868"
"  %13869 = add nuw nsw i32 %13867, %13868"
"  %13869 = add nuw nsw i32 %13867, %13868" -> "  %13901 = and i32 %13869, 65535""  %13869 = add nuw nsw i32 %13867, %13868" -> "  %13873 = lshr i32 %13869, 16"
"  %13870 = and i32 %13858, 65535"
"  %13870 = and i32 %13858, 65535" -> "  %13872 = add nuw nsw i32 %13870, %13871"
"  %13871 = lshr i32 %13846, 16"
"  %13871 = lshr i32 %13846, 16" -> "  %13872 = add nuw nsw i32 %13870, %13871"
"  %13872 = add nuw nsw i32 %13870, %13871"
"  %13872 = add nuw nsw i32 %13870, %13871" -> "  %13876 = lshr i32 %13872, 16""  %13872 = add nuw nsw i32 %13870, %13871" -> "  %13874 = and i32 %13872, 65535"
"  %13873 = lshr i32 %13869, 16"
"  %13873 = lshr i32 %13869, 16" -> "  %13875 = add nuw nsw i32 %13874, %13873"
"  %13874 = and i32 %13872, 65535"
"  %13874 = and i32 %13872, 65535" -> "  %13875 = add nuw nsw i32 %13874, %13873"
"  %13875 = add nuw nsw i32 %13874, %13873"
"  %13875 = add nuw nsw i32 %13874, %13873" -> "  %13904 = and i32 %13875, 65535""  %13875 = add nuw nsw i32 %13874, %13873" -> "  %13881 = lshr i32 %13875, 16"
"  %13876 = lshr i32 %13872, 16"
"  %13876 = lshr i32 %13872, 16" -> "  %13878 = add nuw nsw i32 %13877, %13876"
"  %13877 = and i32 %13866, 65535"
"  %13877 = and i32 %13866, 65535" -> "  %13878 = add nuw nsw i32 %13877, %13876"
"  %13878 = add nuw nsw i32 %13877, %13876"
"  %13878 = add nuw nsw i32 %13877, %13876" -> "  %13880 = add nuw i32 %13878, %13879"
"  %13879 = and i32 %13866, -65536"
"  %13879 = and i32 %13866, -65536" -> "  %13880 = add nuw i32 %13878, %13879"
"  %13880 = add nuw i32 %13878, %13879"
"  %13880 = add nuw i32 %13878, %13879" -> "  %13882 = add nuw i32 %13880, %13881"
"  %13881 = lshr i32 %13875, 16"
"  %13881 = lshr i32 %13875, 16" -> "  %13882 = add nuw i32 %13880, %13881"
"  %13882 = add nuw i32 %13880, %13881"
"  %13882 = add nuw i32 %13880, %13881" -> "  %13936 = lshr i32 %13882, 16""  %13882 = add nuw i32 %13880, %13881" -> "  %13932 = and i32 %13882, 65535"
"  %13883 = mul nuw nsw i32 %13827, 1324"
"  %13883 = mul nuw nsw i32 %13827, 1324" -> "  %13902 = and i32 %13883, 65532""  %13883 = mul nuw nsw i32 %13827, 1324" -> "  %13884 = lshr i32 %13883, 16"
"  %13884 = lshr i32 %13883, 16"
"  %13884 = lshr i32 %13883, 16" -> "  %13887 = add nuw nsw i32 %13886, %13884"
"  %13885 = mul nuw nsw i32 %13828, 1324"
"  %13885 = mul nuw nsw i32 %13828, 1324" -> "  %13888 = and i32 %13885, 134152192""  %13885 = mul nuw nsw i32 %13828, 1324" -> "  %13886 = and i32 %13885, 65532"
"  %13886 = and i32 %13885, 65532"
"  %13886 = and i32 %13885, 65532" -> "  %13887 = add nuw nsw i32 %13886, %13884"
"  %13887 = add nuw nsw i32 %13886, %13884"
"  %13887 = add nuw nsw i32 %13886, %13884" -> "  %13889 = add nuw nsw i32 %13887, %13888"
"  %13888 = and i32 %13885, 134152192"
"  %13888 = and i32 %13885, 134152192" -> "  %13889 = add nuw nsw i32 %13887, %13888"
"  %13889 = add nuw nsw i32 %13887, %13888"
"  %13889 = add nuw nsw i32 %13887, %13888" -> "  %13893 = lshr i32 %13889, 16""  %13889 = add nuw nsw i32 %13887, %13888" -> "  %13891 = and i32 %13889, 65535"
"  %13890 = mul nuw i32 %13827, 62728"
"  %13890 = mul nuw i32 %13827, 62728" -> "  %13892 = add nuw i32 %13891, %13890"
"  %13891 = and i32 %13889, 65535"
"  %13891 = and i32 %13889, 65535" -> "  %13892 = add nuw i32 %13891, %13890"
"  %13892 = add nuw i32 %13891, %13890"
"  %13892 = add nuw i32 %13891, %13890" -> "  %13905 = and i32 %13892, 65535""  %13892 = add nuw i32 %13891, %13890" -> "  %13896 = lshr i32 %13892, 16"
"  %13893 = lshr i32 %13889, 16"
"  %13893 = lshr i32 %13889, 16" -> "  %13895 = add nuw i32 %13893, %13894"
"  %13894 = mul nuw i32 %13828, 62728"
"  %13894 = mul nuw i32 %13828, 62728" -> "  %13895 = add nuw i32 %13893, %13894"
"  %13895 = add nuw i32 %13893, %13894"
"  %13895 = add nuw i32 %13893, %13894" -> "  %13899 = and i32 %13895, -65536""  %13895 = add nuw i32 %13893, %13894" -> "  %13897 = and i32 %13895, 65535"
"  %13896 = lshr i32 %13892, 16"
"  %13896 = lshr i32 %13892, 16" -> "  %13898 = add nuw nsw i32 %13896, %13897"
"  %13897 = and i32 %13895, 65535"
"  %13897 = and i32 %13895, 65535" -> "  %13898 = add nuw nsw i32 %13896, %13897"
"  %13898 = add nuw nsw i32 %13896, %13897"
"  %13898 = add nuw nsw i32 %13896, %13897" -> "  %13900 = add nuw i32 %13898, %13899"
"  %13899 = and i32 %13895, -65536"
"  %13899 = and i32 %13895, -65536" -> "  %13900 = add nuw i32 %13898, %13899"
"  %13900 = add nuw i32 %13898, %13899"
"  %13900 = add nuw i32 %13898, %13899" -> "  %13908 = add nuw i32 %13900, %13907"
"  %13901 = and i32 %13869, 65535"
"  %13901 = and i32 %13869, 65535" -> "  %13903 = add nuw nsw i32 %13901, %13902"
"  %13902 = and i32 %13883, 65532"
"  %13902 = and i32 %13883, 65532" -> "  %13903 = add nuw nsw i32 %13901, %13902"
"  %13903 = add nuw nsw i32 %13901, %13902"
"  %13903 = add nuw nsw i32 %13901, %13902" -> "  %14514 = and i32 %13903, 65535""  %13903 = add nuw nsw i32 %13901, %13902" -> "  %13910 = lshr i32 %13903, 16"
"  %13904 = and i32 %13875, 65535"
"  %13904 = and i32 %13875, 65535" -> "  %13906 = add nuw nsw i32 %13904, %13905"
"  %13905 = and i32 %13892, 65535"
"  %13905 = and i32 %13892, 65535" -> "  %13906 = add nuw nsw i32 %13904, %13905"
"  %13906 = add nuw nsw i32 %13904, %13905"
"  %13906 = add nuw nsw i32 %13904, %13905" -> "  %13909 = and i32 %13906, 65535""  %13906 = add nuw nsw i32 %13904, %13905" -> "  %13907 = lshr i32 %13906, 16"
"  %13907 = lshr i32 %13906, 16"
"  %13907 = lshr i32 %13906, 16" -> "  %13908 = add nuw i32 %13900, %13907"
"  %13908 = add nuw i32 %13900, %13907"
"  %13908 = add nuw i32 %13900, %13907" -> "  %13913 = add nuw i32 %13908, %13912"
"  %13909 = and i32 %13906, 65535"
"  %13909 = and i32 %13906, 65535" -> "  %13911 = add nuw nsw i32 %13909, %13910"
"  %13910 = lshr i32 %13903, 16"
"  %13910 = lshr i32 %13903, 16" -> "  %13911 = add nuw nsw i32 %13909, %13910"
"  %13911 = add nuw nsw i32 %13909, %13910"
"  %13911 = add nuw nsw i32 %13909, %13910" -> "  %14517 = and i32 %13911, 65535""  %13911 = add nuw nsw i32 %13909, %13910" -> "  %13912 = lshr i32 %13911, 16"
"  %13912 = lshr i32 %13911, 16"
"  %13912 = lshr i32 %13911, 16" -> "  %13913 = add nuw i32 %13908, %13912"
"  %13913 = add nuw i32 %13908, %13912"
"  %13913 = add nuw i32 %13908, %13912" -> "  %13949 = lshr i32 %13913, 16""  %13913 = add nuw i32 %13908, %13912" -> "  %13946 = and i32 %13913, 65535"
"  %13914 = mul nuw nsw i32 %13848, 1324"
"  %13914 = mul nuw nsw i32 %13848, 1324" -> "  %13933 = and i32 %13914, 65532""  %13914 = mul nuw nsw i32 %13848, 1324" -> "  %13915 = lshr i32 %13914, 16"
"  %13915 = lshr i32 %13914, 16"
"  %13915 = lshr i32 %13914, 16" -> "  %13918 = add nuw nsw i32 %13917, %13915"
"  %13916 = mul nuw nsw i32 %13847, 1324"
"  %13916 = mul nuw nsw i32 %13847, 1324" -> "  %13919 = and i32 %13916, 134152192""  %13916 = mul nuw nsw i32 %13847, 1324" -> "  %13917 = and i32 %13916, 65532"
"  %13917 = and i32 %13916, 65532"
"  %13917 = and i32 %13916, 65532" -> "  %13918 = add nuw nsw i32 %13917, %13915"
"  %13918 = add nuw nsw i32 %13917, %13915"
"  %13918 = add nuw nsw i32 %13917, %13915" -> "  %13920 = add nuw nsw i32 %13918, %13919"
"  %13919 = and i32 %13916, 134152192"
"  %13919 = and i32 %13916, 134152192" -> "  %13920 = add nuw nsw i32 %13918, %13919"
"  %13920 = add nuw nsw i32 %13918, %13919"
"  %13920 = add nuw nsw i32 %13918, %13919" -> "  %13924 = lshr i32 %13920, 16""  %13920 = add nuw nsw i32 %13918, %13919" -> "  %13922 = and i32 %13920, 65535"
"  %13921 = mul nuw i32 %13848, 62728"
"  %13921 = mul nuw i32 %13848, 62728" -> "  %13923 = add nuw i32 %13922, %13921"
"  %13922 = and i32 %13920, 65535"
"  %13922 = and i32 %13920, 65535" -> "  %13923 = add nuw i32 %13922, %13921"
"  %13923 = add nuw i32 %13922, %13921"
"  %13923 = add nuw i32 %13922, %13921" -> "  %13935 = and i32 %13923, 65535""  %13923 = add nuw i32 %13922, %13921" -> "  %13927 = lshr i32 %13923, 16"
"  %13924 = lshr i32 %13920, 16"
"  %13924 = lshr i32 %13920, 16" -> "  %13926 = add nuw i32 %13924, %13925"
"  %13925 = mul nuw i32 %13847, 62728"
"  %13925 = mul nuw i32 %13847, 62728" -> "  %13926 = add nuw i32 %13924, %13925"
"  %13926 = add nuw i32 %13924, %13925"
"  %13926 = add nuw i32 %13924, %13925" -> "  %13930 = and i32 %13926, -65536""  %13926 = add nuw i32 %13924, %13925" -> "  %13928 = and i32 %13926, 65535"
"  %13927 = lshr i32 %13923, 16"
"  %13927 = lshr i32 %13923, 16" -> "  %13929 = add nuw nsw i32 %13927, %13928"
"  %13928 = and i32 %13926, 65535"
"  %13928 = and i32 %13926, 65535" -> "  %13929 = add nuw nsw i32 %13927, %13928"
"  %13929 = add nuw nsw i32 %13927, %13928"
"  %13929 = add nuw nsw i32 %13927, %13928" -> "  %13931 = add nuw i32 %13929, %13930"
"  %13930 = and i32 %13926, -65536"
"  %13930 = and i32 %13926, -65536" -> "  %13931 = add nuw i32 %13929, %13930"
"  %13931 = add nuw i32 %13929, %13930"
"  %13931 = add nuw i32 %13929, %13930" -> "  %13939 = add nuw i32 %13931, %13938"
"  %13932 = and i32 %13882, 65535"
"  %13932 = and i32 %13882, 65535" -> "  %13934 = add nuw nsw i32 %13932, %13933"
"  %13933 = and i32 %13914, 65532"
"  %13933 = and i32 %13914, 65532" -> "  %13934 = add nuw nsw i32 %13932, %13933"
"  %13934 = add nuw nsw i32 %13932, %13933"
"  %13934 = add nuw nsw i32 %13932, %13933" -> "  %13945 = and i32 %13934, 65535""  %13934 = add nuw nsw i32 %13932, %13933" -> "  %13941 = lshr i32 %13934, 16"
"  %13935 = and i32 %13923, 65535"
"  %13935 = and i32 %13923, 65535" -> "  %13937 = add nuw nsw i32 %13936, %13935"
"  %13936 = lshr i32 %13882, 16"
"  %13936 = lshr i32 %13882, 16" -> "  %13937 = add nuw nsw i32 %13936, %13935"
"  %13937 = add nuw nsw i32 %13936, %13935"
"  %13937 = add nuw nsw i32 %13936, %13935" -> "  %13940 = and i32 %13937, 65535""  %13937 = add nuw nsw i32 %13936, %13935" -> "  %13938 = lshr i32 %13937, 16"
"  %13938 = lshr i32 %13937, 16"
"  %13938 = lshr i32 %13937, 16" -> "  %13939 = add nuw i32 %13931, %13938"
"  %13939 = add nuw i32 %13931, %13938"
"  %13939 = add nuw i32 %13931, %13938" -> "  %13944 = add nuw i32 %13939, %13943"
"  %13940 = and i32 %13937, 65535"
"  %13940 = and i32 %13937, 65535" -> "  %13942 = add nuw nsw i32 %13941, %13940"
"  %13941 = lshr i32 %13934, 16"
"  %13941 = lshr i32 %13934, 16" -> "  %13942 = add nuw nsw i32 %13941, %13940"
"  %13942 = add nuw nsw i32 %13941, %13940"
"  %13942 = add nuw nsw i32 %13941, %13940" -> "  %13948 = and i32 %13942, 65535""  %13942 = add nuw nsw i32 %13941, %13940" -> "  %13943 = lshr i32 %13942, 16"
"  %13943 = lshr i32 %13942, 16"
"  %13943 = lshr i32 %13942, 16" -> "  %13944 = add nuw i32 %13939, %13943"
"  %13944 = add nuw i32 %13939, %13943"
"  %13944 = add nuw i32 %13939, %13943" -> "  %13957 = and i32 %13944, -65536""  %13944 = add nuw i32 %13939, %13943" -> "  %13955 = and i32 %13944, 65535"
"  %13945 = and i32 %13934, 65535"
"  %13945 = and i32 %13934, 65535" -> "  %13947 = add nuw nsw i32 %13946, %13945"
"  %13946 = and i32 %13913, 65535"
"  %13946 = and i32 %13913, 65535" -> "  %13947 = add nuw nsw i32 %13946, %13945"
"  %13947 = add nuw nsw i32 %13946, %13945"
"  %13947 = add nuw nsw i32 %13946, %13945" -> "  %14096 = and i32 %13947, 65535""  %13947 = add nuw nsw i32 %13946, %13945" -> "  %13951 = lshr i32 %13947, 16"
"  %13948 = and i32 %13942, 65535"
"  %13948 = and i32 %13942, 65535" -> "  %13950 = add nuw nsw i32 %13948, %13949"
"  %13949 = lshr i32 %13913, 16"
"  %13949 = lshr i32 %13913, 16" -> "  %13950 = add nuw nsw i32 %13948, %13949"
"  %13950 = add nuw nsw i32 %13948, %13949"
"  %13950 = add nuw nsw i32 %13948, %13949" -> "  %13954 = lshr i32 %13950, 16""  %13950 = add nuw nsw i32 %13948, %13949" -> "  %13952 = and i32 %13950, 65535"
"  %13951 = lshr i32 %13947, 16"
"  %13951 = lshr i32 %13947, 16" -> "  %13953 = add nuw nsw i32 %13952, %13951"
"  %13952 = and i32 %13950, 65535"
"  %13952 = and i32 %13950, 65535" -> "  %13953 = add nuw nsw i32 %13952, %13951"
"  %13953 = add nuw nsw i32 %13952, %13951"
"  %13953 = add nuw nsw i32 %13952, %13951" -> "  %14099 = and i32 %13953, 65535""  %13953 = add nuw nsw i32 %13952, %13951" -> "  %13959 = lshr i32 %13953, 16"
"  %13954 = lshr i32 %13950, 16"
"  %13954 = lshr i32 %13950, 16" -> "  %13956 = add nuw nsw i32 %13954, %13955"
"  %13955 = and i32 %13944, 65535"
"  %13955 = and i32 %13944, 65535" -> "  %13956 = add nuw nsw i32 %13954, %13955"
"  %13956 = add nuw nsw i32 %13954, %13955"
"  %13956 = add nuw nsw i32 %13954, %13955" -> "  %13958 = add nuw i32 %13956, %13957"
"  %13957 = and i32 %13944, -65536"
"  %13957 = and i32 %13944, -65536" -> "  %13958 = add nuw i32 %13956, %13957"
"  %13958 = add nuw i32 %13956, %13957"
"  %13958 = add nuw i32 %13956, %13957" -> "  %13960 = add nuw i32 %13958, %13959"
"  %13959 = lshr i32 %13953, 16"
"  %13959 = lshr i32 %13953, 16" -> "  %13960 = add nuw i32 %13958, %13959"
"  %13960 = add nuw i32 %13958, %13959"
"  %13960 = add nuw i32 %13958, %13959" -> "  %14105 = and i32 %13960, 65535""  %13960 = add nuw i32 %13958, %13959" -> "  %14108 = lshr i32 %13960, 16"
"  %13961 = and i32 %13150, 65535"
"  %13961 = and i32 %13150, 65535" -> "  %15808 = mul nuw nsw i32 %13961, 4087""  %13961 = and i32 %13150, 65535" -> "  %15817 = mul nuw nsw i32 %13961, 11561""  %13961 = and i32 %13150, 65535" -> "  %15857 = mul nuw nsw i32 %13961, 21884""  %13961 = and i32 %13150, 65535" -> "  %15866 = mul nuw i32 %13961, 36786""  %13961 = and i32 %13150, 65535" -> "  %15478 = mul nuw i32 %13961, 42779""  %13961 = and i32 %13150, 65535" -> "  %15487 = mul nuw nsw i32 %13961, 9871""  %13961 = and i32 %13150, 65535" -> "  %15527 = mul nuw nsw i32 %13961, 24315""  %13961 = and i32 %13150, 65535" -> "  %15536 = mul nuw nsw i32 %13961, 29744""  %13961 = and i32 %13150, 65535" -> "  %14300 = mul nuw nsw i32 %13961, 17857""  %13961 = and i32 %13150, 65535" -> "  %14309 = mul nuw i32 %13961, 46547""  %13961 = and i32 %13150, 65535" -> "  %14349 = mul nuw nsw i32 %13961, 31112""  %13961 = and i32 %13150, 65535" -> "  %14358 = mul nuw i32 %13961, 42170""  %13961 = and i32 %13150, 65535" -> "  %14028 = mul nuw i32 %13961, 62728""  %13961 = and i32 %13150, 65535" -> "  %14019 = mul nuw nsw i32 %13961, 1324""  %13961 = and i32 %13150, 65535" -> "  %13974 = mul nuw i32 %13961, 45147""  %13961 = and i32 %13150, 65535" -> "  %13965 = mul nuw i32 %13961, 37996"
"  %13962 = and i32 %13147, 65535"
"  %13962 = and i32 %13147, 65535" -> "  %13963 = mul nuw i32 %13962, 37996""  %13962 = and i32 %13147, 65535" -> "  %14024 = mul nuw i32 %13962, 62728""  %13962 = and i32 %13147, 65535" -> "  %14017 = mul nuw nsw i32 %13962, 1324""  %13962 = and i32 %13147, 65535" -> "  %13970 = mul nuw i32 %13962, 45147""  %13962 = and i32 %13147, 65535" -> "  %14354 = mul nuw i32 %13962, 42170""  %13962 = and i32 %13147, 65535" -> "  %14347 = mul nuw nsw i32 %13962, 31112""  %13962 = and i32 %13147, 65535" -> "  %14305 = mul nuw i32 %13962, 46547""  %13962 = and i32 %13147, 65535" -> "  %14298 = mul nuw nsw i32 %13962, 17857""  %13962 = and i32 %13147, 65535" -> "  %15532 = mul nuw nsw i32 %13962, 29744""  %13962 = and i32 %13147, 65535" -> "  %15525 = mul nuw nsw i32 %13962, 24315""  %13962 = and i32 %13147, 65535" -> "  %15483 = mul nuw nsw i32 %13962, 9871""  %13962 = and i32 %13147, 65535" -> "  %15476 = mul nuw i32 %13962, 42779""  %13962 = and i32 %13147, 65535" -> "  %15862 = mul nuw i32 %13962, 36786""  %13962 = and i32 %13147, 65535" -> "  %15855 = mul nuw nsw i32 %13962, 21884""  %13962 = and i32 %13147, 65535" -> "  %15813 = mul nuw nsw i32 %13962, 11561""  %13962 = and i32 %13147, 65535" -> "  %15806 = mul nuw nsw i32 %13962, 4087"
"  %13963 = mul nuw i32 %13962, 37996"
"  %13963 = mul nuw i32 %13962, 37996" -> "  %14095 = and i32 %13963, 65532""  %13963 = mul nuw i32 %13962, 37996" -> "  %13964 = lshr i32 %13963, 16"
"  %13964 = lshr i32 %13963, 16"
"  %13964 = lshr i32 %13963, 16" -> "  %13967 = add nuw nsw i32 %13966, %13964"
"  %13965 = mul nuw i32 %13961, 37996"
"  %13965 = mul nuw i32 %13961, 37996" -> "  %13966 = and i32 %13965, 65532""  %13965 = mul nuw i32 %13961, 37996" -> "  %13968 = and i32 %13965, -65536"
"  %13966 = and i32 %13965, 65532"
"  %13966 = and i32 %13965, 65532" -> "  %13967 = add nuw nsw i32 %13966, %13964"
"  %13967 = add nuw nsw i32 %13966, %13964"
"  %13967 = add nuw nsw i32 %13966, %13964" -> "  %13969 = add nuw i32 %13967, %13968"
"  %13968 = and i32 %13965, -65536"
"  %13968 = and i32 %13965, -65536" -> "  %13969 = add nuw i32 %13967, %13968"
"  %13969 = add nuw i32 %13967, %13968"
"  %13969 = add nuw i32 %13967, %13968" -> "  %13973 = lshr i32 %13969, 16""  %13969 = add nuw i32 %13967, %13968" -> "  %13971 = and i32 %13969, 65535"
"  %13970 = mul nuw i32 %13962, 45147"
"  %13970 = mul nuw i32 %13962, 45147" -> "  %13972 = add nuw i32 %13971, %13970"
"  %13971 = and i32 %13969, 65535"
"  %13971 = and i32 %13969, 65535" -> "  %13972 = add nuw i32 %13971, %13970"
"  %13972 = add nuw i32 %13971, %13970"
"  %13972 = add nuw i32 %13971, %13970" -> "  %14098 = and i32 %13972, 65535""  %13972 = add nuw i32 %13971, %13970" -> "  %13976 = lshr i32 %13972, 16"
"  %13973 = lshr i32 %13969, 16"
"  %13973 = lshr i32 %13969, 16" -> "  %13975 = add nuw i32 %13973, %13974"
"  %13974 = mul nuw i32 %13961, 45147"
"  %13974 = mul nuw i32 %13961, 45147" -> "  %13975 = add nuw i32 %13973, %13974"
"  %13975 = add nuw i32 %13973, %13974"
"  %13975 = add nuw i32 %13973, %13974" -> "  %13979 = and i32 %13975, -65536""  %13975 = add nuw i32 %13973, %13974" -> "  %13977 = and i32 %13975, 65535"
"  %13976 = lshr i32 %13972, 16"
"  %13976 = lshr i32 %13972, 16" -> "  %13978 = add nuw nsw i32 %13977, %13976"
"  %13977 = and i32 %13975, 65535"
"  %13977 = and i32 %13975, 65535" -> "  %13978 = add nuw nsw i32 %13977, %13976"
"  %13978 = add nuw nsw i32 %13977, %13976"
"  %13978 = add nuw nsw i32 %13977, %13976" -> "  %13980 = add nuw i32 %13978, %13979"
"  %13979 = and i32 %13975, -65536"
"  %13979 = and i32 %13975, -65536" -> "  %13980 = add nuw i32 %13978, %13979"
"  %13980 = add nuw i32 %13978, %13979"
"  %13980 = add nuw i32 %13978, %13979" -> "  %14005 = lshr i32 %13980, 16""  %13980 = add nuw i32 %13978, %13979" -> "  %14001 = and i32 %13980, 65535"
"  %13981 = and i32 %13152, 65535"
"  %13981 = and i32 %13152, 65535" -> "  %15824 = mul nuw nsw i32 %13981, 4087""  %13981 = and i32 %13152, 65535" -> "  %15831 = mul nuw nsw i32 %13981, 11561""  %13981 = and i32 %13152, 65535" -> "  %15886 = mul nuw nsw i32 %13981, 21884""  %13981 = and i32 %13152, 65535" -> "  %15893 = mul nuw i32 %13981, 36786""  %13981 = and i32 %13152, 65535" -> "  %15494 = mul nuw i32 %13981, 42779""  %13981 = and i32 %13152, 65535" -> "  %15501 = mul nuw nsw i32 %13981, 9871""  %13981 = and i32 %13152, 65535" -> "  %15556 = mul nuw nsw i32 %13981, 24315""  %13981 = and i32 %13152, 65535" -> "  %15563 = mul nuw nsw i32 %13981, 29744""  %13981 = and i32 %13152, 65535" -> "  %14316 = mul nuw nsw i32 %13981, 17857""  %13981 = and i32 %13152, 65535" -> "  %14323 = mul nuw i32 %13981, 46547""  %13981 = and i32 %13152, 65535" -> "  %14378 = mul nuw nsw i32 %13981, 31112""  %13981 = and i32 %13152, 65535" -> "  %14385 = mul nuw i32 %13981, 42170""  %13981 = and i32 %13152, 65535" -> "  %14055 = mul nuw i32 %13981, 62728""  %13981 = and i32 %13152, 65535" -> "  %14048 = mul nuw nsw i32 %13981, 1324""  %13981 = and i32 %13152, 65535" -> "  %13990 = mul nuw i32 %13981, 45147""  %13981 = and i32 %13152, 65535" -> "  %13983 = mul nuw i32 %13981, 37996"
"  %13982 = lshr i32 %13152, 16"
"  %13982 = lshr i32 %13152, 16" -> "  %15826 = mul nuw nsw i32 %13982, 4087""  %13982 = lshr i32 %13152, 16" -> "  %15835 = mul nuw nsw i32 %13982, 11561""  %13982 = lshr i32 %13152, 16" -> "  %15888 = mul nuw nsw i32 %13982, 21884""  %13982 = lshr i32 %13152, 16" -> "  %15897 = mul nuw i32 %13982, 36786""  %13982 = lshr i32 %13152, 16" -> "  %15496 = mul nuw i32 %13982, 42779""  %13982 = lshr i32 %13152, 16" -> "  %15505 = mul nuw nsw i32 %13982, 9871""  %13982 = lshr i32 %13152, 16" -> "  %15558 = mul nuw nsw i32 %13982, 24315""  %13982 = lshr i32 %13152, 16" -> "  %15567 = mul nuw nsw i32 %13982, 29744""  %13982 = lshr i32 %13152, 16" -> "  %14318 = mul nuw nsw i32 %13982, 17857""  %13982 = lshr i32 %13152, 16" -> "  %14327 = mul nuw i32 %13982, 46547""  %13982 = lshr i32 %13152, 16" -> "  %14380 = mul nuw nsw i32 %13982, 31112""  %13982 = lshr i32 %13152, 16" -> "  %14389 = mul nuw i32 %13982, 42170""  %13982 = lshr i32 %13152, 16" -> "  %14059 = mul nuw i32 %13982, 62728""  %13982 = lshr i32 %13152, 16" -> "  %14050 = mul nuw nsw i32 %13982, 1324""  %13982 = lshr i32 %13152, 16" -> "  %13994 = mul nuw i32 %13982, 45147""  %13982 = lshr i32 %13152, 16" -> "  %13985 = mul nuw i32 %13982, 37996"
"  %13983 = mul nuw i32 %13981, 37996"
"  %13983 = mul nuw i32 %13981, 37996" -> "  %14002 = and i32 %13983, 65532""  %13983 = mul nuw i32 %13981, 37996" -> "  %13984 = lshr i32 %13983, 16"
"  %13984 = lshr i32 %13983, 16"
"  %13984 = lshr i32 %13983, 16" -> "  %13987 = add nuw nsw i32 %13984, %13986"
"  %13985 = mul nuw i32 %13982, 37996"
"  %13985 = mul nuw i32 %13982, 37996" -> "  %13988 = and i32 %13985, -65536""  %13985 = mul nuw i32 %13982, 37996" -> "  %13986 = and i32 %13985, 65532"
"  %13986 = and i32 %13985, 65532"
"  %13986 = and i32 %13985, 65532" -> "  %13987 = add nuw nsw i32 %13984, %13986"
"  %13987 = add nuw nsw i32 %13984, %13986"
"  %13987 = add nuw nsw i32 %13984, %13986" -> "  %13989 = add nuw i32 %13987, %13988"
"  %13988 = and i32 %13985, -65536"
"  %13988 = and i32 %13985, -65536" -> "  %13989 = add nuw i32 %13987, %13988"
"  %13989 = add nuw i32 %13987, %13988"
"  %13989 = add nuw i32 %13987, %13988" -> "  %13993 = lshr i32 %13989, 16""  %13989 = add nuw i32 %13987, %13988" -> "  %13991 = and i32 %13989, 65535"
"  %13990 = mul nuw i32 %13981, 45147"
"  %13990 = mul nuw i32 %13981, 45147" -> "  %13992 = add nuw i32 %13991, %13990"
"  %13991 = and i32 %13989, 65535"
"  %13991 = and i32 %13989, 65535" -> "  %13992 = add nuw i32 %13991, %13990"
"  %13992 = add nuw i32 %13991, %13990"
"  %13992 = add nuw i32 %13991, %13990" -> "  %14004 = and i32 %13992, 65535""  %13992 = add nuw i32 %13991, %13990" -> "  %13996 = lshr i32 %13992, 16"
"  %13993 = lshr i32 %13989, 16"
"  %13993 = lshr i32 %13989, 16" -> "  %13995 = add nuw i32 %13993, %13994"
"  %13994 = mul nuw i32 %13982, 45147"
"  %13994 = mul nuw i32 %13982, 45147" -> "  %13995 = add nuw i32 %13993, %13994"
"  %13995 = add nuw i32 %13993, %13994"
"  %13995 = add nuw i32 %13993, %13994" -> "  %13999 = and i32 %13995, -65536""  %13995 = add nuw i32 %13993, %13994" -> "  %13997 = and i32 %13995, 65535"
"  %13996 = lshr i32 %13992, 16"
"  %13996 = lshr i32 %13992, 16" -> "  %13998 = add nuw nsw i32 %13996, %13997"
"  %13997 = and i32 %13995, 65535"
"  %13997 = and i32 %13995, 65535" -> "  %13998 = add nuw nsw i32 %13996, %13997"
"  %13998 = add nuw nsw i32 %13996, %13997"
"  %13998 = add nuw nsw i32 %13996, %13997" -> "  %14000 = add nuw i32 %13998, %13999"
"  %13999 = and i32 %13995, -65536"
"  %13999 = and i32 %13995, -65536" -> "  %14000 = add nuw i32 %13998, %13999"
"  %14000 = add nuw i32 %13998, %13999"
"  %14000 = add nuw i32 %13998, %13999" -> "  %14013 = and i32 %14000, -65536""  %14000 = add nuw i32 %13998, %13999" -> "  %14011 = and i32 %14000, 65535"
"  %14001 = and i32 %13980, 65535"
"  %14001 = and i32 %13980, 65535" -> "  %14003 = add nuw nsw i32 %14001, %14002"
"  %14002 = and i32 %13983, 65532"
"  %14002 = and i32 %13983, 65532" -> "  %14003 = add nuw nsw i32 %14001, %14002"
"  %14003 = add nuw nsw i32 %14001, %14002"
"  %14003 = add nuw nsw i32 %14001, %14002" -> "  %14035 = and i32 %14003, 65535""  %14003 = add nuw nsw i32 %14001, %14002" -> "  %14007 = lshr i32 %14003, 16"
"  %14004 = and i32 %13992, 65535"
"  %14004 = and i32 %13992, 65535" -> "  %14006 = add nuw nsw i32 %14005, %14004"
"  %14005 = lshr i32 %13980, 16"
"  %14005 = lshr i32 %13980, 16" -> "  %14006 = add nuw nsw i32 %14005, %14004"
"  %14006 = add nuw nsw i32 %14005, %14004"
"  %14006 = add nuw nsw i32 %14005, %14004" -> "  %14010 = lshr i32 %14006, 16""  %14006 = add nuw nsw i32 %14005, %14004" -> "  %14008 = and i32 %14006, 65535"
"  %14007 = lshr i32 %14003, 16"
"  %14007 = lshr i32 %14003, 16" -> "  %14009 = add nuw nsw i32 %14008, %14007"
"  %14008 = and i32 %14006, 65535"
"  %14008 = and i32 %14006, 65535" -> "  %14009 = add nuw nsw i32 %14008, %14007"
"  %14009 = add nuw nsw i32 %14008, %14007"
"  %14009 = add nuw nsw i32 %14008, %14007" -> "  %14038 = and i32 %14009, 65535""  %14009 = add nuw nsw i32 %14008, %14007" -> "  %14015 = lshr i32 %14009, 16"
"  %14010 = lshr i32 %14006, 16"
"  %14010 = lshr i32 %14006, 16" -> "  %14012 = add nuw nsw i32 %14011, %14010"
"  %14011 = and i32 %14000, 65535"
"  %14011 = and i32 %14000, 65535" -> "  %14012 = add nuw nsw i32 %14011, %14010"
"  %14012 = add nuw nsw i32 %14011, %14010"
"  %14012 = add nuw nsw i32 %14011, %14010" -> "  %14014 = add nuw i32 %14012, %14013"
"  %14013 = and i32 %14000, -65536"
"  %14013 = and i32 %14000, -65536" -> "  %14014 = add nuw i32 %14012, %14013"
"  %14014 = add nuw i32 %14012, %14013"
"  %14014 = add nuw i32 %14012, %14013" -> "  %14016 = add nuw i32 %14014, %14015"
"  %14015 = lshr i32 %14009, 16"
"  %14015 = lshr i32 %14009, 16" -> "  %14016 = add nuw i32 %14014, %14015"
"  %14016 = add nuw i32 %14014, %14015"
"  %14016 = add nuw i32 %14014, %14015" -> "  %14070 = lshr i32 %14016, 16""  %14016 = add nuw i32 %14014, %14015" -> "  %14066 = and i32 %14016, 65535"
"  %14017 = mul nuw nsw i32 %13962, 1324"
"  %14017 = mul nuw nsw i32 %13962, 1324" -> "  %14036 = and i32 %14017, 65532""  %14017 = mul nuw nsw i32 %13962, 1324" -> "  %14018 = lshr i32 %14017, 16"
"  %14018 = lshr i32 %14017, 16"
"  %14018 = lshr i32 %14017, 16" -> "  %14021 = add nuw nsw i32 %14020, %14018"
"  %14019 = mul nuw nsw i32 %13961, 1324"
"  %14019 = mul nuw nsw i32 %13961, 1324" -> "  %14022 = and i32 %14019, 134152192""  %14019 = mul nuw nsw i32 %13961, 1324" -> "  %14020 = and i32 %14019, 65532"
"  %14020 = and i32 %14019, 65532"
"  %14020 = and i32 %14019, 65532" -> "  %14021 = add nuw nsw i32 %14020, %14018"
"  %14021 = add nuw nsw i32 %14020, %14018"
"  %14021 = add nuw nsw i32 %14020, %14018" -> "  %14023 = add nuw nsw i32 %14021, %14022"
"  %14022 = and i32 %14019, 134152192"
"  %14022 = and i32 %14019, 134152192" -> "  %14023 = add nuw nsw i32 %14021, %14022"
"  %14023 = add nuw nsw i32 %14021, %14022"
"  %14023 = add nuw nsw i32 %14021, %14022" -> "  %14027 = lshr i32 %14023, 16""  %14023 = add nuw nsw i32 %14021, %14022" -> "  %14025 = and i32 %14023, 65535"
"  %14024 = mul nuw i32 %13962, 62728"
"  %14024 = mul nuw i32 %13962, 62728" -> "  %14026 = add nuw i32 %14025, %14024"
"  %14025 = and i32 %14023, 65535"
"  %14025 = and i32 %14023, 65535" -> "  %14026 = add nuw i32 %14025, %14024"
"  %14026 = add nuw i32 %14025, %14024"
"  %14026 = add nuw i32 %14025, %14024" -> "  %14039 = and i32 %14026, 65535""  %14026 = add nuw i32 %14025, %14024" -> "  %14030 = lshr i32 %14026, 16"
"  %14027 = lshr i32 %14023, 16"
"  %14027 = lshr i32 %14023, 16" -> "  %14029 = add nuw i32 %14027, %14028"
"  %14028 = mul nuw i32 %13961, 62728"
"  %14028 = mul nuw i32 %13961, 62728" -> "  %14029 = add nuw i32 %14027, %14028"
"  %14029 = add nuw i32 %14027, %14028"
"  %14029 = add nuw i32 %14027, %14028" -> "  %14033 = and i32 %14029, -65536""  %14029 = add nuw i32 %14027, %14028" -> "  %14031 = and i32 %14029, 65535"
"  %14030 = lshr i32 %14026, 16"
"  %14030 = lshr i32 %14026, 16" -> "  %14032 = add nuw nsw i32 %14030, %14031"
"  %14031 = and i32 %14029, 65535"
"  %14031 = and i32 %14029, 65535" -> "  %14032 = add nuw nsw i32 %14030, %14031"
"  %14032 = add nuw nsw i32 %14030, %14031"
"  %14032 = add nuw nsw i32 %14030, %14031" -> "  %14034 = add nuw i32 %14032, %14033"
"  %14033 = and i32 %14029, -65536"
"  %14033 = and i32 %14029, -65536" -> "  %14034 = add nuw i32 %14032, %14033"
"  %14034 = add nuw i32 %14032, %14033"
"  %14034 = add nuw i32 %14032, %14033" -> "  %14042 = add nuw i32 %14034, %14041"
"  %14035 = and i32 %14003, 65535"
"  %14035 = and i32 %14003, 65535" -> "  %14037 = add nuw nsw i32 %14035, %14036"
"  %14036 = and i32 %14017, 65532"
"  %14036 = and i32 %14017, 65532" -> "  %14037 = add nuw nsw i32 %14035, %14036"
"  %14037 = add nuw nsw i32 %14035, %14036"
"  %14037 = add nuw nsw i32 %14035, %14036" -> "  %14104 = and i32 %14037, 65535""  %14037 = add nuw nsw i32 %14035, %14036" -> "  %14044 = lshr i32 %14037, 16"
"  %14038 = and i32 %14009, 65535"
"  %14038 = and i32 %14009, 65535" -> "  %14040 = add nuw nsw i32 %14038, %14039"
"  %14039 = and i32 %14026, 65535"
"  %14039 = and i32 %14026, 65535" -> "  %14040 = add nuw nsw i32 %14038, %14039"
"  %14040 = add nuw nsw i32 %14038, %14039"
"  %14040 = add nuw nsw i32 %14038, %14039" -> "  %14043 = and i32 %14040, 65535""  %14040 = add nuw nsw i32 %14038, %14039" -> "  %14041 = lshr i32 %14040, 16"
"  %14041 = lshr i32 %14040, 16"
"  %14041 = lshr i32 %14040, 16" -> "  %14042 = add nuw i32 %14034, %14041"
"  %14042 = add nuw i32 %14034, %14041"
"  %14042 = add nuw i32 %14034, %14041" -> "  %14047 = add nuw i32 %14042, %14046"
"  %14043 = and i32 %14040, 65535"
"  %14043 = and i32 %14040, 65535" -> "  %14045 = add nuw nsw i32 %14043, %14044"
"  %14044 = lshr i32 %14037, 16"
"  %14044 = lshr i32 %14037, 16" -> "  %14045 = add nuw nsw i32 %14043, %14044"
"  %14045 = add nuw nsw i32 %14043, %14044"
"  %14045 = add nuw nsw i32 %14043, %14044" -> "  %14107 = and i32 %14045, 65535""  %14045 = add nuw nsw i32 %14043, %14044" -> "  %14046 = lshr i32 %14045, 16"
"  %14046 = lshr i32 %14045, 16"
"  %14046 = lshr i32 %14045, 16" -> "  %14047 = add nuw i32 %14042, %14046"
"  %14047 = add nuw i32 %14042, %14046"
"  %14047 = add nuw i32 %14042, %14046" -> "  %14083 = lshr i32 %14047, 16""  %14047 = add nuw i32 %14042, %14046" -> "  %14080 = and i32 %14047, 65535"
"  %14048 = mul nuw nsw i32 %13981, 1324"
"  %14048 = mul nuw nsw i32 %13981, 1324" -> "  %14067 = and i32 %14048, 65532""  %14048 = mul nuw nsw i32 %13981, 1324" -> "  %14049 = lshr i32 %14048, 16"
"  %14049 = lshr i32 %14048, 16"
"  %14049 = lshr i32 %14048, 16" -> "  %14052 = add nuw nsw i32 %14049, %14051"
"  %14050 = mul nuw nsw i32 %13982, 1324"
"  %14050 = mul nuw nsw i32 %13982, 1324" -> "  %14053 = and i32 %14050, 134152192""  %14050 = mul nuw nsw i32 %13982, 1324" -> "  %14051 = and i32 %14050, 65532"
"  %14051 = and i32 %14050, 65532"
"  %14051 = and i32 %14050, 65532" -> "  %14052 = add nuw nsw i32 %14049, %14051"
"  %14052 = add nuw nsw i32 %14049, %14051"
"  %14052 = add nuw nsw i32 %14049, %14051" -> "  %14054 = add nuw nsw i32 %14052, %14053"
"  %14053 = and i32 %14050, 134152192"
"  %14053 = and i32 %14050, 134152192" -> "  %14054 = add nuw nsw i32 %14052, %14053"
"  %14054 = add nuw nsw i32 %14052, %14053"
"  %14054 = add nuw nsw i32 %14052, %14053" -> "  %14058 = lshr i32 %14054, 16""  %14054 = add nuw nsw i32 %14052, %14053" -> "  %14056 = and i32 %14054, 65535"
"  %14055 = mul nuw i32 %13981, 62728"
"  %14055 = mul nuw i32 %13981, 62728" -> "  %14057 = add nuw i32 %14056, %14055"
"  %14056 = and i32 %14054, 65535"
"  %14056 = and i32 %14054, 65535" -> "  %14057 = add nuw i32 %14056, %14055"
"  %14057 = add nuw i32 %14056, %14055"
"  %14057 = add nuw i32 %14056, %14055" -> "  %14069 = and i32 %14057, 65535""  %14057 = add nuw i32 %14056, %14055" -> "  %14061 = lshr i32 %14057, 16"
"  %14058 = lshr i32 %14054, 16"
"  %14058 = lshr i32 %14054, 16" -> "  %14060 = add nuw i32 %14058, %14059"
"  %14059 = mul nuw i32 %13982, 62728"
"  %14059 = mul nuw i32 %13982, 62728" -> "  %14060 = add nuw i32 %14058, %14059"
"  %14060 = add nuw i32 %14058, %14059"
"  %14060 = add nuw i32 %14058, %14059" -> "  %14064 = and i32 %14060, -65536""  %14060 = add nuw i32 %14058, %14059" -> "  %14062 = and i32 %14060, 65535"
"  %14061 = lshr i32 %14057, 16"
"  %14061 = lshr i32 %14057, 16" -> "  %14063 = add nuw nsw i32 %14061, %14062"
"  %14062 = and i32 %14060, 65535"
"  %14062 = and i32 %14060, 65535" -> "  %14063 = add nuw nsw i32 %14061, %14062"
"  %14063 = add nuw nsw i32 %14061, %14062"
"  %14063 = add nuw nsw i32 %14061, %14062" -> "  %14065 = add nuw i32 %14063, %14064"
"  %14064 = and i32 %14060, -65536"
"  %14064 = and i32 %14060, -65536" -> "  %14065 = add nuw i32 %14063, %14064"
"  %14065 = add nuw i32 %14063, %14064"
"  %14065 = add nuw i32 %14063, %14064" -> "  %14073 = add nuw i32 %14065, %14072"
"  %14066 = and i32 %14016, 65535"
"  %14066 = and i32 %14016, 65535" -> "  %14068 = add nuw nsw i32 %14066, %14067"
"  %14067 = and i32 %14048, 65532"
"  %14067 = and i32 %14048, 65532" -> "  %14068 = add nuw nsw i32 %14066, %14067"
"  %14068 = add nuw nsw i32 %14066, %14067"
"  %14068 = add nuw nsw i32 %14066, %14067" -> "  %14079 = and i32 %14068, 65535""  %14068 = add nuw nsw i32 %14066, %14067" -> "  %14075 = lshr i32 %14068, 16"
"  %14069 = and i32 %14057, 65535"
"  %14069 = and i32 %14057, 65535" -> "  %14071 = add nuw nsw i32 %14070, %14069"
"  %14070 = lshr i32 %14016, 16"
"  %14070 = lshr i32 %14016, 16" -> "  %14071 = add nuw nsw i32 %14070, %14069"
"  %14071 = add nuw nsw i32 %14070, %14069"
"  %14071 = add nuw nsw i32 %14070, %14069" -> "  %14074 = and i32 %14071, 65535""  %14071 = add nuw nsw i32 %14070, %14069" -> "  %14072 = lshr i32 %14071, 16"
"  %14072 = lshr i32 %14071, 16"
"  %14072 = lshr i32 %14071, 16" -> "  %14073 = add nuw i32 %14065, %14072"
"  %14073 = add nuw i32 %14065, %14072"
"  %14073 = add nuw i32 %14065, %14072" -> "  %14078 = add nuw i32 %14073, %14077"
"  %14074 = and i32 %14071, 65535"
"  %14074 = and i32 %14071, 65535" -> "  %14076 = add nuw nsw i32 %14075, %14074"
"  %14075 = lshr i32 %14068, 16"
"  %14075 = lshr i32 %14068, 16" -> "  %14076 = add nuw nsw i32 %14075, %14074"
"  %14076 = add nuw nsw i32 %14075, %14074"
"  %14076 = add nuw nsw i32 %14075, %14074" -> "  %14082 = and i32 %14076, 65535""  %14076 = add nuw nsw i32 %14075, %14074" -> "  %14077 = lshr i32 %14076, 16"
"  %14077 = lshr i32 %14076, 16"
"  %14077 = lshr i32 %14076, 16" -> "  %14078 = add nuw i32 %14073, %14077"
"  %14078 = add nuw i32 %14073, %14077"
"  %14078 = add nuw i32 %14073, %14077" -> "  %14091 = and i32 %14078, -65536""  %14078 = add nuw i32 %14073, %14077" -> "  %14089 = and i32 %14078, 65535"
"  %14079 = and i32 %14068, 65535"
"  %14079 = and i32 %14068, 65535" -> "  %14081 = add nuw nsw i32 %14080, %14079"
"  %14080 = and i32 %14047, 65535"
"  %14080 = and i32 %14047, 65535" -> "  %14081 = add nuw nsw i32 %14080, %14079"
"  %14081 = add nuw nsw i32 %14080, %14079"
"  %14081 = add nuw nsw i32 %14080, %14079" -> "  %14121 = and i32 %14081, 65535""  %14081 = add nuw nsw i32 %14080, %14079" -> "  %14085 = lshr i32 %14081, 16"
"  %14082 = and i32 %14076, 65535"
"  %14082 = and i32 %14076, 65535" -> "  %14084 = add nuw nsw i32 %14082, %14083"
"  %14083 = lshr i32 %14047, 16"
"  %14083 = lshr i32 %14047, 16" -> "  %14084 = add nuw nsw i32 %14082, %14083"
"  %14084 = add nuw nsw i32 %14082, %14083"
"  %14084 = add nuw nsw i32 %14082, %14083" -> "  %14088 = lshr i32 %14084, 16""  %14084 = add nuw nsw i32 %14082, %14083" -> "  %14086 = and i32 %14084, 65535"
"  %14085 = lshr i32 %14081, 16"
"  %14085 = lshr i32 %14081, 16" -> "  %14087 = add nuw nsw i32 %14086, %14085"
"  %14086 = and i32 %14084, 65535"
"  %14086 = and i32 %14084, 65535" -> "  %14087 = add nuw nsw i32 %14086, %14085"
"  %14087 = add nuw nsw i32 %14086, %14085"
"  %14087 = add nuw nsw i32 %14086, %14085" -> "  %14128 = and i32 %14087, 65535""  %14087 = add nuw nsw i32 %14086, %14085" -> "  %14093 = lshr i32 %14087, 16"
"  %14088 = lshr i32 %14084, 16"
"  %14088 = lshr i32 %14084, 16" -> "  %14090 = add nuw nsw i32 %14088, %14089"
"  %14089 = and i32 %14078, 65535"
"  %14089 = and i32 %14078, 65535" -> "  %14090 = add nuw nsw i32 %14088, %14089"
"  %14090 = add nuw nsw i32 %14088, %14089"
"  %14090 = add nuw nsw i32 %14088, %14089" -> "  %14092 = add nuw i32 %14090, %14091"
"  %14091 = and i32 %14078, -65536"
"  %14091 = and i32 %14078, -65536" -> "  %14092 = add nuw i32 %14090, %14091"
"  %14092 = add nuw i32 %14090, %14091"
"  %14092 = add nuw i32 %14090, %14091" -> "  %14094 = add nuw i32 %14092, %14093"
"  %14093 = lshr i32 %14087, 16"
"  %14093 = lshr i32 %14087, 16" -> "  %14094 = add nuw i32 %14092, %14093"
"  %14094 = add nuw i32 %14092, %14093"
"  %14094 = add nuw i32 %14092, %14093" -> "  %14132 = add nuw i32 %14094, %14131"
"  %14095 = and i32 %13963, 65532"
"  %14095 = and i32 %13963, 65532" -> "  %14097 = add nuw nsw i32 %14096, %14095"
"  %14096 = and i32 %13947, 65535"
"  %14096 = and i32 %13947, 65535" -> "  %14097 = add nuw nsw i32 %14096, %14095"
"  %14097 = add nuw nsw i32 %14096, %14095"
"  %14097 = add nuw nsw i32 %14096, %14095" -> "  %14261 = and i32 %14097, 65535""  %14097 = add nuw nsw i32 %14096, %14095" -> "  %14101 = lshr i32 %14097, 16"
"  %14098 = and i32 %13972, 65535"
"  %14098 = and i32 %13972, 65535" -> "  %14100 = add nuw nsw i32 %14099, %14098"
"  %14099 = and i32 %13953, 65535"
"  %14099 = and i32 %13953, 65535" -> "  %14100 = add nuw nsw i32 %14099, %14098"
"  %14100 = add nuw nsw i32 %14099, %14098"
"  %14100 = add nuw nsw i32 %14099, %14098" -> "  %14114 = lshr i32 %14100, 16""  %14100 = add nuw nsw i32 %14099, %14098" -> "  %14102 = and i32 %14100, 65535"
"  %14101 = lshr i32 %14097, 16"
"  %14101 = lshr i32 %14097, 16" -> "  %14103 = add nuw nsw i32 %14102, %14101"
"  %14102 = and i32 %14100, 65535"
"  %14102 = and i32 %14100, 65535" -> "  %14103 = add nuw nsw i32 %14102, %14101"
"  %14103 = add nuw nsw i32 %14102, %14101"
"  %14103 = add nuw nsw i32 %14102, %14101" -> "  %14264 = and i32 %14103, 65535""  %14103 = add nuw nsw i32 %14102, %14101" -> "  %14116 = lshr i32 %14103, 16"
"  %14104 = and i32 %14037, 65535"
"  %14104 = and i32 %14037, 65535" -> "  %14106 = add nuw nsw i32 %14105, %14104"
"  %14105 = and i32 %13960, 65535"
"  %14105 = and i32 %13960, 65535" -> "  %14106 = add nuw nsw i32 %14105, %14104"
"  %14106 = add nuw nsw i32 %14105, %14104"
"  %14106 = add nuw nsw i32 %14105, %14104" -> "  %14113 = and i32 %14106, 65535""  %14106 = add nuw nsw i32 %14105, %14104" -> "  %14110 = lshr i32 %14106, 16"
"  %14107 = and i32 %14045, 65535"
"  %14107 = and i32 %14045, 65535" -> "  %14109 = add nuw nsw i32 %14108, %14107"
"  %14108 = lshr i32 %13960, 16"
"  %14108 = lshr i32 %13960, 16" -> "  %14109 = add nuw nsw i32 %14108, %14107"
"  %14109 = add nuw nsw i32 %14108, %14107"
"  %14109 = add nuw nsw i32 %14108, %14107" -> "  %14122 = lshr i32 %14109, 16""  %14109 = add nuw nsw i32 %14108, %14107" -> "  %14111 = and i32 %14109, 65535"
"  %14110 = lshr i32 %14106, 16"
"  %14110 = lshr i32 %14106, 16" -> "  %14112 = add nuw nsw i32 %14111, %14110"
"  %14111 = and i32 %14109, 65535"
"  %14111 = and i32 %14109, 65535" -> "  %14112 = add nuw nsw i32 %14111, %14110"
"  %14112 = add nuw nsw i32 %14111, %14110"
"  %14112 = add nuw nsw i32 %14111, %14110" -> "  %14124 = lshr i32 %14112, 16""  %14112 = add nuw nsw i32 %14111, %14110" -> "  %14119 = and i32 %14112, 65535"
"  %14113 = and i32 %14106, 65535"
"  %14113 = and i32 %14106, 65535" -> "  %14115 = add nuw nsw i32 %14113, %14114"
"  %14114 = lshr i32 %14100, 16"
"  %14114 = lshr i32 %14100, 16" -> "  %14115 = add nuw nsw i32 %14113, %14114"
"  %14115 = add nuw nsw i32 %14113, %14114"
"  %14115 = add nuw nsw i32 %14113, %14114" -> "  %14117 = add nuw nsw i32 %14115, %14116"
"  %14116 = lshr i32 %14103, 16"
"  %14116 = lshr i32 %14103, 16" -> "  %14117 = add nuw nsw i32 %14115, %14116"
"  %14117 = add nuw nsw i32 %14115, %14116"
"  %14117 = add nuw nsw i32 %14115, %14116" -> "  %14273 = and i32 %14117, 65535""  %14117 = add nuw nsw i32 %14115, %14116" -> "  %14118 = lshr i32 %14117, 16"
"  %14118 = lshr i32 %14117, 16"
"  %14118 = lshr i32 %14117, 16" -> "  %14120 = add nuw nsw i32 %14118, %14119"
"  %14119 = and i32 %14112, 65535"
"  %14119 = and i32 %14112, 65535" -> "  %14120 = add nuw nsw i32 %14118, %14119"
"  %14120 = add nuw nsw i32 %14118, %14119"
"  %14120 = add nuw nsw i32 %14118, %14119" -> "  %14276 = and i32 %14120, 65535""  %14120 = add nuw nsw i32 %14118, %14119" -> "  %14126 = lshr i32 %14120, 16"
"  %14121 = and i32 %14081, 65535"
"  %14121 = and i32 %14081, 65535" -> "  %14123 = add nuw nsw i32 %14121, %14122"
"  %14122 = lshr i32 %14109, 16"
"  %14122 = lshr i32 %14109, 16" -> "  %14123 = add nuw nsw i32 %14121, %14122"
"  %14123 = add nuw nsw i32 %14121, %14122"
"  %14123 = add nuw nsw i32 %14121, %14122" -> "  %14125 = add nuw nsw i32 %14123, %14124"
"  %14124 = lshr i32 %14112, 16"
"  %14124 = lshr i32 %14112, 16" -> "  %14125 = add nuw nsw i32 %14123, %14124"
"  %14125 = add nuw nsw i32 %14123, %14124"
"  %14125 = add nuw nsw i32 %14123, %14124" -> "  %14127 = add nuw nsw i32 %14125, %14126"
"  %14126 = lshr i32 %14120, 16"
"  %14126 = lshr i32 %14120, 16" -> "  %14127 = add nuw nsw i32 %14125, %14126"
"  %14127 = add nuw nsw i32 %14125, %14126"
"  %14127 = add nuw nsw i32 %14125, %14126" -> "  %14426 = and i32 %14127, 65535""  %14127 = add nuw nsw i32 %14125, %14126" -> "  %14129 = lshr i32 %14127, 16"
"  %14128 = and i32 %14087, 65535"
"  %14128 = and i32 %14087, 65535" -> "  %14130 = add nuw nsw i32 %14129, %14128"
"  %14129 = lshr i32 %14127, 16"
"  %14129 = lshr i32 %14127, 16" -> "  %14130 = add nuw nsw i32 %14129, %14128"
"  %14130 = add nuw nsw i32 %14129, %14128"
"  %14130 = add nuw nsw i32 %14129, %14128" -> "  %14429 = and i32 %14130, 65535""  %14130 = add nuw nsw i32 %14129, %14128" -> "  %14131 = lshr i32 %14130, 16"
"  %14131 = lshr i32 %14130, 16"
"  %14131 = lshr i32 %14130, 16" -> "  %14132 = add nuw i32 %14094, %14131"
"  %14132 = add nuw i32 %14094, %14131"
"  %14132 = add nuw i32 %14094, %14131" -> "  %14435 = and i32 %14132, 65535""  %14132 = add nuw i32 %14094, %14131" -> "  %14438 = lshr i32 %14132, 16"
"  %14133 = mul nuw nsw i32 %13827, 17857"
"  %14133 = mul nuw nsw i32 %13827, 17857" -> "  %14260 = and i32 %14133, 65535""  %14133 = mul nuw nsw i32 %13827, 17857" -> "  %14134 = lshr i32 %14133, 16"
"  %14134 = lshr i32 %14133, 16"
"  %14134 = lshr i32 %14133, 16" -> "  %14137 = add nuw nsw i32 %14136, %14134"
"  %14135 = mul nuw nsw i32 %13828, 17857"
"  %14135 = mul nuw nsw i32 %13828, 17857" -> "  %14138 = and i32 %14135, 2147418112""  %14135 = mul nuw nsw i32 %13828, 17857" -> "  %14136 = and i32 %14135, 65535"
"  %14136 = and i32 %14135, 65535"
"  %14136 = and i32 %14135, 65535" -> "  %14137 = add nuw nsw i32 %14136, %14134"
"  %14137 = add nuw nsw i32 %14136, %14134"
"  %14137 = add nuw nsw i32 %14136, %14134" -> "  %14139 = add nuw nsw i32 %14137, %14138"
"  %14138 = and i32 %14135, 2147418112"
"  %14138 = and i32 %14135, 2147418112" -> "  %14139 = add nuw nsw i32 %14137, %14138"
"  %14139 = add nuw nsw i32 %14137, %14138"
"  %14139 = add nuw nsw i32 %14137, %14138" -> "  %14143 = lshr i32 %14139, 16""  %14139 = add nuw nsw i32 %14137, %14138" -> "  %14141 = and i32 %14139, 65535"
"  %14140 = mul nuw i32 %13827, 46547"
"  %14140 = mul nuw i32 %13827, 46547" -> "  %14142 = add nuw i32 %14141, %14140"
"  %14141 = and i32 %14139, 65535"
"  %14141 = and i32 %14139, 65535" -> "  %14142 = add nuw i32 %14141, %14140"
"  %14142 = add nuw i32 %14141, %14140"
"  %14142 = add nuw i32 %14141, %14140" -> "  %14263 = and i32 %14142, 65535""  %14142 = add nuw i32 %14141, %14140" -> "  %14146 = lshr i32 %14142, 16"
"  %14143 = lshr i32 %14139, 16"
"  %14143 = lshr i32 %14139, 16" -> "  %14145 = add nuw i32 %14143, %14144"
"  %14144 = mul nuw i32 %13828, 46547"
"  %14144 = mul nuw i32 %13828, 46547" -> "  %14145 = add nuw i32 %14143, %14144"
"  %14145 = add nuw i32 %14143, %14144"
"  %14145 = add nuw i32 %14143, %14144" -> "  %14149 = and i32 %14145, -65536""  %14145 = add nuw i32 %14143, %14144" -> "  %14147 = and i32 %14145, 65535"
"  %14146 = lshr i32 %14142, 16"
"  %14146 = lshr i32 %14142, 16" -> "  %14148 = add nuw nsw i32 %14146, %14147"
"  %14147 = and i32 %14145, 65535"
"  %14147 = and i32 %14145, 65535" -> "  %14148 = add nuw nsw i32 %14146, %14147"
"  %14148 = add nuw nsw i32 %14146, %14147"
"  %14148 = add nuw nsw i32 %14146, %14147" -> "  %14150 = add nuw i32 %14148, %14149"
"  %14149 = and i32 %14145, -65536"
"  %14149 = and i32 %14145, -65536" -> "  %14150 = add nuw i32 %14148, %14149"
"  %14150 = add nuw i32 %14148, %14149"
"  %14150 = add nuw i32 %14148, %14149" -> "  %14173 = lshr i32 %14150, 16""  %14150 = add nuw i32 %14148, %14149" -> "  %14169 = and i32 %14150, 65535"
"  %14151 = mul nuw nsw i32 %13848, 17857"
"  %14151 = mul nuw nsw i32 %13848, 17857" -> "  %14170 = and i32 %14151, 65535""  %14151 = mul nuw nsw i32 %13848, 17857" -> "  %14152 = lshr i32 %14151, 16"
"  %14152 = lshr i32 %14151, 16"
"  %14152 = lshr i32 %14151, 16" -> "  %14155 = add nuw nsw i32 %14154, %14152"
"  %14153 = mul nuw nsw i32 %13847, 17857"
"  %14153 = mul nuw nsw i32 %13847, 17857" -> "  %14156 = and i32 %14153, 2147418112""  %14153 = mul nuw nsw i32 %13847, 17857" -> "  %14154 = and i32 %14153, 65535"
"  %14154 = and i32 %14153, 65535"
"  %14154 = and i32 %14153, 65535" -> "  %14155 = add nuw nsw i32 %14154, %14152"
"  %14155 = add nuw nsw i32 %14154, %14152"
"  %14155 = add nuw nsw i32 %14154, %14152" -> "  %14157 = add nuw nsw i32 %14155, %14156"
"  %14156 = and i32 %14153, 2147418112"
"  %14156 = and i32 %14153, 2147418112" -> "  %14157 = add nuw nsw i32 %14155, %14156"
"  %14157 = add nuw nsw i32 %14155, %14156"
"  %14157 = add nuw nsw i32 %14155, %14156" -> "  %14161 = lshr i32 %14157, 16""  %14157 = add nuw nsw i32 %14155, %14156" -> "  %14159 = and i32 %14157, 65535"
"  %14158 = mul nuw i32 %13848, 46547"
"  %14158 = mul nuw i32 %13848, 46547" -> "  %14160 = add nuw i32 %14159, %14158"
"  %14159 = and i32 %14157, 65535"
"  %14159 = and i32 %14157, 65535" -> "  %14160 = add nuw i32 %14159, %14158"
"  %14160 = add nuw i32 %14159, %14158"
"  %14160 = add nuw i32 %14159, %14158" -> "  %14172 = and i32 %14160, 65535""  %14160 = add nuw i32 %14159, %14158" -> "  %14164 = lshr i32 %14160, 16"
"  %14161 = lshr i32 %14157, 16"
"  %14161 = lshr i32 %14157, 16" -> "  %14163 = add nuw i32 %14161, %14162"
"  %14162 = mul nuw i32 %13847, 46547"
"  %14162 = mul nuw i32 %13847, 46547" -> "  %14163 = add nuw i32 %14161, %14162"
"  %14163 = add nuw i32 %14161, %14162"
"  %14163 = add nuw i32 %14161, %14162" -> "  %14167 = and i32 %14163, -65536""  %14163 = add nuw i32 %14161, %14162" -> "  %14165 = and i32 %14163, 65535"
"  %14164 = lshr i32 %14160, 16"
"  %14164 = lshr i32 %14160, 16" -> "  %14166 = add nuw nsw i32 %14164, %14165"
"  %14165 = and i32 %14163, 65535"
"  %14165 = and i32 %14163, 65535" -> "  %14166 = add nuw nsw i32 %14164, %14165"
"  %14166 = add nuw nsw i32 %14164, %14165"
"  %14166 = add nuw nsw i32 %14164, %14165" -> "  %14168 = add nuw i32 %14166, %14167"
"  %14167 = and i32 %14163, -65536"
"  %14167 = and i32 %14163, -65536" -> "  %14168 = add nuw i32 %14166, %14167"
"  %14168 = add nuw i32 %14166, %14167"
"  %14168 = add nuw i32 %14166, %14167" -> "  %14176 = add nuw i32 %14168, %14175"
"  %14169 = and i32 %14150, 65535"
"  %14169 = and i32 %14150, 65535" -> "  %14171 = add nuw nsw i32 %14169, %14170"
"  %14170 = and i32 %14151, 65535"
"  %14170 = and i32 %14151, 65535" -> "  %14171 = add nuw nsw i32 %14169, %14170"
"  %14171 = add nuw nsw i32 %14169, %14170"
"  %14171 = add nuw nsw i32 %14169, %14170" -> "  %14200 = and i32 %14171, 65535""  %14171 = add nuw nsw i32 %14169, %14170" -> "  %14178 = lshr i32 %14171, 16"
"  %14172 = and i32 %14160, 65535"
"  %14172 = and i32 %14160, 65535" -> "  %14174 = add nuw nsw i32 %14172, %14173"
"  %14173 = lshr i32 %14150, 16"
"  %14173 = lshr i32 %14150, 16" -> "  %14174 = add nuw nsw i32 %14172, %14173"
"  %14174 = add nuw nsw i32 %14172, %14173"
"  %14174 = add nuw nsw i32 %14172, %14173" -> "  %14177 = and i32 %14174, 65535""  %14174 = add nuw nsw i32 %14172, %14173" -> "  %14175 = lshr i32 %14174, 16"
"  %14175 = lshr i32 %14174, 16"
"  %14175 = lshr i32 %14174, 16" -> "  %14176 = add nuw i32 %14168, %14175"
"  %14176 = add nuw i32 %14168, %14175"
"  %14176 = add nuw i32 %14168, %14175" -> "  %14181 = add nuw i32 %14176, %14180"
"  %14177 = and i32 %14174, 65535"
"  %14177 = and i32 %14174, 65535" -> "  %14179 = add nuw nsw i32 %14177, %14178"
"  %14178 = lshr i32 %14171, 16"
"  %14178 = lshr i32 %14171, 16" -> "  %14179 = add nuw nsw i32 %14177, %14178"
"  %14179 = add nuw nsw i32 %14177, %14178"
"  %14179 = add nuw nsw i32 %14177, %14178" -> "  %14203 = and i32 %14179, 65535""  %14179 = add nuw nsw i32 %14177, %14178" -> "  %14180 = lshr i32 %14179, 16"
"  %14180 = lshr i32 %14179, 16"
"  %14180 = lshr i32 %14179, 16" -> "  %14181 = add nuw i32 %14176, %14180"
"  %14181 = add nuw i32 %14176, %14180"
"  %14181 = add nuw i32 %14176, %14180" -> "  %14235 = lshr i32 %14181, 16""  %14181 = add nuw i32 %14176, %14180" -> "  %14231 = and i32 %14181, 65535"
"  %14182 = mul nuw nsw i32 %13827, 31112"
"  %14182 = mul nuw nsw i32 %13827, 31112" -> "  %14201 = and i32 %14182, 65528""  %14182 = mul nuw nsw i32 %13827, 31112" -> "  %14183 = lshr i32 %14182, 16"
"  %14183 = lshr i32 %14182, 16"
"  %14183 = lshr i32 %14182, 16" -> "  %14186 = add nuw nsw i32 %14185, %14183"
"  %14184 = mul nuw nsw i32 %13828, 31112"
"  %14184 = mul nuw nsw i32 %13828, 31112" -> "  %14187 = and i32 %14184, 2147418112""  %14184 = mul nuw nsw i32 %13828, 31112" -> "  %14185 = and i32 %14184, 65528"
"  %14185 = and i32 %14184, 65528"
"  %14185 = and i32 %14184, 65528" -> "  %14186 = add nuw nsw i32 %14185, %14183"
"  %14186 = add nuw nsw i32 %14185, %14183"
"  %14186 = add nuw nsw i32 %14185, %14183" -> "  %14188 = add nuw nsw i32 %14186, %14187"
"  %14187 = and i32 %14184, 2147418112"
"  %14187 = and i32 %14184, 2147418112" -> "  %14188 = add nuw nsw i32 %14186, %14187"
"  %14188 = add nuw nsw i32 %14186, %14187"
"  %14188 = add nuw nsw i32 %14186, %14187" -> "  %14192 = lshr i32 %14188, 16""  %14188 = add nuw nsw i32 %14186, %14187" -> "  %14190 = and i32 %14188, 65535"
"  %14189 = mul nuw i32 %13827, 42170"
"  %14189 = mul nuw i32 %13827, 42170" -> "  %14191 = add nuw i32 %14190, %14189"
"  %14190 = and i32 %14188, 65535"
"  %14190 = and i32 %14188, 65535" -> "  %14191 = add nuw i32 %14190, %14189"
"  %14191 = add nuw i32 %14190, %14189"
"  %14191 = add nuw i32 %14190, %14189" -> "  %14204 = and i32 %14191, 65535""  %14191 = add nuw i32 %14190, %14189" -> "  %14195 = lshr i32 %14191, 16"
"  %14192 = lshr i32 %14188, 16"
"  %14192 = lshr i32 %14188, 16" -> "  %14194 = add nuw i32 %14192, %14193"
"  %14193 = mul nuw i32 %13828, 42170"
"  %14193 = mul nuw i32 %13828, 42170" -> "  %14194 = add nuw i32 %14192, %14193"
"  %14194 = add nuw i32 %14192, %14193"
"  %14194 = add nuw i32 %14192, %14193" -> "  %14198 = and i32 %14194, -65536""  %14194 = add nuw i32 %14192, %14193" -> "  %14196 = and i32 %14194, 65535"
"  %14195 = lshr i32 %14191, 16"
"  %14195 = lshr i32 %14191, 16" -> "  %14197 = add nuw nsw i32 %14195, %14196"
"  %14196 = and i32 %14194, 65535"
"  %14196 = and i32 %14194, 65535" -> "  %14197 = add nuw nsw i32 %14195, %14196"
"  %14197 = add nuw nsw i32 %14195, %14196"
"  %14197 = add nuw nsw i32 %14195, %14196" -> "  %14199 = add nuw i32 %14197, %14198"
"  %14198 = and i32 %14194, -65536"
"  %14198 = and i32 %14194, -65536" -> "  %14199 = add nuw i32 %14197, %14198"
"  %14199 = add nuw i32 %14197, %14198"
"  %14199 = add nuw i32 %14197, %14198" -> "  %14207 = add nuw i32 %14199, %14206"
"  %14200 = and i32 %14171, 65535"
"  %14200 = and i32 %14171, 65535" -> "  %14202 = add nuw nsw i32 %14200, %14201"
"  %14201 = and i32 %14182, 65528"
"  %14201 = and i32 %14182, 65528" -> "  %14202 = add nuw nsw i32 %14200, %14201"
"  %14202 = add nuw nsw i32 %14200, %14201"
"  %14202 = add nuw nsw i32 %14200, %14201" -> "  %14272 = and i32 %14202, 65535""  %14202 = add nuw nsw i32 %14200, %14201" -> "  %14209 = lshr i32 %14202, 16"
"  %14203 = and i32 %14179, 65535"
"  %14203 = and i32 %14179, 65535" -> "  %14205 = add nuw nsw i32 %14203, %14204"
"  %14204 = and i32 %14191, 65535"
"  %14204 = and i32 %14191, 65535" -> "  %14205 = add nuw nsw i32 %14203, %14204"
"  %14205 = add nuw nsw i32 %14203, %14204"
"  %14205 = add nuw nsw i32 %14203, %14204" -> "  %14208 = and i32 %14205, 65535""  %14205 = add nuw nsw i32 %14203, %14204" -> "  %14206 = lshr i32 %14205, 16"
"  %14206 = lshr i32 %14205, 16"
"  %14206 = lshr i32 %14205, 16" -> "  %14207 = add nuw i32 %14199, %14206"
"  %14207 = add nuw i32 %14199, %14206"
"  %14207 = add nuw i32 %14199, %14206" -> "  %14212 = add nuw i32 %14207, %14211"
"  %14208 = and i32 %14205, 65535"
"  %14208 = and i32 %14205, 65535" -> "  %14210 = add nuw nsw i32 %14208, %14209"
"  %14209 = lshr i32 %14202, 16"
"  %14209 = lshr i32 %14202, 16" -> "  %14210 = add nuw nsw i32 %14208, %14209"
"  %14210 = add nuw nsw i32 %14208, %14209"
"  %14210 = add nuw nsw i32 %14208, %14209" -> "  %14275 = and i32 %14210, 65535""  %14210 = add nuw nsw i32 %14208, %14209" -> "  %14211 = lshr i32 %14210, 16"
"  %14211 = lshr i32 %14210, 16"
"  %14211 = lshr i32 %14210, 16" -> "  %14212 = add nuw i32 %14207, %14211"
"  %14212 = add nuw i32 %14207, %14211"
"  %14212 = add nuw i32 %14207, %14211" -> "  %14248 = lshr i32 %14212, 16""  %14212 = add nuw i32 %14207, %14211" -> "  %14245 = and i32 %14212, 65535"
"  %14213 = mul nuw nsw i32 %13848, 31112"
"  %14213 = mul nuw nsw i32 %13848, 31112" -> "  %14232 = and i32 %14213, 65528""  %14213 = mul nuw nsw i32 %13848, 31112" -> "  %14214 = lshr i32 %14213, 16"
"  %14214 = lshr i32 %14213, 16"
"  %14214 = lshr i32 %14213, 16" -> "  %14217 = add nuw nsw i32 %14216, %14214"
"  %14215 = mul nuw nsw i32 %13847, 31112"
"  %14215 = mul nuw nsw i32 %13847, 31112" -> "  %14218 = and i32 %14215, 2147418112""  %14215 = mul nuw nsw i32 %13847, 31112" -> "  %14216 = and i32 %14215, 65528"
"  %14216 = and i32 %14215, 65528"
"  %14216 = and i32 %14215, 65528" -> "  %14217 = add nuw nsw i32 %14216, %14214"
"  %14217 = add nuw nsw i32 %14216, %14214"
"  %14217 = add nuw nsw i32 %14216, %14214" -> "  %14219 = add nuw nsw i32 %14217, %14218"
"  %14218 = and i32 %14215, 2147418112"
"  %14218 = and i32 %14215, 2147418112" -> "  %14219 = add nuw nsw i32 %14217, %14218"
"  %14219 = add nuw nsw i32 %14217, %14218"
"  %14219 = add nuw nsw i32 %14217, %14218" -> "  %14223 = lshr i32 %14219, 16""  %14219 = add nuw nsw i32 %14217, %14218" -> "  %14221 = and i32 %14219, 65535"
"  %14220 = mul nuw i32 %13848, 42170"
"  %14220 = mul nuw i32 %13848, 42170" -> "  %14222 = add nuw i32 %14221, %14220"
"  %14221 = and i32 %14219, 65535"
"  %14221 = and i32 %14219, 65535" -> "  %14222 = add nuw i32 %14221, %14220"
"  %14222 = add nuw i32 %14221, %14220"
"  %14222 = add nuw i32 %14221, %14220" -> "  %14234 = and i32 %14222, 65535""  %14222 = add nuw i32 %14221, %14220" -> "  %14226 = lshr i32 %14222, 16"
"  %14223 = lshr i32 %14219, 16"
"  %14223 = lshr i32 %14219, 16" -> "  %14225 = add nuw i32 %14223, %14224"
"  %14224 = mul nuw i32 %13847, 42170"
"  %14224 = mul nuw i32 %13847, 42170" -> "  %14225 = add nuw i32 %14223, %14224"
"  %14225 = add nuw i32 %14223, %14224"
"  %14225 = add nuw i32 %14223, %14224" -> "  %14229 = and i32 %14225, -65536""  %14225 = add nuw i32 %14223, %14224" -> "  %14227 = and i32 %14225, 65535"
"  %14226 = lshr i32 %14222, 16"
"  %14226 = lshr i32 %14222, 16" -> "  %14228 = add nuw nsw i32 %14226, %14227"
"  %14227 = and i32 %14225, 65535"
"  %14227 = and i32 %14225, 65535" -> "  %14228 = add nuw nsw i32 %14226, %14227"
"  %14228 = add nuw nsw i32 %14226, %14227"
"  %14228 = add nuw nsw i32 %14226, %14227" -> "  %14230 = add nuw i32 %14228, %14229"
"  %14229 = and i32 %14225, -65536"
"  %14229 = and i32 %14225, -65536" -> "  %14230 = add nuw i32 %14228, %14229"
"  %14230 = add nuw i32 %14228, %14229"
"  %14230 = add nuw i32 %14228, %14229" -> "  %14238 = add nuw i32 %14230, %14237"
"  %14231 = and i32 %14181, 65535"
"  %14231 = and i32 %14181, 65535" -> "  %14233 = add nuw nsw i32 %14231, %14232"
"  %14232 = and i32 %14213, 65528"
"  %14232 = and i32 %14213, 65528" -> "  %14233 = add nuw nsw i32 %14231, %14232"
"  %14233 = add nuw nsw i32 %14231, %14232"
"  %14233 = add nuw nsw i32 %14231, %14232" -> "  %14244 = and i32 %14233, 65535""  %14233 = add nuw nsw i32 %14231, %14232" -> "  %14240 = lshr i32 %14233, 16"
"  %14234 = and i32 %14222, 65535"
"  %14234 = and i32 %14222, 65535" -> "  %14236 = add nuw nsw i32 %14235, %14234"
"  %14235 = lshr i32 %14181, 16"
"  %14235 = lshr i32 %14181, 16" -> "  %14236 = add nuw nsw i32 %14235, %14234"
"  %14236 = add nuw nsw i32 %14235, %14234"
"  %14236 = add nuw nsw i32 %14235, %14234" -> "  %14239 = and i32 %14236, 65535""  %14236 = add nuw nsw i32 %14235, %14234" -> "  %14237 = lshr i32 %14236, 16"
"  %14237 = lshr i32 %14236, 16"
"  %14237 = lshr i32 %14236, 16" -> "  %14238 = add nuw i32 %14230, %14237"
"  %14238 = add nuw i32 %14230, %14237"
"  %14238 = add nuw i32 %14230, %14237" -> "  %14243 = add nuw i32 %14238, %14242"
"  %14239 = and i32 %14236, 65535"
"  %14239 = and i32 %14236, 65535" -> "  %14241 = add nuw nsw i32 %14240, %14239"
"  %14240 = lshr i32 %14233, 16"
"  %14240 = lshr i32 %14233, 16" -> "  %14241 = add nuw nsw i32 %14240, %14239"
"  %14241 = add nuw nsw i32 %14240, %14239"
"  %14241 = add nuw nsw i32 %14240, %14239" -> "  %14247 = and i32 %14241, 65535""  %14241 = add nuw nsw i32 %14240, %14239" -> "  %14242 = lshr i32 %14241, 16"
"  %14242 = lshr i32 %14241, 16"
"  %14242 = lshr i32 %14241, 16" -> "  %14243 = add nuw i32 %14238, %14242"
"  %14243 = add nuw i32 %14238, %14242"
"  %14243 = add nuw i32 %14238, %14242" -> "  %14256 = and i32 %14243, -65536""  %14243 = add nuw i32 %14238, %14242" -> "  %14254 = and i32 %14243, 65535"
"  %14244 = and i32 %14233, 65535"
"  %14244 = and i32 %14233, 65535" -> "  %14246 = add nuw nsw i32 %14245, %14244"
"  %14245 = and i32 %14212, 65535"
"  %14245 = and i32 %14212, 65535" -> "  %14246 = add nuw nsw i32 %14245, %14244"
"  %14246 = add nuw nsw i32 %14245, %14244"
"  %14246 = add nuw nsw i32 %14245, %14244" -> "  %14286 = and i32 %14246, 65535""  %14246 = add nuw nsw i32 %14245, %14244" -> "  %14250 = lshr i32 %14246, 16"
"  %14247 = and i32 %14241, 65535"
"  %14247 = and i32 %14241, 65535" -> "  %14249 = add nuw nsw i32 %14248, %14247"
"  %14248 = lshr i32 %14212, 16"
"  %14248 = lshr i32 %14212, 16" -> "  %14249 = add nuw nsw i32 %14248, %14247"
"  %14249 = add nuw nsw i32 %14248, %14247"
"  %14249 = add nuw nsw i32 %14248, %14247" -> "  %14253 = lshr i32 %14249, 16""  %14249 = add nuw nsw i32 %14248, %14247" -> "  %14251 = and i32 %14249, 65535"
"  %14250 = lshr i32 %14246, 16"
"  %14250 = lshr i32 %14246, 16" -> "  %14252 = add nuw nsw i32 %14250, %14251"
"  %14251 = and i32 %14249, 65535"
"  %14251 = and i32 %14249, 65535" -> "  %14252 = add nuw nsw i32 %14250, %14251"
"  %14252 = add nuw nsw i32 %14250, %14251"
"  %14252 = add nuw nsw i32 %14250, %14251" -> "  %14293 = and i32 %14252, 65535""  %14252 = add nuw nsw i32 %14250, %14251" -> "  %14258 = lshr i32 %14252, 16"
"  %14253 = lshr i32 %14249, 16"
"  %14253 = lshr i32 %14249, 16" -> "  %14255 = add nuw nsw i32 %14253, %14254"
"  %14254 = and i32 %14243, 65535"
"  %14254 = and i32 %14243, 65535" -> "  %14255 = add nuw nsw i32 %14253, %14254"
"  %14255 = add nuw nsw i32 %14253, %14254"
"  %14255 = add nuw nsw i32 %14253, %14254" -> "  %14257 = add nuw i32 %14255, %14256"
"  %14256 = and i32 %14243, -65536"
"  %14256 = and i32 %14243, -65536" -> "  %14257 = add nuw i32 %14255, %14256"
"  %14257 = add nuw i32 %14255, %14256"
"  %14257 = add nuw i32 %14255, %14256" -> "  %14259 = add nuw i32 %14257, %14258"
"  %14258 = lshr i32 %14252, 16"
"  %14258 = lshr i32 %14252, 16" -> "  %14259 = add nuw i32 %14257, %14258"
"  %14259 = add nuw i32 %14257, %14258"
"  %14259 = add nuw i32 %14257, %14258" -> "  %14297 = add nuw i32 %14259, %14296"
"  %14260 = and i32 %14133, 65535"
"  %14260 = and i32 %14133, 65535" -> "  %14262 = add nuw nsw i32 %14261, %14260"
"  %14261 = and i32 %14097, 65535"
"  %14261 = and i32 %14097, 65535" -> "  %14262 = add nuw nsw i32 %14261, %14260"
"  %14262 = add nuw nsw i32 %14261, %14260"
"  %14262 = add nuw nsw i32 %14261, %14260" -> "  %14528 = and i32 %14262, 65535""  %14262 = add nuw nsw i32 %14261, %14260" -> "  %14266 = lshr i32 %14262, 16"
"  %14263 = and i32 %14142, 65535"
"  %14263 = and i32 %14142, 65535" -> "  %14265 = add nuw nsw i32 %14264, %14263"
"  %14264 = and i32 %14103, 65535"
"  %14264 = and i32 %14103, 65535" -> "  %14265 = add nuw nsw i32 %14264, %14263"
"  %14265 = add nuw nsw i32 %14264, %14263"
"  %14265 = add nuw nsw i32 %14264, %14263" -> "  %14269 = lshr i32 %14265, 16""  %14265 = add nuw nsw i32 %14264, %14263" -> "  %14267 = and i32 %14265, 65535"
"  %14266 = lshr i32 %14262, 16"
"  %14266 = lshr i32 %14262, 16" -> "  %14268 = add nuw nsw i32 %14267, %14266"
"  %14267 = and i32 %14265, 65535"
"  %14267 = and i32 %14265, 65535" -> "  %14268 = add nuw nsw i32 %14267, %14266"
"  %14268 = add nuw nsw i32 %14267, %14266"
"  %14268 = add nuw nsw i32 %14267, %14266" -> "  %14531 = and i32 %14268, 65535""  %14268 = add nuw nsw i32 %14267, %14266" -> "  %14270 = lshr i32 %14268, 16"
"  %14269 = lshr i32 %14265, 16"
"  %14269 = lshr i32 %14265, 16" -> "  %14271 = add nuw nsw i32 %14270, %14269"
"  %14270 = lshr i32 %14268, 16"
"  %14270 = lshr i32 %14268, 16" -> "  %14271 = add nuw nsw i32 %14270, %14269"
"  %14271 = add nuw nsw i32 %14270, %14269"
"  %14271 = add nuw nsw i32 %14270, %14269" -> "  %14282 = add nuw nsw i32 %14271, %14281"
"  %14272 = and i32 %14202, 65535"
"  %14272 = and i32 %14202, 65535" -> "  %14274 = add nuw nsw i32 %14273, %14272"
"  %14273 = and i32 %14117, 65535"
"  %14273 = and i32 %14117, 65535" -> "  %14274 = add nuw nsw i32 %14273, %14272"
"  %14274 = add nuw nsw i32 %14273, %14272"
"  %14274 = add nuw nsw i32 %14273, %14272" -> "  %14281 = and i32 %14274, 65535""  %14274 = add nuw nsw i32 %14273, %14272" -> "  %14278 = lshr i32 %14274, 16"
"  %14275 = and i32 %14210, 65535"
"  %14275 = and i32 %14210, 65535" -> "  %14277 = add nuw nsw i32 %14276, %14275"
"  %14276 = and i32 %14120, 65535"
"  %14276 = and i32 %14120, 65535" -> "  %14277 = add nuw nsw i32 %14276, %14275"
"  %14277 = add nuw nsw i32 %14276, %14275"
"  %14277 = add nuw nsw i32 %14276, %14275" -> "  %14287 = lshr i32 %14277, 16""  %14277 = add nuw nsw i32 %14276, %14275" -> "  %14279 = and i32 %14277, 65535"
"  %14278 = lshr i32 %14274, 16"
"  %14278 = lshr i32 %14274, 16" -> "  %14280 = add nuw nsw i32 %14279, %14278"
"  %14279 = and i32 %14277, 65535"
"  %14279 = and i32 %14277, 65535" -> "  %14280 = add nuw nsw i32 %14279, %14278"
"  %14280 = add nuw nsw i32 %14279, %14278"
"  %14280 = add nuw nsw i32 %14279, %14278" -> "  %14289 = lshr i32 %14280, 16""  %14280 = add nuw nsw i32 %14279, %14278" -> "  %14284 = and i32 %14280, 65535"
"  %14281 = and i32 %14274, 65535"
"  %14281 = and i32 %14274, 65535" -> "  %14282 = add nuw nsw i32 %14271, %14281"
"  %14282 = add nuw nsw i32 %14271, %14281"
"  %14282 = add nuw nsw i32 %14271, %14281" -> "  %14537 = and i32 %14282, 65535""  %14282 = add nuw nsw i32 %14271, %14281" -> "  %14283 = lshr i32 %14282, 16"
"  %14283 = lshr i32 %14282, 16"
"  %14283 = lshr i32 %14282, 16" -> "  %14285 = add nuw nsw i32 %14284, %14283"
"  %14284 = and i32 %14280, 65535"
"  %14284 = and i32 %14280, 65535" -> "  %14285 = add nuw nsw i32 %14284, %14283"
"  %14285 = add nuw nsw i32 %14284, %14283"
"  %14285 = add nuw nsw i32 %14284, %14283" -> "  %14540 = and i32 %14285, 65535""  %14285 = add nuw nsw i32 %14284, %14283" -> "  %14291 = lshr i32 %14285, 16"
"  %14286 = and i32 %14246, 65535"
"  %14286 = and i32 %14246, 65535" -> "  %14288 = add nuw nsw i32 %14287, %14286"
"  %14287 = lshr i32 %14277, 16"
"  %14287 = lshr i32 %14277, 16" -> "  %14288 = add nuw nsw i32 %14287, %14286"
"  %14288 = add nuw nsw i32 %14287, %14286"
"  %14288 = add nuw nsw i32 %14287, %14286" -> "  %14290 = add nuw nsw i32 %14288, %14289"
"  %14289 = lshr i32 %14280, 16"
"  %14289 = lshr i32 %14280, 16" -> "  %14290 = add nuw nsw i32 %14288, %14289"
"  %14290 = add nuw nsw i32 %14288, %14289"
"  %14290 = add nuw nsw i32 %14288, %14289" -> "  %14292 = add nuw nsw i32 %14290, %14291"
"  %14291 = lshr i32 %14285, 16"
"  %14291 = lshr i32 %14285, 16" -> "  %14292 = add nuw nsw i32 %14290, %14291"
"  %14292 = add nuw nsw i32 %14290, %14291"
"  %14292 = add nuw nsw i32 %14290, %14291" -> "  %14464 = and i32 %14292, 65535""  %14292 = add nuw nsw i32 %14290, %14291" -> "  %14294 = lshr i32 %14292, 16"
"  %14293 = and i32 %14252, 65535"
"  %14293 = and i32 %14252, 65535" -> "  %14295 = add nuw nsw i32 %14294, %14293"
"  %14294 = lshr i32 %14292, 16"
"  %14294 = lshr i32 %14292, 16" -> "  %14295 = add nuw nsw i32 %14294, %14293"
"  %14295 = add nuw nsw i32 %14294, %14293"
"  %14295 = add nuw nsw i32 %14294, %14293" -> "  %14467 = and i32 %14295, 65535""  %14295 = add nuw nsw i32 %14294, %14293" -> "  %14296 = lshr i32 %14295, 16"
"  %14296 = lshr i32 %14295, 16"
"  %14296 = lshr i32 %14295, 16" -> "  %14297 = add nuw i32 %14259, %14296"
"  %14297 = add nuw i32 %14259, %14296"
"  %14297 = add nuw i32 %14259, %14296" -> "  %14472 = and i32 %14297, 65535""  %14297 = add nuw i32 %14259, %14296" -> "  %14475 = lshr i32 %14297, 16"
"  %14298 = mul nuw nsw i32 %13962, 17857"
"  %14298 = mul nuw nsw i32 %13962, 17857" -> "  %14425 = and i32 %14298, 65535""  %14298 = mul nuw nsw i32 %13962, 17857" -> "  %14299 = lshr i32 %14298, 16"
"  %14299 = lshr i32 %14298, 16"
"  %14299 = lshr i32 %14298, 16" -> "  %14302 = add nuw nsw i32 %14301, %14299"
"  %14300 = mul nuw nsw i32 %13961, 17857"
"  %14300 = mul nuw nsw i32 %13961, 17857" -> "  %14303 = and i32 %14300, 2147418112""  %14300 = mul nuw nsw i32 %13961, 17857" -> "  %14301 = and i32 %14300, 65535"
"  %14301 = and i32 %14300, 65535"
"  %14301 = and i32 %14300, 65535" -> "  %14302 = add nuw nsw i32 %14301, %14299"
"  %14302 = add nuw nsw i32 %14301, %14299"
"  %14302 = add nuw nsw i32 %14301, %14299" -> "  %14304 = add nuw nsw i32 %14302, %14303"
"  %14303 = and i32 %14300, 2147418112"
"  %14303 = and i32 %14300, 2147418112" -> "  %14304 = add nuw nsw i32 %14302, %14303"
"  %14304 = add nuw nsw i32 %14302, %14303"
"  %14304 = add nuw nsw i32 %14302, %14303" -> "  %14308 = lshr i32 %14304, 16""  %14304 = add nuw nsw i32 %14302, %14303" -> "  %14306 = and i32 %14304, 65535"
"  %14305 = mul nuw i32 %13962, 46547"
"  %14305 = mul nuw i32 %13962, 46547" -> "  %14307 = add nuw i32 %14306, %14305"
"  %14306 = and i32 %14304, 65535"
"  %14306 = and i32 %14304, 65535" -> "  %14307 = add nuw i32 %14306, %14305"
"  %14307 = add nuw i32 %14306, %14305"
"  %14307 = add nuw i32 %14306, %14305" -> "  %14428 = and i32 %14307, 65535""  %14307 = add nuw i32 %14306, %14305" -> "  %14311 = lshr i32 %14307, 16"
"  %14308 = lshr i32 %14304, 16"
"  %14308 = lshr i32 %14304, 16" -> "  %14310 = add nuw i32 %14308, %14309"
"  %14309 = mul nuw i32 %13961, 46547"
"  %14309 = mul nuw i32 %13961, 46547" -> "  %14310 = add nuw i32 %14308, %14309"
"  %14310 = add nuw i32 %14308, %14309"
"  %14310 = add nuw i32 %14308, %14309" -> "  %14314 = and i32 %14310, -65536""  %14310 = add nuw i32 %14308, %14309" -> "  %14312 = and i32 %14310, 65535"
"  %14311 = lshr i32 %14307, 16"
"  %14311 = lshr i32 %14307, 16" -> "  %14313 = add nuw nsw i32 %14311, %14312"
"  %14312 = and i32 %14310, 65535"
"  %14312 = and i32 %14310, 65535" -> "  %14313 = add nuw nsw i32 %14311, %14312"
"  %14313 = add nuw nsw i32 %14311, %14312"
"  %14313 = add nuw nsw i32 %14311, %14312" -> "  %14315 = add nuw i32 %14313, %14314"
"  %14314 = and i32 %14310, -65536"
"  %14314 = and i32 %14310, -65536" -> "  %14315 = add nuw i32 %14313, %14314"
"  %14315 = add nuw i32 %14313, %14314"
"  %14315 = add nuw i32 %14313, %14314" -> "  %14338 = lshr i32 %14315, 16""  %14315 = add nuw i32 %14313, %14314" -> "  %14334 = and i32 %14315, 65535"
"  %14316 = mul nuw nsw i32 %13981, 17857"
"  %14316 = mul nuw nsw i32 %13981, 17857" -> "  %14335 = and i32 %14316, 65535""  %14316 = mul nuw nsw i32 %13981, 17857" -> "  %14317 = lshr i32 %14316, 16"
"  %14317 = lshr i32 %14316, 16"
"  %14317 = lshr i32 %14316, 16" -> "  %14320 = add nuw nsw i32 %14319, %14317"
"  %14318 = mul nuw nsw i32 %13982, 17857"
"  %14318 = mul nuw nsw i32 %13982, 17857" -> "  %14321 = and i32 %14318, 2147418112""  %14318 = mul nuw nsw i32 %13982, 17857" -> "  %14319 = and i32 %14318, 65535"
"  %14319 = and i32 %14318, 65535"
"  %14319 = and i32 %14318, 65535" -> "  %14320 = add nuw nsw i32 %14319, %14317"
"  %14320 = add nuw nsw i32 %14319, %14317"
"  %14320 = add nuw nsw i32 %14319, %14317" -> "  %14322 = add nuw nsw i32 %14320, %14321"
"  %14321 = and i32 %14318, 2147418112"
"  %14321 = and i32 %14318, 2147418112" -> "  %14322 = add nuw nsw i32 %14320, %14321"
"  %14322 = add nuw nsw i32 %14320, %14321"
"  %14322 = add nuw nsw i32 %14320, %14321" -> "  %14326 = lshr i32 %14322, 16""  %14322 = add nuw nsw i32 %14320, %14321" -> "  %14324 = and i32 %14322, 65535"
"  %14323 = mul nuw i32 %13981, 46547"
"  %14323 = mul nuw i32 %13981, 46547" -> "  %14325 = add nuw i32 %14324, %14323"
"  %14324 = and i32 %14322, 65535"
"  %14324 = and i32 %14322, 65535" -> "  %14325 = add nuw i32 %14324, %14323"
"  %14325 = add nuw i32 %14324, %14323"
"  %14325 = add nuw i32 %14324, %14323" -> "  %14337 = and i32 %14325, 65535""  %14325 = add nuw i32 %14324, %14323" -> "  %14329 = lshr i32 %14325, 16"
"  %14326 = lshr i32 %14322, 16"
"  %14326 = lshr i32 %14322, 16" -> "  %14328 = add nuw i32 %14326, %14327"
"  %14327 = mul nuw i32 %13982, 46547"
"  %14327 = mul nuw i32 %13982, 46547" -> "  %14328 = add nuw i32 %14326, %14327"
"  %14328 = add nuw i32 %14326, %14327"
"  %14328 = add nuw i32 %14326, %14327" -> "  %14332 = and i32 %14328, -65536""  %14328 = add nuw i32 %14326, %14327" -> "  %14330 = and i32 %14328, 65535"
"  %14329 = lshr i32 %14325, 16"
"  %14329 = lshr i32 %14325, 16" -> "  %14331 = add nuw nsw i32 %14329, %14330"
"  %14330 = and i32 %14328, 65535"
"  %14330 = and i32 %14328, 65535" -> "  %14331 = add nuw nsw i32 %14329, %14330"
"  %14331 = add nuw nsw i32 %14329, %14330"
"  %14331 = add nuw nsw i32 %14329, %14330" -> "  %14333 = add nuw i32 %14331, %14332"
"  %14332 = and i32 %14328, -65536"
"  %14332 = and i32 %14328, -65536" -> "  %14333 = add nuw i32 %14331, %14332"
"  %14333 = add nuw i32 %14331, %14332"
"  %14333 = add nuw i32 %14331, %14332" -> "  %14341 = add nuw i32 %14333, %14340"
"  %14334 = and i32 %14315, 65535"
"  %14334 = and i32 %14315, 65535" -> "  %14336 = add nuw nsw i32 %14334, %14335"
"  %14335 = and i32 %14316, 65535"
"  %14335 = and i32 %14316, 65535" -> "  %14336 = add nuw nsw i32 %14334, %14335"
"  %14336 = add nuw nsw i32 %14334, %14335"
"  %14336 = add nuw nsw i32 %14334, %14335" -> "  %14365 = and i32 %14336, 65535""  %14336 = add nuw nsw i32 %14334, %14335" -> "  %14343 = lshr i32 %14336, 16"
"  %14337 = and i32 %14325, 65535"
"  %14337 = and i32 %14325, 65535" -> "  %14339 = add nuw nsw i32 %14338, %14337"
"  %14338 = lshr i32 %14315, 16"
"  %14338 = lshr i32 %14315, 16" -> "  %14339 = add nuw nsw i32 %14338, %14337"
"  %14339 = add nuw nsw i32 %14338, %14337"
"  %14339 = add nuw nsw i32 %14338, %14337" -> "  %14342 = and i32 %14339, 65535""  %14339 = add nuw nsw i32 %14338, %14337" -> "  %14340 = lshr i32 %14339, 16"
"  %14340 = lshr i32 %14339, 16"
"  %14340 = lshr i32 %14339, 16" -> "  %14341 = add nuw i32 %14333, %14340"
"  %14341 = add nuw i32 %14333, %14340"
"  %14341 = add nuw i32 %14333, %14340" -> "  %14346 = add nuw i32 %14341, %14345"
"  %14342 = and i32 %14339, 65535"
"  %14342 = and i32 %14339, 65535" -> "  %14344 = add nuw nsw i32 %14342, %14343"
"  %14343 = lshr i32 %14336, 16"
"  %14343 = lshr i32 %14336, 16" -> "  %14344 = add nuw nsw i32 %14342, %14343"
"  %14344 = add nuw nsw i32 %14342, %14343"
"  %14344 = add nuw nsw i32 %14342, %14343" -> "  %14368 = and i32 %14344, 65535""  %14344 = add nuw nsw i32 %14342, %14343" -> "  %14345 = lshr i32 %14344, 16"
"  %14345 = lshr i32 %14344, 16"
"  %14345 = lshr i32 %14344, 16" -> "  %14346 = add nuw i32 %14341, %14345"
"  %14346 = add nuw i32 %14341, %14345"
"  %14346 = add nuw i32 %14341, %14345" -> "  %14400 = lshr i32 %14346, 16""  %14346 = add nuw i32 %14341, %14345" -> "  %14396 = and i32 %14346, 65535"
"  %14347 = mul nuw nsw i32 %13962, 31112"
"  %14347 = mul nuw nsw i32 %13962, 31112" -> "  %14366 = and i32 %14347, 65528""  %14347 = mul nuw nsw i32 %13962, 31112" -> "  %14348 = lshr i32 %14347, 16"
"  %14348 = lshr i32 %14347, 16"
"  %14348 = lshr i32 %14347, 16" -> "  %14351 = add nuw nsw i32 %14350, %14348"
"  %14349 = mul nuw nsw i32 %13961, 31112"
"  %14349 = mul nuw nsw i32 %13961, 31112" -> "  %14352 = and i32 %14349, 2147418112""  %14349 = mul nuw nsw i32 %13961, 31112" -> "  %14350 = and i32 %14349, 65528"
"  %14350 = and i32 %14349, 65528"
"  %14350 = and i32 %14349, 65528" -> "  %14351 = add nuw nsw i32 %14350, %14348"
"  %14351 = add nuw nsw i32 %14350, %14348"
"  %14351 = add nuw nsw i32 %14350, %14348" -> "  %14353 = add nuw nsw i32 %14351, %14352"
"  %14352 = and i32 %14349, 2147418112"
"  %14352 = and i32 %14349, 2147418112" -> "  %14353 = add nuw nsw i32 %14351, %14352"
"  %14353 = add nuw nsw i32 %14351, %14352"
"  %14353 = add nuw nsw i32 %14351, %14352" -> "  %14357 = lshr i32 %14353, 16""  %14353 = add nuw nsw i32 %14351, %14352" -> "  %14355 = and i32 %14353, 65535"
"  %14354 = mul nuw i32 %13962, 42170"
"  %14354 = mul nuw i32 %13962, 42170" -> "  %14356 = add nuw i32 %14355, %14354"
"  %14355 = and i32 %14353, 65535"
"  %14355 = and i32 %14353, 65535" -> "  %14356 = add nuw i32 %14355, %14354"
"  %14356 = add nuw i32 %14355, %14354"
"  %14356 = add nuw i32 %14355, %14354" -> "  %14369 = and i32 %14356, 65535""  %14356 = add nuw i32 %14355, %14354" -> "  %14360 = lshr i32 %14356, 16"
"  %14357 = lshr i32 %14353, 16"
"  %14357 = lshr i32 %14353, 16" -> "  %14359 = add nuw i32 %14357, %14358"
"  %14358 = mul nuw i32 %13961, 42170"
"  %14358 = mul nuw i32 %13961, 42170" -> "  %14359 = add nuw i32 %14357, %14358"
"  %14359 = add nuw i32 %14357, %14358"
"  %14359 = add nuw i32 %14357, %14358" -> "  %14363 = and i32 %14359, -65536""  %14359 = add nuw i32 %14357, %14358" -> "  %14361 = and i32 %14359, 65535"
"  %14360 = lshr i32 %14356, 16"
"  %14360 = lshr i32 %14356, 16" -> "  %14362 = add nuw nsw i32 %14360, %14361"
"  %14361 = and i32 %14359, 65535"
"  %14361 = and i32 %14359, 65535" -> "  %14362 = add nuw nsw i32 %14360, %14361"
"  %14362 = add nuw nsw i32 %14360, %14361"
"  %14362 = add nuw nsw i32 %14360, %14361" -> "  %14364 = add nuw i32 %14362, %14363"
"  %14363 = and i32 %14359, -65536"
"  %14363 = and i32 %14359, -65536" -> "  %14364 = add nuw i32 %14362, %14363"
"  %14364 = add nuw i32 %14362, %14363"
"  %14364 = add nuw i32 %14362, %14363" -> "  %14372 = add nuw i32 %14364, %14371"
"  %14365 = and i32 %14336, 65535"
"  %14365 = and i32 %14336, 65535" -> "  %14367 = add nuw nsw i32 %14365, %14366"
"  %14366 = and i32 %14347, 65528"
"  %14366 = and i32 %14347, 65528" -> "  %14367 = add nuw nsw i32 %14365, %14366"
"  %14367 = add nuw nsw i32 %14365, %14366"
"  %14367 = add nuw nsw i32 %14365, %14366" -> "  %14434 = and i32 %14367, 65535""  %14367 = add nuw nsw i32 %14365, %14366" -> "  %14374 = lshr i32 %14367, 16"
"  %14368 = and i32 %14344, 65535"
"  %14368 = and i32 %14344, 65535" -> "  %14370 = add nuw nsw i32 %14368, %14369"
"  %14369 = and i32 %14356, 65535"
"  %14369 = and i32 %14356, 65535" -> "  %14370 = add nuw nsw i32 %14368, %14369"
"  %14370 = add nuw nsw i32 %14368, %14369"
"  %14370 = add nuw nsw i32 %14368, %14369" -> "  %14373 = and i32 %14370, 65535""  %14370 = add nuw nsw i32 %14368, %14369" -> "  %14371 = lshr i32 %14370, 16"
"  %14371 = lshr i32 %14370, 16"
"  %14371 = lshr i32 %14370, 16" -> "  %14372 = add nuw i32 %14364, %14371"
"  %14372 = add nuw i32 %14364, %14371"
"  %14372 = add nuw i32 %14364, %14371" -> "  %14377 = add nuw i32 %14372, %14376"
"  %14373 = and i32 %14370, 65535"
"  %14373 = and i32 %14370, 65535" -> "  %14375 = add nuw nsw i32 %14373, %14374"
"  %14374 = lshr i32 %14367, 16"
"  %14374 = lshr i32 %14367, 16" -> "  %14375 = add nuw nsw i32 %14373, %14374"
"  %14375 = add nuw nsw i32 %14373, %14374"
"  %14375 = add nuw nsw i32 %14373, %14374" -> "  %14437 = and i32 %14375, 65535""  %14375 = add nuw nsw i32 %14373, %14374" -> "  %14376 = lshr i32 %14375, 16"
"  %14376 = lshr i32 %14375, 16"
"  %14376 = lshr i32 %14375, 16" -> "  %14377 = add nuw i32 %14372, %14376"
"  %14377 = add nuw i32 %14372, %14376"
"  %14377 = add nuw i32 %14372, %14376" -> "  %14413 = lshr i32 %14377, 16""  %14377 = add nuw i32 %14372, %14376" -> "  %14410 = and i32 %14377, 65535"
"  %14378 = mul nuw nsw i32 %13981, 31112"
"  %14378 = mul nuw nsw i32 %13981, 31112" -> "  %14397 = and i32 %14378, 65528""  %14378 = mul nuw nsw i32 %13981, 31112" -> "  %14379 = lshr i32 %14378, 16"
"  %14379 = lshr i32 %14378, 16"
"  %14379 = lshr i32 %14378, 16" -> "  %14382 = add nuw nsw i32 %14381, %14379"
"  %14380 = mul nuw nsw i32 %13982, 31112"
"  %14380 = mul nuw nsw i32 %13982, 31112" -> "  %14383 = and i32 %14380, 2147418112""  %14380 = mul nuw nsw i32 %13982, 31112" -> "  %14381 = and i32 %14380, 65528"
"  %14381 = and i32 %14380, 65528"
"  %14381 = and i32 %14380, 65528" -> "  %14382 = add nuw nsw i32 %14381, %14379"
"  %14382 = add nuw nsw i32 %14381, %14379"
"  %14382 = add nuw nsw i32 %14381, %14379" -> "  %14384 = add nuw nsw i32 %14382, %14383"
"  %14383 = and i32 %14380, 2147418112"
"  %14383 = and i32 %14380, 2147418112" -> "  %14384 = add nuw nsw i32 %14382, %14383"
"  %14384 = add nuw nsw i32 %14382, %14383"
"  %14384 = add nuw nsw i32 %14382, %14383" -> "  %14388 = lshr i32 %14384, 16""  %14384 = add nuw nsw i32 %14382, %14383" -> "  %14386 = and i32 %14384, 65535"
"  %14385 = mul nuw i32 %13981, 42170"
"  %14385 = mul nuw i32 %13981, 42170" -> "  %14387 = add nuw i32 %14386, %14385"
"  %14386 = and i32 %14384, 65535"
"  %14386 = and i32 %14384, 65535" -> "  %14387 = add nuw i32 %14386, %14385"
"  %14387 = add nuw i32 %14386, %14385"
"  %14387 = add nuw i32 %14386, %14385" -> "  %14399 = and i32 %14387, 65535""  %14387 = add nuw i32 %14386, %14385" -> "  %14391 = lshr i32 %14387, 16"
"  %14388 = lshr i32 %14384, 16"
"  %14388 = lshr i32 %14384, 16" -> "  %14390 = add nuw i32 %14388, %14389"
"  %14389 = mul nuw i32 %13982, 42170"
"  %14389 = mul nuw i32 %13982, 42170" -> "  %14390 = add nuw i32 %14388, %14389"
"  %14390 = add nuw i32 %14388, %14389"
"  %14390 = add nuw i32 %14388, %14389" -> "  %14394 = and i32 %14390, -65536""  %14390 = add nuw i32 %14388, %14389" -> "  %14392 = and i32 %14390, 65535"
"  %14391 = lshr i32 %14387, 16"
"  %14391 = lshr i32 %14387, 16" -> "  %14393 = add nuw nsw i32 %14391, %14392"
"  %14392 = and i32 %14390, 65535"
"  %14392 = and i32 %14390, 65535" -> "  %14393 = add nuw nsw i32 %14391, %14392"
"  %14393 = add nuw nsw i32 %14391, %14392"
"  %14393 = add nuw nsw i32 %14391, %14392" -> "  %14395 = add nuw i32 %14393, %14394"
"  %14394 = and i32 %14390, -65536"
"  %14394 = and i32 %14390, -65536" -> "  %14395 = add nuw i32 %14393, %14394"
"  %14395 = add nuw i32 %14393, %14394"
"  %14395 = add nuw i32 %14393, %14394" -> "  %14403 = add nuw i32 %14395, %14402"
"  %14396 = and i32 %14346, 65535"
"  %14396 = and i32 %14346, 65535" -> "  %14398 = add nuw nsw i32 %14396, %14397"
"  %14397 = and i32 %14378, 65528"
"  %14397 = and i32 %14378, 65528" -> "  %14398 = add nuw nsw i32 %14396, %14397"
"  %14398 = add nuw nsw i32 %14396, %14397"
"  %14398 = add nuw nsw i32 %14396, %14397" -> "  %14409 = and i32 %14398, 65535""  %14398 = add nuw nsw i32 %14396, %14397" -> "  %14405 = lshr i32 %14398, 16"
"  %14399 = and i32 %14387, 65535"
"  %14399 = and i32 %14387, 65535" -> "  %14401 = add nuw nsw i32 %14400, %14399"
"  %14400 = lshr i32 %14346, 16"
"  %14400 = lshr i32 %14346, 16" -> "  %14401 = add nuw nsw i32 %14400, %14399"
"  %14401 = add nuw nsw i32 %14400, %14399"
"  %14401 = add nuw nsw i32 %14400, %14399" -> "  %14404 = and i32 %14401, 65535""  %14401 = add nuw nsw i32 %14400, %14399" -> "  %14402 = lshr i32 %14401, 16"
"  %14402 = lshr i32 %14401, 16"
"  %14402 = lshr i32 %14401, 16" -> "  %14403 = add nuw i32 %14395, %14402"
"  %14403 = add nuw i32 %14395, %14402"
"  %14403 = add nuw i32 %14395, %14402" -> "  %14408 = add nuw i32 %14403, %14407"
"  %14404 = and i32 %14401, 65535"
"  %14404 = and i32 %14401, 65535" -> "  %14406 = add nuw nsw i32 %14404, %14405"
"  %14405 = lshr i32 %14398, 16"
"  %14405 = lshr i32 %14398, 16" -> "  %14406 = add nuw nsw i32 %14404, %14405"
"  %14406 = add nuw nsw i32 %14404, %14405"
"  %14406 = add nuw nsw i32 %14404, %14405" -> "  %14412 = and i32 %14406, 65535""  %14406 = add nuw nsw i32 %14404, %14405" -> "  %14407 = lshr i32 %14406, 16"
"  %14407 = lshr i32 %14406, 16"
"  %14407 = lshr i32 %14406, 16" -> "  %14408 = add nuw i32 %14403, %14407"
"  %14408 = add nuw i32 %14403, %14407"
"  %14408 = add nuw i32 %14403, %14407" -> "  %14421 = and i32 %14408, -65536""  %14408 = add nuw i32 %14403, %14407" -> "  %14419 = and i32 %14408, 65535"
"  %14409 = and i32 %14398, 65535"
"  %14409 = and i32 %14398, 65535" -> "  %14411 = add nuw nsw i32 %14410, %14409"
"  %14410 = and i32 %14377, 65535"
"  %14410 = and i32 %14377, 65535" -> "  %14411 = add nuw nsw i32 %14410, %14409"
"  %14411 = add nuw nsw i32 %14410, %14409"
"  %14411 = add nuw nsw i32 %14410, %14409" -> "  %14451 = and i32 %14411, 65535""  %14411 = add nuw nsw i32 %14410, %14409" -> "  %14415 = lshr i32 %14411, 16"
"  %14412 = and i32 %14406, 65535"
"  %14412 = and i32 %14406, 65535" -> "  %14414 = add nuw nsw i32 %14412, %14413"
"  %14413 = lshr i32 %14377, 16"
"  %14413 = lshr i32 %14377, 16" -> "  %14414 = add nuw nsw i32 %14412, %14413"
"  %14414 = add nuw nsw i32 %14412, %14413"
"  %14414 = add nuw nsw i32 %14412, %14413" -> "  %14418 = lshr i32 %14414, 16""  %14414 = add nuw nsw i32 %14412, %14413" -> "  %14416 = and i32 %14414, 65535"
"  %14415 = lshr i32 %14411, 16"
"  %14415 = lshr i32 %14411, 16" -> "  %14417 = add nuw nsw i32 %14416, %14415"
"  %14416 = and i32 %14414, 65535"
"  %14416 = and i32 %14414, 65535" -> "  %14417 = add nuw nsw i32 %14416, %14415"
"  %14417 = add nuw nsw i32 %14416, %14415"
"  %14417 = add nuw nsw i32 %14416, %14415" -> "  %14458 = and i32 %14417, 65535""  %14417 = add nuw nsw i32 %14416, %14415" -> "  %14423 = lshr i32 %14417, 16"
"  %14418 = lshr i32 %14414, 16"
"  %14418 = lshr i32 %14414, 16" -> "  %14420 = add nuw nsw i32 %14418, %14419"
"  %14419 = and i32 %14408, 65535"
"  %14419 = and i32 %14408, 65535" -> "  %14420 = add nuw nsw i32 %14418, %14419"
"  %14420 = add nuw nsw i32 %14418, %14419"
"  %14420 = add nuw nsw i32 %14418, %14419" -> "  %14422 = add nuw i32 %14420, %14421"
"  %14421 = and i32 %14408, -65536"
"  %14421 = and i32 %14408, -65536" -> "  %14422 = add nuw i32 %14420, %14421"
"  %14422 = add nuw i32 %14420, %14421"
"  %14422 = add nuw i32 %14420, %14421" -> "  %14424 = add nuw i32 %14422, %14423"
"  %14423 = lshr i32 %14417, 16"
"  %14423 = lshr i32 %14417, 16" -> "  %14424 = add nuw i32 %14422, %14423"
"  %14424 = add nuw i32 %14422, %14423"
"  %14424 = add nuw i32 %14422, %14423" -> "  %14462 = add nuw i32 %14424, %14461"
"  %14425 = and i32 %14298, 65535"
"  %14425 = and i32 %14298, 65535" -> "  %14427 = add nuw nsw i32 %14426, %14425"
"  %14426 = and i32 %14127, 65535"
"  %14426 = and i32 %14127, 65535" -> "  %14427 = add nuw nsw i32 %14426, %14425"
"  %14427 = add nuw nsw i32 %14426, %14425"
"  %14427 = add nuw nsw i32 %14426, %14425" -> "  %14463 = and i32 %14427, 65535""  %14427 = add nuw nsw i32 %14426, %14425" -> "  %14431 = lshr i32 %14427, 16"
"  %14428 = and i32 %14307, 65535"
"  %14428 = and i32 %14307, 65535" -> "  %14430 = add nuw nsw i32 %14429, %14428"
"  %14429 = and i32 %14130, 65535"
"  %14429 = and i32 %14130, 65535" -> "  %14430 = add nuw nsw i32 %14429, %14428"
"  %14430 = add nuw nsw i32 %14429, %14428"
"  %14430 = add nuw nsw i32 %14429, %14428" -> "  %14444 = lshr i32 %14430, 16""  %14430 = add nuw nsw i32 %14429, %14428" -> "  %14432 = and i32 %14430, 65535"
"  %14431 = lshr i32 %14427, 16"
"  %14431 = lshr i32 %14427, 16" -> "  %14433 = add nuw nsw i32 %14432, %14431"
"  %14432 = and i32 %14430, 65535"
"  %14432 = and i32 %14430, 65535" -> "  %14433 = add nuw nsw i32 %14432, %14431"
"  %14433 = add nuw nsw i32 %14432, %14431"
"  %14433 = add nuw nsw i32 %14432, %14431" -> "  %14466 = and i32 %14433, 65535""  %14433 = add nuw nsw i32 %14432, %14431" -> "  %14445 = lshr i32 %14433, 16"
"  %14434 = and i32 %14367, 65535"
"  %14434 = and i32 %14367, 65535" -> "  %14436 = add nuw nsw i32 %14435, %14434"
"  %14435 = and i32 %14132, 65535"
"  %14435 = and i32 %14132, 65535" -> "  %14436 = add nuw nsw i32 %14435, %14434"
"  %14436 = add nuw nsw i32 %14435, %14434"
"  %14436 = add nuw nsw i32 %14435, %14434" -> "  %14443 = and i32 %14436, 65535""  %14436 = add nuw nsw i32 %14435, %14434" -> "  %14440 = lshr i32 %14436, 16"
"  %14437 = and i32 %14375, 65535"
"  %14437 = and i32 %14375, 65535" -> "  %14439 = add nuw nsw i32 %14438, %14437"
"  %14438 = lshr i32 %14132, 16"
"  %14438 = lshr i32 %14132, 16" -> "  %14439 = add nuw nsw i32 %14438, %14437"
"  %14439 = add nuw nsw i32 %14438, %14437"
"  %14439 = add nuw nsw i32 %14438, %14437" -> "  %14452 = lshr i32 %14439, 16""  %14439 = add nuw nsw i32 %14438, %14437" -> "  %14441 = and i32 %14439, 65535"
"  %14440 = lshr i32 %14436, 16"
"  %14440 = lshr i32 %14436, 16" -> "  %14442 = add nuw nsw i32 %14441, %14440"
"  %14441 = and i32 %14439, 65535"
"  %14441 = and i32 %14439, 65535" -> "  %14442 = add nuw nsw i32 %14441, %14440"
"  %14442 = add nuw nsw i32 %14441, %14440"
"  %14442 = add nuw nsw i32 %14441, %14440" -> "  %14454 = lshr i32 %14442, 16""  %14442 = add nuw nsw i32 %14441, %14440" -> "  %14449 = and i32 %14442, 65535"
"  %14443 = and i32 %14436, 65535"
"  %14443 = and i32 %14436, 65535" -> "  %14447 = add nuw nsw i32 %14446, %14443"
"  %14444 = lshr i32 %14430, 16"
"  %14444 = lshr i32 %14430, 16" -> "  %14446 = add nuw nsw i32 %14445, %14444"
"  %14445 = lshr i32 %14433, 16"
"  %14445 = lshr i32 %14433, 16" -> "  %14446 = add nuw nsw i32 %14445, %14444"
"  %14446 = add nuw nsw i32 %14445, %14444"
"  %14446 = add nuw nsw i32 %14445, %14444" -> "  %14447 = add nuw nsw i32 %14446, %14443"
"  %14447 = add nuw nsw i32 %14446, %14443"
"  %14447 = add nuw nsw i32 %14446, %14443" -> "  %14473 = and i32 %14447, 65535""  %14447 = add nuw nsw i32 %14446, %14443" -> "  %14448 = lshr i32 %14447, 16"
"  %14448 = lshr i32 %14447, 16"
"  %14448 = lshr i32 %14447, 16" -> "  %14450 = add nuw nsw i32 %14448, %14449"
"  %14449 = and i32 %14442, 65535"
"  %14449 = and i32 %14442, 65535" -> "  %14450 = add nuw nsw i32 %14448, %14449"
"  %14450 = add nuw nsw i32 %14448, %14449"
"  %14450 = add nuw nsw i32 %14448, %14449" -> "  %14476 = and i32 %14450, 65535""  %14450 = add nuw nsw i32 %14448, %14449" -> "  %14456 = lshr i32 %14450, 16"
"  %14451 = and i32 %14411, 65535"
"  %14451 = and i32 %14411, 65535" -> "  %14453 = add nuw nsw i32 %14452, %14451"
"  %14452 = lshr i32 %14439, 16"
"  %14452 = lshr i32 %14439, 16" -> "  %14453 = add nuw nsw i32 %14452, %14451"
"  %14453 = add nuw nsw i32 %14452, %14451"
"  %14453 = add nuw nsw i32 %14452, %14451" -> "  %14455 = add nuw nsw i32 %14453, %14454"
"  %14454 = lshr i32 %14442, 16"
"  %14454 = lshr i32 %14442, 16" -> "  %14455 = add nuw nsw i32 %14453, %14454"
"  %14455 = add nuw nsw i32 %14453, %14454"
"  %14455 = add nuw nsw i32 %14453, %14454" -> "  %14457 = add nuw nsw i32 %14455, %14456"
"  %14456 = lshr i32 %14450, 16"
"  %14456 = lshr i32 %14450, 16" -> "  %14457 = add nuw nsw i32 %14455, %14456"
"  %14457 = add nuw nsw i32 %14455, %14456"
"  %14457 = add nuw nsw i32 %14455, %14456" -> "  %14490 = and i32 %14457, 65535""  %14457 = add nuw nsw i32 %14455, %14456" -> "  %14459 = lshr i32 %14457, 16"
"  %14458 = and i32 %14417, 65535"
"  %14458 = and i32 %14417, 65535" -> "  %14460 = add nuw nsw i32 %14459, %14458"
"  %14459 = lshr i32 %14457, 16"
"  %14459 = lshr i32 %14457, 16" -> "  %14460 = add nuw nsw i32 %14459, %14458"
"  %14460 = add nuw nsw i32 %14459, %14458"
"  %14460 = add nuw nsw i32 %14459, %14458" -> "  %14497 = and i32 %14460, 65535""  %14460 = add nuw nsw i32 %14459, %14458" -> "  %14461 = lshr i32 %14460, 16"
"  %14461 = lshr i32 %14460, 16"
"  %14461 = lshr i32 %14460, 16" -> "  %14462 = add nuw i32 %14424, %14461"
"  %14462 = add nuw i32 %14424, %14461"
"  %14462 = add nuw i32 %14424, %14461" -> "  %14500 = add nuw i32 %14462, %14499"
"  %14463 = and i32 %14427, 65535"
"  %14463 = and i32 %14427, 65535" -> "  %14465 = add nuw nsw i32 %14464, %14463"
"  %14464 = and i32 %14292, 65535"
"  %14464 = and i32 %14292, 65535" -> "  %14465 = add nuw nsw i32 %14464, %14463"
"  %14465 = add nuw nsw i32 %14464, %14463"
"  %14465 = add nuw nsw i32 %14464, %14463" -> "  %14574 = and i32 %14465, 65535""  %14465 = add nuw nsw i32 %14464, %14463" -> "  %14469 = lshr i32 %14465, 16"
"  %14466 = and i32 %14433, 65535"
"  %14466 = and i32 %14433, 65535" -> "  %14468 = add nuw nsw i32 %14467, %14466"
"  %14467 = and i32 %14295, 65535"
"  %14467 = and i32 %14295, 65535" -> "  %14468 = add nuw nsw i32 %14467, %14466"
"  %14468 = add nuw nsw i32 %14467, %14466"
"  %14468 = add nuw nsw i32 %14467, %14466" -> "  %14482 = lshr i32 %14468, 16""  %14468 = add nuw nsw i32 %14467, %14466" -> "  %14470 = and i32 %14468, 65535"
"  %14469 = lshr i32 %14465, 16"
"  %14469 = lshr i32 %14465, 16" -> "  %14471 = add nuw nsw i32 %14470, %14469"
"  %14470 = and i32 %14468, 65535"
"  %14470 = and i32 %14468, 65535" -> "  %14471 = add nuw nsw i32 %14470, %14469"
"  %14471 = add nuw nsw i32 %14470, %14469"
"  %14471 = add nuw nsw i32 %14470, %14469" -> "  %14578 = and i32 %14471, 65535""  %14471 = add nuw nsw i32 %14470, %14469" -> "  %14483 = lshr i32 %14471, 16"
"  %14472 = and i32 %14297, 65535"
"  %14472 = and i32 %14297, 65535" -> "  %14474 = add nuw nsw i32 %14472, %14473"
"  %14473 = and i32 %14447, 65535"
"  %14473 = and i32 %14447, 65535" -> "  %14474 = add nuw nsw i32 %14472, %14473"
"  %14474 = add nuw nsw i32 %14472, %14473"
"  %14474 = add nuw nsw i32 %14472, %14473" -> "  %14481 = and i32 %14474, 65535""  %14474 = add nuw nsw i32 %14472, %14473" -> "  %14478 = lshr i32 %14474, 16"
"  %14475 = lshr i32 %14297, 16"
"  %14475 = lshr i32 %14297, 16" -> "  %14477 = add nuw nsw i32 %14476, %14475"
"  %14476 = and i32 %14450, 65535"
"  %14476 = and i32 %14450, 65535" -> "  %14477 = add nuw nsw i32 %14476, %14475"
"  %14477 = add nuw nsw i32 %14476, %14475"
"  %14477 = add nuw nsw i32 %14476, %14475" -> "  %14489 = lshr i32 %14477, 16""  %14477 = add nuw nsw i32 %14476, %14475" -> "  %14479 = and i32 %14477, 65535"
"  %14478 = lshr i32 %14474, 16"
"  %14478 = lshr i32 %14474, 16" -> "  %14480 = add nuw nsw i32 %14479, %14478"
"  %14479 = and i32 %14477, 65535"
"  %14479 = and i32 %14477, 65535" -> "  %14480 = add nuw nsw i32 %14479, %14478"
"  %14480 = add nuw nsw i32 %14479, %14478"
"  %14480 = add nuw nsw i32 %14479, %14478" -> "  %14492 = lshr i32 %14480, 16""  %14480 = add nuw nsw i32 %14479, %14478" -> "  %14487 = and i32 %14480, 65535"
"  %14481 = and i32 %14474, 65535"
"  %14481 = and i32 %14474, 65535" -> "  %14485 = add nuw nsw i32 %14484, %14481"
"  %14482 = lshr i32 %14468, 16"
"  %14482 = lshr i32 %14468, 16" -> "  %14484 = add nuw nsw i32 %14483, %14482"
"  %14483 = lshr i32 %14471, 16"
"  %14483 = lshr i32 %14471, 16" -> "  %14484 = add nuw nsw i32 %14483, %14482"
"  %14484 = add nuw nsw i32 %14483, %14482"
"  %14484 = add nuw nsw i32 %14483, %14482" -> "  %14485 = add nuw nsw i32 %14484, %14481"
"  %14485 = add nuw nsw i32 %14484, %14481"
"  %14485 = add nuw nsw i32 %14484, %14481" -> "  %14579 = and i32 %14485, 65535""  %14485 = add nuw nsw i32 %14484, %14481" -> "  %14486 = lshr i32 %14485, 16"
"  %14486 = lshr i32 %14485, 16"
"  %14486 = lshr i32 %14485, 16" -> "  %14488 = add nuw nsw i32 %14487, %14486"
"  %14487 = and i32 %14480, 65535"
"  %14487 = and i32 %14480, 65535" -> "  %14488 = add nuw nsw i32 %14487, %14486"
"  %14488 = add nuw nsw i32 %14487, %14486"
"  %14488 = add nuw nsw i32 %14487, %14486" -> "  %14584 = and i32 %14488, 65535""  %14488 = add nuw nsw i32 %14487, %14486" -> "  %14494 = lshr i32 %14488, 16"
"  %14489 = lshr i32 %14477, 16"
"  %14489 = lshr i32 %14477, 16" -> "  %14491 = add nuw nsw i32 %14489, %14490"
"  %14490 = and i32 %14457, 65535"
"  %14490 = and i32 %14457, 65535" -> "  %14491 = add nuw nsw i32 %14489, %14490"
"  %14491 = add nuw nsw i32 %14489, %14490"
"  %14491 = add nuw nsw i32 %14489, %14490" -> "  %14493 = add nuw nsw i32 %14491, %14492"
"  %14492 = lshr i32 %14480, 16"
"  %14492 = lshr i32 %14480, 16" -> "  %14493 = add nuw nsw i32 %14491, %14492"
"  %14493 = add nuw nsw i32 %14491, %14492"
"  %14493 = add nuw nsw i32 %14491, %14492" -> "  %14495 = add nuw nsw i32 %14493, %14494"
"  %14494 = lshr i32 %14488, 16"
"  %14494 = lshr i32 %14488, 16" -> "  %14495 = add nuw nsw i32 %14493, %14494"
"  %14495 = add nuw nsw i32 %14493, %14494"
"  %14495 = add nuw nsw i32 %14493, %14494" -> "  %14587 = and i32 %14495, 65535""  %14495 = add nuw nsw i32 %14493, %14494" -> "  %14496 = lshr i32 %14495, 16"
"  %14496 = lshr i32 %14495, 16"
"  %14496 = lshr i32 %14495, 16" -> "  %14498 = add nuw nsw i32 %14496, %14497"
"  %14497 = and i32 %14460, 65535"
"  %14497 = and i32 %14460, 65535" -> "  %14498 = add nuw nsw i32 %14496, %14497"
"  %14498 = add nuw nsw i32 %14496, %14497"
"  %14498 = add nuw nsw i32 %14496, %14497" -> "  %14590 = and i32 %14498, 65535""  %14498 = add nuw nsw i32 %14496, %14497" -> "  %14499 = lshr i32 %14498, 16"
"  %14499 = lshr i32 %14498, 16"
"  %14499 = lshr i32 %14498, 16" -> "  %14500 = add nuw i32 %14462, %14499"
"  %14500 = add nuw i32 %14462, %14499"
"  %14500 = add nuw i32 %14462, %14499" -> "  %14594 = add nuw i32 %14500, %14593"
"  %14501 = and i32 %13791, 65535"
"  %14501 = and i32 %13791, 65535" -> "  %14503 = add nuw nsw i32 %14501, %14502"
"  %14502 = and i32 %13829, 65532"
"  %14502 = and i32 %13829, 65532" -> "  %14503 = add nuw nsw i32 %14501, %14502"
"  %14503 = add nuw nsw i32 %14501, %14502"
"  %14503 = add nuw nsw i32 %14501, %14502" -> "  %15255 = and i32 %14503, 65535""  %14503 = add nuw nsw i32 %14501, %14502" -> "  %14507 = lshr i32 %14503, 16"
"  %14504 = and i32 %13797, 65535"
"  %14504 = and i32 %13797, 65535" -> "  %14506 = add nuw nsw i32 %14504, %14505"
"  %14505 = and i32 %13838, 65535"
"  %14505 = and i32 %13838, 65535" -> "  %14506 = add nuw nsw i32 %14504, %14505"
"  %14506 = add nuw nsw i32 %14504, %14505"
"  %14506 = add nuw nsw i32 %14504, %14505" -> "  %14510 = lshr i32 %14506, 16""  %14506 = add nuw nsw i32 %14504, %14505" -> "  %14508 = and i32 %14506, 65535"
"  %14507 = lshr i32 %14503, 16"
"  %14507 = lshr i32 %14503, 16" -> "  %14509 = add nuw nsw i32 %14508, %14507"
"  %14508 = and i32 %14506, 65535"
"  %14508 = and i32 %14506, 65535" -> "  %14509 = add nuw nsw i32 %14508, %14507"
"  %14509 = add nuw nsw i32 %14508, %14507"
"  %14509 = add nuw nsw i32 %14508, %14507" -> "  %15258 = and i32 %14509, 65535""  %14509 = add nuw nsw i32 %14508, %14507" -> "  %14511 = lshr i32 %14509, 16"
"  %14510 = lshr i32 %14506, 16"
"  %14510 = lshr i32 %14506, 16" -> "  %14512 = add nuw nsw i32 %14511, %14510"
"  %14511 = lshr i32 %14509, 16"
"  %14511 = lshr i32 %14509, 16" -> "  %14512 = add nuw nsw i32 %14511, %14510"
"  %14512 = add nuw nsw i32 %14511, %14510"
"  %14512 = add nuw nsw i32 %14511, %14510" -> "  %14523 = add nuw nsw i32 %14512, %14522"
"  %14513 = and i32 %13811, 65535"
"  %14513 = and i32 %13811, 65535" -> "  %14515 = add nuw nsw i32 %14513, %14514"
"  %14514 = and i32 %13903, 65535"
"  %14514 = and i32 %13903, 65535" -> "  %14515 = add nuw nsw i32 %14513, %14514"
"  %14515 = add nuw nsw i32 %14513, %14514"
"  %14515 = add nuw nsw i32 %14513, %14514" -> "  %14522 = and i32 %14515, 65535""  %14515 = add nuw nsw i32 %14513, %14514" -> "  %14519 = lshr i32 %14515, 16"
"  %14516 = and i32 %13814, 65535"
"  %14516 = and i32 %13814, 65535" -> "  %14518 = add nuw nsw i32 %14516, %14517"
"  %14517 = and i32 %13911, 65535"
"  %14517 = and i32 %13911, 65535" -> "  %14518 = add nuw nsw i32 %14516, %14517"
"  %14518 = add nuw nsw i32 %14516, %14517"
"  %14518 = add nuw nsw i32 %14516, %14517" -> "  %14558 = lshr i32 %14518, 16""  %14518 = add nuw nsw i32 %14516, %14517" -> "  %14520 = and i32 %14518, 65535"
"  %14519 = lshr i32 %14515, 16"
"  %14519 = lshr i32 %14515, 16" -> "  %14521 = add nuw nsw i32 %14520, %14519"
"  %14520 = and i32 %14518, 65535"
"  %14520 = and i32 %14518, 65535" -> "  %14521 = add nuw nsw i32 %14520, %14519"
"  %14521 = add nuw nsw i32 %14520, %14519"
"  %14521 = add nuw nsw i32 %14520, %14519" -> "  %14559 = lshr i32 %14521, 16""  %14521 = add nuw nsw i32 %14520, %14519" -> "  %14525 = and i32 %14521, 65535"
"  %14522 = and i32 %14515, 65535"
"  %14522 = and i32 %14515, 65535" -> "  %14523 = add nuw nsw i32 %14512, %14522"
"  %14523 = add nuw nsw i32 %14512, %14522"
"  %14523 = add nuw nsw i32 %14512, %14522" -> "  %15267 = and i32 %14523, 65535""  %14523 = add nuw nsw i32 %14512, %14522" -> "  %14524 = lshr i32 %14523, 16"
"  %14524 = lshr i32 %14523, 16"
"  %14524 = lshr i32 %14523, 16" -> "  %14526 = add nuw nsw i32 %14525, %14524"
"  %14525 = and i32 %14521, 65535"
"  %14525 = and i32 %14521, 65535" -> "  %14526 = add nuw nsw i32 %14525, %14524"
"  %14526 = add nuw nsw i32 %14525, %14524"
"  %14526 = add nuw nsw i32 %14525, %14524" -> "  %15270 = and i32 %14526, 65535""  %14526 = add nuw nsw i32 %14525, %14524" -> "  %14560 = lshr i32 %14526, 16"
"  %14527 = and i32 %13821, 65535"
"  %14527 = and i32 %13821, 65535" -> "  %14529 = add nuw nsw i32 %14527, %14528"
"  %14528 = and i32 %14262, 65535"
"  %14528 = and i32 %14262, 65535" -> "  %14529 = add nuw nsw i32 %14527, %14528"
"  %14529 = add nuw nsw i32 %14527, %14528"
"  %14529 = add nuw nsw i32 %14527, %14528" -> "  %14557 = and i32 %14529, 65535""  %14529 = add nuw nsw i32 %14527, %14528" -> "  %14533 = lshr i32 %14529, 16"
"  %14530 = and i32 %13824, 65535"
"  %14530 = and i32 %13824, 65535" -> "  %14532 = add nuw nsw i32 %14530, %14531"
"  %14531 = and i32 %14268, 65535"
"  %14531 = and i32 %14268, 65535" -> "  %14532 = add nuw nsw i32 %14530, %14531"
"  %14532 = add nuw nsw i32 %14530, %14531"
"  %14532 = add nuw nsw i32 %14530, %14531" -> "  %14549 = lshr i32 %14532, 16""  %14532 = add nuw nsw i32 %14530, %14531" -> "  %14534 = and i32 %14532, 65535"
"  %14533 = lshr i32 %14529, 16"
"  %14533 = lshr i32 %14529, 16" -> "  %14535 = add nuw nsw i32 %14534, %14533"
"  %14534 = and i32 %14532, 65535"
"  %14534 = and i32 %14532, 65535" -> "  %14535 = add nuw nsw i32 %14534, %14533"
"  %14535 = add nuw nsw i32 %14534, %14533"
"  %14535 = add nuw nsw i32 %14534, %14533" -> "  %14564 = and i32 %14535, 65535""  %14535 = add nuw nsw i32 %14534, %14533" -> "  %14551 = lshr i32 %14535, 16"
"  %14536 = and i32 %13826, 65535"
"  %14536 = and i32 %13826, 65535" -> "  %14538 = add nuw nsw i32 %14536, %14537"
"  %14537 = and i32 %14282, 65535"
"  %14537 = and i32 %14282, 65535" -> "  %14538 = add nuw nsw i32 %14536, %14537"
"  %14538 = add nuw nsw i32 %14536, %14537"
"  %14538 = add nuw nsw i32 %14536, %14537" -> "  %14548 = and i32 %14538, 65535""  %14538 = add nuw nsw i32 %14536, %14537" -> "  %14542 = lshr i32 %14538, 16"
"  %14539 = lshr i32 %13826, 16"
"  %14539 = lshr i32 %13826, 16" -> "  %14541 = add nuw nsw i32 %14540, %14539"
"  %14540 = and i32 %14285, 65535"
"  %14540 = and i32 %14285, 65535" -> "  %14541 = add nuw nsw i32 %14540, %14539"
"  %14541 = add nuw nsw i32 %14540, %14539"
"  %14541 = add nuw nsw i32 %14540, %14539" -> "  %14545 = lshr i32 %14541, 16""  %14541 = add nuw nsw i32 %14540, %14539" -> "  %14543 = and i32 %14541, 65535"
"  %14542 = lshr i32 %14538, 16"
"  %14542 = lshr i32 %14538, 16" -> "  %14544 = add nuw nsw i32 %14543, %14542"
"  %14543 = and i32 %14541, 65535"
"  %14543 = and i32 %14541, 65535" -> "  %14544 = add nuw nsw i32 %14543, %14542"
"  %14544 = add nuw nsw i32 %14543, %14542"
"  %14544 = add nuw nsw i32 %14543, %14542" -> "  %14553 = and i32 %14544, 65535""  %14544 = add nuw nsw i32 %14543, %14542" -> "  %14546 = lshr i32 %14544, 16"
"  %14545 = lshr i32 %14541, 16"
"  %14545 = lshr i32 %14541, 16" -> "  %14547 = add nuw nsw i32 %14546, %14545"
"  %14546 = lshr i32 %14544, 16"
"  %14546 = lshr i32 %14544, 16" -> "  %14547 = add nuw nsw i32 %14546, %14545"
"  %14547 = add nuw nsw i32 %14546, %14545"
"  %14547 = add nuw nsw i32 %14546, %14545" -> "  %14575 = add nuw nsw i32 %14547, %14574"
"  %14548 = and i32 %14538, 65535"
"  %14548 = and i32 %14538, 65535" -> "  %14550 = add nuw nsw i32 %14548, %14549"
"  %14549 = lshr i32 %14532, 16"
"  %14549 = lshr i32 %14532, 16" -> "  %14550 = add nuw nsw i32 %14548, %14549"
"  %14550 = add nuw nsw i32 %14548, %14549"
"  %14550 = add nuw nsw i32 %14548, %14549" -> "  %14552 = add nuw nsw i32 %14550, %14551"
"  %14551 = lshr i32 %14535, 16"
"  %14551 = lshr i32 %14535, 16" -> "  %14552 = add nuw nsw i32 %14550, %14551"
"  %14552 = add nuw nsw i32 %14550, %14551"
"  %14552 = add nuw nsw i32 %14550, %14551" -> "  %14567 = and i32 %14552, 65535""  %14552 = add nuw nsw i32 %14550, %14551" -> "  %14554 = lshr i32 %14552, 16"
"  %14553 = and i32 %14544, 65535"
"  %14553 = and i32 %14544, 65535" -> "  %14555 = add nuw nsw i32 %14553, %14554"
"  %14554 = lshr i32 %14552, 16"
"  %14554 = lshr i32 %14552, 16" -> "  %14555 = add nuw nsw i32 %14553, %14554"
"  %14555 = add nuw nsw i32 %14553, %14554"
"  %14555 = add nuw nsw i32 %14553, %14554" -> "  %14570 = and i32 %14555, 65535""  %14555 = add nuw nsw i32 %14553, %14554" -> "  %14556 = lshr i32 %14555, 16"
"  %14556 = lshr i32 %14555, 16"
"  %14556 = lshr i32 %14555, 16" -> "  %14576 = add nuw nsw i32 %14575, %14556"
"  %14557 = and i32 %14529, 65535"
"  %14557 = and i32 %14529, 65535" -> "  %14562 = add nuw nsw i32 %14561, %14557"
"  %14558 = lshr i32 %14518, 16"
"  %14558 = lshr i32 %14518, 16" -> "  %14561 = add nuw nsw i32 %14559, %14558"
"  %14559 = lshr i32 %14521, 16"
"  %14559 = lshr i32 %14521, 16" -> "  %14561 = add nuw nsw i32 %14559, %14558"
"  %14560 = lshr i32 %14526, 16"
"  %14560 = lshr i32 %14526, 16" -> "  %14563 = add nuw nsw i32 %14562, %14560"
"  %14561 = add nuw nsw i32 %14559, %14558"
"  %14561 = add nuw nsw i32 %14559, %14558" -> "  %14562 = add nuw nsw i32 %14561, %14557"
"  %14562 = add nuw nsw i32 %14561, %14557"
"  %14562 = add nuw nsw i32 %14561, %14557" -> "  %14563 = add nuw nsw i32 %14562, %14560"
"  %14563 = add nuw nsw i32 %14562, %14560"
"  %14563 = add nuw nsw i32 %14562, %14560" -> "  %15281 = and i32 %14563, 65535""  %14563 = add nuw nsw i32 %14562, %14560" -> "  %14565 = lshr i32 %14563, 16"
"  %14564 = and i32 %14535, 65535"
"  %14564 = and i32 %14535, 65535" -> "  %14566 = add nuw nsw i32 %14564, %14565"
"  %14565 = lshr i32 %14563, 16"
"  %14565 = lshr i32 %14563, 16" -> "  %14566 = add nuw nsw i32 %14564, %14565"
"  %14566 = add nuw nsw i32 %14564, %14565"
"  %14566 = add nuw nsw i32 %14564, %14565" -> "  %15284 = and i32 %14566, 65535""  %14566 = add nuw nsw i32 %14564, %14565" -> "  %14568 = lshr i32 %14566, 16"
"  %14567 = and i32 %14552, 65535"
"  %14567 = and i32 %14552, 65535" -> "  %14569 = add nuw nsw i32 %14567, %14568"
"  %14568 = lshr i32 %14566, 16"
"  %14568 = lshr i32 %14566, 16" -> "  %14569 = add nuw nsw i32 %14567, %14568"
"  %14569 = add nuw nsw i32 %14567, %14568"
"  %14569 = add nuw nsw i32 %14567, %14568" -> "  %15293 = and i32 %14569, 65535""  %14569 = add nuw nsw i32 %14567, %14568" -> "  %14571 = lshr i32 %14569, 16"
"  %14570 = and i32 %14555, 65535"
"  %14570 = and i32 %14555, 65535" -> "  %14572 = add nuw nsw i32 %14570, %14571"
"  %14571 = lshr i32 %14569, 16"
"  %14571 = lshr i32 %14569, 16" -> "  %14572 = add nuw nsw i32 %14570, %14571"
"  %14572 = add nuw nsw i32 %14570, %14571"
"  %14572 = add nuw nsw i32 %14570, %14571" -> "  %15296 = and i32 %14572, 65535""  %14572 = add nuw nsw i32 %14570, %14571" -> "  %14573 = lshr i32 %14572, 16"
"  %14573 = lshr i32 %14572, 16"
"  %14573 = lshr i32 %14572, 16" -> "  %14577 = add nuw nsw i32 %14576, %14573"
"  %14574 = and i32 %14465, 65535"
"  %14574 = and i32 %14465, 65535" -> "  %14575 = add nuw nsw i32 %14547, %14574"
"  %14575 = add nuw nsw i32 %14547, %14574"
"  %14575 = add nuw nsw i32 %14547, %14574" -> "  %14576 = add nuw nsw i32 %14575, %14556"
"  %14576 = add nuw nsw i32 %14575, %14556"
"  %14576 = add nuw nsw i32 %14575, %14556" -> "  %14577 = add nuw nsw i32 %14576, %14573"
"  %14577 = add nuw nsw i32 %14576, %14573"
"  %14577 = add nuw nsw i32 %14576, %14573" -> "  %16009 = and i32 %14577, 65535""  %14577 = add nuw nsw i32 %14576, %14573" -> "  %14580 = lshr i32 %14577, 16"
"  %14578 = and i32 %14471, 65535"
"  %14578 = and i32 %14471, 65535" -> "  %14581 = add nuw nsw i32 %14580, %14578"
"  %14579 = and i32 %14485, 65535"
"  %14579 = and i32 %14485, 65535" -> "  %14583 = add nuw nsw i32 %14582, %14579"
"  %14580 = lshr i32 %14577, 16"
"  %14580 = lshr i32 %14577, 16" -> "  %14581 = add nuw nsw i32 %14580, %14578"
"  %14581 = add nuw nsw i32 %14580, %14578"
"  %14581 = add nuw nsw i32 %14580, %14578" -> "  %16012 = and i32 %14581, 65535""  %14581 = add nuw nsw i32 %14580, %14578" -> "  %14582 = lshr i32 %14581, 16"
"  %14582 = lshr i32 %14581, 16"
"  %14582 = lshr i32 %14581, 16" -> "  %14583 = add nuw nsw i32 %14582, %14579"
"  %14583 = add nuw nsw i32 %14582, %14579"
"  %14583 = add nuw nsw i32 %14582, %14579" -> "  %16018 = and i32 %14583, 65535""  %14583 = add nuw nsw i32 %14582, %14579" -> "  %14585 = lshr i32 %14583, 16"
"  %14584 = and i32 %14488, 65535"
"  %14584 = and i32 %14488, 65535" -> "  %14586 = add nuw nsw i32 %14585, %14584"
"  %14585 = lshr i32 %14583, 16"
"  %14585 = lshr i32 %14583, 16" -> "  %14586 = add nuw nsw i32 %14585, %14584"
"  %14586 = add nuw nsw i32 %14585, %14584"
"  %14586 = add nuw nsw i32 %14585, %14584" -> "  %16021 = and i32 %14586, 65535""  %14586 = add nuw nsw i32 %14585, %14584" -> "  %14588 = lshr i32 %14586, 16"
"  %14587 = and i32 %14495, 65535"
"  %14587 = and i32 %14495, 65535" -> "  %14589 = add nuw nsw i32 %14588, %14587"
"  %14588 = lshr i32 %14586, 16"
"  %14588 = lshr i32 %14586, 16" -> "  %14589 = add nuw nsw i32 %14588, %14587"
"  %14589 = add nuw nsw i32 %14588, %14587"
"  %14589 = add nuw nsw i32 %14588, %14587" -> "  %16035 = and i32 %14589, 65535""  %14589 = add nuw nsw i32 %14588, %14587" -> "  %14591 = lshr i32 %14589, 16"
"  %14590 = and i32 %14498, 65535"
"  %14590 = and i32 %14498, 65535" -> "  %14592 = add nuw nsw i32 %14591, %14590"
"  %14591 = lshr i32 %14589, 16"
"  %14591 = lshr i32 %14589, 16" -> "  %14592 = add nuw nsw i32 %14591, %14590"
"  %14592 = add nuw nsw i32 %14591, %14590"
"  %14592 = add nuw nsw i32 %14591, %14590" -> "  %16038 = and i32 %14592, 65535""  %14592 = add nuw nsw i32 %14591, %14590" -> "  %14593 = lshr i32 %14592, 16"
"  %14593 = lshr i32 %14592, 16"
"  %14593 = lshr i32 %14592, 16" -> "  %14594 = add nuw i32 %14500, %14593"
"  %14594 = add nuw i32 %14500, %14593"
"  %14594 = add nuw i32 %14500, %14593" -> "  %16044 = and i32 %14594, 65535""  %14594 = add nuw i32 %14500, %14593" -> "  %16047 = lshr i32 %14594, 16"
"  %14595 = mul nuw i32 %13153, 42779"
"  %14595 = mul nuw i32 %13153, 42779" -> "  %15256 = and i32 %14595, 65535""  %14595 = mul nuw i32 %13153, 42779" -> "  %14596 = lshr i32 %14595, 16"
"  %14596 = lshr i32 %14595, 16"
"  %14596 = lshr i32 %14595, 16" -> "  %14599 = add nuw nsw i32 %14598, %14596"
"  %14597 = mul nuw i32 %13156, 42779"
"  %14597 = mul nuw i32 %13156, 42779" -> "  %14600 = and i32 %14597, -65536""  %14597 = mul nuw i32 %13156, 42779" -> "  %14598 = and i32 %14597, 65535"
"  %14598 = and i32 %14597, 65535"
"  %14598 = and i32 %14597, 65535" -> "  %14599 = add nuw nsw i32 %14598, %14596"
"  %14599 = add nuw nsw i32 %14598, %14596"
"  %14599 = add nuw nsw i32 %14598, %14596" -> "  %14601 = add nuw i32 %14599, %14600"
"  %14600 = and i32 %14597, -65536"
"  %14600 = and i32 %14597, -65536" -> "  %14601 = add nuw i32 %14599, %14600"
"  %14601 = add nuw i32 %14599, %14600"
"  %14601 = add nuw i32 %14599, %14600" -> "  %14605 = lshr i32 %14601, 16""  %14601 = add nuw i32 %14599, %14600" -> "  %14603 = and i32 %14601, 65535"
"  %14602 = mul nuw nsw i32 %13153, 9871"
"  %14602 = mul nuw nsw i32 %13153, 9871" -> "  %14604 = add nuw nsw i32 %14603, %14602"
"  %14603 = and i32 %14601, 65535"
"  %14603 = and i32 %14601, 65535" -> "  %14604 = add nuw nsw i32 %14603, %14602"
"  %14604 = add nuw nsw i32 %14603, %14602"
"  %14604 = add nuw nsw i32 %14603, %14602" -> "  %15259 = and i32 %14604, 65535""  %14604 = add nuw nsw i32 %14603, %14602" -> "  %14608 = lshr i32 %14604, 16"
"  %14605 = lshr i32 %14601, 16"
"  %14605 = lshr i32 %14601, 16" -> "  %14607 = add nuw nsw i32 %14605, %14606"
"  %14606 = mul nuw nsw i32 %13156, 9871"
"  %14606 = mul nuw nsw i32 %13156, 9871" -> "  %14607 = add nuw nsw i32 %14605, %14606"
"  %14607 = add nuw nsw i32 %14605, %14606"
"  %14607 = add nuw nsw i32 %14605, %14606" -> "  %14609 = and i32 %14607, 65535""  %14607 = add nuw nsw i32 %14605, %14606" -> "  %14611 = and i32 %14607, 2147418112"
"  %14608 = lshr i32 %14604, 16"
"  %14608 = lshr i32 %14604, 16" -> "  %14610 = add nuw nsw i32 %14608, %14609"
"  %14609 = and i32 %14607, 65535"
"  %14609 = and i32 %14607, 65535" -> "  %14610 = add nuw nsw i32 %14608, %14609"
"  %14610 = add nuw nsw i32 %14608, %14609"
"  %14610 = add nuw nsw i32 %14608, %14609" -> "  %14612 = add nuw nsw i32 %14610, %14611"
"  %14611 = and i32 %14607, 2147418112"
"  %14611 = and i32 %14607, 2147418112" -> "  %14612 = add nuw nsw i32 %14610, %14611"
"  %14612 = add nuw nsw i32 %14610, %14611"
"  %14612 = add nuw nsw i32 %14610, %14611" -> "  %14635 = lshr i32 %14612, 16""  %14612 = add nuw nsw i32 %14610, %14611" -> "  %14631 = and i32 %14612, 65535"
"  %14613 = mul nuw i32 %13173, 42779"
"  %14613 = mul nuw i32 %13173, 42779" -> "  %14632 = and i32 %14613, 65535""  %14613 = mul nuw i32 %13173, 42779" -> "  %14614 = lshr i32 %14613, 16"
"  %14614 = lshr i32 %14613, 16"
"  %14614 = lshr i32 %14613, 16" -> "  %14617 = add nuw nsw i32 %14616, %14614"
"  %14615 = mul nuw i32 %13176, 42779"
"  %14615 = mul nuw i32 %13176, 42779" -> "  %14618 = and i32 %14615, -65536""  %14615 = mul nuw i32 %13176, 42779" -> "  %14616 = and i32 %14615, 65535"
"  %14616 = and i32 %14615, 65535"
"  %14616 = and i32 %14615, 65535" -> "  %14617 = add nuw nsw i32 %14616, %14614"
"  %14617 = add nuw nsw i32 %14616, %14614"
"  %14617 = add nuw nsw i32 %14616, %14614" -> "  %14619 = add nuw i32 %14617, %14618"
"  %14618 = and i32 %14615, -65536"
"  %14618 = and i32 %14615, -65536" -> "  %14619 = add nuw i32 %14617, %14618"
"  %14619 = add nuw i32 %14617, %14618"
"  %14619 = add nuw i32 %14617, %14618" -> "  %14623 = lshr i32 %14619, 16""  %14619 = add nuw i32 %14617, %14618" -> "  %14621 = and i32 %14619, 65535"
"  %14620 = mul nuw nsw i32 %13173, 9871"
"  %14620 = mul nuw nsw i32 %13173, 9871" -> "  %14622 = add nuw nsw i32 %14621, %14620"
"  %14621 = and i32 %14619, 65535"
"  %14621 = and i32 %14619, 65535" -> "  %14622 = add nuw nsw i32 %14621, %14620"
"  %14622 = add nuw nsw i32 %14621, %14620"
"  %14622 = add nuw nsw i32 %14621, %14620" -> "  %14634 = and i32 %14622, 65535""  %14622 = add nuw nsw i32 %14621, %14620" -> "  %14626 = lshr i32 %14622, 16"
"  %14623 = lshr i32 %14619, 16"
"  %14623 = lshr i32 %14619, 16" -> "  %14625 = add nuw nsw i32 %14623, %14624"
"  %14624 = mul nuw nsw i32 %13176, 9871"
"  %14624 = mul nuw nsw i32 %13176, 9871" -> "  %14625 = add nuw nsw i32 %14623, %14624"
"  %14625 = add nuw nsw i32 %14623, %14624"
"  %14625 = add nuw nsw i32 %14623, %14624" -> "  %14629 = and i32 %14625, 2147418112""  %14625 = add nuw nsw i32 %14623, %14624" -> "  %14627 = and i32 %14625, 65535"
"  %14626 = lshr i32 %14622, 16"
"  %14626 = lshr i32 %14622, 16" -> "  %14628 = add nuw nsw i32 %14626, %14627"
"  %14627 = and i32 %14625, 65535"
"  %14627 = and i32 %14625, 65535" -> "  %14628 = add nuw nsw i32 %14626, %14627"
"  %14628 = add nuw nsw i32 %14626, %14627"
"  %14628 = add nuw nsw i32 %14626, %14627" -> "  %14630 = add nuw nsw i32 %14628, %14629"
"  %14629 = and i32 %14625, 2147418112"
"  %14629 = and i32 %14625, 2147418112" -> "  %14630 = add nuw nsw i32 %14628, %14629"
"  %14630 = add nuw nsw i32 %14628, %14629"
"  %14630 = add nuw nsw i32 %14628, %14629" -> "  %14638 = add nuw nsw i32 %14630, %14637"
"  %14631 = and i32 %14612, 65535"
"  %14631 = and i32 %14612, 65535" -> "  %14633 = add nuw nsw i32 %14631, %14632"
"  %14632 = and i32 %14613, 65535"
"  %14632 = and i32 %14613, 65535" -> "  %14633 = add nuw nsw i32 %14631, %14632"
"  %14633 = add nuw nsw i32 %14631, %14632"
"  %14633 = add nuw nsw i32 %14631, %14632" -> "  %14662 = and i32 %14633, 65535""  %14633 = add nuw nsw i32 %14631, %14632" -> "  %14640 = lshr i32 %14633, 16"
"  %14634 = and i32 %14622, 65535"
"  %14634 = and i32 %14622, 65535" -> "  %14636 = add nuw nsw i32 %14634, %14635"
"  %14635 = lshr i32 %14612, 16"
"  %14635 = lshr i32 %14612, 16" -> "  %14636 = add nuw nsw i32 %14634, %14635"
"  %14636 = add nuw nsw i32 %14634, %14635"
"  %14636 = add nuw nsw i32 %14634, %14635" -> "  %14639 = and i32 %14636, 65535""  %14636 = add nuw nsw i32 %14634, %14635" -> "  %14637 = lshr i32 %14636, 16"
"  %14637 = lshr i32 %14636, 16"
"  %14637 = lshr i32 %14636, 16" -> "  %14638 = add nuw nsw i32 %14630, %14637"
"  %14638 = add nuw nsw i32 %14630, %14637"
"  %14638 = add nuw nsw i32 %14630, %14637" -> "  %14643 = add nuw nsw i32 %14638, %14642"
"  %14639 = and i32 %14636, 65535"
"  %14639 = and i32 %14636, 65535" -> "  %14641 = add nuw nsw i32 %14639, %14640"
"  %14640 = lshr i32 %14633, 16"
"  %14640 = lshr i32 %14633, 16" -> "  %14641 = add nuw nsw i32 %14639, %14640"
"  %14641 = add nuw nsw i32 %14639, %14640"
"  %14641 = add nuw nsw i32 %14639, %14640" -> "  %14665 = and i32 %14641, 65535""  %14641 = add nuw nsw i32 %14639, %14640" -> "  %14642 = lshr i32 %14641, 16"
"  %14642 = lshr i32 %14641, 16"
"  %14642 = lshr i32 %14641, 16" -> "  %14643 = add nuw nsw i32 %14638, %14642"
"  %14643 = add nuw nsw i32 %14638, %14642"
"  %14643 = add nuw nsw i32 %14638, %14642" -> "  %14697 = lshr i32 %14643, 16""  %14643 = add nuw nsw i32 %14638, %14642" -> "  %14693 = and i32 %14643, 65535"
"  %14644 = mul nuw nsw i32 %13153, 24315"
"  %14644 = mul nuw nsw i32 %13153, 24315" -> "  %14663 = and i32 %14644, 65535""  %14644 = mul nuw nsw i32 %13153, 24315" -> "  %14645 = lshr i32 %14644, 16"
"  %14645 = lshr i32 %14644, 16"
"  %14645 = lshr i32 %14644, 16" -> "  %14648 = add nuw nsw i32 %14647, %14645"
"  %14646 = mul nuw nsw i32 %13156, 24315"
"  %14646 = mul nuw nsw i32 %13156, 24315" -> "  %14649 = and i32 %14646, 2147418112""  %14646 = mul nuw nsw i32 %13156, 24315" -> "  %14647 = and i32 %14646, 65535"
"  %14647 = and i32 %14646, 65535"
"  %14647 = and i32 %14646, 65535" -> "  %14648 = add nuw nsw i32 %14647, %14645"
"  %14648 = add nuw nsw i32 %14647, %14645"
"  %14648 = add nuw nsw i32 %14647, %14645" -> "  %14650 = add nuw nsw i32 %14648, %14649"
"  %14649 = and i32 %14646, 2147418112"
"  %14649 = and i32 %14646, 2147418112" -> "  %14650 = add nuw nsw i32 %14648, %14649"
"  %14650 = add nuw nsw i32 %14648, %14649"
"  %14650 = add nuw nsw i32 %14648, %14649" -> "  %14654 = lshr i32 %14650, 16""  %14650 = add nuw nsw i32 %14648, %14649" -> "  %14652 = and i32 %14650, 65535"
"  %14651 = mul nuw nsw i32 %13153, 29744"
"  %14651 = mul nuw nsw i32 %13153, 29744" -> "  %14653 = add nuw nsw i32 %14652, %14651"
"  %14652 = and i32 %14650, 65535"
"  %14652 = and i32 %14650, 65535" -> "  %14653 = add nuw nsw i32 %14652, %14651"
"  %14653 = add nuw nsw i32 %14652, %14651"
"  %14653 = add nuw nsw i32 %14652, %14651" -> "  %14666 = and i32 %14653, 65535""  %14653 = add nuw nsw i32 %14652, %14651" -> "  %14657 = lshr i32 %14653, 16"
"  %14654 = lshr i32 %14650, 16"
"  %14654 = lshr i32 %14650, 16" -> "  %14656 = add nuw nsw i32 %14654, %14655"
"  %14655 = mul nuw nsw i32 %13156, 29744"
"  %14655 = mul nuw nsw i32 %13156, 29744" -> "  %14656 = add nuw nsw i32 %14654, %14655"
"  %14656 = add nuw nsw i32 %14654, %14655"
"  %14656 = add nuw nsw i32 %14654, %14655" -> "  %14660 = and i32 %14656, 2147418112""  %14656 = add nuw nsw i32 %14654, %14655" -> "  %14658 = and i32 %14656, 65535"
"  %14657 = lshr i32 %14653, 16"
"  %14657 = lshr i32 %14653, 16" -> "  %14659 = add nuw nsw i32 %14657, %14658"
"  %14658 = and i32 %14656, 65535"
"  %14658 = and i32 %14656, 65535" -> "  %14659 = add nuw nsw i32 %14657, %14658"
"  %14659 = add nuw nsw i32 %14657, %14658"
"  %14659 = add nuw nsw i32 %14657, %14658" -> "  %14661 = add nuw nsw i32 %14659, %14660"
"  %14660 = and i32 %14656, 2147418112"
"  %14660 = and i32 %14656, 2147418112" -> "  %14661 = add nuw nsw i32 %14659, %14660"
"  %14661 = add nuw nsw i32 %14659, %14660"
"  %14661 = add nuw nsw i32 %14659, %14660" -> "  %14669 = add nuw nsw i32 %14661, %14668"
"  %14662 = and i32 %14633, 65535"
"  %14662 = and i32 %14633, 65535" -> "  %14664 = add nuw nsw i32 %14662, %14663"
"  %14663 = and i32 %14644, 65535"
"  %14663 = and i32 %14644, 65535" -> "  %14664 = add nuw nsw i32 %14662, %14663"
"  %14664 = add nuw nsw i32 %14662, %14663"
"  %14664 = add nuw nsw i32 %14662, %14663" -> "  %15268 = and i32 %14664, 65535""  %14664 = add nuw nsw i32 %14662, %14663" -> "  %14671 = lshr i32 %14664, 16"
"  %14665 = and i32 %14641, 65535"
"  %14665 = and i32 %14641, 65535" -> "  %14667 = add nuw nsw i32 %14665, %14666"
"  %14666 = and i32 %14653, 65535"
"  %14666 = and i32 %14653, 65535" -> "  %14667 = add nuw nsw i32 %14665, %14666"
"  %14667 = add nuw nsw i32 %14665, %14666"
"  %14667 = add nuw nsw i32 %14665, %14666" -> "  %14670 = and i32 %14667, 65535""  %14667 = add nuw nsw i32 %14665, %14666" -> "  %14668 = lshr i32 %14667, 16"
"  %14668 = lshr i32 %14667, 16"
"  %14668 = lshr i32 %14667, 16" -> "  %14669 = add nuw nsw i32 %14661, %14668"
"  %14669 = add nuw nsw i32 %14661, %14668"
"  %14669 = add nuw nsw i32 %14661, %14668" -> "  %14674 = add nuw nsw i32 %14669, %14673"
"  %14670 = and i32 %14667, 65535"
"  %14670 = and i32 %14667, 65535" -> "  %14672 = add nuw nsw i32 %14670, %14671"
"  %14671 = lshr i32 %14664, 16"
"  %14671 = lshr i32 %14664, 16" -> "  %14672 = add nuw nsw i32 %14670, %14671"
"  %14672 = add nuw nsw i32 %14670, %14671"
"  %14672 = add nuw nsw i32 %14670, %14671" -> "  %15271 = and i32 %14672, 65535""  %14672 = add nuw nsw i32 %14670, %14671" -> "  %14673 = lshr i32 %14672, 16"
"  %14673 = lshr i32 %14672, 16"
"  %14673 = lshr i32 %14672, 16" -> "  %14674 = add nuw nsw i32 %14669, %14673"
"  %14674 = add nuw nsw i32 %14669, %14673"
"  %14674 = add nuw nsw i32 %14669, %14673" -> "  %14710 = lshr i32 %14674, 16""  %14674 = add nuw nsw i32 %14669, %14673" -> "  %14707 = and i32 %14674, 65535"
"  %14675 = mul nuw nsw i32 %13173, 24315"
"  %14675 = mul nuw nsw i32 %13173, 24315" -> "  %14694 = and i32 %14675, 65535""  %14675 = mul nuw nsw i32 %13173, 24315" -> "  %14676 = lshr i32 %14675, 16"
"  %14676 = lshr i32 %14675, 16"
"  %14676 = lshr i32 %14675, 16" -> "  %14679 = add nuw nsw i32 %14678, %14676"
"  %14677 = mul nuw nsw i32 %13176, 24315"
"  %14677 = mul nuw nsw i32 %13176, 24315" -> "  %14680 = and i32 %14677, 2147418112""  %14677 = mul nuw nsw i32 %13176, 24315" -> "  %14678 = and i32 %14677, 65535"
"  %14678 = and i32 %14677, 65535"
"  %14678 = and i32 %14677, 65535" -> "  %14679 = add nuw nsw i32 %14678, %14676"
"  %14679 = add nuw nsw i32 %14678, %14676"
"  %14679 = add nuw nsw i32 %14678, %14676" -> "  %14681 = add nuw nsw i32 %14679, %14680"
"  %14680 = and i32 %14677, 2147418112"
"  %14680 = and i32 %14677, 2147418112" -> "  %14681 = add nuw nsw i32 %14679, %14680"
"  %14681 = add nuw nsw i32 %14679, %14680"
"  %14681 = add nuw nsw i32 %14679, %14680" -> "  %14685 = lshr i32 %14681, 16""  %14681 = add nuw nsw i32 %14679, %14680" -> "  %14683 = and i32 %14681, 65535"
"  %14682 = mul nuw nsw i32 %13173, 29744"
"  %14682 = mul nuw nsw i32 %13173, 29744" -> "  %14684 = add nuw nsw i32 %14683, %14682"
"  %14683 = and i32 %14681, 65535"
"  %14683 = and i32 %14681, 65535" -> "  %14684 = add nuw nsw i32 %14683, %14682"
"  %14684 = add nuw nsw i32 %14683, %14682"
"  %14684 = add nuw nsw i32 %14683, %14682" -> "  %14696 = and i32 %14684, 65535""  %14684 = add nuw nsw i32 %14683, %14682" -> "  %14688 = lshr i32 %14684, 16"
"  %14685 = lshr i32 %14681, 16"
"  %14685 = lshr i32 %14681, 16" -> "  %14687 = add nuw nsw i32 %14685, %14686"
"  %14686 = mul nuw nsw i32 %13176, 29744"
"  %14686 = mul nuw nsw i32 %13176, 29744" -> "  %14687 = add nuw nsw i32 %14685, %14686"
"  %14687 = add nuw nsw i32 %14685, %14686"
"  %14687 = add nuw nsw i32 %14685, %14686" -> "  %14691 = and i32 %14687, 2147418112""  %14687 = add nuw nsw i32 %14685, %14686" -> "  %14689 = and i32 %14687, 65535"
"  %14688 = lshr i32 %14684, 16"
"  %14688 = lshr i32 %14684, 16" -> "  %14690 = add nuw nsw i32 %14688, %14689"
"  %14689 = and i32 %14687, 65535"
"  %14689 = and i32 %14687, 65535" -> "  %14690 = add nuw nsw i32 %14688, %14689"
"  %14690 = add nuw nsw i32 %14688, %14689"
"  %14690 = add nuw nsw i32 %14688, %14689" -> "  %14692 = add nuw nsw i32 %14690, %14691"
"  %14691 = and i32 %14687, 2147418112"
"  %14691 = and i32 %14687, 2147418112" -> "  %14692 = add nuw nsw i32 %14690, %14691"
"  %14692 = add nuw nsw i32 %14690, %14691"
"  %14692 = add nuw nsw i32 %14690, %14691" -> "  %14700 = add nuw nsw i32 %14692, %14699"
"  %14693 = and i32 %14643, 65535"
"  %14693 = and i32 %14643, 65535" -> "  %14695 = add nuw nsw i32 %14693, %14694"
"  %14694 = and i32 %14675, 65535"
"  %14694 = and i32 %14675, 65535" -> "  %14695 = add nuw nsw i32 %14693, %14694"
"  %14695 = add nuw nsw i32 %14693, %14694"
"  %14695 = add nuw nsw i32 %14693, %14694" -> "  %14706 = and i32 %14695, 65535""  %14695 = add nuw nsw i32 %14693, %14694" -> "  %14702 = lshr i32 %14695, 16"
"  %14696 = and i32 %14684, 65535"
"  %14696 = and i32 %14684, 65535" -> "  %14698 = add nuw nsw i32 %14697, %14696"
"  %14697 = lshr i32 %14643, 16"
"  %14697 = lshr i32 %14643, 16" -> "  %14698 = add nuw nsw i32 %14697, %14696"
"  %14698 = add nuw nsw i32 %14697, %14696"
"  %14698 = add nuw nsw i32 %14697, %14696" -> "  %14701 = and i32 %14698, 65535""  %14698 = add nuw nsw i32 %14697, %14696" -> "  %14699 = lshr i32 %14698, 16"
"  %14699 = lshr i32 %14698, 16"
"  %14699 = lshr i32 %14698, 16" -> "  %14700 = add nuw nsw i32 %14692, %14699"
"  %14700 = add nuw nsw i32 %14692, %14699"
"  %14700 = add nuw nsw i32 %14692, %14699" -> "  %14705 = add nuw nsw i32 %14700, %14704"
"  %14701 = and i32 %14698, 65535"
"  %14701 = and i32 %14698, 65535" -> "  %14703 = add nuw nsw i32 %14702, %14701"
"  %14702 = lshr i32 %14695, 16"
"  %14702 = lshr i32 %14695, 16" -> "  %14703 = add nuw nsw i32 %14702, %14701"
"  %14703 = add nuw nsw i32 %14702, %14701"
"  %14703 = add nuw nsw i32 %14702, %14701" -> "  %14709 = and i32 %14703, 65535""  %14703 = add nuw nsw i32 %14702, %14701" -> "  %14704 = lshr i32 %14703, 16"
"  %14704 = lshr i32 %14703, 16"
"  %14704 = lshr i32 %14703, 16" -> "  %14705 = add nuw nsw i32 %14700, %14704"
"  %14705 = add nuw nsw i32 %14700, %14704"
"  %14705 = add nuw nsw i32 %14700, %14704" -> "  %14718 = and i32 %14705, 2147418112""  %14705 = add nuw nsw i32 %14700, %14704" -> "  %14716 = and i32 %14705, 65535"
"  %14706 = and i32 %14695, 65535"
"  %14706 = and i32 %14695, 65535" -> "  %14708 = add nuw nsw i32 %14707, %14706"
"  %14707 = and i32 %14674, 65535"
"  %14707 = and i32 %14674, 65535" -> "  %14708 = add nuw nsw i32 %14707, %14706"
"  %14708 = add nuw nsw i32 %14707, %14706"
"  %14708 = add nuw nsw i32 %14707, %14706" -> "  %14850 = and i32 %14708, 65535""  %14708 = add nuw nsw i32 %14707, %14706" -> "  %14712 = lshr i32 %14708, 16"
"  %14709 = and i32 %14703, 65535"
"  %14709 = and i32 %14703, 65535" -> "  %14711 = add nuw nsw i32 %14710, %14709"
"  %14710 = lshr i32 %14674, 16"
"  %14710 = lshr i32 %14674, 16" -> "  %14711 = add nuw nsw i32 %14710, %14709"
"  %14711 = add nuw nsw i32 %14710, %14709"
"  %14711 = add nuw nsw i32 %14710, %14709" -> "  %14715 = lshr i32 %14711, 16""  %14711 = add nuw nsw i32 %14710, %14709" -> "  %14713 = and i32 %14711, 65535"
"  %14712 = lshr i32 %14708, 16"
"  %14712 = lshr i32 %14708, 16" -> "  %14714 = add nuw nsw i32 %14712, %14713"
"  %14713 = and i32 %14711, 65535"
"  %14713 = and i32 %14711, 65535" -> "  %14714 = add nuw nsw i32 %14712, %14713"
"  %14714 = add nuw nsw i32 %14712, %14713"
"  %14714 = add nuw nsw i32 %14712, %14713" -> "  %14853 = and i32 %14714, 65535""  %14714 = add nuw nsw i32 %14712, %14713" -> "  %14720 = lshr i32 %14714, 16"
"  %14715 = lshr i32 %14711, 16"
"  %14715 = lshr i32 %14711, 16" -> "  %14717 = add nuw nsw i32 %14715, %14716"
"  %14716 = and i32 %14705, 65535"
"  %14716 = and i32 %14705, 65535" -> "  %14717 = add nuw nsw i32 %14715, %14716"
"  %14717 = add nuw nsw i32 %14715, %14716"
"  %14717 = add nuw nsw i32 %14715, %14716" -> "  %14719 = add nuw nsw i32 %14717, %14718"
"  %14718 = and i32 %14705, 2147418112"
"  %14718 = and i32 %14705, 2147418112" -> "  %14719 = add nuw nsw i32 %14717, %14718"
"  %14719 = add nuw nsw i32 %14717, %14718"
"  %14719 = add nuw nsw i32 %14717, %14718" -> "  %14721 = add nuw nsw i32 %14719, %14720"
"  %14720 = lshr i32 %14714, 16"
"  %14720 = lshr i32 %14714, 16" -> "  %14721 = add nuw nsw i32 %14719, %14720"
"  %14721 = add nuw nsw i32 %14719, %14720"
"  %14721 = add nuw nsw i32 %14719, %14720" -> "  %14861 = and i32 %14721, 65535""  %14721 = add nuw nsw i32 %14719, %14720" -> "  %14864 = lshr i32 %14721, 16"
"  %14722 = mul nuw i32 %13287, 42779"
"  %14722 = mul nuw i32 %13287, 42779" -> "  %14849 = and i32 %14722, 65535""  %14722 = mul nuw i32 %13287, 42779" -> "  %14723 = lshr i32 %14722, 16"
"  %14723 = lshr i32 %14722, 16"
"  %14723 = lshr i32 %14722, 16" -> "  %14726 = add nuw nsw i32 %14725, %14723"
"  %14724 = mul nuw i32 %13290, 42779"
"  %14724 = mul nuw i32 %13290, 42779" -> "  %14727 = and i32 %14724, -65536""  %14724 = mul nuw i32 %13290, 42779" -> "  %14725 = and i32 %14724, 65535"
"  %14725 = and i32 %14724, 65535"
"  %14725 = and i32 %14724, 65535" -> "  %14726 = add nuw nsw i32 %14725, %14723"
"  %14726 = add nuw nsw i32 %14725, %14723"
"  %14726 = add nuw nsw i32 %14725, %14723" -> "  %14728 = add nuw i32 %14726, %14727"
"  %14727 = and i32 %14724, -65536"
"  %14727 = and i32 %14724, -65536" -> "  %14728 = add nuw i32 %14726, %14727"
"  %14728 = add nuw i32 %14726, %14727"
"  %14728 = add nuw i32 %14726, %14727" -> "  %14732 = lshr i32 %14728, 16""  %14728 = add nuw i32 %14726, %14727" -> "  %14730 = and i32 %14728, 65535"
"  %14729 = mul nuw nsw i32 %13287, 9871"
"  %14729 = mul nuw nsw i32 %13287, 9871" -> "  %14731 = add nuw nsw i32 %14730, %14729"
"  %14730 = and i32 %14728, 65535"
"  %14730 = and i32 %14728, 65535" -> "  %14731 = add nuw nsw i32 %14730, %14729"
"  %14731 = add nuw nsw i32 %14730, %14729"
"  %14731 = add nuw nsw i32 %14730, %14729" -> "  %14852 = and i32 %14731, 65535""  %14731 = add nuw nsw i32 %14730, %14729" -> "  %14735 = lshr i32 %14731, 16"
"  %14732 = lshr i32 %14728, 16"
"  %14732 = lshr i32 %14728, 16" -> "  %14734 = add nuw nsw i32 %14732, %14733"
"  %14733 = mul nuw nsw i32 %13290, 9871"
"  %14733 = mul nuw nsw i32 %13290, 9871" -> "  %14734 = add nuw nsw i32 %14732, %14733"
"  %14734 = add nuw nsw i32 %14732, %14733"
"  %14734 = add nuw nsw i32 %14732, %14733" -> "  %14738 = and i32 %14734, 2147418112""  %14734 = add nuw nsw i32 %14732, %14733" -> "  %14736 = and i32 %14734, 65535"
"  %14735 = lshr i32 %14731, 16"
"  %14735 = lshr i32 %14731, 16" -> "  %14737 = add nuw nsw i32 %14735, %14736"
"  %14736 = and i32 %14734, 65535"
"  %14736 = and i32 %14734, 65535" -> "  %14737 = add nuw nsw i32 %14735, %14736"
"  %14737 = add nuw nsw i32 %14735, %14736"
"  %14737 = add nuw nsw i32 %14735, %14736" -> "  %14739 = add nuw nsw i32 %14737, %14738"
"  %14738 = and i32 %14734, 2147418112"
"  %14738 = and i32 %14734, 2147418112" -> "  %14739 = add nuw nsw i32 %14737, %14738"
"  %14739 = add nuw nsw i32 %14737, %14738"
"  %14739 = add nuw nsw i32 %14737, %14738" -> "  %14762 = lshr i32 %14739, 16""  %14739 = add nuw nsw i32 %14737, %14738" -> "  %14758 = and i32 %14739, 65535"
"  %14740 = mul nuw i32 %13307, 42779"
"  %14740 = mul nuw i32 %13307, 42779" -> "  %14759 = and i32 %14740, 65535""  %14740 = mul nuw i32 %13307, 42779" -> "  %14741 = lshr i32 %14740, 16"
"  %14741 = lshr i32 %14740, 16"
"  %14741 = lshr i32 %14740, 16" -> "  %14744 = add nuw nsw i32 %14743, %14741"
"  %14742 = mul nuw i32 %13310, 42779"
"  %14742 = mul nuw i32 %13310, 42779" -> "  %14745 = and i32 %14742, -65536""  %14742 = mul nuw i32 %13310, 42779" -> "  %14743 = and i32 %14742, 65535"
"  %14743 = and i32 %14742, 65535"
"  %14743 = and i32 %14742, 65535" -> "  %14744 = add nuw nsw i32 %14743, %14741"
"  %14744 = add nuw nsw i32 %14743, %14741"
"  %14744 = add nuw nsw i32 %14743, %14741" -> "  %14746 = add nuw i32 %14744, %14745"
"  %14745 = and i32 %14742, -65536"
"  %14745 = and i32 %14742, -65536" -> "  %14746 = add nuw i32 %14744, %14745"
"  %14746 = add nuw i32 %14744, %14745"
"  %14746 = add nuw i32 %14744, %14745" -> "  %14750 = lshr i32 %14746, 16""  %14746 = add nuw i32 %14744, %14745" -> "  %14748 = and i32 %14746, 65535"
"  %14747 = mul nuw nsw i32 %13307, 9871"
"  %14747 = mul nuw nsw i32 %13307, 9871" -> "  %14749 = add nuw nsw i32 %14748, %14747"
"  %14748 = and i32 %14746, 65535"
"  %14748 = and i32 %14746, 65535" -> "  %14749 = add nuw nsw i32 %14748, %14747"
"  %14749 = add nuw nsw i32 %14748, %14747"
"  %14749 = add nuw nsw i32 %14748, %14747" -> "  %14761 = and i32 %14749, 65535""  %14749 = add nuw nsw i32 %14748, %14747" -> "  %14753 = lshr i32 %14749, 16"
"  %14750 = lshr i32 %14746, 16"
"  %14750 = lshr i32 %14746, 16" -> "  %14752 = add nuw nsw i32 %14750, %14751"
"  %14751 = mul nuw nsw i32 %13310, 9871"
"  %14751 = mul nuw nsw i32 %13310, 9871" -> "  %14752 = add nuw nsw i32 %14750, %14751"
"  %14752 = add nuw nsw i32 %14750, %14751"
"  %14752 = add nuw nsw i32 %14750, %14751" -> "  %14756 = and i32 %14752, 2147418112""  %14752 = add nuw nsw i32 %14750, %14751" -> "  %14754 = and i32 %14752, 65535"
"  %14753 = lshr i32 %14749, 16"
"  %14753 = lshr i32 %14749, 16" -> "  %14755 = add nuw nsw i32 %14753, %14754"
"  %14754 = and i32 %14752, 65535"
"  %14754 = and i32 %14752, 65535" -> "  %14755 = add nuw nsw i32 %14753, %14754"
"  %14755 = add nuw nsw i32 %14753, %14754"
"  %14755 = add nuw nsw i32 %14753, %14754" -> "  %14757 = add nuw nsw i32 %14755, %14756"
"  %14756 = and i32 %14752, 2147418112"
"  %14756 = and i32 %14752, 2147418112" -> "  %14757 = add nuw nsw i32 %14755, %14756"
"  %14757 = add nuw nsw i32 %14755, %14756"
"  %14757 = add nuw nsw i32 %14755, %14756" -> "  %14765 = add nuw nsw i32 %14757, %14764"
"  %14758 = and i32 %14739, 65535"
"  %14758 = and i32 %14739, 65535" -> "  %14760 = add nuw nsw i32 %14758, %14759"
"  %14759 = and i32 %14740, 65535"
"  %14759 = and i32 %14740, 65535" -> "  %14760 = add nuw nsw i32 %14758, %14759"
"  %14760 = add nuw nsw i32 %14758, %14759"
"  %14760 = add nuw nsw i32 %14758, %14759" -> "  %14789 = and i32 %14760, 65535""  %14760 = add nuw nsw i32 %14758, %14759" -> "  %14767 = lshr i32 %14760, 16"
"  %14761 = and i32 %14749, 65535"
"  %14761 = and i32 %14749, 65535" -> "  %14763 = add nuw nsw i32 %14761, %14762"
"  %14762 = lshr i32 %14739, 16"
"  %14762 = lshr i32 %14739, 16" -> "  %14763 = add nuw nsw i32 %14761, %14762"
"  %14763 = add nuw nsw i32 %14761, %14762"
"  %14763 = add nuw nsw i32 %14761, %14762" -> "  %14766 = and i32 %14763, 65535""  %14763 = add nuw nsw i32 %14761, %14762" -> "  %14764 = lshr i32 %14763, 16"
"  %14764 = lshr i32 %14763, 16"
"  %14764 = lshr i32 %14763, 16" -> "  %14765 = add nuw nsw i32 %14757, %14764"
"  %14765 = add nuw nsw i32 %14757, %14764"
"  %14765 = add nuw nsw i32 %14757, %14764" -> "  %14770 = add nuw nsw i32 %14765, %14769"
"  %14766 = and i32 %14763, 65535"
"  %14766 = and i32 %14763, 65535" -> "  %14768 = add nuw nsw i32 %14766, %14767"
"  %14767 = lshr i32 %14760, 16"
"  %14767 = lshr i32 %14760, 16" -> "  %14768 = add nuw nsw i32 %14766, %14767"
"  %14768 = add nuw nsw i32 %14766, %14767"
"  %14768 = add nuw nsw i32 %14766, %14767" -> "  %14793 = and i32 %14768, 65535""  %14768 = add nuw nsw i32 %14766, %14767" -> "  %14769 = lshr i32 %14768, 16"
"  %14769 = lshr i32 %14768, 16"
"  %14769 = lshr i32 %14768, 16" -> "  %14770 = add nuw nsw i32 %14765, %14769"
"  %14770 = add nuw nsw i32 %14765, %14769"
"  %14770 = add nuw nsw i32 %14765, %14769" -> "  %14820 = and i32 %14770, 65535""  %14770 = add nuw nsw i32 %14765, %14769" -> "  %14824 = lshr i32 %14770, 16"
"  %14771 = mul nuw nsw i32 %13287, 24315"
"  %14771 = mul nuw nsw i32 %13287, 24315" -> "  %14790 = and i32 %14771, 65535""  %14771 = mul nuw nsw i32 %13287, 24315" -> "  %14772 = lshr i32 %14771, 16"
"  %14772 = lshr i32 %14771, 16"
"  %14772 = lshr i32 %14771, 16" -> "  %14775 = add nuw nsw i32 %14774, %14772"
"  %14773 = mul nuw nsw i32 %13290, 24315"
"  %14773 = mul nuw nsw i32 %13290, 24315" -> "  %14776 = and i32 %14773, 2147418112""  %14773 = mul nuw nsw i32 %13290, 24315" -> "  %14774 = and i32 %14773, 65535"
"  %14774 = and i32 %14773, 65535"
"  %14774 = and i32 %14773, 65535" -> "  %14775 = add nuw nsw i32 %14774, %14772"
"  %14775 = add nuw nsw i32 %14774, %14772"
"  %14775 = add nuw nsw i32 %14774, %14772" -> "  %14777 = add nuw nsw i32 %14775, %14776"
"  %14776 = and i32 %14773, 2147418112"
"  %14776 = and i32 %14773, 2147418112" -> "  %14777 = add nuw nsw i32 %14775, %14776"
"  %14777 = add nuw nsw i32 %14775, %14776"
"  %14777 = add nuw nsw i32 %14775, %14776" -> "  %14781 = lshr i32 %14777, 16""  %14777 = add nuw nsw i32 %14775, %14776" -> "  %14779 = and i32 %14777, 65535"
"  %14778 = mul nuw nsw i32 %13287, 29744"
"  %14778 = mul nuw nsw i32 %13287, 29744" -> "  %14780 = add nuw nsw i32 %14779, %14778"
"  %14779 = and i32 %14777, 65535"
"  %14779 = and i32 %14777, 65535" -> "  %14780 = add nuw nsw i32 %14779, %14778"
"  %14780 = add nuw nsw i32 %14779, %14778"
"  %14780 = add nuw nsw i32 %14779, %14778" -> "  %14792 = and i32 %14780, 65535""  %14780 = add nuw nsw i32 %14779, %14778" -> "  %14784 = lshr i32 %14780, 16"
"  %14781 = lshr i32 %14777, 16"
"  %14781 = lshr i32 %14777, 16" -> "  %14783 = add nuw nsw i32 %14781, %14782"
"  %14782 = mul nuw nsw i32 %13290, 29744"
"  %14782 = mul nuw nsw i32 %13290, 29744" -> "  %14783 = add nuw nsw i32 %14781, %14782"
"  %14783 = add nuw nsw i32 %14781, %14782"
"  %14783 = add nuw nsw i32 %14781, %14782" -> "  %14787 = and i32 %14783, 2147418112""  %14783 = add nuw nsw i32 %14781, %14782" -> "  %14785 = and i32 %14783, 65535"
"  %14784 = lshr i32 %14780, 16"
"  %14784 = lshr i32 %14780, 16" -> "  %14786 = add nuw nsw i32 %14784, %14785"
"  %14785 = and i32 %14783, 65535"
"  %14785 = and i32 %14783, 65535" -> "  %14786 = add nuw nsw i32 %14784, %14785"
"  %14786 = add nuw nsw i32 %14784, %14785"
"  %14786 = add nuw nsw i32 %14784, %14785" -> "  %14788 = add nuw nsw i32 %14786, %14787"
"  %14787 = and i32 %14783, 2147418112"
"  %14787 = and i32 %14783, 2147418112" -> "  %14788 = add nuw nsw i32 %14786, %14787"
"  %14788 = add nuw nsw i32 %14786, %14787"
"  %14788 = add nuw nsw i32 %14786, %14787" -> "  %14796 = add nuw nsw i32 %14788, %14795"
"  %14789 = and i32 %14760, 65535"
"  %14789 = and i32 %14760, 65535" -> "  %14791 = add nuw nsw i32 %14789, %14790"
"  %14790 = and i32 %14771, 65535"
"  %14790 = and i32 %14771, 65535" -> "  %14791 = add nuw nsw i32 %14789, %14790"
"  %14791 = add nuw nsw i32 %14789, %14790"
"  %14791 = add nuw nsw i32 %14789, %14790" -> "  %14860 = and i32 %14791, 65535""  %14791 = add nuw nsw i32 %14789, %14790" -> "  %14798 = lshr i32 %14791, 16"
"  %14792 = and i32 %14780, 65535"
"  %14792 = and i32 %14780, 65535" -> "  %14794 = add nuw nsw i32 %14793, %14792"
"  %14793 = and i32 %14768, 65535"
"  %14793 = and i32 %14768, 65535" -> "  %14794 = add nuw nsw i32 %14793, %14792"
"  %14794 = add nuw nsw i32 %14793, %14792"
"  %14794 = add nuw nsw i32 %14793, %14792" -> "  %14797 = and i32 %14794, 65535""  %14794 = add nuw nsw i32 %14793, %14792" -> "  %14795 = lshr i32 %14794, 16"
"  %14795 = lshr i32 %14794, 16"
"  %14795 = lshr i32 %14794, 16" -> "  %14796 = add nuw nsw i32 %14788, %14795"
"  %14796 = add nuw nsw i32 %14788, %14795"
"  %14796 = add nuw nsw i32 %14788, %14795" -> "  %14801 = add nuw nsw i32 %14796, %14800"
"  %14797 = and i32 %14794, 65535"
"  %14797 = and i32 %14794, 65535" -> "  %14799 = add nuw nsw i32 %14797, %14798"
"  %14798 = lshr i32 %14791, 16"
"  %14798 = lshr i32 %14791, 16" -> "  %14799 = add nuw nsw i32 %14797, %14798"
"  %14799 = add nuw nsw i32 %14797, %14798"
"  %14799 = add nuw nsw i32 %14797, %14798" -> "  %14863 = and i32 %14799, 65535""  %14799 = add nuw nsw i32 %14797, %14798" -> "  %14800 = lshr i32 %14799, 16"
"  %14800 = lshr i32 %14799, 16"
"  %14800 = lshr i32 %14799, 16" -> "  %14801 = add nuw nsw i32 %14796, %14800"
"  %14801 = add nuw nsw i32 %14796, %14800"
"  %14801 = add nuw nsw i32 %14796, %14800" -> "  %14837 = lshr i32 %14801, 16""  %14801 = add nuw nsw i32 %14796, %14800" -> "  %14834 = and i32 %14801, 65535"
"  %14802 = mul nuw nsw i32 %13307, 24315"
"  %14802 = mul nuw nsw i32 %13307, 24315" -> "  %14821 = and i32 %14802, 65535""  %14802 = mul nuw nsw i32 %13307, 24315" -> "  %14803 = lshr i32 %14802, 16"
"  %14803 = lshr i32 %14802, 16"
"  %14803 = lshr i32 %14802, 16" -> "  %14806 = add nuw nsw i32 %14805, %14803"
"  %14804 = mul nuw nsw i32 %13310, 24315"
"  %14804 = mul nuw nsw i32 %13310, 24315" -> "  %14807 = and i32 %14804, 2147418112""  %14804 = mul nuw nsw i32 %13310, 24315" -> "  %14805 = and i32 %14804, 65535"
"  %14805 = and i32 %14804, 65535"
"  %14805 = and i32 %14804, 65535" -> "  %14806 = add nuw nsw i32 %14805, %14803"
"  %14806 = add nuw nsw i32 %14805, %14803"
"  %14806 = add nuw nsw i32 %14805, %14803" -> "  %14808 = add nuw nsw i32 %14806, %14807"
"  %14807 = and i32 %14804, 2147418112"
"  %14807 = and i32 %14804, 2147418112" -> "  %14808 = add nuw nsw i32 %14806, %14807"
"  %14808 = add nuw nsw i32 %14806, %14807"
"  %14808 = add nuw nsw i32 %14806, %14807" -> "  %14812 = lshr i32 %14808, 16""  %14808 = add nuw nsw i32 %14806, %14807" -> "  %14810 = and i32 %14808, 65535"
"  %14809 = mul nuw nsw i32 %13307, 29744"
"  %14809 = mul nuw nsw i32 %13307, 29744" -> "  %14811 = add nuw nsw i32 %14810, %14809"
"  %14810 = and i32 %14808, 65535"
"  %14810 = and i32 %14808, 65535" -> "  %14811 = add nuw nsw i32 %14810, %14809"
"  %14811 = add nuw nsw i32 %14810, %14809"
"  %14811 = add nuw nsw i32 %14810, %14809" -> "  %14823 = and i32 %14811, 65535""  %14811 = add nuw nsw i32 %14810, %14809" -> "  %14815 = lshr i32 %14811, 16"
"  %14812 = lshr i32 %14808, 16"
"  %14812 = lshr i32 %14808, 16" -> "  %14814 = add nuw nsw i32 %14812, %14813"
"  %14813 = mul nuw nsw i32 %13310, 29744"
"  %14813 = mul nuw nsw i32 %13310, 29744" -> "  %14814 = add nuw nsw i32 %14812, %14813"
"  %14814 = add nuw nsw i32 %14812, %14813"
"  %14814 = add nuw nsw i32 %14812, %14813" -> "  %14818 = and i32 %14814, 2147418112""  %14814 = add nuw nsw i32 %14812, %14813" -> "  %14816 = and i32 %14814, 65535"
"  %14815 = lshr i32 %14811, 16"
"  %14815 = lshr i32 %14811, 16" -> "  %14817 = add nuw nsw i32 %14815, %14816"
"  %14816 = and i32 %14814, 65535"
"  %14816 = and i32 %14814, 65535" -> "  %14817 = add nuw nsw i32 %14815, %14816"
"  %14817 = add nuw nsw i32 %14815, %14816"
"  %14817 = add nuw nsw i32 %14815, %14816" -> "  %14819 = add nuw nsw i32 %14817, %14818"
"  %14818 = and i32 %14814, 2147418112"
"  %14818 = and i32 %14814, 2147418112" -> "  %14819 = add nuw nsw i32 %14817, %14818"
"  %14819 = add nuw nsw i32 %14817, %14818"
"  %14819 = add nuw nsw i32 %14817, %14818" -> "  %14827 = add nuw nsw i32 %14819, %14826"
"  %14820 = and i32 %14770, 65535"
"  %14820 = and i32 %14770, 65535" -> "  %14822 = add nuw nsw i32 %14820, %14821"
"  %14821 = and i32 %14802, 65535"
"  %14821 = and i32 %14802, 65535" -> "  %14822 = add nuw nsw i32 %14820, %14821"
"  %14822 = add nuw nsw i32 %14820, %14821"
"  %14822 = add nuw nsw i32 %14820, %14821" -> "  %14833 = and i32 %14822, 65535""  %14822 = add nuw nsw i32 %14820, %14821" -> "  %14829 = lshr i32 %14822, 16"
"  %14823 = and i32 %14811, 65535"
"  %14823 = and i32 %14811, 65535" -> "  %14825 = add nuw nsw i32 %14824, %14823"
"  %14824 = lshr i32 %14770, 16"
"  %14824 = lshr i32 %14770, 16" -> "  %14825 = add nuw nsw i32 %14824, %14823"
"  %14825 = add nuw nsw i32 %14824, %14823"
"  %14825 = add nuw nsw i32 %14824, %14823" -> "  %14828 = and i32 %14825, 65535""  %14825 = add nuw nsw i32 %14824, %14823" -> "  %14826 = lshr i32 %14825, 16"
"  %14826 = lshr i32 %14825, 16"
"  %14826 = lshr i32 %14825, 16" -> "  %14827 = add nuw nsw i32 %14819, %14826"
"  %14827 = add nuw nsw i32 %14819, %14826"
"  %14827 = add nuw nsw i32 %14819, %14826" -> "  %14832 = add nuw nsw i32 %14827, %14831"
"  %14828 = and i32 %14825, 65535"
"  %14828 = and i32 %14825, 65535" -> "  %14830 = add nuw nsw i32 %14828, %14829"
"  %14829 = lshr i32 %14822, 16"
"  %14829 = lshr i32 %14822, 16" -> "  %14830 = add nuw nsw i32 %14828, %14829"
"  %14830 = add nuw nsw i32 %14828, %14829"
"  %14830 = add nuw nsw i32 %14828, %14829" -> "  %14836 = and i32 %14830, 65535""  %14830 = add nuw nsw i32 %14828, %14829" -> "  %14831 = lshr i32 %14830, 16"
"  %14831 = lshr i32 %14830, 16"
"  %14831 = lshr i32 %14830, 16" -> "  %14832 = add nuw nsw i32 %14827, %14831"
"  %14832 = add nuw nsw i32 %14827, %14831"
"  %14832 = add nuw nsw i32 %14827, %14831" -> "  %14845 = and i32 %14832, 2147418112""  %14832 = add nuw nsw i32 %14827, %14831" -> "  %14843 = and i32 %14832, 65535"
"  %14833 = and i32 %14822, 65535"
"  %14833 = and i32 %14822, 65535" -> "  %14835 = add nuw nsw i32 %14834, %14833"
"  %14834 = and i32 %14801, 65535"
"  %14834 = and i32 %14801, 65535" -> "  %14835 = add nuw nsw i32 %14834, %14833"
"  %14835 = add nuw nsw i32 %14834, %14833"
"  %14835 = add nuw nsw i32 %14834, %14833" -> "  %14875 = and i32 %14835, 65535""  %14835 = add nuw nsw i32 %14834, %14833" -> "  %14839 = lshr i32 %14835, 16"
"  %14836 = and i32 %14830, 65535"
"  %14836 = and i32 %14830, 65535" -> "  %14838 = add nuw nsw i32 %14836, %14837"
"  %14837 = lshr i32 %14801, 16"
"  %14837 = lshr i32 %14801, 16" -> "  %14838 = add nuw nsw i32 %14836, %14837"
"  %14838 = add nuw nsw i32 %14836, %14837"
"  %14838 = add nuw nsw i32 %14836, %14837" -> "  %14842 = lshr i32 %14838, 16""  %14838 = add nuw nsw i32 %14836, %14837" -> "  %14840 = and i32 %14838, 65535"
"  %14839 = lshr i32 %14835, 16"
"  %14839 = lshr i32 %14835, 16" -> "  %14841 = add nuw nsw i32 %14840, %14839"
"  %14840 = and i32 %14838, 65535"
"  %14840 = and i32 %14838, 65535" -> "  %14841 = add nuw nsw i32 %14840, %14839"
"  %14841 = add nuw nsw i32 %14840, %14839"
"  %14841 = add nuw nsw i32 %14840, %14839" -> "  %14882 = and i32 %14841, 65535""  %14841 = add nuw nsw i32 %14840, %14839" -> "  %14847 = lshr i32 %14841, 16"
"  %14842 = lshr i32 %14838, 16"
"  %14842 = lshr i32 %14838, 16" -> "  %14844 = add nuw nsw i32 %14842, %14843"
"  %14843 = and i32 %14832, 65535"
"  %14843 = and i32 %14832, 65535" -> "  %14844 = add nuw nsw i32 %14842, %14843"
"  %14844 = add nuw nsw i32 %14842, %14843"
"  %14844 = add nuw nsw i32 %14842, %14843" -> "  %14846 = add nuw nsw i32 %14844, %14845"
"  %14845 = and i32 %14832, 2147418112"
"  %14845 = and i32 %14832, 2147418112" -> "  %14846 = add nuw nsw i32 %14844, %14845"
"  %14846 = add nuw nsw i32 %14844, %14845"
"  %14846 = add nuw nsw i32 %14844, %14845" -> "  %14848 = add nuw nsw i32 %14846, %14847"
"  %14847 = lshr i32 %14841, 16"
"  %14847 = lshr i32 %14841, 16" -> "  %14848 = add nuw nsw i32 %14846, %14847"
"  %14848 = add nuw nsw i32 %14846, %14847"
"  %14848 = add nuw nsw i32 %14846, %14847" -> "  %14886 = add nuw nsw i32 %14848, %14885"
"  %14849 = and i32 %14722, 65535"
"  %14849 = and i32 %14722, 65535" -> "  %14851 = add nuw nsw i32 %14850, %14849"
"  %14850 = and i32 %14708, 65535"
"  %14850 = and i32 %14708, 65535" -> "  %14851 = add nuw nsw i32 %14850, %14849"
"  %14851 = add nuw nsw i32 %14850, %14849"
"  %14851 = add nuw nsw i32 %14850, %14849" -> "  %15015 = and i32 %14851, 65535""  %14851 = add nuw nsw i32 %14850, %14849" -> "  %14855 = lshr i32 %14851, 16"
"  %14852 = and i32 %14731, 65535"
"  %14852 = and i32 %14731, 65535" -> "  %14854 = add nuw nsw i32 %14852, %14853"
"  %14853 = and i32 %14714, 65535"
"  %14853 = and i32 %14714, 65535" -> "  %14854 = add nuw nsw i32 %14852, %14853"
"  %14854 = add nuw nsw i32 %14852, %14853"
"  %14854 = add nuw nsw i32 %14852, %14853" -> "  %14858 = lshr i32 %14854, 16""  %14854 = add nuw nsw i32 %14852, %14853" -> "  %14856 = and i32 %14854, 65535"
"  %14855 = lshr i32 %14851, 16"
"  %14855 = lshr i32 %14851, 16" -> "  %14857 = add nuw nsw i32 %14856, %14855"
"  %14856 = and i32 %14854, 65535"
"  %14856 = and i32 %14854, 65535" -> "  %14857 = add nuw nsw i32 %14856, %14855"
"  %14857 = add nuw nsw i32 %14856, %14855"
"  %14857 = add nuw nsw i32 %14856, %14855" -> "  %15018 = and i32 %14857, 65535""  %14857 = add nuw nsw i32 %14856, %14855" -> "  %14859 = lshr i32 %14857, 16"
"  %14858 = lshr i32 %14854, 16"
"  %14858 = lshr i32 %14854, 16" -> "  %14870 = add nuw nsw i32 %14859, %14858"
"  %14859 = lshr i32 %14857, 16"
"  %14859 = lshr i32 %14857, 16" -> "  %14870 = add nuw nsw i32 %14859, %14858"
"  %14860 = and i32 %14791, 65535"
"  %14860 = and i32 %14791, 65535" -> "  %14862 = add nuw nsw i32 %14860, %14861"
"  %14861 = and i32 %14721, 65535"
"  %14861 = and i32 %14721, 65535" -> "  %14862 = add nuw nsw i32 %14860, %14861"
"  %14862 = add nuw nsw i32 %14860, %14861"
"  %14862 = add nuw nsw i32 %14860, %14861" -> "  %14869 = and i32 %14862, 65535""  %14862 = add nuw nsw i32 %14860, %14861" -> "  %14866 = lshr i32 %14862, 16"
"  %14863 = and i32 %14799, 65535"
"  %14863 = and i32 %14799, 65535" -> "  %14865 = add nuw nsw i32 %14863, %14864"
"  %14864 = lshr i32 %14721, 16"
"  %14864 = lshr i32 %14721, 16" -> "  %14865 = add nuw nsw i32 %14863, %14864"
"  %14865 = add nuw nsw i32 %14863, %14864"
"  %14865 = add nuw nsw i32 %14863, %14864" -> "  %14876 = lshr i32 %14865, 16""  %14865 = add nuw nsw i32 %14863, %14864" -> "  %14867 = and i32 %14865, 65535"
"  %14866 = lshr i32 %14862, 16"
"  %14866 = lshr i32 %14862, 16" -> "  %14868 = add nuw nsw i32 %14867, %14866"
"  %14867 = and i32 %14865, 65535"
"  %14867 = and i32 %14865, 65535" -> "  %14868 = add nuw nsw i32 %14867, %14866"
"  %14868 = add nuw nsw i32 %14867, %14866"
"  %14868 = add nuw nsw i32 %14867, %14866" -> "  %14878 = lshr i32 %14868, 16""  %14868 = add nuw nsw i32 %14867, %14866" -> "  %14873 = and i32 %14868, 65535"
"  %14869 = and i32 %14862, 65535"
"  %14869 = and i32 %14862, 65535" -> "  %14871 = add nuw nsw i32 %14870, %14869"
"  %14870 = add nuw nsw i32 %14859, %14858"
"  %14870 = add nuw nsw i32 %14859, %14858" -> "  %14871 = add nuw nsw i32 %14870, %14869"
"  %14871 = add nuw nsw i32 %14870, %14869"
"  %14871 = add nuw nsw i32 %14870, %14869" -> "  %15026 = and i32 %14871, 65535""  %14871 = add nuw nsw i32 %14870, %14869" -> "  %14872 = lshr i32 %14871, 16"
"  %14872 = lshr i32 %14871, 16"
"  %14872 = lshr i32 %14871, 16" -> "  %14874 = add nuw nsw i32 %14873, %14872"
"  %14873 = and i32 %14868, 65535"
"  %14873 = and i32 %14868, 65535" -> "  %14874 = add nuw nsw i32 %14873, %14872"
"  %14874 = add nuw nsw i32 %14873, %14872"
"  %14874 = add nuw nsw i32 %14873, %14872" -> "  %15029 = and i32 %14874, 65535""  %14874 = add nuw nsw i32 %14873, %14872" -> "  %14880 = lshr i32 %14874, 16"
"  %14875 = and i32 %14835, 65535"
"  %14875 = and i32 %14835, 65535" -> "  %14877 = add nuw nsw i32 %14875, %14876"
"  %14876 = lshr i32 %14865, 16"
"  %14876 = lshr i32 %14865, 16" -> "  %14877 = add nuw nsw i32 %14875, %14876"
"  %14877 = add nuw nsw i32 %14875, %14876"
"  %14877 = add nuw nsw i32 %14875, %14876" -> "  %14879 = add nuw nsw i32 %14877, %14878"
"  %14878 = lshr i32 %14868, 16"
"  %14878 = lshr i32 %14868, 16" -> "  %14879 = add nuw nsw i32 %14877, %14878"
"  %14879 = add nuw nsw i32 %14877, %14878"
"  %14879 = add nuw nsw i32 %14877, %14878" -> "  %14881 = add nuw nsw i32 %14879, %14880"
"  %14880 = lshr i32 %14874, 16"
"  %14880 = lshr i32 %14874, 16" -> "  %14881 = add nuw nsw i32 %14879, %14880"
"  %14881 = add nuw nsw i32 %14879, %14880"
"  %14881 = add nuw nsw i32 %14879, %14880" -> "  %15180 = and i32 %14881, 65535""  %14881 = add nuw nsw i32 %14879, %14880" -> "  %14883 = lshr i32 %14881, 16"
"  %14882 = and i32 %14841, 65535"
"  %14882 = and i32 %14841, 65535" -> "  %14884 = add nuw nsw i32 %14883, %14882"
"  %14883 = lshr i32 %14881, 16"
"  %14883 = lshr i32 %14881, 16" -> "  %14884 = add nuw nsw i32 %14883, %14882"
"  %14884 = add nuw nsw i32 %14883, %14882"
"  %14884 = add nuw nsw i32 %14883, %14882" -> "  %15183 = and i32 %14884, 65535""  %14884 = add nuw nsw i32 %14883, %14882" -> "  %14885 = lshr i32 %14884, 16"
"  %14885 = lshr i32 %14884, 16"
"  %14885 = lshr i32 %14884, 16" -> "  %14886 = add nuw nsw i32 %14848, %14885"
"  %14886 = add nuw nsw i32 %14848, %14885"
"  %14886 = add nuw nsw i32 %14848, %14885" -> "  %15189 = and i32 %14886, 65535""  %14886 = add nuw nsw i32 %14848, %14885" -> "  %15192 = lshr i32 %14886, 16"
"  %14887 = mul nuw nsw i32 %13153, 4087"
"  %14887 = mul nuw nsw i32 %13153, 4087" -> "  %15014 = and i32 %14887, 65535""  %14887 = mul nuw nsw i32 %13153, 4087" -> "  %14888 = lshr i32 %14887, 16"
"  %14888 = lshr i32 %14887, 16"
"  %14888 = lshr i32 %14887, 16" -> "  %14891 = add nuw nsw i32 %14890, %14888"
"  %14889 = mul nuw nsw i32 %13156, 4087"
"  %14889 = mul nuw nsw i32 %13156, 4087" -> "  %14892 = and i32 %14889, 268369920""  %14889 = mul nuw nsw i32 %13156, 4087" -> "  %14890 = and i32 %14889, 65535"
"  %14890 = and i32 %14889, 65535"
"  %14890 = and i32 %14889, 65535" -> "  %14891 = add nuw nsw i32 %14890, %14888"
"  %14891 = add nuw nsw i32 %14890, %14888"
"  %14891 = add nuw nsw i32 %14890, %14888" -> "  %14893 = add nuw nsw i32 %14891, %14892"
"  %14892 = and i32 %14889, 268369920"
"  %14892 = and i32 %14889, 268369920" -> "  %14893 = add nuw nsw i32 %14891, %14892"
"  %14893 = add nuw nsw i32 %14891, %14892"
"  %14893 = add nuw nsw i32 %14891, %14892" -> "  %14897 = lshr i32 %14893, 16""  %14893 = add nuw nsw i32 %14891, %14892" -> "  %14895 = and i32 %14893, 65535"
"  %14894 = mul nuw nsw i32 %13153, 11561"
"  %14894 = mul nuw nsw i32 %13153, 11561" -> "  %14896 = add nuw nsw i32 %14895, %14894"
"  %14895 = and i32 %14893, 65535"
"  %14895 = and i32 %14893, 65535" -> "  %14896 = add nuw nsw i32 %14895, %14894"
"  %14896 = add nuw nsw i32 %14895, %14894"
"  %14896 = add nuw nsw i32 %14895, %14894" -> "  %15017 = and i32 %14896, 65535""  %14896 = add nuw nsw i32 %14895, %14894" -> "  %14900 = lshr i32 %14896, 16"
"  %14897 = lshr i32 %14893, 16"
"  %14897 = lshr i32 %14893, 16" -> "  %14899 = add nuw nsw i32 %14897, %14898"
"  %14898 = mul nuw nsw i32 %13156, 11561"
"  %14898 = mul nuw nsw i32 %13156, 11561" -> "  %14899 = add nuw nsw i32 %14897, %14898"
"  %14899 = add nuw nsw i32 %14897, %14898"
"  %14899 = add nuw nsw i32 %14897, %14898" -> "  %14903 = and i32 %14899, 2147418112""  %14899 = add nuw nsw i32 %14897, %14898" -> "  %14901 = and i32 %14899, 65535"
"  %14900 = lshr i32 %14896, 16"
"  %14900 = lshr i32 %14896, 16" -> "  %14902 = add nuw nsw i32 %14900, %14901"
"  %14901 = and i32 %14899, 65535"
"  %14901 = and i32 %14899, 65535" -> "  %14902 = add nuw nsw i32 %14900, %14901"
"  %14902 = add nuw nsw i32 %14900, %14901"
"  %14902 = add nuw nsw i32 %14900, %14901" -> "  %14904 = add nuw nsw i32 %14902, %14903"
"  %14903 = and i32 %14899, 2147418112"
"  %14903 = and i32 %14899, 2147418112" -> "  %14904 = add nuw nsw i32 %14902, %14903"
"  %14904 = add nuw nsw i32 %14902, %14903"
"  %14904 = add nuw nsw i32 %14902, %14903" -> "  %14927 = lshr i32 %14904, 16""  %14904 = add nuw nsw i32 %14902, %14903" -> "  %14923 = and i32 %14904, 65535"
"  %14905 = mul nuw nsw i32 %13173, 4087"
"  %14905 = mul nuw nsw i32 %13173, 4087" -> "  %14924 = and i32 %14905, 65535""  %14905 = mul nuw nsw i32 %13173, 4087" -> "  %14906 = lshr i32 %14905, 16"
"  %14906 = lshr i32 %14905, 16"
"  %14906 = lshr i32 %14905, 16" -> "  %14909 = add nuw nsw i32 %14908, %14906"
"  %14907 = mul nuw nsw i32 %13176, 4087"
"  %14907 = mul nuw nsw i32 %13176, 4087" -> "  %14910 = and i32 %14907, 268369920""  %14907 = mul nuw nsw i32 %13176, 4087" -> "  %14908 = and i32 %14907, 65535"
"  %14908 = and i32 %14907, 65535"
"  %14908 = and i32 %14907, 65535" -> "  %14909 = add nuw nsw i32 %14908, %14906"
"  %14909 = add nuw nsw i32 %14908, %14906"
"  %14909 = add nuw nsw i32 %14908, %14906" -> "  %14911 = add nuw nsw i32 %14909, %14910"
"  %14910 = and i32 %14907, 268369920"
"  %14910 = and i32 %14907, 268369920" -> "  %14911 = add nuw nsw i32 %14909, %14910"
"  %14911 = add nuw nsw i32 %14909, %14910"
"  %14911 = add nuw nsw i32 %14909, %14910" -> "  %14915 = lshr i32 %14911, 16""  %14911 = add nuw nsw i32 %14909, %14910" -> "  %14913 = and i32 %14911, 65535"
"  %14912 = mul nuw nsw i32 %13173, 11561"
"  %14912 = mul nuw nsw i32 %13173, 11561" -> "  %14914 = add nuw nsw i32 %14913, %14912"
"  %14913 = and i32 %14911, 65535"
"  %14913 = and i32 %14911, 65535" -> "  %14914 = add nuw nsw i32 %14913, %14912"
"  %14914 = add nuw nsw i32 %14913, %14912"
"  %14914 = add nuw nsw i32 %14913, %14912" -> "  %14926 = and i32 %14914, 65535""  %14914 = add nuw nsw i32 %14913, %14912" -> "  %14918 = lshr i32 %14914, 16"
"  %14915 = lshr i32 %14911, 16"
"  %14915 = lshr i32 %14911, 16" -> "  %14917 = add nuw nsw i32 %14915, %14916"
"  %14916 = mul nuw nsw i32 %13176, 11561"
"  %14916 = mul nuw nsw i32 %13176, 11561" -> "  %14917 = add nuw nsw i32 %14915, %14916"
"  %14917 = add nuw nsw i32 %14915, %14916"
"  %14917 = add nuw nsw i32 %14915, %14916" -> "  %14921 = and i32 %14917, 2147418112""  %14917 = add nuw nsw i32 %14915, %14916" -> "  %14919 = and i32 %14917, 65535"
"  %14918 = lshr i32 %14914, 16"
"  %14918 = lshr i32 %14914, 16" -> "  %14920 = add nuw nsw i32 %14918, %14919"
"  %14919 = and i32 %14917, 65535"
"  %14919 = and i32 %14917, 65535" -> "  %14920 = add nuw nsw i32 %14918, %14919"
"  %14920 = add nuw nsw i32 %14918, %14919"
"  %14920 = add nuw nsw i32 %14918, %14919" -> "  %14922 = add nuw nsw i32 %14920, %14921"
"  %14921 = and i32 %14917, 2147418112"
"  %14921 = and i32 %14917, 2147418112" -> "  %14922 = add nuw nsw i32 %14920, %14921"
"  %14922 = add nuw nsw i32 %14920, %14921"
"  %14922 = add nuw nsw i32 %14920, %14921" -> "  %14930 = add nuw nsw i32 %14922, %14929"
"  %14923 = and i32 %14904, 65535"
"  %14923 = and i32 %14904, 65535" -> "  %14925 = add nuw nsw i32 %14923, %14924"
"  %14924 = and i32 %14905, 65535"
"  %14924 = and i32 %14905, 65535" -> "  %14925 = add nuw nsw i32 %14923, %14924"
"  %14925 = add nuw nsw i32 %14923, %14924"
"  %14925 = add nuw nsw i32 %14923, %14924" -> "  %14954 = and i32 %14925, 65535""  %14925 = add nuw nsw i32 %14923, %14924" -> "  %14932 = lshr i32 %14925, 16"
"  %14926 = and i32 %14914, 65535"
"  %14926 = and i32 %14914, 65535" -> "  %14928 = add nuw nsw i32 %14926, %14927"
"  %14927 = lshr i32 %14904, 16"
"  %14927 = lshr i32 %14904, 16" -> "  %14928 = add nuw nsw i32 %14926, %14927"
"  %14928 = add nuw nsw i32 %14926, %14927"
"  %14928 = add nuw nsw i32 %14926, %14927" -> "  %14931 = and i32 %14928, 65535""  %14928 = add nuw nsw i32 %14926, %14927" -> "  %14929 = lshr i32 %14928, 16"
"  %14929 = lshr i32 %14928, 16"
"  %14929 = lshr i32 %14928, 16" -> "  %14930 = add nuw nsw i32 %14922, %14929"
"  %14930 = add nuw nsw i32 %14922, %14929"
"  %14930 = add nuw nsw i32 %14922, %14929" -> "  %14935 = add nuw nsw i32 %14930, %14934"
"  %14931 = and i32 %14928, 65535"
"  %14931 = and i32 %14928, 65535" -> "  %14933 = add nuw nsw i32 %14931, %14932"
"  %14932 = lshr i32 %14925, 16"
"  %14932 = lshr i32 %14925, 16" -> "  %14933 = add nuw nsw i32 %14931, %14932"
"  %14933 = add nuw nsw i32 %14931, %14932"
"  %14933 = add nuw nsw i32 %14931, %14932" -> "  %14958 = and i32 %14933, 65535""  %14933 = add nuw nsw i32 %14931, %14932" -> "  %14934 = lshr i32 %14933, 16"
"  %14934 = lshr i32 %14933, 16"
"  %14934 = lshr i32 %14933, 16" -> "  %14935 = add nuw nsw i32 %14930, %14934"
"  %14935 = add nuw nsw i32 %14930, %14934"
"  %14935 = add nuw nsw i32 %14930, %14934" -> "  %14989 = lshr i32 %14935, 16""  %14935 = add nuw nsw i32 %14930, %14934" -> "  %14985 = and i32 %14935, 65535"
"  %14936 = mul nuw nsw i32 %13153, 21884"
"  %14936 = mul nuw nsw i32 %13153, 21884" -> "  %14955 = and i32 %14936, 65532""  %14936 = mul nuw nsw i32 %13153, 21884" -> "  %14937 = lshr i32 %14936, 16"
"  %14937 = lshr i32 %14936, 16"
"  %14937 = lshr i32 %14936, 16" -> "  %14940 = add nuw nsw i32 %14939, %14937"
"  %14938 = mul nuw nsw i32 %13156, 21884"
"  %14938 = mul nuw nsw i32 %13156, 21884" -> "  %14941 = and i32 %14938, 2147418112""  %14938 = mul nuw nsw i32 %13156, 21884" -> "  %14939 = and i32 %14938, 65532"
"  %14939 = and i32 %14938, 65532"
"  %14939 = and i32 %14938, 65532" -> "  %14940 = add nuw nsw i32 %14939, %14937"
"  %14940 = add nuw nsw i32 %14939, %14937"
"  %14940 = add nuw nsw i32 %14939, %14937" -> "  %14942 = add nuw nsw i32 %14940, %14941"
"  %14941 = and i32 %14938, 2147418112"
"  %14941 = and i32 %14938, 2147418112" -> "  %14942 = add nuw nsw i32 %14940, %14941"
"  %14942 = add nuw nsw i32 %14940, %14941"
"  %14942 = add nuw nsw i32 %14940, %14941" -> "  %14946 = lshr i32 %14942, 16""  %14942 = add nuw nsw i32 %14940, %14941" -> "  %14944 = and i32 %14942, 65535"
"  %14943 = mul nuw i32 %13153, 36786"
"  %14943 = mul nuw i32 %13153, 36786" -> "  %14945 = add nuw i32 %14944, %14943"
"  %14944 = and i32 %14942, 65535"
"  %14944 = and i32 %14942, 65535" -> "  %14945 = add nuw i32 %14944, %14943"
"  %14945 = add nuw i32 %14944, %14943"
"  %14945 = add nuw i32 %14944, %14943" -> "  %14957 = and i32 %14945, 65535""  %14945 = add nuw i32 %14944, %14943" -> "  %14949 = lshr i32 %14945, 16"
"  %14946 = lshr i32 %14942, 16"
"  %14946 = lshr i32 %14942, 16" -> "  %14948 = add nuw i32 %14946, %14947"
"  %14947 = mul nuw i32 %13156, 36786"
"  %14947 = mul nuw i32 %13156, 36786" -> "  %14948 = add nuw i32 %14946, %14947"
"  %14948 = add nuw i32 %14946, %14947"
"  %14948 = add nuw i32 %14946, %14947" -> "  %14952 = and i32 %14948, -65536""  %14948 = add nuw i32 %14946, %14947" -> "  %14950 = and i32 %14948, 65535"
"  %14949 = lshr i32 %14945, 16"
"  %14949 = lshr i32 %14945, 16" -> "  %14951 = add nuw nsw i32 %14949, %14950"
"  %14950 = and i32 %14948, 65535"
"  %14950 = and i32 %14948, 65535" -> "  %14951 = add nuw nsw i32 %14949, %14950"
"  %14951 = add nuw nsw i32 %14949, %14950"
"  %14951 = add nuw nsw i32 %14949, %14950" -> "  %14953 = add nuw i32 %14951, %14952"
"  %14952 = and i32 %14948, -65536"
"  %14952 = and i32 %14948, -65536" -> "  %14953 = add nuw i32 %14951, %14952"
"  %14953 = add nuw i32 %14951, %14952"
"  %14953 = add nuw i32 %14951, %14952" -> "  %14961 = add nuw i32 %14953, %14960"
"  %14954 = and i32 %14925, 65535"
"  %14954 = and i32 %14925, 65535" -> "  %14956 = add nuw nsw i32 %14954, %14955"
"  %14955 = and i32 %14936, 65532"
"  %14955 = and i32 %14936, 65532" -> "  %14956 = add nuw nsw i32 %14954, %14955"
"  %14956 = add nuw nsw i32 %14954, %14955"
"  %14956 = add nuw nsw i32 %14954, %14955" -> "  %15025 = and i32 %14956, 65535""  %14956 = add nuw nsw i32 %14954, %14955" -> "  %14963 = lshr i32 %14956, 16"
"  %14957 = and i32 %14945, 65535"
"  %14957 = and i32 %14945, 65535" -> "  %14959 = add nuw nsw i32 %14958, %14957"
"  %14958 = and i32 %14933, 65535"
"  %14958 = and i32 %14933, 65535" -> "  %14959 = add nuw nsw i32 %14958, %14957"
"  %14959 = add nuw nsw i32 %14958, %14957"
"  %14959 = add nuw nsw i32 %14958, %14957" -> "  %14962 = and i32 %14959, 65535""  %14959 = add nuw nsw i32 %14958, %14957" -> "  %14960 = lshr i32 %14959, 16"
"  %14960 = lshr i32 %14959, 16"
"  %14960 = lshr i32 %14959, 16" -> "  %14961 = add nuw i32 %14953, %14960"
"  %14961 = add nuw i32 %14953, %14960"
"  %14961 = add nuw i32 %14953, %14960" -> "  %14966 = add nuw i32 %14961, %14965"
"  %14962 = and i32 %14959, 65535"
"  %14962 = and i32 %14959, 65535" -> "  %14964 = add nuw nsw i32 %14962, %14963"
"  %14963 = lshr i32 %14956, 16"
"  %14963 = lshr i32 %14956, 16" -> "  %14964 = add nuw nsw i32 %14962, %14963"
"  %14964 = add nuw nsw i32 %14962, %14963"
"  %14964 = add nuw nsw i32 %14962, %14963" -> "  %15028 = and i32 %14964, 65535""  %14964 = add nuw nsw i32 %14962, %14963" -> "  %14965 = lshr i32 %14964, 16"
"  %14965 = lshr i32 %14964, 16"
"  %14965 = lshr i32 %14964, 16" -> "  %14966 = add nuw i32 %14961, %14965"
"  %14966 = add nuw i32 %14961, %14965"
"  %14966 = add nuw i32 %14961, %14965" -> "  %15002 = lshr i32 %14966, 16""  %14966 = add nuw i32 %14961, %14965" -> "  %14999 = and i32 %14966, 65535"
"  %14967 = mul nuw nsw i32 %13173, 21884"
"  %14967 = mul nuw nsw i32 %13173, 21884" -> "  %14986 = and i32 %14967, 65532""  %14967 = mul nuw nsw i32 %13173, 21884" -> "  %14968 = lshr i32 %14967, 16"
"  %14968 = lshr i32 %14967, 16"
"  %14968 = lshr i32 %14967, 16" -> "  %14971 = add nuw nsw i32 %14970, %14968"
"  %14969 = mul nuw nsw i32 %13176, 21884"
"  %14969 = mul nuw nsw i32 %13176, 21884" -> "  %14972 = and i32 %14969, 2147418112""  %14969 = mul nuw nsw i32 %13176, 21884" -> "  %14970 = and i32 %14969, 65532"
"  %14970 = and i32 %14969, 65532"
"  %14970 = and i32 %14969, 65532" -> "  %14971 = add nuw nsw i32 %14970, %14968"
"  %14971 = add nuw nsw i32 %14970, %14968"
"  %14971 = add nuw nsw i32 %14970, %14968" -> "  %14973 = add nuw nsw i32 %14971, %14972"
"  %14972 = and i32 %14969, 2147418112"
"  %14972 = and i32 %14969, 2147418112" -> "  %14973 = add nuw nsw i32 %14971, %14972"
"  %14973 = add nuw nsw i32 %14971, %14972"
"  %14973 = add nuw nsw i32 %14971, %14972" -> "  %14977 = lshr i32 %14973, 16""  %14973 = add nuw nsw i32 %14971, %14972" -> "  %14975 = and i32 %14973, 65535"
"  %14974 = mul nuw i32 %13173, 36786"
"  %14974 = mul nuw i32 %13173, 36786" -> "  %14976 = add nuw i32 %14975, %14974"
"  %14975 = and i32 %14973, 65535"
"  %14975 = and i32 %14973, 65535" -> "  %14976 = add nuw i32 %14975, %14974"
"  %14976 = add nuw i32 %14975, %14974"
"  %14976 = add nuw i32 %14975, %14974" -> "  %14988 = and i32 %14976, 65535""  %14976 = add nuw i32 %14975, %14974" -> "  %14980 = lshr i32 %14976, 16"
"  %14977 = lshr i32 %14973, 16"
"  %14977 = lshr i32 %14973, 16" -> "  %14979 = add nuw i32 %14977, %14978"
"  %14978 = mul nuw i32 %13176, 36786"
"  %14978 = mul nuw i32 %13176, 36786" -> "  %14979 = add nuw i32 %14977, %14978"
"  %14979 = add nuw i32 %14977, %14978"
"  %14979 = add nuw i32 %14977, %14978" -> "  %14983 = and i32 %14979, -65536""  %14979 = add nuw i32 %14977, %14978" -> "  %14981 = and i32 %14979, 65535"
"  %14980 = lshr i32 %14976, 16"
"  %14980 = lshr i32 %14976, 16" -> "  %14982 = add nuw nsw i32 %14980, %14981"
"  %14981 = and i32 %14979, 65535"
"  %14981 = and i32 %14979, 65535" -> "  %14982 = add nuw nsw i32 %14980, %14981"
"  %14982 = add nuw nsw i32 %14980, %14981"
"  %14982 = add nuw nsw i32 %14980, %14981" -> "  %14984 = add nuw i32 %14982, %14983"
"  %14983 = and i32 %14979, -65536"
"  %14983 = and i32 %14979, -65536" -> "  %14984 = add nuw i32 %14982, %14983"
"  %14984 = add nuw i32 %14982, %14983"
"  %14984 = add nuw i32 %14982, %14983" -> "  %14992 = add nuw i32 %14984, %14991"
"  %14985 = and i32 %14935, 65535"
"  %14985 = and i32 %14935, 65535" -> "  %14987 = add nuw nsw i32 %14985, %14986"
"  %14986 = and i32 %14967, 65532"
"  %14986 = and i32 %14967, 65532" -> "  %14987 = add nuw nsw i32 %14985, %14986"
"  %14987 = add nuw nsw i32 %14985, %14986"
"  %14987 = add nuw nsw i32 %14985, %14986" -> "  %14998 = and i32 %14987, 65535""  %14987 = add nuw nsw i32 %14985, %14986" -> "  %14994 = lshr i32 %14987, 16"
"  %14988 = and i32 %14976, 65535"
"  %14988 = and i32 %14976, 65535" -> "  %14990 = add nuw nsw i32 %14989, %14988"
"  %14989 = lshr i32 %14935, 16"
"  %14989 = lshr i32 %14935, 16" -> "  %14990 = add nuw nsw i32 %14989, %14988"
"  %14990 = add nuw nsw i32 %14989, %14988"
"  %14990 = add nuw nsw i32 %14989, %14988" -> "  %14993 = and i32 %14990, 65535""  %14990 = add nuw nsw i32 %14989, %14988" -> "  %14991 = lshr i32 %14990, 16"
"  %14991 = lshr i32 %14990, 16"
"  %14991 = lshr i32 %14990, 16" -> "  %14992 = add nuw i32 %14984, %14991"
"  %14992 = add nuw i32 %14984, %14991"
"  %14992 = add nuw i32 %14984, %14991" -> "  %14997 = add nuw i32 %14992, %14996"
"  %14993 = and i32 %14990, 65535"
"  %14993 = and i32 %14990, 65535" -> "  %14995 = add nuw nsw i32 %14993, %14994"
"  %14994 = lshr i32 %14987, 16"
"  %14994 = lshr i32 %14987, 16" -> "  %14995 = add nuw nsw i32 %14993, %14994"
"  %14995 = add nuw nsw i32 %14993, %14994"
"  %14995 = add nuw nsw i32 %14993, %14994" -> "  %15001 = and i32 %14995, 65535""  %14995 = add nuw nsw i32 %14993, %14994" -> "  %14996 = lshr i32 %14995, 16"
"  %14996 = lshr i32 %14995, 16"
"  %14996 = lshr i32 %14995, 16" -> "  %14997 = add nuw i32 %14992, %14996"
"  %14997 = add nuw i32 %14992, %14996"
"  %14997 = add nuw i32 %14992, %14996" -> "  %15010 = and i32 %14997, -65536""  %14997 = add nuw i32 %14992, %14996" -> "  %15008 = and i32 %14997, 65535"
"  %14998 = and i32 %14987, 65535"
"  %14998 = and i32 %14987, 65535" -> "  %15000 = add nuw nsw i32 %14999, %14998"
"  %14999 = and i32 %14966, 65535"
"  %14999 = and i32 %14966, 65535" -> "  %15000 = add nuw nsw i32 %14999, %14998"
"  %15000 = add nuw nsw i32 %14999, %14998"
"  %15000 = add nuw nsw i32 %14999, %14998" -> "  %15040 = and i32 %15000, 65535""  %15000 = add nuw nsw i32 %14999, %14998" -> "  %15004 = lshr i32 %15000, 16"
"  %15001 = and i32 %14995, 65535"
"  %15001 = and i32 %14995, 65535" -> "  %15003 = add nuw nsw i32 %15001, %15002"
"  %15002 = lshr i32 %14966, 16"
"  %15002 = lshr i32 %14966, 16" -> "  %15003 = add nuw nsw i32 %15001, %15002"
"  %15003 = add nuw nsw i32 %15001, %15002"
"  %15003 = add nuw nsw i32 %15001, %15002" -> "  %15007 = lshr i32 %15003, 16""  %15003 = add nuw nsw i32 %15001, %15002" -> "  %15005 = and i32 %15003, 65535"
"  %15004 = lshr i32 %15000, 16"
"  %15004 = lshr i32 %15000, 16" -> "  %15006 = add nuw nsw i32 %15005, %15004"
"  %15005 = and i32 %15003, 65535"
"  %15005 = and i32 %15003, 65535" -> "  %15006 = add nuw nsw i32 %15005, %15004"
"  %15006 = add nuw nsw i32 %15005, %15004"
"  %15006 = add nuw nsw i32 %15005, %15004" -> "  %15047 = and i32 %15006, 65535""  %15006 = add nuw nsw i32 %15005, %15004" -> "  %15012 = lshr i32 %15006, 16"
"  %15007 = lshr i32 %15003, 16"
"  %15007 = lshr i32 %15003, 16" -> "  %15009 = add nuw nsw i32 %15007, %15008"
"  %15008 = and i32 %14997, 65535"
"  %15008 = and i32 %14997, 65535" -> "  %15009 = add nuw nsw i32 %15007, %15008"
"  %15009 = add nuw nsw i32 %15007, %15008"
"  %15009 = add nuw nsw i32 %15007, %15008" -> "  %15011 = add nuw i32 %15009, %15010"
"  %15010 = and i32 %14997, -65536"
"  %15010 = and i32 %14997, -65536" -> "  %15011 = add nuw i32 %15009, %15010"
"  %15011 = add nuw i32 %15009, %15010"
"  %15011 = add nuw i32 %15009, %15010" -> "  %15013 = add nuw i32 %15011, %15012"
"  %15012 = lshr i32 %15006, 16"
"  %15012 = lshr i32 %15006, 16" -> "  %15013 = add nuw i32 %15011, %15012"
"  %15013 = add nuw i32 %15011, %15012"
"  %15013 = add nuw i32 %15011, %15012" -> "  %15051 = add nuw i32 %15013, %15050"
"  %15014 = and i32 %14887, 65535"
"  %15014 = and i32 %14887, 65535" -> "  %15016 = add nuw nsw i32 %15015, %15014"
"  %15015 = and i32 %14851, 65535"
"  %15015 = and i32 %14851, 65535" -> "  %15016 = add nuw nsw i32 %15015, %15014"
"  %15016 = add nuw nsw i32 %15015, %15014"
"  %15016 = add nuw nsw i32 %15015, %15014" -> "  %15282 = and i32 %15016, 65535""  %15016 = add nuw nsw i32 %15015, %15014" -> "  %15020 = lshr i32 %15016, 16""  %15016 = add nuw nsw i32 %15015, %15014" -> "  store i32 %15016, i32* %2781, align 1, !noalias !32"
"  store i32 %15016, i32* %2781, align 1, !noalias !32"

"  %15017 = and i32 %14896, 65535"
"  %15017 = and i32 %14896, 65535" -> "  %15019 = add nuw nsw i32 %15018, %15017"
"  %15018 = and i32 %14857, 65535"
"  %15018 = and i32 %14857, 65535" -> "  %15019 = add nuw nsw i32 %15018, %15017"
"  %15019 = add nuw nsw i32 %15018, %15017"
"  %15019 = add nuw nsw i32 %15018, %15017" -> "  %15023 = lshr i32 %15019, 16""  %15019 = add nuw nsw i32 %15018, %15017" -> "  %15021 = and i32 %15019, 65535"
"  %15020 = lshr i32 %15016, 16"
"  %15020 = lshr i32 %15016, 16" -> "  %15022 = add nuw nsw i32 %15021, %15020"
"  %15021 = and i32 %15019, 65535"
"  %15021 = and i32 %15019, 65535" -> "  %15022 = add nuw nsw i32 %15021, %15020"
"  %15022 = add nuw nsw i32 %15021, %15020"
"  %15022 = add nuw nsw i32 %15021, %15020" -> "  %15285 = and i32 %15022, 65535""  %15022 = add nuw nsw i32 %15021, %15020" -> "  %15024 = lshr i32 %15022, 16"
"  %15023 = lshr i32 %15019, 16"
"  %15023 = lshr i32 %15019, 16" -> "  %15035 = add nuw nsw i32 %15024, %15023"
"  %15024 = lshr i32 %15022, 16"
"  %15024 = lshr i32 %15022, 16" -> "  %15035 = add nuw nsw i32 %15024, %15023"
"  %15025 = and i32 %14956, 65535"
"  %15025 = and i32 %14956, 65535" -> "  %15027 = add nuw nsw i32 %15026, %15025"
"  %15026 = and i32 %14871, 65535"
"  %15026 = and i32 %14871, 65535" -> "  %15027 = add nuw nsw i32 %15026, %15025"
"  %15027 = add nuw nsw i32 %15026, %15025"
"  %15027 = add nuw nsw i32 %15026, %15025" -> "  %15034 = and i32 %15027, 65535""  %15027 = add nuw nsw i32 %15026, %15025" -> "  %15031 = lshr i32 %15027, 16"
"  %15028 = and i32 %14964, 65535"
"  %15028 = and i32 %14964, 65535" -> "  %15030 = add nuw nsw i32 %15029, %15028"
"  %15029 = and i32 %14874, 65535"
"  %15029 = and i32 %14874, 65535" -> "  %15030 = add nuw nsw i32 %15029, %15028"
"  %15030 = add nuw nsw i32 %15029, %15028"
"  %15030 = add nuw nsw i32 %15029, %15028" -> "  %15041 = lshr i32 %15030, 16""  %15030 = add nuw nsw i32 %15029, %15028" -> "  %15032 = and i32 %15030, 65535"
"  %15031 = lshr i32 %15027, 16"
"  %15031 = lshr i32 %15027, 16" -> "  %15033 = add nuw nsw i32 %15032, %15031"
"  %15032 = and i32 %15030, 65535"
"  %15032 = and i32 %15030, 65535" -> "  %15033 = add nuw nsw i32 %15032, %15031"
"  %15033 = add nuw nsw i32 %15032, %15031"
"  %15033 = add nuw nsw i32 %15032, %15031" -> "  %15043 = lshr i32 %15033, 16""  %15033 = add nuw nsw i32 %15032, %15031" -> "  %15038 = and i32 %15033, 65535"
"  %15034 = and i32 %15027, 65535"
"  %15034 = and i32 %15027, 65535" -> "  %15036 = add nuw nsw i32 %15035, %15034"
"  %15035 = add nuw nsw i32 %15024, %15023"
"  %15035 = add nuw nsw i32 %15024, %15023" -> "  %15036 = add nuw nsw i32 %15035, %15034"
"  %15036 = add nuw nsw i32 %15035, %15034"
"  %15036 = add nuw nsw i32 %15035, %15034" -> "  %15294 = and i32 %15036, 65535""  %15036 = add nuw nsw i32 %15035, %15034" -> "  %15037 = lshr i32 %15036, 16""  %15036 = add nuw nsw i32 %15035, %15034" -> "  store i32 %15036, i32* %2975, align 1, !noalias !32"
"  store i32 %15036, i32* %2975, align 1, !noalias !32"

"  %15037 = lshr i32 %15036, 16"
"  %15037 = lshr i32 %15036, 16" -> "  %15039 = add nuw nsw i32 %15038, %15037"
"  %15038 = and i32 %15033, 65535"
"  %15038 = and i32 %15033, 65535" -> "  %15039 = add nuw nsw i32 %15038, %15037"
"  %15039 = add nuw nsw i32 %15038, %15037"
"  %15039 = add nuw nsw i32 %15038, %15037" -> "  %15297 = and i32 %15039, 65535""  %15039 = add nuw nsw i32 %15038, %15037" -> "  %15045 = lshr i32 %15039, 16""  %15039 = add nuw nsw i32 %15038, %15037" -> "  store i32 %15039, i32* %2981, align 1, !noalias !32"
"  store i32 %15039, i32* %2981, align 1, !noalias !32"

"  %15040 = and i32 %15000, 65535"
"  %15040 = and i32 %15000, 65535" -> "  %15042 = add nuw nsw i32 %15041, %15040"
"  %15041 = lshr i32 %15030, 16"
"  %15041 = lshr i32 %15030, 16" -> "  %15042 = add nuw nsw i32 %15041, %15040"
"  %15042 = add nuw nsw i32 %15041, %15040"
"  %15042 = add nuw nsw i32 %15041, %15040" -> "  %15044 = add nuw nsw i32 %15042, %15043"
"  %15043 = lshr i32 %15033, 16"
"  %15043 = lshr i32 %15033, 16" -> "  %15044 = add nuw nsw i32 %15042, %15043"
"  %15044 = add nuw nsw i32 %15042, %15043"
"  %15044 = add nuw nsw i32 %15042, %15043" -> "  %15046 = add nuw nsw i32 %15044, %15045"
"  %15045 = lshr i32 %15039, 16"
"  %15045 = lshr i32 %15039, 16" -> "  %15046 = add nuw nsw i32 %15044, %15045"
"  %15046 = add nuw nsw i32 %15044, %15045"
"  %15046 = add nuw nsw i32 %15044, %15045" -> "  %15218 = and i32 %15046, 65535""  %15046 = add nuw nsw i32 %15044, %15045" -> "  %15048 = lshr i32 %15046, 16"
"  %15047 = and i32 %15006, 65535"
"  %15047 = and i32 %15006, 65535" -> "  %15049 = add nuw nsw i32 %15048, %15047"
"  %15048 = lshr i32 %15046, 16"
"  %15048 = lshr i32 %15046, 16" -> "  %15049 = add nuw nsw i32 %15048, %15047"
"  %15049 = add nuw nsw i32 %15048, %15047"
"  %15049 = add nuw nsw i32 %15048, %15047" -> "  %15221 = and i32 %15049, 65535""  %15049 = add nuw nsw i32 %15048, %15047" -> "  %15050 = lshr i32 %15049, 16"
"  %15050 = lshr i32 %15049, 16"
"  %15050 = lshr i32 %15049, 16" -> "  %15051 = add nuw i32 %15013, %15050"
"  %15051 = add nuw i32 %15013, %15050"
"  %15051 = add nuw i32 %15013, %15050" -> "  %15227 = and i32 %15051, 65535""  %15051 = add nuw i32 %15013, %15050" -> "  %15230 = lshr i32 %15051, 16""  %15051 = add nuw i32 %15013, %15050" -> "  store i32 %15051, i32* %2997, align 1, !noalias !32"
"  store i32 %15051, i32* %2997, align 1, !noalias !32"

"  %15052 = mul nuw nsw i32 %13287, 4087"
"  %15052 = mul nuw nsw i32 %13287, 4087" -> "  %15179 = and i32 %15052, 65535""  %15052 = mul nuw nsw i32 %13287, 4087" -> "  %15053 = lshr i32 %15052, 16""  %15052 = mul nuw nsw i32 %13287, 4087" -> "  store i32 %15052, i32* %7009, align 1, !noalias !32"
"  store i32 %15052, i32* %7009, align 1, !noalias !32"

"  %15053 = lshr i32 %15052, 16"
"  %15053 = lshr i32 %15052, 16" -> "  %15056 = add nuw nsw i32 %15055, %15053"
"  %15054 = mul nuw nsw i32 %13290, 4087"
"  %15054 = mul nuw nsw i32 %13290, 4087" -> "  %15057 = and i32 %15054, 268369920""  %15054 = mul nuw nsw i32 %13290, 4087" -> "  %15055 = and i32 %15054, 65535"
"  %15055 = and i32 %15054, 65535"
"  %15055 = and i32 %15054, 65535" -> "  %15056 = add nuw nsw i32 %15055, %15053"
"  %15056 = add nuw nsw i32 %15055, %15053"
"  %15056 = add nuw nsw i32 %15055, %15053" -> "  %15058 = add nuw nsw i32 %15056, %15057"
"  %15057 = and i32 %15054, 268369920"
"  %15057 = and i32 %15054, 268369920" -> "  %15058 = add nuw nsw i32 %15056, %15057"
"  %15058 = add nuw nsw i32 %15056, %15057"
"  %15058 = add nuw nsw i32 %15056, %15057" -> "  %15062 = lshr i32 %15058, 16""  %15058 = add nuw nsw i32 %15056, %15057" -> "  %15060 = and i32 %15058, 65535"
"  %15059 = mul nuw nsw i32 %13287, 11561"
"  %15059 = mul nuw nsw i32 %13287, 11561" -> "  %15061 = add nuw nsw i32 %15060, %15059"
"  %15060 = and i32 %15058, 65535"
"  %15060 = and i32 %15058, 65535" -> "  %15061 = add nuw nsw i32 %15060, %15059"
"  %15061 = add nuw nsw i32 %15060, %15059"
"  %15061 = add nuw nsw i32 %15060, %15059" -> "  %15182 = and i32 %15061, 65535""  %15061 = add nuw nsw i32 %15060, %15059" -> "  %15065 = lshr i32 %15061, 16"
"  %15062 = lshr i32 %15058, 16"
"  %15062 = lshr i32 %15058, 16" -> "  %15064 = add nuw nsw i32 %15062, %15063"
"  %15063 = mul nuw nsw i32 %13290, 11561"
"  %15063 = mul nuw nsw i32 %13290, 11561" -> "  %15064 = add nuw nsw i32 %15062, %15063"
"  %15064 = add nuw nsw i32 %15062, %15063"
"  %15064 = add nuw nsw i32 %15062, %15063" -> "  %15068 = and i32 %15064, 2147418112""  %15064 = add nuw nsw i32 %15062, %15063" -> "  %15066 = and i32 %15064, 65535"
"  %15065 = lshr i32 %15061, 16"
"  %15065 = lshr i32 %15061, 16" -> "  %15067 = add nuw nsw i32 %15065, %15066"
"  %15066 = and i32 %15064, 65535"
"  %15066 = and i32 %15064, 65535" -> "  %15067 = add nuw nsw i32 %15065, %15066"
"  %15067 = add nuw nsw i32 %15065, %15066"
"  %15067 = add nuw nsw i32 %15065, %15066" -> "  %15069 = add nuw nsw i32 %15067, %15068"
"  %15068 = and i32 %15064, 2147418112"
"  %15068 = and i32 %15064, 2147418112" -> "  %15069 = add nuw nsw i32 %15067, %15068"
"  %15069 = add nuw nsw i32 %15067, %15068"
"  %15069 = add nuw nsw i32 %15067, %15068" -> "  %15092 = lshr i32 %15069, 16""  %15069 = add nuw nsw i32 %15067, %15068" -> "  %15088 = and i32 %15069, 65535"
"  %15070 = mul nuw nsw i32 %13307, 4087"
"  %15070 = mul nuw nsw i32 %13307, 4087" -> "  %15089 = and i32 %15070, 65535""  %15070 = mul nuw nsw i32 %13307, 4087" -> "  %15071 = lshr i32 %15070, 16"
"  %15071 = lshr i32 %15070, 16"
"  %15071 = lshr i32 %15070, 16" -> "  %15074 = add nuw nsw i32 %15073, %15071"
"  %15072 = mul nuw nsw i32 %13310, 4087"
"  %15072 = mul nuw nsw i32 %13310, 4087" -> "  %15075 = and i32 %15072, 268369920""  %15072 = mul nuw nsw i32 %13310, 4087" -> "  %15073 = and i32 %15072, 65535"
"  %15073 = and i32 %15072, 65535"
"  %15073 = and i32 %15072, 65535" -> "  %15074 = add nuw nsw i32 %15073, %15071"
"  %15074 = add nuw nsw i32 %15073, %15071"
"  %15074 = add nuw nsw i32 %15073, %15071" -> "  %15076 = add nuw nsw i32 %15074, %15075"
"  %15075 = and i32 %15072, 268369920"
"  %15075 = and i32 %15072, 268369920" -> "  %15076 = add nuw nsw i32 %15074, %15075"
"  %15076 = add nuw nsw i32 %15074, %15075"
"  %15076 = add nuw nsw i32 %15074, %15075" -> "  %15080 = lshr i32 %15076, 16""  %15076 = add nuw nsw i32 %15074, %15075" -> "  %15078 = and i32 %15076, 65535"
"  %15077 = mul nuw nsw i32 %13307, 11561"
"  %15077 = mul nuw nsw i32 %13307, 11561" -> "  %15079 = add nuw nsw i32 %15078, %15077"
"  %15078 = and i32 %15076, 65535"
"  %15078 = and i32 %15076, 65535" -> "  %15079 = add nuw nsw i32 %15078, %15077"
"  %15079 = add nuw nsw i32 %15078, %15077"
"  %15079 = add nuw nsw i32 %15078, %15077" -> "  %15091 = and i32 %15079, 65535""  %15079 = add nuw nsw i32 %15078, %15077" -> "  %15083 = lshr i32 %15079, 16"
"  %15080 = lshr i32 %15076, 16"
"  %15080 = lshr i32 %15076, 16" -> "  %15082 = add nuw nsw i32 %15080, %15081"
"  %15081 = mul nuw nsw i32 %13310, 11561"
"  %15081 = mul nuw nsw i32 %13310, 11561" -> "  %15082 = add nuw nsw i32 %15080, %15081"
"  %15082 = add nuw nsw i32 %15080, %15081"
"  %15082 = add nuw nsw i32 %15080, %15081" -> "  %15086 = and i32 %15082, 2147418112""  %15082 = add nuw nsw i32 %15080, %15081" -> "  %15084 = and i32 %15082, 65535"
"  %15083 = lshr i32 %15079, 16"
"  %15083 = lshr i32 %15079, 16" -> "  %15085 = add nuw nsw i32 %15083, %15084"
"  %15084 = and i32 %15082, 65535"
"  %15084 = and i32 %15082, 65535" -> "  %15085 = add nuw nsw i32 %15083, %15084"
"  %15085 = add nuw nsw i32 %15083, %15084"
"  %15085 = add nuw nsw i32 %15083, %15084" -> "  %15087 = add nuw nsw i32 %15085, %15086"
"  %15086 = and i32 %15082, 2147418112"
"  %15086 = and i32 %15082, 2147418112" -> "  %15087 = add nuw nsw i32 %15085, %15086"
"  %15087 = add nuw nsw i32 %15085, %15086"
"  %15087 = add nuw nsw i32 %15085, %15086" -> "  %15095 = add nuw nsw i32 %15087, %15094"
"  %15088 = and i32 %15069, 65535"
"  %15088 = and i32 %15069, 65535" -> "  %15090 = add nuw nsw i32 %15088, %15089"
"  %15089 = and i32 %15070, 65535"
"  %15089 = and i32 %15070, 65535" -> "  %15090 = add nuw nsw i32 %15088, %15089"
"  %15090 = add nuw nsw i32 %15088, %15089"
"  %15090 = add nuw nsw i32 %15088, %15089" -> "  %15119 = and i32 %15090, 65535""  %15090 = add nuw nsw i32 %15088, %15089" -> "  %15097 = lshr i32 %15090, 16"
"  %15091 = and i32 %15079, 65535"
"  %15091 = and i32 %15079, 65535" -> "  %15093 = add nuw nsw i32 %15091, %15092"
"  %15092 = lshr i32 %15069, 16"
"  %15092 = lshr i32 %15069, 16" -> "  %15093 = add nuw nsw i32 %15091, %15092"
"  %15093 = add nuw nsw i32 %15091, %15092"
"  %15093 = add nuw nsw i32 %15091, %15092" -> "  %15096 = and i32 %15093, 65535""  %15093 = add nuw nsw i32 %15091, %15092" -> "  %15094 = lshr i32 %15093, 16"
"  %15094 = lshr i32 %15093, 16"
"  %15094 = lshr i32 %15093, 16" -> "  %15095 = add nuw nsw i32 %15087, %15094"
"  %15095 = add nuw nsw i32 %15087, %15094"
"  %15095 = add nuw nsw i32 %15087, %15094" -> "  %15100 = add nuw nsw i32 %15095, %15099"
"  %15096 = and i32 %15093, 65535"
"  %15096 = and i32 %15093, 65535" -> "  %15098 = add nuw nsw i32 %15096, %15097"
"  %15097 = lshr i32 %15090, 16"
"  %15097 = lshr i32 %15090, 16" -> "  %15098 = add nuw nsw i32 %15096, %15097"
"  %15098 = add nuw nsw i32 %15096, %15097"
"  %15098 = add nuw nsw i32 %15096, %15097" -> "  %15123 = and i32 %15098, 65535""  %15098 = add nuw nsw i32 %15096, %15097" -> "  %15099 = lshr i32 %15098, 16"
"  %15099 = lshr i32 %15098, 16"
"  %15099 = lshr i32 %15098, 16" -> "  %15100 = add nuw nsw i32 %15095, %15099"
"  %15100 = add nuw nsw i32 %15095, %15099"
"  %15100 = add nuw nsw i32 %15095, %15099" -> "  %15154 = lshr i32 %15100, 16""  %15100 = add nuw nsw i32 %15095, %15099" -> "  %15150 = and i32 %15100, 65535"
"  %15101 = mul nuw nsw i32 %13287, 21884"
"  %15101 = mul nuw nsw i32 %13287, 21884" -> "  %15120 = and i32 %15101, 65532""  %15101 = mul nuw nsw i32 %13287, 21884" -> "  %15102 = lshr i32 %15101, 16"
"  %15102 = lshr i32 %15101, 16"
"  %15102 = lshr i32 %15101, 16" -> "  %15105 = add nuw nsw i32 %15104, %15102"
"  %15103 = mul nuw nsw i32 %13290, 21884"
"  %15103 = mul nuw nsw i32 %13290, 21884" -> "  %15106 = and i32 %15103, 2147418112""  %15103 = mul nuw nsw i32 %13290, 21884" -> "  %15104 = and i32 %15103, 65532"
"  %15104 = and i32 %15103, 65532"
"  %15104 = and i32 %15103, 65532" -> "  %15105 = add nuw nsw i32 %15104, %15102"
"  %15105 = add nuw nsw i32 %15104, %15102"
"  %15105 = add nuw nsw i32 %15104, %15102" -> "  %15107 = add nuw nsw i32 %15105, %15106"
"  %15106 = and i32 %15103, 2147418112"
"  %15106 = and i32 %15103, 2147418112" -> "  %15107 = add nuw nsw i32 %15105, %15106"
"  %15107 = add nuw nsw i32 %15105, %15106"
"  %15107 = add nuw nsw i32 %15105, %15106" -> "  %15111 = lshr i32 %15107, 16""  %15107 = add nuw nsw i32 %15105, %15106" -> "  %15109 = and i32 %15107, 65535"
"  %15108 = mul nuw i32 %13287, 36786"
"  %15108 = mul nuw i32 %13287, 36786" -> "  %15110 = add nuw i32 %15109, %15108"
"  %15109 = and i32 %15107, 65535"
"  %15109 = and i32 %15107, 65535" -> "  %15110 = add nuw i32 %15109, %15108"
"  %15110 = add nuw i32 %15109, %15108"
"  %15110 = add nuw i32 %15109, %15108" -> "  %15122 = and i32 %15110, 65535""  %15110 = add nuw i32 %15109, %15108" -> "  %15114 = lshr i32 %15110, 16"
"  %15111 = lshr i32 %15107, 16"
"  %15111 = lshr i32 %15107, 16" -> "  %15113 = add nuw i32 %15111, %15112"
"  %15112 = mul nuw i32 %13290, 36786"
"  %15112 = mul nuw i32 %13290, 36786" -> "  %15113 = add nuw i32 %15111, %15112"
"  %15113 = add nuw i32 %15111, %15112"
"  %15113 = add nuw i32 %15111, %15112" -> "  %15117 = and i32 %15113, -65536""  %15113 = add nuw i32 %15111, %15112" -> "  %15115 = and i32 %15113, 65535"
"  %15114 = lshr i32 %15110, 16"
"  %15114 = lshr i32 %15110, 16" -> "  %15116 = add nuw nsw i32 %15114, %15115"
"  %15115 = and i32 %15113, 65535"
"  %15115 = and i32 %15113, 65535" -> "  %15116 = add nuw nsw i32 %15114, %15115"
"  %15116 = add nuw nsw i32 %15114, %15115"
"  %15116 = add nuw nsw i32 %15114, %15115" -> "  %15118 = add nuw i32 %15116, %15117"
"  %15117 = and i32 %15113, -65536"
"  %15117 = and i32 %15113, -65536" -> "  %15118 = add nuw i32 %15116, %15117"
"  %15118 = add nuw i32 %15116, %15117"
"  %15118 = add nuw i32 %15116, %15117" -> "  %15126 = add nuw i32 %15118, %15125"
"  %15119 = and i32 %15090, 65535"
"  %15119 = and i32 %15090, 65535" -> "  %15121 = add nuw nsw i32 %15119, %15120"
"  %15120 = and i32 %15101, 65532"
"  %15120 = and i32 %15101, 65532" -> "  %15121 = add nuw nsw i32 %15119, %15120"
"  %15121 = add nuw nsw i32 %15119, %15120"
"  %15121 = add nuw nsw i32 %15119, %15120" -> "  %15188 = and i32 %15121, 65535""  %15121 = add nuw nsw i32 %15119, %15120" -> "  %15128 = lshr i32 %15121, 16"
"  %15122 = and i32 %15110, 65535"
"  %15122 = and i32 %15110, 65535" -> "  %15124 = add nuw nsw i32 %15123, %15122"
"  %15123 = and i32 %15098, 65535"
"  %15123 = and i32 %15098, 65535" -> "  %15124 = add nuw nsw i32 %15123, %15122"
"  %15124 = add nuw nsw i32 %15123, %15122"
"  %15124 = add nuw nsw i32 %15123, %15122" -> "  %15127 = and i32 %15124, 65535""  %15124 = add nuw nsw i32 %15123, %15122" -> "  %15125 = lshr i32 %15124, 16"
"  %15125 = lshr i32 %15124, 16"
"  %15125 = lshr i32 %15124, 16" -> "  %15126 = add nuw i32 %15118, %15125"
"  %15126 = add nuw i32 %15118, %15125"
"  %15126 = add nuw i32 %15118, %15125" -> "  %15131 = add nuw i32 %15126, %15130"
"  %15127 = and i32 %15124, 65535"
"  %15127 = and i32 %15124, 65535" -> "  %15129 = add nuw nsw i32 %15127, %15128"
"  %15128 = lshr i32 %15121, 16"
"  %15128 = lshr i32 %15121, 16" -> "  %15129 = add nuw nsw i32 %15127, %15128"
"  %15129 = add nuw nsw i32 %15127, %15128"
"  %15129 = add nuw nsw i32 %15127, %15128" -> "  %15191 = and i32 %15129, 65535""  %15129 = add nuw nsw i32 %15127, %15128" -> "  %15130 = lshr i32 %15129, 16"
"  %15130 = lshr i32 %15129, 16"
"  %15130 = lshr i32 %15129, 16" -> "  %15131 = add nuw i32 %15126, %15130"
"  %15131 = add nuw i32 %15126, %15130"
"  %15131 = add nuw i32 %15126, %15130" -> "  %15167 = lshr i32 %15131, 16""  %15131 = add nuw i32 %15126, %15130" -> "  %15164 = and i32 %15131, 65535"
"  %15132 = mul nuw nsw i32 %13307, 21884"
"  %15132 = mul nuw nsw i32 %13307, 21884" -> "  %15151 = and i32 %15132, 65532""  %15132 = mul nuw nsw i32 %13307, 21884" -> "  %15133 = lshr i32 %15132, 16"
"  %15133 = lshr i32 %15132, 16"
"  %15133 = lshr i32 %15132, 16" -> "  %15136 = add nuw nsw i32 %15135, %15133"
"  %15134 = mul nuw nsw i32 %13310, 21884"
"  %15134 = mul nuw nsw i32 %13310, 21884" -> "  %15137 = and i32 %15134, 2147418112""  %15134 = mul nuw nsw i32 %13310, 21884" -> "  %15135 = and i32 %15134, 65532"
"  %15135 = and i32 %15134, 65532"
"  %15135 = and i32 %15134, 65532" -> "  %15136 = add nuw nsw i32 %15135, %15133"
"  %15136 = add nuw nsw i32 %15135, %15133"
"  %15136 = add nuw nsw i32 %15135, %15133" -> "  %15138 = add nuw nsw i32 %15136, %15137"
"  %15137 = and i32 %15134, 2147418112"
"  %15137 = and i32 %15134, 2147418112" -> "  %15138 = add nuw nsw i32 %15136, %15137"
"  %15138 = add nuw nsw i32 %15136, %15137"
"  %15138 = add nuw nsw i32 %15136, %15137" -> "  %15142 = lshr i32 %15138, 16""  %15138 = add nuw nsw i32 %15136, %15137" -> "  %15140 = and i32 %15138, 65535"
"  %15139 = mul nuw i32 %13307, 36786"
"  %15139 = mul nuw i32 %13307, 36786" -> "  %15141 = add nuw i32 %15140, %15139"
"  %15140 = and i32 %15138, 65535"
"  %15140 = and i32 %15138, 65535" -> "  %15141 = add nuw i32 %15140, %15139"
"  %15141 = add nuw i32 %15140, %15139"
"  %15141 = add nuw i32 %15140, %15139" -> "  %15153 = and i32 %15141, 65535""  %15141 = add nuw i32 %15140, %15139" -> "  %15145 = lshr i32 %15141, 16"
"  %15142 = lshr i32 %15138, 16"
"  %15142 = lshr i32 %15138, 16" -> "  %15144 = add nuw i32 %15142, %15143"
"  %15143 = mul nuw i32 %13310, 36786"
"  %15143 = mul nuw i32 %13310, 36786" -> "  %15144 = add nuw i32 %15142, %15143"
"  %15144 = add nuw i32 %15142, %15143"
"  %15144 = add nuw i32 %15142, %15143" -> "  %15148 = and i32 %15144, -65536""  %15144 = add nuw i32 %15142, %15143" -> "  %15146 = and i32 %15144, 65535"
"  %15145 = lshr i32 %15141, 16"
"  %15145 = lshr i32 %15141, 16" -> "  %15147 = add nuw nsw i32 %15145, %15146"
"  %15146 = and i32 %15144, 65535"
"  %15146 = and i32 %15144, 65535" -> "  %15147 = add nuw nsw i32 %15145, %15146"
"  %15147 = add nuw nsw i32 %15145, %15146"
"  %15147 = add nuw nsw i32 %15145, %15146" -> "  %15149 = add nuw i32 %15147, %15148"
"  %15148 = and i32 %15144, -65536"
"  %15148 = and i32 %15144, -65536" -> "  %15149 = add nuw i32 %15147, %15148"
"  %15149 = add nuw i32 %15147, %15148"
"  %15149 = add nuw i32 %15147, %15148" -> "  %15157 = add nuw i32 %15149, %15156"
"  %15150 = and i32 %15100, 65535"
"  %15150 = and i32 %15100, 65535" -> "  %15152 = add nuw nsw i32 %15150, %15151"
"  %15151 = and i32 %15132, 65532"
"  %15151 = and i32 %15132, 65532" -> "  %15152 = add nuw nsw i32 %15150, %15151"
"  %15152 = add nuw nsw i32 %15150, %15151"
"  %15152 = add nuw nsw i32 %15150, %15151" -> "  %15163 = and i32 %15152, 65535""  %15152 = add nuw nsw i32 %15150, %15151" -> "  %15159 = lshr i32 %15152, 16"
"  %15153 = and i32 %15141, 65535"
"  %15153 = and i32 %15141, 65535" -> "  %15155 = add nuw nsw i32 %15154, %15153"
"  %15154 = lshr i32 %15100, 16"
"  %15154 = lshr i32 %15100, 16" -> "  %15155 = add nuw nsw i32 %15154, %15153"
"  %15155 = add nuw nsw i32 %15154, %15153"
"  %15155 = add nuw nsw i32 %15154, %15153" -> "  %15158 = and i32 %15155, 65535""  %15155 = add nuw nsw i32 %15154, %15153" -> "  %15156 = lshr i32 %15155, 16"
"  %15156 = lshr i32 %15155, 16"
"  %15156 = lshr i32 %15155, 16" -> "  %15157 = add nuw i32 %15149, %15156"
"  %15157 = add nuw i32 %15149, %15156"
"  %15157 = add nuw i32 %15149, %15156" -> "  %15162 = add nuw i32 %15157, %15161"
"  %15158 = and i32 %15155, 65535"
"  %15158 = and i32 %15155, 65535" -> "  %15160 = add nuw nsw i32 %15158, %15159"
"  %15159 = lshr i32 %15152, 16"
"  %15159 = lshr i32 %15152, 16" -> "  %15160 = add nuw nsw i32 %15158, %15159"
"  %15160 = add nuw nsw i32 %15158, %15159"
"  %15160 = add nuw nsw i32 %15158, %15159" -> "  %15166 = and i32 %15160, 65535""  %15160 = add nuw nsw i32 %15158, %15159" -> "  %15161 = lshr i32 %15160, 16"
"  %15161 = lshr i32 %15160, 16"
"  %15161 = lshr i32 %15160, 16" -> "  %15162 = add nuw i32 %15157, %15161"
"  %15162 = add nuw i32 %15157, %15161"
"  %15162 = add nuw i32 %15157, %15161" -> "  %15175 = and i32 %15162, -65536""  %15162 = add nuw i32 %15157, %15161" -> "  %15173 = and i32 %15162, 65535"
"  %15163 = and i32 %15152, 65535"
"  %15163 = and i32 %15152, 65535" -> "  %15165 = add nuw nsw i32 %15164, %15163"
"  %15164 = and i32 %15131, 65535"
"  %15164 = and i32 %15131, 65535" -> "  %15165 = add nuw nsw i32 %15164, %15163"
"  %15165 = add nuw nsw i32 %15164, %15163"
"  %15165 = add nuw nsw i32 %15164, %15163" -> "  %15205 = and i32 %15165, 65535""  %15165 = add nuw nsw i32 %15164, %15163" -> "  %15169 = lshr i32 %15165, 16"
"  %15166 = and i32 %15160, 65535"
"  %15166 = and i32 %15160, 65535" -> "  %15168 = add nuw nsw i32 %15166, %15167"
"  %15167 = lshr i32 %15131, 16"
"  %15167 = lshr i32 %15131, 16" -> "  %15168 = add nuw nsw i32 %15166, %15167"
"  %15168 = add nuw nsw i32 %15166, %15167"
"  %15168 = add nuw nsw i32 %15166, %15167" -> "  %15172 = lshr i32 %15168, 16""  %15168 = add nuw nsw i32 %15166, %15167" -> "  %15170 = and i32 %15168, 65535"
"  %15169 = lshr i32 %15165, 16"
"  %15169 = lshr i32 %15165, 16" -> "  %15171 = add nuw nsw i32 %15170, %15169"
"  %15170 = and i32 %15168, 65535"
"  %15170 = and i32 %15168, 65535" -> "  %15171 = add nuw nsw i32 %15170, %15169"
"  %15171 = add nuw nsw i32 %15170, %15169"
"  %15171 = add nuw nsw i32 %15170, %15169" -> "  %15212 = and i32 %15171, 65535""  %15171 = add nuw nsw i32 %15170, %15169" -> "  %15177 = lshr i32 %15171, 16"
"  %15172 = lshr i32 %15168, 16"
"  %15172 = lshr i32 %15168, 16" -> "  %15174 = add nuw nsw i32 %15172, %15173"
"  %15173 = and i32 %15162, 65535"
"  %15173 = and i32 %15162, 65535" -> "  %15174 = add nuw nsw i32 %15172, %15173"
"  %15174 = add nuw nsw i32 %15172, %15173"
"  %15174 = add nuw nsw i32 %15172, %15173" -> "  %15176 = add nuw i32 %15174, %15175"
"  %15175 = and i32 %15162, -65536"
"  %15175 = and i32 %15162, -65536" -> "  %15176 = add nuw i32 %15174, %15175"
"  %15176 = add nuw i32 %15174, %15175"
"  %15176 = add nuw i32 %15174, %15175" -> "  %15178 = add nuw i32 %15176, %15177"
"  %15177 = lshr i32 %15171, 16"
"  %15177 = lshr i32 %15171, 16" -> "  %15178 = add nuw i32 %15176, %15177"
"  %15178 = add nuw i32 %15176, %15177"
"  %15178 = add nuw i32 %15176, %15177" -> "  %15216 = add nuw i32 %15178, %15215"
"  %15179 = and i32 %15052, 65535"
"  %15179 = and i32 %15052, 65535" -> "  %15181 = add nuw nsw i32 %15180, %15179"
"  %15180 = and i32 %14881, 65535"
"  %15180 = and i32 %14881, 65535" -> "  %15181 = add nuw nsw i32 %15180, %15179"
"  %15181 = add nuw nsw i32 %15180, %15179"
"  %15181 = add nuw nsw i32 %15180, %15179" -> "  %15217 = and i32 %15181, 65535""  %15181 = add nuw nsw i32 %15180, %15179" -> "  %15185 = lshr i32 %15181, 16"
"  %15182 = and i32 %15061, 65535"
"  %15182 = and i32 %15061, 65535" -> "  %15184 = add nuw nsw i32 %15183, %15182"
"  %15183 = and i32 %14884, 65535"
"  %15183 = and i32 %14884, 65535" -> "  %15184 = add nuw nsw i32 %15183, %15182"
"  %15184 = add nuw nsw i32 %15183, %15182"
"  %15184 = add nuw nsw i32 %15183, %15182" -> "  %15198 = lshr i32 %15184, 16""  %15184 = add nuw nsw i32 %15183, %15182" -> "  %15186 = and i32 %15184, 65535"
"  %15185 = lshr i32 %15181, 16"
"  %15185 = lshr i32 %15181, 16" -> "  %15187 = add nuw nsw i32 %15186, %15185"
"  %15186 = and i32 %15184, 65535"
"  %15186 = and i32 %15184, 65535" -> "  %15187 = add nuw nsw i32 %15186, %15185"
"  %15187 = add nuw nsw i32 %15186, %15185"
"  %15187 = add nuw nsw i32 %15186, %15185" -> "  %15220 = and i32 %15187, 65535""  %15187 = add nuw nsw i32 %15186, %15185" -> "  %15200 = lshr i32 %15187, 16"
"  %15188 = and i32 %15121, 65535"
"  %15188 = and i32 %15121, 65535" -> "  %15190 = add nuw nsw i32 %15189, %15188"
"  %15189 = and i32 %14886, 65535"
"  %15189 = and i32 %14886, 65535" -> "  %15190 = add nuw nsw i32 %15189, %15188"
"  %15190 = add nuw nsw i32 %15189, %15188"
"  %15190 = add nuw nsw i32 %15189, %15188" -> "  %15197 = and i32 %15190, 65535""  %15190 = add nuw nsw i32 %15189, %15188" -> "  %15194 = lshr i32 %15190, 16"
"  %15191 = and i32 %15129, 65535"
"  %15191 = and i32 %15129, 65535" -> "  %15193 = add nuw nsw i32 %15192, %15191"
"  %15192 = lshr i32 %14886, 16"
"  %15192 = lshr i32 %14886, 16" -> "  %15193 = add nuw nsw i32 %15192, %15191"
"  %15193 = add nuw nsw i32 %15192, %15191"
"  %15193 = add nuw nsw i32 %15192, %15191" -> "  %15206 = lshr i32 %15193, 16""  %15193 = add nuw nsw i32 %15192, %15191" -> "  %15195 = and i32 %15193, 65535"
"  %15194 = lshr i32 %15190, 16"
"  %15194 = lshr i32 %15190, 16" -> "  %15196 = add nuw nsw i32 %15194, %15195"
"  %15195 = and i32 %15193, 65535"
"  %15195 = and i32 %15193, 65535" -> "  %15196 = add nuw nsw i32 %15194, %15195"
"  %15196 = add nuw nsw i32 %15194, %15195"
"  %15196 = add nuw nsw i32 %15194, %15195" -> "  %15208 = lshr i32 %15196, 16""  %15196 = add nuw nsw i32 %15194, %15195" -> "  %15203 = and i32 %15196, 65535"
"  %15197 = and i32 %15190, 65535"
"  %15197 = and i32 %15190, 65535" -> "  %15199 = add nuw nsw i32 %15197, %15198"
"  %15198 = lshr i32 %15184, 16"
"  %15198 = lshr i32 %15184, 16" -> "  %15199 = add nuw nsw i32 %15197, %15198"
"  %15199 = add nuw nsw i32 %15197, %15198"
"  %15199 = add nuw nsw i32 %15197, %15198" -> "  %15201 = add nuw nsw i32 %15199, %15200"
"  %15200 = lshr i32 %15187, 16"
"  %15200 = lshr i32 %15187, 16" -> "  %15201 = add nuw nsw i32 %15199, %15200"
"  %15201 = add nuw nsw i32 %15199, %15200"
"  %15201 = add nuw nsw i32 %15199, %15200" -> "  %15226 = and i32 %15201, 65535""  %15201 = add nuw nsw i32 %15199, %15200" -> "  %15202 = lshr i32 %15201, 16"
"  %15202 = lshr i32 %15201, 16"
"  %15202 = lshr i32 %15201, 16" -> "  %15204 = add nuw nsw i32 %15202, %15203"
"  %15203 = and i32 %15196, 65535"
"  %15203 = and i32 %15196, 65535" -> "  %15204 = add nuw nsw i32 %15202, %15203"
"  %15204 = add nuw nsw i32 %15202, %15203"
"  %15204 = add nuw nsw i32 %15202, %15203" -> "  %15229 = and i32 %15204, 65535""  %15204 = add nuw nsw i32 %15202, %15203" -> "  %15210 = lshr i32 %15204, 16"
"  %15205 = and i32 %15165, 65535"
"  %15205 = and i32 %15165, 65535" -> "  %15207 = add nuw nsw i32 %15206, %15205"
"  %15206 = lshr i32 %15193, 16"
"  %15206 = lshr i32 %15193, 16" -> "  %15207 = add nuw nsw i32 %15206, %15205"
"  %15207 = add nuw nsw i32 %15206, %15205"
"  %15207 = add nuw nsw i32 %15206, %15205" -> "  %15209 = add nuw nsw i32 %15207, %15208"
"  %15208 = lshr i32 %15196, 16"
"  %15208 = lshr i32 %15196, 16" -> "  %15209 = add nuw nsw i32 %15207, %15208"
"  %15209 = add nuw nsw i32 %15207, %15208"
"  %15209 = add nuw nsw i32 %15207, %15208" -> "  %15211 = add nuw nsw i32 %15209, %15210"
"  %15210 = lshr i32 %15204, 16"
"  %15210 = lshr i32 %15204, 16" -> "  %15211 = add nuw nsw i32 %15209, %15210"
"  %15211 = add nuw nsw i32 %15209, %15210"
"  %15211 = add nuw nsw i32 %15209, %15210" -> "  %15243 = and i32 %15211, 65535""  %15211 = add nuw nsw i32 %15209, %15210" -> "  %15213 = lshr i32 %15211, 16"
"  %15212 = and i32 %15171, 65535"
"  %15212 = and i32 %15171, 65535" -> "  %15214 = add nuw nsw i32 %15213, %15212"
"  %15213 = lshr i32 %15211, 16"
"  %15213 = lshr i32 %15211, 16" -> "  %15214 = add nuw nsw i32 %15213, %15212"
"  %15214 = add nuw nsw i32 %15213, %15212"
"  %15214 = add nuw nsw i32 %15213, %15212" -> "  %15250 = and i32 %15214, 65535""  %15214 = add nuw nsw i32 %15213, %15212" -> "  %15215 = lshr i32 %15214, 16"
"  %15215 = lshr i32 %15214, 16"
"  %15215 = lshr i32 %15214, 16" -> "  %15216 = add nuw i32 %15178, %15215"
"  %15216 = add nuw i32 %15178, %15215"
"  %15216 = add nuw i32 %15178, %15215" -> "  %15254 = add nuw i32 %15216, %15253"
"  %15217 = and i32 %15181, 65535"
"  %15217 = and i32 %15181, 65535" -> "  %15219 = add nuw nsw i32 %15218, %15217"
"  %15218 = and i32 %15046, 65535"
"  %15218 = and i32 %15046, 65535" -> "  %15219 = add nuw nsw i32 %15218, %15217"
"  %15219 = add nuw nsw i32 %15218, %15217"
"  %15219 = add nuw nsw i32 %15218, %15217" -> "  %15327 = and i32 %15219, 65535""  %15219 = add nuw nsw i32 %15218, %15217" -> "  %15223 = lshr i32 %15219, 16"
"  %15220 = and i32 %15187, 65535"
"  %15220 = and i32 %15187, 65535" -> "  %15222 = add nuw nsw i32 %15221, %15220"
"  %15221 = and i32 %15049, 65535"
"  %15221 = and i32 %15049, 65535" -> "  %15222 = add nuw nsw i32 %15221, %15220"
"  %15222 = add nuw nsw i32 %15221, %15220"
"  %15222 = add nuw nsw i32 %15221, %15220" -> "  %15236 = lshr i32 %15222, 16""  %15222 = add nuw nsw i32 %15221, %15220" -> "  %15224 = and i32 %15222, 65535"
"  %15223 = lshr i32 %15219, 16"
"  %15223 = lshr i32 %15219, 16" -> "  %15225 = add nuw nsw i32 %15224, %15223"
"  %15224 = and i32 %15222, 65535"
"  %15224 = and i32 %15222, 65535" -> "  %15225 = add nuw nsw i32 %15224, %15223"
"  %15225 = add nuw nsw i32 %15224, %15223"
"  %15225 = add nuw nsw i32 %15224, %15223" -> "  %15332 = and i32 %15225, 65535""  %15225 = add nuw nsw i32 %15224, %15223" -> "  %15237 = lshr i32 %15225, 16"
"  %15226 = and i32 %15201, 65535"
"  %15226 = and i32 %15201, 65535" -> "  %15228 = add nuw nsw i32 %15227, %15226"
"  %15227 = and i32 %15051, 65535"
"  %15227 = and i32 %15051, 65535" -> "  %15228 = add nuw nsw i32 %15227, %15226"
"  %15228 = add nuw nsw i32 %15227, %15226"
"  %15228 = add nuw nsw i32 %15227, %15226" -> "  %15235 = and i32 %15228, 65535""  %15228 = add nuw nsw i32 %15227, %15226" -> "  %15232 = lshr i32 %15228, 16"
"  %15229 = and i32 %15204, 65535"
"  %15229 = and i32 %15204, 65535" -> "  %15231 = add nuw nsw i32 %15229, %15230"
"  %15230 = lshr i32 %15051, 16"
"  %15230 = lshr i32 %15051, 16" -> "  %15231 = add nuw nsw i32 %15229, %15230"
"  %15231 = add nuw nsw i32 %15229, %15230"
"  %15231 = add nuw nsw i32 %15229, %15230" -> "  %15244 = lshr i32 %15231, 16""  %15231 = add nuw nsw i32 %15229, %15230" -> "  %15233 = and i32 %15231, 65535"
"  %15232 = lshr i32 %15228, 16"
"  %15232 = lshr i32 %15228, 16" -> "  %15234 = add nuw nsw i32 %15233, %15232"
"  %15233 = and i32 %15231, 65535"
"  %15233 = and i32 %15231, 65535" -> "  %15234 = add nuw nsw i32 %15233, %15232"
"  %15234 = add nuw nsw i32 %15233, %15232"
"  %15234 = add nuw nsw i32 %15233, %15232" -> "  %15246 = lshr i32 %15234, 16""  %15234 = add nuw nsw i32 %15233, %15232" -> "  %15241 = and i32 %15234, 65535"
"  %15235 = and i32 %15228, 65535"
"  %15235 = and i32 %15228, 65535" -> "  %15239 = add nuw nsw i32 %15238, %15235"
"  %15236 = lshr i32 %15222, 16"
"  %15236 = lshr i32 %15222, 16" -> "  %15238 = add nuw nsw i32 %15237, %15236"
"  %15237 = lshr i32 %15225, 16"
"  %15237 = lshr i32 %15225, 16" -> "  %15238 = add nuw nsw i32 %15237, %15236"
"  %15238 = add nuw nsw i32 %15237, %15236"
"  %15238 = add nuw nsw i32 %15237, %15236" -> "  %15239 = add nuw nsw i32 %15238, %15235"
"  %15239 = add nuw nsw i32 %15238, %15235"
"  %15239 = add nuw nsw i32 %15238, %15235" -> "  %15335 = and i32 %15239, 65535""  %15239 = add nuw nsw i32 %15238, %15235" -> "  %15240 = lshr i32 %15239, 16"
"  %15240 = lshr i32 %15239, 16"
"  %15240 = lshr i32 %15239, 16" -> "  %15242 = add nuw nsw i32 %15241, %15240"
"  %15241 = and i32 %15234, 65535"
"  %15241 = and i32 %15234, 65535" -> "  %15242 = add nuw nsw i32 %15241, %15240"
"  %15242 = add nuw nsw i32 %15241, %15240"
"  %15242 = add nuw nsw i32 %15241, %15240" -> "  %15339 = and i32 %15242, 65535""  %15242 = add nuw nsw i32 %15241, %15240" -> "  %15248 = lshr i32 %15242, 16"
"  %15243 = and i32 %15211, 65535"
"  %15243 = and i32 %15211, 65535" -> "  %15245 = add nuw nsw i32 %15244, %15243"
"  %15244 = lshr i32 %15231, 16"
"  %15244 = lshr i32 %15231, 16" -> "  %15245 = add nuw nsw i32 %15244, %15243"
"  %15245 = add nuw nsw i32 %15244, %15243"
"  %15245 = add nuw nsw i32 %15244, %15243" -> "  %15247 = add nuw nsw i32 %15245, %15246"
"  %15246 = lshr i32 %15234, 16"
"  %15246 = lshr i32 %15234, 16" -> "  %15247 = add nuw nsw i32 %15245, %15246"
"  %15247 = add nuw nsw i32 %15245, %15246"
"  %15247 = add nuw nsw i32 %15245, %15246" -> "  %15249 = add nuw nsw i32 %15247, %15248"
"  %15248 = lshr i32 %15242, 16"
"  %15248 = lshr i32 %15242, 16" -> "  %15249 = add nuw nsw i32 %15247, %15248"
"  %15249 = add nuw nsw i32 %15247, %15248"
"  %15249 = add nuw nsw i32 %15247, %15248" -> "  %15342 = and i32 %15249, 65535""  %15249 = add nuw nsw i32 %15247, %15248" -> "  %15251 = lshr i32 %15249, 16"
"  %15250 = and i32 %15214, 65535"
"  %15250 = and i32 %15214, 65535" -> "  %15252 = add nuw nsw i32 %15251, %15250"
"  %15251 = lshr i32 %15249, 16"
"  %15251 = lshr i32 %15249, 16" -> "  %15252 = add nuw nsw i32 %15251, %15250"
"  %15252 = add nuw nsw i32 %15251, %15250"
"  %15252 = add nuw nsw i32 %15251, %15250" -> "  %15345 = and i32 %15252, 65535""  %15252 = add nuw nsw i32 %15251, %15250" -> "  %15253 = lshr i32 %15252, 16"
"  %15253 = lshr i32 %15252, 16"
"  %15253 = lshr i32 %15252, 16" -> "  %15254 = add nuw i32 %15216, %15253"
"  %15254 = add nuw i32 %15216, %15253"
"  %15254 = add nuw i32 %15216, %15253" -> "  %15348 = add nuw i32 %15254, %15347"
"  %15255 = and i32 %14503, 65535"
"  %15255 = and i32 %14503, 65535" -> "  %15257 = add nuw nsw i32 %15255, %15256"
"  %15256 = and i32 %14595, 65535"
"  %15256 = and i32 %14595, 65535" -> "  %15257 = add nuw nsw i32 %15255, %15256"
"  %15257 = add nuw nsw i32 %15255, %15256"
"  %15257 = add nuw nsw i32 %15255, %15256" -> "  %15261 = lshr i32 %15257, 16"
"  %15258 = and i32 %14509, 65535"
"  %15258 = and i32 %14509, 65535" -> "  %15260 = add nuw nsw i32 %15258, %15259"
"  %15259 = and i32 %14604, 65535"
"  %15259 = and i32 %14604, 65535" -> "  %15260 = add nuw nsw i32 %15258, %15259"
"  %15260 = add nuw nsw i32 %15258, %15259"
"  %15260 = add nuw nsw i32 %15258, %15259" -> "  %15264 = lshr i32 %15260, 16""  %15260 = add nuw nsw i32 %15258, %15259" -> "  %15262 = and i32 %15260, 65535"
"  %15261 = lshr i32 %15257, 16"
"  %15261 = lshr i32 %15257, 16" -> "  %15263 = add nuw nsw i32 %15262, %15261"
"  %15262 = and i32 %15260, 65535"
"  %15262 = and i32 %15260, 65535" -> "  %15263 = add nuw nsw i32 %15262, %15261"
"  %15263 = add nuw nsw i32 %15262, %15261"
"  %15263 = add nuw nsw i32 %15262, %15261" -> "  %15265 = lshr i32 %15263, 16"
"  %15264 = lshr i32 %15260, 16"
"  %15264 = lshr i32 %15260, 16" -> "  %15266 = add nuw nsw i32 %15265, %15264"
"  %15265 = lshr i32 %15263, 16"
"  %15265 = lshr i32 %15263, 16" -> "  %15266 = add nuw nsw i32 %15265, %15264"
"  %15266 = add nuw nsw i32 %15265, %15264"
"  %15266 = add nuw nsw i32 %15265, %15264" -> "  %15277 = add nuw nsw i32 %15266, %15276"
"  %15267 = and i32 %14523, 65535"
"  %15267 = and i32 %14523, 65535" -> "  %15269 = add nuw nsw i32 %15267, %15268"
"  %15268 = and i32 %14664, 65535"
"  %15268 = and i32 %14664, 65535" -> "  %15269 = add nuw nsw i32 %15267, %15268"
"  %15269 = add nuw nsw i32 %15267, %15268"
"  %15269 = add nuw nsw i32 %15267, %15268" -> "  %15276 = and i32 %15269, 65535""  %15269 = add nuw nsw i32 %15267, %15268" -> "  %15273 = lshr i32 %15269, 16"
"  %15270 = and i32 %14526, 65535"
"  %15270 = and i32 %14526, 65535" -> "  %15272 = add nuw nsw i32 %15270, %15271"
"  %15271 = and i32 %14672, 65535"
"  %15271 = and i32 %14672, 65535" -> "  %15272 = add nuw nsw i32 %15270, %15271"
"  %15272 = add nuw nsw i32 %15270, %15271"
"  %15272 = add nuw nsw i32 %15270, %15271" -> "  %15311 = lshr i32 %15272, 16""  %15272 = add nuw nsw i32 %15270, %15271" -> "  %15274 = and i32 %15272, 65535"
"  %15273 = lshr i32 %15269, 16"
"  %15273 = lshr i32 %15269, 16" -> "  %15275 = add nuw nsw i32 %15274, %15273"
"  %15274 = and i32 %15272, 65535"
"  %15274 = and i32 %15272, 65535" -> "  %15275 = add nuw nsw i32 %15274, %15273"
"  %15275 = add nuw nsw i32 %15274, %15273"
"  %15275 = add nuw nsw i32 %15274, %15273" -> "  %15313 = lshr i32 %15275, 16""  %15275 = add nuw nsw i32 %15274, %15273" -> "  %15279 = and i32 %15275, 65535"
"  %15276 = and i32 %15269, 65535"
"  %15276 = and i32 %15269, 65535" -> "  %15277 = add nuw nsw i32 %15266, %15276"
"  %15277 = add nuw nsw i32 %15266, %15276"
"  %15277 = add nuw nsw i32 %15266, %15276" -> "  %15278 = lshr i32 %15277, 16"
"  %15278 = lshr i32 %15277, 16"
"  %15278 = lshr i32 %15277, 16" -> "  %15280 = add nuw nsw i32 %15279, %15278"
"  %15279 = and i32 %15275, 65535"
"  %15279 = and i32 %15275, 65535" -> "  %15280 = add nuw nsw i32 %15279, %15278"
"  %15280 = add nuw nsw i32 %15279, %15278"
"  %15280 = add nuw nsw i32 %15279, %15278" -> "  %15315 = lshr i32 %15280, 16"
"  %15281 = and i32 %14563, 65535"
"  %15281 = and i32 %14563, 65535" -> "  %15283 = add nuw nsw i32 %15281, %15282"
"  %15282 = and i32 %15016, 65535"
"  %15282 = and i32 %15016, 65535" -> "  %15283 = add nuw nsw i32 %15281, %15282"
"  %15283 = add nuw nsw i32 %15281, %15282"
"  %15283 = add nuw nsw i32 %15281, %15282" -> "  %15310 = and i32 %15283, 65535""  %15283 = add nuw nsw i32 %15281, %15282" -> "  %15287 = lshr i32 %15283, 16"
"  %15284 = and i32 %14566, 65535"
"  %15284 = and i32 %14566, 65535" -> "  %15286 = add nuw nsw i32 %15284, %15285"
"  %15285 = and i32 %15022, 65535"
"  %15285 = and i32 %15022, 65535" -> "  %15286 = add nuw nsw i32 %15284, %15285"
"  %15286 = add nuw nsw i32 %15284, %15285"
"  %15286 = add nuw nsw i32 %15284, %15285" -> "  %15290 = lshr i32 %15286, 16""  %15286 = add nuw nsw i32 %15284, %15285" -> "  %15288 = and i32 %15286, 65535"
"  %15287 = lshr i32 %15283, 16"
"  %15287 = lshr i32 %15283, 16" -> "  %15289 = add nuw nsw i32 %15288, %15287"
"  %15288 = and i32 %15286, 65535"
"  %15288 = and i32 %15286, 65535" -> "  %15289 = add nuw nsw i32 %15288, %15287"
"  %15289 = add nuw nsw i32 %15288, %15287"
"  %15289 = add nuw nsw i32 %15288, %15287" -> "  %15317 = and i32 %15289, 65535""  %15289 = add nuw nsw i32 %15288, %15287" -> "  %15291 = lshr i32 %15289, 16"
"  %15290 = lshr i32 %15286, 16"
"  %15290 = lshr i32 %15286, 16" -> "  %15292 = add nuw nsw i32 %15291, %15290"
"  %15291 = lshr i32 %15289, 16"
"  %15291 = lshr i32 %15289, 16" -> "  %15292 = add nuw nsw i32 %15291, %15290"
"  %15292 = add nuw nsw i32 %15291, %15290"
"  %15292 = add nuw nsw i32 %15291, %15290" -> "  %15305 = add nuw nsw i32 %15292, %15304"
"  %15293 = and i32 %14569, 65535"
"  %15293 = and i32 %14569, 65535" -> "  %15295 = add nuw nsw i32 %15293, %15294"
"  %15294 = and i32 %15036, 65535"
"  %15294 = and i32 %15036, 65535" -> "  %15295 = add nuw nsw i32 %15293, %15294"
"  %15295 = add nuw nsw i32 %15293, %15294"
"  %15295 = add nuw nsw i32 %15293, %15294" -> "  %15304 = and i32 %15295, 65535""  %15295 = add nuw nsw i32 %15293, %15294" -> "  %15299 = lshr i32 %15295, 16"
"  %15296 = and i32 %14572, 65535"
"  %15296 = and i32 %14572, 65535" -> "  %15298 = add nuw nsw i32 %15296, %15297"
"  %15297 = and i32 %15039, 65535"
"  %15297 = and i32 %15039, 65535" -> "  %15298 = add nuw nsw i32 %15296, %15297"
"  %15298 = add nuw nsw i32 %15296, %15297"
"  %15298 = add nuw nsw i32 %15296, %15297" -> "  %15302 = lshr i32 %15298, 16""  %15298 = add nuw nsw i32 %15296, %15297" -> "  %15300 = and i32 %15298, 65535"
"  %15299 = lshr i32 %15295, 16"
"  %15299 = lshr i32 %15295, 16" -> "  %15301 = add nuw nsw i32 %15300, %15299"
"  %15300 = and i32 %15298, 65535"
"  %15300 = and i32 %15298, 65535" -> "  %15301 = add nuw nsw i32 %15300, %15299"
"  %15301 = add nuw nsw i32 %15300, %15299"
"  %15301 = add nuw nsw i32 %15300, %15299" -> "  %15306 = and i32 %15301, 65535""  %15301 = add nuw nsw i32 %15300, %15299" -> "  %15303 = lshr i32 %15301, 16"
"  %15302 = lshr i32 %15298, 16"
"  %15302 = lshr i32 %15298, 16" -> "  %15328 = add nuw nsw i32 %15302, %15327"
"  %15303 = lshr i32 %15301, 16"
"  %15303 = lshr i32 %15301, 16" -> "  %15329 = add nuw nsw i32 %15328, %15303"
"  %15304 = and i32 %15295, 65535"
"  %15304 = and i32 %15295, 65535" -> "  %15305 = add nuw nsw i32 %15292, %15304"
"  %15305 = add nuw nsw i32 %15292, %15304"
"  %15305 = add nuw nsw i32 %15292, %15304" -> "  %15320 = and i32 %15305, 65535""  %15305 = add nuw nsw i32 %15292, %15304" -> "  %15307 = lshr i32 %15305, 16"
"  %15306 = and i32 %15301, 65535"
"  %15306 = and i32 %15301, 65535" -> "  %15308 = add nuw nsw i32 %15306, %15307"
"  %15307 = lshr i32 %15305, 16"
"  %15307 = lshr i32 %15305, 16" -> "  %15308 = add nuw nsw i32 %15306, %15307"
"  %15308 = add nuw nsw i32 %15306, %15307"
"  %15308 = add nuw nsw i32 %15306, %15307" -> "  %15323 = and i32 %15308, 65535""  %15308 = add nuw nsw i32 %15306, %15307" -> "  %15309 = lshr i32 %15308, 16"
"  %15309 = lshr i32 %15308, 16"
"  %15309 = lshr i32 %15308, 16" -> "  %15330 = add nuw nsw i32 %15329, %15309"
"  %15310 = and i32 %15283, 65535"
"  %15310 = and i32 %15283, 65535" -> "  %15312 = add nuw nsw i32 %15310, %15311"
"  %15311 = lshr i32 %15272, 16"
"  %15311 = lshr i32 %15272, 16" -> "  %15312 = add nuw nsw i32 %15310, %15311"
"  %15312 = add nuw nsw i32 %15310, %15311"
"  %15312 = add nuw nsw i32 %15310, %15311" -> "  %15314 = add nuw nsw i32 %15312, %15313"
"  %15313 = lshr i32 %15275, 16"
"  %15313 = lshr i32 %15275, 16" -> "  %15314 = add nuw nsw i32 %15312, %15313"
"  %15314 = add nuw nsw i32 %15312, %15313"
"  %15314 = add nuw nsw i32 %15312, %15313" -> "  %15316 = add nuw nsw i32 %15314, %15315"
"  %15315 = lshr i32 %15280, 16"
"  %15315 = lshr i32 %15280, 16" -> "  %15316 = add nuw nsw i32 %15314, %15315"
"  %15316 = add nuw nsw i32 %15314, %15315"
"  %15316 = add nuw nsw i32 %15314, %15315" -> "  %15318 = lshr i32 %15316, 16"
"  %15317 = and i32 %15289, 65535"
"  %15317 = and i32 %15289, 65535" -> "  %15319 = add nuw nsw i32 %15317, %15318"
"  %15318 = lshr i32 %15316, 16"
"  %15318 = lshr i32 %15316, 16" -> "  %15319 = add nuw nsw i32 %15317, %15318"
"  %15319 = add nuw nsw i32 %15317, %15318"
"  %15319 = add nuw nsw i32 %15317, %15318" -> "  %15321 = lshr i32 %15319, 16"
"  %15320 = and i32 %15305, 65535"
"  %15320 = and i32 %15305, 65535" -> "  %15322 = add nuw nsw i32 %15320, %15321"
"  %15321 = lshr i32 %15319, 16"
"  %15321 = lshr i32 %15319, 16" -> "  %15322 = add nuw nsw i32 %15320, %15321"
"  %15322 = add nuw nsw i32 %15320, %15321"
"  %15322 = add nuw nsw i32 %15320, %15321" -> "  %15324 = lshr i32 %15322, 16"
"  %15323 = and i32 %15308, 65535"
"  %15323 = and i32 %15308, 65535" -> "  %15325 = add nuw nsw i32 %15323, %15324"
"  %15324 = lshr i32 %15322, 16"
"  %15324 = lshr i32 %15322, 16" -> "  %15325 = add nuw nsw i32 %15323, %15324"
"  %15325 = add nuw nsw i32 %15323, %15324"
"  %15325 = add nuw nsw i32 %15323, %15324" -> "  %15326 = lshr i32 %15325, 16"
"  %15326 = lshr i32 %15325, 16"
"  %15326 = lshr i32 %15325, 16" -> "  %15331 = add nuw nsw i32 %15330, %15326"
"  %15327 = and i32 %15219, 65535"
"  %15327 = and i32 %15219, 65535" -> "  %15328 = add nuw nsw i32 %15302, %15327"
"  %15328 = add nuw nsw i32 %15302, %15327"
"  %15328 = add nuw nsw i32 %15302, %15327" -> "  %15329 = add nuw nsw i32 %15328, %15303"
"  %15329 = add nuw nsw i32 %15328, %15303"
"  %15329 = add nuw nsw i32 %15328, %15303" -> "  %15330 = add nuw nsw i32 %15329, %15309"
"  %15330 = add nuw nsw i32 %15329, %15309"
"  %15330 = add nuw nsw i32 %15329, %15309" -> "  %15331 = add nuw nsw i32 %15330, %15326"
"  %15331 = add nuw nsw i32 %15330, %15326"
"  %15331 = add nuw nsw i32 %15330, %15326" -> "  %16103 = and i32 %15331, 65535""  %15331 = add nuw nsw i32 %15330, %15326" -> "  %15333 = lshr i32 %15331, 16"
"  %15332 = and i32 %15225, 65535"
"  %15332 = and i32 %15225, 65535" -> "  %15334 = add nuw nsw i32 %15333, %15332"
"  %15333 = lshr i32 %15331, 16"
"  %15333 = lshr i32 %15331, 16" -> "  %15334 = add nuw nsw i32 %15333, %15332"
"  %15334 = add nuw nsw i32 %15333, %15332"
"  %15334 = add nuw nsw i32 %15333, %15332" -> "  %16106 = and i32 %15334, 65535""  %15334 = add nuw nsw i32 %15333, %15332" -> "  %15336 = lshr i32 %15334, 16"
"  %15335 = and i32 %15239, 65535"
"  %15335 = and i32 %15239, 65535" -> "  %15337 = add nuw nsw i32 %15336, %15335"
"  %15336 = lshr i32 %15334, 16"
"  %15336 = lshr i32 %15334, 16" -> "  %15337 = add nuw nsw i32 %15336, %15335"
"  %15337 = add nuw nsw i32 %15336, %15335"
"  %15337 = add nuw nsw i32 %15336, %15335" -> "  %16112 = and i32 %15337, 65535""  %15337 = add nuw nsw i32 %15336, %15335" -> "  %15338 = lshr i32 %15337, 16"
"  %15338 = lshr i32 %15337, 16"
"  %15338 = lshr i32 %15337, 16" -> "  %15340 = add nuw nsw i32 %15338, %15339"
"  %15339 = and i32 %15242, 65535"
"  %15339 = and i32 %15242, 65535" -> "  %15340 = add nuw nsw i32 %15338, %15339"
"  %15340 = add nuw nsw i32 %15338, %15339"
"  %15340 = add nuw nsw i32 %15338, %15339" -> "  %16115 = and i32 %15340, 65535""  %15340 = add nuw nsw i32 %15338, %15339" -> "  %15341 = lshr i32 %15340, 16"
"  %15341 = lshr i32 %15340, 16"
"  %15341 = lshr i32 %15340, 16" -> "  %15343 = add nuw nsw i32 %15341, %15342"
"  %15342 = and i32 %15249, 65535"
"  %15342 = and i32 %15249, 65535" -> "  %15343 = add nuw nsw i32 %15341, %15342"
"  %15343 = add nuw nsw i32 %15341, %15342"
"  %15343 = add nuw nsw i32 %15341, %15342" -> "  %16129 = and i32 %15343, 65535""  %15343 = add nuw nsw i32 %15341, %15342" -> "  %15344 = lshr i32 %15343, 16"
"  %15344 = lshr i32 %15343, 16"
"  %15344 = lshr i32 %15343, 16" -> "  %15346 = add nuw nsw i32 %15344, %15345"
"  %15345 = and i32 %15252, 65535"
"  %15345 = and i32 %15252, 65535" -> "  %15346 = add nuw nsw i32 %15344, %15345"
"  %15346 = add nuw nsw i32 %15344, %15345"
"  %15346 = add nuw nsw i32 %15344, %15345" -> "  %16132 = and i32 %15346, 65535""  %15346 = add nuw nsw i32 %15344, %15345" -> "  %15347 = lshr i32 %15346, 16"
"  %15347 = lshr i32 %15346, 16"
"  %15347 = lshr i32 %15346, 16" -> "  %15348 = add nuw i32 %15254, %15347"
"  %15348 = add nuw i32 %15254, %15347"
"  %15348 = add nuw i32 %15254, %15347" -> "  %16138 = and i32 %15348, 65535""  %15348 = add nuw i32 %15254, %15347" -> "  %16142 = lshr i32 %15348, 16"
"  %15349 = mul nuw i32 %13827, 42779"
"  %15349 = mul nuw i32 %13827, 42779" -> "  %16010 = and i32 %15349, 65535""  %15349 = mul nuw i32 %13827, 42779" -> "  %15350 = lshr i32 %15349, 16"
"  %15350 = lshr i32 %15349, 16"
"  %15350 = lshr i32 %15349, 16" -> "  %15353 = add nuw nsw i32 %15352, %15350"
"  %15351 = mul nuw i32 %13828, 42779"
"  %15351 = mul nuw i32 %13828, 42779" -> "  %15354 = and i32 %15351, -65536""  %15351 = mul nuw i32 %13828, 42779" -> "  %15352 = and i32 %15351, 65535"
"  %15352 = and i32 %15351, 65535"
"  %15352 = and i32 %15351, 65535" -> "  %15353 = add nuw nsw i32 %15352, %15350"
"  %15353 = add nuw nsw i32 %15352, %15350"
"  %15353 = add nuw nsw i32 %15352, %15350" -> "  %15355 = add nuw i32 %15353, %15354"
"  %15354 = and i32 %15351, -65536"
"  %15354 = and i32 %15351, -65536" -> "  %15355 = add nuw i32 %15353, %15354"
"  %15355 = add nuw i32 %15353, %15354"
"  %15355 = add nuw i32 %15353, %15354" -> "  %15359 = lshr i32 %15355, 16""  %15355 = add nuw i32 %15353, %15354" -> "  %15357 = and i32 %15355, 65535"
"  %15356 = mul nuw nsw i32 %13827, 9871"
"  %15356 = mul nuw nsw i32 %13827, 9871" -> "  %15358 = add nuw nsw i32 %15357, %15356"
"  %15357 = and i32 %15355, 65535"
"  %15357 = and i32 %15355, 65535" -> "  %15358 = add nuw nsw i32 %15357, %15356"
"  %15358 = add nuw nsw i32 %15357, %15356"
"  %15358 = add nuw nsw i32 %15357, %15356" -> "  %16013 = and i32 %15358, 65535""  %15358 = add nuw nsw i32 %15357, %15356" -> "  %15362 = lshr i32 %15358, 16"
"  %15359 = lshr i32 %15355, 16"
"  %15359 = lshr i32 %15355, 16" -> "  %15361 = add nuw nsw i32 %15359, %15360"
"  %15360 = mul nuw nsw i32 %13828, 9871"
"  %15360 = mul nuw nsw i32 %13828, 9871" -> "  %15361 = add nuw nsw i32 %15359, %15360"
"  %15361 = add nuw nsw i32 %15359, %15360"
"  %15361 = add nuw nsw i32 %15359, %15360" -> "  %15365 = and i32 %15361, 2147418112""  %15361 = add nuw nsw i32 %15359, %15360" -> "  %15363 = and i32 %15361, 65535"
"  %15362 = lshr i32 %15358, 16"
"  %15362 = lshr i32 %15358, 16" -> "  %15364 = add nuw nsw i32 %15362, %15363"
"  %15363 = and i32 %15361, 65535"
"  %15363 = and i32 %15361, 65535" -> "  %15364 = add nuw nsw i32 %15362, %15363"
"  %15364 = add nuw nsw i32 %15362, %15363"
"  %15364 = add nuw nsw i32 %15362, %15363" -> "  %15366 = add nuw nsw i32 %15364, %15365"
"  %15365 = and i32 %15361, 2147418112"
"  %15365 = and i32 %15361, 2147418112" -> "  %15366 = add nuw nsw i32 %15364, %15365"
"  %15366 = add nuw nsw i32 %15364, %15365"
"  %15366 = add nuw nsw i32 %15364, %15365" -> "  %15389 = lshr i32 %15366, 16""  %15366 = add nuw nsw i32 %15364, %15365" -> "  %15385 = and i32 %15366, 65535"
"  %15367 = mul nuw i32 %13848, 42779"
"  %15367 = mul nuw i32 %13848, 42779" -> "  %15386 = and i32 %15367, 65535""  %15367 = mul nuw i32 %13848, 42779" -> "  %15368 = lshr i32 %15367, 16"
"  %15368 = lshr i32 %15367, 16"
"  %15368 = lshr i32 %15367, 16" -> "  %15371 = add nuw nsw i32 %15370, %15368"
"  %15369 = mul nuw i32 %13847, 42779"
"  %15369 = mul nuw i32 %13847, 42779" -> "  %15372 = and i32 %15369, -65536""  %15369 = mul nuw i32 %13847, 42779" -> "  %15370 = and i32 %15369, 65535"
"  %15370 = and i32 %15369, 65535"
"  %15370 = and i32 %15369, 65535" -> "  %15371 = add nuw nsw i32 %15370, %15368"
"  %15371 = add nuw nsw i32 %15370, %15368"
"  %15371 = add nuw nsw i32 %15370, %15368" -> "  %15373 = add nuw i32 %15371, %15372"
"  %15372 = and i32 %15369, -65536"
"  %15372 = and i32 %15369, -65536" -> "  %15373 = add nuw i32 %15371, %15372"
"  %15373 = add nuw i32 %15371, %15372"
"  %15373 = add nuw i32 %15371, %15372" -> "  %15377 = lshr i32 %15373, 16""  %15373 = add nuw i32 %15371, %15372" -> "  %15375 = and i32 %15373, 65535"
"  %15374 = mul nuw nsw i32 %13848, 9871"
"  %15374 = mul nuw nsw i32 %13848, 9871" -> "  %15376 = add nuw nsw i32 %15375, %15374"
"  %15375 = and i32 %15373, 65535"
"  %15375 = and i32 %15373, 65535" -> "  %15376 = add nuw nsw i32 %15375, %15374"
"  %15376 = add nuw nsw i32 %15375, %15374"
"  %15376 = add nuw nsw i32 %15375, %15374" -> "  %15388 = and i32 %15376, 65535""  %15376 = add nuw nsw i32 %15375, %15374" -> "  %15380 = lshr i32 %15376, 16"
"  %15377 = lshr i32 %15373, 16"
"  %15377 = lshr i32 %15373, 16" -> "  %15379 = add nuw nsw i32 %15377, %15378"
"  %15378 = mul nuw nsw i32 %13847, 9871"
"  %15378 = mul nuw nsw i32 %13847, 9871" -> "  %15379 = add nuw nsw i32 %15377, %15378"
"  %15379 = add nuw nsw i32 %15377, %15378"
"  %15379 = add nuw nsw i32 %15377, %15378" -> "  %15383 = and i32 %15379, 2147418112""  %15379 = add nuw nsw i32 %15377, %15378" -> "  %15381 = and i32 %15379, 65535"
"  %15380 = lshr i32 %15376, 16"
"  %15380 = lshr i32 %15376, 16" -> "  %15382 = add nuw nsw i32 %15380, %15381"
"  %15381 = and i32 %15379, 65535"
"  %15381 = and i32 %15379, 65535" -> "  %15382 = add nuw nsw i32 %15380, %15381"
"  %15382 = add nuw nsw i32 %15380, %15381"
"  %15382 = add nuw nsw i32 %15380, %15381" -> "  %15384 = add nuw nsw i32 %15382, %15383"
"  %15383 = and i32 %15379, 2147418112"
"  %15383 = and i32 %15379, 2147418112" -> "  %15384 = add nuw nsw i32 %15382, %15383"
"  %15384 = add nuw nsw i32 %15382, %15383"
"  %15384 = add nuw nsw i32 %15382, %15383" -> "  %15392 = add nuw nsw i32 %15384, %15391"
"  %15385 = and i32 %15366, 65535"
"  %15385 = and i32 %15366, 65535" -> "  %15387 = add nuw nsw i32 %15385, %15386"
"  %15386 = and i32 %15367, 65535"
"  %15386 = and i32 %15367, 65535" -> "  %15387 = add nuw nsw i32 %15385, %15386"
"  %15387 = add nuw nsw i32 %15385, %15386"
"  %15387 = add nuw nsw i32 %15385, %15386" -> "  %15416 = and i32 %15387, 65535""  %15387 = add nuw nsw i32 %15385, %15386" -> "  %15394 = lshr i32 %15387, 16"
"  %15388 = and i32 %15376, 65535"
"  %15388 = and i32 %15376, 65535" -> "  %15390 = add nuw nsw i32 %15388, %15389"
"  %15389 = lshr i32 %15366, 16"
"  %15389 = lshr i32 %15366, 16" -> "  %15390 = add nuw nsw i32 %15388, %15389"
"  %15390 = add nuw nsw i32 %15388, %15389"
"  %15390 = add nuw nsw i32 %15388, %15389" -> "  %15393 = and i32 %15390, 65535""  %15390 = add nuw nsw i32 %15388, %15389" -> "  %15391 = lshr i32 %15390, 16"
"  %15391 = lshr i32 %15390, 16"
"  %15391 = lshr i32 %15390, 16" -> "  %15392 = add nuw nsw i32 %15384, %15391"
"  %15392 = add nuw nsw i32 %15384, %15391"
"  %15392 = add nuw nsw i32 %15384, %15391" -> "  %15397 = add nuw nsw i32 %15392, %15396"
"  %15393 = and i32 %15390, 65535"
"  %15393 = and i32 %15390, 65535" -> "  %15395 = add nuw nsw i32 %15393, %15394"
"  %15394 = lshr i32 %15387, 16"
"  %15394 = lshr i32 %15387, 16" -> "  %15395 = add nuw nsw i32 %15393, %15394"
"  %15395 = add nuw nsw i32 %15393, %15394"
"  %15395 = add nuw nsw i32 %15393, %15394" -> "  %15419 = and i32 %15395, 65535""  %15395 = add nuw nsw i32 %15393, %15394" -> "  %15396 = lshr i32 %15395, 16"
"  %15396 = lshr i32 %15395, 16"
"  %15396 = lshr i32 %15395, 16" -> "  %15397 = add nuw nsw i32 %15392, %15396"
"  %15397 = add nuw nsw i32 %15392, %15396"
"  %15397 = add nuw nsw i32 %15392, %15396" -> "  %15447 = and i32 %15397, 65535""  %15397 = add nuw nsw i32 %15392, %15396" -> "  %15451 = lshr i32 %15397, 16"
"  %15398 = mul nuw nsw i32 %13827, 24315"
"  %15398 = mul nuw nsw i32 %13827, 24315" -> "  %15417 = and i32 %15398, 65535""  %15398 = mul nuw nsw i32 %13827, 24315" -> "  %15399 = lshr i32 %15398, 16"
"  %15399 = lshr i32 %15398, 16"
"  %15399 = lshr i32 %15398, 16" -> "  %15402 = add nuw nsw i32 %15401, %15399"
"  %15400 = mul nuw nsw i32 %13828, 24315"
"  %15400 = mul nuw nsw i32 %13828, 24315" -> "  %15403 = and i32 %15400, 2147418112""  %15400 = mul nuw nsw i32 %13828, 24315" -> "  %15401 = and i32 %15400, 65535"
"  %15401 = and i32 %15400, 65535"
"  %15401 = and i32 %15400, 65535" -> "  %15402 = add nuw nsw i32 %15401, %15399"
"  %15402 = add nuw nsw i32 %15401, %15399"
"  %15402 = add nuw nsw i32 %15401, %15399" -> "  %15404 = add nuw nsw i32 %15402, %15403"
"  %15403 = and i32 %15400, 2147418112"
"  %15403 = and i32 %15400, 2147418112" -> "  %15404 = add nuw nsw i32 %15402, %15403"
"  %15404 = add nuw nsw i32 %15402, %15403"
"  %15404 = add nuw nsw i32 %15402, %15403" -> "  %15408 = lshr i32 %15404, 16""  %15404 = add nuw nsw i32 %15402, %15403" -> "  %15406 = and i32 %15404, 65535"
"  %15405 = mul nuw nsw i32 %13827, 29744"
"  %15405 = mul nuw nsw i32 %13827, 29744" -> "  %15407 = add nuw nsw i32 %15406, %15405"
"  %15406 = and i32 %15404, 65535"
"  %15406 = and i32 %15404, 65535" -> "  %15407 = add nuw nsw i32 %15406, %15405"
"  %15407 = add nuw nsw i32 %15406, %15405"
"  %15407 = add nuw nsw i32 %15406, %15405" -> "  %15420 = and i32 %15407, 65535""  %15407 = add nuw nsw i32 %15406, %15405" -> "  %15411 = lshr i32 %15407, 16"
"  %15408 = lshr i32 %15404, 16"
"  %15408 = lshr i32 %15404, 16" -> "  %15410 = add nuw nsw i32 %15408, %15409"
"  %15409 = mul nuw nsw i32 %13828, 29744"
"  %15409 = mul nuw nsw i32 %13828, 29744" -> "  %15410 = add nuw nsw i32 %15408, %15409"
"  %15410 = add nuw nsw i32 %15408, %15409"
"  %15410 = add nuw nsw i32 %15408, %15409" -> "  %15414 = and i32 %15410, 2147418112""  %15410 = add nuw nsw i32 %15408, %15409" -> "  %15412 = and i32 %15410, 65535"
"  %15411 = lshr i32 %15407, 16"
"  %15411 = lshr i32 %15407, 16" -> "  %15413 = add nuw nsw i32 %15411, %15412"
"  %15412 = and i32 %15410, 65535"
"  %15412 = and i32 %15410, 65535" -> "  %15413 = add nuw nsw i32 %15411, %15412"
"  %15413 = add nuw nsw i32 %15411, %15412"
"  %15413 = add nuw nsw i32 %15411, %15412" -> "  %15415 = add nuw nsw i32 %15413, %15414"
"  %15414 = and i32 %15410, 2147418112"
"  %15414 = and i32 %15410, 2147418112" -> "  %15415 = add nuw nsw i32 %15413, %15414"
"  %15415 = add nuw nsw i32 %15413, %15414"
"  %15415 = add nuw nsw i32 %15413, %15414" -> "  %15423 = add nuw nsw i32 %15415, %15422"
"  %15416 = and i32 %15387, 65535"
"  %15416 = and i32 %15387, 65535" -> "  %15418 = add nuw nsw i32 %15416, %15417"
"  %15417 = and i32 %15398, 65535"
"  %15417 = and i32 %15398, 65535" -> "  %15418 = add nuw nsw i32 %15416, %15417"
"  %15418 = add nuw nsw i32 %15416, %15417"
"  %15418 = add nuw nsw i32 %15416, %15417" -> "  %16019 = and i32 %15418, 65535""  %15418 = add nuw nsw i32 %15416, %15417" -> "  %15425 = lshr i32 %15418, 16"
"  %15419 = and i32 %15395, 65535"
"  %15419 = and i32 %15395, 65535" -> "  %15421 = add nuw nsw i32 %15419, %15420"
"  %15420 = and i32 %15407, 65535"
"  %15420 = and i32 %15407, 65535" -> "  %15421 = add nuw nsw i32 %15419, %15420"
"  %15421 = add nuw nsw i32 %15419, %15420"
"  %15421 = add nuw nsw i32 %15419, %15420" -> "  %15424 = and i32 %15421, 65535""  %15421 = add nuw nsw i32 %15419, %15420" -> "  %15422 = lshr i32 %15421, 16"
"  %15422 = lshr i32 %15421, 16"
"  %15422 = lshr i32 %15421, 16" -> "  %15423 = add nuw nsw i32 %15415, %15422"
"  %15423 = add nuw nsw i32 %15415, %15422"
"  %15423 = add nuw nsw i32 %15415, %15422" -> "  %15428 = add nuw nsw i32 %15423, %15427"
"  %15424 = and i32 %15421, 65535"
"  %15424 = and i32 %15421, 65535" -> "  %15426 = add nuw nsw i32 %15424, %15425"
"  %15425 = lshr i32 %15418, 16"
"  %15425 = lshr i32 %15418, 16" -> "  %15426 = add nuw nsw i32 %15424, %15425"
"  %15426 = add nuw nsw i32 %15424, %15425"
"  %15426 = add nuw nsw i32 %15424, %15425" -> "  %16022 = and i32 %15426, 65535""  %15426 = add nuw nsw i32 %15424, %15425" -> "  %15427 = lshr i32 %15426, 16"
"  %15427 = lshr i32 %15426, 16"
"  %15427 = lshr i32 %15426, 16" -> "  %15428 = add nuw nsw i32 %15423, %15427"
"  %15428 = add nuw nsw i32 %15423, %15427"
"  %15428 = add nuw nsw i32 %15423, %15427" -> "  %15464 = lshr i32 %15428, 16""  %15428 = add nuw nsw i32 %15423, %15427" -> "  %15461 = and i32 %15428, 65535"
"  %15429 = mul nuw nsw i32 %13848, 24315"
"  %15429 = mul nuw nsw i32 %13848, 24315" -> "  %15448 = and i32 %15429, 65535""  %15429 = mul nuw nsw i32 %13848, 24315" -> "  %15430 = lshr i32 %15429, 16"
"  %15430 = lshr i32 %15429, 16"
"  %15430 = lshr i32 %15429, 16" -> "  %15433 = add nuw nsw i32 %15432, %15430"
"  %15431 = mul nuw nsw i32 %13847, 24315"
"  %15431 = mul nuw nsw i32 %13847, 24315" -> "  %15434 = and i32 %15431, 2147418112""  %15431 = mul nuw nsw i32 %13847, 24315" -> "  %15432 = and i32 %15431, 65535"
"  %15432 = and i32 %15431, 65535"
"  %15432 = and i32 %15431, 65535" -> "  %15433 = add nuw nsw i32 %15432, %15430"
"  %15433 = add nuw nsw i32 %15432, %15430"
"  %15433 = add nuw nsw i32 %15432, %15430" -> "  %15435 = add nuw nsw i32 %15433, %15434"
"  %15434 = and i32 %15431, 2147418112"
"  %15434 = and i32 %15431, 2147418112" -> "  %15435 = add nuw nsw i32 %15433, %15434"
"  %15435 = add nuw nsw i32 %15433, %15434"
"  %15435 = add nuw nsw i32 %15433, %15434" -> "  %15439 = lshr i32 %15435, 16""  %15435 = add nuw nsw i32 %15433, %15434" -> "  %15437 = and i32 %15435, 65535"
"  %15436 = mul nuw nsw i32 %13848, 29744"
"  %15436 = mul nuw nsw i32 %13848, 29744" -> "  %15438 = add nuw nsw i32 %15437, %15436"
"  %15437 = and i32 %15435, 65535"
"  %15437 = and i32 %15435, 65535" -> "  %15438 = add nuw nsw i32 %15437, %15436"
"  %15438 = add nuw nsw i32 %15437, %15436"
"  %15438 = add nuw nsw i32 %15437, %15436" -> "  %15450 = and i32 %15438, 65535""  %15438 = add nuw nsw i32 %15437, %15436" -> "  %15442 = lshr i32 %15438, 16"
"  %15439 = lshr i32 %15435, 16"
"  %15439 = lshr i32 %15435, 16" -> "  %15441 = add nuw nsw i32 %15439, %15440"
"  %15440 = mul nuw nsw i32 %13847, 29744"
"  %15440 = mul nuw nsw i32 %13847, 29744" -> "  %15441 = add nuw nsw i32 %15439, %15440"
"  %15441 = add nuw nsw i32 %15439, %15440"
"  %15441 = add nuw nsw i32 %15439, %15440" -> "  %15445 = and i32 %15441, 2147418112""  %15441 = add nuw nsw i32 %15439, %15440" -> "  %15443 = and i32 %15441, 65535"
"  %15442 = lshr i32 %15438, 16"
"  %15442 = lshr i32 %15438, 16" -> "  %15444 = add nuw nsw i32 %15442, %15443"
"  %15443 = and i32 %15441, 65535"
"  %15443 = and i32 %15441, 65535" -> "  %15444 = add nuw nsw i32 %15442, %15443"
"  %15444 = add nuw nsw i32 %15442, %15443"
"  %15444 = add nuw nsw i32 %15442, %15443" -> "  %15446 = add nuw nsw i32 %15444, %15445"
"  %15445 = and i32 %15441, 2147418112"
"  %15445 = and i32 %15441, 2147418112" -> "  %15446 = add nuw nsw i32 %15444, %15445"
"  %15446 = add nuw nsw i32 %15444, %15445"
"  %15446 = add nuw nsw i32 %15444, %15445" -> "  %15454 = add nuw nsw i32 %15446, %15453"
"  %15447 = and i32 %15397, 65535"
"  %15447 = and i32 %15397, 65535" -> "  %15449 = add nuw nsw i32 %15447, %15448"
"  %15448 = and i32 %15429, 65535"
"  %15448 = and i32 %15429, 65535" -> "  %15449 = add nuw nsw i32 %15447, %15448"
"  %15449 = add nuw nsw i32 %15447, %15448"
"  %15449 = add nuw nsw i32 %15447, %15448" -> "  %15460 = and i32 %15449, 65535""  %15449 = add nuw nsw i32 %15447, %15448" -> "  %15456 = lshr i32 %15449, 16"
"  %15450 = and i32 %15438, 65535"
"  %15450 = and i32 %15438, 65535" -> "  %15452 = add nuw nsw i32 %15451, %15450"
"  %15451 = lshr i32 %15397, 16"
"  %15451 = lshr i32 %15397, 16" -> "  %15452 = add nuw nsw i32 %15451, %15450"
"  %15452 = add nuw nsw i32 %15451, %15450"
"  %15452 = add nuw nsw i32 %15451, %15450" -> "  %15455 = and i32 %15452, 65535""  %15452 = add nuw nsw i32 %15451, %15450" -> "  %15453 = lshr i32 %15452, 16"
"  %15453 = lshr i32 %15452, 16"
"  %15453 = lshr i32 %15452, 16" -> "  %15454 = add nuw nsw i32 %15446, %15453"
"  %15454 = add nuw nsw i32 %15446, %15453"
"  %15454 = add nuw nsw i32 %15446, %15453" -> "  %15459 = add nuw nsw i32 %15454, %15458"
"  %15455 = and i32 %15452, 65535"
"  %15455 = and i32 %15452, 65535" -> "  %15457 = add nuw nsw i32 %15455, %15456"
"  %15456 = lshr i32 %15449, 16"
"  %15456 = lshr i32 %15449, 16" -> "  %15457 = add nuw nsw i32 %15455, %15456"
"  %15457 = add nuw nsw i32 %15455, %15456"
"  %15457 = add nuw nsw i32 %15455, %15456" -> "  %15463 = and i32 %15457, 65535""  %15457 = add nuw nsw i32 %15455, %15456" -> "  %15458 = lshr i32 %15457, 16"
"  %15458 = lshr i32 %15457, 16"
"  %15458 = lshr i32 %15457, 16" -> "  %15459 = add nuw nsw i32 %15454, %15458"
"  %15459 = add nuw nsw i32 %15454, %15458"
"  %15459 = add nuw nsw i32 %15454, %15458" -> "  %15472 = and i32 %15459, 2147418112""  %15459 = add nuw nsw i32 %15454, %15458" -> "  %15470 = and i32 %15459, 65535"
"  %15460 = and i32 %15449, 65535"
"  %15460 = and i32 %15449, 65535" -> "  %15462 = add nuw nsw i32 %15461, %15460"
"  %15461 = and i32 %15428, 65535"
"  %15461 = and i32 %15428, 65535" -> "  %15462 = add nuw nsw i32 %15461, %15460"
"  %15462 = add nuw nsw i32 %15461, %15460"
"  %15462 = add nuw nsw i32 %15461, %15460" -> "  %15604 = and i32 %15462, 65535""  %15462 = add nuw nsw i32 %15461, %15460" -> "  %15466 = lshr i32 %15462, 16"
"  %15463 = and i32 %15457, 65535"
"  %15463 = and i32 %15457, 65535" -> "  %15465 = add nuw nsw i32 %15463, %15464"
"  %15464 = lshr i32 %15428, 16"
"  %15464 = lshr i32 %15428, 16" -> "  %15465 = add nuw nsw i32 %15463, %15464"
"  %15465 = add nuw nsw i32 %15463, %15464"
"  %15465 = add nuw nsw i32 %15463, %15464" -> "  %15469 = lshr i32 %15465, 16""  %15465 = add nuw nsw i32 %15463, %15464" -> "  %15467 = and i32 %15465, 65535"
"  %15466 = lshr i32 %15462, 16"
"  %15466 = lshr i32 %15462, 16" -> "  %15468 = add nuw nsw i32 %15467, %15466"
"  %15467 = and i32 %15465, 65535"
"  %15467 = and i32 %15465, 65535" -> "  %15468 = add nuw nsw i32 %15467, %15466"
"  %15468 = add nuw nsw i32 %15467, %15466"
"  %15468 = add nuw nsw i32 %15467, %15466" -> "  %15607 = and i32 %15468, 65535""  %15468 = add nuw nsw i32 %15467, %15466" -> "  %15474 = lshr i32 %15468, 16"
"  %15469 = lshr i32 %15465, 16"
"  %15469 = lshr i32 %15465, 16" -> "  %15471 = add nuw nsw i32 %15469, %15470"
"  %15470 = and i32 %15459, 65535"
"  %15470 = and i32 %15459, 65535" -> "  %15471 = add nuw nsw i32 %15469, %15470"
"  %15471 = add nuw nsw i32 %15469, %15470"
"  %15471 = add nuw nsw i32 %15469, %15470" -> "  %15473 = add nuw nsw i32 %15471, %15472"
"  %15472 = and i32 %15459, 2147418112"
"  %15472 = and i32 %15459, 2147418112" -> "  %15473 = add nuw nsw i32 %15471, %15472"
"  %15473 = add nuw nsw i32 %15471, %15472"
"  %15473 = add nuw nsw i32 %15471, %15472" -> "  %15475 = add nuw nsw i32 %15473, %15474"
"  %15474 = lshr i32 %15468, 16"
"  %15474 = lshr i32 %15468, 16" -> "  %15475 = add nuw nsw i32 %15473, %15474"
"  %15475 = add nuw nsw i32 %15473, %15474"
"  %15475 = add nuw nsw i32 %15473, %15474" -> "  %15612 = and i32 %15475, 65535""  %15475 = add nuw nsw i32 %15473, %15474" -> "  %15615 = lshr i32 %15475, 16"
"  %15476 = mul nuw i32 %13962, 42779"
"  %15476 = mul nuw i32 %13962, 42779" -> "  %15603 = and i32 %15476, 65535""  %15476 = mul nuw i32 %13962, 42779" -> "  %15477 = lshr i32 %15476, 16"
"  %15477 = lshr i32 %15476, 16"
"  %15477 = lshr i32 %15476, 16" -> "  %15480 = add nuw nsw i32 %15479, %15477"
"  %15478 = mul nuw i32 %13961, 42779"
"  %15478 = mul nuw i32 %13961, 42779" -> "  %15481 = and i32 %15478, -65536""  %15478 = mul nuw i32 %13961, 42779" -> "  %15479 = and i32 %15478, 65535"
"  %15479 = and i32 %15478, 65535"
"  %15479 = and i32 %15478, 65535" -> "  %15480 = add nuw nsw i32 %15479, %15477"
"  %15480 = add nuw nsw i32 %15479, %15477"
"  %15480 = add nuw nsw i32 %15479, %15477" -> "  %15482 = add nuw i32 %15480, %15481"
"  %15481 = and i32 %15478, -65536"
"  %15481 = and i32 %15478, -65536" -> "  %15482 = add nuw i32 %15480, %15481"
"  %15482 = add nuw i32 %15480, %15481"
"  %15482 = add nuw i32 %15480, %15481" -> "  %15486 = lshr i32 %15482, 16""  %15482 = add nuw i32 %15480, %15481" -> "  %15484 = and i32 %15482, 65535"
"  %15483 = mul nuw nsw i32 %13962, 9871"
"  %15483 = mul nuw nsw i32 %13962, 9871" -> "  %15485 = add nuw nsw i32 %15484, %15483"
"  %15484 = and i32 %15482, 65535"
"  %15484 = and i32 %15482, 65535" -> "  %15485 = add nuw nsw i32 %15484, %15483"
"  %15485 = add nuw nsw i32 %15484, %15483"
"  %15485 = add nuw nsw i32 %15484, %15483" -> "  %15606 = and i32 %15485, 65535""  %15485 = add nuw nsw i32 %15484, %15483" -> "  %15489 = lshr i32 %15485, 16"
"  %15486 = lshr i32 %15482, 16"
"  %15486 = lshr i32 %15482, 16" -> "  %15488 = add nuw nsw i32 %15486, %15487"
"  %15487 = mul nuw nsw i32 %13961, 9871"
"  %15487 = mul nuw nsw i32 %13961, 9871" -> "  %15488 = add nuw nsw i32 %15486, %15487"
"  %15488 = add nuw nsw i32 %15486, %15487"
"  %15488 = add nuw nsw i32 %15486, %15487" -> "  %15492 = and i32 %15488, 2147418112""  %15488 = add nuw nsw i32 %15486, %15487" -> "  %15490 = and i32 %15488, 65535"
"  %15489 = lshr i32 %15485, 16"
"  %15489 = lshr i32 %15485, 16" -> "  %15491 = add nuw nsw i32 %15489, %15490"
"  %15490 = and i32 %15488, 65535"
"  %15490 = and i32 %15488, 65535" -> "  %15491 = add nuw nsw i32 %15489, %15490"
"  %15491 = add nuw nsw i32 %15489, %15490"
"  %15491 = add nuw nsw i32 %15489, %15490" -> "  %15493 = add nuw nsw i32 %15491, %15492"
"  %15492 = and i32 %15488, 2147418112"
"  %15492 = and i32 %15488, 2147418112" -> "  %15493 = add nuw nsw i32 %15491, %15492"
"  %15493 = add nuw nsw i32 %15491, %15492"
"  %15493 = add nuw nsw i32 %15491, %15492" -> "  %15516 = lshr i32 %15493, 16""  %15493 = add nuw nsw i32 %15491, %15492" -> "  %15512 = and i32 %15493, 65535"
"  %15494 = mul nuw i32 %13981, 42779"
"  %15494 = mul nuw i32 %13981, 42779" -> "  %15513 = and i32 %15494, 65535""  %15494 = mul nuw i32 %13981, 42779" -> "  %15495 = lshr i32 %15494, 16"
"  %15495 = lshr i32 %15494, 16"
"  %15495 = lshr i32 %15494, 16" -> "  %15498 = add nuw nsw i32 %15497, %15495"
"  %15496 = mul nuw i32 %13982, 42779"
"  %15496 = mul nuw i32 %13982, 42779" -> "  %15499 = and i32 %15496, -65536""  %15496 = mul nuw i32 %13982, 42779" -> "  %15497 = and i32 %15496, 65535"
"  %15497 = and i32 %15496, 65535"
"  %15497 = and i32 %15496, 65535" -> "  %15498 = add nuw nsw i32 %15497, %15495"
"  %15498 = add nuw nsw i32 %15497, %15495"
"  %15498 = add nuw nsw i32 %15497, %15495" -> "  %15500 = add nuw i32 %15498, %15499"
"  %15499 = and i32 %15496, -65536"
"  %15499 = and i32 %15496, -65536" -> "  %15500 = add nuw i32 %15498, %15499"
"  %15500 = add nuw i32 %15498, %15499"
"  %15500 = add nuw i32 %15498, %15499" -> "  %15504 = lshr i32 %15500, 16""  %15500 = add nuw i32 %15498, %15499" -> "  %15502 = and i32 %15500, 65535"
"  %15501 = mul nuw nsw i32 %13981, 9871"
"  %15501 = mul nuw nsw i32 %13981, 9871" -> "  %15503 = add nuw nsw i32 %15502, %15501"
"  %15502 = and i32 %15500, 65535"
"  %15502 = and i32 %15500, 65535" -> "  %15503 = add nuw nsw i32 %15502, %15501"
"  %15503 = add nuw nsw i32 %15502, %15501"
"  %15503 = add nuw nsw i32 %15502, %15501" -> "  %15515 = and i32 %15503, 65535""  %15503 = add nuw nsw i32 %15502, %15501" -> "  %15507 = lshr i32 %15503, 16"
"  %15504 = lshr i32 %15500, 16"
"  %15504 = lshr i32 %15500, 16" -> "  %15506 = add nuw nsw i32 %15504, %15505"
"  %15505 = mul nuw nsw i32 %13982, 9871"
"  %15505 = mul nuw nsw i32 %13982, 9871" -> "  %15506 = add nuw nsw i32 %15504, %15505"
"  %15506 = add nuw nsw i32 %15504, %15505"
"  %15506 = add nuw nsw i32 %15504, %15505" -> "  %15510 = and i32 %15506, 2147418112""  %15506 = add nuw nsw i32 %15504, %15505" -> "  %15508 = and i32 %15506, 65535"
"  %15507 = lshr i32 %15503, 16"
"  %15507 = lshr i32 %15503, 16" -> "  %15509 = add nuw nsw i32 %15507, %15508"
"  %15508 = and i32 %15506, 65535"
"  %15508 = and i32 %15506, 65535" -> "  %15509 = add nuw nsw i32 %15507, %15508"
"  %15509 = add nuw nsw i32 %15507, %15508"
"  %15509 = add nuw nsw i32 %15507, %15508" -> "  %15511 = add nuw nsw i32 %15509, %15510"
"  %15510 = and i32 %15506, 2147418112"
"  %15510 = and i32 %15506, 2147418112" -> "  %15511 = add nuw nsw i32 %15509, %15510"
"  %15511 = add nuw nsw i32 %15509, %15510"
"  %15511 = add nuw nsw i32 %15509, %15510" -> "  %15519 = add nuw nsw i32 %15511, %15518"
"  %15512 = and i32 %15493, 65535"
"  %15512 = and i32 %15493, 65535" -> "  %15514 = add nuw nsw i32 %15512, %15513"
"  %15513 = and i32 %15494, 65535"
"  %15513 = and i32 %15494, 65535" -> "  %15514 = add nuw nsw i32 %15512, %15513"
"  %15514 = add nuw nsw i32 %15512, %15513"
"  %15514 = add nuw nsw i32 %15512, %15513" -> "  %15543 = and i32 %15514, 65535""  %15514 = add nuw nsw i32 %15512, %15513" -> "  %15521 = lshr i32 %15514, 16"
"  %15515 = and i32 %15503, 65535"
"  %15515 = and i32 %15503, 65535" -> "  %15517 = add nuw nsw i32 %15516, %15515"
"  %15516 = lshr i32 %15493, 16"
"  %15516 = lshr i32 %15493, 16" -> "  %15517 = add nuw nsw i32 %15516, %15515"
"  %15517 = add nuw nsw i32 %15516, %15515"
"  %15517 = add nuw nsw i32 %15516, %15515" -> "  %15520 = and i32 %15517, 65535""  %15517 = add nuw nsw i32 %15516, %15515" -> "  %15518 = lshr i32 %15517, 16"
"  %15518 = lshr i32 %15517, 16"
"  %15518 = lshr i32 %15517, 16" -> "  %15519 = add nuw nsw i32 %15511, %15518"
"  %15519 = add nuw nsw i32 %15511, %15518"
"  %15519 = add nuw nsw i32 %15511, %15518" -> "  %15524 = add nuw nsw i32 %15519, %15523"
"  %15520 = and i32 %15517, 65535"
"  %15520 = and i32 %15517, 65535" -> "  %15522 = add nuw nsw i32 %15520, %15521"
"  %15521 = lshr i32 %15514, 16"
"  %15521 = lshr i32 %15514, 16" -> "  %15522 = add nuw nsw i32 %15520, %15521"
"  %15522 = add nuw nsw i32 %15520, %15521"
"  %15522 = add nuw nsw i32 %15520, %15521" -> "  %15546 = and i32 %15522, 65535""  %15522 = add nuw nsw i32 %15520, %15521" -> "  %15523 = lshr i32 %15522, 16"
"  %15523 = lshr i32 %15522, 16"
"  %15523 = lshr i32 %15522, 16" -> "  %15524 = add nuw nsw i32 %15519, %15523"
"  %15524 = add nuw nsw i32 %15519, %15523"
"  %15524 = add nuw nsw i32 %15519, %15523" -> "  %15578 = lshr i32 %15524, 16""  %15524 = add nuw nsw i32 %15519, %15523" -> "  %15574 = and i32 %15524, 65535"
"  %15525 = mul nuw nsw i32 %13962, 24315"
"  %15525 = mul nuw nsw i32 %13962, 24315" -> "  %15544 = and i32 %15525, 65535""  %15525 = mul nuw nsw i32 %13962, 24315" -> "  %15526 = lshr i32 %15525, 16"
"  %15526 = lshr i32 %15525, 16"
"  %15526 = lshr i32 %15525, 16" -> "  %15529 = add nuw nsw i32 %15528, %15526"
"  %15527 = mul nuw nsw i32 %13961, 24315"
"  %15527 = mul nuw nsw i32 %13961, 24315" -> "  %15530 = and i32 %15527, 2147418112""  %15527 = mul nuw nsw i32 %13961, 24315" -> "  %15528 = and i32 %15527, 65535"
"  %15528 = and i32 %15527, 65535"
"  %15528 = and i32 %15527, 65535" -> "  %15529 = add nuw nsw i32 %15528, %15526"
"  %15529 = add nuw nsw i32 %15528, %15526"
"  %15529 = add nuw nsw i32 %15528, %15526" -> "  %15531 = add nuw nsw i32 %15529, %15530"
"  %15530 = and i32 %15527, 2147418112"
"  %15530 = and i32 %15527, 2147418112" -> "  %15531 = add nuw nsw i32 %15529, %15530"
"  %15531 = add nuw nsw i32 %15529, %15530"
"  %15531 = add nuw nsw i32 %15529, %15530" -> "  %15535 = lshr i32 %15531, 16""  %15531 = add nuw nsw i32 %15529, %15530" -> "  %15533 = and i32 %15531, 65535"
"  %15532 = mul nuw nsw i32 %13962, 29744"
"  %15532 = mul nuw nsw i32 %13962, 29744" -> "  %15534 = add nuw nsw i32 %15533, %15532"
"  %15533 = and i32 %15531, 65535"
"  %15533 = and i32 %15531, 65535" -> "  %15534 = add nuw nsw i32 %15533, %15532"
"  %15534 = add nuw nsw i32 %15533, %15532"
"  %15534 = add nuw nsw i32 %15533, %15532" -> "  %15547 = and i32 %15534, 65535""  %15534 = add nuw nsw i32 %15533, %15532" -> "  %15538 = lshr i32 %15534, 16"
"  %15535 = lshr i32 %15531, 16"
"  %15535 = lshr i32 %15531, 16" -> "  %15537 = add nuw nsw i32 %15535, %15536"
"  %15536 = mul nuw nsw i32 %13961, 29744"
"  %15536 = mul nuw nsw i32 %13961, 29744" -> "  %15537 = add nuw nsw i32 %15535, %15536"
"  %15537 = add nuw nsw i32 %15535, %15536"
"  %15537 = add nuw nsw i32 %15535, %15536" -> "  %15541 = and i32 %15537, 2147418112""  %15537 = add nuw nsw i32 %15535, %15536" -> "  %15539 = and i32 %15537, 65535"
"  %15538 = lshr i32 %15534, 16"
"  %15538 = lshr i32 %15534, 16" -> "  %15540 = add nuw nsw i32 %15538, %15539"
"  %15539 = and i32 %15537, 65535"
"  %15539 = and i32 %15537, 65535" -> "  %15540 = add nuw nsw i32 %15538, %15539"
"  %15540 = add nuw nsw i32 %15538, %15539"
"  %15540 = add nuw nsw i32 %15538, %15539" -> "  %15542 = add nuw nsw i32 %15540, %15541"
"  %15541 = and i32 %15537, 2147418112"
"  %15541 = and i32 %15537, 2147418112" -> "  %15542 = add nuw nsw i32 %15540, %15541"
"  %15542 = add nuw nsw i32 %15540, %15541"
"  %15542 = add nuw nsw i32 %15540, %15541" -> "  %15550 = add nuw nsw i32 %15542, %15549"
"  %15543 = and i32 %15514, 65535"
"  %15543 = and i32 %15514, 65535" -> "  %15545 = add nuw nsw i32 %15543, %15544"
"  %15544 = and i32 %15525, 65535"
"  %15544 = and i32 %15525, 65535" -> "  %15545 = add nuw nsw i32 %15543, %15544"
"  %15545 = add nuw nsw i32 %15543, %15544"
"  %15545 = add nuw nsw i32 %15543, %15544" -> "  %15613 = and i32 %15545, 65535""  %15545 = add nuw nsw i32 %15543, %15544" -> "  %15552 = lshr i32 %15545, 16"
"  %15546 = and i32 %15522, 65535"
"  %15546 = and i32 %15522, 65535" -> "  %15548 = add nuw nsw i32 %15546, %15547"
"  %15547 = and i32 %15534, 65535"
"  %15547 = and i32 %15534, 65535" -> "  %15548 = add nuw nsw i32 %15546, %15547"
"  %15548 = add nuw nsw i32 %15546, %15547"
"  %15548 = add nuw nsw i32 %15546, %15547" -> "  %15551 = and i32 %15548, 65535""  %15548 = add nuw nsw i32 %15546, %15547" -> "  %15549 = lshr i32 %15548, 16"
"  %15549 = lshr i32 %15548, 16"
"  %15549 = lshr i32 %15548, 16" -> "  %15550 = add nuw nsw i32 %15542, %15549"
"  %15550 = add nuw nsw i32 %15542, %15549"
"  %15550 = add nuw nsw i32 %15542, %15549" -> "  %15555 = add nuw nsw i32 %15550, %15554"
"  %15551 = and i32 %15548, 65535"
"  %15551 = and i32 %15548, 65535" -> "  %15553 = add nuw nsw i32 %15551, %15552"
"  %15552 = lshr i32 %15545, 16"
"  %15552 = lshr i32 %15545, 16" -> "  %15553 = add nuw nsw i32 %15551, %15552"
"  %15553 = add nuw nsw i32 %15551, %15552"
"  %15553 = add nuw nsw i32 %15551, %15552" -> "  %15616 = and i32 %15553, 65535""  %15553 = add nuw nsw i32 %15551, %15552" -> "  %15554 = lshr i32 %15553, 16"
"  %15554 = lshr i32 %15553, 16"
"  %15554 = lshr i32 %15553, 16" -> "  %15555 = add nuw nsw i32 %15550, %15554"
"  %15555 = add nuw nsw i32 %15550, %15554"
"  %15555 = add nuw nsw i32 %15550, %15554" -> "  %15591 = lshr i32 %15555, 16""  %15555 = add nuw nsw i32 %15550, %15554" -> "  %15588 = and i32 %15555, 65535"
"  %15556 = mul nuw nsw i32 %13981, 24315"
"  %15556 = mul nuw nsw i32 %13981, 24315" -> "  %15575 = and i32 %15556, 65535""  %15556 = mul nuw nsw i32 %13981, 24315" -> "  %15557 = lshr i32 %15556, 16"
"  %15557 = lshr i32 %15556, 16"
"  %15557 = lshr i32 %15556, 16" -> "  %15560 = add nuw nsw i32 %15559, %15557"
"  %15558 = mul nuw nsw i32 %13982, 24315"
"  %15558 = mul nuw nsw i32 %13982, 24315" -> "  %15561 = and i32 %15558, 2147418112""  %15558 = mul nuw nsw i32 %13982, 24315" -> "  %15559 = and i32 %15558, 65535"
"  %15559 = and i32 %15558, 65535"
"  %15559 = and i32 %15558, 65535" -> "  %15560 = add nuw nsw i32 %15559, %15557"
"  %15560 = add nuw nsw i32 %15559, %15557"
"  %15560 = add nuw nsw i32 %15559, %15557" -> "  %15562 = add nuw nsw i32 %15560, %15561"
"  %15561 = and i32 %15558, 2147418112"
"  %15561 = and i32 %15558, 2147418112" -> "  %15562 = add nuw nsw i32 %15560, %15561"
"  %15562 = add nuw nsw i32 %15560, %15561"
"  %15562 = add nuw nsw i32 %15560, %15561" -> "  %15566 = lshr i32 %15562, 16""  %15562 = add nuw nsw i32 %15560, %15561" -> "  %15564 = and i32 %15562, 65535"
"  %15563 = mul nuw nsw i32 %13981, 29744"
"  %15563 = mul nuw nsw i32 %13981, 29744" -> "  %15565 = add nuw nsw i32 %15564, %15563"
"  %15564 = and i32 %15562, 65535"
"  %15564 = and i32 %15562, 65535" -> "  %15565 = add nuw nsw i32 %15564, %15563"
"  %15565 = add nuw nsw i32 %15564, %15563"
"  %15565 = add nuw nsw i32 %15564, %15563" -> "  %15577 = and i32 %15565, 65535""  %15565 = add nuw nsw i32 %15564, %15563" -> "  %15569 = lshr i32 %15565, 16"
"  %15566 = lshr i32 %15562, 16"
"  %15566 = lshr i32 %15562, 16" -> "  %15568 = add nuw nsw i32 %15566, %15567"
"  %15567 = mul nuw nsw i32 %13982, 29744"
"  %15567 = mul nuw nsw i32 %13982, 29744" -> "  %15568 = add nuw nsw i32 %15566, %15567"
"  %15568 = add nuw nsw i32 %15566, %15567"
"  %15568 = add nuw nsw i32 %15566, %15567" -> "  %15572 = and i32 %15568, 2147418112""  %15568 = add nuw nsw i32 %15566, %15567" -> "  %15570 = and i32 %15568, 65535"
"  %15569 = lshr i32 %15565, 16"
"  %15569 = lshr i32 %15565, 16" -> "  %15571 = add nuw nsw i32 %15569, %15570"
"  %15570 = and i32 %15568, 65535"
"  %15570 = and i32 %15568, 65535" -> "  %15571 = add nuw nsw i32 %15569, %15570"
"  %15571 = add nuw nsw i32 %15569, %15570"
"  %15571 = add nuw nsw i32 %15569, %15570" -> "  %15573 = add nuw nsw i32 %15571, %15572"
"  %15572 = and i32 %15568, 2147418112"
"  %15572 = and i32 %15568, 2147418112" -> "  %15573 = add nuw nsw i32 %15571, %15572"
"  %15573 = add nuw nsw i32 %15571, %15572"
"  %15573 = add nuw nsw i32 %15571, %15572" -> "  %15581 = add nuw nsw i32 %15573, %15580"
"  %15574 = and i32 %15524, 65535"
"  %15574 = and i32 %15524, 65535" -> "  %15576 = add nuw nsw i32 %15574, %15575"
"  %15575 = and i32 %15556, 65535"
"  %15575 = and i32 %15556, 65535" -> "  %15576 = add nuw nsw i32 %15574, %15575"
"  %15576 = add nuw nsw i32 %15574, %15575"
"  %15576 = add nuw nsw i32 %15574, %15575" -> "  %15587 = and i32 %15576, 65535""  %15576 = add nuw nsw i32 %15574, %15575" -> "  %15583 = lshr i32 %15576, 16"
"  %15577 = and i32 %15565, 65535"
"  %15577 = and i32 %15565, 65535" -> "  %15579 = add nuw nsw i32 %15578, %15577"
"  %15578 = lshr i32 %15524, 16"
"  %15578 = lshr i32 %15524, 16" -> "  %15579 = add nuw nsw i32 %15578, %15577"
"  %15579 = add nuw nsw i32 %15578, %15577"
"  %15579 = add nuw nsw i32 %15578, %15577" -> "  %15582 = and i32 %15579, 65535""  %15579 = add nuw nsw i32 %15578, %15577" -> "  %15580 = lshr i32 %15579, 16"
"  %15580 = lshr i32 %15579, 16"
"  %15580 = lshr i32 %15579, 16" -> "  %15581 = add nuw nsw i32 %15573, %15580"
"  %15581 = add nuw nsw i32 %15573, %15580"
"  %15581 = add nuw nsw i32 %15573, %15580" -> "  %15586 = add nuw nsw i32 %15581, %15585"
"  %15582 = and i32 %15579, 65535"
"  %15582 = and i32 %15579, 65535" -> "  %15584 = add nuw nsw i32 %15583, %15582"
"  %15583 = lshr i32 %15576, 16"
"  %15583 = lshr i32 %15576, 16" -> "  %15584 = add nuw nsw i32 %15583, %15582"
"  %15584 = add nuw nsw i32 %15583, %15582"
"  %15584 = add nuw nsw i32 %15583, %15582" -> "  %15590 = and i32 %15584, 65535""  %15584 = add nuw nsw i32 %15583, %15582" -> "  %15585 = lshr i32 %15584, 16"
"  %15585 = lshr i32 %15584, 16"
"  %15585 = lshr i32 %15584, 16" -> "  %15586 = add nuw nsw i32 %15581, %15585"
"  %15586 = add nuw nsw i32 %15581, %15585"
"  %15586 = add nuw nsw i32 %15581, %15585" -> "  %15597 = and i32 %15586, 65535""  %15586 = add nuw nsw i32 %15581, %15585" -> "  %15599 = and i32 %15586, 2147418112"
"  %15587 = and i32 %15576, 65535"
"  %15587 = and i32 %15576, 65535" -> "  %15589 = add nuw nsw i32 %15588, %15587"
"  %15588 = and i32 %15555, 65535"
"  %15588 = and i32 %15555, 65535" -> "  %15589 = add nuw nsw i32 %15588, %15587"
"  %15589 = add nuw nsw i32 %15588, %15587"
"  %15589 = add nuw nsw i32 %15588, %15587" -> "  %15630 = and i32 %15589, 65535""  %15589 = add nuw nsw i32 %15588, %15587" -> "  %15593 = lshr i32 %15589, 16"
"  %15590 = and i32 %15584, 65535"
"  %15590 = and i32 %15584, 65535" -> "  %15592 = add nuw nsw i32 %15591, %15590"
"  %15591 = lshr i32 %15555, 16"
"  %15591 = lshr i32 %15555, 16" -> "  %15592 = add nuw nsw i32 %15591, %15590"
"  %15592 = add nuw nsw i32 %15591, %15590"
"  %15592 = add nuw nsw i32 %15591, %15590" -> "  %15596 = lshr i32 %15592, 16""  %15592 = add nuw nsw i32 %15591, %15590" -> "  %15594 = and i32 %15592, 65535"
"  %15593 = lshr i32 %15589, 16"
"  %15593 = lshr i32 %15589, 16" -> "  %15595 = add nuw nsw i32 %15593, %15594"
"  %15594 = and i32 %15592, 65535"
"  %15594 = and i32 %15592, 65535" -> "  %15595 = add nuw nsw i32 %15593, %15594"
"  %15595 = add nuw nsw i32 %15593, %15594"
"  %15595 = add nuw nsw i32 %15593, %15594" -> "  %15636 = and i32 %15595, 65535""  %15595 = add nuw nsw i32 %15593, %15594" -> "  %15601 = lshr i32 %15595, 16"
"  %15596 = lshr i32 %15592, 16"
"  %15596 = lshr i32 %15592, 16" -> "  %15598 = add nuw nsw i32 %15596, %15597"
"  %15597 = and i32 %15586, 65535"
"  %15597 = and i32 %15586, 65535" -> "  %15598 = add nuw nsw i32 %15596, %15597"
"  %15598 = add nuw nsw i32 %15596, %15597"
"  %15598 = add nuw nsw i32 %15596, %15597" -> "  %15600 = add nuw nsw i32 %15598, %15599"
"  %15599 = and i32 %15586, 2147418112"
"  %15599 = and i32 %15586, 2147418112" -> "  %15600 = add nuw nsw i32 %15598, %15599"
"  %15600 = add nuw nsw i32 %15598, %15599"
"  %15600 = add nuw nsw i32 %15598, %15599" -> "  %15602 = add nuw nsw i32 %15600, %15601"
"  %15601 = lshr i32 %15595, 16"
"  %15601 = lshr i32 %15595, 16" -> "  %15602 = add nuw nsw i32 %15600, %15601"
"  %15602 = add nuw nsw i32 %15600, %15601"
"  %15602 = add nuw nsw i32 %15600, %15601" -> "  %15640 = add nuw nsw i32 %15602, %15639"
"  %15603 = and i32 %15476, 65535"
"  %15603 = and i32 %15476, 65535" -> "  %15605 = add nuw nsw i32 %15604, %15603"
"  %15604 = and i32 %15462, 65535"
"  %15604 = and i32 %15462, 65535" -> "  %15605 = add nuw nsw i32 %15604, %15603"
"  %15605 = add nuw nsw i32 %15604, %15603"
"  %15605 = add nuw nsw i32 %15604, %15603" -> "  %15769 = and i32 %15605, 65535""  %15605 = add nuw nsw i32 %15604, %15603" -> "  %15609 = lshr i32 %15605, 16"
"  %15606 = and i32 %15485, 65535"
"  %15606 = and i32 %15485, 65535" -> "  %15608 = add nuw nsw i32 %15607, %15606"
"  %15607 = and i32 %15468, 65535"
"  %15607 = and i32 %15468, 65535" -> "  %15608 = add nuw nsw i32 %15607, %15606"
"  %15608 = add nuw nsw i32 %15607, %15606"
"  %15608 = add nuw nsw i32 %15607, %15606" -> "  %15622 = lshr i32 %15608, 16""  %15608 = add nuw nsw i32 %15607, %15606" -> "  %15610 = and i32 %15608, 65535"
"  %15609 = lshr i32 %15605, 16"
"  %15609 = lshr i32 %15605, 16" -> "  %15611 = add nuw nsw i32 %15610, %15609"
"  %15610 = and i32 %15608, 65535"
"  %15610 = and i32 %15608, 65535" -> "  %15611 = add nuw nsw i32 %15610, %15609"
"  %15611 = add nuw nsw i32 %15610, %15609"
"  %15611 = add nuw nsw i32 %15610, %15609" -> "  %15772 = and i32 %15611, 65535""  %15611 = add nuw nsw i32 %15610, %15609" -> "  %15623 = lshr i32 %15611, 16"
"  %15612 = and i32 %15475, 65535"
"  %15612 = and i32 %15475, 65535" -> "  %15614 = add nuw nsw i32 %15612, %15613"
"  %15613 = and i32 %15545, 65535"
"  %15613 = and i32 %15545, 65535" -> "  %15614 = add nuw nsw i32 %15612, %15613"
"  %15614 = add nuw nsw i32 %15612, %15613"
"  %15614 = add nuw nsw i32 %15612, %15613" -> "  %15621 = and i32 %15614, 65535""  %15614 = add nuw nsw i32 %15612, %15613" -> "  %15618 = lshr i32 %15614, 16"
"  %15615 = lshr i32 %15475, 16"
"  %15615 = lshr i32 %15475, 16" -> "  %15617 = add nuw nsw i32 %15615, %15616"
"  %15616 = and i32 %15553, 65535"
"  %15616 = and i32 %15553, 65535" -> "  %15617 = add nuw nsw i32 %15615, %15616"
"  %15617 = add nuw nsw i32 %15615, %15616"
"  %15617 = add nuw nsw i32 %15615, %15616" -> "  %15629 = lshr i32 %15617, 16""  %15617 = add nuw nsw i32 %15615, %15616" -> "  %15619 = and i32 %15617, 65535"
"  %15618 = lshr i32 %15614, 16"
"  %15618 = lshr i32 %15614, 16" -> "  %15620 = add nuw nsw i32 %15619, %15618"
"  %15619 = and i32 %15617, 65535"
"  %15619 = and i32 %15617, 65535" -> "  %15620 = add nuw nsw i32 %15619, %15618"
"  %15620 = add nuw nsw i32 %15619, %15618"
"  %15620 = add nuw nsw i32 %15619, %15618" -> "  %15632 = lshr i32 %15620, 16""  %15620 = add nuw nsw i32 %15619, %15618" -> "  %15627 = and i32 %15620, 65535"
"  %15621 = and i32 %15614, 65535"
"  %15621 = and i32 %15614, 65535" -> "  %15624 = add nuw nsw i32 %15621, %15622"
"  %15622 = lshr i32 %15608, 16"
"  %15622 = lshr i32 %15608, 16" -> "  %15624 = add nuw nsw i32 %15621, %15622"
"  %15623 = lshr i32 %15611, 16"
"  %15623 = lshr i32 %15611, 16" -> "  %15625 = add nuw nsw i32 %15624, %15623"
"  %15624 = add nuw nsw i32 %15621, %15622"
"  %15624 = add nuw nsw i32 %15621, %15622" -> "  %15625 = add nuw nsw i32 %15624, %15623"
"  %15625 = add nuw nsw i32 %15624, %15623"
"  %15625 = add nuw nsw i32 %15624, %15623" -> "  %15779 = and i32 %15625, 65535""  %15625 = add nuw nsw i32 %15624, %15623" -> "  %15626 = lshr i32 %15625, 16"
"  %15626 = lshr i32 %15625, 16"
"  %15626 = lshr i32 %15625, 16" -> "  %15628 = add nuw nsw i32 %15626, %15627"
"  %15627 = and i32 %15620, 65535"
"  %15627 = and i32 %15620, 65535" -> "  %15628 = add nuw nsw i32 %15626, %15627"
"  %15628 = add nuw nsw i32 %15626, %15627"
"  %15628 = add nuw nsw i32 %15626, %15627" -> "  %15783 = and i32 %15628, 65535""  %15628 = add nuw nsw i32 %15626, %15627" -> "  %15634 = lshr i32 %15628, 16"
"  %15629 = lshr i32 %15617, 16"
"  %15629 = lshr i32 %15617, 16" -> "  %15631 = add nuw nsw i32 %15630, %15629"
"  %15630 = and i32 %15589, 65535"
"  %15630 = and i32 %15589, 65535" -> "  %15631 = add nuw nsw i32 %15630, %15629"
"  %15631 = add nuw nsw i32 %15630, %15629"
"  %15631 = add nuw nsw i32 %15630, %15629" -> "  %15633 = add nuw nsw i32 %15631, %15632"
"  %15632 = lshr i32 %15620, 16"
"  %15632 = lshr i32 %15620, 16" -> "  %15633 = add nuw nsw i32 %15631, %15632"
"  %15633 = add nuw nsw i32 %15631, %15632"
"  %15633 = add nuw nsw i32 %15631, %15632" -> "  %15635 = add nuw nsw i32 %15633, %15634"
"  %15634 = lshr i32 %15628, 16"
"  %15634 = lshr i32 %15628, 16" -> "  %15635 = add nuw nsw i32 %15633, %15634"
"  %15635 = add nuw nsw i32 %15633, %15634"
"  %15635 = add nuw nsw i32 %15633, %15634" -> "  %15934 = and i32 %15635, 65535""  %15635 = add nuw nsw i32 %15633, %15634" -> "  %15637 = lshr i32 %15635, 16"
"  %15636 = and i32 %15595, 65535"
"  %15636 = and i32 %15595, 65535" -> "  %15638 = add nuw nsw i32 %15637, %15636"
"  %15637 = lshr i32 %15635, 16"
"  %15637 = lshr i32 %15635, 16" -> "  %15638 = add nuw nsw i32 %15637, %15636"
"  %15638 = add nuw nsw i32 %15637, %15636"
"  %15638 = add nuw nsw i32 %15637, %15636" -> "  %15937 = and i32 %15638, 65535""  %15638 = add nuw nsw i32 %15637, %15636" -> "  %15639 = lshr i32 %15638, 16"
"  %15639 = lshr i32 %15638, 16"
"  %15639 = lshr i32 %15638, 16" -> "  %15640 = add nuw nsw i32 %15602, %15639"
"  %15640 = add nuw nsw i32 %15602, %15639"
"  %15640 = add nuw nsw i32 %15602, %15639" -> "  %15942 = and i32 %15640, 65535""  %15640 = add nuw nsw i32 %15602, %15639" -> "  %15945 = lshr i32 %15640, 16"
"  %15641 = mul nuw nsw i32 %13827, 4087"
"  %15641 = mul nuw nsw i32 %13827, 4087" -> "  %15768 = and i32 %15641, 65535""  %15641 = mul nuw nsw i32 %13827, 4087" -> "  %15642 = lshr i32 %15641, 16""  %15641 = mul nuw nsw i32 %13827, 4087" -> "  store i32 %15641, i32* %2790, align 1, !noalias !35"
"  store i32 %15641, i32* %2790, align 1, !noalias !35"

"  %15642 = lshr i32 %15641, 16"
"  %15642 = lshr i32 %15641, 16" -> "  %15645 = add nuw nsw i32 %15644, %15642"
"  %15643 = mul nuw nsw i32 %13828, 4087"
"  %15643 = mul nuw nsw i32 %13828, 4087" -> "  %15646 = and i32 %15643, 268369920""  %15643 = mul nuw nsw i32 %13828, 4087" -> "  %15644 = and i32 %15643, 65535"
"  %15644 = and i32 %15643, 65535"
"  %15644 = and i32 %15643, 65535" -> "  %15645 = add nuw nsw i32 %15644, %15642"
"  %15645 = add nuw nsw i32 %15644, %15642"
"  %15645 = add nuw nsw i32 %15644, %15642" -> "  %15647 = add nuw nsw i32 %15645, %15646"
"  %15646 = and i32 %15643, 268369920"
"  %15646 = and i32 %15643, 268369920" -> "  %15647 = add nuw nsw i32 %15645, %15646"
"  %15647 = add nuw nsw i32 %15645, %15646"
"  %15647 = add nuw nsw i32 %15645, %15646" -> "  %15651 = lshr i32 %15647, 16""  %15647 = add nuw nsw i32 %15645, %15646" -> "  %15649 = and i32 %15647, 65535"
"  %15648 = mul nuw nsw i32 %13827, 11561"
"  %15648 = mul nuw nsw i32 %13827, 11561" -> "  %15650 = add nuw nsw i32 %15649, %15648"
"  %15649 = and i32 %15647, 65535"
"  %15649 = and i32 %15647, 65535" -> "  %15650 = add nuw nsw i32 %15649, %15648"
"  %15650 = add nuw nsw i32 %15649, %15648"
"  %15650 = add nuw nsw i32 %15649, %15648" -> "  %15771 = and i32 %15650, 65535""  %15650 = add nuw nsw i32 %15649, %15648" -> "  %15654 = lshr i32 %15650, 16"
"  %15651 = lshr i32 %15647, 16"
"  %15651 = lshr i32 %15647, 16" -> "  %15653 = add nuw nsw i32 %15651, %15652"
"  %15652 = mul nuw nsw i32 %13828, 11561"
"  %15652 = mul nuw nsw i32 %13828, 11561" -> "  %15653 = add nuw nsw i32 %15651, %15652"
"  %15653 = add nuw nsw i32 %15651, %15652"
"  %15653 = add nuw nsw i32 %15651, %15652" -> "  %15657 = and i32 %15653, 2147418112""  %15653 = add nuw nsw i32 %15651, %15652" -> "  %15655 = and i32 %15653, 65535"
"  %15654 = lshr i32 %15650, 16"
"  %15654 = lshr i32 %15650, 16" -> "  %15656 = add nuw nsw i32 %15654, %15655"
"  %15655 = and i32 %15653, 65535"
"  %15655 = and i32 %15653, 65535" -> "  %15656 = add nuw nsw i32 %15654, %15655"
"  %15656 = add nuw nsw i32 %15654, %15655"
"  %15656 = add nuw nsw i32 %15654, %15655" -> "  %15658 = add nuw nsw i32 %15656, %15657"
"  %15657 = and i32 %15653, 2147418112"
"  %15657 = and i32 %15653, 2147418112" -> "  %15658 = add nuw nsw i32 %15656, %15657"
"  %15658 = add nuw nsw i32 %15656, %15657"
"  %15658 = add nuw nsw i32 %15656, %15657" -> "  %15681 = lshr i32 %15658, 16""  %15658 = add nuw nsw i32 %15656, %15657" -> "  %15677 = and i32 %15658, 65535"
"  %15659 = mul nuw nsw i32 %13848, 4087"
"  %15659 = mul nuw nsw i32 %13848, 4087" -> "  %15678 = and i32 %15659, 65535""  %15659 = mul nuw nsw i32 %13848, 4087" -> "  %15660 = lshr i32 %15659, 16"
"  %15660 = lshr i32 %15659, 16"
"  %15660 = lshr i32 %15659, 16" -> "  %15663 = add nuw nsw i32 %15662, %15660"
"  %15661 = mul nuw nsw i32 %13847, 4087"
"  %15661 = mul nuw nsw i32 %13847, 4087" -> "  %15664 = and i32 %15661, 268369920""  %15661 = mul nuw nsw i32 %13847, 4087" -> "  %15662 = and i32 %15661, 65535"
"  %15662 = and i32 %15661, 65535"
"  %15662 = and i32 %15661, 65535" -> "  %15663 = add nuw nsw i32 %15662, %15660"
"  %15663 = add nuw nsw i32 %15662, %15660"
"  %15663 = add nuw nsw i32 %15662, %15660" -> "  %15665 = add nuw nsw i32 %15663, %15664"
"  %15664 = and i32 %15661, 268369920"
"  %15664 = and i32 %15661, 268369920" -> "  %15665 = add nuw nsw i32 %15663, %15664"
"  %15665 = add nuw nsw i32 %15663, %15664"
"  %15665 = add nuw nsw i32 %15663, %15664" -> "  %15669 = lshr i32 %15665, 16""  %15665 = add nuw nsw i32 %15663, %15664" -> "  %15667 = and i32 %15665, 65535"
"  %15666 = mul nuw nsw i32 %13848, 11561"
"  %15666 = mul nuw nsw i32 %13848, 11561" -> "  %15668 = add nuw nsw i32 %15667, %15666"
"  %15667 = and i32 %15665, 65535"
"  %15667 = and i32 %15665, 65535" -> "  %15668 = add nuw nsw i32 %15667, %15666"
"  %15668 = add nuw nsw i32 %15667, %15666"
"  %15668 = add nuw nsw i32 %15667, %15666" -> "  %15680 = and i32 %15668, 65535""  %15668 = add nuw nsw i32 %15667, %15666" -> "  %15672 = lshr i32 %15668, 16"
"  %15669 = lshr i32 %15665, 16"
"  %15669 = lshr i32 %15665, 16" -> "  %15671 = add nuw nsw i32 %15669, %15670"
"  %15670 = mul nuw nsw i32 %13847, 11561"
"  %15670 = mul nuw nsw i32 %13847, 11561" -> "  %15671 = add nuw nsw i32 %15669, %15670"
"  %15671 = add nuw nsw i32 %15669, %15670"
"  %15671 = add nuw nsw i32 %15669, %15670" -> "  %15675 = and i32 %15671, 2147418112""  %15671 = add nuw nsw i32 %15669, %15670" -> "  %15673 = and i32 %15671, 65535"
"  %15672 = lshr i32 %15668, 16"
"  %15672 = lshr i32 %15668, 16" -> "  %15674 = add nuw nsw i32 %15672, %15673"
"  %15673 = and i32 %15671, 65535"
"  %15673 = and i32 %15671, 65535" -> "  %15674 = add nuw nsw i32 %15672, %15673"
"  %15674 = add nuw nsw i32 %15672, %15673"
"  %15674 = add nuw nsw i32 %15672, %15673" -> "  %15676 = add nuw nsw i32 %15674, %15675"
"  %15675 = and i32 %15671, 2147418112"
"  %15675 = and i32 %15671, 2147418112" -> "  %15676 = add nuw nsw i32 %15674, %15675"
"  %15676 = add nuw nsw i32 %15674, %15675"
"  %15676 = add nuw nsw i32 %15674, %15675" -> "  %15684 = add nuw nsw i32 %15676, %15683"
"  %15677 = and i32 %15658, 65535"
"  %15677 = and i32 %15658, 65535" -> "  %15679 = add nuw nsw i32 %15677, %15678"
"  %15678 = and i32 %15659, 65535"
"  %15678 = and i32 %15659, 65535" -> "  %15679 = add nuw nsw i32 %15677, %15678"
"  %15679 = add nuw nsw i32 %15677, %15678"
"  %15679 = add nuw nsw i32 %15677, %15678" -> "  %15708 = and i32 %15679, 65535""  %15679 = add nuw nsw i32 %15677, %15678" -> "  %15686 = lshr i32 %15679, 16"
"  %15680 = and i32 %15668, 65535"
"  %15680 = and i32 %15668, 65535" -> "  %15682 = add nuw nsw i32 %15680, %15681"
"  %15681 = lshr i32 %15658, 16"
"  %15681 = lshr i32 %15658, 16" -> "  %15682 = add nuw nsw i32 %15680, %15681"
"  %15682 = add nuw nsw i32 %15680, %15681"
"  %15682 = add nuw nsw i32 %15680, %15681" -> "  %15685 = and i32 %15682, 65535""  %15682 = add nuw nsw i32 %15680, %15681" -> "  %15683 = lshr i32 %15682, 16"
"  %15683 = lshr i32 %15682, 16"
"  %15683 = lshr i32 %15682, 16" -> "  %15684 = add nuw nsw i32 %15676, %15683"
"  %15684 = add nuw nsw i32 %15676, %15683"
"  %15684 = add nuw nsw i32 %15676, %15683" -> "  %15689 = add nuw nsw i32 %15684, %15688"
"  %15685 = and i32 %15682, 65535"
"  %15685 = and i32 %15682, 65535" -> "  %15687 = add nuw nsw i32 %15685, %15686"
"  %15686 = lshr i32 %15679, 16"
"  %15686 = lshr i32 %15679, 16" -> "  %15687 = add nuw nsw i32 %15685, %15686"
"  %15687 = add nuw nsw i32 %15685, %15686"
"  %15687 = add nuw nsw i32 %15685, %15686" -> "  %15711 = and i32 %15687, 65535""  %15687 = add nuw nsw i32 %15685, %15686" -> "  %15688 = lshr i32 %15687, 16"
"  %15688 = lshr i32 %15687, 16"
"  %15688 = lshr i32 %15687, 16" -> "  %15689 = add nuw nsw i32 %15684, %15688"
"  %15689 = add nuw nsw i32 %15684, %15688"
"  %15689 = add nuw nsw i32 %15684, %15688" -> "  %15743 = lshr i32 %15689, 16""  %15689 = add nuw nsw i32 %15684, %15688" -> "  %15739 = and i32 %15689, 65535"
"  %15690 = mul nuw nsw i32 %13827, 21884"
"  %15690 = mul nuw nsw i32 %13827, 21884" -> "  %15709 = and i32 %15690, 65532""  %15690 = mul nuw nsw i32 %13827, 21884" -> "  %15691 = lshr i32 %15690, 16"
"  %15691 = lshr i32 %15690, 16"
"  %15691 = lshr i32 %15690, 16" -> "  %15694 = add nuw nsw i32 %15693, %15691"
"  %15692 = mul nuw nsw i32 %13828, 21884"
"  %15692 = mul nuw nsw i32 %13828, 21884" -> "  %15695 = and i32 %15692, 2147418112""  %15692 = mul nuw nsw i32 %13828, 21884" -> "  %15693 = and i32 %15692, 65532"
"  %15693 = and i32 %15692, 65532"
"  %15693 = and i32 %15692, 65532" -> "  %15694 = add nuw nsw i32 %15693, %15691"
"  %15694 = add nuw nsw i32 %15693, %15691"
"  %15694 = add nuw nsw i32 %15693, %15691" -> "  %15696 = add nuw nsw i32 %15694, %15695"
"  %15695 = and i32 %15692, 2147418112"
"  %15695 = and i32 %15692, 2147418112" -> "  %15696 = add nuw nsw i32 %15694, %15695"
"  %15696 = add nuw nsw i32 %15694, %15695"
"  %15696 = add nuw nsw i32 %15694, %15695" -> "  %15700 = lshr i32 %15696, 16""  %15696 = add nuw nsw i32 %15694, %15695" -> "  %15698 = and i32 %15696, 65535"
"  %15697 = mul nuw i32 %13827, 36786"
"  %15697 = mul nuw i32 %13827, 36786" -> "  %15699 = add nuw i32 %15698, %15697"
"  %15698 = and i32 %15696, 65535"
"  %15698 = and i32 %15696, 65535" -> "  %15699 = add nuw i32 %15698, %15697"
"  %15699 = add nuw i32 %15698, %15697"
"  %15699 = add nuw i32 %15698, %15697" -> "  %15712 = and i32 %15699, 65535""  %15699 = add nuw i32 %15698, %15697" -> "  %15703 = lshr i32 %15699, 16"
"  %15700 = lshr i32 %15696, 16"
"  %15700 = lshr i32 %15696, 16" -> "  %15702 = add nuw i32 %15700, %15701"
"  %15701 = mul nuw i32 %13828, 36786"
"  %15701 = mul nuw i32 %13828, 36786" -> "  %15702 = add nuw i32 %15700, %15701"
"  %15702 = add nuw i32 %15700, %15701"
"  %15702 = add nuw i32 %15700, %15701" -> "  %15706 = and i32 %15702, -65536""  %15702 = add nuw i32 %15700, %15701" -> "  %15704 = and i32 %15702, 65535"
"  %15703 = lshr i32 %15699, 16"
"  %15703 = lshr i32 %15699, 16" -> "  %15705 = add nuw nsw i32 %15703, %15704"
"  %15704 = and i32 %15702, 65535"
"  %15704 = and i32 %15702, 65535" -> "  %15705 = add nuw nsw i32 %15703, %15704"
"  %15705 = add nuw nsw i32 %15703, %15704"
"  %15705 = add nuw nsw i32 %15703, %15704" -> "  %15707 = add nuw i32 %15705, %15706"
"  %15706 = and i32 %15702, -65536"
"  %15706 = and i32 %15702, -65536" -> "  %15707 = add nuw i32 %15705, %15706"
"  %15707 = add nuw i32 %15705, %15706"
"  %15707 = add nuw i32 %15705, %15706" -> "  %15715 = add nuw i32 %15707, %15714"
"  %15708 = and i32 %15679, 65535"
"  %15708 = and i32 %15679, 65535" -> "  %15710 = add nuw nsw i32 %15708, %15709"
"  %15709 = and i32 %15690, 65532"
"  %15709 = and i32 %15690, 65532" -> "  %15710 = add nuw nsw i32 %15708, %15709"
"  %15710 = add nuw nsw i32 %15708, %15709"
"  %15710 = add nuw nsw i32 %15708, %15709" -> "  %15780 = and i32 %15710, 65535""  %15710 = add nuw nsw i32 %15708, %15709" -> "  %15717 = lshr i32 %15710, 16"
"  %15711 = and i32 %15687, 65535"
"  %15711 = and i32 %15687, 65535" -> "  %15713 = add nuw nsw i32 %15711, %15712"
"  %15712 = and i32 %15699, 65535"
"  %15712 = and i32 %15699, 65535" -> "  %15713 = add nuw nsw i32 %15711, %15712"
"  %15713 = add nuw nsw i32 %15711, %15712"
"  %15713 = add nuw nsw i32 %15711, %15712" -> "  %15716 = and i32 %15713, 65535""  %15713 = add nuw nsw i32 %15711, %15712" -> "  %15714 = lshr i32 %15713, 16"
"  %15714 = lshr i32 %15713, 16"
"  %15714 = lshr i32 %15713, 16" -> "  %15715 = add nuw i32 %15707, %15714"
"  %15715 = add nuw i32 %15707, %15714"
"  %15715 = add nuw i32 %15707, %15714" -> "  %15720 = add nuw i32 %15715, %15719"
"  %15716 = and i32 %15713, 65535"
"  %15716 = and i32 %15713, 65535" -> "  %15718 = add nuw nsw i32 %15716, %15717"
"  %15717 = lshr i32 %15710, 16"
"  %15717 = lshr i32 %15710, 16" -> "  %15718 = add nuw nsw i32 %15716, %15717"
"  %15718 = add nuw nsw i32 %15716, %15717"
"  %15718 = add nuw nsw i32 %15716, %15717" -> "  %15782 = and i32 %15718, 65535""  %15718 = add nuw nsw i32 %15716, %15717" -> "  %15719 = lshr i32 %15718, 16"
"  %15719 = lshr i32 %15718, 16"
"  %15719 = lshr i32 %15718, 16" -> "  %15720 = add nuw i32 %15715, %15719"
"  %15720 = add nuw i32 %15715, %15719"
"  %15720 = add nuw i32 %15715, %15719" -> "  %15755 = lshr i32 %15720, 16""  %15720 = add nuw i32 %15715, %15719" -> "  %15753 = and i32 %15720, 65535"
"  %15721 = mul nuw nsw i32 %13848, 21884"
"  %15721 = mul nuw nsw i32 %13848, 21884" -> "  %15740 = and i32 %15721, 65532""  %15721 = mul nuw nsw i32 %13848, 21884" -> "  %15722 = lshr i32 %15721, 16"
"  %15722 = lshr i32 %15721, 16"
"  %15722 = lshr i32 %15721, 16" -> "  %15725 = add nuw nsw i32 %15724, %15722"
"  %15723 = mul nuw nsw i32 %13847, 21884"
"  %15723 = mul nuw nsw i32 %13847, 21884" -> "  %15726 = and i32 %15723, 2147418112""  %15723 = mul nuw nsw i32 %13847, 21884" -> "  %15724 = and i32 %15723, 65532"
"  %15724 = and i32 %15723, 65532"
"  %15724 = and i32 %15723, 65532" -> "  %15725 = add nuw nsw i32 %15724, %15722"
"  %15725 = add nuw nsw i32 %15724, %15722"
"  %15725 = add nuw nsw i32 %15724, %15722" -> "  %15727 = add nuw nsw i32 %15725, %15726"
"  %15726 = and i32 %15723, 2147418112"
"  %15726 = and i32 %15723, 2147418112" -> "  %15727 = add nuw nsw i32 %15725, %15726"
"  %15727 = add nuw nsw i32 %15725, %15726"
"  %15727 = add nuw nsw i32 %15725, %15726" -> "  %15731 = lshr i32 %15727, 16""  %15727 = add nuw nsw i32 %15725, %15726" -> "  %15729 = and i32 %15727, 65535"
"  %15728 = mul nuw i32 %13848, 36786"
"  %15728 = mul nuw i32 %13848, 36786" -> "  %15730 = add nuw i32 %15729, %15728"
"  %15729 = and i32 %15727, 65535"
"  %15729 = and i32 %15727, 65535" -> "  %15730 = add nuw i32 %15729, %15728"
"  %15730 = add nuw i32 %15729, %15728"
"  %15730 = add nuw i32 %15729, %15728" -> "  %15742 = and i32 %15730, 65535""  %15730 = add nuw i32 %15729, %15728" -> "  %15734 = lshr i32 %15730, 16"
"  %15731 = lshr i32 %15727, 16"
"  %15731 = lshr i32 %15727, 16" -> "  %15733 = add nuw i32 %15731, %15732"
"  %15732 = mul nuw i32 %13847, 36786"
"  %15732 = mul nuw i32 %13847, 36786" -> "  %15733 = add nuw i32 %15731, %15732"
"  %15733 = add nuw i32 %15731, %15732"
"  %15733 = add nuw i32 %15731, %15732" -> "  %15737 = and i32 %15733, -65536""  %15733 = add nuw i32 %15731, %15732" -> "  %15735 = and i32 %15733, 65535"
"  %15734 = lshr i32 %15730, 16"
"  %15734 = lshr i32 %15730, 16" -> "  %15736 = add nuw nsw i32 %15734, %15735"
"  %15735 = and i32 %15733, 65535"
"  %15735 = and i32 %15733, 65535" -> "  %15736 = add nuw nsw i32 %15734, %15735"
"  %15736 = add nuw nsw i32 %15734, %15735"
"  %15736 = add nuw nsw i32 %15734, %15735" -> "  %15738 = add nuw i32 %15736, %15737"
"  %15737 = and i32 %15733, -65536"
"  %15737 = and i32 %15733, -65536" -> "  %15738 = add nuw i32 %15736, %15737"
"  %15738 = add nuw i32 %15736, %15737"
"  %15738 = add nuw i32 %15736, %15737" -> "  %15746 = add nuw i32 %15738, %15745"
"  %15739 = and i32 %15689, 65535"
"  %15739 = and i32 %15689, 65535" -> "  %15741 = add nuw nsw i32 %15739, %15740"
"  %15740 = and i32 %15721, 65532"
"  %15740 = and i32 %15721, 65532" -> "  %15741 = add nuw nsw i32 %15739, %15740"
"  %15741 = add nuw nsw i32 %15739, %15740"
"  %15741 = add nuw nsw i32 %15739, %15740" -> "  %15752 = and i32 %15741, 65535""  %15741 = add nuw nsw i32 %15739, %15740" -> "  %15748 = lshr i32 %15741, 16"
"  %15742 = and i32 %15730, 65535"
"  %15742 = and i32 %15730, 65535" -> "  %15744 = add nuw nsw i32 %15743, %15742"
"  %15743 = lshr i32 %15689, 16"
"  %15743 = lshr i32 %15689, 16" -> "  %15744 = add nuw nsw i32 %15743, %15742"
"  %15744 = add nuw nsw i32 %15743, %15742"
"  %15744 = add nuw nsw i32 %15743, %15742" -> "  %15747 = and i32 %15744, 65535""  %15744 = add nuw nsw i32 %15743, %15742" -> "  %15745 = lshr i32 %15744, 16"
"  %15745 = lshr i32 %15744, 16"
"  %15745 = lshr i32 %15744, 16" -> "  %15746 = add nuw i32 %15738, %15745"
"  %15746 = add nuw i32 %15738, %15745"
"  %15746 = add nuw i32 %15738, %15745" -> "  %15751 = add nuw i32 %15746, %15750"
"  %15747 = and i32 %15744, 65535"
"  %15747 = and i32 %15744, 65535" -> "  %15749 = add nuw nsw i32 %15748, %15747"
"  %15748 = lshr i32 %15741, 16"
"  %15748 = lshr i32 %15741, 16" -> "  %15749 = add nuw nsw i32 %15748, %15747"
"  %15749 = add nuw nsw i32 %15748, %15747"
"  %15749 = add nuw nsw i32 %15748, %15747" -> "  %15756 = and i32 %15749, 65535""  %15749 = add nuw nsw i32 %15748, %15747" -> "  %15750 = lshr i32 %15749, 16"
"  %15750 = lshr i32 %15749, 16"
"  %15750 = lshr i32 %15749, 16" -> "  %15751 = add nuw i32 %15746, %15750"
"  %15751 = add nuw i32 %15746, %15750"
"  %15751 = add nuw i32 %15746, %15750" -> "  %15762 = and i32 %15751, 65535""  %15751 = add nuw i32 %15746, %15750" -> "  %15764 = and i32 %15751, -65536"
"  %15752 = and i32 %15741, 65535"
"  %15752 = and i32 %15741, 65535" -> "  %15754 = add nuw nsw i32 %15753, %15752"
"  %15753 = and i32 %15720, 65535"
"  %15753 = and i32 %15720, 65535" -> "  %15754 = add nuw nsw i32 %15753, %15752"
"  %15754 = add nuw nsw i32 %15753, %15752"
"  %15754 = add nuw nsw i32 %15753, %15752" -> "  %15795 = and i32 %15754, 65535""  %15754 = add nuw nsw i32 %15753, %15752" -> "  %15758 = lshr i32 %15754, 16"
"  %15755 = lshr i32 %15720, 16"
"  %15755 = lshr i32 %15720, 16" -> "  %15757 = add nuw nsw i32 %15755, %15756"
"  %15756 = and i32 %15749, 65535"
"  %15756 = and i32 %15749, 65535" -> "  %15757 = add nuw nsw i32 %15755, %15756"
"  %15757 = add nuw nsw i32 %15755, %15756"
"  %15757 = add nuw nsw i32 %15755, %15756" -> "  %15761 = lshr i32 %15757, 16""  %15757 = add nuw nsw i32 %15755, %15756" -> "  %15759 = and i32 %15757, 65535"
"  %15758 = lshr i32 %15754, 16"
"  %15758 = lshr i32 %15754, 16" -> "  %15760 = add nuw nsw i32 %15759, %15758"
"  %15759 = and i32 %15757, 65535"
"  %15759 = and i32 %15757, 65535" -> "  %15760 = add nuw nsw i32 %15759, %15758"
"  %15760 = add nuw nsw i32 %15759, %15758"
"  %15760 = add nuw nsw i32 %15759, %15758" -> "  %15801 = and i32 %15760, 65535""  %15760 = add nuw nsw i32 %15759, %15758" -> "  %15766 = lshr i32 %15760, 16"
"  %15761 = lshr i32 %15757, 16"
"  %15761 = lshr i32 %15757, 16" -> "  %15763 = add nuw nsw i32 %15761, %15762"
"  %15762 = and i32 %15751, 65535"
"  %15762 = and i32 %15751, 65535" -> "  %15763 = add nuw nsw i32 %15761, %15762"
"  %15763 = add nuw nsw i32 %15761, %15762"
"  %15763 = add nuw nsw i32 %15761, %15762" -> "  %15765 = add nuw i32 %15763, %15764"
"  %15764 = and i32 %15751, -65536"
"  %15764 = and i32 %15751, -65536" -> "  %15765 = add nuw i32 %15763, %15764"
"  %15765 = add nuw i32 %15763, %15764"
"  %15765 = add nuw i32 %15763, %15764" -> "  %15767 = add nuw i32 %15765, %15766"
"  %15766 = lshr i32 %15760, 16"
"  %15766 = lshr i32 %15760, 16" -> "  %15767 = add nuw i32 %15765, %15766"
"  %15767 = add nuw i32 %15765, %15766"
"  %15767 = add nuw i32 %15765, %15766" -> "  %15805 = add nuw i32 %15767, %15804"
"  %15768 = and i32 %15641, 65535"
"  %15768 = and i32 %15641, 65535" -> "  %15770 = add nuw nsw i32 %15769, %15768"
"  %15769 = and i32 %15605, 65535"
"  %15769 = and i32 %15605, 65535" -> "  %15770 = add nuw nsw i32 %15769, %15768"
"  %15770 = add nuw nsw i32 %15769, %15768"
"  %15770 = add nuw nsw i32 %15769, %15768" -> "  %16036 = and i32 %15770, 65535""  %15770 = add nuw nsw i32 %15769, %15768" -> "  %15774 = lshr i32 %15770, 16"
"  %15771 = and i32 %15650, 65535"
"  %15771 = and i32 %15650, 65535" -> "  %15773 = add nuw nsw i32 %15772, %15771"
"  %15772 = and i32 %15611, 65535"
"  %15772 = and i32 %15611, 65535" -> "  %15773 = add nuw nsw i32 %15772, %15771"
"  %15773 = add nuw nsw i32 %15772, %15771"
"  %15773 = add nuw nsw i32 %15772, %15771" -> "  %15777 = lshr i32 %15773, 16""  %15773 = add nuw nsw i32 %15772, %15771" -> "  %15775 = and i32 %15773, 65535"
"  %15774 = lshr i32 %15770, 16"
"  %15774 = lshr i32 %15770, 16" -> "  %15776 = add nuw nsw i32 %15775, %15774"
"  %15775 = and i32 %15773, 65535"
"  %15775 = and i32 %15773, 65535" -> "  %15776 = add nuw nsw i32 %15775, %15774"
"  %15776 = add nuw nsw i32 %15775, %15774"
"  %15776 = add nuw nsw i32 %15775, %15774" -> "  %16039 = and i32 %15776, 65535""  %15776 = add nuw nsw i32 %15775, %15774" -> "  %15778 = lshr i32 %15776, 16"
"  %15777 = lshr i32 %15773, 16"
"  %15777 = lshr i32 %15773, 16" -> "  %15789 = add nuw nsw i32 %15778, %15777"
"  %15778 = lshr i32 %15776, 16"
"  %15778 = lshr i32 %15776, 16" -> "  %15789 = add nuw nsw i32 %15778, %15777"
"  %15779 = and i32 %15625, 65535"
"  %15779 = and i32 %15625, 65535" -> "  %15781 = add nuw nsw i32 %15779, %15780"
"  %15780 = and i32 %15710, 65535"
"  %15780 = and i32 %15710, 65535" -> "  %15781 = add nuw nsw i32 %15779, %15780"
"  %15781 = add nuw nsw i32 %15779, %15780"
"  %15781 = add nuw nsw i32 %15779, %15780" -> "  %15788 = and i32 %15781, 65535""  %15781 = add nuw nsw i32 %15779, %15780" -> "  %15785 = lshr i32 %15781, 16"
"  %15782 = and i32 %15718, 65535"
"  %15782 = and i32 %15718, 65535" -> "  %15784 = add nuw nsw i32 %15783, %15782"
"  %15783 = and i32 %15628, 65535"
"  %15783 = and i32 %15628, 65535" -> "  %15784 = add nuw nsw i32 %15783, %15782"
"  %15784 = add nuw nsw i32 %15783, %15782"
"  %15784 = add nuw nsw i32 %15783, %15782" -> "  %15794 = lshr i32 %15784, 16""  %15784 = add nuw nsw i32 %15783, %15782" -> "  %15786 = and i32 %15784, 65535"
"  %15785 = lshr i32 %15781, 16"
"  %15785 = lshr i32 %15781, 16" -> "  %15787 = add nuw nsw i32 %15786, %15785"
"  %15786 = and i32 %15784, 65535"
"  %15786 = and i32 %15784, 65535" -> "  %15787 = add nuw nsw i32 %15786, %15785"
"  %15787 = add nuw nsw i32 %15786, %15785"
"  %15787 = add nuw nsw i32 %15786, %15785" -> "  %15797 = lshr i32 %15787, 16""  %15787 = add nuw nsw i32 %15786, %15785" -> "  %15792 = and i32 %15787, 65535"
"  %15788 = and i32 %15781, 65535"
"  %15788 = and i32 %15781, 65535" -> "  %15790 = add nuw nsw i32 %15789, %15788"
"  %15789 = add nuw nsw i32 %15778, %15777"
"  %15789 = add nuw nsw i32 %15778, %15777" -> "  %15790 = add nuw nsw i32 %15789, %15788"
"  %15790 = add nuw nsw i32 %15789, %15788"
"  %15790 = add nuw nsw i32 %15789, %15788" -> "  %16045 = and i32 %15790, 65535""  %15790 = add nuw nsw i32 %15789, %15788" -> "  %15791 = lshr i32 %15790, 16"
"  %15791 = lshr i32 %15790, 16"
"  %15791 = lshr i32 %15790, 16" -> "  %15793 = add nuw nsw i32 %15792, %15791"
"  %15792 = and i32 %15787, 65535"
"  %15792 = and i32 %15787, 65535" -> "  %15793 = add nuw nsw i32 %15792, %15791"
"  %15793 = add nuw nsw i32 %15792, %15791"
"  %15793 = add nuw nsw i32 %15792, %15791" -> "  %16048 = and i32 %15793, 65535""  %15793 = add nuw nsw i32 %15792, %15791" -> "  %15799 = lshr i32 %15793, 16"
"  %15794 = lshr i32 %15784, 16"
"  %15794 = lshr i32 %15784, 16" -> "  %15796 = add nuw nsw i32 %15794, %15795"
"  %15795 = and i32 %15754, 65535"
"  %15795 = and i32 %15754, 65535" -> "  %15796 = add nuw nsw i32 %15794, %15795"
"  %15796 = add nuw nsw i32 %15794, %15795"
"  %15796 = add nuw nsw i32 %15794, %15795" -> "  %15798 = add nuw nsw i32 %15796, %15797"
"  %15797 = lshr i32 %15787, 16"
"  %15797 = lshr i32 %15787, 16" -> "  %15798 = add nuw nsw i32 %15796, %15797"
"  %15798 = add nuw nsw i32 %15796, %15797"
"  %15798 = add nuw nsw i32 %15796, %15797" -> "  %15800 = add nuw nsw i32 %15798, %15799"
"  %15799 = lshr i32 %15793, 16"
"  %15799 = lshr i32 %15793, 16" -> "  %15800 = add nuw nsw i32 %15798, %15799"
"  %15800 = add nuw nsw i32 %15798, %15799"
"  %15800 = add nuw nsw i32 %15798, %15799" -> "  %15972 = and i32 %15800, 65535""  %15800 = add nuw nsw i32 %15798, %15799" -> "  %15802 = lshr i32 %15800, 16"
"  %15801 = and i32 %15760, 65535"
"  %15801 = and i32 %15760, 65535" -> "  %15803 = add nuw nsw i32 %15802, %15801"
"  %15802 = lshr i32 %15800, 16"
"  %15802 = lshr i32 %15800, 16" -> "  %15803 = add nuw nsw i32 %15802, %15801"
"  %15803 = add nuw nsw i32 %15802, %15801"
"  %15803 = add nuw nsw i32 %15802, %15801" -> "  %15975 = and i32 %15803, 65535""  %15803 = add nuw nsw i32 %15802, %15801" -> "  %15804 = lshr i32 %15803, 16"
"  %15804 = lshr i32 %15803, 16"
"  %15804 = lshr i32 %15803, 16" -> "  %15805 = add nuw i32 %15767, %15804"
"  %15805 = add nuw i32 %15767, %15804"
"  %15805 = add nuw i32 %15767, %15804" -> "  %15981 = and i32 %15805, 65535""  %15805 = add nuw i32 %15767, %15804" -> "  %15984 = lshr i32 %15805, 16""  %15805 = add nuw i32 %15767, %15804" -> "  store i32 %15805, i32* %2398, align 1, !noalias !38"
"  store i32 %15805, i32* %2398, align 1, !noalias !38"

"  %15806 = mul nuw nsw i32 %13962, 4087"
"  %15806 = mul nuw nsw i32 %13962, 4087" -> "  %15933 = and i32 %15806, 65535""  %15806 = mul nuw nsw i32 %13962, 4087" -> "  %15807 = lshr i32 %15806, 16""  %15806 = mul nuw nsw i32 %13962, 4087" -> "  store i32 %15806, i32* %2817, align 1, !noalias !38"
"  store i32 %15806, i32* %2817, align 1, !noalias !38"

"  %15807 = lshr i32 %15806, 16"
"  %15807 = lshr i32 %15806, 16" -> "  %15810 = add nuw nsw i32 %15809, %15807"
"  %15808 = mul nuw nsw i32 %13961, 4087"
"  %15808 = mul nuw nsw i32 %13961, 4087" -> "  %15811 = and i32 %15808, 268369920""  %15808 = mul nuw nsw i32 %13961, 4087" -> "  %15809 = and i32 %15808, 65535"
"  %15809 = and i32 %15808, 65535"
"  %15809 = and i32 %15808, 65535" -> "  %15810 = add nuw nsw i32 %15809, %15807"
"  %15810 = add nuw nsw i32 %15809, %15807"
"  %15810 = add nuw nsw i32 %15809, %15807" -> "  %15812 = add nuw nsw i32 %15810, %15811"
"  %15811 = and i32 %15808, 268369920"
"  %15811 = and i32 %15808, 268369920" -> "  %15812 = add nuw nsw i32 %15810, %15811"
"  %15812 = add nuw nsw i32 %15810, %15811"
"  %15812 = add nuw nsw i32 %15810, %15811" -> "  %15816 = lshr i32 %15812, 16""  %15812 = add nuw nsw i32 %15810, %15811" -> "  %15814 = and i32 %15812, 65535"
"  %15813 = mul nuw nsw i32 %13962, 11561"
"  %15813 = mul nuw nsw i32 %13962, 11561" -> "  %15815 = add nuw nsw i32 %15814, %15813"
"  %15814 = and i32 %15812, 65535"
"  %15814 = and i32 %15812, 65535" -> "  %15815 = add nuw nsw i32 %15814, %15813"
"  %15815 = add nuw nsw i32 %15814, %15813"
"  %15815 = add nuw nsw i32 %15814, %15813" -> "  %15936 = and i32 %15815, 65535""  %15815 = add nuw nsw i32 %15814, %15813" -> "  %15819 = lshr i32 %15815, 16"
"  %15816 = lshr i32 %15812, 16"
"  %15816 = lshr i32 %15812, 16" -> "  %15818 = add nuw nsw i32 %15816, %15817"
"  %15817 = mul nuw nsw i32 %13961, 11561"
"  %15817 = mul nuw nsw i32 %13961, 11561" -> "  %15818 = add nuw nsw i32 %15816, %15817"
"  %15818 = add nuw nsw i32 %15816, %15817"
"  %15818 = add nuw nsw i32 %15816, %15817" -> "  %15822 = and i32 %15818, 2147418112""  %15818 = add nuw nsw i32 %15816, %15817" -> "  %15820 = and i32 %15818, 65535"
"  %15819 = lshr i32 %15815, 16"
"  %15819 = lshr i32 %15815, 16" -> "  %15821 = add nuw nsw i32 %15819, %15820"
"  %15820 = and i32 %15818, 65535"
"  %15820 = and i32 %15818, 65535" -> "  %15821 = add nuw nsw i32 %15819, %15820"
"  %15821 = add nuw nsw i32 %15819, %15820"
"  %15821 = add nuw nsw i32 %15819, %15820" -> "  %15823 = add nuw nsw i32 %15821, %15822"
"  %15822 = and i32 %15818, 2147418112"
"  %15822 = and i32 %15818, 2147418112" -> "  %15823 = add nuw nsw i32 %15821, %15822"
"  %15823 = add nuw nsw i32 %15821, %15822"
"  %15823 = add nuw nsw i32 %15821, %15822" -> "  %15846 = lshr i32 %15823, 16""  %15823 = add nuw nsw i32 %15821, %15822" -> "  %15842 = and i32 %15823, 65535"
"  %15824 = mul nuw nsw i32 %13981, 4087"
"  %15824 = mul nuw nsw i32 %13981, 4087" -> "  %15843 = and i32 %15824, 65535""  %15824 = mul nuw nsw i32 %13981, 4087" -> "  %15825 = lshr i32 %15824, 16"
"  %15825 = lshr i32 %15824, 16"
"  %15825 = lshr i32 %15824, 16" -> "  %15828 = add nuw nsw i32 %15827, %15825"
"  %15826 = mul nuw nsw i32 %13982, 4087"
"  %15826 = mul nuw nsw i32 %13982, 4087" -> "  %15829 = and i32 %15826, 268369920""  %15826 = mul nuw nsw i32 %13982, 4087" -> "  %15827 = and i32 %15826, 65535"
"  %15827 = and i32 %15826, 65535"
"  %15827 = and i32 %15826, 65535" -> "  %15828 = add nuw nsw i32 %15827, %15825"
"  %15828 = add nuw nsw i32 %15827, %15825"
"  %15828 = add nuw nsw i32 %15827, %15825" -> "  %15830 = add nuw nsw i32 %15828, %15829"
"  %15829 = and i32 %15826, 268369920"
"  %15829 = and i32 %15826, 268369920" -> "  %15830 = add nuw nsw i32 %15828, %15829"
"  %15830 = add nuw nsw i32 %15828, %15829"
"  %15830 = add nuw nsw i32 %15828, %15829" -> "  %15834 = lshr i32 %15830, 16""  %15830 = add nuw nsw i32 %15828, %15829" -> "  %15832 = and i32 %15830, 65535"
"  %15831 = mul nuw nsw i32 %13981, 11561"
"  %15831 = mul nuw nsw i32 %13981, 11561" -> "  %15833 = add nuw nsw i32 %15832, %15831"
"  %15832 = and i32 %15830, 65535"
"  %15832 = and i32 %15830, 65535" -> "  %15833 = add nuw nsw i32 %15832, %15831"
"  %15833 = add nuw nsw i32 %15832, %15831"
"  %15833 = add nuw nsw i32 %15832, %15831" -> "  %15845 = and i32 %15833, 65535""  %15833 = add nuw nsw i32 %15832, %15831" -> "  %15837 = lshr i32 %15833, 16"
"  %15834 = lshr i32 %15830, 16"
"  %15834 = lshr i32 %15830, 16" -> "  %15836 = add nuw nsw i32 %15834, %15835"
"  %15835 = mul nuw nsw i32 %13982, 11561"
"  %15835 = mul nuw nsw i32 %13982, 11561" -> "  %15836 = add nuw nsw i32 %15834, %15835"
"  %15836 = add nuw nsw i32 %15834, %15835"
"  %15836 = add nuw nsw i32 %15834, %15835" -> "  %15840 = and i32 %15836, 2147418112""  %15836 = add nuw nsw i32 %15834, %15835" -> "  %15838 = and i32 %15836, 65535"
"  %15837 = lshr i32 %15833, 16"
"  %15837 = lshr i32 %15833, 16" -> "  %15839 = add nuw nsw i32 %15837, %15838"
"  %15838 = and i32 %15836, 65535"
"  %15838 = and i32 %15836, 65535" -> "  %15839 = add nuw nsw i32 %15837, %15838"
"  %15839 = add nuw nsw i32 %15837, %15838"
"  %15839 = add nuw nsw i32 %15837, %15838" -> "  %15841 = add nuw nsw i32 %15839, %15840"
"  %15840 = and i32 %15836, 2147418112"
"  %15840 = and i32 %15836, 2147418112" -> "  %15841 = add nuw nsw i32 %15839, %15840"
"  %15841 = add nuw nsw i32 %15839, %15840"
"  %15841 = add nuw nsw i32 %15839, %15840" -> "  %15849 = add nuw nsw i32 %15841, %15848"
"  %15842 = and i32 %15823, 65535"
"  %15842 = and i32 %15823, 65535" -> "  %15844 = add nuw nsw i32 %15842, %15843"
"  %15843 = and i32 %15824, 65535"
"  %15843 = and i32 %15824, 65535" -> "  %15844 = add nuw nsw i32 %15842, %15843"
"  %15844 = add nuw nsw i32 %15842, %15843"
"  %15844 = add nuw nsw i32 %15842, %15843" -> "  %15873 = and i32 %15844, 65535""  %15844 = add nuw nsw i32 %15842, %15843" -> "  %15851 = lshr i32 %15844, 16"
"  %15845 = and i32 %15833, 65535"
"  %15845 = and i32 %15833, 65535" -> "  %15847 = add nuw nsw i32 %15846, %15845"
"  %15846 = lshr i32 %15823, 16"
"  %15846 = lshr i32 %15823, 16" -> "  %15847 = add nuw nsw i32 %15846, %15845"
"  %15847 = add nuw nsw i32 %15846, %15845"
"  %15847 = add nuw nsw i32 %15846, %15845" -> "  %15850 = and i32 %15847, 65535""  %15847 = add nuw nsw i32 %15846, %15845" -> "  %15848 = lshr i32 %15847, 16"
"  %15848 = lshr i32 %15847, 16"
"  %15848 = lshr i32 %15847, 16" -> "  %15849 = add nuw nsw i32 %15841, %15848"
"  %15849 = add nuw nsw i32 %15841, %15848"
"  %15849 = add nuw nsw i32 %15841, %15848" -> "  %15854 = add nuw nsw i32 %15849, %15853"
"  %15850 = and i32 %15847, 65535"
"  %15850 = and i32 %15847, 65535" -> "  %15852 = add nuw nsw i32 %15850, %15851"
"  %15851 = lshr i32 %15844, 16"
"  %15851 = lshr i32 %15844, 16" -> "  %15852 = add nuw nsw i32 %15850, %15851"
"  %15852 = add nuw nsw i32 %15850, %15851"
"  %15852 = add nuw nsw i32 %15850, %15851" -> "  %15876 = and i32 %15852, 65535""  %15852 = add nuw nsw i32 %15850, %15851" -> "  %15853 = lshr i32 %15852, 16"
"  %15853 = lshr i32 %15852, 16"
"  %15853 = lshr i32 %15852, 16" -> "  %15854 = add nuw nsw i32 %15849, %15853"
"  %15854 = add nuw nsw i32 %15849, %15853"
"  %15854 = add nuw nsw i32 %15849, %15853" -> "  %15908 = lshr i32 %15854, 16""  %15854 = add nuw nsw i32 %15849, %15853" -> "  %15904 = and i32 %15854, 65535"
"  %15855 = mul nuw nsw i32 %13962, 21884"
"  %15855 = mul nuw nsw i32 %13962, 21884" -> "  %15874 = and i32 %15855, 65532""  %15855 = mul nuw nsw i32 %13962, 21884" -> "  %15856 = lshr i32 %15855, 16"
"  %15856 = lshr i32 %15855, 16"
"  %15856 = lshr i32 %15855, 16" -> "  %15859 = add nuw nsw i32 %15858, %15856"
"  %15857 = mul nuw nsw i32 %13961, 21884"
"  %15857 = mul nuw nsw i32 %13961, 21884" -> "  %15860 = and i32 %15857, 2147418112""  %15857 = mul nuw nsw i32 %13961, 21884" -> "  %15858 = and i32 %15857, 65532"
"  %15858 = and i32 %15857, 65532"
"  %15858 = and i32 %15857, 65532" -> "  %15859 = add nuw nsw i32 %15858, %15856"
"  %15859 = add nuw nsw i32 %15858, %15856"
"  %15859 = add nuw nsw i32 %15858, %15856" -> "  %15861 = add nuw nsw i32 %15859, %15860"
"  %15860 = and i32 %15857, 2147418112"
"  %15860 = and i32 %15857, 2147418112" -> "  %15861 = add nuw nsw i32 %15859, %15860"
"  %15861 = add nuw nsw i32 %15859, %15860"
"  %15861 = add nuw nsw i32 %15859, %15860" -> "  %15865 = lshr i32 %15861, 16""  %15861 = add nuw nsw i32 %15859, %15860" -> "  %15863 = and i32 %15861, 65535"
"  %15862 = mul nuw i32 %13962, 36786"
"  %15862 = mul nuw i32 %13962, 36786" -> "  %15864 = add nuw i32 %15863, %15862"
"  %15863 = and i32 %15861, 65535"
"  %15863 = and i32 %15861, 65535" -> "  %15864 = add nuw i32 %15863, %15862"
"  %15864 = add nuw i32 %15863, %15862"
"  %15864 = add nuw i32 %15863, %15862" -> "  %15877 = and i32 %15864, 65535""  %15864 = add nuw i32 %15863, %15862" -> "  %15868 = lshr i32 %15864, 16"
"  %15865 = lshr i32 %15861, 16"
"  %15865 = lshr i32 %15861, 16" -> "  %15867 = add nuw i32 %15865, %15866"
"  %15866 = mul nuw i32 %13961, 36786"
"  %15866 = mul nuw i32 %13961, 36786" -> "  %15867 = add nuw i32 %15865, %15866"
"  %15867 = add nuw i32 %15865, %15866"
"  %15867 = add nuw i32 %15865, %15866" -> "  %15871 = and i32 %15867, -65536""  %15867 = add nuw i32 %15865, %15866" -> "  %15869 = and i32 %15867, 65535"
"  %15868 = lshr i32 %15864, 16"
"  %15868 = lshr i32 %15864, 16" -> "  %15870 = add nuw nsw i32 %15868, %15869"
"  %15869 = and i32 %15867, 65535"
"  %15869 = and i32 %15867, 65535" -> "  %15870 = add nuw nsw i32 %15868, %15869"
"  %15870 = add nuw nsw i32 %15868, %15869"
"  %15870 = add nuw nsw i32 %15868, %15869" -> "  %15872 = add nuw i32 %15870, %15871"
"  %15871 = and i32 %15867, -65536"
"  %15871 = and i32 %15867, -65536" -> "  %15872 = add nuw i32 %15870, %15871"
"  %15872 = add nuw i32 %15870, %15871"
"  %15872 = add nuw i32 %15870, %15871" -> "  %15880 = add nuw i32 %15872, %15879"
"  %15873 = and i32 %15844, 65535"
"  %15873 = and i32 %15844, 65535" -> "  %15875 = add nuw nsw i32 %15873, %15874"
"  %15874 = and i32 %15855, 65532"
"  %15874 = and i32 %15855, 65532" -> "  %15875 = add nuw nsw i32 %15873, %15874"
"  %15875 = add nuw nsw i32 %15873, %15874"
"  %15875 = add nuw nsw i32 %15873, %15874" -> "  %15943 = and i32 %15875, 65535""  %15875 = add nuw nsw i32 %15873, %15874" -> "  %15882 = lshr i32 %15875, 16"
"  %15876 = and i32 %15852, 65535"
"  %15876 = and i32 %15852, 65535" -> "  %15878 = add nuw nsw i32 %15876, %15877"
"  %15877 = and i32 %15864, 65535"
"  %15877 = and i32 %15864, 65535" -> "  %15878 = add nuw nsw i32 %15876, %15877"
"  %15878 = add nuw nsw i32 %15876, %15877"
"  %15878 = add nuw nsw i32 %15876, %15877" -> "  %15881 = and i32 %15878, 65535""  %15878 = add nuw nsw i32 %15876, %15877" -> "  %15879 = lshr i32 %15878, 16"
"  %15879 = lshr i32 %15878, 16"
"  %15879 = lshr i32 %15878, 16" -> "  %15880 = add nuw i32 %15872, %15879"
"  %15880 = add nuw i32 %15872, %15879"
"  %15880 = add nuw i32 %15872, %15879" -> "  %15885 = add nuw i32 %15880, %15884"
"  %15881 = and i32 %15878, 65535"
"  %15881 = and i32 %15878, 65535" -> "  %15883 = add nuw nsw i32 %15881, %15882"
"  %15882 = lshr i32 %15875, 16"
"  %15882 = lshr i32 %15875, 16" -> "  %15883 = add nuw nsw i32 %15881, %15882"
"  %15883 = add nuw nsw i32 %15881, %15882"
"  %15883 = add nuw nsw i32 %15881, %15882" -> "  %15946 = and i32 %15883, 65535""  %15883 = add nuw nsw i32 %15881, %15882" -> "  %15884 = lshr i32 %15883, 16"
"  %15884 = lshr i32 %15883, 16"
"  %15884 = lshr i32 %15883, 16" -> "  %15885 = add nuw i32 %15880, %15884"
"  %15885 = add nuw i32 %15880, %15884"
"  %15885 = add nuw i32 %15880, %15884" -> "  %15921 = lshr i32 %15885, 16""  %15885 = add nuw i32 %15880, %15884" -> "  %15918 = and i32 %15885, 65535"
"  %15886 = mul nuw nsw i32 %13981, 21884"
"  %15886 = mul nuw nsw i32 %13981, 21884" -> "  %15905 = and i32 %15886, 65532""  %15886 = mul nuw nsw i32 %13981, 21884" -> "  %15887 = lshr i32 %15886, 16"
"  %15887 = lshr i32 %15886, 16"
"  %15887 = lshr i32 %15886, 16" -> "  %15890 = add nuw nsw i32 %15889, %15887"
"  %15888 = mul nuw nsw i32 %13982, 21884"
"  %15888 = mul nuw nsw i32 %13982, 21884" -> "  %15891 = and i32 %15888, 2147418112""  %15888 = mul nuw nsw i32 %13982, 21884" -> "  %15889 = and i32 %15888, 65532"
"  %15889 = and i32 %15888, 65532"
"  %15889 = and i32 %15888, 65532" -> "  %15890 = add nuw nsw i32 %15889, %15887"
"  %15890 = add nuw nsw i32 %15889, %15887"
"  %15890 = add nuw nsw i32 %15889, %15887" -> "  %15892 = add nuw nsw i32 %15890, %15891"
"  %15891 = and i32 %15888, 2147418112"
"  %15891 = and i32 %15888, 2147418112" -> "  %15892 = add nuw nsw i32 %15890, %15891"
"  %15892 = add nuw nsw i32 %15890, %15891"
"  %15892 = add nuw nsw i32 %15890, %15891" -> "  %15896 = lshr i32 %15892, 16""  %15892 = add nuw nsw i32 %15890, %15891" -> "  %15894 = and i32 %15892, 65535"
"  %15893 = mul nuw i32 %13981, 36786"
"  %15893 = mul nuw i32 %13981, 36786" -> "  %15895 = add nuw i32 %15894, %15893"
"  %15894 = and i32 %15892, 65535"
"  %15894 = and i32 %15892, 65535" -> "  %15895 = add nuw i32 %15894, %15893"
"  %15895 = add nuw i32 %15894, %15893"
"  %15895 = add nuw i32 %15894, %15893" -> "  %15907 = and i32 %15895, 65535""  %15895 = add nuw i32 %15894, %15893" -> "  %15899 = lshr i32 %15895, 16"
"  %15896 = lshr i32 %15892, 16"
"  %15896 = lshr i32 %15892, 16" -> "  %15898 = add nuw i32 %15896, %15897"
"  %15897 = mul nuw i32 %13982, 36786"
"  %15897 = mul nuw i32 %13982, 36786" -> "  %15898 = add nuw i32 %15896, %15897"
"  %15898 = add nuw i32 %15896, %15897"
"  %15898 = add nuw i32 %15896, %15897" -> "  %15902 = and i32 %15898, -65536""  %15898 = add nuw i32 %15896, %15897" -> "  %15900 = and i32 %15898, 65535"
"  %15899 = lshr i32 %15895, 16"
"  %15899 = lshr i32 %15895, 16" -> "  %15901 = add nuw nsw i32 %15899, %15900"
"  %15900 = and i32 %15898, 65535"
"  %15900 = and i32 %15898, 65535" -> "  %15901 = add nuw nsw i32 %15899, %15900"
"  %15901 = add nuw nsw i32 %15899, %15900"
"  %15901 = add nuw nsw i32 %15899, %15900" -> "  %15903 = add nuw i32 %15901, %15902"
"  %15902 = and i32 %15898, -65536"
"  %15902 = and i32 %15898, -65536" -> "  %15903 = add nuw i32 %15901, %15902"
"  %15903 = add nuw i32 %15901, %15902"
"  %15903 = add nuw i32 %15901, %15902" -> "  %15911 = add nuw i32 %15903, %15910"
"  %15904 = and i32 %15854, 65535"
"  %15904 = and i32 %15854, 65535" -> "  %15906 = add nuw nsw i32 %15904, %15905"
"  %15905 = and i32 %15886, 65532"
"  %15905 = and i32 %15886, 65532" -> "  %15906 = add nuw nsw i32 %15904, %15905"
"  %15906 = add nuw nsw i32 %15904, %15905"
"  %15906 = add nuw nsw i32 %15904, %15905" -> "  %15917 = and i32 %15906, 65535""  %15906 = add nuw nsw i32 %15904, %15905" -> "  %15913 = lshr i32 %15906, 16"
"  %15907 = and i32 %15895, 65535"
"  %15907 = and i32 %15895, 65535" -> "  %15909 = add nuw nsw i32 %15908, %15907"
"  %15908 = lshr i32 %15854, 16"
"  %15908 = lshr i32 %15854, 16" -> "  %15909 = add nuw nsw i32 %15908, %15907"
"  %15909 = add nuw nsw i32 %15908, %15907"
"  %15909 = add nuw nsw i32 %15908, %15907" -> "  %15912 = and i32 %15909, 65535""  %15909 = add nuw nsw i32 %15908, %15907" -> "  %15910 = lshr i32 %15909, 16"
"  %15910 = lshr i32 %15909, 16"
"  %15910 = lshr i32 %15909, 16" -> "  %15911 = add nuw i32 %15903, %15910"
"  %15911 = add nuw i32 %15903, %15910"
"  %15911 = add nuw i32 %15903, %15910" -> "  %15916 = add nuw i32 %15911, %15915"
"  %15912 = and i32 %15909, 65535"
"  %15912 = and i32 %15909, 65535" -> "  %15914 = add nuw nsw i32 %15913, %15912"
"  %15913 = lshr i32 %15906, 16"
"  %15913 = lshr i32 %15906, 16" -> "  %15914 = add nuw nsw i32 %15913, %15912"
"  %15914 = add nuw nsw i32 %15913, %15912"
"  %15914 = add nuw nsw i32 %15913, %15912" -> "  %15920 = and i32 %15914, 65535""  %15914 = add nuw nsw i32 %15913, %15912" -> "  %15915 = lshr i32 %15914, 16"
"  %15915 = lshr i32 %15914, 16"
"  %15915 = lshr i32 %15914, 16" -> "  %15916 = add nuw i32 %15911, %15915"
"  %15916 = add nuw i32 %15911, %15915"
"  %15916 = add nuw i32 %15911, %15915" -> "  %15927 = and i32 %15916, 65535""  %15916 = add nuw i32 %15911, %15915" -> "  %15929 = and i32 %15916, -65536"
"  %15917 = and i32 %15906, 65535"
"  %15917 = and i32 %15906, 65535" -> "  %15919 = add nuw nsw i32 %15918, %15917"
"  %15918 = and i32 %15885, 65535"
"  %15918 = and i32 %15885, 65535" -> "  %15919 = add nuw nsw i32 %15918, %15917"
"  %15919 = add nuw nsw i32 %15918, %15917"
"  %15919 = add nuw nsw i32 %15918, %15917" -> "  %15960 = and i32 %15919, 65535""  %15919 = add nuw nsw i32 %15918, %15917" -> "  %15923 = lshr i32 %15919, 16"
"  %15920 = and i32 %15914, 65535"
"  %15920 = and i32 %15914, 65535" -> "  %15922 = add nuw nsw i32 %15920, %15921"
"  %15921 = lshr i32 %15885, 16"
"  %15921 = lshr i32 %15885, 16" -> "  %15922 = add nuw nsw i32 %15920, %15921"
"  %15922 = add nuw nsw i32 %15920, %15921"
"  %15922 = add nuw nsw i32 %15920, %15921" -> "  %15926 = lshr i32 %15922, 16""  %15922 = add nuw nsw i32 %15920, %15921" -> "  %15924 = and i32 %15922, 65535"
"  %15923 = lshr i32 %15919, 16"
"  %15923 = lshr i32 %15919, 16" -> "  %15925 = add nuw nsw i32 %15923, %15924"
"  %15924 = and i32 %15922, 65535"
"  %15924 = and i32 %15922, 65535" -> "  %15925 = add nuw nsw i32 %15923, %15924"
"  %15925 = add nuw nsw i32 %15923, %15924"
"  %15925 = add nuw nsw i32 %15923, %15924" -> "  %15966 = and i32 %15925, 65535""  %15925 = add nuw nsw i32 %15923, %15924" -> "  %15931 = lshr i32 %15925, 16"
"  %15926 = lshr i32 %15922, 16"
"  %15926 = lshr i32 %15922, 16" -> "  %15928 = add nuw nsw i32 %15926, %15927"
"  %15927 = and i32 %15916, 65535"
"  %15927 = and i32 %15916, 65535" -> "  %15928 = add nuw nsw i32 %15926, %15927"
"  %15928 = add nuw nsw i32 %15926, %15927"
"  %15928 = add nuw nsw i32 %15926, %15927" -> "  %15930 = add nuw i32 %15928, %15929"
"  %15929 = and i32 %15916, -65536"
"  %15929 = and i32 %15916, -65536" -> "  %15930 = add nuw i32 %15928, %15929"
"  %15930 = add nuw i32 %15928, %15929"
"  %15930 = add nuw i32 %15928, %15929" -> "  %15932 = add nuw i32 %15930, %15931"
"  %15931 = lshr i32 %15925, 16"
"  %15931 = lshr i32 %15925, 16" -> "  %15932 = add nuw i32 %15930, %15931"
"  %15932 = add nuw i32 %15930, %15931"
"  %15932 = add nuw i32 %15930, %15931" -> "  %15970 = add nuw i32 %15932, %15969"
"  %15933 = and i32 %15806, 65535"
"  %15933 = and i32 %15806, 65535" -> "  %15935 = add nuw nsw i32 %15934, %15933"
"  %15934 = and i32 %15635, 65535"
"  %15934 = and i32 %15635, 65535" -> "  %15935 = add nuw nsw i32 %15934, %15933"
"  %15935 = add nuw nsw i32 %15934, %15933"
"  %15935 = add nuw nsw i32 %15934, %15933" -> "  %15971 = and i32 %15935, 65535""  %15935 = add nuw nsw i32 %15934, %15933" -> "  %15939 = lshr i32 %15935, 16"
"  %15936 = and i32 %15815, 65535"
"  %15936 = and i32 %15815, 65535" -> "  %15938 = add nuw nsw i32 %15937, %15936"
"  %15937 = and i32 %15638, 65535"
"  %15937 = and i32 %15638, 65535" -> "  %15938 = add nuw nsw i32 %15937, %15936"
"  %15938 = add nuw nsw i32 %15937, %15936"
"  %15938 = add nuw nsw i32 %15937, %15936" -> "  %15952 = lshr i32 %15938, 16""  %15938 = add nuw nsw i32 %15937, %15936" -> "  %15940 = and i32 %15938, 65535"
"  %15939 = lshr i32 %15935, 16"
"  %15939 = lshr i32 %15935, 16" -> "  %15941 = add nuw nsw i32 %15940, %15939"
"  %15940 = and i32 %15938, 65535"
"  %15940 = and i32 %15938, 65535" -> "  %15941 = add nuw nsw i32 %15940, %15939"
"  %15941 = add nuw nsw i32 %15940, %15939"
"  %15941 = add nuw nsw i32 %15940, %15939" -> "  %15974 = and i32 %15941, 65535""  %15941 = add nuw nsw i32 %15940, %15939" -> "  %15954 = lshr i32 %15941, 16"
"  %15942 = and i32 %15640, 65535"
"  %15942 = and i32 %15640, 65535" -> "  %15944 = add nuw nsw i32 %15942, %15943"
"  %15943 = and i32 %15875, 65535"
"  %15943 = and i32 %15875, 65535" -> "  %15944 = add nuw nsw i32 %15942, %15943"
"  %15944 = add nuw nsw i32 %15942, %15943"
"  %15944 = add nuw nsw i32 %15942, %15943" -> "  %15951 = and i32 %15944, 65535""  %15944 = add nuw nsw i32 %15942, %15943" -> "  %15948 = lshr i32 %15944, 16"
"  %15945 = lshr i32 %15640, 16"
"  %15945 = lshr i32 %15640, 16" -> "  %15947 = add nuw nsw i32 %15945, %15946"
"  %15946 = and i32 %15883, 65535"
"  %15946 = and i32 %15883, 65535" -> "  %15947 = add nuw nsw i32 %15945, %15946"
"  %15947 = add nuw nsw i32 %15945, %15946"
"  %15947 = add nuw nsw i32 %15945, %15946" -> "  %15959 = lshr i32 %15947, 16""  %15947 = add nuw nsw i32 %15945, %15946" -> "  %15949 = and i32 %15947, 65535"
"  %15948 = lshr i32 %15944, 16"
"  %15948 = lshr i32 %15944, 16" -> "  %15950 = add nuw nsw i32 %15949, %15948"
"  %15949 = and i32 %15947, 65535"
"  %15949 = and i32 %15947, 65535" -> "  %15950 = add nuw nsw i32 %15949, %15948"
"  %15950 = add nuw nsw i32 %15949, %15948"
"  %15950 = add nuw nsw i32 %15949, %15948" -> "  %15962 = lshr i32 %15950, 16""  %15950 = add nuw nsw i32 %15949, %15948" -> "  %15957 = and i32 %15950, 65535"
"  %15951 = and i32 %15944, 65535"
"  %15951 = and i32 %15944, 65535" -> "  %15953 = add nuw nsw i32 %15951, %15952"
"  %15952 = lshr i32 %15938, 16"
"  %15952 = lshr i32 %15938, 16" -> "  %15953 = add nuw nsw i32 %15951, %15952"
"  %15953 = add nuw nsw i32 %15951, %15952"
"  %15953 = add nuw nsw i32 %15951, %15952" -> "  %15955 = add nuw nsw i32 %15953, %15954"
"  %15954 = lshr i32 %15941, 16"
"  %15954 = lshr i32 %15941, 16" -> "  %15955 = add nuw nsw i32 %15953, %15954"
"  %15955 = add nuw nsw i32 %15953, %15954"
"  %15955 = add nuw nsw i32 %15953, %15954" -> "  %15980 = and i32 %15955, 65535""  %15955 = add nuw nsw i32 %15953, %15954" -> "  %15956 = lshr i32 %15955, 16"
"  %15956 = lshr i32 %15955, 16"
"  %15956 = lshr i32 %15955, 16" -> "  %15958 = add nuw nsw i32 %15956, %15957"
"  %15957 = and i32 %15950, 65535"
"  %15957 = and i32 %15950, 65535" -> "  %15958 = add nuw nsw i32 %15956, %15957"
"  %15958 = add nuw nsw i32 %15956, %15957"
"  %15958 = add nuw nsw i32 %15956, %15957" -> "  %15983 = and i32 %15958, 65535""  %15958 = add nuw nsw i32 %15956, %15957" -> "  %15964 = lshr i32 %15958, 16"
"  %15959 = lshr i32 %15947, 16"
"  %15959 = lshr i32 %15947, 16" -> "  %15961 = add nuw nsw i32 %15959, %15960"
"  %15960 = and i32 %15919, 65535"
"  %15960 = and i32 %15919, 65535" -> "  %15961 = add nuw nsw i32 %15959, %15960"
"  %15961 = add nuw nsw i32 %15959, %15960"
"  %15961 = add nuw nsw i32 %15959, %15960" -> "  %15963 = add nuw nsw i32 %15961, %15962"
"  %15962 = lshr i32 %15950, 16"
"  %15962 = lshr i32 %15950, 16" -> "  %15963 = add nuw nsw i32 %15961, %15962"
"  %15963 = add nuw nsw i32 %15961, %15962"
"  %15963 = add nuw nsw i32 %15961, %15962" -> "  %15965 = add nuw nsw i32 %15963, %15964"
"  %15964 = lshr i32 %15958, 16"
"  %15964 = lshr i32 %15958, 16" -> "  %15965 = add nuw nsw i32 %15963, %15964"
"  %15965 = add nuw nsw i32 %15963, %15964"
"  %15965 = add nuw nsw i32 %15963, %15964" -> "  %15997 = and i32 %15965, 65535""  %15965 = add nuw nsw i32 %15963, %15964" -> "  %15967 = lshr i32 %15965, 16"
"  %15966 = and i32 %15925, 65535"
"  %15966 = and i32 %15925, 65535" -> "  %15968 = add nuw nsw i32 %15967, %15966"
"  %15967 = lshr i32 %15965, 16"
"  %15967 = lshr i32 %15965, 16" -> "  %15968 = add nuw nsw i32 %15967, %15966"
"  %15968 = add nuw nsw i32 %15967, %15966"
"  %15968 = add nuw nsw i32 %15967, %15966" -> "  %16004 = and i32 %15968, 65535""  %15968 = add nuw nsw i32 %15967, %15966" -> "  %15969 = lshr i32 %15968, 16"
"  %15969 = lshr i32 %15968, 16"
"  %15969 = lshr i32 %15968, 16" -> "  %15970 = add nuw i32 %15932, %15969"
"  %15970 = add nuw i32 %15932, %15969"
"  %15970 = add nuw i32 %15932, %15969" -> "  %16008 = add nuw i32 %15970, %16007"
"  %15971 = and i32 %15935, 65535"
"  %15971 = and i32 %15935, 65535" -> "  %15973 = add nuw nsw i32 %15972, %15971"
"  %15972 = and i32 %15800, 65535"
"  %15972 = and i32 %15800, 65535" -> "  %15973 = add nuw nsw i32 %15972, %15971"
"  %15973 = add nuw nsw i32 %15972, %15971"
"  %15973 = add nuw nsw i32 %15972, %15971" -> "  %16081 = and i32 %15973, 65535""  %15973 = add nuw nsw i32 %15972, %15971" -> "  %15977 = lshr i32 %15973, 16"
"  %15974 = and i32 %15941, 65535"
"  %15974 = and i32 %15941, 65535" -> "  %15976 = add nuw nsw i32 %15975, %15974"
"  %15975 = and i32 %15803, 65535"
"  %15975 = and i32 %15803, 65535" -> "  %15976 = add nuw nsw i32 %15975, %15974"
"  %15976 = add nuw nsw i32 %15975, %15974"
"  %15976 = add nuw nsw i32 %15975, %15974" -> "  %15990 = lshr i32 %15976, 16""  %15976 = add nuw nsw i32 %15975, %15974" -> "  %15978 = and i32 %15976, 65535"
"  %15977 = lshr i32 %15973, 16"
"  %15977 = lshr i32 %15973, 16" -> "  %15979 = add nuw nsw i32 %15978, %15977"
"  %15978 = and i32 %15976, 65535"
"  %15978 = and i32 %15976, 65535" -> "  %15979 = add nuw nsw i32 %15978, %15977"
"  %15979 = add nuw nsw i32 %15978, %15977"
"  %15979 = add nuw nsw i32 %15978, %15977" -> "  %16086 = and i32 %15979, 65535""  %15979 = add nuw nsw i32 %15978, %15977" -> "  %15992 = lshr i32 %15979, 16"
"  %15980 = and i32 %15955, 65535"
"  %15980 = and i32 %15955, 65535" -> "  %15982 = add nuw nsw i32 %15981, %15980"
"  %15981 = and i32 %15805, 65535"
"  %15981 = and i32 %15805, 65535" -> "  %15982 = add nuw nsw i32 %15981, %15980"
"  %15982 = add nuw nsw i32 %15981, %15980"
"  %15982 = add nuw nsw i32 %15981, %15980" -> "  %15989 = and i32 %15982, 65535""  %15982 = add nuw nsw i32 %15981, %15980" -> "  %15986 = lshr i32 %15982, 16"
"  %15983 = and i32 %15958, 65535"
"  %15983 = and i32 %15958, 65535" -> "  %15985 = add nuw nsw i32 %15983, %15984"
"  %15984 = lshr i32 %15805, 16"
"  %15984 = lshr i32 %15805, 16" -> "  %15985 = add nuw nsw i32 %15983, %15984"
"  %15985 = add nuw nsw i32 %15983, %15984"
"  %15985 = add nuw nsw i32 %15983, %15984" -> "  %15998 = lshr i32 %15985, 16""  %15985 = add nuw nsw i32 %15983, %15984" -> "  %15987 = and i32 %15985, 65535"
"  %15986 = lshr i32 %15982, 16"
"  %15986 = lshr i32 %15982, 16" -> "  %15988 = add nuw nsw i32 %15987, %15986"
"  %15987 = and i32 %15985, 65535"
"  %15987 = and i32 %15985, 65535" -> "  %15988 = add nuw nsw i32 %15987, %15986"
"  %15988 = add nuw nsw i32 %15987, %15986"
"  %15988 = add nuw nsw i32 %15987, %15986" -> "  %16000 = lshr i32 %15988, 16""  %15988 = add nuw nsw i32 %15987, %15986" -> "  %15995 = and i32 %15988, 65535"
"  %15989 = and i32 %15982, 65535"
"  %15989 = and i32 %15982, 65535" -> "  %15991 = add nuw nsw i32 %15989, %15990"
"  %15990 = lshr i32 %15976, 16"
"  %15990 = lshr i32 %15976, 16" -> "  %15991 = add nuw nsw i32 %15989, %15990"
"  %15991 = add nuw nsw i32 %15989, %15990"
"  %15991 = add nuw nsw i32 %15989, %15990" -> "  %15993 = add nuw nsw i32 %15991, %15992"
"  %15992 = lshr i32 %15979, 16"
"  %15992 = lshr i32 %15979, 16" -> "  %15993 = add nuw nsw i32 %15991, %15992"
"  %15993 = add nuw nsw i32 %15991, %15992"
"  %15993 = add nuw nsw i32 %15991, %15992" -> "  %16089 = and i32 %15993, 65535""  %15993 = add nuw nsw i32 %15991, %15992" -> "  %15994 = lshr i32 %15993, 16"
"  %15994 = lshr i32 %15993, 16"
"  %15994 = lshr i32 %15993, 16" -> "  %15996 = add nuw nsw i32 %15995, %15994"
"  %15995 = and i32 %15988, 65535"
"  %15995 = and i32 %15988, 65535" -> "  %15996 = add nuw nsw i32 %15995, %15994"
"  %15996 = add nuw nsw i32 %15995, %15994"
"  %15996 = add nuw nsw i32 %15995, %15994" -> "  %16093 = and i32 %15996, 65535""  %15996 = add nuw nsw i32 %15995, %15994" -> "  %16002 = lshr i32 %15996, 16"
"  %15997 = and i32 %15965, 65535"
"  %15997 = and i32 %15965, 65535" -> "  %15999 = add nuw nsw i32 %15998, %15997"
"  %15998 = lshr i32 %15985, 16"
"  %15998 = lshr i32 %15985, 16" -> "  %15999 = add nuw nsw i32 %15998, %15997"
"  %15999 = add nuw nsw i32 %15998, %15997"
"  %15999 = add nuw nsw i32 %15998, %15997" -> "  %16001 = add nuw nsw i32 %15999, %16000"
"  %16000 = lshr i32 %15988, 16"
"  %16000 = lshr i32 %15988, 16" -> "  %16001 = add nuw nsw i32 %15999, %16000"
"  %16001 = add nuw nsw i32 %15999, %16000"
"  %16001 = add nuw nsw i32 %15999, %16000" -> "  %16003 = add nuw nsw i32 %16001, %16002"
"  %16002 = lshr i32 %15996, 16"
"  %16002 = lshr i32 %15996, 16" -> "  %16003 = add nuw nsw i32 %16001, %16002"
"  %16003 = add nuw nsw i32 %16001, %16002"
"  %16003 = add nuw nsw i32 %16001, %16002" -> "  %16096 = and i32 %16003, 65535""  %16003 = add nuw nsw i32 %16001, %16002" -> "  %16005 = lshr i32 %16003, 16"
"  %16004 = and i32 %15968, 65535"
"  %16004 = and i32 %15968, 65535" -> "  %16006 = add nuw nsw i32 %16005, %16004"
"  %16005 = lshr i32 %16003, 16"
"  %16005 = lshr i32 %16003, 16" -> "  %16006 = add nuw nsw i32 %16005, %16004"
"  %16006 = add nuw nsw i32 %16005, %16004"
"  %16006 = add nuw nsw i32 %16005, %16004" -> "  %16099 = and i32 %16006, 65535""  %16006 = add nuw nsw i32 %16005, %16004" -> "  %16007 = lshr i32 %16006, 16"
"  %16007 = lshr i32 %16006, 16"
"  %16007 = lshr i32 %16006, 16" -> "  %16008 = add nuw i32 %15970, %16007"
"  %16008 = add nuw i32 %15970, %16007"
"  %16008 = add nuw i32 %15970, %16007" -> "  %16102 = add nuw i32 %16008, %16101"
"  %16009 = and i32 %14577, 65535"
"  %16009 = and i32 %14577, 65535" -> "  %16011 = add nuw nsw i32 %16009, %16010"
"  %16010 = and i32 %15349, 65535"
"  %16010 = and i32 %15349, 65535" -> "  %16011 = add nuw nsw i32 %16009, %16010"
"  %16011 = add nuw nsw i32 %16009, %16010"
"  %16011 = add nuw nsw i32 %16009, %16010" -> "  %16104 = and i32 %16011, 65535""  %16011 = add nuw nsw i32 %16009, %16010" -> "  %16015 = lshr i32 %16011, 16"
"  %16012 = and i32 %14581, 65535"
"  %16012 = and i32 %14581, 65535" -> "  %16014 = add nuw nsw i32 %16012, %16013"
"  %16013 = and i32 %15358, 65535"
"  %16013 = and i32 %15358, 65535" -> "  %16014 = add nuw nsw i32 %16012, %16013"
"  %16014 = add nuw nsw i32 %16012, %16013"
"  %16014 = add nuw nsw i32 %16012, %16013" -> "  %16028 = lshr i32 %16014, 16""  %16014 = add nuw nsw i32 %16012, %16013" -> "  %16016 = and i32 %16014, 65535"
"  %16015 = lshr i32 %16011, 16"
"  %16015 = lshr i32 %16011, 16" -> "  %16017 = add nuw nsw i32 %16016, %16015"
"  %16016 = and i32 %16014, 65535"
"  %16016 = and i32 %16014, 65535" -> "  %16017 = add nuw nsw i32 %16016, %16015"
"  %16017 = add nuw nsw i32 %16016, %16015"
"  %16017 = add nuw nsw i32 %16016, %16015" -> "  %16107 = and i32 %16017, 65535""  %16017 = add nuw nsw i32 %16016, %16015" -> "  %16029 = lshr i32 %16017, 16"
"  %16018 = and i32 %14583, 65535"
"  %16018 = and i32 %14583, 65535" -> "  %16020 = add nuw nsw i32 %16018, %16019"
"  %16019 = and i32 %15418, 65535"
"  %16019 = and i32 %15418, 65535" -> "  %16020 = add nuw nsw i32 %16018, %16019"
"  %16020 = add nuw nsw i32 %16018, %16019"
"  %16020 = add nuw nsw i32 %16018, %16019" -> "  %16027 = and i32 %16020, 65535""  %16020 = add nuw nsw i32 %16018, %16019" -> "  %16024 = lshr i32 %16020, 16"
"  %16021 = and i32 %14586, 65535"
"  %16021 = and i32 %14586, 65535" -> "  %16023 = add nuw nsw i32 %16021, %16022"
"  %16022 = and i32 %15426, 65535"
"  %16022 = and i32 %15426, 65535" -> "  %16023 = add nuw nsw i32 %16021, %16022"
"  %16023 = add nuw nsw i32 %16021, %16022"
"  %16023 = add nuw nsw i32 %16021, %16022" -> "  %16065 = lshr i32 %16023, 16""  %16023 = add nuw nsw i32 %16021, %16022" -> "  %16025 = and i32 %16023, 65535"
"  %16024 = lshr i32 %16020, 16"
"  %16024 = lshr i32 %16020, 16" -> "  %16026 = add nuw nsw i32 %16025, %16024"
"  %16025 = and i32 %16023, 65535"
"  %16025 = and i32 %16023, 65535" -> "  %16026 = add nuw nsw i32 %16025, %16024"
"  %16026 = add nuw nsw i32 %16025, %16024"
"  %16026 = add nuw nsw i32 %16025, %16024" -> "  %16066 = lshr i32 %16026, 16""  %16026 = add nuw nsw i32 %16025, %16024" -> "  %16033 = and i32 %16026, 65535"
"  %16027 = and i32 %16020, 65535"
"  %16027 = and i32 %16020, 65535" -> "  %16031 = add nuw nsw i32 %16030, %16027"
"  %16028 = lshr i32 %16014, 16"
"  %16028 = lshr i32 %16014, 16" -> "  %16030 = add nuw nsw i32 %16029, %16028"
"  %16029 = lshr i32 %16017, 16"
"  %16029 = lshr i32 %16017, 16" -> "  %16030 = add nuw nsw i32 %16029, %16028"
"  %16030 = add nuw nsw i32 %16029, %16028"
"  %16030 = add nuw nsw i32 %16029, %16028" -> "  %16031 = add nuw nsw i32 %16030, %16027"
"  %16031 = add nuw nsw i32 %16030, %16027"
"  %16031 = add nuw nsw i32 %16030, %16027" -> "  %16113 = and i32 %16031, 65535""  %16031 = add nuw nsw i32 %16030, %16027" -> "  %16032 = lshr i32 %16031, 16"
"  %16032 = lshr i32 %16031, 16"
"  %16032 = lshr i32 %16031, 16" -> "  %16034 = add nuw nsw i32 %16033, %16032"
"  %16033 = and i32 %16026, 65535"
"  %16033 = and i32 %16026, 65535" -> "  %16034 = add nuw nsw i32 %16033, %16032"
"  %16034 = add nuw nsw i32 %16033, %16032"
"  %16034 = add nuw nsw i32 %16033, %16032" -> "  %16116 = and i32 %16034, 65535""  %16034 = add nuw nsw i32 %16033, %16032" -> "  %16067 = lshr i32 %16034, 16"
"  %16035 = and i32 %14589, 65535"
"  %16035 = and i32 %14589, 65535" -> "  %16037 = add nuw nsw i32 %16035, %16036"
"  %16036 = and i32 %15770, 65535"
"  %16036 = and i32 %15770, 65535" -> "  %16037 = add nuw nsw i32 %16035, %16036"
"  %16037 = add nuw nsw i32 %16035, %16036"
"  %16037 = add nuw nsw i32 %16035, %16036" -> "  %16064 = and i32 %16037, 65535""  %16037 = add nuw nsw i32 %16035, %16036" -> "  %16041 = lshr i32 %16037, 16"
"  %16038 = and i32 %14592, 65535"
"  %16038 = and i32 %14592, 65535" -> "  %16040 = add nuw nsw i32 %16038, %16039"
"  %16039 = and i32 %15776, 65535"
"  %16039 = and i32 %15776, 65535" -> "  %16040 = add nuw nsw i32 %16038, %16039"
"  %16040 = add nuw nsw i32 %16038, %16039"
"  %16040 = add nuw nsw i32 %16038, %16039" -> "  %16056 = lshr i32 %16040, 16""  %16040 = add nuw nsw i32 %16038, %16039" -> "  %16042 = and i32 %16040, 65535"
"  %16041 = lshr i32 %16037, 16"
"  %16041 = lshr i32 %16037, 16" -> "  %16043 = add nuw nsw i32 %16042, %16041"
"  %16042 = and i32 %16040, 65535"
"  %16042 = and i32 %16040, 65535" -> "  %16043 = add nuw nsw i32 %16042, %16041"
"  %16043 = add nuw nsw i32 %16042, %16041"
"  %16043 = add nuw nsw i32 %16042, %16041" -> "  %16071 = and i32 %16043, 65535""  %16043 = add nuw nsw i32 %16042, %16041" -> "  %16058 = lshr i32 %16043, 16"
"  %16044 = and i32 %14594, 65535"
"  %16044 = and i32 %14594, 65535" -> "  %16046 = add nuw nsw i32 %16044, %16045"
"  %16045 = and i32 %15790, 65535"
"  %16045 = and i32 %15790, 65535" -> "  %16046 = add nuw nsw i32 %16044, %16045"
"  %16046 = add nuw nsw i32 %16044, %16045"
"  %16046 = add nuw nsw i32 %16044, %16045" -> "  %16055 = and i32 %16046, 65535""  %16046 = add nuw nsw i32 %16044, %16045" -> "  %16050 = lshr i32 %16046, 16"
"  %16047 = lshr i32 %14594, 16"
"  %16047 = lshr i32 %14594, 16" -> "  %16049 = add nuw nsw i32 %16047, %16048"
"  %16048 = and i32 %15793, 65535"
"  %16048 = and i32 %15793, 65535" -> "  %16049 = add nuw nsw i32 %16047, %16048"
"  %16049 = add nuw nsw i32 %16047, %16048"
"  %16049 = add nuw nsw i32 %16047, %16048" -> "  %16053 = lshr i32 %16049, 16""  %16049 = add nuw nsw i32 %16047, %16048" -> "  %16051 = and i32 %16049, 65535"
"  %16050 = lshr i32 %16046, 16"
"  %16050 = lshr i32 %16046, 16" -> "  %16052 = add nuw nsw i32 %16051, %16050"
"  %16051 = and i32 %16049, 65535"
"  %16051 = and i32 %16049, 65535" -> "  %16052 = add nuw nsw i32 %16051, %16050"
"  %16052 = add nuw nsw i32 %16051, %16050"
"  %16052 = add nuw nsw i32 %16051, %16050" -> "  %16060 = and i32 %16052, 65535""  %16052 = add nuw nsw i32 %16051, %16050" -> "  %16054 = lshr i32 %16052, 16"
"  %16053 = lshr i32 %16049, 16"
"  %16053 = lshr i32 %16049, 16" -> "  %16082 = add nuw nsw i32 %16053, %16081"
"  %16054 = lshr i32 %16052, 16"
"  %16054 = lshr i32 %16052, 16" -> "  %16083 = add nuw nsw i32 %16082, %16054"
"  %16055 = and i32 %16046, 65535"
"  %16055 = and i32 %16046, 65535" -> "  %16057 = add nuw nsw i32 %16055, %16056"
"  %16056 = lshr i32 %16040, 16"
"  %16056 = lshr i32 %16040, 16" -> "  %16057 = add nuw nsw i32 %16055, %16056"
"  %16057 = add nuw nsw i32 %16055, %16056"
"  %16057 = add nuw nsw i32 %16055, %16056" -> "  %16059 = add nuw nsw i32 %16057, %16058"
"  %16058 = lshr i32 %16043, 16"
"  %16058 = lshr i32 %16043, 16" -> "  %16059 = add nuw nsw i32 %16057, %16058"
"  %16059 = add nuw nsw i32 %16057, %16058"
"  %16059 = add nuw nsw i32 %16057, %16058" -> "  %16074 = and i32 %16059, 65535""  %16059 = add nuw nsw i32 %16057, %16058" -> "  %16061 = lshr i32 %16059, 16"
"  %16060 = and i32 %16052, 65535"
"  %16060 = and i32 %16052, 65535" -> "  %16062 = add nuw nsw i32 %16061, %16060"
"  %16061 = lshr i32 %16059, 16"
"  %16061 = lshr i32 %16059, 16" -> "  %16062 = add nuw nsw i32 %16061, %16060"
"  %16062 = add nuw nsw i32 %16061, %16060"
"  %16062 = add nuw nsw i32 %16061, %16060" -> "  %16077 = and i32 %16062, 65535""  %16062 = add nuw nsw i32 %16061, %16060" -> "  %16063 = lshr i32 %16062, 16"
"  %16063 = lshr i32 %16062, 16"
"  %16063 = lshr i32 %16062, 16" -> "  %16084 = add nuw nsw i32 %16083, %16063"
"  %16064 = and i32 %16037, 65535"
"  %16064 = and i32 %16037, 65535" -> "  %16069 = add nuw nsw i32 %16068, %16064"
"  %16065 = lshr i32 %16023, 16"
"  %16065 = lshr i32 %16023, 16" -> "  %16068 = add nuw nsw i32 %16066, %16065"
"  %16066 = lshr i32 %16026, 16"
"  %16066 = lshr i32 %16026, 16" -> "  %16068 = add nuw nsw i32 %16066, %16065"
"  %16067 = lshr i32 %16034, 16"
"  %16067 = lshr i32 %16034, 16" -> "  %16070 = add nuw nsw i32 %16069, %16067"
"  %16068 = add nuw nsw i32 %16066, %16065"
"  %16068 = add nuw nsw i32 %16066, %16065" -> "  %16069 = add nuw nsw i32 %16068, %16064"
"  %16069 = add nuw nsw i32 %16068, %16064"
"  %16069 = add nuw nsw i32 %16068, %16064" -> "  %16070 = add nuw nsw i32 %16069, %16067"
"  %16070 = add nuw nsw i32 %16069, %16067"
"  %16070 = add nuw nsw i32 %16069, %16067" -> "  %16130 = and i32 %16070, 65535""  %16070 = add nuw nsw i32 %16069, %16067" -> "  %16072 = lshr i32 %16070, 16"
"  %16071 = and i32 %16043, 65535"
"  %16071 = and i32 %16043, 65535" -> "  %16073 = add nuw nsw i32 %16071, %16072"
"  %16072 = lshr i32 %16070, 16"
"  %16072 = lshr i32 %16070, 16" -> "  %16073 = add nuw nsw i32 %16071, %16072"
"  %16073 = add nuw nsw i32 %16071, %16072"
"  %16073 = add nuw nsw i32 %16071, %16072" -> "  %16133 = and i32 %16073, 65535""  %16073 = add nuw nsw i32 %16071, %16072" -> "  %16075 = lshr i32 %16073, 16"
"  %16074 = and i32 %16059, 65535"
"  %16074 = and i32 %16059, 65535" -> "  %16076 = add nuw nsw i32 %16074, %16075"
"  %16075 = lshr i32 %16073, 16"
"  %16075 = lshr i32 %16073, 16" -> "  %16076 = add nuw nsw i32 %16074, %16075"
"  %16076 = add nuw nsw i32 %16074, %16075"
"  %16076 = add nuw nsw i32 %16074, %16075" -> "  %16139 = and i32 %16076, 65535""  %16076 = add nuw nsw i32 %16074, %16075" -> "  %16078 = lshr i32 %16076, 16"
"  %16077 = and i32 %16062, 65535"
"  %16077 = and i32 %16062, 65535" -> "  %16079 = add nuw nsw i32 %16077, %16078"
"  %16078 = lshr i32 %16076, 16"
"  %16078 = lshr i32 %16076, 16" -> "  %16079 = add nuw nsw i32 %16077, %16078"
"  %16079 = add nuw nsw i32 %16077, %16078"
"  %16079 = add nuw nsw i32 %16077, %16078" -> "  %16141 = and i32 %16079, 65535""  %16079 = add nuw nsw i32 %16077, %16078" -> "  %16080 = lshr i32 %16079, 16"
"  %16080 = lshr i32 %16079, 16"
"  %16080 = lshr i32 %16079, 16" -> "  %16085 = add nuw nsw i32 %16084, %16080"
"  %16081 = and i32 %15973, 65535"
"  %16081 = and i32 %15973, 65535" -> "  %16082 = add nuw nsw i32 %16053, %16081"
"  %16082 = add nuw nsw i32 %16053, %16081"
"  %16082 = add nuw nsw i32 %16053, %16081" -> "  %16083 = add nuw nsw i32 %16082, %16054"
"  %16083 = add nuw nsw i32 %16082, %16054"
"  %16083 = add nuw nsw i32 %16082, %16054" -> "  %16084 = add nuw nsw i32 %16083, %16063"
"  %16084 = add nuw nsw i32 %16083, %16063"
"  %16084 = add nuw nsw i32 %16083, %16063" -> "  %16085 = add nuw nsw i32 %16084, %16080"
"  %16085 = add nuw nsw i32 %16084, %16080"
"  %16085 = add nuw nsw i32 %16084, %16080" -> "  %16177 = and i32 %16085, 65535""  %16085 = add nuw nsw i32 %16084, %16080" -> "  %16087 = lshr i32 %16085, 16"
"  %16086 = and i32 %15979, 65535"
"  %16086 = and i32 %15979, 65535" -> "  %16088 = add nuw nsw i32 %16087, %16086"
"  %16087 = lshr i32 %16085, 16"
"  %16087 = lshr i32 %16085, 16" -> "  %16088 = add nuw nsw i32 %16087, %16086"
"  %16088 = add nuw nsw i32 %16087, %16086"
"  %16088 = add nuw nsw i32 %16087, %16086" -> "  %16176 = and i32 %16088, 65535""  %16088 = add nuw nsw i32 %16087, %16086" -> "  %16090 = lshr i32 %16088, 16"
"  %16089 = and i32 %15993, 65535"
"  %16089 = and i32 %15993, 65535" -> "  %16091 = add nuw nsw i32 %16090, %16089"
"  %16090 = lshr i32 %16088, 16"
"  %16090 = lshr i32 %16088, 16" -> "  %16091 = add nuw nsw i32 %16090, %16089"
"  %16091 = add nuw nsw i32 %16090, %16089"
"  %16091 = add nuw nsw i32 %16090, %16089" -> "  %16182 = and i32 %16091, 65535""  %16091 = add nuw nsw i32 %16090, %16089" -> "  %16092 = lshr i32 %16091, 16"
"  %16092 = lshr i32 %16091, 16"
"  %16092 = lshr i32 %16091, 16" -> "  %16094 = add nuw nsw i32 %16092, %16093"
"  %16093 = and i32 %15996, 65535"
"  %16093 = and i32 %15996, 65535" -> "  %16094 = add nuw nsw i32 %16092, %16093"
"  %16094 = add nuw nsw i32 %16092, %16093"
"  %16094 = add nuw nsw i32 %16092, %16093" -> "  %16188 = and i32 %16094, 65535""  %16094 = add nuw nsw i32 %16092, %16093" -> "  %16095 = lshr i32 %16094, 16"
"  %16095 = lshr i32 %16094, 16"
"  %16095 = lshr i32 %16094, 16" -> "  %16097 = add nuw nsw i32 %16095, %16096"
"  %16096 = and i32 %16003, 65535"
"  %16096 = and i32 %16003, 65535" -> "  %16097 = add nuw nsw i32 %16095, %16096"
"  %16097 = add nuw nsw i32 %16095, %16096"
"  %16097 = add nuw nsw i32 %16095, %16096" -> "  %16194 = and i32 %16097, 65535""  %16097 = add nuw nsw i32 %16095, %16096" -> "  %16098 = lshr i32 %16097, 16"
"  %16098 = lshr i32 %16097, 16"
"  %16098 = lshr i32 %16097, 16" -> "  %16100 = add nuw nsw i32 %16098, %16099"
"  %16099 = and i32 %16006, 65535"
"  %16099 = and i32 %16006, 65535" -> "  %16100 = add nuw nsw i32 %16098, %16099"
"  %16100 = add nuw nsw i32 %16098, %16099"
"  %16100 = add nuw nsw i32 %16098, %16099" -> "  %16196 = and i32 %16100, 65535""  %16100 = add nuw nsw i32 %16098, %16099" -> "  %16101 = lshr i32 %16100, 16"
"  %16101 = lshr i32 %16100, 16"
"  %16101 = lshr i32 %16100, 16" -> "  %16102 = add nuw i32 %16008, %16101"
"  %16102 = add nuw i32 %16008, %16101"
"  %16102 = add nuw i32 %16008, %16101" -> "  %16201 = add nuw i32 %16102, %16200"
"  %16103 = and i32 %15331, 65535"
"  %16103 = and i32 %15331, 65535" -> "  %16105 = add nuw nsw i32 %16103, %16104"
"  %16104 = and i32 %16011, 65535"
"  %16104 = and i32 %16011, 65535" -> "  %16105 = add nuw nsw i32 %16103, %16104"
"  %16105 = add nuw nsw i32 %16103, %16104"
"  %16105 = add nuw nsw i32 %16103, %16104" -> "  %16109 = lshr i32 %16105, 16"
"  %16106 = and i32 %15334, 65535"
"  %16106 = and i32 %15334, 65535" -> "  %16108 = add nuw nsw i32 %16106, %16107"
"  %16107 = and i32 %16017, 65535"
"  %16107 = and i32 %16017, 65535" -> "  %16108 = add nuw nsw i32 %16106, %16107"
"  %16108 = add nuw nsw i32 %16106, %16107"
"  %16108 = add nuw nsw i32 %16106, %16107" -> "  %16122 = lshr i32 %16108, 16""  %16108 = add nuw nsw i32 %16106, %16107" -> "  %16110 = and i32 %16108, 65535"
"  %16109 = lshr i32 %16105, 16"
"  %16109 = lshr i32 %16105, 16" -> "  %16111 = add nuw nsw i32 %16110, %16109"
"  %16110 = and i32 %16108, 65535"
"  %16110 = and i32 %16108, 65535" -> "  %16111 = add nuw nsw i32 %16110, %16109"
"  %16111 = add nuw nsw i32 %16110, %16109"
"  %16111 = add nuw nsw i32 %16110, %16109" -> "  %16124 = lshr i32 %16111, 16"
"  %16112 = and i32 %15337, 65535"
"  %16112 = and i32 %15337, 65535" -> "  %16114 = add nuw nsw i32 %16112, %16113"
"  %16113 = and i32 %16031, 65535"
"  %16113 = and i32 %16031, 65535" -> "  %16114 = add nuw nsw i32 %16112, %16113"
"  %16114 = add nuw nsw i32 %16112, %16113"
"  %16114 = add nuw nsw i32 %16112, %16113" -> "  %16121 = and i32 %16114, 65535""  %16114 = add nuw nsw i32 %16112, %16113" -> "  %16118 = lshr i32 %16114, 16"
"  %16115 = and i32 %15340, 65535"
"  %16115 = and i32 %15340, 65535" -> "  %16117 = add nuw nsw i32 %16115, %16116"
"  %16116 = and i32 %16034, 65535"
"  %16116 = and i32 %16034, 65535" -> "  %16117 = add nuw nsw i32 %16115, %16116"
"  %16117 = add nuw nsw i32 %16115, %16116"
"  %16117 = add nuw nsw i32 %16115, %16116" -> "  %16159 = lshr i32 %16117, 16""  %16117 = add nuw nsw i32 %16115, %16116" -> "  %16119 = and i32 %16117, 65535"
"  %16118 = lshr i32 %16114, 16"
"  %16118 = lshr i32 %16114, 16" -> "  %16120 = add nuw nsw i32 %16119, %16118"
"  %16119 = and i32 %16117, 65535"
"  %16119 = and i32 %16117, 65535" -> "  %16120 = add nuw nsw i32 %16119, %16118"
"  %16120 = add nuw nsw i32 %16119, %16118"
"  %16120 = add nuw nsw i32 %16119, %16118" -> "  %16161 = lshr i32 %16120, 16""  %16120 = add nuw nsw i32 %16119, %16118" -> "  %16127 = and i32 %16120, 65535"
"  %16121 = and i32 %16114, 65535"
"  %16121 = and i32 %16114, 65535" -> "  %16123 = add nuw nsw i32 %16121, %16122"
"  %16122 = lshr i32 %16108, 16"
"  %16122 = lshr i32 %16108, 16" -> "  %16123 = add nuw nsw i32 %16121, %16122"
"  %16123 = add nuw nsw i32 %16121, %16122"
"  %16123 = add nuw nsw i32 %16121, %16122" -> "  %16125 = add nuw nsw i32 %16123, %16124"
"  %16124 = lshr i32 %16111, 16"
"  %16124 = lshr i32 %16111, 16" -> "  %16125 = add nuw nsw i32 %16123, %16124"
"  %16125 = add nuw nsw i32 %16123, %16124"
"  %16125 = add nuw nsw i32 %16123, %16124" -> "  %16126 = lshr i32 %16125, 16"
"  %16126 = lshr i32 %16125, 16"
"  %16126 = lshr i32 %16125, 16" -> "  %16128 = add nuw nsw i32 %16127, %16126"
"  %16127 = and i32 %16120, 65535"
"  %16127 = and i32 %16120, 65535" -> "  %16128 = add nuw nsw i32 %16127, %16126"
"  %16128 = add nuw nsw i32 %16127, %16126"
"  %16128 = add nuw nsw i32 %16127, %16126" -> "  %16163 = lshr i32 %16128, 16"
"  %16129 = and i32 %15343, 65535"
"  %16129 = and i32 %15343, 65535" -> "  %16131 = add nuw nsw i32 %16129, %16130"
"  %16130 = and i32 %16070, 65535"
"  %16130 = and i32 %16070, 65535" -> "  %16131 = add nuw nsw i32 %16129, %16130"
"  %16131 = add nuw nsw i32 %16129, %16130"
"  %16131 = add nuw nsw i32 %16129, %16130" -> "  %16158 = and i32 %16131, 65535""  %16131 = add nuw nsw i32 %16129, %16130" -> "  %16135 = lshr i32 %16131, 16"
"  %16132 = and i32 %15346, 65535"
"  %16132 = and i32 %15346, 65535" -> "  %16134 = add nuw nsw i32 %16132, %16133"
"  %16133 = and i32 %16073, 65535"
"  %16133 = and i32 %16073, 65535" -> "  %16134 = add nuw nsw i32 %16132, %16133"
"  %16134 = add nuw nsw i32 %16132, %16133"
"  %16134 = add nuw nsw i32 %16132, %16133" -> "  %16150 = lshr i32 %16134, 16""  %16134 = add nuw nsw i32 %16132, %16133" -> "  %16136 = and i32 %16134, 65535"
"  %16135 = lshr i32 %16131, 16"
"  %16135 = lshr i32 %16131, 16" -> "  %16137 = add nuw nsw i32 %16136, %16135"
"  %16136 = and i32 %16134, 65535"
"  %16136 = and i32 %16134, 65535" -> "  %16137 = add nuw nsw i32 %16136, %16135"
"  %16137 = add nuw nsw i32 %16136, %16135"
"  %16137 = add nuw nsw i32 %16136, %16135" -> "  %16165 = and i32 %16137, 65535""  %16137 = add nuw nsw i32 %16136, %16135" -> "  %16152 = lshr i32 %16137, 16"
"  %16138 = and i32 %15348, 65535"
"  %16138 = and i32 %15348, 65535" -> "  %16140 = add nuw nsw i32 %16138, %16139"
"  %16139 = and i32 %16076, 65535"
"  %16139 = and i32 %16076, 65535" -> "  %16140 = add nuw nsw i32 %16138, %16139"
"  %16140 = add nuw nsw i32 %16138, %16139"
"  %16140 = add nuw nsw i32 %16138, %16139" -> "  %16149 = and i32 %16140, 65535""  %16140 = add nuw nsw i32 %16138, %16139" -> "  %16144 = lshr i32 %16140, 16"
"  %16141 = and i32 %16079, 65535"
"  %16141 = and i32 %16079, 65535" -> "  %16143 = add nuw nsw i32 %16141, %16142"
"  %16142 = lshr i32 %15348, 16"
"  %16142 = lshr i32 %15348, 16" -> "  %16143 = add nuw nsw i32 %16141, %16142"
"  %16143 = add nuw nsw i32 %16141, %16142"
"  %16143 = add nuw nsw i32 %16141, %16142" -> "  %16147 = lshr i32 %16143, 16""  %16143 = add nuw nsw i32 %16141, %16142" -> "  %16145 = and i32 %16143, 65535"
"  %16144 = lshr i32 %16140, 16"
"  %16144 = lshr i32 %16140, 16" -> "  %16146 = add nuw nsw i32 %16145, %16144"
"  %16145 = and i32 %16143, 65535"
"  %16145 = and i32 %16143, 65535" -> "  %16146 = add nuw nsw i32 %16145, %16144"
"  %16146 = add nuw nsw i32 %16145, %16144"
"  %16146 = add nuw nsw i32 %16145, %16144" -> "  %16154 = and i32 %16146, 65535""  %16146 = add nuw nsw i32 %16145, %16144" -> "  %16148 = lshr i32 %16146, 16"
"  %16147 = lshr i32 %16143, 16"
"  %16147 = lshr i32 %16143, 16" -> "  %16178 = add nuw nsw i32 %16177, %16147"
"  %16148 = lshr i32 %16146, 16"
"  %16148 = lshr i32 %16146, 16" -> "  %16179 = add nuw nsw i32 %16178, %16148"
"  %16149 = and i32 %16140, 65535"
"  %16149 = and i32 %16140, 65535" -> "  %16151 = add nuw nsw i32 %16149, %16150"
"  %16150 = lshr i32 %16134, 16"
"  %16150 = lshr i32 %16134, 16" -> "  %16151 = add nuw nsw i32 %16149, %16150"
"  %16151 = add nuw nsw i32 %16149, %16150"
"  %16151 = add nuw nsw i32 %16149, %16150" -> "  %16153 = add nuw nsw i32 %16151, %16152"
"  %16152 = lshr i32 %16137, 16"
"  %16152 = lshr i32 %16137, 16" -> "  %16153 = add nuw nsw i32 %16151, %16152"
"  %16153 = add nuw nsw i32 %16151, %16152"
"  %16153 = add nuw nsw i32 %16151, %16152" -> "  %16168 = and i32 %16153, 65535""  %16153 = add nuw nsw i32 %16151, %16152" -> "  %16155 = lshr i32 %16153, 16"
"  %16154 = and i32 %16146, 65535"
"  %16154 = and i32 %16146, 65535" -> "  %16156 = add nuw nsw i32 %16155, %16154"
"  %16155 = lshr i32 %16153, 16"
"  %16155 = lshr i32 %16153, 16" -> "  %16156 = add nuw nsw i32 %16155, %16154"
"  %16156 = add nuw nsw i32 %16155, %16154"
"  %16156 = add nuw nsw i32 %16155, %16154" -> "  %16171 = and i32 %16156, 65535""  %16156 = add nuw nsw i32 %16155, %16154" -> "  %16157 = lshr i32 %16156, 16"
"  %16157 = lshr i32 %16156, 16"
"  %16157 = lshr i32 %16156, 16" -> "  %16180 = add nuw nsw i32 %16179, %16157"
"  %16158 = and i32 %16131, 65535"
"  %16158 = and i32 %16131, 65535" -> "  %16160 = add nuw nsw i32 %16158, %16159"
"  %16159 = lshr i32 %16117, 16"
"  %16159 = lshr i32 %16117, 16" -> "  %16160 = add nuw nsw i32 %16158, %16159"
"  %16160 = add nuw nsw i32 %16158, %16159"
"  %16160 = add nuw nsw i32 %16158, %16159" -> "  %16162 = add nuw nsw i32 %16160, %16161"
"  %16161 = lshr i32 %16120, 16"
"  %16161 = lshr i32 %16120, 16" -> "  %16162 = add nuw nsw i32 %16160, %16161"
"  %16162 = add nuw nsw i32 %16160, %16161"
"  %16162 = add nuw nsw i32 %16160, %16161" -> "  %16164 = add nuw nsw i32 %16162, %16163"
"  %16163 = lshr i32 %16128, 16"
"  %16163 = lshr i32 %16128, 16" -> "  %16164 = add nuw nsw i32 %16162, %16163"
"  %16164 = add nuw nsw i32 %16162, %16163"
"  %16164 = add nuw nsw i32 %16162, %16163" -> "  %16166 = lshr i32 %16164, 16"
"  %16165 = and i32 %16137, 65535"
"  %16165 = and i32 %16137, 65535" -> "  %16167 = add nuw nsw i32 %16166, %16165"
"  %16166 = lshr i32 %16164, 16"
"  %16166 = lshr i32 %16164, 16" -> "  %16167 = add nuw nsw i32 %16166, %16165"
"  %16167 = add nuw nsw i32 %16166, %16165"
"  %16167 = add nuw nsw i32 %16166, %16165" -> "  %16169 = lshr i32 %16167, 16"
"  %16168 = and i32 %16153, 65535"
"  %16168 = and i32 %16153, 65535" -> "  %16170 = add nuw nsw i32 %16168, %16169"
"  %16169 = lshr i32 %16167, 16"
"  %16169 = lshr i32 %16167, 16" -> "  %16170 = add nuw nsw i32 %16168, %16169"
"  %16170 = add nuw nsw i32 %16168, %16169"
"  %16170 = add nuw nsw i32 %16168, %16169" -> "  %16172 = lshr i32 %16170, 16"
"  %16171 = and i32 %16156, 65535"
"  %16171 = and i32 %16156, 65535" -> "  %16173 = add nuw nsw i32 %16172, %16171"
"  %16172 = lshr i32 %16170, 16"
"  %16172 = lshr i32 %16170, 16" -> "  %16173 = add nuw nsw i32 %16172, %16171"
"  %16173 = add nuw nsw i32 %16172, %16171"
"  %16173 = add nuw nsw i32 %16172, %16171" -> "  %16175 = lshr i32 %16173, 16""  %16173 = add nuw nsw i32 %16172, %16171" -> "  %16174 = lshr i32 %16173, 15"
"  %16174 = lshr i32 %16173, 15"
"  %16174 = lshr i32 %16173, 15" -> "  %16223 = and i32 %16174, 1"
"  %16175 = lshr i32 %16173, 16"
"  %16175 = lshr i32 %16173, 16" -> "  %16181 = add nuw nsw i32 %16180, %16175"
"  %16176 = and i32 %16088, 65535"
"  %16176 = and i32 %16088, 65535" -> "  %16184 = add nuw nsw i32 %16183, %16176"
"  %16177 = and i32 %16085, 65535"
"  %16177 = and i32 %16085, 65535" -> "  %16178 = add nuw nsw i32 %16177, %16147"
"  %16178 = add nuw nsw i32 %16177, %16147"
"  %16178 = add nuw nsw i32 %16177, %16147" -> "  %16179 = add nuw nsw i32 %16178, %16148"
"  %16179 = add nuw nsw i32 %16178, %16148"
"  %16179 = add nuw nsw i32 %16178, %16148" -> "  %16180 = add nuw nsw i32 %16179, %16157"
"  %16180 = add nuw nsw i32 %16179, %16157"
"  %16180 = add nuw nsw i32 %16179, %16157" -> "  %16181 = add nuw nsw i32 %16180, %16175"
"  %16181 = add nuw nsw i32 %16180, %16175"
"  %16181 = add nuw nsw i32 %16180, %16175" -> "  %16224 = shl nuw nsw i32 %16181, 1""  %16181 = add nuw nsw i32 %16180, %16175" -> "  %16210 = lshr i32 %16181, 15""  %16181 = add nuw nsw i32 %16180, %16175" -> "  %16183 = lshr i32 %16181, 16"
"  %16182 = and i32 %16091, 65535"
"  %16182 = and i32 %16091, 65535" -> "  %16187 = add nuw nsw i32 %16186, %16182"
"  %16183 = lshr i32 %16181, 16"
"  %16183 = lshr i32 %16181, 16" -> "  %16184 = add nuw nsw i32 %16183, %16176"
"  %16184 = add nuw nsw i32 %16183, %16176"
"  %16184 = add nuw nsw i32 %16183, %16176" -> "  %16212 = shl nuw nsw i32 %16184, 1""  %16184 = add nuw nsw i32 %16183, %16176" -> "  %16186 = lshr i32 %16184, 16""  %16184 = add nuw nsw i32 %16183, %16176" -> "  %16185 = lshr i32 %16184, 15"
"  %16185 = lshr i32 %16184, 15"
"  %16185 = lshr i32 %16184, 15" -> "  %16206 = and i32 %16185, 1"
"  %16186 = lshr i32 %16184, 16"
"  %16186 = lshr i32 %16184, 16" -> "  %16187 = add nuw nsw i32 %16186, %16182"
"  %16187 = add nuw nsw i32 %16186, %16182"
"  %16187 = add nuw nsw i32 %16186, %16182" -> "  %16207 = shl nuw nsw i32 %16187, 1""  %16187 = add nuw nsw i32 %16186, %16182" -> "  %16190 = lshr i32 %16187, 16""  %16187 = add nuw nsw i32 %16186, %16182" -> "  %16189 = lshr i32 %16187, 15"
"  %16188 = and i32 %16094, 65535"
"  %16188 = and i32 %16094, 65535" -> "  %16191 = add nuw nsw i32 %16190, %16188"
"  %16189 = lshr i32 %16187, 15"
"  %16189 = lshr i32 %16187, 15" -> "  %16202 = and i32 %16189, 1"
"  %16190 = lshr i32 %16187, 16"
"  %16190 = lshr i32 %16187, 16" -> "  %16191 = add nuw nsw i32 %16190, %16188"
"  %16191 = add nuw nsw i32 %16190, %16188"
"  %16191 = add nuw nsw i32 %16190, %16188" -> "  %16203 = shl nuw nsw i32 %16191, 1""  %16191 = add nuw nsw i32 %16190, %16188" -> "  %16193 = lshr i32 %16191, 16""  %16191 = add nuw nsw i32 %16190, %16188" -> "  %16192 = lshr i32 %16191, 15"
"  %16192 = lshr i32 %16191, 15"
"  %16192 = lshr i32 %16191, 15" -> "  %16219 = and i32 %16192, 1"
"  %16193 = lshr i32 %16191, 16"
"  %16193 = lshr i32 %16191, 16" -> "  %16195 = add nuw nsw i32 %16193, %16194"
"  %16194 = and i32 %16097, 65535"
"  %16194 = and i32 %16097, 65535" -> "  %16195 = add nuw nsw i32 %16193, %16194"
"  %16195 = add nuw nsw i32 %16193, %16194"
"  %16195 = add nuw nsw i32 %16193, %16194" -> "  %16220 = shl nuw nsw i32 %16195, 1""  %16195 = add nuw nsw i32 %16193, %16194" -> "  %16427 = lshr i32 %16195, 15""  %16195 = add nuw nsw i32 %16193, %16194" -> "  %16197 = lshr i32 %16195, 16"
"  %16196 = and i32 %16100, 65535"
"  %16196 = and i32 %16100, 65535" -> "  %16198 = add nuw nsw i32 %16197, %16196"
"  %16197 = lshr i32 %16195, 16"
"  %16197 = lshr i32 %16195, 16" -> "  %16198 = add nuw nsw i32 %16197, %16196"
"  %16198 = add nuw nsw i32 %16197, %16196"
"  %16198 = add nuw nsw i32 %16197, %16196" -> "  %16429 = shl nuw nsw i32 %16198, 1""  %16198 = add nuw nsw i32 %16197, %16196" -> "  %16200 = lshr i32 %16198, 16""  %16198 = add nuw nsw i32 %16197, %16196" -> "  %16199 = lshr i32 %16198, 15"
"  %16199 = lshr i32 %16198, 15"
"  %16199 = lshr i32 %16198, 15" -> "  %16215 = and i32 %16199, 1"
"  %16200 = lshr i32 %16198, 16"
"  %16200 = lshr i32 %16198, 16" -> "  %16201 = add nuw i32 %16102, %16200"
"  %16201 = add nuw i32 %16102, %16200"
"  %16201 = add nuw i32 %16102, %16200" -> "  %16216 = shl i32 %16201, 1""  %16201 = add nuw i32 %16102, %16200" -> "  %16450 = lshr i32 %16201, 15"
"  %16202 = and i32 %16189, 1"
"  %16202 = and i32 %16189, 1" -> "  %16205 = or i32 %16204, %16202"
"  %16203 = shl nuw nsw i32 %16191, 1"
"  %16203 = shl nuw nsw i32 %16191, 1" -> "  %16204 = and i32 %16203, 65534"
"  %16204 = and i32 %16203, 65534"
"  %16204 = and i32 %16203, 65534" -> "  %16205 = or i32 %16204, %16202"
"  %16205 = or i32 %16204, %16202"
"  %16205 = or i32 %16204, %16202" -> "  %16386 = mul nuw nsw i32 %16205, 1146""  %16205 = or i32 %16204, %16202" -> "  %16318 = mul nuw i32 %16205, 63663""  %16205 = or i32 %16204, %16202" -> "  %16314 = mul nuw nsw i32 %16205, 7935""  %16205 = or i32 %16204, %16202" -> "  %16287 = mul nuw i32 %16205, 34017""  %16205 = or i32 %16204, %16202" -> "  %16283 = mul nuw nsw i32 %16205, 17399"
"  %16206 = and i32 %16185, 1"
"  %16206 = and i32 %16185, 1" -> "  %16209 = or i32 %16208, %16206"
"  %16207 = shl nuw nsw i32 %16187, 1"
"  %16207 = shl nuw nsw i32 %16187, 1" -> "  %16208 = and i32 %16207, 65534"
"  %16208 = and i32 %16207, 65534"
"  %16208 = and i32 %16207, 65534" -> "  %16209 = or i32 %16208, %16206"
"  %16209 = or i32 %16208, %16206"
"  %16209 = or i32 %16208, %16206" -> "  %16383 = mul nuw nsw i32 %16209, 1146""  %16209 = or i32 %16208, %16206" -> "  %16381 = mul nuw i32 %16209, 43563""  %16209 = or i32 %16208, %16206" -> "  %16309 = mul nuw i32 %16209, 63663""  %16209 = or i32 %16208, %16206" -> "  %16307 = mul nuw nsw i32 %16209, 7935""  %16209 = or i32 %16208, %16206" -> "  %16278 = mul nuw i32 %16209, 34017""  %16209 = or i32 %16208, %16206" -> "  %16276 = mul nuw nsw i32 %16209, 17399"
"  %16210 = lshr i32 %16181, 15"
"  %16210 = lshr i32 %16181, 15" -> "  %16211 = and i32 %16210, 1"
"  %16211 = and i32 %16210, 1"
"  %16211 = and i32 %16210, 1" -> "  %16214 = or i32 %16213, %16211"
"  %16212 = shl nuw nsw i32 %16184, 1"
"  %16212 = shl nuw nsw i32 %16184, 1" -> "  %16213 = and i32 %16212, 65534"
"  %16213 = and i32 %16212, 65534"
"  %16213 = and i32 %16212, 65534" -> "  %16214 = or i32 %16213, %16211"
"  %16214 = or i32 %16213, %16211"
"  %16214 = or i32 %16213, %16211" -> "  %16376 = mul nuw nsw i32 %16214, 13953""  %16214 = or i32 %16213, %16211" -> "  %16365 = mul nuw i32 %16214, 43563""  %16214 = or i32 %16213, %16211" -> "  %16361 = mul nuw nsw i32 %16214, 1146""  %16214 = or i32 %16213, %16211" -> "  %16256 = mul nuw i32 %16214, 63663""  %16214 = or i32 %16213, %16211" -> "  %16252 = mul nuw nsw i32 %16214, 7935""  %16214 = or i32 %16213, %16211" -> "  %16238 = mul nuw i32 %16214, 34017""  %16214 = or i32 %16213, %16211" -> "  %16234 = mul nuw nsw i32 %16214, 17399"
"  %16215 = and i32 %16199, 1"
"  %16215 = and i32 %16199, 1" -> "  %16218 = or i32 %16217, %16215"
"  %16216 = shl i32 %16201, 1"
"  %16216 = shl i32 %16201, 1" -> "  %16217 = and i32 %16216, 65534"
"  %16217 = and i32 %16216, 65534"
"  %16217 = and i32 %16216, 65534" -> "  %16218 = or i32 %16217, %16215"
"  %16218 = or i32 %16217, %16215"
"  %16218 = or i32 %16217, %16215" -> "  %16453 = mul nuw i32 %16218, 34017""  %16218 = or i32 %16217, %16215" -> "  %16454 = mul nuw nsw i32 %16218, 17399"
"  %16219 = and i32 %16192, 1"
"  %16219 = and i32 %16192, 1" -> "  %16222 = or i32 %16221, %16219"
"  %16220 = shl nuw nsw i32 %16195, 1"
"  %16220 = shl nuw nsw i32 %16195, 1" -> "  %16221 = and i32 %16220, 65534"
"  %16221 = and i32 %16220, 65534"
"  %16221 = and i32 %16220, 65534" -> "  %16222 = or i32 %16221, %16219"
"  %16222 = or i32 %16221, %16219"
"  %16222 = or i32 %16221, %16219" -> "  %16420 = mul nuw nsw i32 %16222, 17399""  %16222 = or i32 %16221, %16219" -> "  %16422 = mul nuw i32 %16222, 34017""  %16222 = or i32 %16221, %16219" -> "  %16443 = mul nuw nsw i32 %16222, 7935""  %16222 = or i32 %16221, %16219" -> "  %16445 = mul nuw i32 %16222, 63663"
"  %16223 = and i32 %16174, 1"
"  %16223 = and i32 %16174, 1" -> "  %16226 = or i32 %16225, %16223"
"  %16224 = shl nuw nsw i32 %16181, 1"
"  %16224 = shl nuw nsw i32 %16181, 1" -> "  %16225 = and i32 %16224, 65534"
"  %16225 = and i32 %16224, 65534"
"  %16225 = and i32 %16224, 65534" -> "  %16226 = or i32 %16225, %16223"
"  %16226 = or i32 %16225, %16223"
"  %16226 = or i32 %16225, %16223" -> "  %16374 = mul nuw i32 %16226, 58377""  %16226 = or i32 %16225, %16223" -> "  %16372 = mul nuw nsw i32 %16226, 13953""  %16226 = or i32 %16225, %16223" -> "  %16356 = mul nuw i32 %16226, 43563""  %16226 = or i32 %16225, %16223" -> "  %16354 = mul nuw nsw i32 %16226, 1146""  %16226 = or i32 %16225, %16223" -> "  %16247 = mul nuw i32 %16226, 63663""  %16226 = or i32 %16225, %16223" -> "  %16245 = mul nuw nsw i32 %16226, 7935""  %16226 = or i32 %16225, %16223" -> "  %16229 = mul nuw i32 %16226, 34017""  %16226 = or i32 %16225, %16223" -> "  %16227 = mul nuw nsw i32 %16226, 17399"
"  %16227 = mul nuw nsw i32 %16226, 17399"
"  %16227 = mul nuw nsw i32 %16226, 17399" -> "  %16494 = and i32 %16227, 65535""  %16227 = mul nuw nsw i32 %16226, 17399" -> "  %16228 = lshr i32 %16227, 16"
"  %16228 = lshr i32 %16227, 16"
"  %16228 = lshr i32 %16227, 16" -> "  %16231 = add nuw nsw i32 %16228, %16230"
"  %16229 = mul nuw i32 %16226, 34017"
"  %16229 = mul nuw i32 %16226, 34017" -> "  %16232 = and i32 %16229, -65536""  %16229 = mul nuw i32 %16226, 34017" -> "  %16230 = and i32 %16229, 65535"
"  %16230 = and i32 %16229, 65535"
"  %16230 = and i32 %16229, 65535" -> "  %16231 = add nuw nsw i32 %16228, %16230"
"  %16231 = add nuw nsw i32 %16228, %16230"
"  %16231 = add nuw nsw i32 %16228, %16230" -> "  %16233 = add nuw i32 %16231, %16232"
"  %16232 = and i32 %16229, -65536"
"  %16232 = and i32 %16229, -65536" -> "  %16233 = add nuw i32 %16231, %16232"
"  %16233 = add nuw i32 %16231, %16232"
"  %16233 = add nuw i32 %16231, %16232" -> "  %16237 = lshr i32 %16233, 16""  %16233 = add nuw i32 %16231, %16232" -> "  %16235 = and i32 %16233, 65535"
"  %16234 = mul nuw nsw i32 %16214, 17399"
"  %16234 = mul nuw nsw i32 %16214, 17399" -> "  %16236 = add nuw nsw i32 %16235, %16234"
"  %16235 = and i32 %16233, 65535"
"  %16235 = and i32 %16233, 65535" -> "  %16236 = add nuw nsw i32 %16235, %16234"
"  %16236 = add nuw nsw i32 %16235, %16234"
"  %16236 = add nuw nsw i32 %16235, %16234" -> "  %16496 = and i32 %16236, 65535""  %16236 = add nuw nsw i32 %16235, %16234" -> "  %16240 = lshr i32 %16236, 16"
"  %16237 = lshr i32 %16233, 16"
"  %16237 = lshr i32 %16233, 16" -> "  %16239 = add nuw i32 %16237, %16238"
"  %16238 = mul nuw i32 %16214, 34017"
"  %16238 = mul nuw i32 %16214, 34017" -> "  %16239 = add nuw i32 %16237, %16238"
"  %16239 = add nuw i32 %16237, %16238"
"  %16239 = add nuw i32 %16237, %16238" -> "  %16243 = and i32 %16239, -65536""  %16239 = add nuw i32 %16237, %16238" -> "  %16241 = and i32 %16239, 65535"
"  %16240 = lshr i32 %16236, 16"
"  %16240 = lshr i32 %16236, 16" -> "  %16242 = add nuw nsw i32 %16240, %16241"
"  %16241 = and i32 %16239, 65535"
"  %16241 = and i32 %16239, 65535" -> "  %16242 = add nuw nsw i32 %16240, %16241"
"  %16242 = add nuw nsw i32 %16240, %16241"
"  %16242 = add nuw nsw i32 %16240, %16241" -> "  %16244 = add i32 %16242, %16243"
"  %16243 = and i32 %16239, -65536"
"  %16243 = and i32 %16239, -65536" -> "  %16244 = add i32 %16242, %16243"
"  %16244 = add i32 %16242, %16243"
"  %16244 = add i32 %16242, %16243" -> "  %16267 = lshr i32 %16244, 16""  %16244 = add i32 %16242, %16243" -> "  %16263 = and i32 %16244, 65535"
"  %16245 = mul nuw nsw i32 %16226, 7935"
"  %16245 = mul nuw nsw i32 %16226, 7935" -> "  %16264 = and i32 %16245, 65535""  %16245 = mul nuw nsw i32 %16226, 7935" -> "  %16246 = lshr i32 %16245, 16"
"  %16246 = lshr i32 %16245, 16"
"  %16246 = lshr i32 %16245, 16" -> "  %16249 = add nuw nsw i32 %16246, %16248"
"  %16247 = mul nuw i32 %16226, 63663"
"  %16247 = mul nuw i32 %16226, 63663" -> "  %16250 = and i32 %16247, -65536""  %16247 = mul nuw i32 %16226, 63663" -> "  %16248 = and i32 %16247, 65535"
"  %16248 = and i32 %16247, 65535"
"  %16248 = and i32 %16247, 65535" -> "  %16249 = add nuw nsw i32 %16246, %16248"
"  %16249 = add nuw nsw i32 %16246, %16248"
"  %16249 = add nuw nsw i32 %16246, %16248" -> "  %16251 = add i32 %16249, %16250"
"  %16250 = and i32 %16247, -65536"
"  %16250 = and i32 %16247, -65536" -> "  %16251 = add i32 %16249, %16250"
"  %16251 = add i32 %16249, %16250"
"  %16251 = add i32 %16249, %16250" -> "  %16255 = lshr i32 %16251, 16""  %16251 = add i32 %16249, %16250" -> "  %16253 = and i32 %16251, 65535"
"  %16252 = mul nuw nsw i32 %16214, 7935"
"  %16252 = mul nuw nsw i32 %16214, 7935" -> "  %16254 = add nuw nsw i32 %16253, %16252"
"  %16253 = and i32 %16251, 65535"
"  %16253 = and i32 %16251, 65535" -> "  %16254 = add nuw nsw i32 %16253, %16252"
"  %16254 = add nuw nsw i32 %16253, %16252"
"  %16254 = add nuw nsw i32 %16253, %16252" -> "  %16266 = and i32 %16254, 65535""  %16254 = add nuw nsw i32 %16253, %16252" -> "  %16258 = lshr i32 %16254, 16"
"  %16255 = lshr i32 %16251, 16"
"  %16255 = lshr i32 %16251, 16" -> "  %16257 = add i32 %16255, %16256"
"  %16256 = mul nuw i32 %16214, 63663"
"  %16256 = mul nuw i32 %16214, 63663" -> "  %16257 = add i32 %16255, %16256"
"  %16257 = add i32 %16255, %16256"
"  %16257 = add i32 %16255, %16256" -> "  %16261 = and i32 %16257, -65536""  %16257 = add i32 %16255, %16256" -> "  %16259 = and i32 %16257, 65535"
"  %16258 = lshr i32 %16254, 16"
"  %16258 = lshr i32 %16254, 16" -> "  %16260 = add nuw nsw i32 %16258, %16259"
"  %16259 = and i32 %16257, 65535"
"  %16259 = and i32 %16257, 65535" -> "  %16260 = add nuw nsw i32 %16258, %16259"
"  %16260 = add nuw nsw i32 %16258, %16259"
"  %16260 = add nuw nsw i32 %16258, %16259" -> "  %16262 = add i32 %16260, %16261"
"  %16261 = and i32 %16257, -65536"
"  %16261 = and i32 %16257, -65536" -> "  %16262 = add i32 %16260, %16261"
"  %16262 = add i32 %16260, %16261"
"  %16262 = add i32 %16260, %16261" -> "  %16270 = add i32 %16262, %16269"
"  %16263 = and i32 %16244, 65535"
"  %16263 = and i32 %16244, 65535" -> "  %16265 = add nuw nsw i32 %16263, %16264"
"  %16264 = and i32 %16245, 65535"
"  %16264 = and i32 %16245, 65535" -> "  %16265 = add nuw nsw i32 %16263, %16264"
"  %16265 = add nuw nsw i32 %16263, %16264"
"  %16265 = add nuw nsw i32 %16263, %16264" -> "  %16294 = and i32 %16265, 65535""  %16265 = add nuw nsw i32 %16263, %16264" -> "  %16272 = lshr i32 %16265, 16"
"  %16266 = and i32 %16254, 65535"
"  %16266 = and i32 %16254, 65535" -> "  %16268 = add nuw nsw i32 %16267, %16266"
"  %16267 = lshr i32 %16244, 16"
"  %16267 = lshr i32 %16244, 16" -> "  %16268 = add nuw nsw i32 %16267, %16266"
"  %16268 = add nuw nsw i32 %16267, %16266"
"  %16268 = add nuw nsw i32 %16267, %16266" -> "  %16271 = and i32 %16268, 65535""  %16268 = add nuw nsw i32 %16267, %16266" -> "  %16269 = lshr i32 %16268, 16"
"  %16269 = lshr i32 %16268, 16"
"  %16269 = lshr i32 %16268, 16" -> "  %16270 = add i32 %16262, %16269"
"  %16270 = add i32 %16262, %16269"
"  %16270 = add i32 %16262, %16269" -> "  %16275 = add i32 %16270, %16274"
"  %16271 = and i32 %16268, 65535"
"  %16271 = and i32 %16268, 65535" -> "  %16273 = add nuw nsw i32 %16271, %16272"
"  %16272 = lshr i32 %16265, 16"
"  %16272 = lshr i32 %16265, 16" -> "  %16273 = add nuw nsw i32 %16271, %16272"
"  %16273 = add nuw nsw i32 %16271, %16272"
"  %16273 = add nuw nsw i32 %16271, %16272" -> "  %16297 = and i32 %16273, 65535""  %16273 = add nuw nsw i32 %16271, %16272" -> "  %16274 = lshr i32 %16273, 16"
"  %16274 = lshr i32 %16273, 16"
"  %16274 = lshr i32 %16273, 16" -> "  %16275 = add i32 %16270, %16274"
"  %16275 = add i32 %16270, %16274"
"  %16275 = add i32 %16270, %16274" -> "  %16329 = lshr i32 %16275, 16""  %16275 = add i32 %16270, %16274" -> "  %16325 = and i32 %16275, 65535"
"  %16276 = mul nuw nsw i32 %16209, 17399"
"  %16276 = mul nuw nsw i32 %16209, 17399" -> "  %16295 = and i32 %16276, 65535""  %16276 = mul nuw nsw i32 %16209, 17399" -> "  %16277 = lshr i32 %16276, 16"
"  %16277 = lshr i32 %16276, 16"
"  %16277 = lshr i32 %16276, 16" -> "  %16280 = add nuw nsw i32 %16277, %16279"
"  %16278 = mul nuw i32 %16209, 34017"
"  %16278 = mul nuw i32 %16209, 34017" -> "  %16281 = and i32 %16278, -65536""  %16278 = mul nuw i32 %16209, 34017" -> "  %16279 = and i32 %16278, 65535"
"  %16279 = and i32 %16278, 65535"
"  %16279 = and i32 %16278, 65535" -> "  %16280 = add nuw nsw i32 %16277, %16279"
"  %16280 = add nuw nsw i32 %16277, %16279"
"  %16280 = add nuw nsw i32 %16277, %16279" -> "  %16282 = add i32 %16280, %16281"
"  %16281 = and i32 %16278, -65536"
"  %16281 = and i32 %16278, -65536" -> "  %16282 = add i32 %16280, %16281"
"  %16282 = add i32 %16280, %16281"
"  %16282 = add i32 %16280, %16281" -> "  %16286 = lshr i32 %16282, 16""  %16282 = add i32 %16280, %16281" -> "  %16284 = and i32 %16282, 65535"
"  %16283 = mul nuw nsw i32 %16205, 17399"
"  %16283 = mul nuw nsw i32 %16205, 17399" -> "  %16285 = add nuw i32 %16284, %16283"
"  %16284 = and i32 %16282, 65535"
"  %16284 = and i32 %16282, 65535" -> "  %16285 = add nuw i32 %16284, %16283"
"  %16285 = add nuw i32 %16284, %16283"
"  %16285 = add nuw i32 %16284, %16283" -> "  %16298 = and i32 %16285, 65535""  %16285 = add nuw i32 %16284, %16283" -> "  %16289 = lshr i32 %16285, 16"
"  %16286 = lshr i32 %16282, 16"
"  %16286 = lshr i32 %16282, 16" -> "  %16288 = add i32 %16286, %16287"
"  %16287 = mul nuw i32 %16205, 34017"
"  %16287 = mul nuw i32 %16205, 34017" -> "  %16288 = add i32 %16286, %16287"
"  %16288 = add i32 %16286, %16287"
"  %16288 = add i32 %16286, %16287" -> "  %16292 = and i32 %16288, -65536""  %16288 = add i32 %16286, %16287" -> "  %16290 = and i32 %16288, 65535"
"  %16289 = lshr i32 %16285, 16"
"  %16289 = lshr i32 %16285, 16" -> "  %16291 = add nuw nsw i32 %16289, %16290"
"  %16290 = and i32 %16288, 65535"
"  %16290 = and i32 %16288, 65535" -> "  %16291 = add nuw nsw i32 %16289, %16290"
"  %16291 = add nuw nsw i32 %16289, %16290"
"  %16291 = add nuw nsw i32 %16289, %16290" -> "  %16293 = add i32 %16291, %16292"
"  %16292 = and i32 %16288, -65536"
"  %16292 = and i32 %16288, -65536" -> "  %16293 = add i32 %16291, %16292"
"  %16293 = add i32 %16291, %16292"
"  %16293 = add i32 %16291, %16292" -> "  %16301 = add i32 %16293, %16300"
"  %16294 = and i32 %16265, 65535"
"  %16294 = and i32 %16265, 65535" -> "  %16296 = add nuw nsw i32 %16294, %16295"
"  %16295 = and i32 %16276, 65535"
"  %16295 = and i32 %16276, 65535" -> "  %16296 = add nuw nsw i32 %16294, %16295"
"  %16296 = add nuw nsw i32 %16294, %16295"
"  %16296 = add nuw nsw i32 %16294, %16295" -> "  %16500 = and i32 %16296, 65535""  %16296 = add nuw nsw i32 %16294, %16295" -> "  %16303 = lshr i32 %16296, 16"
"  %16297 = and i32 %16273, 65535"
"  %16297 = and i32 %16273, 65535" -> "  %16299 = add nuw nsw i32 %16297, %16298"
"  %16298 = and i32 %16285, 65535"
"  %16298 = and i32 %16285, 65535" -> "  %16299 = add nuw nsw i32 %16297, %16298"
"  %16299 = add nuw nsw i32 %16297, %16298"
"  %16299 = add nuw nsw i32 %16297, %16298" -> "  %16302 = and i32 %16299, 65535""  %16299 = add nuw nsw i32 %16297, %16298" -> "  %16300 = lshr i32 %16299, 16"
"  %16300 = lshr i32 %16299, 16"
"  %16300 = lshr i32 %16299, 16" -> "  %16301 = add i32 %16293, %16300"
"  %16301 = add i32 %16293, %16300"
"  %16301 = add i32 %16293, %16300" -> "  %16306 = add i32 %16301, %16305"
"  %16302 = and i32 %16299, 65535"
"  %16302 = and i32 %16299, 65535" -> "  %16304 = add nuw nsw i32 %16302, %16303"
"  %16303 = lshr i32 %16296, 16"
"  %16303 = lshr i32 %16296, 16" -> "  %16304 = add nuw nsw i32 %16302, %16303"
"  %16304 = add nuw nsw i32 %16302, %16303"
"  %16304 = add nuw nsw i32 %16302, %16303" -> "  %16504 = and i32 %16304, 65535""  %16304 = add nuw nsw i32 %16302, %16303" -> "  %16305 = lshr i32 %16304, 16"
"  %16305 = lshr i32 %16304, 16"
"  %16305 = lshr i32 %16304, 16" -> "  %16306 = add i32 %16301, %16305"
"  %16306 = add i32 %16301, %16305"
"  %16306 = add i32 %16301, %16305" -> "  %16342 = lshr i32 %16306, 16""  %16306 = add i32 %16301, %16305" -> "  %16339 = and i32 %16306, 65535"
"  %16307 = mul nuw nsw i32 %16209, 7935"
"  %16307 = mul nuw nsw i32 %16209, 7935" -> "  %16326 = and i32 %16307, 65535""  %16307 = mul nuw nsw i32 %16209, 7935" -> "  %16308 = lshr i32 %16307, 16"
"  %16308 = lshr i32 %16307, 16"
"  %16308 = lshr i32 %16307, 16" -> "  %16311 = add nuw nsw i32 %16308, %16310"
"  %16309 = mul nuw i32 %16209, 63663"
"  %16309 = mul nuw i32 %16209, 63663" -> "  %16312 = and i32 %16309, -65536""  %16309 = mul nuw i32 %16209, 63663" -> "  %16310 = and i32 %16309, 65535"
"  %16310 = and i32 %16309, 65535"
"  %16310 = and i32 %16309, 65535" -> "  %16311 = add nuw nsw i32 %16308, %16310"
"  %16311 = add nuw nsw i32 %16308, %16310"
"  %16311 = add nuw nsw i32 %16308, %16310" -> "  %16313 = add i32 %16311, %16312"
"  %16312 = and i32 %16309, -65536"
"  %16312 = and i32 %16309, -65536" -> "  %16313 = add i32 %16311, %16312"
"  %16313 = add i32 %16311, %16312"
"  %16313 = add i32 %16311, %16312" -> "  %16317 = lshr i32 %16313, 16""  %16313 = add i32 %16311, %16312" -> "  %16315 = and i32 %16313, 65535"
"  %16314 = mul nuw nsw i32 %16205, 7935"
"  %16314 = mul nuw nsw i32 %16205, 7935" -> "  %16316 = add nuw nsw i32 %16315, %16314"
"  %16315 = and i32 %16313, 65535"
"  %16315 = and i32 %16313, 65535" -> "  %16316 = add nuw nsw i32 %16315, %16314"
"  %16316 = add nuw nsw i32 %16315, %16314"
"  %16316 = add nuw nsw i32 %16315, %16314" -> "  %16328 = and i32 %16316, 65535""  %16316 = add nuw nsw i32 %16315, %16314" -> "  %16320 = lshr i32 %16316, 16"
"  %16317 = lshr i32 %16313, 16"
"  %16317 = lshr i32 %16313, 16" -> "  %16319 = add i32 %16317, %16318"
"  %16318 = mul nuw i32 %16205, 63663"
"  %16318 = mul nuw i32 %16205, 63663" -> "  %16319 = add i32 %16317, %16318"
"  %16319 = add i32 %16317, %16318"
"  %16319 = add i32 %16317, %16318" -> "  %16323 = and i32 %16319, -65536""  %16319 = add i32 %16317, %16318" -> "  %16321 = and i32 %16319, 65535"
"  %16320 = lshr i32 %16316, 16"
"  %16320 = lshr i32 %16316, 16" -> "  %16322 = add nuw nsw i32 %16320, %16321"
"  %16321 = and i32 %16319, 65535"
"  %16321 = and i32 %16319, 65535" -> "  %16322 = add nuw nsw i32 %16320, %16321"
"  %16322 = add nuw nsw i32 %16320, %16321"
"  %16322 = add nuw nsw i32 %16320, %16321" -> "  %16324 = add i32 %16322, %16323"
"  %16323 = and i32 %16319, -65536"
"  %16323 = and i32 %16319, -65536" -> "  %16324 = add i32 %16322, %16323"
"  %16324 = add i32 %16322, %16323"
"  %16324 = add i32 %16322, %16323" -> "  %16332 = add i32 %16324, %16331"
"  %16325 = and i32 %16275, 65535"
"  %16325 = and i32 %16275, 65535" -> "  %16327 = add nuw nsw i32 %16325, %16326"
"  %16326 = and i32 %16307, 65535"
"  %16326 = and i32 %16307, 65535" -> "  %16327 = add nuw nsw i32 %16325, %16326"
"  %16327 = add nuw nsw i32 %16325, %16326"
"  %16327 = add nuw nsw i32 %16325, %16326" -> "  %16338 = and i32 %16327, 65535""  %16327 = add nuw nsw i32 %16325, %16326" -> "  %16334 = lshr i32 %16327, 16"
"  %16328 = and i32 %16316, 65535"
"  %16328 = and i32 %16316, 65535" -> "  %16330 = add nuw nsw i32 %16329, %16328"
"  %16329 = lshr i32 %16275, 16"
"  %16329 = lshr i32 %16275, 16" -> "  %16330 = add nuw nsw i32 %16329, %16328"
"  %16330 = add nuw nsw i32 %16329, %16328"
"  %16330 = add nuw nsw i32 %16329, %16328" -> "  %16333 = and i32 %16330, 65535""  %16330 = add nuw nsw i32 %16329, %16328" -> "  %16331 = lshr i32 %16330, 16"
"  %16331 = lshr i32 %16330, 16"
"  %16331 = lshr i32 %16330, 16" -> "  %16332 = add i32 %16324, %16331"
"  %16332 = add i32 %16324, %16331"
"  %16332 = add i32 %16324, %16331" -> "  %16337 = add i32 %16332, %16336"
"  %16333 = and i32 %16330, 65535"
"  %16333 = and i32 %16330, 65535" -> "  %16335 = add nuw nsw i32 %16333, %16334"
"  %16334 = lshr i32 %16327, 16"
"  %16334 = lshr i32 %16327, 16" -> "  %16335 = add nuw nsw i32 %16333, %16334"
"  %16335 = add nuw nsw i32 %16333, %16334"
"  %16335 = add nuw nsw i32 %16333, %16334" -> "  %16341 = and i32 %16335, 65535""  %16335 = add nuw nsw i32 %16333, %16334" -> "  %16336 = lshr i32 %16335, 16"
"  %16336 = lshr i32 %16335, 16"
"  %16336 = lshr i32 %16335, 16" -> "  %16337 = add i32 %16332, %16336"
"  %16337 = add i32 %16332, %16336"
"  %16337 = add i32 %16332, %16336" -> "  %16350 = and i32 %16337, -65536""  %16337 = add i32 %16332, %16336" -> "  %16348 = and i32 %16337, 65535"
"  %16338 = and i32 %16327, 65535"
"  %16338 = and i32 %16327, 65535" -> "  %16340 = add nuw nsw i32 %16339, %16338"
"  %16339 = and i32 %16306, 65535"
"  %16339 = and i32 %16306, 65535" -> "  %16340 = add nuw nsw i32 %16339, %16338"
"  %16340 = add nuw nsw i32 %16339, %16338"
"  %16340 = add nuw nsw i32 %16339, %16338" -> "  %16399 = and i32 %16340, 65535""  %16340 = add nuw nsw i32 %16339, %16338" -> "  %16344 = lshr i32 %16340, 16"
"  %16341 = and i32 %16335, 65535"
"  %16341 = and i32 %16335, 65535" -> "  %16343 = add nuw nsw i32 %16341, %16342"
"  %16342 = lshr i32 %16306, 16"
"  %16342 = lshr i32 %16306, 16" -> "  %16343 = add nuw nsw i32 %16341, %16342"
"  %16343 = add nuw nsw i32 %16341, %16342"
"  %16343 = add nuw nsw i32 %16341, %16342" -> "  %16347 = lshr i32 %16343, 16""  %16343 = add nuw nsw i32 %16341, %16342" -> "  %16345 = and i32 %16343, 65535"
"  %16344 = lshr i32 %16340, 16"
"  %16344 = lshr i32 %16340, 16" -> "  %16346 = add nuw nsw i32 %16345, %16344"
"  %16345 = and i32 %16343, 65535"
"  %16345 = and i32 %16343, 65535" -> "  %16346 = add nuw nsw i32 %16345, %16344"
"  %16346 = add nuw nsw i32 %16345, %16344"
"  %16346 = add nuw nsw i32 %16345, %16344" -> "  %16402 = and i32 %16346, 65535""  %16346 = add nuw nsw i32 %16345, %16344" -> "  %16352 = lshr i32 %16346, 16"
"  %16347 = lshr i32 %16343, 16"
"  %16347 = lshr i32 %16343, 16" -> "  %16349 = add nuw nsw i32 %16347, %16348"
"  %16348 = and i32 %16337, 65535"
"  %16348 = and i32 %16337, 65535" -> "  %16349 = add nuw nsw i32 %16347, %16348"
"  %16349 = add nuw nsw i32 %16347, %16348"
"  %16349 = add nuw nsw i32 %16347, %16348" -> "  %16351 = add i32 %16349, %16350"
"  %16350 = and i32 %16337, -65536"
"  %16350 = and i32 %16337, -65536" -> "  %16351 = add i32 %16349, %16350"
"  %16351 = add i32 %16349, %16350"
"  %16351 = add i32 %16349, %16350" -> "  %16353 = add i32 %16351, %16352"
"  %16352 = lshr i32 %16346, 16"
"  %16352 = lshr i32 %16346, 16" -> "  %16353 = add i32 %16351, %16352"
"  %16353 = add i32 %16351, %16352"
"  %16353 = add i32 %16351, %16352" -> "  %16409 = and i32 %16353, 65535""  %16353 = add i32 %16351, %16352" -> "  %16397 = lshr i32 %16353, 16"
"  %16354 = mul nuw nsw i32 %16226, 1146"
"  %16354 = mul nuw nsw i32 %16226, 1146" -> "  %16400 = and i32 %16354, 65534""  %16354 = mul nuw nsw i32 %16226, 1146" -> "  %16355 = lshr i32 %16354, 16"
"  %16355 = lshr i32 %16354, 16"
"  %16355 = lshr i32 %16354, 16" -> "  %16358 = add nuw nsw i32 %16355, %16357"
"  %16356 = mul nuw i32 %16226, 43563"
"  %16356 = mul nuw i32 %16226, 43563" -> "  %16359 = and i32 %16356, -65536""  %16356 = mul nuw i32 %16226, 43563" -> "  %16357 = and i32 %16356, 65535"
"  %16357 = and i32 %16356, 65535"
"  %16357 = and i32 %16356, 65535" -> "  %16358 = add nuw nsw i32 %16355, %16357"
"  %16358 = add nuw nsw i32 %16355, %16357"
"  %16358 = add nuw nsw i32 %16355, %16357" -> "  %16360 = add i32 %16358, %16359"
"  %16359 = and i32 %16356, -65536"
"  %16359 = and i32 %16356, -65536" -> "  %16360 = add i32 %16358, %16359"
"  %16360 = add i32 %16358, %16359"
"  %16360 = add i32 %16358, %16359" -> "  %16364 = lshr i32 %16360, 16""  %16360 = add i32 %16358, %16359" -> "  %16362 = and i32 %16360, 65535"
"  %16361 = mul nuw nsw i32 %16214, 1146"
"  %16361 = mul nuw nsw i32 %16214, 1146" -> "  %16363 = add nuw nsw i32 %16362, %16361"
"  %16362 = and i32 %16360, 65535"
"  %16362 = and i32 %16360, 65535" -> "  %16363 = add nuw nsw i32 %16362, %16361"
"  %16363 = add nuw nsw i32 %16362, %16361"
"  %16363 = add nuw nsw i32 %16362, %16361" -> "  %16403 = and i32 %16363, 65535""  %16363 = add nuw nsw i32 %16362, %16361" -> "  %16367 = lshr i32 %16363, 16"
"  %16364 = lshr i32 %16360, 16"
"  %16364 = lshr i32 %16360, 16" -> "  %16366 = add i32 %16364, %16365"
"  %16365 = mul nuw i32 %16214, 43563"
"  %16365 = mul nuw i32 %16214, 43563" -> "  %16366 = add i32 %16364, %16365"
"  %16366 = add i32 %16364, %16365"
"  %16366 = add i32 %16364, %16365" -> "  %16370 = and i32 %16366, -65536""  %16366 = add i32 %16364, %16365" -> "  %16368 = and i32 %16366, 65535"
"  %16367 = lshr i32 %16363, 16"
"  %16367 = lshr i32 %16363, 16" -> "  %16369 = add nuw nsw i32 %16367, %16368"
"  %16368 = and i32 %16366, 65535"
"  %16368 = and i32 %16366, 65535" -> "  %16369 = add nuw nsw i32 %16367, %16368"
"  %16369 = add nuw nsw i32 %16367, %16368"
"  %16369 = add nuw nsw i32 %16367, %16368" -> "  %16371 = add i32 %16369, %16370"
"  %16370 = and i32 %16366, -65536"
"  %16370 = and i32 %16366, -65536" -> "  %16371 = add i32 %16369, %16370"
"  %16371 = add i32 %16369, %16370"
"  %16371 = add i32 %16369, %16370" -> "  %16388 = lshr i32 %16371, 16""  %16371 = add i32 %16369, %16370" -> "  %16378 = and i32 %16371, 65535"
"  %16372 = mul nuw nsw i32 %16226, 13953"
"  %16372 = mul nuw nsw i32 %16226, 13953" -> "  %16379 = and i32 %16372, 65535""  %16372 = mul nuw nsw i32 %16226, 13953" -> "  %16373 = lshr i32 %16372, 16"
"  %16373 = lshr i32 %16372, 16"
"  %16373 = lshr i32 %16372, 16" -> "  %16375 = add i32 %16373, %16374"
"  %16374 = mul nuw i32 %16226, 58377"
"  %16374 = mul nuw i32 %16226, 58377" -> "  %16375 = add i32 %16373, %16374"
"  %16375 = add i32 %16373, %16374"
"  %16375 = add i32 %16373, %16374" -> "  %16377 = add i32 %16375, %16376"
"  %16376 = mul nuw nsw i32 %16214, 13953"
"  %16376 = mul nuw nsw i32 %16214, 13953" -> "  %16377 = add i32 %16375, %16376"
"  %16377 = add i32 %16375, %16376"
"  %16377 = add i32 %16375, %16376" -> "  %16382 = add i32 %16377, %16381"
"  %16378 = and i32 %16371, 65535"
"  %16378 = and i32 %16371, 65535" -> "  %16380 = add nuw nsw i32 %16378, %16379"
"  %16379 = and i32 %16372, 65535"
"  %16379 = and i32 %16372, 65535" -> "  %16380 = add nuw nsw i32 %16378, %16379"
"  %16380 = add nuw nsw i32 %16378, %16379"
"  %16380 = add nuw nsw i32 %16378, %16379" -> "  %16392 = and i32 %16380, 65535""  %16380 = add nuw nsw i32 %16378, %16379" -> "  %16390 = lshr i32 %16380, 16"
"  %16381 = mul nuw i32 %16209, 43563"
"  %16381 = mul nuw i32 %16209, 43563" -> "  %16382 = add i32 %16377, %16381"
"  %16382 = add i32 %16377, %16381"
"  %16382 = add i32 %16377, %16381" -> "  %16385 = add i32 %16382, %16384"
"  %16383 = mul nuw nsw i32 %16209, 1146"
"  %16383 = mul nuw nsw i32 %16209, 1146" -> "  %16393 = and i32 %16383, 65534""  %16383 = mul nuw nsw i32 %16209, 1146" -> "  %16384 = lshr i32 %16383, 16"
"  %16384 = lshr i32 %16383, 16"
"  %16384 = lshr i32 %16383, 16" -> "  %16385 = add i32 %16382, %16384"
"  %16385 = add i32 %16382, %16384"
"  %16385 = add i32 %16382, %16384" -> "  %16387 = add i32 %16385, %16386"
"  %16386 = mul nuw nsw i32 %16205, 1146"
"  %16386 = mul nuw nsw i32 %16205, 1146" -> "  %16387 = add i32 %16385, %16386"
"  %16387 = add i32 %16385, %16386"
"  %16387 = add i32 %16385, %16386" -> "  %16389 = add i32 %16387, %16388"
"  %16388 = lshr i32 %16371, 16"
"  %16388 = lshr i32 %16371, 16" -> "  %16389 = add i32 %16387, %16388"
"  %16389 = add i32 %16387, %16388"
"  %16389 = add i32 %16387, %16388" -> "  %16391 = add i32 %16389, %16390"
"  %16390 = lshr i32 %16380, 16"
"  %16390 = lshr i32 %16380, 16" -> "  %16391 = add i32 %16389, %16390"
"  %16391 = add i32 %16389, %16390"
"  %16391 = add i32 %16389, %16390" -> "  %16396 = add i32 %16391, %16395"
"  %16392 = and i32 %16380, 65535"
"  %16392 = and i32 %16380, 65535" -> "  %16394 = add nuw nsw i32 %16392, %16393"
"  %16393 = and i32 %16383, 65534"
"  %16393 = and i32 %16383, 65534" -> "  %16394 = add nuw nsw i32 %16392, %16393"
"  %16394 = add nuw nsw i32 %16392, %16393"
"  %16394 = add nuw nsw i32 %16392, %16393" -> "  %16408 = and i32 %16394, 65535""  %16394 = add nuw nsw i32 %16392, %16393" -> "  %16395 = lshr i32 %16394, 16"
"  %16395 = lshr i32 %16394, 16"
"  %16395 = lshr i32 %16394, 16" -> "  %16396 = add i32 %16391, %16395"
"  %16396 = add i32 %16391, %16395"
"  %16396 = add i32 %16391, %16395" -> "  %16398 = add i32 %16396, %16397"
"  %16397 = lshr i32 %16353, 16"
"  %16397 = lshr i32 %16353, 16" -> "  %16398 = add i32 %16396, %16397"
"  %16398 = add i32 %16396, %16397"
"  %16398 = add i32 %16396, %16397" -> "  %16412 = add i32 %16398, %16411"
"  %16399 = and i32 %16340, 65535"
"  %16399 = and i32 %16340, 65535" -> "  %16401 = add nuw nsw i32 %16399, %16400"
"  %16400 = and i32 %16354, 65534"
"  %16400 = and i32 %16354, 65534" -> "  %16401 = add nuw nsw i32 %16399, %16400"
"  %16401 = add nuw nsw i32 %16399, %16400"
"  %16401 = add nuw nsw i32 %16399, %16400" -> "  %16471 = and i32 %16401, 65535""  %16401 = add nuw nsw i32 %16399, %16400" -> "  %16405 = lshr i32 %16401, 16"
"  %16402 = and i32 %16346, 65535"
"  %16402 = and i32 %16346, 65535" -> "  %16404 = add nuw nsw i32 %16402, %16403"
"  %16403 = and i32 %16363, 65535"
"  %16403 = and i32 %16363, 65535" -> "  %16404 = add nuw nsw i32 %16402, %16403"
"  %16404 = add nuw nsw i32 %16402, %16403"
"  %16404 = add nuw nsw i32 %16402, %16403" -> "  %16414 = lshr i32 %16404, 16""  %16404 = add nuw nsw i32 %16402, %16403" -> "  %16406 = and i32 %16404, 65535"
"  %16405 = lshr i32 %16401, 16"
"  %16405 = lshr i32 %16401, 16" -> "  %16407 = add nuw nsw i32 %16406, %16405"
"  %16406 = and i32 %16404, 65535"
"  %16406 = and i32 %16404, 65535" -> "  %16407 = add nuw nsw i32 %16406, %16405"
"  %16407 = add nuw nsw i32 %16406, %16405"
"  %16407 = add nuw nsw i32 %16406, %16405" -> "  %16474 = and i32 %16407, 65535""  %16407 = add nuw nsw i32 %16406, %16405" -> "  %16416 = lshr i32 %16407, 16"
"  %16408 = and i32 %16394, 65535"
"  %16408 = and i32 %16394, 65535" -> "  %16410 = add nuw nsw i32 %16409, %16408"
"  %16409 = and i32 %16353, 65535"
"  %16409 = and i32 %16353, 65535" -> "  %16410 = add nuw nsw i32 %16409, %16408"
"  %16410 = add nuw nsw i32 %16409, %16408"
"  %16410 = add nuw nsw i32 %16409, %16408" -> "  %16413 = and i32 %16410, 65535""  %16410 = add nuw nsw i32 %16409, %16408" -> "  %16411 = lshr i32 %16410, 16"
"  %16411 = lshr i32 %16410, 16"
"  %16411 = lshr i32 %16410, 16" -> "  %16412 = add i32 %16398, %16411"
"  %16412 = add i32 %16398, %16411"
"  %16412 = add i32 %16398, %16411" -> "  %16419 = add i32 %16412, %16418"
"  %16413 = and i32 %16410, 65535"
"  %16413 = and i32 %16410, 65535" -> "  %16415 = add nuw nsw i32 %16413, %16414"
"  %16414 = lshr i32 %16404, 16"
"  %16414 = lshr i32 %16404, 16" -> "  %16415 = add nuw nsw i32 %16413, %16414"
"  %16415 = add nuw nsw i32 %16413, %16414"
"  %16415 = add nuw nsw i32 %16413, %16414" -> "  %16417 = add nuw nsw i32 %16415, %16416"
"  %16416 = lshr i32 %16407, 16"
"  %16416 = lshr i32 %16407, 16" -> "  %16417 = add nuw nsw i32 %16415, %16416"
"  %16417 = add nuw nsw i32 %16415, %16416"
"  %16417 = add nuw nsw i32 %16415, %16416" -> "  %16483 = and i32 %16417, 65535""  %16417 = add nuw nsw i32 %16415, %16416" -> "  %16418 = lshr i32 %16417, 16"
"  %16418 = lshr i32 %16417, 16"
"  %16418 = lshr i32 %16417, 16" -> "  %16419 = add i32 %16412, %16418"
"  %16419 = add i32 %16412, %16418"
"  %16419 = add i32 %16412, %16418" -> "  %16485 = and i32 %16419, 65535"
"  %16420 = mul nuw nsw i32 %16222, 17399"
"  %16420 = mul nuw nsw i32 %16222, 17399" -> "  %16470 = and i32 %16420, 65535""  %16420 = mul nuw nsw i32 %16222, 17399" -> "  %16421 = lshr i32 %16420, 16"
"  %16421 = lshr i32 %16420, 16"
"  %16421 = lshr i32 %16420, 16" -> "  %16424 = add nuw nsw i32 %16421, %16423"
"  %16422 = mul nuw i32 %16222, 34017"
"  %16422 = mul nuw i32 %16222, 34017" -> "  %16425 = and i32 %16422, -65536""  %16422 = mul nuw i32 %16222, 34017" -> "  %16423 = and i32 %16422, 65535"
"  %16423 = and i32 %16422, 65535"
"  %16423 = and i32 %16422, 65535" -> "  %16424 = add nuw nsw i32 %16421, %16423"
"  %16424 = add nuw nsw i32 %16421, %16423"
"  %16424 = add nuw nsw i32 %16421, %16423" -> "  %16426 = add i32 %16424, %16425"
"  %16425 = and i32 %16422, -65536"
"  %16425 = and i32 %16422, -65536" -> "  %16426 = add i32 %16424, %16425"
"  %16426 = add i32 %16424, %16425"
"  %16426 = add i32 %16424, %16425" -> "  %16435 = lshr i32 %16426, 16""  %16426 = add i32 %16424, %16425" -> "  %16433 = and i32 %16426, 65535"
"  %16427 = lshr i32 %16195, 15"
"  %16427 = lshr i32 %16195, 15" -> "  %16428 = and i32 %16427, 1"
"  %16428 = and i32 %16427, 1"
"  %16428 = and i32 %16427, 1" -> "  %16431 = or i32 %16430, %16428"
"  %16429 = shl nuw nsw i32 %16198, 1"
"  %16429 = shl nuw nsw i32 %16198, 1" -> "  %16430 = and i32 %16429, 65534"
"  %16430 = and i32 %16429, 65534"
"  %16430 = and i32 %16429, 65534" -> "  %16431 = or i32 %16430, %16428"
"  %16431 = or i32 %16430, %16428"
"  %16431 = or i32 %16430, %16428" -> "  %16446 = mul nuw nsw i32 %16431, 7935""  %16431 = or i32 %16430, %16428" -> "  %16436 = mul nuw i32 %16431, 34017""  %16431 = or i32 %16430, %16428" -> "  %16432 = mul nuw nsw i32 %16431, 17399"
"  %16432 = mul nuw nsw i32 %16431, 17399"
"  %16432 = mul nuw nsw i32 %16431, 17399" -> "  %16434 = add nuw nsw i32 %16433, %16432"
"  %16433 = and i32 %16426, 65535"
"  %16433 = and i32 %16426, 65535" -> "  %16434 = add nuw nsw i32 %16433, %16432"
"  %16434 = add nuw nsw i32 %16433, %16432"
"  %16434 = add nuw nsw i32 %16433, %16432" -> "  %16473 = and i32 %16434, 65535""  %16434 = add nuw nsw i32 %16433, %16432" -> "  %16438 = lshr i32 %16434, 16"
"  %16435 = lshr i32 %16426, 16"
"  %16435 = lshr i32 %16426, 16" -> "  %16437 = add nuw i32 %16435, %16436"
"  %16436 = mul nuw i32 %16431, 34017"
"  %16436 = mul nuw i32 %16431, 34017" -> "  %16437 = add nuw i32 %16435, %16436"
"  %16437 = add nuw i32 %16435, %16436"
"  %16437 = add nuw i32 %16435, %16436" -> "  %16441 = and i32 %16437, -65536""  %16437 = add nuw i32 %16435, %16436" -> "  %16439 = and i32 %16437, 65535"
"  %16438 = lshr i32 %16434, 16"
"  %16438 = lshr i32 %16434, 16" -> "  %16440 = add nuw nsw i32 %16438, %16439"
"  %16439 = and i32 %16437, 65535"
"  %16439 = and i32 %16437, 65535" -> "  %16440 = add nuw nsw i32 %16438, %16439"
"  %16440 = add nuw nsw i32 %16438, %16439"
"  %16440 = add nuw nsw i32 %16438, %16439" -> "  %16442 = add nuw i32 %16440, %16441"
"  %16441 = and i32 %16437, -65536"
"  %16441 = and i32 %16437, -65536" -> "  %16442 = add nuw i32 %16440, %16441"
"  %16442 = add nuw i32 %16440, %16441"
"  %16442 = add nuw i32 %16440, %16441" -> "  %16456 = lshr i32 %16442, 16""  %16442 = add nuw i32 %16440, %16441" -> "  %16447 = and i32 %16442, 65535"
"  %16443 = mul nuw nsw i32 %16222, 7935"
"  %16443 = mul nuw nsw i32 %16222, 7935" -> "  %16448 = and i32 %16443, 65535""  %16443 = mul nuw nsw i32 %16222, 7935" -> "  %16444 = lshr i32 %16443, 16"
"  %16444 = lshr i32 %16443, 16"
"  %16444 = lshr i32 %16443, 16" -> "  %16462 = add i32 %16444, %16445"
"  %16445 = mul nuw i32 %16222, 63663"
"  %16445 = mul nuw i32 %16222, 63663" -> "  %16462 = add i32 %16444, %16445"
"  %16446 = mul nuw nsw i32 %16431, 7935"
"  %16446 = mul nuw nsw i32 %16431, 7935" -> "  %16463 = add i32 %16462, %16446"
"  %16447 = and i32 %16442, 65535"
"  %16447 = and i32 %16442, 65535" -> "  %16449 = add nuw nsw i32 %16447, %16448"
"  %16448 = and i32 %16443, 65535"
"  %16448 = and i32 %16443, 65535" -> "  %16449 = add nuw nsw i32 %16447, %16448"
"  %16449 = add nuw nsw i32 %16447, %16448"
"  %16449 = add nuw nsw i32 %16447, %16448" -> "  %16458 = and i32 %16449, 65535""  %16449 = add nuw nsw i32 %16447, %16448" -> "  %16457 = lshr i32 %16449, 16"
"  %16450 = lshr i32 %16201, 15"
"  %16450 = lshr i32 %16201, 15" -> "  %16451 = and i32 %16450, 65535"
"  %16451 = and i32 %16450, 65535"
"  %16451 = and i32 %16450, 65535" -> "  %16452 = mul nuw nsw i32 %16451, 17399"
"  %16452 = mul nuw nsw i32 %16451, 17399"
"  %16452 = mul nuw nsw i32 %16451, 17399" -> "  %16464 = add i32 %16463, %16452"
"  %16453 = mul nuw i32 %16218, 34017"
"  %16453 = mul nuw i32 %16218, 34017" -> "  %16465 = add i32 %16464, %16453"
"  %16454 = mul nuw nsw i32 %16218, 17399"
"  %16454 = mul nuw nsw i32 %16218, 17399" -> "  %16459 = and i32 %16454, 65535""  %16454 = mul nuw nsw i32 %16218, 17399" -> "  %16455 = lshr i32 %16454, 16"
"  %16455 = lshr i32 %16454, 16"
"  %16455 = lshr i32 %16454, 16" -> "  %16466 = add i32 %16465, %16455"
"  %16456 = lshr i32 %16442, 16"
"  %16456 = lshr i32 %16442, 16" -> "  %16467 = add i32 %16466, %16456"
"  %16457 = lshr i32 %16449, 16"
"  %16457 = lshr i32 %16449, 16" -> "  %16468 = add i32 %16467, %16457"
"  %16458 = and i32 %16449, 65535"
"  %16458 = and i32 %16449, 65535" -> "  %16460 = add nuw nsw i32 %16458, %16459"
"  %16459 = and i32 %16454, 65535"
"  %16459 = and i32 %16454, 65535" -> "  %16460 = add nuw nsw i32 %16458, %16459"
"  %16460 = add nuw nsw i32 %16458, %16459"
"  %16460 = add nuw nsw i32 %16458, %16459" -> "  %16482 = and i32 %16460, 65535""  %16460 = add nuw nsw i32 %16458, %16459" -> "  %16461 = lshr i32 %16460, 16"
"  %16461 = lshr i32 %16460, 16"
"  %16461 = lshr i32 %16460, 16" -> "  %16469 = add i32 %16468, %16461"
"  %16462 = add i32 %16444, %16445"
"  %16462 = add i32 %16444, %16445" -> "  %16463 = add i32 %16462, %16446"
"  %16463 = add i32 %16462, %16446"
"  %16463 = add i32 %16462, %16446" -> "  %16464 = add i32 %16463, %16452"
"  %16464 = add i32 %16463, %16452"
"  %16464 = add i32 %16463, %16452" -> "  %16465 = add i32 %16464, %16453"
"  %16465 = add i32 %16464, %16453"
"  %16465 = add i32 %16464, %16453" -> "  %16466 = add i32 %16465, %16455"
"  %16466 = add i32 %16465, %16455"
"  %16466 = add i32 %16465, %16455" -> "  %16467 = add i32 %16466, %16456"
"  %16467 = add i32 %16466, %16456"
"  %16467 = add i32 %16466, %16456" -> "  %16468 = add i32 %16467, %16457"
"  %16468 = add i32 %16467, %16457"
"  %16468 = add i32 %16467, %16457" -> "  %16469 = add i32 %16468, %16461"
"  %16469 = add i32 %16468, %16461"
"  %16469 = add i32 %16468, %16461" -> "  %16486 = and i32 %16469, 65535"
"  %16470 = and i32 %16420, 65535"
"  %16470 = and i32 %16420, 65535" -> "  %16472 = add nuw nsw i32 %16471, %16470"
"  %16471 = and i32 %16401, 65535"
"  %16471 = and i32 %16401, 65535" -> "  %16472 = add nuw nsw i32 %16471, %16470"
"  %16472 = add nuw nsw i32 %16471, %16470"
"  %16472 = add nuw nsw i32 %16471, %16470" -> "  %16509 = and i32 %16472, 65535""  %16472 = add nuw nsw i32 %16471, %16470" -> "  %16476 = lshr i32 %16472, 16"
"  %16473 = and i32 %16434, 65535"
"  %16473 = and i32 %16434, 65535" -> "  %16475 = add nuw nsw i32 %16474, %16473"
"  %16474 = and i32 %16407, 65535"
"  %16474 = and i32 %16407, 65535" -> "  %16475 = add nuw nsw i32 %16474, %16473"
"  %16475 = add nuw nsw i32 %16474, %16473"
"  %16475 = add nuw nsw i32 %16474, %16473" -> "  %16479 = lshr i32 %16475, 16""  %16475 = add nuw nsw i32 %16474, %16473" -> "  %16477 = and i32 %16475, 65535"
"  %16476 = lshr i32 %16472, 16"
"  %16476 = lshr i32 %16472, 16" -> "  %16478 = add nuw nsw i32 %16477, %16476"
"  %16477 = and i32 %16475, 65535"
"  %16477 = and i32 %16475, 65535" -> "  %16478 = add nuw nsw i32 %16477, %16476"
"  %16478 = add nuw nsw i32 %16477, %16476"
"  %16478 = add nuw nsw i32 %16477, %16476" -> "  %16512 = and i32 %16478, 65535""  %16478 = add nuw nsw i32 %16477, %16476" -> "  %16480 = lshr i32 %16478, 16"
"  %16479 = lshr i32 %16475, 16"
"  %16479 = lshr i32 %16475, 16" -> "  %16481 = add nuw nsw i32 %16480, %16479"
"  %16480 = lshr i32 %16478, 16"
"  %16480 = lshr i32 %16478, 16" -> "  %16481 = add nuw nsw i32 %16480, %16479"
"  %16481 = add nuw nsw i32 %16480, %16479"
"  %16481 = add nuw nsw i32 %16480, %16479" -> "  %16491 = add nuw nsw i32 %16481, %16490"
"  %16482 = and i32 %16460, 65535"
"  %16482 = and i32 %16460, 65535" -> "  %16484 = add nuw nsw i32 %16483, %16482"
"  %16483 = and i32 %16417, 65535"
"  %16483 = and i32 %16417, 65535" -> "  %16484 = add nuw nsw i32 %16483, %16482"
"  %16484 = add nuw nsw i32 %16483, %16482"
"  %16484 = add nuw nsw i32 %16483, %16482" -> "  %16490 = and i32 %16484, 65535""  %16484 = add nuw nsw i32 %16483, %16482" -> "  %16488 = lshr i32 %16484, 16"
"  %16485 = and i32 %16419, 65535"
"  %16485 = and i32 %16419, 65535" -> "  %16487 = add nuw nsw i32 %16485, %16486"
"  %16486 = and i32 %16469, 65535"
"  %16486 = and i32 %16469, 65535" -> "  %16487 = add nuw nsw i32 %16485, %16486"
"  %16487 = add nuw nsw i32 %16485, %16486"
"  %16487 = add nuw nsw i32 %16485, %16486" -> "  %16489 = add nuw nsw i32 %16487, %16488"
"  %16488 = lshr i32 %16484, 16"
"  %16488 = lshr i32 %16484, 16" -> "  %16489 = add nuw nsw i32 %16487, %16488"
"  %16489 = add nuw nsw i32 %16487, %16488"
"  %16489 = add nuw nsw i32 %16487, %16488" -> "  %16493 = add nuw nsw i32 %16489, %16492"
"  %16490 = and i32 %16484, 65535"
"  %16490 = and i32 %16484, 65535" -> "  %16491 = add nuw nsw i32 %16481, %16490"
"  %16491 = add nuw nsw i32 %16481, %16490"
"  %16491 = add nuw nsw i32 %16481, %16490" -> "  %16516 = and i32 %16491, 65535""  %16491 = add nuw nsw i32 %16481, %16490" -> "  %16492 = lshr i32 %16491, 16"
"  %16492 = lshr i32 %16491, 16"
"  %16492 = lshr i32 %16491, 16" -> "  %16493 = add nuw nsw i32 %16489, %16492"
"  %16493 = add nuw nsw i32 %16489, %16492"
"  %16493 = add nuw nsw i32 %16489, %16492" -> "  %16557 = xor i32 %16493, 65535"
"  %16494 = and i32 %16227, 65535"
"  %16494 = and i32 %16227, 65535" -> "  %16495 = sub nuw nsw i32 65536, %16494"
"  %16495 = sub nuw nsw i32 65536, %16494"
"  %16495 = sub nuw nsw i32 65536, %16494" -> "  %16520 = and i32 %16495, 65535""  %16495 = sub nuw nsw i32 65536, %16494" -> "  %16498 = lshr i32 %16495, 16"
"  %16496 = and i32 %16236, 65535"
"  %16496 = and i32 %16236, 65535" -> "  %16497 = xor i32 %16496, 65535"
"  %16497 = xor i32 %16496, 65535"
"  %16497 = xor i32 %16496, 65535" -> "  %16499 = add nuw nsw i32 %16497, %16498"
"  %16498 = lshr i32 %16495, 16"
"  %16498 = lshr i32 %16495, 16" -> "  %16499 = add nuw nsw i32 %16497, %16498"
"  %16499 = add nuw nsw i32 %16497, %16498"
"  %16499 = add nuw nsw i32 %16497, %16498" -> "  %16522 = and i32 %16499, 65535""  %16499 = add nuw nsw i32 %16497, %16498" -> "  %16502 = lshr i32 %16499, 16"
"  %16500 = and i32 %16296, 65535"
"  %16500 = and i32 %16296, 65535" -> "  %16501 = xor i32 %16500, 65535"
"  %16501 = xor i32 %16500, 65535"
"  %16501 = xor i32 %16500, 65535" -> "  %16503 = add nuw nsw i32 %16501, %16502"
"  %16502 = lshr i32 %16499, 16"
"  %16502 = lshr i32 %16499, 16" -> "  %16503 = add nuw nsw i32 %16501, %16502"
"  %16503 = add nuw nsw i32 %16501, %16502"
"  %16503 = add nuw nsw i32 %16501, %16502" -> "  %16530 = and i32 %16503, 65535""  %16503 = add nuw nsw i32 %16501, %16502" -> "  %16506 = lshr i32 %16503, 16"
"  %16504 = and i32 %16304, 65535"
"  %16504 = and i32 %16304, 65535" -> "  %16505 = xor i32 %16504, 65535"
"  %16505 = xor i32 %16504, 65535"
"  %16505 = xor i32 %16504, 65535" -> "  %16507 = add nuw nsw i32 %16505, %16506"
"  %16506 = lshr i32 %16503, 16"
"  %16506 = lshr i32 %16503, 16" -> "  %16507 = add nuw nsw i32 %16505, %16506"
"  %16507 = add nuw nsw i32 %16505, %16506"
"  %16507 = add nuw nsw i32 %16505, %16506" -> "  %16532 = and i32 %16507, 65535""  %16507 = add nuw nsw i32 %16505, %16506" -> "  %16508 = lshr i32 %16507, 16"
"  %16508 = lshr i32 %16507, 16"
"  %16508 = lshr i32 %16507, 16" -> "  %16511 = add nuw nsw i32 %16510, %16508"
"  %16509 = and i32 %16472, 65535"
"  %16509 = and i32 %16472, 65535" -> "  %16510 = xor i32 %16509, 65535"
"  %16510 = xor i32 %16509, 65535"
"  %16510 = xor i32 %16509, 65535" -> "  %16511 = add nuw nsw i32 %16510, %16508"
"  %16511 = add nuw nsw i32 %16510, %16508"
"  %16511 = add nuw nsw i32 %16510, %16508" -> "  %16546 = and i32 %16511, 65535""  %16511 = add nuw nsw i32 %16510, %16508" -> "  %16514 = lshr i32 %16511, 16"
"  %16512 = and i32 %16478, 65535"
"  %16512 = and i32 %16478, 65535" -> "  %16513 = xor i32 %16512, 65535"
"  %16513 = xor i32 %16512, 65535"
"  %16513 = xor i32 %16512, 65535" -> "  %16515 = add nuw nsw i32 %16513, %16514"
"  %16514 = lshr i32 %16511, 16"
"  %16514 = lshr i32 %16511, 16" -> "  %16515 = add nuw nsw i32 %16513, %16514"
"  %16515 = add nuw nsw i32 %16513, %16514"
"  %16515 = add nuw nsw i32 %16513, %16514" -> "  %16548 = and i32 %16515, 65535""  %16515 = add nuw nsw i32 %16513, %16514" -> "  %16518 = lshr i32 %16515, 16"
"  %16516 = and i32 %16491, 65535"
"  %16516 = and i32 %16491, 65535" -> "  %16517 = xor i32 %16516, 65535"
"  %16517 = xor i32 %16516, 65535"
"  %16517 = xor i32 %16516, 65535" -> "  %16519 = add nuw nsw i32 %16517, %16518"
"  %16518 = lshr i32 %16515, 16"
"  %16518 = lshr i32 %16515, 16" -> "  %16519 = add nuw nsw i32 %16517, %16518"
"  %16519 = add nuw nsw i32 %16517, %16518"
"  %16519 = add nuw nsw i32 %16517, %16518" -> "  %16572 = add i32 %16571, %16519""  %16519 = add nuw nsw i32 %16517, %16518" -> "  %16555 = and i32 %16519, 65535"
"  %16520 = and i32 %16495, 65535"
"  %16520 = and i32 %16495, 65535" -> "  %16521 = add nuw nsw i32 %16520, %13153"
"  %16521 = add nuw nsw i32 %16520, %13153"
"  %16521 = add nuw nsw i32 %16520, %13153" -> "  %16579 = and i32 %16521, 65535""  %16521 = add nuw nsw i32 %16520, %13153" -> "  %16524 = lshr i32 %16521, 16"
"  %16522 = and i32 %16499, 65535"
"  %16522 = and i32 %16499, 65535" -> "  %16523 = add nuw nsw i32 %16522, %13156"
"  %16523 = add nuw nsw i32 %16522, %13156"
"  %16523 = add nuw nsw i32 %16522, %13156" -> "  %16527 = lshr i32 %16523, 16""  %16523 = add nuw nsw i32 %16522, %13156" -> "  %16525 = and i32 %16523, 65535"
"  %16524 = lshr i32 %16521, 16"
"  %16524 = lshr i32 %16521, 16" -> "  %16526 = add nuw nsw i32 %16525, %16524"
"  %16525 = and i32 %16523, 65535"
"  %16525 = and i32 %16523, 65535" -> "  %16526 = add nuw nsw i32 %16525, %16524"
"  %16526 = add nuw nsw i32 %16525, %16524"
"  %16526 = add nuw nsw i32 %16525, %16524" -> "  %16580 = and i32 %16526, 65535""  %16526 = add nuw nsw i32 %16525, %16524" -> "  %16528 = lshr i32 %16526, 16"
"  %16527 = lshr i32 %16523, 16"
"  %16527 = lshr i32 %16523, 16" -> "  %16529 = add nuw nsw i32 %16528, %16527"
"  %16528 = lshr i32 %16526, 16"
"  %16528 = lshr i32 %16526, 16" -> "  %16529 = add nuw nsw i32 %16528, %16527"
"  %16529 = add nuw nsw i32 %16528, %16527"
"  %16529 = add nuw nsw i32 %16528, %16527" -> "  %16541 = add nuw nsw i32 %16529, %16540"
"  %16530 = and i32 %16503, 65535"
"  %16530 = and i32 %16503, 65535" -> "  %16531 = add nuw nsw i32 %16530, %13173"
"  %16531 = add nuw nsw i32 %16530, %13173"
"  %16531 = add nuw nsw i32 %16530, %13173" -> "  %16540 = and i32 %16531, 65535""  %16531 = add nuw nsw i32 %16530, %13173" -> "  %16534 = lshr i32 %16531, 16"
"  %16532 = and i32 %16507, 65535"
"  %16532 = and i32 %16507, 65535" -> "  %16533 = add nuw nsw i32 %16532, %13176"
"  %16533 = add nuw nsw i32 %16532, %13176"
"  %16533 = add nuw nsw i32 %16532, %13176" -> "  %16537 = lshr i32 %16533, 16""  %16533 = add nuw nsw i32 %16532, %13176" -> "  %16535 = and i32 %16533, 65535"
"  %16534 = lshr i32 %16531, 16"
"  %16534 = lshr i32 %16531, 16" -> "  %16536 = add nuw nsw i32 %16535, %16534"
"  %16535 = and i32 %16533, 65535"
"  %16535 = and i32 %16533, 65535" -> "  %16536 = add nuw nsw i32 %16535, %16534"
"  %16536 = add nuw nsw i32 %16535, %16534"
"  %16536 = add nuw nsw i32 %16535, %16534" -> "  %16542 = and i32 %16536, 65535""  %16536 = add nuw nsw i32 %16535, %16534" -> "  %16538 = lshr i32 %16536, 16"
"  %16537 = lshr i32 %16533, 16"
"  %16537 = lshr i32 %16533, 16" -> "  %16539 = add nuw nsw i32 %16538, %16537"
"  %16538 = lshr i32 %16536, 16"
"  %16538 = lshr i32 %16536, 16" -> "  %16539 = add nuw nsw i32 %16538, %16537"
"  %16539 = add nuw nsw i32 %16538, %16537"
"  %16539 = add nuw nsw i32 %16538, %16537" -> "  %16563 = add nuw nsw i32 %16539, %16545"
"  %16540 = and i32 %16531, 65535"
"  %16540 = and i32 %16531, 65535" -> "  %16541 = add nuw nsw i32 %16529, %16540"
"  %16541 = add nuw nsw i32 %16529, %16540"
"  %16541 = add nuw nsw i32 %16529, %16540" -> "  %16599 = and i32 %16541, 65535""  %16541 = add nuw nsw i32 %16529, %16540" -> "  %16543 = lshr i32 %16541, 16"
"  %16542 = and i32 %16536, 65535"
"  %16542 = and i32 %16536, 65535" -> "  %16544 = add nuw nsw i32 %16542, %16543"
"  %16543 = lshr i32 %16541, 16"
"  %16543 = lshr i32 %16541, 16" -> "  %16544 = add nuw nsw i32 %16542, %16543"
"  %16544 = add nuw nsw i32 %16542, %16543"
"  %16544 = add nuw nsw i32 %16542, %16543" -> "  %16600 = and i32 %16544, 65535""  %16544 = add nuw nsw i32 %16542, %16543" -> "  %16545 = lshr i32 %16544, 16"
"  %16545 = lshr i32 %16544, 16"
"  %16545 = lshr i32 %16544, 16" -> "  %16563 = add nuw nsw i32 %16539, %16545"
"  %16546 = and i32 %16511, 65535"
"  %16546 = and i32 %16511, 65535" -> "  %16547 = add nuw nsw i32 %16546, %13287"
"  %16547 = add nuw nsw i32 %16546, %13287"
"  %16547 = add nuw nsw i32 %16546, %13287" -> "  %16562 = and i32 %16547, 65535""  %16547 = add nuw nsw i32 %16546, %13287" -> "  %16550 = lshr i32 %16547, 16"
"  %16548 = and i32 %16515, 65535"
"  %16548 = and i32 %16515, 65535" -> "  %16549 = add nuw nsw i32 %16548, %13290"
"  %16549 = add nuw nsw i32 %16548, %13290"
"  %16549 = add nuw nsw i32 %16548, %13290" -> "  %16553 = lshr i32 %16549, 16""  %16549 = add nuw nsw i32 %16548, %13290" -> "  %16551 = and i32 %16549, 65535"
"  %16550 = lshr i32 %16547, 16"
"  %16550 = lshr i32 %16547, 16" -> "  %16552 = add nuw nsw i32 %16551, %16550"
"  %16551 = and i32 %16549, 65535"
"  %16551 = and i32 %16549, 65535" -> "  %16552 = add nuw nsw i32 %16551, %16550"
"  %16552 = add nuw nsw i32 %16551, %16550"
"  %16552 = add nuw nsw i32 %16551, %16550" -> "  %16565 = and i32 %16552, 65535""  %16552 = add nuw nsw i32 %16551, %16550" -> "  %16554 = lshr i32 %16552, 16"
"  %16553 = lshr i32 %16549, 16"
"  %16553 = lshr i32 %16549, 16" -> "  %16560 = add nuw nsw i32 %16554, %16553"
"  %16554 = lshr i32 %16552, 16"
"  %16554 = lshr i32 %16552, 16" -> "  %16560 = add nuw nsw i32 %16554, %16553"
"  %16555 = and i32 %16519, 65535"
"  %16555 = and i32 %16519, 65535" -> "  %16556 = add nuw nsw i32 %16555, %13307"
"  %16556 = add nuw nsw i32 %16555, %13307"
"  %16556 = add nuw nsw i32 %16555, %13307" -> "  %16574 = add i32 %16573, %16556""  %16556 = add nuw nsw i32 %16555, %13307" -> "  %16559 = and i32 %16556, 65535"
"  %16557 = xor i32 %16493, 65535"
"  %16557 = xor i32 %16493, 65535" -> "  %16558 = add nuw nsw i32 %16557, %12945"
"  %16558 = add nuw nsw i32 %16557, %12945"
"  %16558 = add nuw nsw i32 %16557, %12945" -> "  %16571 = shl i32 %16558, 16"
"  %16559 = and i32 %16556, 65535"
"  %16559 = and i32 %16556, 65535" -> "  %16561 = add nuw nsw i32 %16560, %16559"
"  %16560 = add nuw nsw i32 %16554, %16553"
"  %16560 = add nuw nsw i32 %16554, %16553" -> "  %16561 = add nuw nsw i32 %16560, %16559"
"  %16561 = add nuw nsw i32 %16560, %16559"
"  %16561 = add nuw nsw i32 %16560, %16559" -> "  %16576 = add i32 %16575, %16561""  %16561 = add nuw nsw i32 %16560, %16559" -> "  %16569 = and i32 %16561, 65535"
"  %16562 = and i32 %16547, 65535"
"  %16562 = and i32 %16547, 65535" -> "  %16564 = add nuw nsw i32 %16563, %16562"
"  %16563 = add nuw nsw i32 %16539, %16545"
"  %16563 = add nuw nsw i32 %16539, %16545" -> "  %16564 = add nuw nsw i32 %16563, %16562"
"  %16564 = add nuw nsw i32 %16563, %16562"
"  %16564 = add nuw nsw i32 %16563, %16562" -> "  %16710 = and i32 %16564, 65535""  %16564 = add nuw nsw i32 %16563, %16562" -> "  %16566 = lshr i32 %16564, 16"
"  %16565 = and i32 %16552, 65535"
"  %16565 = and i32 %16552, 65535" -> "  %16567 = add nuw nsw i32 %16565, %16566"
"  %16566 = lshr i32 %16564, 16"
"  %16566 = lshr i32 %16564, 16" -> "  %16567 = add nuw nsw i32 %16565, %16566"
"  %16567 = add nuw nsw i32 %16565, %16566"
"  %16567 = add nuw nsw i32 %16565, %16566" -> "  %16713 = and i32 %16567, 65535""  %16567 = add nuw nsw i32 %16565, %16566" -> "  %16568 = lshr i32 %16567, 16"
"  %16568 = lshr i32 %16567, 16"
"  %16568 = lshr i32 %16567, 16" -> "  %16570 = add nuw nsw i32 %16569, %16568"
"  %16569 = and i32 %16561, 65535"
"  %16569 = and i32 %16561, 65535" -> "  %16570 = add nuw nsw i32 %16569, %16568"
"  %16570 = add nuw nsw i32 %16569, %16568"
"  %16570 = add nuw nsw i32 %16569, %16568" -> "  %16578 = add i32 %16570, %16577"
"  %16571 = shl i32 %16558, 16"
"  %16571 = shl i32 %16558, 16" -> "  %16572 = add i32 %16571, %16519"
"  %16572 = add i32 %16571, %16519"
"  %16572 = add i32 %16571, %16519" -> "  %16573 = and i32 %16572, -65536"
"  %16573 = and i32 %16572, -65536"
"  %16573 = and i32 %16572, -65536" -> "  %16574 = add i32 %16573, %16556"
"  %16574 = add i32 %16573, %16556"
"  %16574 = add i32 %16573, %16556" -> "  %16575 = and i32 %16574, -65536"
"  %16575 = and i32 %16574, -65536"
"  %16575 = and i32 %16574, -65536" -> "  %16576 = add i32 %16575, %16561"
"  %16576 = add i32 %16575, %16561"
"  %16576 = add i32 %16575, %16561" -> "  %16577 = and i32 %16576, -65536"
"  %16577 = and i32 %16576, -65536"
"  %16577 = and i32 %16576, -65536" -> "  %16578 = add i32 %16570, %16577"
"  %16578 = add i32 %16570, %16577"
"  %16578 = add i32 %16570, %16577" -> "  %16730 = and i32 %16578, 65535""  %16578 = add i32 %16570, %16577" -> "  %16733 = lshr i32 %16578, 16"
"  %16579 = and i32 %16521, 65535"
"  %16579 = and i32 %16521, 65535" -> "  %16932 = mul nuw i32 %16579, %549""  %16579 = and i32 %16521, 65535" -> "  %16925 = mul nuw i32 %16579, %546""  %16579 = and i32 %16521, 65535" -> "  %16883 = mul nuw i32 %16579, %515""  %16579 = and i32 %16521, 65535" -> "  %16876 = mul nuw i32 %16579, %514""  %16579 = and i32 %16521, 65535" -> "  %16639 = mul nuw i32 %16579, %347""  %16579 = and i32 %16521, 65535" -> "  %16632 = mul nuw i32 %16579, %346""  %16579 = and i32 %16521, 65535" -> "  %16588 = mul nuw i32 %16579, %345""  %16579 = and i32 %16521, 65535" -> "  %16581 = mul nuw i32 %16579, %344"
"  %16580 = and i32 %16526, 65535"
"  %16580 = and i32 %16526, 65535" -> "  %16936 = mul nuw i32 %16580, %549""  %16580 = and i32 %16526, 65535" -> "  %16927 = mul nuw i32 %16580, %546""  %16580 = and i32 %16526, 65535" -> "  %16887 = mul nuw i32 %16580, %515""  %16580 = and i32 %16526, 65535" -> "  %16878 = mul nuw i32 %16580, %514""  %16580 = and i32 %16526, 65535" -> "  %16643 = mul nuw i32 %16580, %347""  %16580 = and i32 %16526, 65535" -> "  %16634 = mul nuw i32 %16580, %346""  %16580 = and i32 %16526, 65535" -> "  %16592 = mul nuw i32 %16580, %345""  %16580 = and i32 %16526, 65535" -> "  %16583 = mul nuw i32 %16580, %344"
"  %16581 = mul nuw i32 %16579, %344"
"  %16581 = mul nuw i32 %16579, %344" -> "  %17241 = and i32 %16581, 65535""  %16581 = mul nuw i32 %16579, %344" -> "  %16582 = lshr i32 %16581, 16"
"  %16582 = lshr i32 %16581, 16"
"  %16582 = lshr i32 %16581, 16" -> "  %16585 = add nuw nsw i32 %16584, %16582"
"  %16583 = mul nuw i32 %16580, %344"
"  %16583 = mul nuw i32 %16580, %344" -> "  %16586 = and i32 %16583, -65536""  %16583 = mul nuw i32 %16580, %344" -> "  %16584 = and i32 %16583, 65535"
"  %16584 = and i32 %16583, 65535"
"  %16584 = and i32 %16583, 65535" -> "  %16585 = add nuw nsw i32 %16584, %16582"
"  %16585 = add nuw nsw i32 %16584, %16582"
"  %16585 = add nuw nsw i32 %16584, %16582" -> "  %16587 = add nuw i32 %16585, %16586"
"  %16586 = and i32 %16583, -65536"
"  %16586 = and i32 %16583, -65536" -> "  %16587 = add nuw i32 %16585, %16586"
"  %16587 = add nuw i32 %16585, %16586"
"  %16587 = add nuw i32 %16585, %16586" -> "  %16591 = lshr i32 %16587, 16""  %16587 = add nuw i32 %16585, %16586" -> "  %16589 = and i32 %16587, 65535"
"  %16588 = mul nuw i32 %16579, %345"
"  %16588 = mul nuw i32 %16579, %345" -> "  %16590 = add nuw i32 %16589, %16588"
"  %16589 = and i32 %16587, 65535"
"  %16589 = and i32 %16587, 65535" -> "  %16590 = add nuw i32 %16589, %16588"
"  %16590 = add nuw i32 %16589, %16588"
"  %16590 = add nuw i32 %16589, %16588" -> "  %17244 = and i32 %16590, 65535""  %16590 = add nuw i32 %16589, %16588" -> "  %16594 = lshr i32 %16590, 16"
"  %16591 = lshr i32 %16587, 16"
"  %16591 = lshr i32 %16587, 16" -> "  %16593 = add nuw i32 %16591, %16592"
"  %16592 = mul nuw i32 %16580, %345"
"  %16592 = mul nuw i32 %16580, %345" -> "  %16593 = add nuw i32 %16591, %16592"
"  %16593 = add nuw i32 %16591, %16592"
"  %16593 = add nuw i32 %16591, %16592" -> "  %16597 = and i32 %16593, -65536""  %16593 = add nuw i32 %16591, %16592" -> "  %16595 = and i32 %16593, 65535"
"  %16594 = lshr i32 %16590, 16"
"  %16594 = lshr i32 %16590, 16" -> "  %16596 = add nuw nsw i32 %16594, %16595"
"  %16595 = and i32 %16593, 65535"
"  %16595 = and i32 %16593, 65535" -> "  %16596 = add nuw nsw i32 %16594, %16595"
"  %16596 = add nuw nsw i32 %16594, %16595"
"  %16596 = add nuw nsw i32 %16594, %16595" -> "  %16598 = add i32 %16596, %16597"
"  %16597 = and i32 %16593, -65536"
"  %16597 = and i32 %16593, -65536" -> "  %16598 = add i32 %16596, %16597"
"  %16598 = add i32 %16596, %16597"
"  %16598 = add i32 %16596, %16597" -> "  %16623 = lshr i32 %16598, 16""  %16598 = add i32 %16596, %16597" -> "  %16619 = and i32 %16598, 65535"
"  %16599 = and i32 %16541, 65535"
"  %16599 = and i32 %16541, 65535" -> "  %16963 = mul nuw i32 %16599, %549""  %16599 = and i32 %16541, 65535" -> "  %16956 = mul nuw i32 %16599, %546""  %16599 = and i32 %16541, 65535" -> "  %16901 = mul nuw i32 %16599, %515""  %16599 = and i32 %16541, 65535" -> "  %16894 = mul nuw i32 %16599, %514""  %16599 = and i32 %16541, 65535" -> "  %16670 = mul nuw i32 %16599, %347""  %16599 = and i32 %16541, 65535" -> "  %16663 = mul nuw i32 %16599, %346""  %16599 = and i32 %16541, 65535" -> "  %16608 = mul nuw i32 %16599, %345""  %16599 = and i32 %16541, 65535" -> "  %16601 = mul nuw i32 %16599, %344"
"  %16600 = and i32 %16544, 65535"
"  %16600 = and i32 %16544, 65535" -> "  %16967 = mul nuw i32 %16600, %549""  %16600 = and i32 %16544, 65535" -> "  %16958 = mul nuw i32 %16600, %546""  %16600 = and i32 %16544, 65535" -> "  %16905 = mul nuw i32 %16600, %515""  %16600 = and i32 %16544, 65535" -> "  %16896 = mul nuw i32 %16600, %514""  %16600 = and i32 %16544, 65535" -> "  %16674 = mul nuw i32 %16600, %347""  %16600 = and i32 %16544, 65535" -> "  %16665 = mul nuw i32 %16600, %346""  %16600 = and i32 %16544, 65535" -> "  %16612 = mul nuw i32 %16600, %345""  %16600 = and i32 %16544, 65535" -> "  %16603 = mul nuw i32 %16600, %344"
"  %16601 = mul nuw i32 %16599, %344"
"  %16601 = mul nuw i32 %16599, %344" -> "  %16620 = and i32 %16601, 65535""  %16601 = mul nuw i32 %16599, %344" -> "  %16602 = lshr i32 %16601, 16"
"  %16602 = lshr i32 %16601, 16"
"  %16602 = lshr i32 %16601, 16" -> "  %16605 = add nuw nsw i32 %16604, %16602"
"  %16603 = mul nuw i32 %16600, %344"
"  %16603 = mul nuw i32 %16600, %344" -> "  %16606 = and i32 %16603, -65536""  %16603 = mul nuw i32 %16600, %344" -> "  %16604 = and i32 %16603, 65535"
"  %16604 = and i32 %16603, 65535"
"  %16604 = and i32 %16603, 65535" -> "  %16605 = add nuw nsw i32 %16604, %16602"
"  %16605 = add nuw nsw i32 %16604, %16602"
"  %16605 = add nuw nsw i32 %16604, %16602" -> "  %16607 = add nuw i32 %16605, %16606"
"  %16606 = and i32 %16603, -65536"
"  %16606 = and i32 %16603, -65536" -> "  %16607 = add nuw i32 %16605, %16606"
"  %16607 = add nuw i32 %16605, %16606"
"  %16607 = add nuw i32 %16605, %16606" -> "  %16611 = lshr i32 %16607, 16""  %16607 = add nuw i32 %16605, %16606" -> "  %16609 = and i32 %16607, 65535"
"  %16608 = mul nuw i32 %16599, %345"
"  %16608 = mul nuw i32 %16599, %345" -> "  %16610 = add nuw i32 %16609, %16608"
"  %16609 = and i32 %16607, 65535"
"  %16609 = and i32 %16607, 65535" -> "  %16610 = add nuw i32 %16609, %16608"
"  %16610 = add nuw i32 %16609, %16608"
"  %16610 = add nuw i32 %16609, %16608" -> "  %16622 = and i32 %16610, 65535""  %16610 = add nuw i32 %16609, %16608" -> "  %16614 = lshr i32 %16610, 16"
"  %16611 = lshr i32 %16607, 16"
"  %16611 = lshr i32 %16607, 16" -> "  %16613 = add nuw i32 %16611, %16612"
"  %16612 = mul nuw i32 %16600, %345"
"  %16612 = mul nuw i32 %16600, %345" -> "  %16613 = add nuw i32 %16611, %16612"
"  %16613 = add nuw i32 %16611, %16612"
"  %16613 = add nuw i32 %16611, %16612" -> "  %16617 = and i32 %16613, -65536""  %16613 = add nuw i32 %16611, %16612" -> "  %16615 = and i32 %16613, 65535"
"  %16614 = lshr i32 %16610, 16"
"  %16614 = lshr i32 %16610, 16" -> "  %16616 = add nuw nsw i32 %16614, %16615"
"  %16615 = and i32 %16613, 65535"
"  %16615 = and i32 %16613, 65535" -> "  %16616 = add nuw nsw i32 %16614, %16615"
"  %16616 = add nuw nsw i32 %16614, %16615"
"  %16616 = add nuw nsw i32 %16614, %16615" -> "  %16618 = add i32 %16616, %16617"
"  %16617 = and i32 %16613, -65536"
"  %16617 = and i32 %16613, -65536" -> "  %16618 = add i32 %16616, %16617"
"  %16618 = add i32 %16616, %16617"
"  %16618 = add i32 %16616, %16617" -> "  %16630 = add i32 %16618, %16628"
"  %16619 = and i32 %16598, 65535"
"  %16619 = and i32 %16598, 65535" -> "  %16621 = add nuw nsw i32 %16619, %16620"
"  %16620 = and i32 %16601, 65535"
"  %16620 = and i32 %16601, 65535" -> "  %16621 = add nuw nsw i32 %16619, %16620"
"  %16621 = add nuw nsw i32 %16619, %16620"
"  %16621 = add nuw nsw i32 %16619, %16620" -> "  %16650 = and i32 %16621, 65535""  %16621 = add nuw nsw i32 %16619, %16620" -> "  %16625 = lshr i32 %16621, 16"
"  %16622 = and i32 %16610, 65535"
"  %16622 = and i32 %16610, 65535" -> "  %16624 = add nuw nsw i32 %16622, %16623"
"  %16623 = lshr i32 %16598, 16"
"  %16623 = lshr i32 %16598, 16" -> "  %16624 = add nuw nsw i32 %16622, %16623"
"  %16624 = add nuw nsw i32 %16622, %16623"
"  %16624 = add nuw nsw i32 %16622, %16623" -> "  %16628 = lshr i32 %16624, 16""  %16624 = add nuw nsw i32 %16622, %16623" -> "  %16626 = and i32 %16624, 65535"
"  %16625 = lshr i32 %16621, 16"
"  %16625 = lshr i32 %16621, 16" -> "  %16627 = add nuw nsw i32 %16626, %16625"
"  %16626 = and i32 %16624, 65535"
"  %16626 = and i32 %16624, 65535" -> "  %16627 = add nuw nsw i32 %16626, %16625"
"  %16627 = add nuw nsw i32 %16626, %16625"
"  %16627 = add nuw nsw i32 %16626, %16625" -> "  %16653 = and i32 %16627, 65535""  %16627 = add nuw nsw i32 %16626, %16625" -> "  %16629 = lshr i32 %16627, 16"
"  %16628 = lshr i32 %16624, 16"
"  %16628 = lshr i32 %16624, 16" -> "  %16630 = add i32 %16618, %16628"
"  %16629 = lshr i32 %16627, 16"
"  %16629 = lshr i32 %16627, 16" -> "  %16631 = add i32 %16630, %16629"
"  %16630 = add i32 %16618, %16628"
"  %16630 = add i32 %16618, %16628" -> "  %16631 = add i32 %16630, %16629"
"  %16631 = add i32 %16630, %16629"
"  %16631 = add i32 %16630, %16629" -> "  %16685 = lshr i32 %16631, 16""  %16631 = add i32 %16630, %16629" -> "  %16681 = and i32 %16631, 65535"
"  %16632 = mul nuw i32 %16579, %346"
"  %16632 = mul nuw i32 %16579, %346" -> "  %16651 = and i32 %16632, 65535""  %16632 = mul nuw i32 %16579, %346" -> "  %16633 = lshr i32 %16632, 16"
"  %16633 = lshr i32 %16632, 16"
"  %16633 = lshr i32 %16632, 16" -> "  %16636 = add nuw nsw i32 %16635, %16633"
"  %16634 = mul nuw i32 %16580, %346"
"  %16634 = mul nuw i32 %16580, %346" -> "  %16637 = and i32 %16634, -65536""  %16634 = mul nuw i32 %16580, %346" -> "  %16635 = and i32 %16634, 65535"
"  %16635 = and i32 %16634, 65535"
"  %16635 = and i32 %16634, 65535" -> "  %16636 = add nuw nsw i32 %16635, %16633"
"  %16636 = add nuw nsw i32 %16635, %16633"
"  %16636 = add nuw nsw i32 %16635, %16633" -> "  %16638 = add nuw i32 %16636, %16637"
"  %16637 = and i32 %16634, -65536"
"  %16637 = and i32 %16634, -65536" -> "  %16638 = add nuw i32 %16636, %16637"
"  %16638 = add nuw i32 %16636, %16637"
"  %16638 = add nuw i32 %16636, %16637" -> "  %16642 = lshr i32 %16638, 16""  %16638 = add nuw i32 %16636, %16637" -> "  %16640 = and i32 %16638, 65535"
"  %16639 = mul nuw i32 %16579, %347"
"  %16639 = mul nuw i32 %16579, %347" -> "  %16641 = add nuw i32 %16640, %16639"
"  %16640 = and i32 %16638, 65535"
"  %16640 = and i32 %16638, 65535" -> "  %16641 = add nuw i32 %16640, %16639"
"  %16641 = add nuw i32 %16640, %16639"
"  %16641 = add nuw i32 %16640, %16639" -> "  %16654 = and i32 %16641, 65535""  %16641 = add nuw i32 %16640, %16639" -> "  %16645 = lshr i32 %16641, 16"
"  %16642 = lshr i32 %16638, 16"
"  %16642 = lshr i32 %16638, 16" -> "  %16644 = add nuw i32 %16642, %16643"
"  %16643 = mul nuw i32 %16580, %347"
"  %16643 = mul nuw i32 %16580, %347" -> "  %16644 = add nuw i32 %16642, %16643"
"  %16644 = add nuw i32 %16642, %16643"
"  %16644 = add nuw i32 %16642, %16643" -> "  %16648 = and i32 %16644, -65536""  %16644 = add nuw i32 %16642, %16643" -> "  %16646 = and i32 %16644, 65535"
"  %16645 = lshr i32 %16641, 16"
"  %16645 = lshr i32 %16641, 16" -> "  %16647 = add nuw nsw i32 %16645, %16646"
"  %16646 = and i32 %16644, 65535"
"  %16646 = and i32 %16644, 65535" -> "  %16647 = add nuw nsw i32 %16645, %16646"
"  %16647 = add nuw nsw i32 %16645, %16646"
"  %16647 = add nuw nsw i32 %16645, %16646" -> "  %16649 = add i32 %16647, %16648"
"  %16648 = and i32 %16644, -65536"
"  %16648 = and i32 %16644, -65536" -> "  %16649 = add i32 %16647, %16648"
"  %16649 = add i32 %16647, %16648"
"  %16649 = add i32 %16647, %16648" -> "  %16657 = add i32 %16649, %16656"
"  %16650 = and i32 %16621, 65535"
"  %16650 = and i32 %16621, 65535" -> "  %16652 = add nuw nsw i32 %16650, %16651"
"  %16651 = and i32 %16632, 65535"
"  %16651 = and i32 %16632, 65535" -> "  %16652 = add nuw nsw i32 %16650, %16651"
"  %16652 = add nuw nsw i32 %16650, %16651"
"  %16652 = add nuw nsw i32 %16650, %16651" -> "  %17261 = and i32 %16652, 65535""  %16652 = add nuw nsw i32 %16650, %16651" -> "  %16659 = lshr i32 %16652, 16"
"  %16653 = and i32 %16627, 65535"
"  %16653 = and i32 %16627, 65535" -> "  %16655 = add nuw nsw i32 %16653, %16654"
"  %16654 = and i32 %16641, 65535"
"  %16654 = and i32 %16641, 65535" -> "  %16655 = add nuw nsw i32 %16653, %16654"
"  %16655 = add nuw nsw i32 %16653, %16654"
"  %16655 = add nuw nsw i32 %16653, %16654" -> "  %16658 = and i32 %16655, 65535""  %16655 = add nuw nsw i32 %16653, %16654" -> "  %16656 = lshr i32 %16655, 16"
"  %16656 = lshr i32 %16655, 16"
"  %16656 = lshr i32 %16655, 16" -> "  %16657 = add i32 %16649, %16656"
"  %16657 = add i32 %16649, %16656"
"  %16657 = add i32 %16649, %16656" -> "  %16662 = add i32 %16657, %16661"
"  %16658 = and i32 %16655, 65535"
"  %16658 = and i32 %16655, 65535" -> "  %16660 = add nuw nsw i32 %16658, %16659"
"  %16659 = lshr i32 %16652, 16"
"  %16659 = lshr i32 %16652, 16" -> "  %16660 = add nuw nsw i32 %16658, %16659"
"  %16660 = add nuw nsw i32 %16658, %16659"
"  %16660 = add nuw nsw i32 %16658, %16659" -> "  %17264 = and i32 %16660, 65535""  %16660 = add nuw nsw i32 %16658, %16659" -> "  %16661 = lshr i32 %16660, 16"
"  %16661 = lshr i32 %16660, 16"
"  %16661 = lshr i32 %16660, 16" -> "  %16662 = add i32 %16657, %16661"
"  %16662 = add i32 %16657, %16661"
"  %16662 = add i32 %16657, %16661" -> "  %16698 = lshr i32 %16662, 16""  %16662 = add i32 %16657, %16661" -> "  %16695 = and i32 %16662, 65535"
"  %16663 = mul nuw i32 %16599, %346"
"  %16663 = mul nuw i32 %16599, %346" -> "  %16682 = and i32 %16663, 65535""  %16663 = mul nuw i32 %16599, %346" -> "  %16664 = lshr i32 %16663, 16"
"  %16664 = lshr i32 %16663, 16"
"  %16664 = lshr i32 %16663, 16" -> "  %16667 = add nuw nsw i32 %16666, %16664"
"  %16665 = mul nuw i32 %16600, %346"
"  %16665 = mul nuw i32 %16600, %346" -> "  %16668 = and i32 %16665, -65536""  %16665 = mul nuw i32 %16600, %346" -> "  %16666 = and i32 %16665, 65535"
"  %16666 = and i32 %16665, 65535"
"  %16666 = and i32 %16665, 65535" -> "  %16667 = add nuw nsw i32 %16666, %16664"
"  %16667 = add nuw nsw i32 %16666, %16664"
"  %16667 = add nuw nsw i32 %16666, %16664" -> "  %16669 = add nuw i32 %16667, %16668"
"  %16668 = and i32 %16665, -65536"
"  %16668 = and i32 %16665, -65536" -> "  %16669 = add nuw i32 %16667, %16668"
"  %16669 = add nuw i32 %16667, %16668"
"  %16669 = add nuw i32 %16667, %16668" -> "  %16673 = lshr i32 %16669, 16""  %16669 = add nuw i32 %16667, %16668" -> "  %16671 = and i32 %16669, 65535"
"  %16670 = mul nuw i32 %16599, %347"
"  %16670 = mul nuw i32 %16599, %347" -> "  %16672 = add nuw i32 %16671, %16670"
"  %16671 = and i32 %16669, 65535"
"  %16671 = and i32 %16669, 65535" -> "  %16672 = add nuw i32 %16671, %16670"
"  %16672 = add nuw i32 %16671, %16670"
"  %16672 = add nuw i32 %16671, %16670" -> "  %16684 = and i32 %16672, 65535""  %16672 = add nuw i32 %16671, %16670" -> "  %16676 = lshr i32 %16672, 16"
"  %16673 = lshr i32 %16669, 16"
"  %16673 = lshr i32 %16669, 16" -> "  %16675 = add nuw i32 %16673, %16674"
"  %16674 = mul nuw i32 %16600, %347"
"  %16674 = mul nuw i32 %16600, %347" -> "  %16675 = add nuw i32 %16673, %16674"
"  %16675 = add nuw i32 %16673, %16674"
"  %16675 = add nuw i32 %16673, %16674" -> "  %16679 = and i32 %16675, -65536""  %16675 = add nuw i32 %16673, %16674" -> "  %16677 = and i32 %16675, 65535"
"  %16676 = lshr i32 %16672, 16"
"  %16676 = lshr i32 %16672, 16" -> "  %16678 = add nuw nsw i32 %16676, %16677"
"  %16677 = and i32 %16675, 65535"
"  %16677 = and i32 %16675, 65535" -> "  %16678 = add nuw nsw i32 %16676, %16677"
"  %16678 = add nuw nsw i32 %16676, %16677"
"  %16678 = add nuw nsw i32 %16676, %16677" -> "  %16680 = add i32 %16678, %16679"
"  %16679 = and i32 %16675, -65536"
"  %16679 = and i32 %16675, -65536" -> "  %16680 = add i32 %16678, %16679"
"  %16680 = add i32 %16678, %16679"
"  %16680 = add i32 %16678, %16679" -> "  %16688 = add i32 %16680, %16687"
"  %16681 = and i32 %16631, 65535"
"  %16681 = and i32 %16631, 65535" -> "  %16683 = add nuw nsw i32 %16681, %16682"
"  %16682 = and i32 %16663, 65535"
"  %16682 = and i32 %16663, 65535" -> "  %16683 = add nuw nsw i32 %16681, %16682"
"  %16683 = add nuw nsw i32 %16681, %16682"
"  %16683 = add nuw nsw i32 %16681, %16682" -> "  %16694 = and i32 %16683, 65535""  %16683 = add nuw nsw i32 %16681, %16682" -> "  %16690 = lshr i32 %16683, 16"
"  %16684 = and i32 %16672, 65535"
"  %16684 = and i32 %16672, 65535" -> "  %16686 = add nuw nsw i32 %16685, %16684"
"  %16685 = lshr i32 %16631, 16"
"  %16685 = lshr i32 %16631, 16" -> "  %16686 = add nuw nsw i32 %16685, %16684"
"  %16686 = add nuw nsw i32 %16685, %16684"
"  %16686 = add nuw nsw i32 %16685, %16684" -> "  %16689 = and i32 %16686, 65535""  %16686 = add nuw nsw i32 %16685, %16684" -> "  %16687 = lshr i32 %16686, 16"
"  %16687 = lshr i32 %16686, 16"
"  %16687 = lshr i32 %16686, 16" -> "  %16688 = add i32 %16680, %16687"
"  %16688 = add i32 %16680, %16687"
"  %16688 = add i32 %16680, %16687" -> "  %16693 = add i32 %16688, %16692"
"  %16689 = and i32 %16686, 65535"
"  %16689 = and i32 %16686, 65535" -> "  %16691 = add nuw nsw i32 %16689, %16690"
"  %16690 = lshr i32 %16683, 16"
"  %16690 = lshr i32 %16683, 16" -> "  %16691 = add nuw nsw i32 %16689, %16690"
"  %16691 = add nuw nsw i32 %16689, %16690"
"  %16691 = add nuw nsw i32 %16689, %16690" -> "  %16697 = and i32 %16691, 65535""  %16691 = add nuw nsw i32 %16689, %16690" -> "  %16692 = lshr i32 %16691, 16"
"  %16692 = lshr i32 %16691, 16"
"  %16692 = lshr i32 %16691, 16" -> "  %16693 = add i32 %16688, %16692"
"  %16693 = add i32 %16688, %16692"
"  %16693 = add i32 %16688, %16692" -> "  %16706 = and i32 %16693, -65536""  %16693 = add i32 %16688, %16692" -> "  %16704 = and i32 %16693, 65535"
"  %16694 = and i32 %16683, 65535"
"  %16694 = and i32 %16683, 65535" -> "  %16696 = add nuw nsw i32 %16695, %16694"
"  %16695 = and i32 %16662, 65535"
"  %16695 = and i32 %16662, 65535" -> "  %16696 = add nuw nsw i32 %16695, %16694"
"  %16696 = add nuw nsw i32 %16695, %16694"
"  %16696 = add nuw nsw i32 %16695, %16694" -> "  %16839 = and i32 %16696, 65535""  %16696 = add nuw nsw i32 %16695, %16694" -> "  %16700 = lshr i32 %16696, 16"
"  %16697 = and i32 %16691, 65535"
"  %16697 = and i32 %16691, 65535" -> "  %16699 = add nuw nsw i32 %16697, %16698"
"  %16698 = lshr i32 %16662, 16"
"  %16698 = lshr i32 %16662, 16" -> "  %16699 = add nuw nsw i32 %16697, %16698"
"  %16699 = add nuw nsw i32 %16697, %16698"
"  %16699 = add nuw nsw i32 %16697, %16698" -> "  %16703 = lshr i32 %16699, 16""  %16699 = add nuw nsw i32 %16697, %16698" -> "  %16701 = and i32 %16699, 65535"
"  %16700 = lshr i32 %16696, 16"
"  %16700 = lshr i32 %16696, 16" -> "  %16702 = add nuw nsw i32 %16701, %16700"
"  %16701 = and i32 %16699, 65535"
"  %16701 = and i32 %16699, 65535" -> "  %16702 = add nuw nsw i32 %16701, %16700"
"  %16702 = add nuw nsw i32 %16701, %16700"
"  %16702 = add nuw nsw i32 %16701, %16700" -> "  %16842 = and i32 %16702, 65535""  %16702 = add nuw nsw i32 %16701, %16700" -> "  %16708 = lshr i32 %16702, 16"
"  %16703 = lshr i32 %16699, 16"
"  %16703 = lshr i32 %16699, 16" -> "  %16705 = add nuw nsw i32 %16703, %16704"
"  %16704 = and i32 %16693, 65535"
"  %16704 = and i32 %16693, 65535" -> "  %16705 = add nuw nsw i32 %16703, %16704"
"  %16705 = add nuw nsw i32 %16703, %16704"
"  %16705 = add nuw nsw i32 %16703, %16704" -> "  %16707 = add i32 %16705, %16706"
"  %16706 = and i32 %16693, -65536"
"  %16706 = and i32 %16693, -65536" -> "  %16707 = add i32 %16705, %16706"
"  %16707 = add i32 %16705, %16706"
"  %16707 = add i32 %16705, %16706" -> "  %16709 = add i32 %16707, %16708"
"  %16708 = lshr i32 %16702, 16"
"  %16708 = lshr i32 %16702, 16" -> "  %16709 = add i32 %16707, %16708"
"  %16709 = add i32 %16707, %16708"
"  %16709 = add i32 %16707, %16708" -> "  %16851 = and i32 %16709, 65535""  %16709 = add i32 %16707, %16708" -> "  %16854 = lshr i32 %16709, 16"
"  %16710 = and i32 %16564, 65535"
"  %16710 = and i32 %16564, 65535" -> "  %17094 = mul nuw i32 %16710, %549""  %16710 = and i32 %16564, 65535" -> "  %17087 = mul nuw i32 %16710, %546""  %16710 = and i32 %16564, 65535" -> "  %17048 = mul nuw i32 %16710, %515""  %16710 = and i32 %16564, 65535" -> "  %17041 = mul nuw i32 %16710, %514""  %16710 = and i32 %16564, 65535" -> "  %16770 = mul nuw i32 %16710, %347""  %16710 = and i32 %16564, 65535" -> "  %16763 = mul nuw i32 %16710, %346""  %16710 = and i32 %16564, 65535" -> "  %16719 = mul nuw i32 %16710, %345""  %16710 = and i32 %16564, 65535" -> "  %16711 = mul nuw i32 %16710, %344"
"  %16711 = mul nuw i32 %16710, %344"
"  %16711 = mul nuw i32 %16710, %344" -> "  %16838 = and i32 %16711, 65535""  %16711 = mul nuw i32 %16710, %344" -> "  %16712 = lshr i32 %16711, 16"
"  %16712 = lshr i32 %16711, 16"
"  %16712 = lshr i32 %16711, 16" -> "  %16716 = add nuw nsw i32 %16715, %16712"
"  %16713 = and i32 %16567, 65535"
"  %16713 = and i32 %16567, 65535" -> "  %17098 = mul nuw i32 %16713, %549""  %16713 = and i32 %16567, 65535" -> "  %17089 = mul nuw i32 %16713, %546""  %16713 = and i32 %16567, 65535" -> "  %17052 = mul nuw i32 %16713, %515""  %16713 = and i32 %16567, 65535" -> "  %17043 = mul nuw i32 %16713, %514""  %16713 = and i32 %16567, 65535" -> "  %16774 = mul nuw i32 %16713, %347""  %16713 = and i32 %16567, 65535" -> "  %16765 = mul nuw i32 %16713, %346""  %16713 = and i32 %16567, 65535" -> "  %16723 = mul nuw i32 %16713, %345""  %16713 = and i32 %16567, 65535" -> "  %16714 = mul nuw i32 %16713, %344"
"  %16714 = mul nuw i32 %16713, %344"
"  %16714 = mul nuw i32 %16713, %344" -> "  %16717 = and i32 %16714, -65536""  %16714 = mul nuw i32 %16713, %344" -> "  %16715 = and i32 %16714, 65535"
"  %16715 = and i32 %16714, 65535"
"  %16715 = and i32 %16714, 65535" -> "  %16716 = add nuw nsw i32 %16715, %16712"
"  %16716 = add nuw nsw i32 %16715, %16712"
"  %16716 = add nuw nsw i32 %16715, %16712" -> "  %16718 = add nuw i32 %16716, %16717"
"  %16717 = and i32 %16714, -65536"
"  %16717 = and i32 %16714, -65536" -> "  %16718 = add nuw i32 %16716, %16717"
"  %16718 = add nuw i32 %16716, %16717"
"  %16718 = add nuw i32 %16716, %16717" -> "  %16722 = lshr i32 %16718, 16""  %16718 = add nuw i32 %16716, %16717" -> "  %16720 = and i32 %16718, 65535"
"  %16719 = mul nuw i32 %16710, %345"
"  %16719 = mul nuw i32 %16710, %345" -> "  %16721 = add nuw i32 %16720, %16719"
"  %16720 = and i32 %16718, 65535"
"  %16720 = and i32 %16718, 65535" -> "  %16721 = add nuw i32 %16720, %16719"
"  %16721 = add nuw i32 %16720, %16719"
"  %16721 = add nuw i32 %16720, %16719" -> "  %16841 = and i32 %16721, 65535""  %16721 = add nuw i32 %16720, %16719" -> "  %16725 = lshr i32 %16721, 16"
"  %16722 = lshr i32 %16718, 16"
"  %16722 = lshr i32 %16718, 16" -> "  %16724 = add nuw i32 %16722, %16723"
"  %16723 = mul nuw i32 %16713, %345"
"  %16723 = mul nuw i32 %16713, %345" -> "  %16724 = add nuw i32 %16722, %16723"
"  %16724 = add nuw i32 %16722, %16723"
"  %16724 = add nuw i32 %16722, %16723" -> "  %16726 = and i32 %16724, 65535""  %16724 = add nuw i32 %16722, %16723" -> "  %16728 = and i32 %16724, -65536"
"  %16725 = lshr i32 %16721, 16"
"  %16725 = lshr i32 %16721, 16" -> "  %16727 = add nuw nsw i32 %16725, %16726"
"  %16726 = and i32 %16724, 65535"
"  %16726 = and i32 %16724, 65535" -> "  %16727 = add nuw nsw i32 %16725, %16726"
"  %16727 = add nuw nsw i32 %16725, %16726"
"  %16727 = add nuw nsw i32 %16725, %16726" -> "  %16729 = add i32 %16727, %16728"
"  %16728 = and i32 %16724, -65536"
"  %16728 = and i32 %16724, -65536" -> "  %16729 = add i32 %16727, %16728"
"  %16729 = add i32 %16727, %16728"
"  %16729 = add i32 %16727, %16728" -> "  %16754 = lshr i32 %16729, 16""  %16729 = add i32 %16727, %16728" -> "  %16750 = and i32 %16729, 65535"
"  %16730 = and i32 %16578, 65535"
"  %16730 = and i32 %16578, 65535" -> "  %17125 = mul nuw i32 %16730, %549""  %16730 = and i32 %16578, 65535" -> "  %17118 = mul nuw i32 %16730, %546""  %16730 = and i32 %16578, 65535" -> "  %17063 = mul nuw i32 %16730, %515""  %16730 = and i32 %16578, 65535" -> "  %17059 = mul nuw i32 %16730, %514""  %16730 = and i32 %16578, 65535" -> "  %16801 = mul nuw i32 %16730, %347""  %16730 = and i32 %16578, 65535" -> "  %16794 = mul nuw i32 %16730, %346""  %16730 = and i32 %16578, 65535" -> "  %16739 = mul nuw i32 %16730, %345""  %16730 = and i32 %16578, 65535" -> "  %16731 = mul nuw i32 %16730, %344"
"  %16731 = mul nuw i32 %16730, %344"
"  %16731 = mul nuw i32 %16730, %344" -> "  %16751 = and i32 %16731, 65535""  %16731 = mul nuw i32 %16730, %344" -> "  %16732 = lshr i32 %16731, 16"
"  %16732 = lshr i32 %16731, 16"
"  %16732 = lshr i32 %16731, 16" -> "  %16736 = add nuw nsw i32 %16735, %16732"
"  %16733 = lshr i32 %16578, 16"
"  %16733 = lshr i32 %16578, 16" -> "  %17128 = mul nuw i32 %16733, %549""  %16733 = lshr i32 %16578, 16" -> "  %17120 = mul nuw i32 %16733, %546""  %16733 = lshr i32 %16578, 16" -> "  %17067 = mul nuw i32 %16733, %515""  %16733 = lshr i32 %16578, 16" -> "  %17061 = mul nuw i32 %16733, %514""  %16733 = lshr i32 %16578, 16" -> "  %16805 = mul nuw i32 %16733, %347""  %16733 = lshr i32 %16578, 16" -> "  %16796 = mul nuw i32 %16733, %346""  %16733 = lshr i32 %16578, 16" -> "  %16743 = mul nuw i32 %16733, %345""  %16733 = lshr i32 %16578, 16" -> "  %16734 = mul nuw i32 %16733, %344"
"  %16734 = mul nuw i32 %16733, %344"
"  %16734 = mul nuw i32 %16733, %344" -> "  %16737 = and i32 %16734, -65536""  %16734 = mul nuw i32 %16733, %344" -> "  %16735 = and i32 %16734, 65535"
"  %16735 = and i32 %16734, 65535"
"  %16735 = and i32 %16734, 65535" -> "  %16736 = add nuw nsw i32 %16735, %16732"
"  %16736 = add nuw nsw i32 %16735, %16732"
"  %16736 = add nuw nsw i32 %16735, %16732" -> "  %16738 = add nuw i32 %16736, %16737"
"  %16737 = and i32 %16734, -65536"
"  %16737 = and i32 %16734, -65536" -> "  %16738 = add nuw i32 %16736, %16737"
"  %16738 = add nuw i32 %16736, %16737"
"  %16738 = add nuw i32 %16736, %16737" -> "  %16742 = lshr i32 %16738, 16""  %16738 = add nuw i32 %16736, %16737" -> "  %16740 = and i32 %16738, 65535"
"  %16739 = mul nuw i32 %16730, %345"
"  %16739 = mul nuw i32 %16730, %345" -> "  %16741 = add nuw i32 %16740, %16739"
"  %16740 = and i32 %16738, 65535"
"  %16740 = and i32 %16738, 65535" -> "  %16741 = add nuw i32 %16740, %16739"
"  %16741 = add nuw i32 %16740, %16739"
"  %16741 = add nuw i32 %16740, %16739" -> "  %16753 = and i32 %16741, 65535""  %16741 = add nuw i32 %16740, %16739" -> "  %16745 = lshr i32 %16741, 16"
"  %16742 = lshr i32 %16738, 16"
"  %16742 = lshr i32 %16738, 16" -> "  %16744 = add nuw i32 %16742, %16743"
"  %16743 = mul nuw i32 %16733, %345"
"  %16743 = mul nuw i32 %16733, %345" -> "  %16744 = add nuw i32 %16742, %16743"
"  %16744 = add nuw i32 %16742, %16743"
"  %16744 = add nuw i32 %16742, %16743" -> "  %16748 = and i32 %16744, -65536""  %16744 = add nuw i32 %16742, %16743" -> "  %16746 = and i32 %16744, 65535"
"  %16745 = lshr i32 %16741, 16"
"  %16745 = lshr i32 %16741, 16" -> "  %16747 = add nuw nsw i32 %16745, %16746"
"  %16746 = and i32 %16744, 65535"
"  %16746 = and i32 %16744, 65535" -> "  %16747 = add nuw nsw i32 %16745, %16746"
"  %16747 = add nuw nsw i32 %16745, %16746"
"  %16747 = add nuw nsw i32 %16745, %16746" -> "  %16749 = add i32 %16747, %16748"
"  %16748 = and i32 %16744, -65536"
"  %16748 = and i32 %16744, -65536" -> "  %16749 = add i32 %16747, %16748"
"  %16749 = add i32 %16747, %16748"
"  %16749 = add i32 %16747, %16748" -> "  %16761 = add i32 %16749, %16759"
"  %16750 = and i32 %16729, 65535"
"  %16750 = and i32 %16729, 65535" -> "  %16752 = add nuw nsw i32 %16750, %16751"
"  %16751 = and i32 %16731, 65535"
"  %16751 = and i32 %16731, 65535" -> "  %16752 = add nuw nsw i32 %16750, %16751"
"  %16752 = add nuw nsw i32 %16750, %16751"
"  %16752 = add nuw nsw i32 %16750, %16751" -> "  %16781 = and i32 %16752, 65535""  %16752 = add nuw nsw i32 %16750, %16751" -> "  %16756 = lshr i32 %16752, 16"
"  %16753 = and i32 %16741, 65535"
"  %16753 = and i32 %16741, 65535" -> "  %16755 = add nuw nsw i32 %16753, %16754"
"  %16754 = lshr i32 %16729, 16"
"  %16754 = lshr i32 %16729, 16" -> "  %16755 = add nuw nsw i32 %16753, %16754"
"  %16755 = add nuw nsw i32 %16753, %16754"
"  %16755 = add nuw nsw i32 %16753, %16754" -> "  %16759 = lshr i32 %16755, 16""  %16755 = add nuw nsw i32 %16753, %16754" -> "  %16757 = and i32 %16755, 65535"
"  %16756 = lshr i32 %16752, 16"
"  %16756 = lshr i32 %16752, 16" -> "  %16758 = add nuw nsw i32 %16757, %16756"
"  %16757 = and i32 %16755, 65535"
"  %16757 = and i32 %16755, 65535" -> "  %16758 = add nuw nsw i32 %16757, %16756"
"  %16758 = add nuw nsw i32 %16757, %16756"
"  %16758 = add nuw nsw i32 %16757, %16756" -> "  %16784 = and i32 %16758, 65535""  %16758 = add nuw nsw i32 %16757, %16756" -> "  %16760 = lshr i32 %16758, 16"
"  %16759 = lshr i32 %16755, 16"
"  %16759 = lshr i32 %16755, 16" -> "  %16761 = add i32 %16749, %16759"
"  %16760 = lshr i32 %16758, 16"
"  %16760 = lshr i32 %16758, 16" -> "  %16762 = add i32 %16761, %16760"
"  %16761 = add i32 %16749, %16759"
"  %16761 = add i32 %16749, %16759" -> "  %16762 = add i32 %16761, %16760"
"  %16762 = add i32 %16761, %16760"
"  %16762 = add i32 %16761, %16760" -> "  %16816 = lshr i32 %16762, 16""  %16762 = add i32 %16761, %16760" -> "  %16812 = and i32 %16762, 65535"
"  %16763 = mul nuw i32 %16710, %346"
"  %16763 = mul nuw i32 %16710, %346" -> "  %16782 = and i32 %16763, 65535""  %16763 = mul nuw i32 %16710, %346" -> "  %16764 = lshr i32 %16763, 16"
"  %16764 = lshr i32 %16763, 16"
"  %16764 = lshr i32 %16763, 16" -> "  %16767 = add nuw nsw i32 %16766, %16764"
"  %16765 = mul nuw i32 %16713, %346"
"  %16765 = mul nuw i32 %16713, %346" -> "  %16768 = and i32 %16765, -65536""  %16765 = mul nuw i32 %16713, %346" -> "  %16766 = and i32 %16765, 65535"
"  %16766 = and i32 %16765, 65535"
"  %16766 = and i32 %16765, 65535" -> "  %16767 = add nuw nsw i32 %16766, %16764"
"  %16767 = add nuw nsw i32 %16766, %16764"
"  %16767 = add nuw nsw i32 %16766, %16764" -> "  %16769 = add nuw i32 %16767, %16768"
"  %16768 = and i32 %16765, -65536"
"  %16768 = and i32 %16765, -65536" -> "  %16769 = add nuw i32 %16767, %16768"
"  %16769 = add nuw i32 %16767, %16768"
"  %16769 = add nuw i32 %16767, %16768" -> "  %16773 = lshr i32 %16769, 16""  %16769 = add nuw i32 %16767, %16768" -> "  %16771 = and i32 %16769, 65535"
"  %16770 = mul nuw i32 %16710, %347"
"  %16770 = mul nuw i32 %16710, %347" -> "  %16772 = add nuw i32 %16771, %16770"
"  %16771 = and i32 %16769, 65535"
"  %16771 = and i32 %16769, 65535" -> "  %16772 = add nuw i32 %16771, %16770"
"  %16772 = add nuw i32 %16771, %16770"
"  %16772 = add nuw i32 %16771, %16770" -> "  %16785 = and i32 %16772, 65535""  %16772 = add nuw i32 %16771, %16770" -> "  %16776 = lshr i32 %16772, 16"
"  %16773 = lshr i32 %16769, 16"
"  %16773 = lshr i32 %16769, 16" -> "  %16775 = add nuw i32 %16773, %16774"
"  %16774 = mul nuw i32 %16713, %347"
"  %16774 = mul nuw i32 %16713, %347" -> "  %16775 = add nuw i32 %16773, %16774"
"  %16775 = add nuw i32 %16773, %16774"
"  %16775 = add nuw i32 %16773, %16774" -> "  %16779 = and i32 %16775, -65536""  %16775 = add nuw i32 %16773, %16774" -> "  %16777 = and i32 %16775, 65535"
"  %16776 = lshr i32 %16772, 16"
"  %16776 = lshr i32 %16772, 16" -> "  %16778 = add nuw nsw i32 %16776, %16777"
"  %16777 = and i32 %16775, 65535"
"  %16777 = and i32 %16775, 65535" -> "  %16778 = add nuw nsw i32 %16776, %16777"
"  %16778 = add nuw nsw i32 %16776, %16777"
"  %16778 = add nuw nsw i32 %16776, %16777" -> "  %16780 = add i32 %16778, %16779"
"  %16779 = and i32 %16775, -65536"
"  %16779 = and i32 %16775, -65536" -> "  %16780 = add i32 %16778, %16779"
"  %16780 = add i32 %16778, %16779"
"  %16780 = add i32 %16778, %16779" -> "  %16788 = add i32 %16780, %16787"
"  %16781 = and i32 %16752, 65535"
"  %16781 = and i32 %16752, 65535" -> "  %16783 = add nuw nsw i32 %16781, %16782"
"  %16782 = and i32 %16763, 65535"
"  %16782 = and i32 %16763, 65535" -> "  %16783 = add nuw nsw i32 %16781, %16782"
"  %16783 = add nuw nsw i32 %16781, %16782"
"  %16783 = add nuw nsw i32 %16781, %16782" -> "  %16850 = and i32 %16783, 65535""  %16783 = add nuw nsw i32 %16781, %16782" -> "  %16790 = lshr i32 %16783, 16"
"  %16784 = and i32 %16758, 65535"
"  %16784 = and i32 %16758, 65535" -> "  %16786 = add nuw nsw i32 %16784, %16785"
"  %16785 = and i32 %16772, 65535"
"  %16785 = and i32 %16772, 65535" -> "  %16786 = add nuw nsw i32 %16784, %16785"
"  %16786 = add nuw nsw i32 %16784, %16785"
"  %16786 = add nuw nsw i32 %16784, %16785" -> "  %16789 = and i32 %16786, 65535""  %16786 = add nuw nsw i32 %16784, %16785" -> "  %16787 = lshr i32 %16786, 16"
"  %16787 = lshr i32 %16786, 16"
"  %16787 = lshr i32 %16786, 16" -> "  %16788 = add i32 %16780, %16787"
"  %16788 = add i32 %16780, %16787"
"  %16788 = add i32 %16780, %16787" -> "  %16793 = add i32 %16788, %16792"
"  %16789 = and i32 %16786, 65535"
"  %16789 = and i32 %16786, 65535" -> "  %16791 = add nuw nsw i32 %16789, %16790"
"  %16790 = lshr i32 %16783, 16"
"  %16790 = lshr i32 %16783, 16" -> "  %16791 = add nuw nsw i32 %16789, %16790"
"  %16791 = add nuw nsw i32 %16789, %16790"
"  %16791 = add nuw nsw i32 %16789, %16790" -> "  %16853 = and i32 %16791, 65535""  %16791 = add nuw nsw i32 %16789, %16790" -> "  %16792 = lshr i32 %16791, 16"
"  %16792 = lshr i32 %16791, 16"
"  %16792 = lshr i32 %16791, 16" -> "  %16793 = add i32 %16788, %16792"
"  %16793 = add i32 %16788, %16792"
"  %16793 = add i32 %16788, %16792" -> "  %16829 = lshr i32 %16793, 16""  %16793 = add i32 %16788, %16792" -> "  %16826 = and i32 %16793, 65535"
"  %16794 = mul nuw i32 %16730, %346"
"  %16794 = mul nuw i32 %16730, %346" -> "  %16813 = and i32 %16794, 65535""  %16794 = mul nuw i32 %16730, %346" -> "  %16795 = lshr i32 %16794, 16"
"  %16795 = lshr i32 %16794, 16"
"  %16795 = lshr i32 %16794, 16" -> "  %16798 = add nuw nsw i32 %16795, %16797"
"  %16796 = mul nuw i32 %16733, %346"
"  %16796 = mul nuw i32 %16733, %346" -> "  %16799 = and i32 %16796, -65536""  %16796 = mul nuw i32 %16733, %346" -> "  %16797 = and i32 %16796, 65535"
"  %16797 = and i32 %16796, 65535"
"  %16797 = and i32 %16796, 65535" -> "  %16798 = add nuw nsw i32 %16795, %16797"
"  %16798 = add nuw nsw i32 %16795, %16797"
"  %16798 = add nuw nsw i32 %16795, %16797" -> "  %16800 = add nuw i32 %16798, %16799"
"  %16799 = and i32 %16796, -65536"
"  %16799 = and i32 %16796, -65536" -> "  %16800 = add nuw i32 %16798, %16799"
"  %16800 = add nuw i32 %16798, %16799"
"  %16800 = add nuw i32 %16798, %16799" -> "  %16804 = lshr i32 %16800, 16""  %16800 = add nuw i32 %16798, %16799" -> "  %16802 = and i32 %16800, 65535"
"  %16801 = mul nuw i32 %16730, %347"
"  %16801 = mul nuw i32 %16730, %347" -> "  %16803 = add nuw i32 %16802, %16801"
"  %16802 = and i32 %16800, 65535"
"  %16802 = and i32 %16800, 65535" -> "  %16803 = add nuw i32 %16802, %16801"
"  %16803 = add nuw i32 %16802, %16801"
"  %16803 = add nuw i32 %16802, %16801" -> "  %16815 = and i32 %16803, 65535""  %16803 = add nuw i32 %16802, %16801" -> "  %16807 = lshr i32 %16803, 16"
"  %16804 = lshr i32 %16800, 16"
"  %16804 = lshr i32 %16800, 16" -> "  %16806 = add nuw i32 %16804, %16805"
"  %16805 = mul nuw i32 %16733, %347"
"  %16805 = mul nuw i32 %16733, %347" -> "  %16806 = add nuw i32 %16804, %16805"
"  %16806 = add nuw i32 %16804, %16805"
"  %16806 = add nuw i32 %16804, %16805" -> "  %16810 = and i32 %16806, -65536""  %16806 = add nuw i32 %16804, %16805" -> "  %16808 = and i32 %16806, 65535"
"  %16807 = lshr i32 %16803, 16"
"  %16807 = lshr i32 %16803, 16" -> "  %16809 = add nuw nsw i32 %16807, %16808"
"  %16808 = and i32 %16806, 65535"
"  %16808 = and i32 %16806, 65535" -> "  %16809 = add nuw nsw i32 %16807, %16808"
"  %16809 = add nuw nsw i32 %16807, %16808"
"  %16809 = add nuw nsw i32 %16807, %16808" -> "  %16811 = add i32 %16809, %16810"
"  %16810 = and i32 %16806, -65536"
"  %16810 = and i32 %16806, -65536" -> "  %16811 = add i32 %16809, %16810"
"  %16811 = add i32 %16809, %16810"
"  %16811 = add i32 %16809, %16810" -> "  %16819 = add i32 %16811, %16818"
"  %16812 = and i32 %16762, 65535"
"  %16812 = and i32 %16762, 65535" -> "  %16814 = add nuw nsw i32 %16812, %16813"
"  %16813 = and i32 %16794, 65535"
"  %16813 = and i32 %16794, 65535" -> "  %16814 = add nuw nsw i32 %16812, %16813"
"  %16814 = add nuw nsw i32 %16812, %16813"
"  %16814 = add nuw nsw i32 %16812, %16813" -> "  %16825 = and i32 %16814, 65535""  %16814 = add nuw nsw i32 %16812, %16813" -> "  %16821 = lshr i32 %16814, 16"
"  %16815 = and i32 %16803, 65535"
"  %16815 = and i32 %16803, 65535" -> "  %16817 = add nuw nsw i32 %16816, %16815"
"  %16816 = lshr i32 %16762, 16"
"  %16816 = lshr i32 %16762, 16" -> "  %16817 = add nuw nsw i32 %16816, %16815"
"  %16817 = add nuw nsw i32 %16816, %16815"
"  %16817 = add nuw nsw i32 %16816, %16815" -> "  %16820 = and i32 %16817, 65535""  %16817 = add nuw nsw i32 %16816, %16815" -> "  %16818 = lshr i32 %16817, 16"
"  %16818 = lshr i32 %16817, 16"
"  %16818 = lshr i32 %16817, 16" -> "  %16819 = add i32 %16811, %16818"
"  %16819 = add i32 %16811, %16818"
"  %16819 = add i32 %16811, %16818" -> "  %16824 = add i32 %16819, %16823"
"  %16820 = and i32 %16817, 65535"
"  %16820 = and i32 %16817, 65535" -> "  %16822 = add nuw nsw i32 %16820, %16821"
"  %16821 = lshr i32 %16814, 16"
"  %16821 = lshr i32 %16814, 16" -> "  %16822 = add nuw nsw i32 %16820, %16821"
"  %16822 = add nuw nsw i32 %16820, %16821"
"  %16822 = add nuw nsw i32 %16820, %16821" -> "  %16828 = and i32 %16822, 65535""  %16822 = add nuw nsw i32 %16820, %16821" -> "  %16823 = lshr i32 %16822, 16"
"  %16823 = lshr i32 %16822, 16"
"  %16823 = lshr i32 %16822, 16" -> "  %16824 = add i32 %16819, %16823"
"  %16824 = add i32 %16819, %16823"
"  %16824 = add i32 %16819, %16823" -> "  %16836 = add i32 %16824, %16834"
"  %16825 = and i32 %16814, 65535"
"  %16825 = and i32 %16814, 65535" -> "  %16827 = add nuw nsw i32 %16826, %16825"
"  %16826 = and i32 %16793, 65535"
"  %16826 = and i32 %16793, 65535" -> "  %16827 = add nuw nsw i32 %16826, %16825"
"  %16827 = add nuw nsw i32 %16826, %16825"
"  %16827 = add nuw nsw i32 %16826, %16825" -> "  %16864 = and i32 %16827, 65535""  %16827 = add nuw nsw i32 %16826, %16825" -> "  %16831 = lshr i32 %16827, 16"
"  %16828 = and i32 %16822, 65535"
"  %16828 = and i32 %16822, 65535" -> "  %16830 = add nuw nsw i32 %16829, %16828"
"  %16829 = lshr i32 %16793, 16"
"  %16829 = lshr i32 %16793, 16" -> "  %16830 = add nuw nsw i32 %16829, %16828"
"  %16830 = add nuw nsw i32 %16829, %16828"
"  %16830 = add nuw nsw i32 %16829, %16828" -> "  %16834 = lshr i32 %16830, 16""  %16830 = add nuw nsw i32 %16829, %16828" -> "  %16832 = and i32 %16830, 65535"
"  %16831 = lshr i32 %16827, 16"
"  %16831 = lshr i32 %16827, 16" -> "  %16833 = add nuw nsw i32 %16831, %16832"
"  %16832 = and i32 %16830, 65535"
"  %16832 = and i32 %16830, 65535" -> "  %16833 = add nuw nsw i32 %16831, %16832"
"  %16833 = add nuw nsw i32 %16831, %16832"
"  %16833 = add nuw nsw i32 %16831, %16832" -> "  %16871 = and i32 %16833, 65535""  %16833 = add nuw nsw i32 %16831, %16832" -> "  %16835 = lshr i32 %16833, 16"
"  %16834 = lshr i32 %16830, 16"
"  %16834 = lshr i32 %16830, 16" -> "  %16836 = add i32 %16824, %16834"
"  %16835 = lshr i32 %16833, 16"
"  %16835 = lshr i32 %16833, 16" -> "  %16837 = add i32 %16836, %16835"
"  %16836 = add i32 %16824, %16834"
"  %16836 = add i32 %16824, %16834" -> "  %16837 = add i32 %16836, %16835"
"  %16837 = add i32 %16836, %16835"
"  %16837 = add i32 %16836, %16835" -> "  %16875 = add i32 %16837, %16874"
"  %16838 = and i32 %16711, 65535"
"  %16838 = and i32 %16711, 65535" -> "  %16840 = add nuw nsw i32 %16839, %16838"
"  %16839 = and i32 %16696, 65535"
"  %16839 = and i32 %16696, 65535" -> "  %16840 = add nuw nsw i32 %16839, %16838"
"  %16840 = add nuw nsw i32 %16839, %16838"
"  %16840 = add nuw nsw i32 %16839, %16838" -> "  %17004 = and i32 %16840, 65535""  %16840 = add nuw nsw i32 %16839, %16838" -> "  %16844 = lshr i32 %16840, 16"
"  %16841 = and i32 %16721, 65535"
"  %16841 = and i32 %16721, 65535" -> "  %16843 = add nuw nsw i32 %16842, %16841"
"  %16842 = and i32 %16702, 65535"
"  %16842 = and i32 %16702, 65535" -> "  %16843 = add nuw nsw i32 %16842, %16841"
"  %16843 = add nuw nsw i32 %16842, %16841"
"  %16843 = add nuw nsw i32 %16842, %16841" -> "  %16847 = lshr i32 %16843, 16""  %16843 = add nuw nsw i32 %16842, %16841" -> "  %16845 = and i32 %16843, 65535"
"  %16844 = lshr i32 %16840, 16"
"  %16844 = lshr i32 %16840, 16" -> "  %16846 = add nuw nsw i32 %16845, %16844"
"  %16845 = and i32 %16843, 65535"
"  %16845 = and i32 %16843, 65535" -> "  %16846 = add nuw nsw i32 %16845, %16844"
"  %16846 = add nuw nsw i32 %16845, %16844"
"  %16846 = add nuw nsw i32 %16845, %16844" -> "  %17007 = and i32 %16846, 65535""  %16846 = add nuw nsw i32 %16845, %16844" -> "  %16848 = lshr i32 %16846, 16"
"  %16847 = lshr i32 %16843, 16"
"  %16847 = lshr i32 %16843, 16" -> "  %16849 = add nuw nsw i32 %16848, %16847"
"  %16848 = lshr i32 %16846, 16"
"  %16848 = lshr i32 %16846, 16" -> "  %16849 = add nuw nsw i32 %16848, %16847"
"  %16849 = add nuw nsw i32 %16848, %16847"
"  %16849 = add nuw nsw i32 %16848, %16847" -> "  %16860 = add nuw nsw i32 %16849, %16859"
"  %16850 = and i32 %16783, 65535"
"  %16850 = and i32 %16783, 65535" -> "  %16852 = add nuw nsw i32 %16850, %16851"
"  %16851 = and i32 %16709, 65535"
"  %16851 = and i32 %16709, 65535" -> "  %16852 = add nuw nsw i32 %16850, %16851"
"  %16852 = add nuw nsw i32 %16850, %16851"
"  %16852 = add nuw nsw i32 %16850, %16851" -> "  %16859 = and i32 %16852, 65535""  %16852 = add nuw nsw i32 %16850, %16851" -> "  %16856 = lshr i32 %16852, 16"
"  %16853 = and i32 %16791, 65535"
"  %16853 = and i32 %16791, 65535" -> "  %16855 = add nuw nsw i32 %16853, %16854"
"  %16854 = lshr i32 %16709, 16"
"  %16854 = lshr i32 %16709, 16" -> "  %16855 = add nuw nsw i32 %16853, %16854"
"  %16855 = add nuw nsw i32 %16853, %16854"
"  %16855 = add nuw nsw i32 %16853, %16854" -> "  %16865 = lshr i32 %16855, 16""  %16855 = add nuw nsw i32 %16853, %16854" -> "  %16857 = and i32 %16855, 65535"
"  %16856 = lshr i32 %16852, 16"
"  %16856 = lshr i32 %16852, 16" -> "  %16858 = add nuw nsw i32 %16857, %16856"
"  %16857 = and i32 %16855, 65535"
"  %16857 = and i32 %16855, 65535" -> "  %16858 = add nuw nsw i32 %16857, %16856"
"  %16858 = add nuw nsw i32 %16857, %16856"
"  %16858 = add nuw nsw i32 %16857, %16856" -> "  %16867 = lshr i32 %16858, 16""  %16858 = add nuw nsw i32 %16857, %16856" -> "  %16862 = and i32 %16858, 65535"
"  %16859 = and i32 %16852, 65535"
"  %16859 = and i32 %16852, 65535" -> "  %16860 = add nuw nsw i32 %16849, %16859"
"  %16860 = add nuw nsw i32 %16849, %16859"
"  %16860 = add nuw nsw i32 %16849, %16859" -> "  %17016 = and i32 %16860, 65535""  %16860 = add nuw nsw i32 %16849, %16859" -> "  %16861 = lshr i32 %16860, 16"
"  %16861 = lshr i32 %16860, 16"
"  %16861 = lshr i32 %16860, 16" -> "  %16863 = add nuw nsw i32 %16862, %16861"
"  %16862 = and i32 %16858, 65535"
"  %16862 = and i32 %16858, 65535" -> "  %16863 = add nuw nsw i32 %16862, %16861"
"  %16863 = add nuw nsw i32 %16862, %16861"
"  %16863 = add nuw nsw i32 %16862, %16861" -> "  %17019 = and i32 %16863, 65535""  %16863 = add nuw nsw i32 %16862, %16861" -> "  %16869 = lshr i32 %16863, 16"
"  %16864 = and i32 %16827, 65535"
"  %16864 = and i32 %16827, 65535" -> "  %16866 = add nuw nsw i32 %16864, %16865"
"  %16865 = lshr i32 %16855, 16"
"  %16865 = lshr i32 %16855, 16" -> "  %16866 = add nuw nsw i32 %16864, %16865"
"  %16866 = add nuw nsw i32 %16864, %16865"
"  %16866 = add nuw nsw i32 %16864, %16865" -> "  %16868 = add nuw nsw i32 %16866, %16867"
"  %16867 = lshr i32 %16858, 16"
"  %16867 = lshr i32 %16858, 16" -> "  %16868 = add nuw nsw i32 %16866, %16867"
"  %16868 = add nuw nsw i32 %16866, %16867"
"  %16868 = add nuw nsw i32 %16866, %16867" -> "  %16870 = add nuw nsw i32 %16868, %16869"
"  %16869 = lshr i32 %16863, 16"
"  %16869 = lshr i32 %16863, 16" -> "  %16870 = add nuw nsw i32 %16868, %16869"
"  %16870 = add nuw nsw i32 %16868, %16869"
"  %16870 = add nuw nsw i32 %16868, %16869" -> "  %17166 = and i32 %16870, 65535""  %16870 = add nuw nsw i32 %16868, %16869" -> "  %16872 = lshr i32 %16870, 16"
"  %16871 = and i32 %16833, 65535"
"  %16871 = and i32 %16833, 65535" -> "  %16873 = add nuw nsw i32 %16872, %16871"
"  %16872 = lshr i32 %16870, 16"
"  %16872 = lshr i32 %16870, 16" -> "  %16873 = add nuw nsw i32 %16872, %16871"
"  %16873 = add nuw nsw i32 %16872, %16871"
"  %16873 = add nuw nsw i32 %16872, %16871" -> "  %17169 = and i32 %16873, 65535""  %16873 = add nuw nsw i32 %16872, %16871" -> "  %16874 = lshr i32 %16873, 16"
"  %16874 = lshr i32 %16873, 16"
"  %16874 = lshr i32 %16873, 16" -> "  %16875 = add i32 %16837, %16874"
"  %16875 = add i32 %16837, %16874"
"  %16875 = add i32 %16837, %16874" -> "  %17175 = and i32 %16875, 65535""  %16875 = add i32 %16837, %16874" -> "  %17178 = lshr i32 %16875, 16"
"  %16876 = mul nuw i32 %16579, %514"
"  %16876 = mul nuw i32 %16579, %514" -> "  %17003 = and i32 %16876, 65535""  %16876 = mul nuw i32 %16579, %514" -> "  %16877 = lshr i32 %16876, 16"
"  %16877 = lshr i32 %16876, 16"
"  %16877 = lshr i32 %16876, 16" -> "  %16880 = add nuw nsw i32 %16879, %16877"
"  %16878 = mul nuw i32 %16580, %514"
"  %16878 = mul nuw i32 %16580, %514" -> "  %16881 = and i32 %16878, -65536""  %16878 = mul nuw i32 %16580, %514" -> "  %16879 = and i32 %16878, 65535"
"  %16879 = and i32 %16878, 65535"
"  %16879 = and i32 %16878, 65535" -> "  %16880 = add nuw nsw i32 %16879, %16877"
"  %16880 = add nuw nsw i32 %16879, %16877"
"  %16880 = add nuw nsw i32 %16879, %16877" -> "  %16882 = add nuw i32 %16880, %16881"
"  %16881 = and i32 %16878, -65536"
"  %16881 = and i32 %16878, -65536" -> "  %16882 = add nuw i32 %16880, %16881"
"  %16882 = add nuw i32 %16880, %16881"
"  %16882 = add nuw i32 %16880, %16881" -> "  %16886 = lshr i32 %16882, 16""  %16882 = add nuw i32 %16880, %16881" -> "  %16884 = and i32 %16882, 65535"
"  %16883 = mul nuw i32 %16579, %515"
"  %16883 = mul nuw i32 %16579, %515" -> "  %16885 = add nuw i32 %16884, %16883"
"  %16884 = and i32 %16882, 65535"
"  %16884 = and i32 %16882, 65535" -> "  %16885 = add nuw i32 %16884, %16883"
"  %16885 = add nuw i32 %16884, %16883"
"  %16885 = add nuw i32 %16884, %16883" -> "  %17006 = and i32 %16885, 65535""  %16885 = add nuw i32 %16884, %16883" -> "  %16889 = lshr i32 %16885, 16"
"  %16886 = lshr i32 %16882, 16"
"  %16886 = lshr i32 %16882, 16" -> "  %16888 = add nuw i32 %16886, %16887"
"  %16887 = mul nuw i32 %16580, %515"
"  %16887 = mul nuw i32 %16580, %515" -> "  %16888 = add nuw i32 %16886, %16887"
"  %16888 = add nuw i32 %16886, %16887"
"  %16888 = add nuw i32 %16886, %16887" -> "  %16892 = and i32 %16888, -65536""  %16888 = add nuw i32 %16886, %16887" -> "  %16890 = and i32 %16888, 65535"
"  %16889 = lshr i32 %16885, 16"
"  %16889 = lshr i32 %16885, 16" -> "  %16891 = add nuw nsw i32 %16889, %16890"
"  %16890 = and i32 %16888, 65535"
"  %16890 = and i32 %16888, 65535" -> "  %16891 = add nuw nsw i32 %16889, %16890"
"  %16891 = add nuw nsw i32 %16889, %16890"
"  %16891 = add nuw nsw i32 %16889, %16890" -> "  %16893 = add i32 %16891, %16892"
"  %16892 = and i32 %16888, -65536"
"  %16892 = and i32 %16888, -65536" -> "  %16893 = add i32 %16891, %16892"
"  %16893 = add i32 %16891, %16892"
"  %16893 = add i32 %16891, %16892" -> "  %16916 = lshr i32 %16893, 16""  %16893 = add i32 %16891, %16892" -> "  %16912 = and i32 %16893, 65535"
"  %16894 = mul nuw i32 %16599, %514"
"  %16894 = mul nuw i32 %16599, %514" -> "  %16913 = and i32 %16894, 65535""  %16894 = mul nuw i32 %16599, %514" -> "  %16895 = lshr i32 %16894, 16"
"  %16895 = lshr i32 %16894, 16"
"  %16895 = lshr i32 %16894, 16" -> "  %16898 = add nuw nsw i32 %16897, %16895"
"  %16896 = mul nuw i32 %16600, %514"
"  %16896 = mul nuw i32 %16600, %514" -> "  %16899 = and i32 %16896, -65536""  %16896 = mul nuw i32 %16600, %514" -> "  %16897 = and i32 %16896, 65535"
"  %16897 = and i32 %16896, 65535"
"  %16897 = and i32 %16896, 65535" -> "  %16898 = add nuw nsw i32 %16897, %16895"
"  %16898 = add nuw nsw i32 %16897, %16895"
"  %16898 = add nuw nsw i32 %16897, %16895" -> "  %16900 = add nuw i32 %16898, %16899"
"  %16899 = and i32 %16896, -65536"
"  %16899 = and i32 %16896, -65536" -> "  %16900 = add nuw i32 %16898, %16899"
"  %16900 = add nuw i32 %16898, %16899"
"  %16900 = add nuw i32 %16898, %16899" -> "  %16904 = lshr i32 %16900, 16""  %16900 = add nuw i32 %16898, %16899" -> "  %16902 = and i32 %16900, 65535"
"  %16901 = mul nuw i32 %16599, %515"
"  %16901 = mul nuw i32 %16599, %515" -> "  %16903 = add nuw i32 %16902, %16901"
"  %16902 = and i32 %16900, 65535"
"  %16902 = and i32 %16900, 65535" -> "  %16903 = add nuw i32 %16902, %16901"
"  %16903 = add nuw i32 %16902, %16901"
"  %16903 = add nuw i32 %16902, %16901" -> "  %16915 = and i32 %16903, 65535""  %16903 = add nuw i32 %16902, %16901" -> "  %16907 = lshr i32 %16903, 16"
"  %16904 = lshr i32 %16900, 16"
"  %16904 = lshr i32 %16900, 16" -> "  %16906 = add nuw i32 %16904, %16905"
"  %16905 = mul nuw i32 %16600, %515"
"  %16905 = mul nuw i32 %16600, %515" -> "  %16906 = add nuw i32 %16904, %16905"
"  %16906 = add nuw i32 %16904, %16905"
"  %16906 = add nuw i32 %16904, %16905" -> "  %16910 = and i32 %16906, -65536""  %16906 = add nuw i32 %16904, %16905" -> "  %16908 = and i32 %16906, 65535"
"  %16907 = lshr i32 %16903, 16"
"  %16907 = lshr i32 %16903, 16" -> "  %16909 = add nuw nsw i32 %16907, %16908"
"  %16908 = and i32 %16906, 65535"
"  %16908 = and i32 %16906, 65535" -> "  %16909 = add nuw nsw i32 %16907, %16908"
"  %16909 = add nuw nsw i32 %16907, %16908"
"  %16909 = add nuw nsw i32 %16907, %16908" -> "  %16911 = add i32 %16909, %16910"
"  %16910 = and i32 %16906, -65536"
"  %16910 = and i32 %16906, -65536" -> "  %16911 = add i32 %16909, %16910"
"  %16911 = add i32 %16909, %16910"
"  %16911 = add i32 %16909, %16910" -> "  %16919 = add i32 %16911, %16918"
"  %16912 = and i32 %16893, 65535"
"  %16912 = and i32 %16893, 65535" -> "  %16914 = add nuw nsw i32 %16912, %16913"
"  %16913 = and i32 %16894, 65535"
"  %16913 = and i32 %16894, 65535" -> "  %16914 = add nuw nsw i32 %16912, %16913"
"  %16914 = add nuw nsw i32 %16912, %16913"
"  %16914 = add nuw nsw i32 %16912, %16913" -> "  %16943 = and i32 %16914, 65535""  %16914 = add nuw nsw i32 %16912, %16913" -> "  %16921 = lshr i32 %16914, 16"
"  %16915 = and i32 %16903, 65535"
"  %16915 = and i32 %16903, 65535" -> "  %16917 = add nuw nsw i32 %16915, %16916"
"  %16916 = lshr i32 %16893, 16"
"  %16916 = lshr i32 %16893, 16" -> "  %16917 = add nuw nsw i32 %16915, %16916"
"  %16917 = add nuw nsw i32 %16915, %16916"
"  %16917 = add nuw nsw i32 %16915, %16916" -> "  %16920 = and i32 %16917, 65535""  %16917 = add nuw nsw i32 %16915, %16916" -> "  %16918 = lshr i32 %16917, 16"
"  %16918 = lshr i32 %16917, 16"
"  %16918 = lshr i32 %16917, 16" -> "  %16919 = add i32 %16911, %16918"
"  %16919 = add i32 %16911, %16918"
"  %16919 = add i32 %16911, %16918" -> "  %16924 = add i32 %16919, %16923"
"  %16920 = and i32 %16917, 65535"
"  %16920 = and i32 %16917, 65535" -> "  %16922 = add nuw nsw i32 %16920, %16921"
"  %16921 = lshr i32 %16914, 16"
"  %16921 = lshr i32 %16914, 16" -> "  %16922 = add nuw nsw i32 %16920, %16921"
"  %16922 = add nuw nsw i32 %16920, %16921"
"  %16922 = add nuw nsw i32 %16920, %16921" -> "  %16946 = and i32 %16922, 65535""  %16922 = add nuw nsw i32 %16920, %16921" -> "  %16923 = lshr i32 %16922, 16"
"  %16923 = lshr i32 %16922, 16"
"  %16923 = lshr i32 %16922, 16" -> "  %16924 = add i32 %16919, %16923"
"  %16924 = add i32 %16919, %16923"
"  %16924 = add i32 %16919, %16923" -> "  %16978 = lshr i32 %16924, 16""  %16924 = add i32 %16919, %16923" -> "  %16974 = and i32 %16924, 65535"
"  %16925 = mul nuw i32 %16579, %546"
"  %16925 = mul nuw i32 %16579, %546" -> "  %16944 = and i32 %16925, 65535""  %16925 = mul nuw i32 %16579, %546" -> "  %16926 = lshr i32 %16925, 16"
"  %16926 = lshr i32 %16925, 16"
"  %16926 = lshr i32 %16925, 16" -> "  %16929 = add nuw nsw i32 %16928, %16926"
"  %16927 = mul nuw i32 %16580, %546"
"  %16927 = mul nuw i32 %16580, %546" -> "  %16930 = and i32 %16927, -65536""  %16927 = mul nuw i32 %16580, %546" -> "  %16928 = and i32 %16927, 65535"
"  %16928 = and i32 %16927, 65535"
"  %16928 = and i32 %16927, 65535" -> "  %16929 = add nuw nsw i32 %16928, %16926"
"  %16929 = add nuw nsw i32 %16928, %16926"
"  %16929 = add nuw nsw i32 %16928, %16926" -> "  %16931 = add nuw i32 %16929, %16930"
"  %16930 = and i32 %16927, -65536"
"  %16930 = and i32 %16927, -65536" -> "  %16931 = add nuw i32 %16929, %16930"
"  %16931 = add nuw i32 %16929, %16930"
"  %16931 = add nuw i32 %16929, %16930" -> "  %16935 = lshr i32 %16931, 16""  %16931 = add nuw i32 %16929, %16930" -> "  %16933 = and i32 %16931, 65535"
"  %16932 = mul nuw i32 %16579, %549"
"  %16932 = mul nuw i32 %16579, %549" -> "  %16934 = add nuw i32 %16933, %16932"
"  %16933 = and i32 %16931, 65535"
"  %16933 = and i32 %16931, 65535" -> "  %16934 = add nuw i32 %16933, %16932"
"  %16934 = add nuw i32 %16933, %16932"
"  %16934 = add nuw i32 %16933, %16932" -> "  %16947 = and i32 %16934, 65535""  %16934 = add nuw i32 %16933, %16932" -> "  %16938 = lshr i32 %16934, 16"
"  %16935 = lshr i32 %16931, 16"
"  %16935 = lshr i32 %16931, 16" -> "  %16937 = add nuw i32 %16935, %16936"
"  %16936 = mul nuw i32 %16580, %549"
"  %16936 = mul nuw i32 %16580, %549" -> "  %16937 = add nuw i32 %16935, %16936"
"  %16937 = add nuw i32 %16935, %16936"
"  %16937 = add nuw i32 %16935, %16936" -> "  %16941 = and i32 %16937, -65536""  %16937 = add nuw i32 %16935, %16936" -> "  %16939 = and i32 %16937, 65535"
"  %16938 = lshr i32 %16934, 16"
"  %16938 = lshr i32 %16934, 16" -> "  %16940 = add nuw nsw i32 %16938, %16939"
"  %16939 = and i32 %16937, 65535"
"  %16939 = and i32 %16937, 65535" -> "  %16940 = add nuw nsw i32 %16938, %16939"
"  %16940 = add nuw nsw i32 %16938, %16939"
"  %16940 = add nuw nsw i32 %16938, %16939" -> "  %16942 = add i32 %16940, %16941"
"  %16941 = and i32 %16937, -65536"
"  %16941 = and i32 %16937, -65536" -> "  %16942 = add i32 %16940, %16941"
"  %16942 = add i32 %16940, %16941"
"  %16942 = add i32 %16940, %16941" -> "  %16950 = add i32 %16942, %16949"
"  %16943 = and i32 %16914, 65535"
"  %16943 = and i32 %16914, 65535" -> "  %16945 = add nuw nsw i32 %16943, %16944"
"  %16944 = and i32 %16925, 65535"
"  %16944 = and i32 %16925, 65535" -> "  %16945 = add nuw nsw i32 %16943, %16944"
"  %16945 = add nuw nsw i32 %16943, %16944"
"  %16945 = add nuw nsw i32 %16943, %16944" -> "  %17015 = and i32 %16945, 65535""  %16945 = add nuw nsw i32 %16943, %16944" -> "  %16952 = lshr i32 %16945, 16"
"  %16946 = and i32 %16922, 65535"
"  %16946 = and i32 %16922, 65535" -> "  %16948 = add nuw nsw i32 %16946, %16947"
"  %16947 = and i32 %16934, 65535"
"  %16947 = and i32 %16934, 65535" -> "  %16948 = add nuw nsw i32 %16946, %16947"
"  %16948 = add nuw nsw i32 %16946, %16947"
"  %16948 = add nuw nsw i32 %16946, %16947" -> "  %16951 = and i32 %16948, 65535""  %16948 = add nuw nsw i32 %16946, %16947" -> "  %16949 = lshr i32 %16948, 16"
"  %16949 = lshr i32 %16948, 16"
"  %16949 = lshr i32 %16948, 16" -> "  %16950 = add i32 %16942, %16949"
"  %16950 = add i32 %16942, %16949"
"  %16950 = add i32 %16942, %16949" -> "  %16955 = add i32 %16950, %16954"
"  %16951 = and i32 %16948, 65535"
"  %16951 = and i32 %16948, 65535" -> "  %16953 = add nuw nsw i32 %16951, %16952"
"  %16952 = lshr i32 %16945, 16"
"  %16952 = lshr i32 %16945, 16" -> "  %16953 = add nuw nsw i32 %16951, %16952"
"  %16953 = add nuw nsw i32 %16951, %16952"
"  %16953 = add nuw nsw i32 %16951, %16952" -> "  %17018 = and i32 %16953, 65535""  %16953 = add nuw nsw i32 %16951, %16952" -> "  %16954 = lshr i32 %16953, 16"
"  %16954 = lshr i32 %16953, 16"
"  %16954 = lshr i32 %16953, 16" -> "  %16955 = add i32 %16950, %16954"
"  %16955 = add i32 %16950, %16954"
"  %16955 = add i32 %16950, %16954" -> "  %16991 = lshr i32 %16955, 16""  %16955 = add i32 %16950, %16954" -> "  %16988 = and i32 %16955, 65535"
"  %16956 = mul nuw i32 %16599, %546"
"  %16956 = mul nuw i32 %16599, %546" -> "  %16975 = and i32 %16956, 65535""  %16956 = mul nuw i32 %16599, %546" -> "  %16957 = lshr i32 %16956, 16"
"  %16957 = lshr i32 %16956, 16"
"  %16957 = lshr i32 %16956, 16" -> "  %16960 = add nuw nsw i32 %16959, %16957"
"  %16958 = mul nuw i32 %16600, %546"
"  %16958 = mul nuw i32 %16600, %546" -> "  %16961 = and i32 %16958, -65536""  %16958 = mul nuw i32 %16600, %546" -> "  %16959 = and i32 %16958, 65535"
"  %16959 = and i32 %16958, 65535"
"  %16959 = and i32 %16958, 65535" -> "  %16960 = add nuw nsw i32 %16959, %16957"
"  %16960 = add nuw nsw i32 %16959, %16957"
"  %16960 = add nuw nsw i32 %16959, %16957" -> "  %16962 = add nuw i32 %16960, %16961"
"  %16961 = and i32 %16958, -65536"
"  %16961 = and i32 %16958, -65536" -> "  %16962 = add nuw i32 %16960, %16961"
"  %16962 = add nuw i32 %16960, %16961"
"  %16962 = add nuw i32 %16960, %16961" -> "  %16966 = lshr i32 %16962, 16""  %16962 = add nuw i32 %16960, %16961" -> "  %16964 = and i32 %16962, 65535"
"  %16963 = mul nuw i32 %16599, %549"
"  %16963 = mul nuw i32 %16599, %549" -> "  %16965 = add nuw i32 %16964, %16963"
"  %16964 = and i32 %16962, 65535"
"  %16964 = and i32 %16962, 65535" -> "  %16965 = add nuw i32 %16964, %16963"
"  %16965 = add nuw i32 %16964, %16963"
"  %16965 = add nuw i32 %16964, %16963" -> "  %16977 = and i32 %16965, 65535""  %16965 = add nuw i32 %16964, %16963" -> "  %16969 = lshr i32 %16965, 16"
"  %16966 = lshr i32 %16962, 16"
"  %16966 = lshr i32 %16962, 16" -> "  %16968 = add nuw i32 %16966, %16967"
"  %16967 = mul nuw i32 %16600, %549"
"  %16967 = mul nuw i32 %16600, %549" -> "  %16968 = add nuw i32 %16966, %16967"
"  %16968 = add nuw i32 %16966, %16967"
"  %16968 = add nuw i32 %16966, %16967" -> "  %16972 = and i32 %16968, -65536""  %16968 = add nuw i32 %16966, %16967" -> "  %16970 = and i32 %16968, 65535"
"  %16969 = lshr i32 %16965, 16"
"  %16969 = lshr i32 %16965, 16" -> "  %16971 = add nuw nsw i32 %16969, %16970"
"  %16970 = and i32 %16968, 65535"
"  %16970 = and i32 %16968, 65535" -> "  %16971 = add nuw nsw i32 %16969, %16970"
"  %16971 = add nuw nsw i32 %16969, %16970"
"  %16971 = add nuw nsw i32 %16969, %16970" -> "  %16973 = add i32 %16971, %16972"
"  %16972 = and i32 %16968, -65536"
"  %16972 = and i32 %16968, -65536" -> "  %16973 = add i32 %16971, %16972"
"  %16973 = add i32 %16971, %16972"
"  %16973 = add i32 %16971, %16972" -> "  %16981 = add i32 %16973, %16980"
"  %16974 = and i32 %16924, 65535"
"  %16974 = and i32 %16924, 65535" -> "  %16976 = add nuw nsw i32 %16974, %16975"
"  %16975 = and i32 %16956, 65535"
"  %16975 = and i32 %16956, 65535" -> "  %16976 = add nuw nsw i32 %16974, %16975"
"  %16976 = add nuw nsw i32 %16974, %16975"
"  %16976 = add nuw nsw i32 %16974, %16975" -> "  %16987 = and i32 %16976, 65535""  %16976 = add nuw nsw i32 %16974, %16975" -> "  %16983 = lshr i32 %16976, 16"
"  %16977 = and i32 %16965, 65535"
"  %16977 = and i32 %16965, 65535" -> "  %16979 = add nuw nsw i32 %16978, %16977"
"  %16978 = lshr i32 %16924, 16"
"  %16978 = lshr i32 %16924, 16" -> "  %16979 = add nuw nsw i32 %16978, %16977"
"  %16979 = add nuw nsw i32 %16978, %16977"
"  %16979 = add nuw nsw i32 %16978, %16977" -> "  %16982 = and i32 %16979, 65535""  %16979 = add nuw nsw i32 %16978, %16977" -> "  %16980 = lshr i32 %16979, 16"
"  %16980 = lshr i32 %16979, 16"
"  %16980 = lshr i32 %16979, 16" -> "  %16981 = add i32 %16973, %16980"
"  %16981 = add i32 %16973, %16980"
"  %16981 = add i32 %16973, %16980" -> "  %16986 = add i32 %16981, %16985"
"  %16982 = and i32 %16979, 65535"
"  %16982 = and i32 %16979, 65535" -> "  %16984 = add nuw nsw i32 %16982, %16983"
"  %16983 = lshr i32 %16976, 16"
"  %16983 = lshr i32 %16976, 16" -> "  %16984 = add nuw nsw i32 %16982, %16983"
"  %16984 = add nuw nsw i32 %16982, %16983"
"  %16984 = add nuw nsw i32 %16982, %16983" -> "  %16990 = and i32 %16984, 65535""  %16984 = add nuw nsw i32 %16982, %16983" -> "  %16985 = lshr i32 %16984, 16"
"  %16985 = lshr i32 %16984, 16"
"  %16985 = lshr i32 %16984, 16" -> "  %16986 = add i32 %16981, %16985"
"  %16986 = add i32 %16981, %16985"
"  %16986 = add i32 %16981, %16985" -> "  %16999 = and i32 %16986, -65536""  %16986 = add i32 %16981, %16985" -> "  %16997 = and i32 %16986, 65535"
"  %16987 = and i32 %16976, 65535"
"  %16987 = and i32 %16976, 65535" -> "  %16989 = add nuw nsw i32 %16988, %16987"
"  %16988 = and i32 %16955, 65535"
"  %16988 = and i32 %16955, 65535" -> "  %16989 = add nuw nsw i32 %16988, %16987"
"  %16989 = add nuw nsw i32 %16988, %16987"
"  %16989 = add nuw nsw i32 %16988, %16987" -> "  %17030 = and i32 %16989, 65535""  %16989 = add nuw nsw i32 %16988, %16987" -> "  %16993 = lshr i32 %16989, 16"
"  %16990 = and i32 %16984, 65535"
"  %16990 = and i32 %16984, 65535" -> "  %16992 = add nuw nsw i32 %16991, %16990"
"  %16991 = lshr i32 %16955, 16"
"  %16991 = lshr i32 %16955, 16" -> "  %16992 = add nuw nsw i32 %16991, %16990"
"  %16992 = add nuw nsw i32 %16991, %16990"
"  %16992 = add nuw nsw i32 %16991, %16990" -> "  %16996 = lshr i32 %16992, 16""  %16992 = add nuw nsw i32 %16991, %16990" -> "  %16994 = and i32 %16992, 65535"
"  %16993 = lshr i32 %16989, 16"
"  %16993 = lshr i32 %16989, 16" -> "  %16995 = add nuw nsw i32 %16993, %16994"
"  %16994 = and i32 %16992, 65535"
"  %16994 = and i32 %16992, 65535" -> "  %16995 = add nuw nsw i32 %16993, %16994"
"  %16995 = add nuw nsw i32 %16993, %16994"
"  %16995 = add nuw nsw i32 %16993, %16994" -> "  %17037 = and i32 %16995, 65535""  %16995 = add nuw nsw i32 %16993, %16994" -> "  %17001 = lshr i32 %16995, 16"
"  %16996 = lshr i32 %16992, 16"
"  %16996 = lshr i32 %16992, 16" -> "  %16998 = add nuw nsw i32 %16996, %16997"
"  %16997 = and i32 %16986, 65535"
"  %16997 = and i32 %16986, 65535" -> "  %16998 = add nuw nsw i32 %16996, %16997"
"  %16998 = add nuw nsw i32 %16996, %16997"
"  %16998 = add nuw nsw i32 %16996, %16997" -> "  %17000 = add i32 %16998, %16999"
"  %16999 = and i32 %16986, -65536"
"  %16999 = and i32 %16986, -65536" -> "  %17000 = add i32 %16998, %16999"
"  %17000 = add i32 %16998, %16999"
"  %17000 = add i32 %16998, %16999" -> "  %17002 = add i32 %17000, %17001"
"  %17001 = lshr i32 %16995, 16"
"  %17001 = lshr i32 %16995, 16" -> "  %17002 = add i32 %17000, %17001"
"  %17002 = add i32 %17000, %17001"
"  %17002 = add i32 %17000, %17001" -> "  %17040 = add i32 %17002, %17039"
"  %17003 = and i32 %16876, 65535"
"  %17003 = and i32 %16876, 65535" -> "  %17005 = add nuw nsw i32 %17004, %17003"
"  %17004 = and i32 %16840, 65535"
"  %17004 = and i32 %16840, 65535" -> "  %17005 = add nuw nsw i32 %17004, %17003"
"  %17005 = add nuw nsw i32 %17004, %17003"
"  %17005 = add nuw nsw i32 %17004, %17003" -> "  %17375 = and i32 %17005, 65535""  %17005 = add nuw nsw i32 %17004, %17003" -> "  %17009 = lshr i32 %17005, 16"
"  %17006 = and i32 %16885, 65535"
"  %17006 = and i32 %16885, 65535" -> "  %17008 = add nuw nsw i32 %17007, %17006"
"  %17007 = and i32 %16846, 65535"
"  %17007 = and i32 %16846, 65535" -> "  %17008 = add nuw nsw i32 %17007, %17006"
"  %17008 = add nuw nsw i32 %17007, %17006"
"  %17008 = add nuw nsw i32 %17007, %17006" -> "  %17012 = lshr i32 %17008, 16""  %17008 = add nuw nsw i32 %17007, %17006" -> "  %17010 = and i32 %17008, 65535"
"  %17009 = lshr i32 %17005, 16"
"  %17009 = lshr i32 %17005, 16" -> "  %17011 = add nuw nsw i32 %17010, %17009"
"  %17010 = and i32 %17008, 65535"
"  %17010 = and i32 %17008, 65535" -> "  %17011 = add nuw nsw i32 %17010, %17009"
"  %17011 = add nuw nsw i32 %17010, %17009"
"  %17011 = add nuw nsw i32 %17010, %17009" -> "  %17376 = and i32 %17011, 65535""  %17011 = add nuw nsw i32 %17010, %17009" -> "  %17013 = lshr i32 %17011, 16"
"  %17012 = lshr i32 %17008, 16"
"  %17012 = lshr i32 %17008, 16" -> "  %17014 = add nuw nsw i32 %17013, %17012"
"  %17013 = lshr i32 %17011, 16"
"  %17013 = lshr i32 %17011, 16" -> "  %17014 = add nuw nsw i32 %17013, %17012"
"  %17014 = add nuw nsw i32 %17013, %17012"
"  %17014 = add nuw nsw i32 %17013, %17012" -> "  %17025 = add nuw nsw i32 %17014, %17024"
"  %17015 = and i32 %16945, 65535"
"  %17015 = and i32 %16945, 65535" -> "  %17017 = add nuw nsw i32 %17016, %17015"
"  %17016 = and i32 %16860, 65535"
"  %17016 = and i32 %16860, 65535" -> "  %17017 = add nuw nsw i32 %17016, %17015"
"  %17017 = add nuw nsw i32 %17016, %17015"
"  %17017 = add nuw nsw i32 %17016, %17015" -> "  %17024 = and i32 %17017, 65535""  %17017 = add nuw nsw i32 %17016, %17015" -> "  %17021 = lshr i32 %17017, 16"
"  %17018 = and i32 %16953, 65535"
"  %17018 = and i32 %16953, 65535" -> "  %17020 = add nuw nsw i32 %17019, %17018"
"  %17019 = and i32 %16863, 65535"
"  %17019 = and i32 %16863, 65535" -> "  %17020 = add nuw nsw i32 %17019, %17018"
"  %17020 = add nuw nsw i32 %17019, %17018"
"  %17020 = add nuw nsw i32 %17019, %17018" -> "  %17029 = lshr i32 %17020, 16""  %17020 = add nuw nsw i32 %17019, %17018" -> "  %17022 = and i32 %17020, 65535"
"  %17021 = lshr i32 %17017, 16"
"  %17021 = lshr i32 %17017, 16" -> "  %17023 = add nuw nsw i32 %17022, %17021"
"  %17022 = and i32 %17020, 65535"
"  %17022 = and i32 %17020, 65535" -> "  %17023 = add nuw nsw i32 %17022, %17021"
"  %17023 = add nuw nsw i32 %17022, %17021"
"  %17023 = add nuw nsw i32 %17022, %17021" -> "  %17027 = and i32 %17023, 65535""  %17023 = add nuw nsw i32 %17022, %17021" -> "  %17031 = lshr i32 %17023, 16"
"  %17024 = and i32 %17017, 65535"
"  %17024 = and i32 %17017, 65535" -> "  %17025 = add nuw nsw i32 %17014, %17024"
"  %17025 = add nuw nsw i32 %17014, %17024"
"  %17025 = add nuw nsw i32 %17014, %17024" -> "  %17395 = and i32 %17025, 65535""  %17025 = add nuw nsw i32 %17014, %17024" -> "  %17026 = lshr i32 %17025, 16"
"  %17026 = lshr i32 %17025, 16"
"  %17026 = lshr i32 %17025, 16" -> "  %17028 = add nuw nsw i32 %17027, %17026"
"  %17027 = and i32 %17023, 65535"
"  %17027 = and i32 %17023, 65535" -> "  %17028 = add nuw nsw i32 %17027, %17026"
"  %17028 = add nuw nsw i32 %17027, %17026"
"  %17028 = add nuw nsw i32 %17027, %17026" -> "  %17398 = and i32 %17028, 65535""  %17028 = add nuw nsw i32 %17027, %17026" -> "  %17032 = lshr i32 %17028, 16""  %17028 = add nuw nsw i32 %17027, %17026" -> "  store i32 %17028, i32* %540, align 1, !noalias !41"
"  store i32 %17028, i32* %540, align 1, !noalias !41"

"  %17029 = lshr i32 %17020, 16"
"  %17029 = lshr i32 %17020, 16" -> "  %17033 = add nuw nsw i32 %17029, %17030"
"  %17030 = and i32 %16989, 65535"
"  %17030 = and i32 %16989, 65535" -> "  %17033 = add nuw nsw i32 %17029, %17030"
"  %17031 = lshr i32 %17023, 16"
"  %17031 = lshr i32 %17023, 16" -> "  %17034 = add nuw nsw i32 %17033, %17031"
"  %17032 = lshr i32 %17028, 16"
"  %17032 = lshr i32 %17028, 16" -> "  %17035 = add nuw nsw i32 %17034, %17032"
"  %17033 = add nuw nsw i32 %17029, %17030"
"  %17033 = add nuw nsw i32 %17029, %17030" -> "  %17034 = add nuw nsw i32 %17033, %17031"
"  %17034 = add nuw nsw i32 %17033, %17031"
"  %17034 = add nuw nsw i32 %17033, %17031" -> "  %17035 = add nuw nsw i32 %17034, %17032"
"  %17035 = add nuw nsw i32 %17034, %17032"
"  %17035 = add nuw nsw i32 %17034, %17032" -> "  %17204 = and i32 %17035, 65535""  %17035 = add nuw nsw i32 %17034, %17032" -> "  %17036 = lshr i32 %17035, 16"
"  %17036 = lshr i32 %17035, 16"
"  %17036 = lshr i32 %17035, 16" -> "  %17038 = add nuw nsw i32 %17036, %17037"
"  %17037 = and i32 %16995, 65535"
"  %17037 = and i32 %16995, 65535" -> "  %17038 = add nuw nsw i32 %17036, %17037"
"  %17038 = add nuw nsw i32 %17036, %17037"
"  %17038 = add nuw nsw i32 %17036, %17037" -> "  %17207 = and i32 %17038, 65535""  %17038 = add nuw nsw i32 %17036, %17037" -> "  %17039 = lshr i32 %17038, 16"
"  %17039 = lshr i32 %17038, 16"
"  %17039 = lshr i32 %17038, 16" -> "  %17040 = add i32 %17002, %17039"
"  %17040 = add i32 %17002, %17039"
"  %17040 = add i32 %17002, %17039" -> "  %17213 = and i32 %17040, 65535""  %17040 = add i32 %17002, %17039" -> "  %17216 = lshr i32 %17040, 16"
"  %17041 = mul nuw i32 %16710, %514"
"  %17041 = mul nuw i32 %16710, %514" -> "  %17165 = and i32 %17041, 65535""  %17041 = mul nuw i32 %16710, %514" -> "  %17042 = lshr i32 %17041, 16"
"  %17042 = lshr i32 %17041, 16"
"  %17042 = lshr i32 %17041, 16" -> "  %17045 = add nuw nsw i32 %17044, %17042"
"  %17043 = mul nuw i32 %16713, %514"
"  %17043 = mul nuw i32 %16713, %514" -> "  %17046 = and i32 %17043, -65536""  %17043 = mul nuw i32 %16713, %514" -> "  %17044 = and i32 %17043, 65535"
"  %17044 = and i32 %17043, 65535"
"  %17044 = and i32 %17043, 65535" -> "  %17045 = add nuw nsw i32 %17044, %17042"
"  %17045 = add nuw nsw i32 %17044, %17042"
"  %17045 = add nuw nsw i32 %17044, %17042" -> "  %17047 = add nuw i32 %17045, %17046"
"  %17046 = and i32 %17043, -65536"
"  %17046 = and i32 %17043, -65536" -> "  %17047 = add nuw i32 %17045, %17046"
"  %17047 = add nuw i32 %17045, %17046"
"  %17047 = add nuw i32 %17045, %17046" -> "  %17051 = lshr i32 %17047, 16""  %17047 = add nuw i32 %17045, %17046" -> "  %17049 = and i32 %17047, 65535"
"  %17048 = mul nuw i32 %16710, %515"
"  %17048 = mul nuw i32 %16710, %515" -> "  %17050 = add nuw i32 %17049, %17048"
"  %17049 = and i32 %17047, 65535"
"  %17049 = and i32 %17047, 65535" -> "  %17050 = add nuw i32 %17049, %17048"
"  %17050 = add nuw i32 %17049, %17048"
"  %17050 = add nuw i32 %17049, %17048" -> "  %17168 = and i32 %17050, 65535""  %17050 = add nuw i32 %17049, %17048" -> "  %17054 = lshr i32 %17050, 16"
"  %17051 = lshr i32 %17047, 16"
"  %17051 = lshr i32 %17047, 16" -> "  %17053 = add nuw i32 %17051, %17052"
"  %17052 = mul nuw i32 %16713, %515"
"  %17052 = mul nuw i32 %16713, %515" -> "  %17053 = add nuw i32 %17051, %17052"
"  %17053 = add nuw i32 %17051, %17052"
"  %17053 = add nuw i32 %17051, %17052" -> "  %17057 = and i32 %17053, -65536""  %17053 = add nuw i32 %17051, %17052" -> "  %17055 = and i32 %17053, 65535"
"  %17054 = lshr i32 %17050, 16"
"  %17054 = lshr i32 %17050, 16" -> "  %17056 = add nuw nsw i32 %17054, %17055"
"  %17055 = and i32 %17053, 65535"
"  %17055 = and i32 %17053, 65535" -> "  %17056 = add nuw nsw i32 %17054, %17055"
"  %17056 = add nuw nsw i32 %17054, %17055"
"  %17056 = add nuw nsw i32 %17054, %17055" -> "  %17058 = add i32 %17056, %17057"
"  %17057 = and i32 %17053, -65536"
"  %17057 = and i32 %17053, -65536" -> "  %17058 = add i32 %17056, %17057"
"  %17058 = add i32 %17056, %17057"
"  %17058 = add i32 %17056, %17057" -> "  %17078 = lshr i32 %17058, 16""  %17058 = add i32 %17056, %17057" -> "  %17074 = and i32 %17058, 65535"
"  %17059 = mul nuw i32 %16730, %514"
"  %17059 = mul nuw i32 %16730, %514" -> "  %17075 = and i32 %17059, 65535""  %17059 = mul nuw i32 %16730, %514" -> "  %17060 = lshr i32 %17059, 16"
"  %17060 = lshr i32 %17059, 16"
"  %17060 = lshr i32 %17059, 16" -> "  %17062 = add nuw i32 %17060, %17061"
"  %17061 = mul nuw i32 %16733, %514"
"  %17061 = mul nuw i32 %16733, %514" -> "  %17062 = add nuw i32 %17060, %17061"
"  %17062 = add nuw i32 %17060, %17061"
"  %17062 = add nuw i32 %17060, %17061" -> "  %17066 = lshr i32 %17062, 16""  %17062 = add nuw i32 %17060, %17061" -> "  %17064 = and i32 %17062, 65535"
"  %17063 = mul nuw i32 %16730, %515"
"  %17063 = mul nuw i32 %16730, %515" -> "  %17065 = add nuw i32 %17064, %17063"
"  %17064 = and i32 %17062, 65535"
"  %17064 = and i32 %17062, 65535" -> "  %17065 = add nuw i32 %17064, %17063"
"  %17065 = add nuw i32 %17064, %17063"
"  %17065 = add nuw i32 %17064, %17063" -> "  %17077 = and i32 %17065, 65535""  %17065 = add nuw i32 %17064, %17063" -> "  %17069 = lshr i32 %17065, 16"
"  %17066 = lshr i32 %17062, 16"
"  %17066 = lshr i32 %17062, 16" -> "  %17068 = add nuw i32 %17066, %17067"
"  %17067 = mul nuw i32 %16733, %515"
"  %17067 = mul nuw i32 %16733, %515" -> "  %17068 = add nuw i32 %17066, %17067"
"  %17068 = add nuw i32 %17066, %17067"
"  %17068 = add nuw i32 %17066, %17067" -> "  %17072 = and i32 %17068, -65536""  %17068 = add nuw i32 %17066, %17067" -> "  %17070 = and i32 %17068, 65535"
"  %17069 = lshr i32 %17065, 16"
"  %17069 = lshr i32 %17065, 16" -> "  %17071 = add nuw nsw i32 %17069, %17070"
"  %17070 = and i32 %17068, 65535"
"  %17070 = and i32 %17068, 65535" -> "  %17071 = add nuw nsw i32 %17069, %17070"
"  %17071 = add nuw nsw i32 %17069, %17070"
"  %17071 = add nuw nsw i32 %17069, %17070" -> "  %17073 = add i32 %17071, %17072"
"  %17072 = and i32 %17068, -65536"
"  %17072 = and i32 %17068, -65536" -> "  %17073 = add i32 %17071, %17072"
"  %17073 = add i32 %17071, %17072"
"  %17073 = add i32 %17071, %17072" -> "  %17081 = add i32 %17073, %17080"
"  %17074 = and i32 %17058, 65535"
"  %17074 = and i32 %17058, 65535" -> "  %17076 = add nuw nsw i32 %17074, %17075"
"  %17075 = and i32 %17059, 65535"
"  %17075 = and i32 %17059, 65535" -> "  %17076 = add nuw nsw i32 %17074, %17075"
"  %17076 = add nuw nsw i32 %17074, %17075"
"  %17076 = add nuw nsw i32 %17074, %17075" -> "  %17105 = and i32 %17076, 65535""  %17076 = add nuw nsw i32 %17074, %17075" -> "  %17083 = lshr i32 %17076, 16"
"  %17077 = and i32 %17065, 65535"
"  %17077 = and i32 %17065, 65535" -> "  %17079 = add nuw nsw i32 %17077, %17078"
"  %17078 = lshr i32 %17058, 16"
"  %17078 = lshr i32 %17058, 16" -> "  %17079 = add nuw nsw i32 %17077, %17078"
"  %17079 = add nuw nsw i32 %17077, %17078"
"  %17079 = add nuw nsw i32 %17077, %17078" -> "  %17082 = and i32 %17079, 65535""  %17079 = add nuw nsw i32 %17077, %17078" -> "  %17080 = lshr i32 %17079, 16"
"  %17080 = lshr i32 %17079, 16"
"  %17080 = lshr i32 %17079, 16" -> "  %17081 = add i32 %17073, %17080"
"  %17081 = add i32 %17073, %17080"
"  %17081 = add i32 %17073, %17080" -> "  %17086 = add i32 %17081, %17085"
"  %17082 = and i32 %17079, 65535"
"  %17082 = and i32 %17079, 65535" -> "  %17084 = add nuw nsw i32 %17082, %17083"
"  %17083 = lshr i32 %17076, 16"
"  %17083 = lshr i32 %17076, 16" -> "  %17084 = add nuw nsw i32 %17082, %17083"
"  %17084 = add nuw nsw i32 %17082, %17083"
"  %17084 = add nuw nsw i32 %17082, %17083" -> "  %17108 = and i32 %17084, 65535""  %17084 = add nuw nsw i32 %17082, %17083" -> "  %17085 = lshr i32 %17084, 16"
"  %17085 = lshr i32 %17084, 16"
"  %17085 = lshr i32 %17084, 16" -> "  %17086 = add i32 %17081, %17085"
"  %17086 = add i32 %17081, %17085"
"  %17086 = add i32 %17081, %17085" -> "  %17140 = lshr i32 %17086, 16""  %17086 = add i32 %17081, %17085" -> "  %17136 = and i32 %17086, 65535"
"  %17087 = mul nuw i32 %16710, %546"
"  %17087 = mul nuw i32 %16710, %546" -> "  %17106 = and i32 %17087, 65535""  %17087 = mul nuw i32 %16710, %546" -> "  %17088 = lshr i32 %17087, 16"
"  %17088 = lshr i32 %17087, 16"
"  %17088 = lshr i32 %17087, 16" -> "  %17091 = add nuw nsw i32 %17090, %17088"
"  %17089 = mul nuw i32 %16713, %546"
"  %17089 = mul nuw i32 %16713, %546" -> "  %17092 = and i32 %17089, -65536""  %17089 = mul nuw i32 %16713, %546" -> "  %17090 = and i32 %17089, 65535"
"  %17090 = and i32 %17089, 65535"
"  %17090 = and i32 %17089, 65535" -> "  %17091 = add nuw nsw i32 %17090, %17088"
"  %17091 = add nuw nsw i32 %17090, %17088"
"  %17091 = add nuw nsw i32 %17090, %17088" -> "  %17093 = add nuw i32 %17091, %17092"
"  %17092 = and i32 %17089, -65536"
"  %17092 = and i32 %17089, -65536" -> "  %17093 = add nuw i32 %17091, %17092"
"  %17093 = add nuw i32 %17091, %17092"
"  %17093 = add nuw i32 %17091, %17092" -> "  %17097 = lshr i32 %17093, 16""  %17093 = add nuw i32 %17091, %17092" -> "  %17095 = and i32 %17093, 65535"
"  %17094 = mul nuw i32 %16710, %549"
"  %17094 = mul nuw i32 %16710, %549" -> "  %17096 = add nuw i32 %17095, %17094"
"  %17095 = and i32 %17093, 65535"
"  %17095 = and i32 %17093, 65535" -> "  %17096 = add nuw i32 %17095, %17094"
"  %17096 = add nuw i32 %17095, %17094"
"  %17096 = add nuw i32 %17095, %17094" -> "  %17109 = and i32 %17096, 65535""  %17096 = add nuw i32 %17095, %17094" -> "  %17100 = lshr i32 %17096, 16"
"  %17097 = lshr i32 %17093, 16"
"  %17097 = lshr i32 %17093, 16" -> "  %17099 = add nuw i32 %17097, %17098"
"  %17098 = mul nuw i32 %16713, %549"
"  %17098 = mul nuw i32 %16713, %549" -> "  %17099 = add nuw i32 %17097, %17098"
"  %17099 = add nuw i32 %17097, %17098"
"  %17099 = add nuw i32 %17097, %17098" -> "  %17103 = and i32 %17099, -65536""  %17099 = add nuw i32 %17097, %17098" -> "  %17101 = and i32 %17099, 65535"
"  %17100 = lshr i32 %17096, 16"
"  %17100 = lshr i32 %17096, 16" -> "  %17102 = add nuw nsw i32 %17100, %17101"
"  %17101 = and i32 %17099, 65535"
"  %17101 = and i32 %17099, 65535" -> "  %17102 = add nuw nsw i32 %17100, %17101"
"  %17102 = add nuw nsw i32 %17100, %17101"
"  %17102 = add nuw nsw i32 %17100, %17101" -> "  %17104 = add i32 %17102, %17103"
"  %17103 = and i32 %17099, -65536"
"  %17103 = and i32 %17099, -65536" -> "  %17104 = add i32 %17102, %17103"
"  %17104 = add i32 %17102, %17103"
"  %17104 = add i32 %17102, %17103" -> "  %17112 = add i32 %17104, %17111"
"  %17105 = and i32 %17076, 65535"
"  %17105 = and i32 %17076, 65535" -> "  %17107 = add nuw nsw i32 %17105, %17106"
"  %17106 = and i32 %17087, 65535"
"  %17106 = and i32 %17087, 65535" -> "  %17107 = add nuw nsw i32 %17105, %17106"
"  %17107 = add nuw nsw i32 %17105, %17106"
"  %17107 = add nuw nsw i32 %17105, %17106" -> "  %17174 = and i32 %17107, 65535""  %17107 = add nuw nsw i32 %17105, %17106" -> "  %17114 = lshr i32 %17107, 16"
"  %17108 = and i32 %17084, 65535"
"  %17108 = and i32 %17084, 65535" -> "  %17110 = add nuw nsw i32 %17108, %17109"
"  %17109 = and i32 %17096, 65535"
"  %17109 = and i32 %17096, 65535" -> "  %17110 = add nuw nsw i32 %17108, %17109"
"  %17110 = add nuw nsw i32 %17108, %17109"
"  %17110 = add nuw nsw i32 %17108, %17109" -> "  %17113 = and i32 %17110, 65535""  %17110 = add nuw nsw i32 %17108, %17109" -> "  %17111 = lshr i32 %17110, 16"
"  %17111 = lshr i32 %17110, 16"
"  %17111 = lshr i32 %17110, 16" -> "  %17112 = add i32 %17104, %17111"
"  %17112 = add i32 %17104, %17111"
"  %17112 = add i32 %17104, %17111" -> "  %17117 = add i32 %17112, %17116"
"  %17113 = and i32 %17110, 65535"
"  %17113 = and i32 %17110, 65535" -> "  %17115 = add nuw nsw i32 %17113, %17114"
"  %17114 = lshr i32 %17107, 16"
"  %17114 = lshr i32 %17107, 16" -> "  %17115 = add nuw nsw i32 %17113, %17114"
"  %17115 = add nuw nsw i32 %17113, %17114"
"  %17115 = add nuw nsw i32 %17113, %17114" -> "  %17177 = and i32 %17115, 65535""  %17115 = add nuw nsw i32 %17113, %17114" -> "  %17116 = lshr i32 %17115, 16"
"  %17116 = lshr i32 %17115, 16"
"  %17116 = lshr i32 %17115, 16" -> "  %17117 = add i32 %17112, %17116"
"  %17117 = add i32 %17112, %17116"
"  %17117 = add i32 %17112, %17116" -> "  %17153 = lshr i32 %17117, 16""  %17117 = add i32 %17112, %17116" -> "  %17150 = and i32 %17117, 65535"
"  %17118 = mul nuw i32 %16730, %546"
"  %17118 = mul nuw i32 %16730, %546" -> "  %17137 = and i32 %17118, 65535""  %17118 = mul nuw i32 %16730, %546" -> "  %17119 = lshr i32 %17118, 16"
"  %17119 = lshr i32 %17118, 16"
"  %17119 = lshr i32 %17118, 16" -> "  %17122 = add nuw nsw i32 %17119, %17121"
"  %17120 = mul nuw i32 %16733, %546"
"  %17120 = mul nuw i32 %16733, %546" -> "  %17123 = and i32 %17120, -65536""  %17120 = mul nuw i32 %16733, %546" -> "  %17121 = and i32 %17120, 65535"
"  %17121 = and i32 %17120, 65535"
"  %17121 = and i32 %17120, 65535" -> "  %17122 = add nuw nsw i32 %17119, %17121"
"  %17122 = add nuw nsw i32 %17119, %17121"
"  %17122 = add nuw nsw i32 %17119, %17121" -> "  %17124 = add nuw i32 %17122, %17123"
"  %17123 = and i32 %17120, -65536"
"  %17123 = and i32 %17120, -65536" -> "  %17124 = add nuw i32 %17122, %17123"
"  %17124 = add nuw i32 %17122, %17123"
"  %17124 = add nuw i32 %17122, %17123" -> "  %17129 = lshr i32 %17124, 16""  %17124 = add nuw i32 %17122, %17123" -> "  %17126 = and i32 %17124, 65535"
"  %17125 = mul nuw i32 %16730, %549"
"  %17125 = mul nuw i32 %16730, %549" -> "  %17127 = add nuw i32 %17126, %17125"
"  %17126 = and i32 %17124, 65535"
"  %17126 = and i32 %17124, 65535" -> "  %17127 = add nuw i32 %17126, %17125"
"  %17127 = add nuw i32 %17126, %17125"
"  %17127 = add nuw i32 %17126, %17125" -> "  %17139 = and i32 %17127, 65535""  %17127 = add nuw i32 %17126, %17125" -> "  %17131 = lshr i32 %17127, 16"
"  %17128 = mul nuw i32 %16733, %549"
"  %17128 = mul nuw i32 %16733, %549" -> "  %17130 = add nuw i32 %17129, %17128"
"  %17129 = lshr i32 %17124, 16"
"  %17129 = lshr i32 %17124, 16" -> "  %17130 = add nuw i32 %17129, %17128"
"  %17130 = add nuw i32 %17129, %17128"
"  %17130 = add nuw i32 %17129, %17128" -> "  %17134 = and i32 %17130, -65536""  %17130 = add nuw i32 %17129, %17128" -> "  %17132 = and i32 %17130, 65535"
"  %17131 = lshr i32 %17127, 16"
"  %17131 = lshr i32 %17127, 16" -> "  %17133 = add nuw nsw i32 %17131, %17132"
"  %17132 = and i32 %17130, 65535"
"  %17132 = and i32 %17130, 65535" -> "  %17133 = add nuw nsw i32 %17131, %17132"
"  %17133 = add nuw nsw i32 %17131, %17132"
"  %17133 = add nuw nsw i32 %17131, %17132" -> "  %17135 = add i32 %17133, %17134"
"  %17134 = and i32 %17130, -65536"
"  %17134 = and i32 %17130, -65536" -> "  %17135 = add i32 %17133, %17134"
"  %17135 = add i32 %17133, %17134"
"  %17135 = add i32 %17133, %17134" -> "  %17143 = add i32 %17135, %17142"
"  %17136 = and i32 %17086, 65535"
"  %17136 = and i32 %17086, 65535" -> "  %17138 = add nuw nsw i32 %17136, %17137"
"  %17137 = and i32 %17118, 65535"
"  %17137 = and i32 %17118, 65535" -> "  %17138 = add nuw nsw i32 %17136, %17137"
"  %17138 = add nuw nsw i32 %17136, %17137"
"  %17138 = add nuw nsw i32 %17136, %17137" -> "  %17149 = and i32 %17138, 65535""  %17138 = add nuw nsw i32 %17136, %17137" -> "  %17145 = lshr i32 %17138, 16"
"  %17139 = and i32 %17127, 65535"
"  %17139 = and i32 %17127, 65535" -> "  %17141 = add nuw nsw i32 %17140, %17139"
"  %17140 = lshr i32 %17086, 16"
"  %17140 = lshr i32 %17086, 16" -> "  %17141 = add nuw nsw i32 %17140, %17139"
"  %17141 = add nuw nsw i32 %17140, %17139"
"  %17141 = add nuw nsw i32 %17140, %17139" -> "  %17144 = and i32 %17141, 65535""  %17141 = add nuw nsw i32 %17140, %17139" -> "  %17142 = lshr i32 %17141, 16"
"  %17142 = lshr i32 %17141, 16"
"  %17142 = lshr i32 %17141, 16" -> "  %17143 = add i32 %17135, %17142"
"  %17143 = add i32 %17135, %17142"
"  %17143 = add i32 %17135, %17142" -> "  %17148 = add i32 %17143, %17147"
"  %17144 = and i32 %17141, 65535"
"  %17144 = and i32 %17141, 65535" -> "  %17146 = add nuw nsw i32 %17144, %17145"
"  %17145 = lshr i32 %17138, 16"
"  %17145 = lshr i32 %17138, 16" -> "  %17146 = add nuw nsw i32 %17144, %17145"
"  %17146 = add nuw nsw i32 %17144, %17145"
"  %17146 = add nuw nsw i32 %17144, %17145" -> "  %17152 = and i32 %17146, 65535""  %17146 = add nuw nsw i32 %17144, %17145" -> "  %17147 = lshr i32 %17146, 16"
"  %17147 = lshr i32 %17146, 16"
"  %17147 = lshr i32 %17146, 16" -> "  %17148 = add i32 %17143, %17147"
"  %17148 = add i32 %17143, %17147"
"  %17148 = add i32 %17143, %17147" -> "  %17161 = and i32 %17148, -65536""  %17148 = add i32 %17143, %17147" -> "  %17159 = and i32 %17148, 65535"
"  %17149 = and i32 %17138, 65535"
"  %17149 = and i32 %17138, 65535" -> "  %17151 = add nuw nsw i32 %17150, %17149"
"  %17150 = and i32 %17117, 65535"
"  %17150 = and i32 %17117, 65535" -> "  %17151 = add nuw nsw i32 %17150, %17149"
"  %17151 = add nuw nsw i32 %17150, %17149"
"  %17151 = add nuw nsw i32 %17150, %17149" -> "  %17192 = and i32 %17151, 65535""  %17151 = add nuw nsw i32 %17150, %17149" -> "  %17155 = lshr i32 %17151, 16"
"  %17152 = and i32 %17146, 65535"
"  %17152 = and i32 %17146, 65535" -> "  %17154 = add nuw nsw i32 %17152, %17153"
"  %17153 = lshr i32 %17117, 16"
"  %17153 = lshr i32 %17117, 16" -> "  %17154 = add nuw nsw i32 %17152, %17153"
"  %17154 = add nuw nsw i32 %17152, %17153"
"  %17154 = add nuw nsw i32 %17152, %17153" -> "  %17158 = lshr i32 %17154, 16""  %17154 = add nuw nsw i32 %17152, %17153" -> "  %17156 = and i32 %17154, 65535"
"  %17155 = lshr i32 %17151, 16"
"  %17155 = lshr i32 %17151, 16" -> "  %17157 = add nuw nsw i32 %17156, %17155"
"  %17156 = and i32 %17154, 65535"
"  %17156 = and i32 %17154, 65535" -> "  %17157 = add nuw nsw i32 %17156, %17155"
"  %17157 = add nuw nsw i32 %17156, %17155"
"  %17157 = add nuw nsw i32 %17156, %17155" -> "  %17199 = and i32 %17157, 65535""  %17157 = add nuw nsw i32 %17156, %17155" -> "  %17163 = lshr i32 %17157, 16"
"  %17158 = lshr i32 %17154, 16"
"  %17158 = lshr i32 %17154, 16" -> "  %17160 = add nuw nsw i32 %17158, %17159"
"  %17159 = and i32 %17148, 65535"
"  %17159 = and i32 %17148, 65535" -> "  %17160 = add nuw nsw i32 %17158, %17159"
"  %17160 = add nuw nsw i32 %17158, %17159"
"  %17160 = add nuw nsw i32 %17158, %17159" -> "  %17162 = add i32 %17160, %17161"
"  %17161 = and i32 %17148, -65536"
"  %17161 = and i32 %17148, -65536" -> "  %17162 = add i32 %17160, %17161"
"  %17162 = add i32 %17160, %17161"
"  %17162 = add i32 %17160, %17161" -> "  %17164 = add i32 %17162, %17163"
"  %17163 = lshr i32 %17157, 16"
"  %17163 = lshr i32 %17157, 16" -> "  %17164 = add i32 %17162, %17163"
"  %17164 = add i32 %17162, %17163"
"  %17164 = add i32 %17162, %17163" -> "  %17202 = add i32 %17164, %17201"
"  %17165 = and i32 %17041, 65535"
"  %17165 = and i32 %17041, 65535" -> "  %17167 = add nuw nsw i32 %17166, %17165"
"  %17166 = and i32 %16870, 65535"
"  %17166 = and i32 %16870, 65535" -> "  %17167 = add nuw nsw i32 %17166, %17165"
"  %17167 = add nuw nsw i32 %17166, %17165"
"  %17167 = add nuw nsw i32 %17166, %17165" -> "  %17203 = and i32 %17167, 65535""  %17167 = add nuw nsw i32 %17166, %17165" -> "  %17171 = lshr i32 %17167, 16"
"  %17168 = and i32 %17050, 65535"
"  %17168 = and i32 %17050, 65535" -> "  %17170 = add nuw nsw i32 %17169, %17168"
"  %17169 = and i32 %16873, 65535"
"  %17169 = and i32 %16873, 65535" -> "  %17170 = add nuw nsw i32 %17169, %17168"
"  %17170 = add nuw nsw i32 %17169, %17168"
"  %17170 = add nuw nsw i32 %17169, %17168" -> "  %17183 = lshr i32 %17170, 16""  %17170 = add nuw nsw i32 %17169, %17168" -> "  %17172 = and i32 %17170, 65535"
"  %17171 = lshr i32 %17167, 16"
"  %17171 = lshr i32 %17167, 16" -> "  %17173 = add nuw nsw i32 %17172, %17171"
"  %17172 = and i32 %17170, 65535"
"  %17172 = and i32 %17170, 65535" -> "  %17173 = add nuw nsw i32 %17172, %17171"
"  %17173 = add nuw nsw i32 %17172, %17171"
"  %17173 = add nuw nsw i32 %17172, %17171" -> "  %17206 = and i32 %17173, 65535""  %17173 = add nuw nsw i32 %17172, %17171" -> "  %17185 = lshr i32 %17173, 16"
"  %17174 = and i32 %17107, 65535"
"  %17174 = and i32 %17107, 65535" -> "  %17176 = add nuw nsw i32 %17175, %17174"
"  %17175 = and i32 %16875, 65535"
"  %17175 = and i32 %16875, 65535" -> "  %17176 = add nuw nsw i32 %17175, %17174"
"  %17176 = add nuw nsw i32 %17175, %17174"
"  %17176 = add nuw nsw i32 %17175, %17174" -> "  %17184 = and i32 %17176, 65535""  %17176 = add nuw nsw i32 %17175, %17174" -> "  %17180 = lshr i32 %17176, 16"
"  %17177 = and i32 %17115, 65535"
"  %17177 = and i32 %17115, 65535" -> "  %17179 = add nuw nsw i32 %17178, %17177"
"  %17178 = lshr i32 %16875, 16"
"  %17178 = lshr i32 %16875, 16" -> "  %17179 = add nuw nsw i32 %17178, %17177"
"  %17179 = add nuw nsw i32 %17178, %17177"
"  %17179 = add nuw nsw i32 %17178, %17177" -> "  %17191 = lshr i32 %17179, 16""  %17179 = add nuw nsw i32 %17178, %17177" -> "  %17181 = and i32 %17179, 65535"
"  %17180 = lshr i32 %17176, 16"
"  %17180 = lshr i32 %17176, 16" -> "  %17182 = add nuw nsw i32 %17180, %17181"
"  %17181 = and i32 %17179, 65535"
"  %17181 = and i32 %17179, 65535" -> "  %17182 = add nuw nsw i32 %17180, %17181"
"  %17182 = add nuw nsw i32 %17180, %17181"
"  %17182 = add nuw nsw i32 %17180, %17181" -> "  %17193 = lshr i32 %17182, 16""  %17182 = add nuw nsw i32 %17180, %17181" -> "  %17189 = and i32 %17182, 65535"
"  %17183 = lshr i32 %17170, 16"
"  %17183 = lshr i32 %17170, 16" -> "  %17186 = add nuw nsw i32 %17185, %17183"
"  %17184 = and i32 %17176, 65535"
"  %17184 = and i32 %17176, 65535" -> "  %17187 = add nuw nsw i32 %17186, %17184"
"  %17185 = lshr i32 %17173, 16"
"  %17185 = lshr i32 %17173, 16" -> "  %17186 = add nuw nsw i32 %17185, %17183"
"  %17186 = add nuw nsw i32 %17185, %17183"
"  %17186 = add nuw nsw i32 %17185, %17183" -> "  %17187 = add nuw nsw i32 %17186, %17184"
"  %17187 = add nuw nsw i32 %17186, %17184"
"  %17187 = add nuw nsw i32 %17186, %17184" -> "  %17212 = and i32 %17187, 65535""  %17187 = add nuw nsw i32 %17186, %17184" -> "  %17188 = lshr i32 %17187, 16"
"  %17188 = lshr i32 %17187, 16"
"  %17188 = lshr i32 %17187, 16" -> "  %17190 = add nuw nsw i32 %17188, %17189"
"  %17189 = and i32 %17182, 65535"
"  %17189 = and i32 %17182, 65535" -> "  %17190 = add nuw nsw i32 %17188, %17189"
"  %17190 = add nuw nsw i32 %17188, %17189"
"  %17190 = add nuw nsw i32 %17188, %17189" -> "  %17215 = and i32 %17190, 65535""  %17190 = add nuw nsw i32 %17188, %17189" -> "  %17194 = lshr i32 %17190, 16"
"  %17191 = lshr i32 %17179, 16"
"  %17191 = lshr i32 %17179, 16" -> "  %17195 = add nuw nsw i32 %17191, %17192"
"  %17192 = and i32 %17151, 65535"
"  %17192 = and i32 %17151, 65535" -> "  %17195 = add nuw nsw i32 %17191, %17192"
"  %17193 = lshr i32 %17182, 16"
"  %17193 = lshr i32 %17182, 16" -> "  %17196 = add nuw nsw i32 %17195, %17193"
"  %17194 = lshr i32 %17190, 16"
"  %17194 = lshr i32 %17190, 16" -> "  %17197 = add nuw nsw i32 %17196, %17194"
"  %17195 = add nuw nsw i32 %17191, %17192"
"  %17195 = add nuw nsw i32 %17191, %17192" -> "  %17196 = add nuw nsw i32 %17195, %17193"
"  %17196 = add nuw nsw i32 %17195, %17193"
"  %17196 = add nuw nsw i32 %17195, %17193" -> "  %17197 = add nuw nsw i32 %17196, %17194"
"  %17197 = add nuw nsw i32 %17196, %17194"
"  %17197 = add nuw nsw i32 %17196, %17194" -> "  %17229 = and i32 %17197, 65535""  %17197 = add nuw nsw i32 %17196, %17194" -> "  %17198 = lshr i32 %17197, 16"
"  %17198 = lshr i32 %17197, 16"
"  %17198 = lshr i32 %17197, 16" -> "  %17200 = add nuw nsw i32 %17198, %17199"
"  %17199 = and i32 %17157, 65535"
"  %17199 = and i32 %17157, 65535" -> "  %17200 = add nuw nsw i32 %17198, %17199"
"  %17200 = add nuw nsw i32 %17198, %17199"
"  %17200 = add nuw nsw i32 %17198, %17199" -> "  %17236 = and i32 %17200, 65535""  %17200 = add nuw nsw i32 %17198, %17199" -> "  %17201 = lshr i32 %17200, 16"
"  %17201 = lshr i32 %17200, 16"
"  %17201 = lshr i32 %17200, 16" -> "  %17202 = add i32 %17164, %17201"
"  %17202 = add i32 %17164, %17201"
"  %17202 = add i32 %17164, %17201" -> "  %17240 = add i32 %17202, %17239"
"  %17203 = and i32 %17167, 65535"
"  %17203 = and i32 %17167, 65535" -> "  %17205 = add nuw nsw i32 %17204, %17203"
"  %17204 = and i32 %17035, 65535"
"  %17204 = and i32 %17035, 65535" -> "  %17205 = add nuw nsw i32 %17204, %17203"
"  %17205 = add nuw nsw i32 %17204, %17203"
"  %17205 = add nuw nsw i32 %17204, %17203" -> "  %17915 = and i32 %17205, 65535""  %17205 = add nuw nsw i32 %17204, %17203" -> "  %17209 = lshr i32 %17205, 16"
"  %17206 = and i32 %17173, 65535"
"  %17206 = and i32 %17173, 65535" -> "  %17208 = add nuw nsw i32 %17207, %17206"
"  %17207 = and i32 %17038, 65535"
"  %17207 = and i32 %17038, 65535" -> "  %17208 = add nuw nsw i32 %17207, %17206"
"  %17208 = add nuw nsw i32 %17207, %17206"
"  %17208 = add nuw nsw i32 %17207, %17206" -> "  %17222 = lshr i32 %17208, 16""  %17208 = add nuw nsw i32 %17207, %17206" -> "  %17210 = and i32 %17208, 65535"
"  %17209 = lshr i32 %17205, 16"
"  %17209 = lshr i32 %17205, 16" -> "  %17211 = add nuw nsw i32 %17210, %17209"
"  %17210 = and i32 %17208, 65535"
"  %17210 = and i32 %17208, 65535" -> "  %17211 = add nuw nsw i32 %17210, %17209"
"  %17211 = add nuw nsw i32 %17210, %17209"
"  %17211 = add nuw nsw i32 %17210, %17209" -> "  %17918 = and i32 %17211, 65535""  %17211 = add nuw nsw i32 %17210, %17209" -> "  %17224 = lshr i32 %17211, 16"
"  %17212 = and i32 %17187, 65535"
"  %17212 = and i32 %17187, 65535" -> "  %17214 = add nuw nsw i32 %17213, %17212"
"  %17213 = and i32 %17040, 65535"
"  %17213 = and i32 %17040, 65535" -> "  %17214 = add nuw nsw i32 %17213, %17212"
"  %17214 = add nuw nsw i32 %17213, %17212"
"  %17214 = add nuw nsw i32 %17213, %17212" -> "  %17221 = and i32 %17214, 65535""  %17214 = add nuw nsw i32 %17213, %17212" -> "  %17218 = lshr i32 %17214, 16"
"  %17215 = and i32 %17190, 65535"
"  %17215 = and i32 %17190, 65535" -> "  %17217 = add nuw nsw i32 %17215, %17216"
"  %17216 = lshr i32 %17040, 16"
"  %17216 = lshr i32 %17040, 16" -> "  %17217 = add nuw nsw i32 %17215, %17216"
"  %17217 = add nuw nsw i32 %17215, %17216"
"  %17217 = add nuw nsw i32 %17215, %17216" -> "  %17230 = lshr i32 %17217, 16""  %17217 = add nuw nsw i32 %17215, %17216" -> "  %17219 = and i32 %17217, 65535"
"  %17218 = lshr i32 %17214, 16"
"  %17218 = lshr i32 %17214, 16" -> "  %17220 = add nuw nsw i32 %17219, %17218"
"  %17219 = and i32 %17217, 65535"
"  %17219 = and i32 %17217, 65535" -> "  %17220 = add nuw nsw i32 %17219, %17218"
"  %17220 = add nuw nsw i32 %17219, %17218"
"  %17220 = add nuw nsw i32 %17219, %17218" -> "  %17232 = lshr i32 %17220, 16""  %17220 = add nuw nsw i32 %17219, %17218" -> "  %17227 = and i32 %17220, 65535"
"  %17221 = and i32 %17214, 65535"
"  %17221 = and i32 %17214, 65535" -> "  %17223 = add nuw nsw i32 %17221, %17222"
"  %17222 = lshr i32 %17208, 16"
"  %17222 = lshr i32 %17208, 16" -> "  %17223 = add nuw nsw i32 %17221, %17222"
"  %17223 = add nuw nsw i32 %17221, %17222"
"  %17223 = add nuw nsw i32 %17221, %17222" -> "  %17225 = add nuw nsw i32 %17223, %17224"
"  %17224 = lshr i32 %17211, 16"
"  %17224 = lshr i32 %17211, 16" -> "  %17225 = add nuw nsw i32 %17223, %17224"
"  %17225 = add nuw nsw i32 %17223, %17224"
"  %17225 = add nuw nsw i32 %17223, %17224" -> "  %17935 = and i32 %17225, 65535""  %17225 = add nuw nsw i32 %17223, %17224" -> "  %17226 = lshr i32 %17225, 16"
"  %17226 = lshr i32 %17225, 16"
"  %17226 = lshr i32 %17225, 16" -> "  %17228 = add nuw nsw i32 %17226, %17227"
"  %17227 = and i32 %17220, 65535"
"  %17227 = and i32 %17220, 65535" -> "  %17228 = add nuw nsw i32 %17226, %17227"
"  %17228 = add nuw nsw i32 %17226, %17227"
"  %17228 = add nuw nsw i32 %17226, %17227" -> "  %17938 = and i32 %17228, 65535""  %17228 = add nuw nsw i32 %17226, %17227" -> "  %17234 = lshr i32 %17228, 16"
"  %17229 = and i32 %17197, 65535"
"  %17229 = and i32 %17197, 65535" -> "  %17231 = add nuw nsw i32 %17230, %17229"
"  %17230 = lshr i32 %17217, 16"
"  %17230 = lshr i32 %17217, 16" -> "  %17231 = add nuw nsw i32 %17230, %17229"
"  %17231 = add nuw nsw i32 %17230, %17229"
"  %17231 = add nuw nsw i32 %17230, %17229" -> "  %17233 = add nuw nsw i32 %17231, %17232"
"  %17232 = lshr i32 %17220, 16"
"  %17232 = lshr i32 %17220, 16" -> "  %17233 = add nuw nsw i32 %17231, %17232"
"  %17233 = add nuw nsw i32 %17231, %17232"
"  %17233 = add nuw nsw i32 %17231, %17232" -> "  %17235 = add nuw nsw i32 %17233, %17234"
"  %17234 = lshr i32 %17228, 16"
"  %17234 = lshr i32 %17228, 16" -> "  %17235 = add nuw nsw i32 %17233, %17234"
"  %17235 = add nuw nsw i32 %17233, %17234"
"  %17235 = add nuw nsw i32 %17233, %17234" -> "  %18049 = and i32 %17235, 65535""  %17235 = add nuw nsw i32 %17233, %17234" -> "  %17237 = lshr i32 %17235, 16"
"  %17236 = and i32 %17200, 65535"
"  %17236 = and i32 %17200, 65535" -> "  %17238 = add nuw nsw i32 %17237, %17236"
"  %17237 = lshr i32 %17235, 16"
"  %17237 = lshr i32 %17235, 16" -> "  %17238 = add nuw nsw i32 %17237, %17236"
"  %17238 = add nuw nsw i32 %17237, %17236"
"  %17238 = add nuw nsw i32 %17237, %17236" -> "  %18050 = and i32 %17238, 65535""  %17238 = add nuw nsw i32 %17237, %17236" -> "  %17239 = lshr i32 %17238, 16"
"  %17239 = lshr i32 %17238, 16"
"  %17239 = lshr i32 %17238, 16" -> "  %17240 = add i32 %17202, %17239"
"  %17240 = add i32 %17202, %17239"
"  %17240 = add i32 %17202, %17239" -> "  %18069 = and i32 %17240, 65535""  %17240 = add i32 %17202, %17239" -> "  %18070 = lshr i32 %17240, 16"
"  %17241 = and i32 %16581, 65535"
"  %17241 = and i32 %16581, 65535" -> "  %20588 = add nuw nsw i32 %20587, %17241""  %17241 = and i32 %16581, 65535" -> "  %18960 = mul nuw nsw i32 %17241, 4087""  %17241 = and i32 %16581, 65535" -> "  %18967 = mul nuw nsw i32 %17241, 11561""  %17241 = and i32 %16581, 65535" -> "  %19009 = mul nuw nsw i32 %17241, 21884""  %17241 = and i32 %16581, 65535" -> "  %19016 = mul nuw i32 %17241, 36786""  %17241 = and i32 %16581, 65535" -> "  %18671 = mul nuw i32 %17241, 42779""  %17241 = and i32 %16581, 65535" -> "  %18678 = mul nuw nsw i32 %17241, 9871""  %17241 = and i32 %16581, 65535" -> "  %18720 = mul nuw nsw i32 %17241, 24315""  %17241 = and i32 %16581, 65535" -> "  %18727 = mul nuw nsw i32 %17241, 29744""  %17241 = and i32 %16581, 65535" -> "  %17547 = mul nuw nsw i32 %17241, 17857""  %17241 = and i32 %16581, 65535" -> "  %17554 = mul nuw i32 %17241, 46547""  %17241 = and i32 %16581, 65535" -> "  %17596 = mul nuw nsw i32 %17241, 31112""  %17241 = and i32 %16581, 65535" -> "  %17603 = mul nuw i32 %17241, 42170""  %17241 = and i32 %16581, 65535" -> "  %17304 = mul nuw i32 %17241, 62728""  %17241 = and i32 %16581, 65535" -> "  store i32 %17241, i32* %153, align 1, !noalias !44""  %17241 = and i32 %16581, 65535" -> "  %17250 = mul nuw i32 %17241, 45147""  %17241 = and i32 %16581, 65535" -> "  %17242 = mul nuw i32 %17241, 37996""  %17241 = and i32 %16581, 65535" -> "  %17297 = mul nuw nsw i32 %17241, 1324"
"  %17242 = mul nuw i32 %17241, 37996"
"  %17242 = mul nuw i32 %17241, 37996" -> "  %17243 = lshr i32 %17242, 16"
"  %17243 = lshr i32 %17242, 16"
"  %17243 = lshr i32 %17242, 16" -> "  %17247 = add nuw nsw i32 %17246, %17243"
"  %17244 = and i32 %16590, 65535"
"  %17244 = and i32 %16590, 65535" -> "  %20590 = add nuw nsw i32 %20589, %17244""  %17244 = and i32 %16590, 65535" -> "  %17245 = mul nuw i32 %17244, 37996""  %17244 = and i32 %16590, 65535" -> "  %17254 = mul nuw i32 %17244, 45147""  %17244 = and i32 %16590, 65535" -> "  store i32 %17244, i32* %162, align 1, !noalias !44""  %17244 = and i32 %16590, 65535" -> "  %17299 = mul nuw nsw i32 %17244, 1324""  %17244 = and i32 %16590, 65535" -> "  %17308 = mul nuw i32 %17244, 62728""  %17244 = and i32 %16590, 65535" -> "  %17607 = mul nuw i32 %17244, 42170""  %17244 = and i32 %16590, 65535" -> "  %17598 = mul nuw nsw i32 %17244, 31112""  %17244 = and i32 %16590, 65535" -> "  %17558 = mul nuw i32 %17244, 46547""  %17244 = and i32 %16590, 65535" -> "  %17549 = mul nuw nsw i32 %17244, 17857""  %17244 = and i32 %16590, 65535" -> "  %18731 = mul nuw nsw i32 %17244, 29744""  %17244 = and i32 %16590, 65535" -> "  %18722 = mul nuw nsw i32 %17244, 24315""  %17244 = and i32 %16590, 65535" -> "  %18682 = mul nuw nsw i32 %17244, 9871""  %17244 = and i32 %16590, 65535" -> "  %18673 = mul nuw i32 %17244, 42779""  %17244 = and i32 %16590, 65535" -> "  %19020 = mul nuw i32 %17244, 36786""  %17244 = and i32 %16590, 65535" -> "  %19011 = mul nuw nsw i32 %17244, 21884""  %17244 = and i32 %16590, 65535" -> "  %18971 = mul nuw nsw i32 %17244, 11561""  %17244 = and i32 %16590, 65535" -> "  %18962 = mul nuw nsw i32 %17244, 4087"
"  %17245 = mul nuw i32 %17244, 37996"
"  %17245 = mul nuw i32 %17244, 37996" -> "  %17248 = and i32 %17245, -65536""  %17245 = mul nuw i32 %17244, 37996" -> "  %17246 = and i32 %17245, 65532"
"  %17246 = and i32 %17245, 65532"
"  %17246 = and i32 %17245, 65532" -> "  %17247 = add nuw nsw i32 %17246, %17243"
"  %17247 = add nuw nsw i32 %17246, %17243"
"  %17247 = add nuw nsw i32 %17246, %17243" -> "  %17249 = add nuw i32 %17247, %17248"
"  %17248 = and i32 %17245, -65536"
"  %17248 = and i32 %17245, -65536" -> "  %17249 = add nuw i32 %17247, %17248"
"  %17249 = add nuw i32 %17247, %17248"
"  %17249 = add nuw i32 %17247, %17248" -> "  %17253 = lshr i32 %17249, 16""  %17249 = add nuw i32 %17247, %17248" -> "  %17251 = and i32 %17249, 65535"
"  %17250 = mul nuw i32 %17241, 45147"
"  %17250 = mul nuw i32 %17241, 45147" -> "  %17252 = add nuw i32 %17251, %17250"
"  %17251 = and i32 %17249, 65535"
"  %17251 = and i32 %17249, 65535" -> "  %17252 = add nuw i32 %17251, %17250"
"  %17252 = add nuw i32 %17251, %17250"
"  %17252 = add nuw i32 %17251, %17250" -> "  %17256 = lshr i32 %17252, 16"
"  %17253 = lshr i32 %17249, 16"
"  %17253 = lshr i32 %17249, 16" -> "  %17255 = add nuw i32 %17253, %17254"
"  %17254 = mul nuw i32 %17244, 45147"
"  %17254 = mul nuw i32 %17244, 45147" -> "  %17255 = add nuw i32 %17253, %17254"
"  %17255 = add nuw i32 %17253, %17254"
"  %17255 = add nuw i32 %17253, %17254" -> "  %17259 = and i32 %17255, -65536""  %17255 = add nuw i32 %17253, %17254" -> "  %17257 = and i32 %17255, 65535"
"  %17256 = lshr i32 %17252, 16"
"  %17256 = lshr i32 %17252, 16" -> "  %17258 = add nuw nsw i32 %17256, %17257"
"  %17257 = and i32 %17255, 65535"
"  %17257 = and i32 %17255, 65535" -> "  %17258 = add nuw nsw i32 %17256, %17257"
"  %17258 = add nuw nsw i32 %17256, %17257"
"  %17258 = add nuw nsw i32 %17256, %17257" -> "  %17260 = add nuw i32 %17258, %17259"
"  %17259 = and i32 %17255, -65536"
"  %17259 = and i32 %17255, -65536" -> "  %17260 = add nuw i32 %17258, %17259"
"  %17260 = add nuw i32 %17258, %17259"
"  %17260 = add nuw i32 %17258, %17259" -> "  %17285 = lshr i32 %17260, 16""  %17260 = add nuw i32 %17258, %17259" -> "  %17281 = and i32 %17260, 65535"
"  %17261 = and i32 %16652, 65535"
"  %17261 = and i32 %16652, 65535" -> "  %18978 = mul nuw nsw i32 %17261, 4087""  %17261 = and i32 %16652, 65535" -> "  %18985 = mul nuw nsw i32 %17261, 11561""  %17261 = and i32 %16652, 65535" -> "  %19040 = mul nuw nsw i32 %17261, 21884""  %17261 = and i32 %16652, 65535" -> "  %19047 = mul nuw i32 %17261, 36786""  %17261 = and i32 %16652, 65535" -> "  %18689 = mul nuw i32 %17261, 42779""  %17261 = and i32 %16652, 65535" -> "  %18696 = mul nuw nsw i32 %17261, 9871""  %17261 = and i32 %16652, 65535" -> "  %18751 = mul nuw nsw i32 %17261, 24315""  %17261 = and i32 %16652, 65535" -> "  %18758 = mul nuw nsw i32 %17261, 29744""  %17261 = and i32 %16652, 65535" -> "  %17565 = mul nuw nsw i32 %17261, 17857""  %17261 = and i32 %16652, 65535" -> "  %17572 = mul nuw i32 %17261, 46547""  %17261 = and i32 %16652, 65535" -> "  %17627 = mul nuw nsw i32 %17261, 31112""  %17261 = and i32 %16652, 65535" -> "  %17634 = mul nuw i32 %17261, 42170""  %17261 = and i32 %16652, 65535" -> "  store i32 %17261, i32* %73, align 1, !noalias !44""  %17261 = and i32 %16652, 65535" -> "  %17270 = mul nuw i32 %17261, 45147""  %17261 = and i32 %16652, 65535" -> "  %17262 = mul nuw i32 %17261, 37996""  %17261 = and i32 %16652, 65535" -> "  %17335 = mul nuw i32 %17261, 62728""  %17261 = and i32 %16652, 65535" -> "  %17328 = mul nuw nsw i32 %17261, 1324"
"  %17262 = mul nuw i32 %17261, 37996"
"  %17262 = mul nuw i32 %17261, 37996" -> "  %17282 = and i32 %17262, 65532""  %17262 = mul nuw i32 %17261, 37996" -> "  %17263 = lshr i32 %17262, 16"
"  %17263 = lshr i32 %17262, 16"
"  %17263 = lshr i32 %17262, 16" -> "  %17267 = add nuw nsw i32 %17266, %17263"
"  %17264 = and i32 %16660, 65535"
"  %17264 = and i32 %16660, 65535" -> "  %17265 = mul nuw i32 %17264, 37996""  %17264 = and i32 %16660, 65535" -> "  %17274 = mul nuw i32 %17264, 45147""  %17264 = and i32 %16660, 65535" -> "  store i32 %17264, i32* %86, align 1, !noalias !44""  %17264 = and i32 %16660, 65535" -> "  %17330 = mul nuw nsw i32 %17264, 1324""  %17264 = and i32 %16660, 65535" -> "  %17339 = mul nuw i32 %17264, 62728""  %17264 = and i32 %16660, 65535" -> "  %17638 = mul nuw i32 %17264, 42170""  %17264 = and i32 %16660, 65535" -> "  %17629 = mul nuw nsw i32 %17264, 31112""  %17264 = and i32 %16660, 65535" -> "  %17576 = mul nuw i32 %17264, 46547""  %17264 = and i32 %16660, 65535" -> "  %17567 = mul nuw nsw i32 %17264, 17857""  %17264 = and i32 %16660, 65535" -> "  %18762 = mul nuw nsw i32 %17264, 29744""  %17264 = and i32 %16660, 65535" -> "  %18753 = mul nuw nsw i32 %17264, 24315""  %17264 = and i32 %16660, 65535" -> "  %18700 = mul nuw nsw i32 %17264, 9871""  %17264 = and i32 %16660, 65535" -> "  %18691 = mul nuw i32 %17264, 42779""  %17264 = and i32 %16660, 65535" -> "  %19051 = mul nuw i32 %17264, 36786""  %17264 = and i32 %16660, 65535" -> "  %19042 = mul nuw nsw i32 %17264, 21884""  %17264 = and i32 %16660, 65535" -> "  %18989 = mul nuw nsw i32 %17264, 11561""  %17264 = and i32 %16660, 65535" -> "  %18980 = mul nuw nsw i32 %17264, 4087"
"  %17265 = mul nuw i32 %17264, 37996"
"  %17265 = mul nuw i32 %17264, 37996" -> "  %17268 = and i32 %17265, -65536""  %17265 = mul nuw i32 %17264, 37996" -> "  %17266 = and i32 %17265, 65532"
"  %17266 = and i32 %17265, 65532"
"  %17266 = and i32 %17265, 65532" -> "  %17267 = add nuw nsw i32 %17266, %17263"
"  %17267 = add nuw nsw i32 %17266, %17263"
"  %17267 = add nuw nsw i32 %17266, %17263" -> "  %17269 = add nuw i32 %17267, %17268"
"  %17268 = and i32 %17265, -65536"
"  %17268 = and i32 %17265, -65536" -> "  %17269 = add nuw i32 %17267, %17268"
"  %17269 = add nuw i32 %17267, %17268"
"  %17269 = add nuw i32 %17267, %17268" -> "  %17273 = lshr i32 %17269, 16""  %17269 = add nuw i32 %17267, %17268" -> "  %17271 = and i32 %17269, 65535"
"  %17270 = mul nuw i32 %17261, 45147"
"  %17270 = mul nuw i32 %17261, 45147" -> "  %17272 = add nuw i32 %17271, %17270"
"  %17271 = and i32 %17269, 65535"
"  %17271 = and i32 %17269, 65535" -> "  %17272 = add nuw i32 %17271, %17270"
"  %17272 = add nuw i32 %17271, %17270"
"  %17272 = add nuw i32 %17271, %17270" -> "  %17284 = and i32 %17272, 65535""  %17272 = add nuw i32 %17271, %17270" -> "  %17276 = lshr i32 %17272, 16"
"  %17273 = lshr i32 %17269, 16"
"  %17273 = lshr i32 %17269, 16" -> "  %17275 = add nuw i32 %17273, %17274"
"  %17274 = mul nuw i32 %17264, 45147"
"  %17274 = mul nuw i32 %17264, 45147" -> "  %17275 = add nuw i32 %17273, %17274"
"  %17275 = add nuw i32 %17273, %17274"
"  %17275 = add nuw i32 %17273, %17274" -> "  %17279 = and i32 %17275, -65536""  %17275 = add nuw i32 %17273, %17274" -> "  %17277 = and i32 %17275, 65535"
"  %17276 = lshr i32 %17272, 16"
"  %17276 = lshr i32 %17272, 16" -> "  %17278 = add nuw nsw i32 %17276, %17277"
"  %17277 = and i32 %17275, 65535"
"  %17277 = and i32 %17275, 65535" -> "  %17278 = add nuw nsw i32 %17276, %17277"
"  %17278 = add nuw nsw i32 %17276, %17277"
"  %17278 = add nuw nsw i32 %17276, %17277" -> "  %17280 = add nuw i32 %17278, %17279"
"  %17279 = and i32 %17275, -65536"
"  %17279 = and i32 %17275, -65536" -> "  %17280 = add nuw i32 %17278, %17279"
"  %17280 = add nuw i32 %17278, %17279"
"  %17280 = add nuw i32 %17278, %17279" -> "  %17293 = and i32 %17280, -65536""  %17280 = add nuw i32 %17278, %17279" -> "  %17291 = and i32 %17280, 65535"
"  %17281 = and i32 %17260, 65535"
"  %17281 = and i32 %17260, 65535" -> "  %17283 = add nuw nsw i32 %17281, %17282"
"  %17282 = and i32 %17262, 65532"
"  %17282 = and i32 %17262, 65532" -> "  %17283 = add nuw nsw i32 %17281, %17282"
"  %17283 = add nuw nsw i32 %17281, %17282"
"  %17283 = add nuw nsw i32 %17281, %17282" -> "  %17315 = and i32 %17283, 65535""  %17283 = add nuw nsw i32 %17281, %17282" -> "  %17287 = lshr i32 %17283, 16"
"  %17284 = and i32 %17272, 65535"
"  %17284 = and i32 %17272, 65535" -> "  %17286 = add nuw nsw i32 %17284, %17285"
"  %17285 = lshr i32 %17260, 16"
"  %17285 = lshr i32 %17260, 16" -> "  %17286 = add nuw nsw i32 %17284, %17285"
"  %17286 = add nuw nsw i32 %17284, %17285"
"  %17286 = add nuw nsw i32 %17284, %17285" -> "  %17290 = lshr i32 %17286, 16""  %17286 = add nuw nsw i32 %17284, %17285" -> "  %17288 = and i32 %17286, 65535"
"  %17287 = lshr i32 %17283, 16"
"  %17287 = lshr i32 %17283, 16" -> "  %17289 = add nuw nsw i32 %17288, %17287"
"  %17288 = and i32 %17286, 65535"
"  %17288 = and i32 %17286, 65535" -> "  %17289 = add nuw nsw i32 %17288, %17287"
"  %17289 = add nuw nsw i32 %17288, %17287"
"  %17289 = add nuw nsw i32 %17288, %17287" -> "  %17318 = and i32 %17289, 65535""  %17289 = add nuw nsw i32 %17288, %17287" -> "  %17295 = lshr i32 %17289, 16"
"  %17290 = lshr i32 %17286, 16"
"  %17290 = lshr i32 %17286, 16" -> "  %17292 = add nuw nsw i32 %17291, %17290"
"  %17291 = and i32 %17280, 65535"
"  %17291 = and i32 %17280, 65535" -> "  %17292 = add nuw nsw i32 %17291, %17290"
"  %17292 = add nuw nsw i32 %17291, %17290"
"  %17292 = add nuw nsw i32 %17291, %17290" -> "  %17294 = add nuw i32 %17292, %17293"
"  %17293 = and i32 %17280, -65536"
"  %17293 = and i32 %17280, -65536" -> "  %17294 = add nuw i32 %17292, %17293"
"  %17294 = add nuw i32 %17292, %17293"
"  %17294 = add nuw i32 %17292, %17293" -> "  %17296 = add nuw i32 %17294, %17295"
"  %17295 = lshr i32 %17289, 16"
"  %17295 = lshr i32 %17289, 16" -> "  %17296 = add nuw i32 %17294, %17295"
"  %17296 = add nuw i32 %17294, %17295"
"  %17296 = add nuw i32 %17294, %17295" -> "  %17346 = and i32 %17296, 65535""  %17296 = add nuw i32 %17294, %17295" -> "  %17349 = lshr i32 %17296, 16"
"  store i32 %17241, i32* %153, align 1, !noalias !44"

"  %17297 = mul nuw nsw i32 %17241, 1324"
"  %17297 = mul nuw nsw i32 %17241, 1324" -> "  %17316 = and i32 %17297, 65532""  %17297 = mul nuw nsw i32 %17241, 1324" -> "  %17298 = lshr i32 %17297, 16"
"  %17298 = lshr i32 %17297, 16"
"  %17298 = lshr i32 %17297, 16" -> "  %17301 = add nuw nsw i32 %17300, %17298"
"  store i32 %17244, i32* %162, align 1, !noalias !44"

"  %17299 = mul nuw nsw i32 %17244, 1324"
"  %17299 = mul nuw nsw i32 %17244, 1324" -> "  %17302 = and i32 %17299, 134152192""  %17299 = mul nuw nsw i32 %17244, 1324" -> "  %17300 = and i32 %17299, 65532"
"  %17300 = and i32 %17299, 65532"
"  %17300 = and i32 %17299, 65532" -> "  %17301 = add nuw nsw i32 %17300, %17298"
"  %17301 = add nuw nsw i32 %17300, %17298"
"  %17301 = add nuw nsw i32 %17300, %17298" -> "  %17303 = add nuw nsw i32 %17301, %17302"
"  %17302 = and i32 %17299, 134152192"
"  %17302 = and i32 %17299, 134152192" -> "  %17303 = add nuw nsw i32 %17301, %17302"
"  %17303 = add nuw nsw i32 %17301, %17302"
"  %17303 = add nuw nsw i32 %17301, %17302" -> "  %17307 = lshr i32 %17303, 16""  %17303 = add nuw nsw i32 %17301, %17302" -> "  %17305 = and i32 %17303, 65535"
"  %17304 = mul nuw i32 %17241, 62728"
"  %17304 = mul nuw i32 %17241, 62728" -> "  %17306 = add nuw i32 %17305, %17304"
"  %17305 = and i32 %17303, 65535"
"  %17305 = and i32 %17303, 65535" -> "  %17306 = add nuw i32 %17305, %17304"
"  %17306 = add nuw i32 %17305, %17304"
"  %17306 = add nuw i32 %17305, %17304" -> "  %17319 = and i32 %17306, 65535""  %17306 = add nuw i32 %17305, %17304" -> "  %17310 = lshr i32 %17306, 16"
"  %17307 = lshr i32 %17303, 16"
"  %17307 = lshr i32 %17303, 16" -> "  %17309 = add nuw i32 %17307, %17308"
"  %17308 = mul nuw i32 %17244, 62728"
"  %17308 = mul nuw i32 %17244, 62728" -> "  %17309 = add nuw i32 %17307, %17308"
"  %17309 = add nuw i32 %17307, %17308"
"  %17309 = add nuw i32 %17307, %17308" -> "  %17313 = and i32 %17309, -65536""  %17309 = add nuw i32 %17307, %17308" -> "  %17311 = and i32 %17309, 65535"
"  %17310 = lshr i32 %17306, 16"
"  %17310 = lshr i32 %17306, 16" -> "  %17312 = add nuw nsw i32 %17310, %17311"
"  %17311 = and i32 %17309, 65535"
"  %17311 = and i32 %17309, 65535" -> "  %17312 = add nuw nsw i32 %17310, %17311"
"  %17312 = add nuw nsw i32 %17310, %17311"
"  %17312 = add nuw nsw i32 %17310, %17311" -> "  %17314 = add nuw i32 %17312, %17313"
"  %17313 = and i32 %17309, -65536"
"  %17313 = and i32 %17309, -65536" -> "  %17314 = add nuw i32 %17312, %17313"
"  %17314 = add nuw i32 %17312, %17313"
"  %17314 = add nuw i32 %17312, %17313" -> "  %17322 = add nuw i32 %17314, %17321"
"  %17315 = and i32 %17283, 65535"
"  %17315 = and i32 %17283, 65535" -> "  %17317 = add nuw nsw i32 %17315, %17316"
"  %17316 = and i32 %17297, 65532"
"  %17316 = and i32 %17297, 65532" -> "  %17317 = add nuw nsw i32 %17315, %17316"
"  %17317 = add nuw nsw i32 %17315, %17316"
"  %17317 = add nuw nsw i32 %17315, %17316" -> "  %17324 = lshr i32 %17317, 16"
"  %17318 = and i32 %17289, 65535"
"  %17318 = and i32 %17289, 65535" -> "  %17320 = add nuw nsw i32 %17318, %17319"
"  %17319 = and i32 %17306, 65535"
"  %17319 = and i32 %17306, 65535" -> "  %17320 = add nuw nsw i32 %17318, %17319"
"  %17320 = add nuw nsw i32 %17318, %17319"
"  %17320 = add nuw nsw i32 %17318, %17319" -> "  %17323 = and i32 %17320, 65535""  %17320 = add nuw nsw i32 %17318, %17319" -> "  %17321 = lshr i32 %17320, 16"
"  %17321 = lshr i32 %17320, 16"
"  %17321 = lshr i32 %17320, 16" -> "  %17322 = add nuw i32 %17314, %17321"
"  %17322 = add nuw i32 %17314, %17321"
"  %17322 = add nuw i32 %17314, %17321" -> "  %17327 = add nuw i32 %17322, %17326"
"  %17323 = and i32 %17320, 65535"
"  %17323 = and i32 %17320, 65535" -> "  %17325 = add nuw nsw i32 %17323, %17324"
"  %17324 = lshr i32 %17317, 16"
"  %17324 = lshr i32 %17317, 16" -> "  %17325 = add nuw nsw i32 %17323, %17324"
"  %17325 = add nuw nsw i32 %17323, %17324"
"  %17325 = add nuw nsw i32 %17323, %17324" -> "  %17326 = lshr i32 %17325, 16"
"  %17326 = lshr i32 %17325, 16"
"  %17326 = lshr i32 %17325, 16" -> "  %17327 = add nuw i32 %17322, %17326"
"  %17327 = add nuw i32 %17322, %17326"
"  %17327 = add nuw i32 %17322, %17326" -> "  %17360 = and i32 %17327, 65535""  %17327 = add nuw i32 %17322, %17326" -> "  %17363 = lshr i32 %17327, 16"
"  store i32 %17261, i32* %73, align 1, !noalias !44"

"  %17328 = mul nuw nsw i32 %17261, 1324"
"  %17328 = mul nuw nsw i32 %17261, 1324" -> "  %17329 = lshr i32 %17328, 16""  %17328 = mul nuw nsw i32 %17261, 1324" -> "  %17347 = and i32 %17328, 65532"
"  %17329 = lshr i32 %17328, 16"
"  %17329 = lshr i32 %17328, 16" -> "  %17332 = add nuw nsw i32 %17331, %17329"
"  store i32 %17264, i32* %86, align 1, !noalias !44"

"  %17330 = mul nuw nsw i32 %17264, 1324"
"  %17330 = mul nuw nsw i32 %17264, 1324" -> "  %17333 = and i32 %17330, 134152192""  %17330 = mul nuw nsw i32 %17264, 1324" -> "  %17331 = and i32 %17330, 65532"
"  %17331 = and i32 %17330, 65532"
"  %17331 = and i32 %17330, 65532" -> "  %17332 = add nuw nsw i32 %17331, %17329"
"  %17332 = add nuw nsw i32 %17331, %17329"
"  %17332 = add nuw nsw i32 %17331, %17329" -> "  %17334 = add nuw nsw i32 %17332, %17333"
"  %17333 = and i32 %17330, 134152192"
"  %17333 = and i32 %17330, 134152192" -> "  %17334 = add nuw nsw i32 %17332, %17333"
"  %17334 = add nuw nsw i32 %17332, %17333"
"  %17334 = add nuw nsw i32 %17332, %17333" -> "  %17338 = lshr i32 %17334, 16""  %17334 = add nuw nsw i32 %17332, %17333" -> "  %17336 = and i32 %17334, 65535"
"  %17335 = mul nuw i32 %17261, 62728"
"  %17335 = mul nuw i32 %17261, 62728" -> "  %17337 = add nuw i32 %17336, %17335"
"  %17336 = and i32 %17334, 65535"
"  %17336 = and i32 %17334, 65535" -> "  %17337 = add nuw i32 %17336, %17335"
"  %17337 = add nuw i32 %17336, %17335"
"  %17337 = add nuw i32 %17336, %17335" -> "  %17350 = and i32 %17337, 65535""  %17337 = add nuw i32 %17336, %17335" -> "  %17341 = lshr i32 %17337, 16"
"  %17338 = lshr i32 %17334, 16"
"  %17338 = lshr i32 %17334, 16" -> "  %17340 = add nuw i32 %17338, %17339"
"  %17339 = mul nuw i32 %17264, 62728"
"  %17339 = mul nuw i32 %17264, 62728" -> "  %17340 = add nuw i32 %17338, %17339"
"  %17340 = add nuw i32 %17338, %17339"
"  %17340 = add nuw i32 %17338, %17339" -> "  %17344 = and i32 %17340, -65536""  %17340 = add nuw i32 %17338, %17339" -> "  %17342 = and i32 %17340, 65535"
"  %17341 = lshr i32 %17337, 16"
"  %17341 = lshr i32 %17337, 16" -> "  %17343 = add nuw nsw i32 %17341, %17342"
"  %17342 = and i32 %17340, 65535"
"  %17342 = and i32 %17340, 65535" -> "  %17343 = add nuw nsw i32 %17341, %17342"
"  %17343 = add nuw nsw i32 %17341, %17342"
"  %17343 = add nuw nsw i32 %17341, %17342" -> "  %17345 = add nuw i32 %17343, %17344"
"  %17344 = and i32 %17340, -65536"
"  %17344 = and i32 %17340, -65536" -> "  %17345 = add nuw i32 %17343, %17344"
"  %17345 = add nuw i32 %17343, %17344"
"  %17345 = add nuw i32 %17343, %17344" -> "  %17353 = add nuw i32 %17345, %17352"
"  %17346 = and i32 %17296, 65535"
"  %17346 = and i32 %17296, 65535" -> "  %17348 = add nuw nsw i32 %17346, %17347"
"  %17347 = and i32 %17328, 65532"
"  %17347 = and i32 %17328, 65532" -> "  %17348 = add nuw nsw i32 %17346, %17347"
"  %17348 = add nuw nsw i32 %17346, %17347"
"  %17348 = add nuw nsw i32 %17346, %17347" -> "  %17359 = and i32 %17348, 65535""  %17348 = add nuw nsw i32 %17346, %17347" -> "  %17355 = lshr i32 %17348, 16"
"  %17349 = lshr i32 %17296, 16"
"  %17349 = lshr i32 %17296, 16" -> "  %17351 = add nuw nsw i32 %17349, %17350"
"  %17350 = and i32 %17337, 65535"
"  %17350 = and i32 %17337, 65535" -> "  %17351 = add nuw nsw i32 %17349, %17350"
"  %17351 = add nuw nsw i32 %17349, %17350"
"  %17351 = add nuw nsw i32 %17349, %17350" -> "  %17354 = and i32 %17351, 65535""  %17351 = add nuw nsw i32 %17349, %17350" -> "  %17352 = lshr i32 %17351, 16"
"  %17352 = lshr i32 %17351, 16"
"  %17352 = lshr i32 %17351, 16" -> "  %17353 = add nuw i32 %17345, %17352"
"  %17353 = add nuw i32 %17345, %17352"
"  %17353 = add nuw i32 %17345, %17352" -> "  %17358 = add nuw i32 %17353, %17357"
"  %17354 = and i32 %17351, 65535"
"  %17354 = and i32 %17351, 65535" -> "  %17356 = add nuw nsw i32 %17354, %17355"
"  %17355 = lshr i32 %17348, 16"
"  %17355 = lshr i32 %17348, 16" -> "  %17356 = add nuw nsw i32 %17354, %17355"
"  %17356 = add nuw nsw i32 %17354, %17355"
"  %17356 = add nuw nsw i32 %17354, %17355" -> "  %17362 = and i32 %17356, 65535""  %17356 = add nuw nsw i32 %17354, %17355" -> "  %17357 = lshr i32 %17356, 16"
"  %17357 = lshr i32 %17356, 16"
"  %17357 = lshr i32 %17356, 16" -> "  %17358 = add nuw i32 %17353, %17357"
"  %17358 = add nuw i32 %17353, %17357"
"  %17358 = add nuw i32 %17353, %17357" -> "  %17371 = and i32 %17358, -65536""  %17358 = add nuw i32 %17353, %17357" -> "  %17369 = and i32 %17358, 65535"
"  %17359 = and i32 %17348, 65535"
"  %17359 = and i32 %17348, 65535" -> "  %17361 = add nuw nsw i32 %17360, %17359"
"  %17360 = and i32 %17327, 65535"
"  %17360 = and i32 %17327, 65535" -> "  %17361 = add nuw nsw i32 %17360, %17359"
"  %17361 = add nuw nsw i32 %17360, %17359"
"  %17361 = add nuw nsw i32 %17360, %17359" -> "  %17510 = and i32 %17361, 65535""  %17361 = add nuw nsw i32 %17360, %17359" -> "  %17365 = lshr i32 %17361, 16"
"  %17362 = and i32 %17356, 65535"
"  %17362 = and i32 %17356, 65535" -> "  %17364 = add nuw nsw i32 %17362, %17363"
"  %17363 = lshr i32 %17327, 16"
"  %17363 = lshr i32 %17327, 16" -> "  %17364 = add nuw nsw i32 %17362, %17363"
"  %17364 = add nuw nsw i32 %17362, %17363"
"  %17364 = add nuw nsw i32 %17362, %17363" -> "  %17368 = lshr i32 %17364, 16""  %17364 = add nuw nsw i32 %17362, %17363" -> "  %17366 = and i32 %17364, 65535"
"  %17365 = lshr i32 %17361, 16"
"  %17365 = lshr i32 %17361, 16" -> "  %17367 = add nuw nsw i32 %17366, %17365"
"  %17366 = and i32 %17364, 65535"
"  %17366 = and i32 %17364, 65535" -> "  %17367 = add nuw nsw i32 %17366, %17365"
"  %17367 = add nuw nsw i32 %17366, %17365"
"  %17367 = add nuw nsw i32 %17366, %17365" -> "  %17513 = and i32 %17367, 65535""  %17367 = add nuw nsw i32 %17366, %17365" -> "  %17373 = lshr i32 %17367, 16"
"  %17368 = lshr i32 %17364, 16"
"  %17368 = lshr i32 %17364, 16" -> "  %17370 = add nuw nsw i32 %17368, %17369"
"  %17369 = and i32 %17358, 65535"
"  %17369 = and i32 %17358, 65535" -> "  %17370 = add nuw nsw i32 %17368, %17369"
"  %17370 = add nuw nsw i32 %17368, %17369"
"  %17370 = add nuw nsw i32 %17368, %17369" -> "  %17372 = add nuw i32 %17370, %17371"
"  %17371 = and i32 %17358, -65536"
"  %17371 = and i32 %17358, -65536" -> "  %17372 = add nuw i32 %17370, %17371"
"  %17372 = add nuw i32 %17370, %17371"
"  %17372 = add nuw i32 %17370, %17371" -> "  %17374 = add nuw i32 %17372, %17373"
"  %17373 = lshr i32 %17367, 16"
"  %17373 = lshr i32 %17367, 16" -> "  %17374 = add nuw i32 %17372, %17373"
"  %17374 = add nuw i32 %17372, %17373"
"  %17374 = add nuw i32 %17372, %17373" -> "  %17520 = and i32 %17374, 65535""  %17374 = add nuw i32 %17372, %17373" -> "  %17523 = lshr i32 %17374, 16"
"  %17375 = and i32 %17005, 65535"
"  %17375 = and i32 %17005, 65535" -> "  %17712 = mul nuw nsw i32 %17375, 17857""  %17375 = and i32 %17005, 65535" -> "  %17377 = mul nuw i32 %17375, 37996""  %17375 = and i32 %17005, 65535" -> "  %17384 = mul nuw i32 %17375, 45147""  %17375 = and i32 %17005, 65535" -> "  store i32 %17375, i32* %127, align 1, !noalias !47""  %17375 = and i32 %17005, 65535" -> "  %17431 = mul nuw nsw i32 %17375, 1324""  %17375 = and i32 %17005, 65535" -> "  %17438 = mul nuw i32 %17375, 62728""  %17375 = and i32 %17005, 65535" -> "  %17768 = mul nuw i32 %17375, 42170""  %17375 = and i32 %17005, 65535" -> "  %17761 = mul nuw nsw i32 %17375, 31112""  %17375 = and i32 %17005, 65535" -> "  %17719 = mul nuw i32 %17375, 46547""  %17375 = and i32 %17005, 65535" -> "  %18854 = mul nuw nsw i32 %17375, 29744""  %17375 = and i32 %17005, 65535" -> "  %18847 = mul nuw nsw i32 %17375, 24315""  %17375 = and i32 %17005, 65535" -> "  %18805 = mul nuw nsw i32 %17375, 9871""  %17375 = and i32 %17005, 65535" -> "  %18798 = mul nuw i32 %17375, 42779""  %17375 = and i32 %17005, 65535" -> "  %19181 = mul nuw i32 %17375, 36786""  %17375 = and i32 %17005, 65535" -> "  %19174 = mul nuw nsw i32 %17375, 21884""  %17375 = and i32 %17005, 65535" -> "  %19132 = mul nuw nsw i32 %17375, 11561""  %17375 = and i32 %17005, 65535" -> "  %19125 = mul nuw nsw i32 %17375, 4087"
"  %17376 = and i32 %17011, 65535"
"  %17376 = and i32 %17011, 65535" -> "  %17379 = mul nuw i32 %17376, 37996""  %17376 = and i32 %17011, 65535" -> "  %17388 = mul nuw i32 %17376, 45147""  %17376 = and i32 %17011, 65535" -> "  store i32 %17376, i32* %316, align 1, !noalias !47""  %17376 = and i32 %17011, 65535" -> "  %17433 = mul nuw nsw i32 %17376, 1324""  %17376 = and i32 %17011, 65535" -> "  %17442 = mul nuw i32 %17376, 62728""  %17376 = and i32 %17011, 65535" -> "  %17772 = mul nuw i32 %17376, 42170""  %17376 = and i32 %17011, 65535" -> "  %17763 = mul nuw nsw i32 %17376, 31112""  %17376 = and i32 %17011, 65535" -> "  %17723 = mul nuw i32 %17376, 46547""  %17376 = and i32 %17011, 65535" -> "  %17714 = mul nuw nsw i32 %17376, 17857""  %17376 = and i32 %17011, 65535" -> "  %18858 = mul nuw nsw i32 %17376, 29744""  %17376 = and i32 %17011, 65535" -> "  %18849 = mul nuw nsw i32 %17376, 24315""  %17376 = and i32 %17011, 65535" -> "  %18809 = mul nuw nsw i32 %17376, 9871""  %17376 = and i32 %17011, 65535" -> "  %18800 = mul nuw i32 %17376, 42779""  %17376 = and i32 %17011, 65535" -> "  %19185 = mul nuw i32 %17376, 36786""  %17376 = and i32 %17011, 65535" -> "  %19176 = mul nuw nsw i32 %17376, 21884""  %17376 = and i32 %17011, 65535" -> "  %19136 = mul nuw nsw i32 %17376, 11561""  %17376 = and i32 %17011, 65535" -> "  %19127 = mul nuw nsw i32 %17376, 4087"
"  %17377 = mul nuw i32 %17375, 37996"
"  %17377 = mul nuw i32 %17375, 37996" -> "  %17509 = and i32 %17377, 65532""  %17377 = mul nuw i32 %17375, 37996" -> "  %17378 = lshr i32 %17377, 16"
"  %17378 = lshr i32 %17377, 16"
"  %17378 = lshr i32 %17377, 16" -> "  %17381 = add nuw nsw i32 %17380, %17378"
"  %17379 = mul nuw i32 %17376, 37996"
"  %17379 = mul nuw i32 %17376, 37996" -> "  %17382 = and i32 %17379, -65536""  %17379 = mul nuw i32 %17376, 37996" -> "  %17380 = and i32 %17379, 65532"
"  %17380 = and i32 %17379, 65532"
"  %17380 = and i32 %17379, 65532" -> "  %17381 = add nuw nsw i32 %17380, %17378"
"  %17381 = add nuw nsw i32 %17380, %17378"
"  %17381 = add nuw nsw i32 %17380, %17378" -> "  %17383 = add nuw i32 %17381, %17382"
"  %17382 = and i32 %17379, -65536"
"  %17382 = and i32 %17379, -65536" -> "  %17383 = add nuw i32 %17381, %17382"
"  %17383 = add nuw i32 %17381, %17382"
"  %17383 = add nuw i32 %17381, %17382" -> "  %17387 = lshr i32 %17383, 16""  %17383 = add nuw i32 %17381, %17382" -> "  %17385 = and i32 %17383, 65535"
"  %17384 = mul nuw i32 %17375, 45147"
"  %17384 = mul nuw i32 %17375, 45147" -> "  %17386 = add nuw i32 %17385, %17384"
"  %17385 = and i32 %17383, 65535"
"  %17385 = and i32 %17383, 65535" -> "  %17386 = add nuw i32 %17385, %17384"
"  %17386 = add nuw i32 %17385, %17384"
"  %17386 = add nuw i32 %17385, %17384" -> "  %17512 = and i32 %17386, 65535""  %17386 = add nuw i32 %17385, %17384" -> "  %17390 = lshr i32 %17386, 16"
"  %17387 = lshr i32 %17383, 16"
"  %17387 = lshr i32 %17383, 16" -> "  %17389 = add nuw i32 %17387, %17388"
"  %17388 = mul nuw i32 %17376, 45147"
"  %17388 = mul nuw i32 %17376, 45147" -> "  %17389 = add nuw i32 %17387, %17388"
"  %17389 = add nuw i32 %17387, %17388"
"  %17389 = add nuw i32 %17387, %17388" -> "  %17393 = and i32 %17389, -65536""  %17389 = add nuw i32 %17387, %17388" -> "  %17391 = and i32 %17389, 65535"
"  %17390 = lshr i32 %17386, 16"
"  %17390 = lshr i32 %17386, 16" -> "  %17392 = add nuw nsw i32 %17390, %17391"
"  %17391 = and i32 %17389, 65535"
"  %17391 = and i32 %17389, 65535" -> "  %17392 = add nuw nsw i32 %17390, %17391"
"  %17392 = add nuw nsw i32 %17390, %17391"
"  %17392 = add nuw nsw i32 %17390, %17391" -> "  %17394 = add nuw i32 %17392, %17393"
"  %17393 = and i32 %17389, -65536"
"  %17393 = and i32 %17389, -65536" -> "  %17394 = add nuw i32 %17392, %17393"
"  %17394 = add nuw i32 %17392, %17393"
"  %17394 = add nuw i32 %17392, %17393" -> "  %17419 = lshr i32 %17394, 16""  %17394 = add nuw i32 %17392, %17393" -> "  %17415 = and i32 %17394, 65535"
"  %17395 = and i32 %17025, 65535"
"  %17395 = and i32 %17025, 65535" -> "  %18878 = mul nuw nsw i32 %17395, 24315""  %17395 = and i32 %17025, 65535" -> "  %17396 = mul nuw i32 %17395, 37996""  %17395 = and i32 %17025, 65535" -> "  %17404 = mul nuw i32 %17395, 45147""  %17395 = and i32 %17025, 65535" -> "  store i32 %17395, i32* %167, align 1, !noalias !47""  %17395 = and i32 %17025, 65535" -> "  %17462 = mul nuw nsw i32 %17395, 1324""  %17395 = and i32 %17025, 65535" -> "  %17469 = mul nuw i32 %17395, 62728""  %17395 = and i32 %17025, 65535" -> "  %17799 = mul nuw i32 %17395, 42170""  %17395 = and i32 %17025, 65535" -> "  %17792 = mul nuw nsw i32 %17395, 31112""  %17395 = and i32 %17025, 65535" -> "  %17737 = mul nuw i32 %17395, 46547""  %17395 = and i32 %17025, 65535" -> "  %17730 = mul nuw nsw i32 %17395, 17857""  %17395 = and i32 %17025, 65535" -> "  %18882 = mul nuw nsw i32 %17395, 29744""  %17395 = and i32 %17025, 65535" -> "  %18823 = mul nuw nsw i32 %17395, 9871""  %17395 = and i32 %17025, 65535" -> "  %18816 = mul nuw i32 %17395, 42779""  %17395 = and i32 %17025, 65535" -> "  %19212 = mul nuw i32 %17395, 36786""  %17395 = and i32 %17025, 65535" -> "  %19205 = mul nuw nsw i32 %17395, 21884""  %17395 = and i32 %17025, 65535" -> "  %19150 = mul nuw nsw i32 %17395, 11561""  %17395 = and i32 %17025, 65535" -> "  %19143 = mul nuw nsw i32 %17395, 4087"
"  %17396 = mul nuw i32 %17395, 37996"
"  %17396 = mul nuw i32 %17395, 37996" -> "  %17416 = and i32 %17396, 65532""  %17396 = mul nuw i32 %17395, 37996" -> "  %17397 = lshr i32 %17396, 16"
"  %17397 = lshr i32 %17396, 16"
"  %17397 = lshr i32 %17396, 16" -> "  %17401 = add nuw nsw i32 %17400, %17397"
"  %17398 = and i32 %17028, 65535"
"  %17398 = and i32 %17028, 65535" -> "  %17399 = mul nuw i32 %17398, 37996""  %17398 = and i32 %17028, 65535" -> "  %17408 = mul nuw i32 %17398, 45147""  %17398 = and i32 %17028, 65535" -> "  %17464 = mul nuw nsw i32 %17398, 1324""  %17398 = and i32 %17028, 65535" -> "  %17473 = mul nuw i32 %17398, 62728""  %17398 = and i32 %17028, 65535" -> "  %17803 = mul nuw i32 %17398, 42170""  %17398 = and i32 %17028, 65535" -> "  %17794 = mul nuw nsw i32 %17398, 31112""  %17398 = and i32 %17028, 65535" -> "  %17741 = mul nuw i32 %17398, 46547""  %17398 = and i32 %17028, 65535" -> "  %17732 = mul nuw nsw i32 %17398, 17857""  %17398 = and i32 %17028, 65535" -> "  %18886 = mul nuw nsw i32 %17398, 29744""  %17398 = and i32 %17028, 65535" -> "  %18880 = mul nuw nsw i32 %17398, 24315""  %17398 = and i32 %17028, 65535" -> "  %18827 = mul nuw nsw i32 %17398, 9871""  %17398 = and i32 %17028, 65535" -> "  %18818 = mul nuw i32 %17398, 42779""  %17398 = and i32 %17028, 65535" -> "  %19216 = mul nuw i32 %17398, 36786""  %17398 = and i32 %17028, 65535" -> "  %19207 = mul nuw nsw i32 %17398, 21884""  %17398 = and i32 %17028, 65535" -> "  %19154 = mul nuw nsw i32 %17398, 11561""  %17398 = and i32 %17028, 65535" -> "  %19145 = mul nuw nsw i32 %17398, 4087"
"  %17399 = mul nuw i32 %17398, 37996"
"  %17399 = mul nuw i32 %17398, 37996" -> "  %17402 = and i32 %17399, -65536""  %17399 = mul nuw i32 %17398, 37996" -> "  %17400 = and i32 %17399, 65532"
"  %17400 = and i32 %17399, 65532"
"  %17400 = and i32 %17399, 65532" -> "  %17401 = add nuw nsw i32 %17400, %17397"
"  %17401 = add nuw nsw i32 %17400, %17397"
"  %17401 = add nuw nsw i32 %17400, %17397" -> "  %17403 = add nuw i32 %17401, %17402"
"  %17402 = and i32 %17399, -65536"
"  %17402 = and i32 %17399, -65536" -> "  %17403 = add nuw i32 %17401, %17402"
"  %17403 = add nuw i32 %17401, %17402"
"  %17403 = add nuw i32 %17401, %17402" -> "  %17407 = lshr i32 %17403, 16""  %17403 = add nuw i32 %17401, %17402" -> "  %17405 = and i32 %17403, 65535"
"  %17404 = mul nuw i32 %17395, 45147"
"  %17404 = mul nuw i32 %17395, 45147" -> "  %17406 = add nuw i32 %17405, %17404"
"  %17405 = and i32 %17403, 65535"
"  %17405 = and i32 %17403, 65535" -> "  %17406 = add nuw i32 %17405, %17404"
"  %17406 = add nuw i32 %17405, %17404"
"  %17406 = add nuw i32 %17405, %17404" -> "  %17418 = and i32 %17406, 65535""  %17406 = add nuw i32 %17405, %17404" -> "  %17410 = lshr i32 %17406, 16"
"  %17407 = lshr i32 %17403, 16"
"  %17407 = lshr i32 %17403, 16" -> "  %17409 = add nuw i32 %17407, %17408"
"  %17408 = mul nuw i32 %17398, 45147"
"  %17408 = mul nuw i32 %17398, 45147" -> "  %17409 = add nuw i32 %17407, %17408"
"  %17409 = add nuw i32 %17407, %17408"
"  %17409 = add nuw i32 %17407, %17408" -> "  %17413 = and i32 %17409, -65536""  %17409 = add nuw i32 %17407, %17408" -> "  %17411 = and i32 %17409, 65535"
"  %17410 = lshr i32 %17406, 16"
"  %17410 = lshr i32 %17406, 16" -> "  %17412 = add nuw nsw i32 %17410, %17411"
"  %17411 = and i32 %17409, 65535"
"  %17411 = and i32 %17409, 65535" -> "  %17412 = add nuw nsw i32 %17410, %17411"
"  %17412 = add nuw nsw i32 %17410, %17411"
"  %17412 = add nuw nsw i32 %17410, %17411" -> "  %17414 = add nuw i32 %17412, %17413"
"  %17413 = and i32 %17409, -65536"
"  %17413 = and i32 %17409, -65536" -> "  %17414 = add nuw i32 %17412, %17413"
"  %17414 = add nuw i32 %17412, %17413"
"  %17414 = add nuw i32 %17412, %17413" -> "  %17427 = and i32 %17414, -65536""  %17414 = add nuw i32 %17412, %17413" -> "  %17425 = and i32 %17414, 65535"
"  %17415 = and i32 %17394, 65535"
"  %17415 = and i32 %17394, 65535" -> "  %17417 = add nuw nsw i32 %17415, %17416"
"  %17416 = and i32 %17396, 65532"
"  %17416 = and i32 %17396, 65532" -> "  %17417 = add nuw nsw i32 %17415, %17416"
"  %17417 = add nuw nsw i32 %17415, %17416"
"  %17417 = add nuw nsw i32 %17415, %17416" -> "  %17449 = and i32 %17417, 65535""  %17417 = add nuw nsw i32 %17415, %17416" -> "  %17421 = lshr i32 %17417, 16"
"  %17418 = and i32 %17406, 65535"
"  %17418 = and i32 %17406, 65535" -> "  %17420 = add nuw nsw i32 %17418, %17419"
"  %17419 = lshr i32 %17394, 16"
"  %17419 = lshr i32 %17394, 16" -> "  %17420 = add nuw nsw i32 %17418, %17419"
"  %17420 = add nuw nsw i32 %17418, %17419"
"  %17420 = add nuw nsw i32 %17418, %17419" -> "  %17424 = lshr i32 %17420, 16""  %17420 = add nuw nsw i32 %17418, %17419" -> "  %17422 = and i32 %17420, 65535"
"  %17421 = lshr i32 %17417, 16"
"  %17421 = lshr i32 %17417, 16" -> "  %17423 = add nuw nsw i32 %17422, %17421"
"  %17422 = and i32 %17420, 65535"
"  %17422 = and i32 %17420, 65535" -> "  %17423 = add nuw nsw i32 %17422, %17421"
"  %17423 = add nuw nsw i32 %17422, %17421"
"  %17423 = add nuw nsw i32 %17422, %17421" -> "  %17452 = and i32 %17423, 65535""  %17423 = add nuw nsw i32 %17422, %17421" -> "  %17429 = lshr i32 %17423, 16"
"  %17424 = lshr i32 %17420, 16"
"  %17424 = lshr i32 %17420, 16" -> "  %17426 = add nuw nsw i32 %17425, %17424"
"  %17425 = and i32 %17414, 65535"
"  %17425 = and i32 %17414, 65535" -> "  %17426 = add nuw nsw i32 %17425, %17424"
"  %17426 = add nuw nsw i32 %17425, %17424"
"  %17426 = add nuw nsw i32 %17425, %17424" -> "  %17428 = add nuw i32 %17426, %17427"
"  %17427 = and i32 %17414, -65536"
"  %17427 = and i32 %17414, -65536" -> "  %17428 = add nuw i32 %17426, %17427"
"  %17428 = add nuw i32 %17426, %17427"
"  %17428 = add nuw i32 %17426, %17427" -> "  %17430 = add nuw i32 %17428, %17429"
"  %17429 = lshr i32 %17423, 16"
"  %17429 = lshr i32 %17423, 16" -> "  %17430 = add nuw i32 %17428, %17429"
"  %17430 = add nuw i32 %17428, %17429"
"  %17430 = add nuw i32 %17428, %17429" -> "  %17484 = lshr i32 %17430, 16""  %17430 = add nuw i32 %17428, %17429" -> "  %17480 = and i32 %17430, 65535"
"  store i32 %17375, i32* %127, align 1, !noalias !47"

"  %17431 = mul nuw nsw i32 %17375, 1324"
"  %17431 = mul nuw nsw i32 %17375, 1324" -> "  %17450 = and i32 %17431, 65532""  %17431 = mul nuw nsw i32 %17375, 1324" -> "  %17432 = lshr i32 %17431, 16"
"  %17432 = lshr i32 %17431, 16"
"  %17432 = lshr i32 %17431, 16" -> "  %17435 = add nuw nsw i32 %17434, %17432"
"  store i32 %17376, i32* %316, align 1, !noalias !47"

"  %17433 = mul nuw nsw i32 %17376, 1324"
"  %17433 = mul nuw nsw i32 %17376, 1324" -> "  %17436 = and i32 %17433, 134152192""  %17433 = mul nuw nsw i32 %17376, 1324" -> "  %17434 = and i32 %17433, 65532"
"  %17434 = and i32 %17433, 65532"
"  %17434 = and i32 %17433, 65532" -> "  %17435 = add nuw nsw i32 %17434, %17432"
"  %17435 = add nuw nsw i32 %17434, %17432"
"  %17435 = add nuw nsw i32 %17434, %17432" -> "  %17437 = add nuw nsw i32 %17435, %17436"
"  %17436 = and i32 %17433, 134152192"
"  %17436 = and i32 %17433, 134152192" -> "  %17437 = add nuw nsw i32 %17435, %17436"
"  %17437 = add nuw nsw i32 %17435, %17436"
"  %17437 = add nuw nsw i32 %17435, %17436" -> "  %17441 = lshr i32 %17437, 16""  %17437 = add nuw nsw i32 %17435, %17436" -> "  %17439 = and i32 %17437, 65535"
"  %17438 = mul nuw i32 %17375, 62728"
"  %17438 = mul nuw i32 %17375, 62728" -> "  %17440 = add nuw i32 %17439, %17438"
"  %17439 = and i32 %17437, 65535"
"  %17439 = and i32 %17437, 65535" -> "  %17440 = add nuw i32 %17439, %17438"
"  %17440 = add nuw i32 %17439, %17438"
"  %17440 = add nuw i32 %17439, %17438" -> "  %17453 = and i32 %17440, 65535""  %17440 = add nuw i32 %17439, %17438" -> "  %17444 = lshr i32 %17440, 16"
"  %17441 = lshr i32 %17437, 16"
"  %17441 = lshr i32 %17437, 16" -> "  %17443 = add nuw i32 %17441, %17442"
"  %17442 = mul nuw i32 %17376, 62728"
"  %17442 = mul nuw i32 %17376, 62728" -> "  %17443 = add nuw i32 %17441, %17442"
"  %17443 = add nuw i32 %17441, %17442"
"  %17443 = add nuw i32 %17441, %17442" -> "  %17447 = and i32 %17443, -65536""  %17443 = add nuw i32 %17441, %17442" -> "  %17445 = and i32 %17443, 65535"
"  %17444 = lshr i32 %17440, 16"
"  %17444 = lshr i32 %17440, 16" -> "  %17446 = add nuw nsw i32 %17444, %17445"
"  %17445 = and i32 %17443, 65535"
"  %17445 = and i32 %17443, 65535" -> "  %17446 = add nuw nsw i32 %17444, %17445"
"  %17446 = add nuw nsw i32 %17444, %17445"
"  %17446 = add nuw nsw i32 %17444, %17445" -> "  %17448 = add nuw i32 %17446, %17447"
"  %17447 = and i32 %17443, -65536"
"  %17447 = and i32 %17443, -65536" -> "  %17448 = add nuw i32 %17446, %17447"
"  %17448 = add nuw i32 %17446, %17447"
"  %17448 = add nuw i32 %17446, %17447" -> "  %17456 = add nuw i32 %17448, %17455"
"  %17449 = and i32 %17417, 65535"
"  %17449 = and i32 %17417, 65535" -> "  %17451 = add nuw nsw i32 %17449, %17450"
"  %17450 = and i32 %17431, 65532"
"  %17450 = and i32 %17431, 65532" -> "  %17451 = add nuw nsw i32 %17449, %17450"
"  %17451 = add nuw nsw i32 %17449, %17450"
"  %17451 = add nuw nsw i32 %17449, %17450" -> "  %17521 = and i32 %17451, 65535""  %17451 = add nuw nsw i32 %17449, %17450" -> "  %17458 = lshr i32 %17451, 16"
"  %17452 = and i32 %17423, 65535"
"  %17452 = and i32 %17423, 65535" -> "  %17454 = add nuw nsw i32 %17452, %17453"
"  %17453 = and i32 %17440, 65535"
"  %17453 = and i32 %17440, 65535" -> "  %17454 = add nuw nsw i32 %17452, %17453"
"  %17454 = add nuw nsw i32 %17452, %17453"
"  %17454 = add nuw nsw i32 %17452, %17453" -> "  %17457 = and i32 %17454, 65535""  %17454 = add nuw nsw i32 %17452, %17453" -> "  %17455 = lshr i32 %17454, 16"
"  %17455 = lshr i32 %17454, 16"
"  %17455 = lshr i32 %17454, 16" -> "  %17456 = add nuw i32 %17448, %17455"
"  %17456 = add nuw i32 %17448, %17455"
"  %17456 = add nuw i32 %17448, %17455" -> "  %17461 = add nuw i32 %17456, %17460"
"  %17457 = and i32 %17454, 65535"
"  %17457 = and i32 %17454, 65535" -> "  %17459 = add nuw nsw i32 %17457, %17458"
"  %17458 = lshr i32 %17451, 16"
"  %17458 = lshr i32 %17451, 16" -> "  %17459 = add nuw nsw i32 %17457, %17458"
"  %17459 = add nuw nsw i32 %17457, %17458"
"  %17459 = add nuw nsw i32 %17457, %17458" -> "  %17524 = and i32 %17459, 65535""  %17459 = add nuw nsw i32 %17457, %17458" -> "  %17460 = lshr i32 %17459, 16"
"  %17460 = lshr i32 %17459, 16"
"  %17460 = lshr i32 %17459, 16" -> "  %17461 = add nuw i32 %17456, %17460"
"  %17461 = add nuw i32 %17456, %17460"
"  %17461 = add nuw i32 %17456, %17460" -> "  %17497 = lshr i32 %17461, 16""  %17461 = add nuw i32 %17456, %17460" -> "  %17494 = and i32 %17461, 65535"
"  store i32 %17395, i32* %167, align 1, !noalias !47"

"  %17462 = mul nuw nsw i32 %17395, 1324"
"  %17462 = mul nuw nsw i32 %17395, 1324" -> "  %17481 = and i32 %17462, 65532""  %17462 = mul nuw nsw i32 %17395, 1324" -> "  %17463 = lshr i32 %17462, 16"
"  %17463 = lshr i32 %17462, 16"
"  %17463 = lshr i32 %17462, 16" -> "  %17466 = add nuw nsw i32 %17465, %17463"
"  %17464 = mul nuw nsw i32 %17398, 1324"
"  %17464 = mul nuw nsw i32 %17398, 1324" -> "  %17467 = and i32 %17464, 134152192""  %17464 = mul nuw nsw i32 %17398, 1324" -> "  %17465 = and i32 %17464, 65532"
"  %17465 = and i32 %17464, 65532"
"  %17465 = and i32 %17464, 65532" -> "  %17466 = add nuw nsw i32 %17465, %17463"
"  %17466 = add nuw nsw i32 %17465, %17463"
"  %17466 = add nuw nsw i32 %17465, %17463" -> "  %17468 = add nuw nsw i32 %17466, %17467"
"  %17467 = and i32 %17464, 134152192"
"  %17467 = and i32 %17464, 134152192" -> "  %17468 = add nuw nsw i32 %17466, %17467"
"  %17468 = add nuw nsw i32 %17466, %17467"
"  %17468 = add nuw nsw i32 %17466, %17467" -> "  %17472 = lshr i32 %17468, 16""  %17468 = add nuw nsw i32 %17466, %17467" -> "  %17470 = and i32 %17468, 65535"
"  %17469 = mul nuw i32 %17395, 62728"
"  %17469 = mul nuw i32 %17395, 62728" -> "  %17471 = add nuw i32 %17470, %17469"
"  %17470 = and i32 %17468, 65535"
"  %17470 = and i32 %17468, 65535" -> "  %17471 = add nuw i32 %17470, %17469"
"  %17471 = add nuw i32 %17470, %17469"
"  %17471 = add nuw i32 %17470, %17469" -> "  %17483 = and i32 %17471, 65535""  %17471 = add nuw i32 %17470, %17469" -> "  %17475 = lshr i32 %17471, 16"
"  %17472 = lshr i32 %17468, 16"
"  %17472 = lshr i32 %17468, 16" -> "  %17474 = add nuw i32 %17472, %17473"
"  %17473 = mul nuw i32 %17398, 62728"
"  %17473 = mul nuw i32 %17398, 62728" -> "  %17474 = add nuw i32 %17472, %17473"
"  %17474 = add nuw i32 %17472, %17473"
"  %17474 = add nuw i32 %17472, %17473" -> "  %17478 = and i32 %17474, -65536""  %17474 = add nuw i32 %17472, %17473" -> "  %17476 = and i32 %17474, 65535"
"  %17475 = lshr i32 %17471, 16"
"  %17475 = lshr i32 %17471, 16" -> "  %17477 = add nuw nsw i32 %17475, %17476"
"  %17476 = and i32 %17474, 65535"
"  %17476 = and i32 %17474, 65535" -> "  %17477 = add nuw nsw i32 %17475, %17476"
"  %17477 = add nuw nsw i32 %17475, %17476"
"  %17477 = add nuw nsw i32 %17475, %17476" -> "  %17479 = add nuw i32 %17477, %17478"
"  %17478 = and i32 %17474, -65536"
"  %17478 = and i32 %17474, -65536" -> "  %17479 = add nuw i32 %17477, %17478"
"  %17479 = add nuw i32 %17477, %17478"
"  %17479 = add nuw i32 %17477, %17478" -> "  %17487 = add nuw i32 %17479, %17486"
"  %17480 = and i32 %17430, 65535"
"  %17480 = and i32 %17430, 65535" -> "  %17482 = add nuw nsw i32 %17480, %17481"
"  %17481 = and i32 %17462, 65532"
"  %17481 = and i32 %17462, 65532" -> "  %17482 = add nuw nsw i32 %17480, %17481"
"  %17482 = add nuw nsw i32 %17480, %17481"
"  %17482 = add nuw nsw i32 %17480, %17481" -> "  %17493 = and i32 %17482, 65535""  %17482 = add nuw nsw i32 %17480, %17481" -> "  %17489 = lshr i32 %17482, 16"
"  %17483 = and i32 %17471, 65535"
"  %17483 = and i32 %17471, 65535" -> "  %17485 = add nuw nsw i32 %17484, %17483"
"  %17484 = lshr i32 %17430, 16"
"  %17484 = lshr i32 %17430, 16" -> "  %17485 = add nuw nsw i32 %17484, %17483"
"  %17485 = add nuw nsw i32 %17484, %17483"
"  %17485 = add nuw nsw i32 %17484, %17483" -> "  %17488 = and i32 %17485, 65535""  %17485 = add nuw nsw i32 %17484, %17483" -> "  %17486 = lshr i32 %17485, 16"
"  %17486 = lshr i32 %17485, 16"
"  %17486 = lshr i32 %17485, 16" -> "  %17487 = add nuw i32 %17479, %17486"
"  %17487 = add nuw i32 %17479, %17486"
"  %17487 = add nuw i32 %17479, %17486" -> "  %17492 = add nuw i32 %17487, %17491"
"  %17488 = and i32 %17485, 65535"
"  %17488 = and i32 %17485, 65535" -> "  %17490 = add nuw nsw i32 %17489, %17488"
"  %17489 = lshr i32 %17482, 16"
"  %17489 = lshr i32 %17482, 16" -> "  %17490 = add nuw nsw i32 %17489, %17488"
"  %17490 = add nuw nsw i32 %17489, %17488"
"  %17490 = add nuw nsw i32 %17489, %17488" -> "  %17496 = and i32 %17490, 65535""  %17490 = add nuw nsw i32 %17489, %17488" -> "  %17491 = lshr i32 %17490, 16"
"  %17491 = lshr i32 %17490, 16"
"  %17491 = lshr i32 %17490, 16" -> "  %17492 = add nuw i32 %17487, %17491"
"  %17492 = add nuw i32 %17487, %17491"
"  %17492 = add nuw i32 %17487, %17491" -> "  %17505 = and i32 %17492, -65536""  %17492 = add nuw i32 %17487, %17491" -> "  %17503 = and i32 %17492, 65535"
"  %17493 = and i32 %17482, 65535"
"  %17493 = and i32 %17482, 65535" -> "  %17495 = add nuw nsw i32 %17494, %17493"
"  %17494 = and i32 %17461, 65535"
"  %17494 = and i32 %17461, 65535" -> "  %17495 = add nuw nsw i32 %17494, %17493"
"  %17495 = add nuw nsw i32 %17494, %17493"
"  %17495 = add nuw nsw i32 %17494, %17493" -> "  %17536 = and i32 %17495, 65535""  %17495 = add nuw nsw i32 %17494, %17493" -> "  %17499 = lshr i32 %17495, 16"
"  %17496 = and i32 %17490, 65535"
"  %17496 = and i32 %17490, 65535" -> "  %17498 = add nuw nsw i32 %17496, %17497"
"  %17497 = lshr i32 %17461, 16"
"  %17497 = lshr i32 %17461, 16" -> "  %17498 = add nuw nsw i32 %17496, %17497"
"  %17498 = add nuw nsw i32 %17496, %17497"
"  %17498 = add nuw nsw i32 %17496, %17497" -> "  %17502 = lshr i32 %17498, 16""  %17498 = add nuw nsw i32 %17496, %17497" -> "  %17500 = and i32 %17498, 65535"
"  %17499 = lshr i32 %17495, 16"
"  %17499 = lshr i32 %17495, 16" -> "  %17501 = add nuw nsw i32 %17500, %17499"
"  %17500 = and i32 %17498, 65535"
"  %17500 = and i32 %17498, 65535" -> "  %17501 = add nuw nsw i32 %17500, %17499"
"  %17501 = add nuw nsw i32 %17500, %17499"
"  %17501 = add nuw nsw i32 %17500, %17499" -> "  %17543 = and i32 %17501, 65535""  %17501 = add nuw nsw i32 %17500, %17499" -> "  %17507 = lshr i32 %17501, 16"
"  %17502 = lshr i32 %17498, 16"
"  %17502 = lshr i32 %17498, 16" -> "  %17504 = add nuw nsw i32 %17502, %17503"
"  %17503 = and i32 %17492, 65535"
"  %17503 = and i32 %17492, 65535" -> "  %17504 = add nuw nsw i32 %17502, %17503"
"  %17504 = add nuw nsw i32 %17502, %17503"
"  %17504 = add nuw nsw i32 %17502, %17503" -> "  %17506 = add nuw i32 %17504, %17505"
"  %17505 = and i32 %17492, -65536"
"  %17505 = and i32 %17492, -65536" -> "  %17506 = add nuw i32 %17504, %17505"
"  %17506 = add nuw i32 %17504, %17505"
"  %17506 = add nuw i32 %17504, %17505" -> "  %17508 = add nuw i32 %17506, %17507"
"  %17507 = lshr i32 %17501, 16"
"  %17507 = lshr i32 %17501, 16" -> "  %17508 = add nuw i32 %17506, %17507"
"  %17508 = add nuw i32 %17506, %17507"
"  %17508 = add nuw i32 %17506, %17507" -> "  %17546 = add nuw i32 %17508, %17545"
"  %17509 = and i32 %17377, 65532"
"  %17509 = and i32 %17377, 65532" -> "  %17511 = add nuw nsw i32 %17510, %17509"
"  %17510 = and i32 %17361, 65535"
"  %17510 = and i32 %17361, 65535" -> "  %17511 = add nuw nsw i32 %17510, %17509"
"  %17511 = add nuw nsw i32 %17510, %17509"
"  %17511 = add nuw nsw i32 %17510, %17509" -> "  %17675 = and i32 %17511, 65535""  %17511 = add nuw nsw i32 %17510, %17509" -> "  %17515 = lshr i32 %17511, 16"
"  %17512 = and i32 %17386, 65535"
"  %17512 = and i32 %17386, 65535" -> "  %17514 = add nuw nsw i32 %17513, %17512"
"  %17513 = and i32 %17367, 65535"
"  %17513 = and i32 %17367, 65535" -> "  %17514 = add nuw nsw i32 %17513, %17512"
"  %17514 = add nuw nsw i32 %17513, %17512"
"  %17514 = add nuw nsw i32 %17513, %17512" -> "  %17518 = lshr i32 %17514, 16""  %17514 = add nuw nsw i32 %17513, %17512" -> "  %17516 = and i32 %17514, 65535"
"  %17515 = lshr i32 %17511, 16"
"  %17515 = lshr i32 %17511, 16" -> "  %17517 = add nuw nsw i32 %17516, %17515"
"  %17516 = and i32 %17514, 65535"
"  %17516 = and i32 %17514, 65535" -> "  %17517 = add nuw nsw i32 %17516, %17515"
"  %17517 = add nuw nsw i32 %17516, %17515"
"  %17517 = add nuw nsw i32 %17516, %17515" -> "  %17678 = and i32 %17517, 65535""  %17517 = add nuw nsw i32 %17516, %17515" -> "  %17519 = lshr i32 %17517, 16"
"  %17518 = lshr i32 %17514, 16"
"  %17518 = lshr i32 %17514, 16" -> "  %17530 = add nuw nsw i32 %17519, %17518"
"  %17519 = lshr i32 %17517, 16"
"  %17519 = lshr i32 %17517, 16" -> "  %17530 = add nuw nsw i32 %17519, %17518"
"  %17520 = and i32 %17374, 65535"
"  %17520 = and i32 %17374, 65535" -> "  %17522 = add nuw nsw i32 %17521, %17520"
"  %17521 = and i32 %17451, 65535"
"  %17521 = and i32 %17451, 65535" -> "  %17522 = add nuw nsw i32 %17521, %17520"
"  %17522 = add nuw nsw i32 %17521, %17520"
"  %17522 = add nuw nsw i32 %17521, %17520" -> "  %17529 = and i32 %17522, 65535""  %17522 = add nuw nsw i32 %17521, %17520" -> "  %17526 = lshr i32 %17522, 16"
"  %17523 = lshr i32 %17374, 16"
"  %17523 = lshr i32 %17374, 16" -> "  %17525 = add nuw nsw i32 %17524, %17523"
"  %17524 = and i32 %17459, 65535"
"  %17524 = and i32 %17459, 65535" -> "  %17525 = add nuw nsw i32 %17524, %17523"
"  %17525 = add nuw nsw i32 %17524, %17523"
"  %17525 = add nuw nsw i32 %17524, %17523" -> "  %17535 = lshr i32 %17525, 16""  %17525 = add nuw nsw i32 %17524, %17523" -> "  %17527 = and i32 %17525, 65535"
"  %17526 = lshr i32 %17522, 16"
"  %17526 = lshr i32 %17522, 16" -> "  %17528 = add nuw nsw i32 %17527, %17526"
"  %17527 = and i32 %17525, 65535"
"  %17527 = and i32 %17525, 65535" -> "  %17528 = add nuw nsw i32 %17527, %17526"
"  %17528 = add nuw nsw i32 %17527, %17526"
"  %17528 = add nuw nsw i32 %17527, %17526" -> "  %17538 = lshr i32 %17528, 16""  %17528 = add nuw nsw i32 %17527, %17526" -> "  %17533 = and i32 %17528, 65535"
"  %17529 = and i32 %17522, 65535"
"  %17529 = and i32 %17522, 65535" -> "  %17531 = add nuw nsw i32 %17530, %17529"
"  %17530 = add nuw nsw i32 %17519, %17518"
"  %17530 = add nuw nsw i32 %17519, %17518" -> "  %17531 = add nuw nsw i32 %17530, %17529"
"  %17531 = add nuw nsw i32 %17530, %17529"
"  %17531 = add nuw nsw i32 %17530, %17529" -> "  %17685 = and i32 %17531, 65535""  %17531 = add nuw nsw i32 %17530, %17529" -> "  %17532 = lshr i32 %17531, 16"
"  %17532 = lshr i32 %17531, 16"
"  %17532 = lshr i32 %17531, 16" -> "  %17534 = add nuw nsw i32 %17533, %17532"
"  %17533 = and i32 %17528, 65535"
"  %17533 = and i32 %17528, 65535" -> "  %17534 = add nuw nsw i32 %17533, %17532"
"  %17534 = add nuw nsw i32 %17533, %17532"
"  %17534 = add nuw nsw i32 %17533, %17532" -> "  %17689 = and i32 %17534, 65535""  %17534 = add nuw nsw i32 %17533, %17532" -> "  %17540 = lshr i32 %17534, 16"
"  %17535 = lshr i32 %17525, 16"
"  %17535 = lshr i32 %17525, 16" -> "  %17537 = add nuw nsw i32 %17536, %17535"
"  %17536 = and i32 %17495, 65535"
"  %17536 = and i32 %17495, 65535" -> "  %17537 = add nuw nsw i32 %17536, %17535"
"  %17537 = add nuw nsw i32 %17536, %17535"
"  %17537 = add nuw nsw i32 %17536, %17535" -> "  %17539 = add nuw nsw i32 %17537, %17538"
"  %17538 = lshr i32 %17528, 16"
"  %17538 = lshr i32 %17528, 16" -> "  %17539 = add nuw nsw i32 %17537, %17538"
"  %17539 = add nuw nsw i32 %17537, %17538"
"  %17539 = add nuw nsw i32 %17537, %17538" -> "  %17541 = add nuw nsw i32 %17539, %17540"
"  %17540 = lshr i32 %17534, 16"
"  %17540 = lshr i32 %17534, 16" -> "  %17541 = add nuw nsw i32 %17539, %17540"
"  %17541 = add nuw nsw i32 %17539, %17540"
"  %17541 = add nuw nsw i32 %17539, %17540" -> "  %17840 = and i32 %17541, 65535""  %17541 = add nuw nsw i32 %17539, %17540" -> "  %17542 = lshr i32 %17541, 16"
"  %17542 = lshr i32 %17541, 16"
"  %17542 = lshr i32 %17541, 16" -> "  %17544 = add nuw nsw i32 %17542, %17543"
"  %17543 = and i32 %17501, 65535"
"  %17543 = and i32 %17501, 65535" -> "  %17544 = add nuw nsw i32 %17542, %17543"
"  %17544 = add nuw nsw i32 %17542, %17543"
"  %17544 = add nuw nsw i32 %17542, %17543" -> "  %17843 = and i32 %17544, 65535""  %17544 = add nuw nsw i32 %17542, %17543" -> "  %17545 = lshr i32 %17544, 16"
"  %17545 = lshr i32 %17544, 16"
"  %17545 = lshr i32 %17544, 16" -> "  %17546 = add nuw i32 %17508, %17545"
"  %17546 = add nuw i32 %17508, %17545"
"  %17546 = add nuw i32 %17508, %17545" -> "  %17848 = and i32 %17546, 65535""  %17546 = add nuw i32 %17508, %17545" -> "  %17851 = lshr i32 %17546, 16"
"  %17547 = mul nuw nsw i32 %17241, 17857"
"  %17547 = mul nuw nsw i32 %17241, 17857" -> "  %17674 = and i32 %17547, 65535""  %17547 = mul nuw nsw i32 %17241, 17857" -> "  %17548 = lshr i32 %17547, 16"
"  %17548 = lshr i32 %17547, 16"
"  %17548 = lshr i32 %17547, 16" -> "  %17551 = add nuw nsw i32 %17550, %17548"
"  %17549 = mul nuw nsw i32 %17244, 17857"
"  %17549 = mul nuw nsw i32 %17244, 17857" -> "  %17552 = and i32 %17549, 2147418112""  %17549 = mul nuw nsw i32 %17244, 17857" -> "  %17550 = and i32 %17549, 65535"
"  %17550 = and i32 %17549, 65535"
"  %17550 = and i32 %17549, 65535" -> "  %17551 = add nuw nsw i32 %17550, %17548"
"  %17551 = add nuw nsw i32 %17550, %17548"
"  %17551 = add nuw nsw i32 %17550, %17548" -> "  %17553 = add nuw nsw i32 %17551, %17552"
"  %17552 = and i32 %17549, 2147418112"
"  %17552 = and i32 %17549, 2147418112" -> "  %17553 = add nuw nsw i32 %17551, %17552"
"  %17553 = add nuw nsw i32 %17551, %17552"
"  %17553 = add nuw nsw i32 %17551, %17552" -> "  %17557 = lshr i32 %17553, 16""  %17553 = add nuw nsw i32 %17551, %17552" -> "  %17555 = and i32 %17553, 65535"
"  %17554 = mul nuw i32 %17241, 46547"
"  %17554 = mul nuw i32 %17241, 46547" -> "  %17556 = add nuw i32 %17555, %17554"
"  %17555 = and i32 %17553, 65535"
"  %17555 = and i32 %17553, 65535" -> "  %17556 = add nuw i32 %17555, %17554"
"  %17556 = add nuw i32 %17555, %17554"
"  %17556 = add nuw i32 %17555, %17554" -> "  %17677 = and i32 %17556, 65535""  %17556 = add nuw i32 %17555, %17554" -> "  %17560 = lshr i32 %17556, 16"
"  %17557 = lshr i32 %17553, 16"
"  %17557 = lshr i32 %17553, 16" -> "  %17559 = add nuw i32 %17557, %17558"
"  %17558 = mul nuw i32 %17244, 46547"
"  %17558 = mul nuw i32 %17244, 46547" -> "  %17559 = add nuw i32 %17557, %17558"
"  %17559 = add nuw i32 %17557, %17558"
"  %17559 = add nuw i32 %17557, %17558" -> "  %17563 = and i32 %17559, -65536""  %17559 = add nuw i32 %17557, %17558" -> "  %17561 = and i32 %17559, 65535"
"  %17560 = lshr i32 %17556, 16"
"  %17560 = lshr i32 %17556, 16" -> "  %17562 = add nuw nsw i32 %17560, %17561"
"  %17561 = and i32 %17559, 65535"
"  %17561 = and i32 %17559, 65535" -> "  %17562 = add nuw nsw i32 %17560, %17561"
"  %17562 = add nuw nsw i32 %17560, %17561"
"  %17562 = add nuw nsw i32 %17560, %17561" -> "  %17564 = add nuw i32 %17562, %17563"
"  %17563 = and i32 %17559, -65536"
"  %17563 = and i32 %17559, -65536" -> "  %17564 = add nuw i32 %17562, %17563"
"  %17564 = add nuw i32 %17562, %17563"
"  %17564 = add nuw i32 %17562, %17563" -> "  %17587 = lshr i32 %17564, 16""  %17564 = add nuw i32 %17562, %17563" -> "  %17583 = and i32 %17564, 65535"
"  %17565 = mul nuw nsw i32 %17261, 17857"
"  %17565 = mul nuw nsw i32 %17261, 17857" -> "  %17584 = and i32 %17565, 65535""  %17565 = mul nuw nsw i32 %17261, 17857" -> "  %17566 = lshr i32 %17565, 16"
"  %17566 = lshr i32 %17565, 16"
"  %17566 = lshr i32 %17565, 16" -> "  %17569 = add nuw nsw i32 %17568, %17566"
"  %17567 = mul nuw nsw i32 %17264, 17857"
"  %17567 = mul nuw nsw i32 %17264, 17857" -> "  %17570 = and i32 %17567, 2147418112""  %17567 = mul nuw nsw i32 %17264, 17857" -> "  %17568 = and i32 %17567, 65535"
"  %17568 = and i32 %17567, 65535"
"  %17568 = and i32 %17567, 65535" -> "  %17569 = add nuw nsw i32 %17568, %17566"
"  %17569 = add nuw nsw i32 %17568, %17566"
"  %17569 = add nuw nsw i32 %17568, %17566" -> "  %17571 = add nuw nsw i32 %17569, %17570"
"  %17570 = and i32 %17567, 2147418112"
"  %17570 = and i32 %17567, 2147418112" -> "  %17571 = add nuw nsw i32 %17569, %17570"
"  %17571 = add nuw nsw i32 %17569, %17570"
"  %17571 = add nuw nsw i32 %17569, %17570" -> "  %17575 = lshr i32 %17571, 16""  %17571 = add nuw nsw i32 %17569, %17570" -> "  %17573 = and i32 %17571, 65535"
"  %17572 = mul nuw i32 %17261, 46547"
"  %17572 = mul nuw i32 %17261, 46547" -> "  %17574 = add nuw i32 %17573, %17572"
"  %17573 = and i32 %17571, 65535"
"  %17573 = and i32 %17571, 65535" -> "  %17574 = add nuw i32 %17573, %17572"
"  %17574 = add nuw i32 %17573, %17572"
"  %17574 = add nuw i32 %17573, %17572" -> "  %17586 = and i32 %17574, 65535""  %17574 = add nuw i32 %17573, %17572" -> "  %17578 = lshr i32 %17574, 16"
"  %17575 = lshr i32 %17571, 16"
"  %17575 = lshr i32 %17571, 16" -> "  %17577 = add nuw i32 %17575, %17576"
"  %17576 = mul nuw i32 %17264, 46547"
"  %17576 = mul nuw i32 %17264, 46547" -> "  %17577 = add nuw i32 %17575, %17576"
"  %17577 = add nuw i32 %17575, %17576"
"  %17577 = add nuw i32 %17575, %17576" -> "  %17581 = and i32 %17577, -65536""  %17577 = add nuw i32 %17575, %17576" -> "  %17579 = and i32 %17577, 65535"
"  %17578 = lshr i32 %17574, 16"
"  %17578 = lshr i32 %17574, 16" -> "  %17580 = add nuw nsw i32 %17578, %17579"
"  %17579 = and i32 %17577, 65535"
"  %17579 = and i32 %17577, 65535" -> "  %17580 = add nuw nsw i32 %17578, %17579"
"  %17580 = add nuw nsw i32 %17578, %17579"
"  %17580 = add nuw nsw i32 %17578, %17579" -> "  %17582 = add nuw i32 %17580, %17581"
"  %17581 = and i32 %17577, -65536"
"  %17581 = and i32 %17577, -65536" -> "  %17582 = add nuw i32 %17580, %17581"
"  %17582 = add nuw i32 %17580, %17581"
"  %17582 = add nuw i32 %17580, %17581" -> "  %17590 = add nuw i32 %17582, %17589"
"  %17583 = and i32 %17564, 65535"
"  %17583 = and i32 %17564, 65535" -> "  %17585 = add nuw nsw i32 %17583, %17584"
"  %17584 = and i32 %17565, 65535"
"  %17584 = and i32 %17565, 65535" -> "  %17585 = add nuw nsw i32 %17583, %17584"
"  %17585 = add nuw nsw i32 %17583, %17584"
"  %17585 = add nuw nsw i32 %17583, %17584" -> "  %17614 = and i32 %17585, 65535""  %17585 = add nuw nsw i32 %17583, %17584" -> "  %17592 = lshr i32 %17585, 16"
"  %17586 = and i32 %17574, 65535"
"  %17586 = and i32 %17574, 65535" -> "  %17588 = add nuw nsw i32 %17586, %17587"
"  %17587 = lshr i32 %17564, 16"
"  %17587 = lshr i32 %17564, 16" -> "  %17588 = add nuw nsw i32 %17586, %17587"
"  %17588 = add nuw nsw i32 %17586, %17587"
"  %17588 = add nuw nsw i32 %17586, %17587" -> "  %17591 = and i32 %17588, 65535""  %17588 = add nuw nsw i32 %17586, %17587" -> "  %17589 = lshr i32 %17588, 16"
"  %17589 = lshr i32 %17588, 16"
"  %17589 = lshr i32 %17588, 16" -> "  %17590 = add nuw i32 %17582, %17589"
"  %17590 = add nuw i32 %17582, %17589"
"  %17590 = add nuw i32 %17582, %17589" -> "  %17595 = add nuw i32 %17590, %17594"
"  %17591 = and i32 %17588, 65535"
"  %17591 = and i32 %17588, 65535" -> "  %17593 = add nuw nsw i32 %17591, %17592"
"  %17592 = lshr i32 %17585, 16"
"  %17592 = lshr i32 %17585, 16" -> "  %17593 = add nuw nsw i32 %17591, %17592"
"  %17593 = add nuw nsw i32 %17591, %17592"
"  %17593 = add nuw nsw i32 %17591, %17592" -> "  %17617 = and i32 %17593, 65535""  %17593 = add nuw nsw i32 %17591, %17592" -> "  %17594 = lshr i32 %17593, 16"
"  %17594 = lshr i32 %17593, 16"
"  %17594 = lshr i32 %17593, 16" -> "  %17595 = add nuw i32 %17590, %17594"
"  %17595 = add nuw i32 %17590, %17594"
"  %17595 = add nuw i32 %17590, %17594" -> "  %17649 = lshr i32 %17595, 16""  %17595 = add nuw i32 %17590, %17594" -> "  %17645 = and i32 %17595, 65535"
"  %17596 = mul nuw nsw i32 %17241, 31112"
"  %17596 = mul nuw nsw i32 %17241, 31112" -> "  %17615 = and i32 %17596, 65528""  %17596 = mul nuw nsw i32 %17241, 31112" -> "  %17597 = lshr i32 %17596, 16"
"  %17597 = lshr i32 %17596, 16"
"  %17597 = lshr i32 %17596, 16" -> "  %17600 = add nuw nsw i32 %17599, %17597"
"  %17598 = mul nuw nsw i32 %17244, 31112"
"  %17598 = mul nuw nsw i32 %17244, 31112" -> "  %17601 = and i32 %17598, 2147418112""  %17598 = mul nuw nsw i32 %17244, 31112" -> "  %17599 = and i32 %17598, 65528"
"  %17599 = and i32 %17598, 65528"
"  %17599 = and i32 %17598, 65528" -> "  %17600 = add nuw nsw i32 %17599, %17597"
"  %17600 = add nuw nsw i32 %17599, %17597"
"  %17600 = add nuw nsw i32 %17599, %17597" -> "  %17602 = add nuw nsw i32 %17600, %17601"
"  %17601 = and i32 %17598, 2147418112"
"  %17601 = and i32 %17598, 2147418112" -> "  %17602 = add nuw nsw i32 %17600, %17601"
"  %17602 = add nuw nsw i32 %17600, %17601"
"  %17602 = add nuw nsw i32 %17600, %17601" -> "  %17606 = lshr i32 %17602, 16""  %17602 = add nuw nsw i32 %17600, %17601" -> "  %17604 = and i32 %17602, 65535"
"  %17603 = mul nuw i32 %17241, 42170"
"  %17603 = mul nuw i32 %17241, 42170" -> "  %17605 = add nuw i32 %17604, %17603"
"  %17604 = and i32 %17602, 65535"
"  %17604 = and i32 %17602, 65535" -> "  %17605 = add nuw i32 %17604, %17603"
"  %17605 = add nuw i32 %17604, %17603"
"  %17605 = add nuw i32 %17604, %17603" -> "  %17618 = and i32 %17605, 65535""  %17605 = add nuw i32 %17604, %17603" -> "  %17609 = lshr i32 %17605, 16"
"  %17606 = lshr i32 %17602, 16"
"  %17606 = lshr i32 %17602, 16" -> "  %17608 = add nuw i32 %17606, %17607"
"  %17607 = mul nuw i32 %17244, 42170"
"  %17607 = mul nuw i32 %17244, 42170" -> "  %17608 = add nuw i32 %17606, %17607"
"  %17608 = add nuw i32 %17606, %17607"
"  %17608 = add nuw i32 %17606, %17607" -> "  %17612 = and i32 %17608, -65536""  %17608 = add nuw i32 %17606, %17607" -> "  %17610 = and i32 %17608, 65535"
"  %17609 = lshr i32 %17605, 16"
"  %17609 = lshr i32 %17605, 16" -> "  %17611 = add nuw nsw i32 %17609, %17610"
"  %17610 = and i32 %17608, 65535"
"  %17610 = and i32 %17608, 65535" -> "  %17611 = add nuw nsw i32 %17609, %17610"
"  %17611 = add nuw nsw i32 %17609, %17610"
"  %17611 = add nuw nsw i32 %17609, %17610" -> "  %17613 = add nuw i32 %17611, %17612"
"  %17612 = and i32 %17608, -65536"
"  %17612 = and i32 %17608, -65536" -> "  %17613 = add nuw i32 %17611, %17612"
"  %17613 = add nuw i32 %17611, %17612"
"  %17613 = add nuw i32 %17611, %17612" -> "  %17621 = add nuw i32 %17613, %17620"
"  %17614 = and i32 %17585, 65535"
"  %17614 = and i32 %17585, 65535" -> "  %17616 = add nuw nsw i32 %17614, %17615"
"  %17615 = and i32 %17596, 65528"
"  %17615 = and i32 %17596, 65528" -> "  %17616 = add nuw nsw i32 %17614, %17615"
"  %17616 = add nuw nsw i32 %17614, %17615"
"  %17616 = add nuw nsw i32 %17614, %17615" -> "  %17686 = and i32 %17616, 65535""  %17616 = add nuw nsw i32 %17614, %17615" -> "  %17623 = lshr i32 %17616, 16"
"  %17617 = and i32 %17593, 65535"
"  %17617 = and i32 %17593, 65535" -> "  %17619 = add nuw nsw i32 %17617, %17618"
"  %17618 = and i32 %17605, 65535"
"  %17618 = and i32 %17605, 65535" -> "  %17619 = add nuw nsw i32 %17617, %17618"
"  %17619 = add nuw nsw i32 %17617, %17618"
"  %17619 = add nuw nsw i32 %17617, %17618" -> "  %17622 = and i32 %17619, 65535""  %17619 = add nuw nsw i32 %17617, %17618" -> "  %17620 = lshr i32 %17619, 16"
"  %17620 = lshr i32 %17619, 16"
"  %17620 = lshr i32 %17619, 16" -> "  %17621 = add nuw i32 %17613, %17620"
"  %17621 = add nuw i32 %17613, %17620"
"  %17621 = add nuw i32 %17613, %17620" -> "  %17626 = add nuw i32 %17621, %17625"
"  %17622 = and i32 %17619, 65535"
"  %17622 = and i32 %17619, 65535" -> "  %17624 = add nuw nsw i32 %17622, %17623"
"  %17623 = lshr i32 %17616, 16"
"  %17623 = lshr i32 %17616, 16" -> "  %17624 = add nuw nsw i32 %17622, %17623"
"  %17624 = add nuw nsw i32 %17622, %17623"
"  %17624 = add nuw nsw i32 %17622, %17623" -> "  %17688 = and i32 %17624, 65535""  %17624 = add nuw nsw i32 %17622, %17623" -> "  %17625 = lshr i32 %17624, 16"
"  %17625 = lshr i32 %17624, 16"
"  %17625 = lshr i32 %17624, 16" -> "  %17626 = add nuw i32 %17621, %17625"
"  %17626 = add nuw i32 %17621, %17625"
"  %17626 = add nuw i32 %17621, %17625" -> "  %17662 = lshr i32 %17626, 16""  %17626 = add nuw i32 %17621, %17625" -> "  %17659 = and i32 %17626, 65535"
"  %17627 = mul nuw nsw i32 %17261, 31112"
"  %17627 = mul nuw nsw i32 %17261, 31112" -> "  %17646 = and i32 %17627, 65528""  %17627 = mul nuw nsw i32 %17261, 31112" -> "  %17628 = lshr i32 %17627, 16"
"  %17628 = lshr i32 %17627, 16"
"  %17628 = lshr i32 %17627, 16" -> "  %17631 = add nuw nsw i32 %17630, %17628"
"  %17629 = mul nuw nsw i32 %17264, 31112"
"  %17629 = mul nuw nsw i32 %17264, 31112" -> "  %17632 = and i32 %17629, 2147418112""  %17629 = mul nuw nsw i32 %17264, 31112" -> "  %17630 = and i32 %17629, 65528"
"  %17630 = and i32 %17629, 65528"
"  %17630 = and i32 %17629, 65528" -> "  %17631 = add nuw nsw i32 %17630, %17628"
"  %17631 = add nuw nsw i32 %17630, %17628"
"  %17631 = add nuw nsw i32 %17630, %17628" -> "  %17633 = add nuw nsw i32 %17631, %17632"
"  %17632 = and i32 %17629, 2147418112"
"  %17632 = and i32 %17629, 2147418112" -> "  %17633 = add nuw nsw i32 %17631, %17632"
"  %17633 = add nuw nsw i32 %17631, %17632"
"  %17633 = add nuw nsw i32 %17631, %17632" -> "  %17637 = lshr i32 %17633, 16""  %17633 = add nuw nsw i32 %17631, %17632" -> "  %17635 = and i32 %17633, 65535"
"  %17634 = mul nuw i32 %17261, 42170"
"  %17634 = mul nuw i32 %17261, 42170" -> "  %17636 = add nuw i32 %17635, %17634"
"  %17635 = and i32 %17633, 65535"
"  %17635 = and i32 %17633, 65535" -> "  %17636 = add nuw i32 %17635, %17634"
"  %17636 = add nuw i32 %17635, %17634"
"  %17636 = add nuw i32 %17635, %17634" -> "  %17648 = and i32 %17636, 65535""  %17636 = add nuw i32 %17635, %17634" -> "  %17640 = lshr i32 %17636, 16"
"  %17637 = lshr i32 %17633, 16"
"  %17637 = lshr i32 %17633, 16" -> "  %17639 = add nuw i32 %17637, %17638"
"  %17638 = mul nuw i32 %17264, 42170"
"  %17638 = mul nuw i32 %17264, 42170" -> "  %17639 = add nuw i32 %17637, %17638"
"  %17639 = add nuw i32 %17637, %17638"
"  %17639 = add nuw i32 %17637, %17638" -> "  %17643 = and i32 %17639, -65536""  %17639 = add nuw i32 %17637, %17638" -> "  %17641 = and i32 %17639, 65535"
"  %17640 = lshr i32 %17636, 16"
"  %17640 = lshr i32 %17636, 16" -> "  %17642 = add nuw nsw i32 %17640, %17641"
"  %17641 = and i32 %17639, 65535"
"  %17641 = and i32 %17639, 65535" -> "  %17642 = add nuw nsw i32 %17640, %17641"
"  %17642 = add nuw nsw i32 %17640, %17641"
"  %17642 = add nuw nsw i32 %17640, %17641" -> "  %17644 = add nuw i32 %17642, %17643"
"  %17643 = and i32 %17639, -65536"
"  %17643 = and i32 %17639, -65536" -> "  %17644 = add nuw i32 %17642, %17643"
"  %17644 = add nuw i32 %17642, %17643"
"  %17644 = add nuw i32 %17642, %17643" -> "  %17652 = add nuw i32 %17644, %17651"
"  %17645 = and i32 %17595, 65535"
"  %17645 = and i32 %17595, 65535" -> "  %17647 = add nuw nsw i32 %17645, %17646"
"  %17646 = and i32 %17627, 65528"
"  %17646 = and i32 %17627, 65528" -> "  %17647 = add nuw nsw i32 %17645, %17646"
"  %17647 = add nuw nsw i32 %17645, %17646"
"  %17647 = add nuw nsw i32 %17645, %17646" -> "  %17658 = and i32 %17647, 65535""  %17647 = add nuw nsw i32 %17645, %17646" -> "  %17654 = lshr i32 %17647, 16"
"  %17648 = and i32 %17636, 65535"
"  %17648 = and i32 %17636, 65535" -> "  %17650 = add nuw nsw i32 %17649, %17648"
"  %17649 = lshr i32 %17595, 16"
"  %17649 = lshr i32 %17595, 16" -> "  %17650 = add nuw nsw i32 %17649, %17648"
"  %17650 = add nuw nsw i32 %17649, %17648"
"  %17650 = add nuw nsw i32 %17649, %17648" -> "  %17653 = and i32 %17650, 65535""  %17650 = add nuw nsw i32 %17649, %17648" -> "  %17651 = lshr i32 %17650, 16"
"  %17651 = lshr i32 %17650, 16"
"  %17651 = lshr i32 %17650, 16" -> "  %17652 = add nuw i32 %17644, %17651"
"  %17652 = add nuw i32 %17644, %17651"
"  %17652 = add nuw i32 %17644, %17651" -> "  %17657 = add nuw i32 %17652, %17656"
"  %17653 = and i32 %17650, 65535"
"  %17653 = and i32 %17650, 65535" -> "  %17655 = add nuw nsw i32 %17654, %17653"
"  %17654 = lshr i32 %17647, 16"
"  %17654 = lshr i32 %17647, 16" -> "  %17655 = add nuw nsw i32 %17654, %17653"
"  %17655 = add nuw nsw i32 %17654, %17653"
"  %17655 = add nuw nsw i32 %17654, %17653" -> "  %17661 = and i32 %17655, 65535""  %17655 = add nuw nsw i32 %17654, %17653" -> "  %17656 = lshr i32 %17655, 16"
"  %17656 = lshr i32 %17655, 16"
"  %17656 = lshr i32 %17655, 16" -> "  %17657 = add nuw i32 %17652, %17656"
"  %17657 = add nuw i32 %17652, %17656"
"  %17657 = add nuw i32 %17652, %17656" -> "  %17670 = and i32 %17657, -65536""  %17657 = add nuw i32 %17652, %17656" -> "  %17668 = and i32 %17657, 65535"
"  %17658 = and i32 %17647, 65535"
"  %17658 = and i32 %17647, 65535" -> "  %17660 = add nuw nsw i32 %17659, %17658"
"  %17659 = and i32 %17626, 65535"
"  %17659 = and i32 %17626, 65535" -> "  %17660 = add nuw nsw i32 %17659, %17658"
"  %17660 = add nuw nsw i32 %17659, %17658"
"  %17660 = add nuw nsw i32 %17659, %17658" -> "  %17701 = and i32 %17660, 65535""  %17660 = add nuw nsw i32 %17659, %17658" -> "  %17664 = lshr i32 %17660, 16"
"  %17661 = and i32 %17655, 65535"
"  %17661 = and i32 %17655, 65535" -> "  %17663 = add nuw nsw i32 %17662, %17661"
"  %17662 = lshr i32 %17626, 16"
"  %17662 = lshr i32 %17626, 16" -> "  %17663 = add nuw nsw i32 %17662, %17661"
"  %17663 = add nuw nsw i32 %17662, %17661"
"  %17663 = add nuw nsw i32 %17662, %17661" -> "  %17667 = lshr i32 %17663, 16""  %17663 = add nuw nsw i32 %17662, %17661" -> "  %17665 = and i32 %17663, 65535"
"  %17664 = lshr i32 %17660, 16"
"  %17664 = lshr i32 %17660, 16" -> "  %17666 = add nuw nsw i32 %17664, %17665"
"  %17665 = and i32 %17663, 65535"
"  %17665 = and i32 %17663, 65535" -> "  %17666 = add nuw nsw i32 %17664, %17665"
"  %17666 = add nuw nsw i32 %17664, %17665"
"  %17666 = add nuw nsw i32 %17664, %17665" -> "  %17708 = and i32 %17666, 65535""  %17666 = add nuw nsw i32 %17664, %17665" -> "  %17672 = lshr i32 %17666, 16"
"  %17667 = lshr i32 %17663, 16"
"  %17667 = lshr i32 %17663, 16" -> "  %17669 = add nuw nsw i32 %17667, %17668"
"  %17668 = and i32 %17657, 65535"
"  %17668 = and i32 %17657, 65535" -> "  %17669 = add nuw nsw i32 %17667, %17668"
"  %17669 = add nuw nsw i32 %17667, %17668"
"  %17669 = add nuw nsw i32 %17667, %17668" -> "  %17671 = add nuw i32 %17669, %17670"
"  %17670 = and i32 %17657, -65536"
"  %17670 = and i32 %17657, -65536" -> "  %17671 = add nuw i32 %17669, %17670"
"  %17671 = add nuw i32 %17669, %17670"
"  %17671 = add nuw i32 %17669, %17670" -> "  %17673 = add nuw i32 %17671, %17672"
"  %17672 = lshr i32 %17666, 16"
"  %17672 = lshr i32 %17666, 16" -> "  %17673 = add nuw i32 %17671, %17672"
"  %17673 = add nuw i32 %17671, %17672"
"  %17673 = add nuw i32 %17671, %17672" -> "  %17711 = add nuw i32 %17673, %17710"
"  %17674 = and i32 %17547, 65535"
"  %17674 = and i32 %17547, 65535" -> "  %17676 = add nuw nsw i32 %17675, %17674"
"  %17675 = and i32 %17511, 65535"
"  %17675 = and i32 %17511, 65535" -> "  %17676 = add nuw nsw i32 %17675, %17674"
"  %17676 = add nuw nsw i32 %17675, %17674"
"  %17676 = add nuw nsw i32 %17675, %17674" -> "  %17680 = lshr i32 %17676, 16"
"  %17677 = and i32 %17556, 65535"
"  %17677 = and i32 %17556, 65535" -> "  %17679 = add nuw nsw i32 %17678, %17677"
"  %17678 = and i32 %17517, 65535"
"  %17678 = and i32 %17517, 65535" -> "  %17679 = add nuw nsw i32 %17678, %17677"
"  %17679 = add nuw nsw i32 %17678, %17677"
"  %17679 = add nuw nsw i32 %17678, %17677" -> "  %17683 = lshr i32 %17679, 16""  %17679 = add nuw nsw i32 %17678, %17677" -> "  %17681 = and i32 %17679, 65535"
"  %17680 = lshr i32 %17676, 16"
"  %17680 = lshr i32 %17676, 16" -> "  %17682 = add nuw nsw i32 %17681, %17680"
"  %17681 = and i32 %17679, 65535"
"  %17681 = and i32 %17679, 65535" -> "  %17682 = add nuw nsw i32 %17681, %17680"
"  %17682 = add nuw nsw i32 %17681, %17680"
"  %17682 = add nuw nsw i32 %17681, %17680" -> "  %17684 = lshr i32 %17682, 16"
"  %17683 = lshr i32 %17679, 16"
"  %17683 = lshr i32 %17679, 16" -> "  %17695 = add nuw nsw i32 %17684, %17683"
"  %17684 = lshr i32 %17682, 16"
"  %17684 = lshr i32 %17682, 16" -> "  %17695 = add nuw nsw i32 %17684, %17683"
"  %17685 = and i32 %17531, 65535"
"  %17685 = and i32 %17531, 65535" -> "  %17687 = add nuw nsw i32 %17685, %17686"
"  %17686 = and i32 %17616, 65535"
"  %17686 = and i32 %17616, 65535" -> "  %17687 = add nuw nsw i32 %17685, %17686"
"  %17687 = add nuw nsw i32 %17685, %17686"
"  %17687 = add nuw nsw i32 %17685, %17686" -> "  %17694 = and i32 %17687, 65535""  %17687 = add nuw nsw i32 %17685, %17686" -> "  %17691 = lshr i32 %17687, 16"
"  %17688 = and i32 %17624, 65535"
"  %17688 = and i32 %17624, 65535" -> "  %17690 = add nuw nsw i32 %17689, %17688"
"  %17689 = and i32 %17534, 65535"
"  %17689 = and i32 %17534, 65535" -> "  %17690 = add nuw nsw i32 %17689, %17688"
"  %17690 = add nuw nsw i32 %17689, %17688"
"  %17690 = add nuw nsw i32 %17689, %17688" -> "  %17700 = lshr i32 %17690, 16""  %17690 = add nuw nsw i32 %17689, %17688" -> "  %17692 = and i32 %17690, 65535"
"  %17691 = lshr i32 %17687, 16"
"  %17691 = lshr i32 %17687, 16" -> "  %17693 = add nuw nsw i32 %17692, %17691"
"  %17692 = and i32 %17690, 65535"
"  %17692 = and i32 %17690, 65535" -> "  %17693 = add nuw nsw i32 %17692, %17691"
"  %17693 = add nuw nsw i32 %17692, %17691"
"  %17693 = add nuw nsw i32 %17692, %17691" -> "  %17703 = lshr i32 %17693, 16""  %17693 = add nuw nsw i32 %17692, %17691" -> "  %17698 = and i32 %17693, 65535"
"  %17694 = and i32 %17687, 65535"
"  %17694 = and i32 %17687, 65535" -> "  %17696 = add nuw nsw i32 %17695, %17694"
"  %17695 = add nuw nsw i32 %17684, %17683"
"  %17695 = add nuw nsw i32 %17684, %17683" -> "  %17696 = add nuw nsw i32 %17695, %17694"
"  %17696 = add nuw nsw i32 %17695, %17694"
"  %17696 = add nuw nsw i32 %17695, %17694" -> "  %17697 = lshr i32 %17696, 16"
"  %17697 = lshr i32 %17696, 16"
"  %17697 = lshr i32 %17696, 16" -> "  %17699 = add nuw nsw i32 %17698, %17697"
"  %17698 = and i32 %17693, 65535"
"  %17698 = and i32 %17693, 65535" -> "  %17699 = add nuw nsw i32 %17698, %17697"
"  %17699 = add nuw nsw i32 %17698, %17697"
"  %17699 = add nuw nsw i32 %17698, %17697" -> "  %17705 = lshr i32 %17699, 16"
"  %17700 = lshr i32 %17690, 16"
"  %17700 = lshr i32 %17690, 16" -> "  %17702 = add nuw nsw i32 %17700, %17701"
"  %17701 = and i32 %17660, 65535"
"  %17701 = and i32 %17660, 65535" -> "  %17702 = add nuw nsw i32 %17700, %17701"
"  %17702 = add nuw nsw i32 %17700, %17701"
"  %17702 = add nuw nsw i32 %17700, %17701" -> "  %17704 = add nuw nsw i32 %17702, %17703"
"  %17703 = lshr i32 %17693, 16"
"  %17703 = lshr i32 %17693, 16" -> "  %17704 = add nuw nsw i32 %17702, %17703"
"  %17704 = add nuw nsw i32 %17702, %17703"
"  %17704 = add nuw nsw i32 %17702, %17703" -> "  %17706 = add nuw nsw i32 %17704, %17705"
"  %17705 = lshr i32 %17699, 16"
"  %17705 = lshr i32 %17699, 16" -> "  %17706 = add nuw nsw i32 %17704, %17705"
"  %17706 = add nuw nsw i32 %17704, %17705"
"  %17706 = add nuw nsw i32 %17704, %17705" -> "  %17878 = and i32 %17706, 65535""  %17706 = add nuw nsw i32 %17704, %17705" -> "  %17707 = lshr i32 %17706, 16"
"  %17707 = lshr i32 %17706, 16"
"  %17707 = lshr i32 %17706, 16" -> "  %17709 = add nuw nsw i32 %17707, %17708"
"  %17708 = and i32 %17666, 65535"
"  %17708 = and i32 %17666, 65535" -> "  %17709 = add nuw nsw i32 %17707, %17708"
"  %17709 = add nuw nsw i32 %17707, %17708"
"  %17709 = add nuw nsw i32 %17707, %17708" -> "  %17881 = and i32 %17709, 65535""  %17709 = add nuw nsw i32 %17707, %17708" -> "  %17710 = lshr i32 %17709, 16"
"  %17710 = lshr i32 %17709, 16"
"  %17710 = lshr i32 %17709, 16" -> "  %17711 = add nuw i32 %17673, %17710"
"  %17711 = add nuw i32 %17673, %17710"
"  %17711 = add nuw i32 %17673, %17710" -> "  %17887 = and i32 %17711, 65535""  %17711 = add nuw i32 %17673, %17710" -> "  %17890 = lshr i32 %17711, 16"
"  %17712 = mul nuw nsw i32 %17375, 17857"
"  %17712 = mul nuw nsw i32 %17375, 17857" -> "  %17839 = and i32 %17712, 65535""  %17712 = mul nuw nsw i32 %17375, 17857" -> "  %17713 = lshr i32 %17712, 16"
"  %17713 = lshr i32 %17712, 16"
"  %17713 = lshr i32 %17712, 16" -> "  %17716 = add nuw nsw i32 %17715, %17713"
"  %17714 = mul nuw nsw i32 %17376, 17857"
"  %17714 = mul nuw nsw i32 %17376, 17857" -> "  %17717 = and i32 %17714, 2147418112""  %17714 = mul nuw nsw i32 %17376, 17857" -> "  %17715 = and i32 %17714, 65535"
"  %17715 = and i32 %17714, 65535"
"  %17715 = and i32 %17714, 65535" -> "  %17716 = add nuw nsw i32 %17715, %17713"
"  %17716 = add nuw nsw i32 %17715, %17713"
"  %17716 = add nuw nsw i32 %17715, %17713" -> "  %17718 = add nuw nsw i32 %17716, %17717"
"  %17717 = and i32 %17714, 2147418112"
"  %17717 = and i32 %17714, 2147418112" -> "  %17718 = add nuw nsw i32 %17716, %17717"
"  %17718 = add nuw nsw i32 %17716, %17717"
"  %17718 = add nuw nsw i32 %17716, %17717" -> "  %17722 = lshr i32 %17718, 16""  %17718 = add nuw nsw i32 %17716, %17717" -> "  %17720 = and i32 %17718, 65535"
"  %17719 = mul nuw i32 %17375, 46547"
"  %17719 = mul nuw i32 %17375, 46547" -> "  %17721 = add nuw i32 %17720, %17719"
"  %17720 = and i32 %17718, 65535"
"  %17720 = and i32 %17718, 65535" -> "  %17721 = add nuw i32 %17720, %17719"
"  %17721 = add nuw i32 %17720, %17719"
"  %17721 = add nuw i32 %17720, %17719" -> "  %17842 = and i32 %17721, 65535""  %17721 = add nuw i32 %17720, %17719" -> "  %17725 = lshr i32 %17721, 16"
"  %17722 = lshr i32 %17718, 16"
"  %17722 = lshr i32 %17718, 16" -> "  %17724 = add nuw i32 %17722, %17723"
"  %17723 = mul nuw i32 %17376, 46547"
"  %17723 = mul nuw i32 %17376, 46547" -> "  %17724 = add nuw i32 %17722, %17723"
"  %17724 = add nuw i32 %17722, %17723"
"  %17724 = add nuw i32 %17722, %17723" -> "  %17728 = and i32 %17724, -65536""  %17724 = add nuw i32 %17722, %17723" -> "  %17726 = and i32 %17724, 65535"
"  %17725 = lshr i32 %17721, 16"
"  %17725 = lshr i32 %17721, 16" -> "  %17727 = add nuw nsw i32 %17725, %17726"
"  %17726 = and i32 %17724, 65535"
"  %17726 = and i32 %17724, 65535" -> "  %17727 = add nuw nsw i32 %17725, %17726"
"  %17727 = add nuw nsw i32 %17725, %17726"
"  %17727 = add nuw nsw i32 %17725, %17726" -> "  %17729 = add nuw i32 %17727, %17728"
"  %17728 = and i32 %17724, -65536"
"  %17728 = and i32 %17724, -65536" -> "  %17729 = add nuw i32 %17727, %17728"
"  %17729 = add nuw i32 %17727, %17728"
"  %17729 = add nuw i32 %17727, %17728" -> "  %17752 = lshr i32 %17729, 16""  %17729 = add nuw i32 %17727, %17728" -> "  %17748 = and i32 %17729, 65535"
"  %17730 = mul nuw nsw i32 %17395, 17857"
"  %17730 = mul nuw nsw i32 %17395, 17857" -> "  %17749 = and i32 %17730, 65535""  %17730 = mul nuw nsw i32 %17395, 17857" -> "  %17731 = lshr i32 %17730, 16"
"  %17731 = lshr i32 %17730, 16"
"  %17731 = lshr i32 %17730, 16" -> "  %17734 = add nuw nsw i32 %17733, %17731"
"  %17732 = mul nuw nsw i32 %17398, 17857"
"  %17732 = mul nuw nsw i32 %17398, 17857" -> "  %17735 = and i32 %17732, 2147418112""  %17732 = mul nuw nsw i32 %17398, 17857" -> "  %17733 = and i32 %17732, 65535"
"  %17733 = and i32 %17732, 65535"
"  %17733 = and i32 %17732, 65535" -> "  %17734 = add nuw nsw i32 %17733, %17731"
"  %17734 = add nuw nsw i32 %17733, %17731"
"  %17734 = add nuw nsw i32 %17733, %17731" -> "  %17736 = add nuw nsw i32 %17734, %17735"
"  %17735 = and i32 %17732, 2147418112"
"  %17735 = and i32 %17732, 2147418112" -> "  %17736 = add nuw nsw i32 %17734, %17735"
"  %17736 = add nuw nsw i32 %17734, %17735"
"  %17736 = add nuw nsw i32 %17734, %17735" -> "  %17740 = lshr i32 %17736, 16""  %17736 = add nuw nsw i32 %17734, %17735" -> "  %17738 = and i32 %17736, 65535"
"  %17737 = mul nuw i32 %17395, 46547"
"  %17737 = mul nuw i32 %17395, 46547" -> "  %17739 = add nuw i32 %17738, %17737"
"  %17738 = and i32 %17736, 65535"
"  %17738 = and i32 %17736, 65535" -> "  %17739 = add nuw i32 %17738, %17737"
"  %17739 = add nuw i32 %17738, %17737"
"  %17739 = add nuw i32 %17738, %17737" -> "  %17751 = and i32 %17739, 65535""  %17739 = add nuw i32 %17738, %17737" -> "  %17743 = lshr i32 %17739, 16"
"  %17740 = lshr i32 %17736, 16"
"  %17740 = lshr i32 %17736, 16" -> "  %17742 = add nuw i32 %17740, %17741"
"  %17741 = mul nuw i32 %17398, 46547"
"  %17741 = mul nuw i32 %17398, 46547" -> "  %17742 = add nuw i32 %17740, %17741"
"  %17742 = add nuw i32 %17740, %17741"
"  %17742 = add nuw i32 %17740, %17741" -> "  %17746 = and i32 %17742, -65536""  %17742 = add nuw i32 %17740, %17741" -> "  %17744 = and i32 %17742, 65535"
"  %17743 = lshr i32 %17739, 16"
"  %17743 = lshr i32 %17739, 16" -> "  %17745 = add nuw nsw i32 %17743, %17744"
"  %17744 = and i32 %17742, 65535"
"  %17744 = and i32 %17742, 65535" -> "  %17745 = add nuw nsw i32 %17743, %17744"
"  %17745 = add nuw nsw i32 %17743, %17744"
"  %17745 = add nuw nsw i32 %17743, %17744" -> "  %17747 = add nuw i32 %17745, %17746"
"  %17746 = and i32 %17742, -65536"
"  %17746 = and i32 %17742, -65536" -> "  %17747 = add nuw i32 %17745, %17746"
"  %17747 = add nuw i32 %17745, %17746"
"  %17747 = add nuw i32 %17745, %17746" -> "  %17755 = add nuw i32 %17747, %17754"
"  %17748 = and i32 %17729, 65535"
"  %17748 = and i32 %17729, 65535" -> "  %17750 = add nuw nsw i32 %17748, %17749"
"  %17749 = and i32 %17730, 65535"
"  %17749 = and i32 %17730, 65535" -> "  %17750 = add nuw nsw i32 %17748, %17749"
"  %17750 = add nuw nsw i32 %17748, %17749"
"  %17750 = add nuw nsw i32 %17748, %17749" -> "  %17779 = and i32 %17750, 65535""  %17750 = add nuw nsw i32 %17748, %17749" -> "  %17757 = lshr i32 %17750, 16"
"  %17751 = and i32 %17739, 65535"
"  %17751 = and i32 %17739, 65535" -> "  %17753 = add nuw nsw i32 %17751, %17752"
"  %17752 = lshr i32 %17729, 16"
"  %17752 = lshr i32 %17729, 16" -> "  %17753 = add nuw nsw i32 %17751, %17752"
"  %17753 = add nuw nsw i32 %17751, %17752"
"  %17753 = add nuw nsw i32 %17751, %17752" -> "  %17756 = and i32 %17753, 65535""  %17753 = add nuw nsw i32 %17751, %17752" -> "  %17754 = lshr i32 %17753, 16"
"  %17754 = lshr i32 %17753, 16"
"  %17754 = lshr i32 %17753, 16" -> "  %17755 = add nuw i32 %17747, %17754"
"  %17755 = add nuw i32 %17747, %17754"
"  %17755 = add nuw i32 %17747, %17754" -> "  %17760 = add nuw i32 %17755, %17759"
"  %17756 = and i32 %17753, 65535"
"  %17756 = and i32 %17753, 65535" -> "  %17758 = add nuw nsw i32 %17756, %17757"
"  %17757 = lshr i32 %17750, 16"
"  %17757 = lshr i32 %17750, 16" -> "  %17758 = add nuw nsw i32 %17756, %17757"
"  %17758 = add nuw nsw i32 %17756, %17757"
"  %17758 = add nuw nsw i32 %17756, %17757" -> "  %17782 = and i32 %17758, 65535""  %17758 = add nuw nsw i32 %17756, %17757" -> "  %17759 = lshr i32 %17758, 16"
"  %17759 = lshr i32 %17758, 16"
"  %17759 = lshr i32 %17758, 16" -> "  %17760 = add nuw i32 %17755, %17759"
"  %17760 = add nuw i32 %17755, %17759"
"  %17760 = add nuw i32 %17755, %17759" -> "  %17814 = lshr i32 %17760, 16""  %17760 = add nuw i32 %17755, %17759" -> "  %17810 = and i32 %17760, 65535"
"  %17761 = mul nuw nsw i32 %17375, 31112"
"  %17761 = mul nuw nsw i32 %17375, 31112" -> "  %17780 = and i32 %17761, 65528""  %17761 = mul nuw nsw i32 %17375, 31112" -> "  %17762 = lshr i32 %17761, 16"
"  %17762 = lshr i32 %17761, 16"
"  %17762 = lshr i32 %17761, 16" -> "  %17765 = add nuw nsw i32 %17764, %17762"
"  %17763 = mul nuw nsw i32 %17376, 31112"
"  %17763 = mul nuw nsw i32 %17376, 31112" -> "  %17766 = and i32 %17763, 2147418112""  %17763 = mul nuw nsw i32 %17376, 31112" -> "  %17764 = and i32 %17763, 65528"
"  %17764 = and i32 %17763, 65528"
"  %17764 = and i32 %17763, 65528" -> "  %17765 = add nuw nsw i32 %17764, %17762"
"  %17765 = add nuw nsw i32 %17764, %17762"
"  %17765 = add nuw nsw i32 %17764, %17762" -> "  %17767 = add nuw nsw i32 %17765, %17766"
"  %17766 = and i32 %17763, 2147418112"
"  %17766 = and i32 %17763, 2147418112" -> "  %17767 = add nuw nsw i32 %17765, %17766"
"  %17767 = add nuw nsw i32 %17765, %17766"
"  %17767 = add nuw nsw i32 %17765, %17766" -> "  %17771 = lshr i32 %17767, 16""  %17767 = add nuw nsw i32 %17765, %17766" -> "  %17769 = and i32 %17767, 65535"
"  %17768 = mul nuw i32 %17375, 42170"
"  %17768 = mul nuw i32 %17375, 42170" -> "  %17770 = add nuw i32 %17769, %17768"
"  %17769 = and i32 %17767, 65535"
"  %17769 = and i32 %17767, 65535" -> "  %17770 = add nuw i32 %17769, %17768"
"  %17770 = add nuw i32 %17769, %17768"
"  %17770 = add nuw i32 %17769, %17768" -> "  %17783 = and i32 %17770, 65535""  %17770 = add nuw i32 %17769, %17768" -> "  %17774 = lshr i32 %17770, 16"
"  %17771 = lshr i32 %17767, 16"
"  %17771 = lshr i32 %17767, 16" -> "  %17773 = add nuw i32 %17771, %17772"
"  %17772 = mul nuw i32 %17376, 42170"
"  %17772 = mul nuw i32 %17376, 42170" -> "  %17773 = add nuw i32 %17771, %17772"
"  %17773 = add nuw i32 %17771, %17772"
"  %17773 = add nuw i32 %17771, %17772" -> "  %17777 = and i32 %17773, -65536""  %17773 = add nuw i32 %17771, %17772" -> "  %17775 = and i32 %17773, 65535"
"  %17774 = lshr i32 %17770, 16"
"  %17774 = lshr i32 %17770, 16" -> "  %17776 = add nuw nsw i32 %17774, %17775"
"  %17775 = and i32 %17773, 65535"
"  %17775 = and i32 %17773, 65535" -> "  %17776 = add nuw nsw i32 %17774, %17775"
"  %17776 = add nuw nsw i32 %17774, %17775"
"  %17776 = add nuw nsw i32 %17774, %17775" -> "  %17778 = add nuw i32 %17776, %17777"
"  %17777 = and i32 %17773, -65536"
"  %17777 = and i32 %17773, -65536" -> "  %17778 = add nuw i32 %17776, %17777"
"  %17778 = add nuw i32 %17776, %17777"
"  %17778 = add nuw i32 %17776, %17777" -> "  %17786 = add nuw i32 %17778, %17785"
"  %17779 = and i32 %17750, 65535"
"  %17779 = and i32 %17750, 65535" -> "  %17781 = add nuw nsw i32 %17779, %17780"
"  %17780 = and i32 %17761, 65528"
"  %17780 = and i32 %17761, 65528" -> "  %17781 = add nuw nsw i32 %17779, %17780"
"  %17781 = add nuw nsw i32 %17779, %17780"
"  %17781 = add nuw nsw i32 %17779, %17780" -> "  %17849 = and i32 %17781, 65535""  %17781 = add nuw nsw i32 %17779, %17780" -> "  %17788 = lshr i32 %17781, 16"
"  %17782 = and i32 %17758, 65535"
"  %17782 = and i32 %17758, 65535" -> "  %17784 = add nuw nsw i32 %17782, %17783"
"  %17783 = and i32 %17770, 65535"
"  %17783 = and i32 %17770, 65535" -> "  %17784 = add nuw nsw i32 %17782, %17783"
"  %17784 = add nuw nsw i32 %17782, %17783"
"  %17784 = add nuw nsw i32 %17782, %17783" -> "  %17787 = and i32 %17784, 65535""  %17784 = add nuw nsw i32 %17782, %17783" -> "  %17785 = lshr i32 %17784, 16"
"  %17785 = lshr i32 %17784, 16"
"  %17785 = lshr i32 %17784, 16" -> "  %17786 = add nuw i32 %17778, %17785"
"  %17786 = add nuw i32 %17778, %17785"
"  %17786 = add nuw i32 %17778, %17785" -> "  %17791 = add nuw i32 %17786, %17790"
"  %17787 = and i32 %17784, 65535"
"  %17787 = and i32 %17784, 65535" -> "  %17789 = add nuw nsw i32 %17787, %17788"
"  %17788 = lshr i32 %17781, 16"
"  %17788 = lshr i32 %17781, 16" -> "  %17789 = add nuw nsw i32 %17787, %17788"
"  %17789 = add nuw nsw i32 %17787, %17788"
"  %17789 = add nuw nsw i32 %17787, %17788" -> "  %17852 = and i32 %17789, 65535""  %17789 = add nuw nsw i32 %17787, %17788" -> "  %17790 = lshr i32 %17789, 16"
"  %17790 = lshr i32 %17789, 16"
"  %17790 = lshr i32 %17789, 16" -> "  %17791 = add nuw i32 %17786, %17790"
"  %17791 = add nuw i32 %17786, %17790"
"  %17791 = add nuw i32 %17786, %17790" -> "  %17827 = lshr i32 %17791, 16""  %17791 = add nuw i32 %17786, %17790" -> "  %17824 = and i32 %17791, 65535"
"  %17792 = mul nuw nsw i32 %17395, 31112"
"  %17792 = mul nuw nsw i32 %17395, 31112" -> "  %17811 = and i32 %17792, 65528""  %17792 = mul nuw nsw i32 %17395, 31112" -> "  %17793 = lshr i32 %17792, 16"
"  %17793 = lshr i32 %17792, 16"
"  %17793 = lshr i32 %17792, 16" -> "  %17796 = add nuw nsw i32 %17795, %17793"
"  %17794 = mul nuw nsw i32 %17398, 31112"
"  %17794 = mul nuw nsw i32 %17398, 31112" -> "  %17797 = and i32 %17794, 2147418112""  %17794 = mul nuw nsw i32 %17398, 31112" -> "  %17795 = and i32 %17794, 65528"
"  %17795 = and i32 %17794, 65528"
"  %17795 = and i32 %17794, 65528" -> "  %17796 = add nuw nsw i32 %17795, %17793"
"  %17796 = add nuw nsw i32 %17795, %17793"
"  %17796 = add nuw nsw i32 %17795, %17793" -> "  %17798 = add nuw nsw i32 %17796, %17797"
"  %17797 = and i32 %17794, 2147418112"
"  %17797 = and i32 %17794, 2147418112" -> "  %17798 = add nuw nsw i32 %17796, %17797"
"  %17798 = add nuw nsw i32 %17796, %17797"
"  %17798 = add nuw nsw i32 %17796, %17797" -> "  %17802 = lshr i32 %17798, 16""  %17798 = add nuw nsw i32 %17796, %17797" -> "  %17800 = and i32 %17798, 65535"
"  %17799 = mul nuw i32 %17395, 42170"
"  %17799 = mul nuw i32 %17395, 42170" -> "  %17801 = add nuw i32 %17800, %17799"
"  %17800 = and i32 %17798, 65535"
"  %17800 = and i32 %17798, 65535" -> "  %17801 = add nuw i32 %17800, %17799"
"  %17801 = add nuw i32 %17800, %17799"
"  %17801 = add nuw i32 %17800, %17799" -> "  %17813 = and i32 %17801, 65535""  %17801 = add nuw i32 %17800, %17799" -> "  %17805 = lshr i32 %17801, 16"
"  %17802 = lshr i32 %17798, 16"
"  %17802 = lshr i32 %17798, 16" -> "  %17804 = add nuw i32 %17802, %17803"
"  %17803 = mul nuw i32 %17398, 42170"
"  %17803 = mul nuw i32 %17398, 42170" -> "  %17804 = add nuw i32 %17802, %17803"
"  %17804 = add nuw i32 %17802, %17803"
"  %17804 = add nuw i32 %17802, %17803" -> "  %17808 = and i32 %17804, -65536""  %17804 = add nuw i32 %17802, %17803" -> "  %17806 = and i32 %17804, 65535"
"  %17805 = lshr i32 %17801, 16"
"  %17805 = lshr i32 %17801, 16" -> "  %17807 = add nuw nsw i32 %17805, %17806"
"  %17806 = and i32 %17804, 65535"
"  %17806 = and i32 %17804, 65535" -> "  %17807 = add nuw nsw i32 %17805, %17806"
"  %17807 = add nuw nsw i32 %17805, %17806"
"  %17807 = add nuw nsw i32 %17805, %17806" -> "  %17809 = add nuw i32 %17807, %17808"
"  %17808 = and i32 %17804, -65536"
"  %17808 = and i32 %17804, -65536" -> "  %17809 = add nuw i32 %17807, %17808"
"  %17809 = add nuw i32 %17807, %17808"
"  %17809 = add nuw i32 %17807, %17808" -> "  %17817 = add nuw i32 %17809, %17816"
"  %17810 = and i32 %17760, 65535"
"  %17810 = and i32 %17760, 65535" -> "  %17812 = add nuw nsw i32 %17810, %17811"
"  %17811 = and i32 %17792, 65528"
"  %17811 = and i32 %17792, 65528" -> "  %17812 = add nuw nsw i32 %17810, %17811"
"  %17812 = add nuw nsw i32 %17810, %17811"
"  %17812 = add nuw nsw i32 %17810, %17811" -> "  %17823 = and i32 %17812, 65535""  %17812 = add nuw nsw i32 %17810, %17811" -> "  %17819 = lshr i32 %17812, 16"
"  %17813 = and i32 %17801, 65535"
"  %17813 = and i32 %17801, 65535" -> "  %17815 = add nuw nsw i32 %17814, %17813"
"  %17814 = lshr i32 %17760, 16"
"  %17814 = lshr i32 %17760, 16" -> "  %17815 = add nuw nsw i32 %17814, %17813"
"  %17815 = add nuw nsw i32 %17814, %17813"
"  %17815 = add nuw nsw i32 %17814, %17813" -> "  %17818 = and i32 %17815, 65535""  %17815 = add nuw nsw i32 %17814, %17813" -> "  %17816 = lshr i32 %17815, 16"
"  %17816 = lshr i32 %17815, 16"
"  %17816 = lshr i32 %17815, 16" -> "  %17817 = add nuw i32 %17809, %17816"
"  %17817 = add nuw i32 %17809, %17816"
"  %17817 = add nuw i32 %17809, %17816" -> "  %17822 = add nuw i32 %17817, %17821"
"  %17818 = and i32 %17815, 65535"
"  %17818 = and i32 %17815, 65535" -> "  %17820 = add nuw nsw i32 %17819, %17818"
"  %17819 = lshr i32 %17812, 16"
"  %17819 = lshr i32 %17812, 16" -> "  %17820 = add nuw nsw i32 %17819, %17818"
"  %17820 = add nuw nsw i32 %17819, %17818"
"  %17820 = add nuw nsw i32 %17819, %17818" -> "  %17826 = and i32 %17820, 65535""  %17820 = add nuw nsw i32 %17819, %17818" -> "  %17821 = lshr i32 %17820, 16"
"  %17821 = lshr i32 %17820, 16"
"  %17821 = lshr i32 %17820, 16" -> "  %17822 = add nuw i32 %17817, %17821"
"  %17822 = add nuw i32 %17817, %17821"
"  %17822 = add nuw i32 %17817, %17821" -> "  %17835 = and i32 %17822, -65536""  %17822 = add nuw i32 %17817, %17821" -> "  %17833 = and i32 %17822, 65535"
"  %17823 = and i32 %17812, 65535"
"  %17823 = and i32 %17812, 65535" -> "  %17825 = add nuw nsw i32 %17824, %17823"
"  %17824 = and i32 %17791, 65535"
"  %17824 = and i32 %17791, 65535" -> "  %17825 = add nuw nsw i32 %17824, %17823"
"  %17825 = add nuw nsw i32 %17824, %17823"
"  %17825 = add nuw nsw i32 %17824, %17823" -> "  %17866 = and i32 %17825, 65535""  %17825 = add nuw nsw i32 %17824, %17823" -> "  %17829 = lshr i32 %17825, 16"
"  %17826 = and i32 %17820, 65535"
"  %17826 = and i32 %17820, 65535" -> "  %17828 = add nuw nsw i32 %17827, %17826"
"  %17827 = lshr i32 %17791, 16"
"  %17827 = lshr i32 %17791, 16" -> "  %17828 = add nuw nsw i32 %17827, %17826"
"  %17828 = add nuw nsw i32 %17827, %17826"
"  %17828 = add nuw nsw i32 %17827, %17826" -> "  %17832 = lshr i32 %17828, 16""  %17828 = add nuw nsw i32 %17827, %17826" -> "  %17830 = and i32 %17828, 65535"
"  %17829 = lshr i32 %17825, 16"
"  %17829 = lshr i32 %17825, 16" -> "  %17831 = add nuw nsw i32 %17829, %17830"
"  %17830 = and i32 %17828, 65535"
"  %17830 = and i32 %17828, 65535" -> "  %17831 = add nuw nsw i32 %17829, %17830"
"  %17831 = add nuw nsw i32 %17829, %17830"
"  %17831 = add nuw nsw i32 %17829, %17830" -> "  %17873 = and i32 %17831, 65535""  %17831 = add nuw nsw i32 %17829, %17830" -> "  %17837 = lshr i32 %17831, 16"
"  %17832 = lshr i32 %17828, 16"
"  %17832 = lshr i32 %17828, 16" -> "  %17834 = add nuw nsw i32 %17832, %17833"
"  %17833 = and i32 %17822, 65535"
"  %17833 = and i32 %17822, 65535" -> "  %17834 = add nuw nsw i32 %17832, %17833"
"  %17834 = add nuw nsw i32 %17832, %17833"
"  %17834 = add nuw nsw i32 %17832, %17833" -> "  %17836 = add nuw i32 %17834, %17835"
"  %17835 = and i32 %17822, -65536"
"  %17835 = and i32 %17822, -65536" -> "  %17836 = add nuw i32 %17834, %17835"
"  %17836 = add nuw i32 %17834, %17835"
"  %17836 = add nuw i32 %17834, %17835" -> "  %17838 = add nuw i32 %17836, %17837"
"  %17837 = lshr i32 %17831, 16"
"  %17837 = lshr i32 %17831, 16" -> "  %17838 = add nuw i32 %17836, %17837"
"  %17838 = add nuw i32 %17836, %17837"
"  %17838 = add nuw i32 %17836, %17837" -> "  %17876 = add nuw i32 %17838, %17875"
"  %17839 = and i32 %17712, 65535"
"  %17839 = and i32 %17712, 65535" -> "  %17841 = add nuw nsw i32 %17840, %17839"
"  %17840 = and i32 %17541, 65535"
"  %17840 = and i32 %17541, 65535" -> "  %17841 = add nuw nsw i32 %17840, %17839"
"  %17841 = add nuw nsw i32 %17840, %17839"
"  %17841 = add nuw nsw i32 %17840, %17839" -> "  %17877 = and i32 %17841, 65535""  %17841 = add nuw nsw i32 %17840, %17839" -> "  %17845 = lshr i32 %17841, 16"
"  %17842 = and i32 %17721, 65535"
"  %17842 = and i32 %17721, 65535" -> "  %17844 = add nuw nsw i32 %17843, %17842"
"  %17843 = and i32 %17544, 65535"
"  %17843 = and i32 %17544, 65535" -> "  %17844 = add nuw nsw i32 %17843, %17842"
"  %17844 = add nuw nsw i32 %17843, %17842"
"  %17844 = add nuw nsw i32 %17843, %17842" -> "  %17858 = lshr i32 %17844, 16""  %17844 = add nuw nsw i32 %17843, %17842" -> "  %17846 = and i32 %17844, 65535"
"  %17845 = lshr i32 %17841, 16"
"  %17845 = lshr i32 %17841, 16" -> "  %17847 = add nuw nsw i32 %17846, %17845"
"  %17846 = and i32 %17844, 65535"
"  %17846 = and i32 %17844, 65535" -> "  %17847 = add nuw nsw i32 %17846, %17845"
"  %17847 = add nuw nsw i32 %17846, %17845"
"  %17847 = add nuw nsw i32 %17846, %17845" -> "  %17880 = and i32 %17847, 65535""  %17847 = add nuw nsw i32 %17846, %17845" -> "  %17859 = lshr i32 %17847, 16"
"  %17848 = and i32 %17546, 65535"
"  %17848 = and i32 %17546, 65535" -> "  %17850 = add nuw nsw i32 %17848, %17849"
"  %17849 = and i32 %17781, 65535"
"  %17849 = and i32 %17781, 65535" -> "  %17850 = add nuw nsw i32 %17848, %17849"
"  %17850 = add nuw nsw i32 %17848, %17849"
"  %17850 = add nuw nsw i32 %17848, %17849" -> "  %17857 = and i32 %17850, 65535""  %17850 = add nuw nsw i32 %17848, %17849" -> "  %17854 = lshr i32 %17850, 16"
"  %17851 = lshr i32 %17546, 16"
"  %17851 = lshr i32 %17546, 16" -> "  %17853 = add nuw nsw i32 %17851, %17852"
"  %17852 = and i32 %17789, 65535"
"  %17852 = and i32 %17789, 65535" -> "  %17853 = add nuw nsw i32 %17851, %17852"
"  %17853 = add nuw nsw i32 %17851, %17852"
"  %17853 = add nuw nsw i32 %17851, %17852" -> "  %17865 = lshr i32 %17853, 16""  %17853 = add nuw nsw i32 %17851, %17852" -> "  %17855 = and i32 %17853, 65535"
"  %17854 = lshr i32 %17850, 16"
"  %17854 = lshr i32 %17850, 16" -> "  %17856 = add nuw nsw i32 %17855, %17854"
"  %17855 = and i32 %17853, 65535"
"  %17855 = and i32 %17853, 65535" -> "  %17856 = add nuw nsw i32 %17855, %17854"
"  %17856 = add nuw nsw i32 %17855, %17854"
"  %17856 = add nuw nsw i32 %17855, %17854" -> "  %17868 = lshr i32 %17856, 16""  %17856 = add nuw nsw i32 %17855, %17854" -> "  %17863 = and i32 %17856, 65535"
"  %17857 = and i32 %17850, 65535"
"  %17857 = and i32 %17850, 65535" -> "  %17860 = add nuw nsw i32 %17857, %17858"
"  %17858 = lshr i32 %17844, 16"
"  %17858 = lshr i32 %17844, 16" -> "  %17860 = add nuw nsw i32 %17857, %17858"
"  %17859 = lshr i32 %17847, 16"
"  %17859 = lshr i32 %17847, 16" -> "  %17861 = add nuw nsw i32 %17860, %17859"
"  %17860 = add nuw nsw i32 %17857, %17858"
"  %17860 = add nuw nsw i32 %17857, %17858" -> "  %17861 = add nuw nsw i32 %17860, %17859"
"  %17861 = add nuw nsw i32 %17860, %17859"
"  %17861 = add nuw nsw i32 %17860, %17859" -> "  %17886 = and i32 %17861, 65535""  %17861 = add nuw nsw i32 %17860, %17859" -> "  %17862 = lshr i32 %17861, 16"
"  %17862 = lshr i32 %17861, 16"
"  %17862 = lshr i32 %17861, 16" -> "  %17864 = add nuw nsw i32 %17862, %17863"
"  %17863 = and i32 %17856, 65535"
"  %17863 = and i32 %17856, 65535" -> "  %17864 = add nuw nsw i32 %17862, %17863"
"  %17864 = add nuw nsw i32 %17862, %17863"
"  %17864 = add nuw nsw i32 %17862, %17863" -> "  %17889 = and i32 %17864, 65535""  %17864 = add nuw nsw i32 %17862, %17863" -> "  %17870 = lshr i32 %17864, 16"
"  %17865 = lshr i32 %17853, 16"
"  %17865 = lshr i32 %17853, 16" -> "  %17867 = add nuw nsw i32 %17865, %17866"
"  %17866 = and i32 %17825, 65535"
"  %17866 = and i32 %17825, 65535" -> "  %17867 = add nuw nsw i32 %17865, %17866"
"  %17867 = add nuw nsw i32 %17865, %17866"
"  %17867 = add nuw nsw i32 %17865, %17866" -> "  %17869 = add nuw nsw i32 %17867, %17868"
"  %17868 = lshr i32 %17856, 16"
"  %17868 = lshr i32 %17856, 16" -> "  %17869 = add nuw nsw i32 %17867, %17868"
"  %17869 = add nuw nsw i32 %17867, %17868"
"  %17869 = add nuw nsw i32 %17867, %17868" -> "  %17871 = add nuw nsw i32 %17869, %17870"
"  %17870 = lshr i32 %17864, 16"
"  %17870 = lshr i32 %17864, 16" -> "  %17871 = add nuw nsw i32 %17869, %17870"
"  %17871 = add nuw nsw i32 %17869, %17870"
"  %17871 = add nuw nsw i32 %17869, %17870" -> "  %17903 = and i32 %17871, 65535""  %17871 = add nuw nsw i32 %17869, %17870" -> "  %17872 = lshr i32 %17871, 16"
"  %17872 = lshr i32 %17871, 16"
"  %17872 = lshr i32 %17871, 16" -> "  %17874 = add nuw nsw i32 %17872, %17873"
"  %17873 = and i32 %17831, 65535"
"  %17873 = and i32 %17831, 65535" -> "  %17874 = add nuw nsw i32 %17872, %17873"
"  %17874 = add nuw nsw i32 %17872, %17873"
"  %17874 = add nuw nsw i32 %17872, %17873" -> "  %17910 = and i32 %17874, 65535""  %17874 = add nuw nsw i32 %17872, %17873" -> "  %17875 = lshr i32 %17874, 16"
"  %17875 = lshr i32 %17874, 16"
"  %17875 = lshr i32 %17874, 16" -> "  %17876 = add nuw i32 %17838, %17875"
"  %17876 = add nuw i32 %17838, %17875"
"  %17876 = add nuw i32 %17838, %17875" -> "  %17914 = add nuw i32 %17876, %17913"
"  %17877 = and i32 %17841, 65535"
"  %17877 = and i32 %17841, 65535" -> "  %17879 = add nuw nsw i32 %17878, %17877"
"  %17878 = and i32 %17706, 65535"
"  %17878 = and i32 %17706, 65535" -> "  %17879 = add nuw nsw i32 %17878, %17877"
"  %17879 = add nuw nsw i32 %17878, %17877"
"  %17879 = add nuw nsw i32 %17878, %17877" -> "  %18577 = and i32 %17879, 65535""  %17879 = add nuw nsw i32 %17878, %17877" -> "  %17883 = lshr i32 %17879, 16"
"  %17880 = and i32 %17847, 65535"
"  %17880 = and i32 %17847, 65535" -> "  %17882 = add nuw nsw i32 %17881, %17880"
"  %17881 = and i32 %17709, 65535"
"  %17881 = and i32 %17709, 65535" -> "  %17882 = add nuw nsw i32 %17881, %17880"
"  %17882 = add nuw nsw i32 %17881, %17880"
"  %17882 = add nuw nsw i32 %17881, %17880" -> "  %17896 = lshr i32 %17882, 16""  %17882 = add nuw nsw i32 %17881, %17880" -> "  %17884 = and i32 %17882, 65535"
"  %17883 = lshr i32 %17879, 16"
"  %17883 = lshr i32 %17879, 16" -> "  %17885 = add nuw nsw i32 %17884, %17883"
"  %17884 = and i32 %17882, 65535"
"  %17884 = and i32 %17882, 65535" -> "  %17885 = add nuw nsw i32 %17884, %17883"
"  %17885 = add nuw nsw i32 %17884, %17883"
"  %17885 = add nuw nsw i32 %17884, %17883" -> "  %18580 = and i32 %17885, 65535""  %17885 = add nuw nsw i32 %17884, %17883" -> "  %17897 = lshr i32 %17885, 16"
"  %17886 = and i32 %17861, 65535"
"  %17886 = and i32 %17861, 65535" -> "  %17888 = add nuw nsw i32 %17887, %17886"
"  %17887 = and i32 %17711, 65535"
"  %17887 = and i32 %17711, 65535" -> "  %17888 = add nuw nsw i32 %17887, %17886"
"  %17888 = add nuw nsw i32 %17887, %17886"
"  %17888 = add nuw nsw i32 %17887, %17886" -> "  %17895 = and i32 %17888, 65535""  %17888 = add nuw nsw i32 %17887, %17886" -> "  %17892 = lshr i32 %17888, 16"
"  %17889 = and i32 %17864, 65535"
"  %17889 = and i32 %17864, 65535" -> "  %17891 = add nuw nsw i32 %17889, %17890"
"  %17890 = lshr i32 %17711, 16"
"  %17890 = lshr i32 %17711, 16" -> "  %17891 = add nuw nsw i32 %17889, %17890"
"  %17891 = add nuw nsw i32 %17889, %17890"
"  %17891 = add nuw nsw i32 %17889, %17890" -> "  %17904 = lshr i32 %17891, 16""  %17891 = add nuw nsw i32 %17889, %17890" -> "  %17893 = and i32 %17891, 65535"
"  %17892 = lshr i32 %17888, 16"
"  %17892 = lshr i32 %17888, 16" -> "  %17894 = add nuw nsw i32 %17893, %17892"
"  %17893 = and i32 %17891, 65535"
"  %17893 = and i32 %17891, 65535" -> "  %17894 = add nuw nsw i32 %17893, %17892"
"  %17894 = add nuw nsw i32 %17893, %17892"
"  %17894 = add nuw nsw i32 %17893, %17892" -> "  %17906 = lshr i32 %17894, 16""  %17894 = add nuw nsw i32 %17893, %17892" -> "  %17901 = and i32 %17894, 65535"
"  %17895 = and i32 %17888, 65535"
"  %17895 = and i32 %17888, 65535" -> "  %17899 = add nuw nsw i32 %17898, %17895"
"  %17896 = lshr i32 %17882, 16"
"  %17896 = lshr i32 %17882, 16" -> "  %17898 = add nuw nsw i32 %17897, %17896"
"  %17897 = lshr i32 %17885, 16"
"  %17897 = lshr i32 %17885, 16" -> "  %17898 = add nuw nsw i32 %17897, %17896"
"  %17898 = add nuw nsw i32 %17897, %17896"
"  %17898 = add nuw nsw i32 %17897, %17896" -> "  %17899 = add nuw nsw i32 %17898, %17895"
"  %17899 = add nuw nsw i32 %17898, %17895"
"  %17899 = add nuw nsw i32 %17898, %17895" -> "  %18589 = and i32 %17899, 65535""  %17899 = add nuw nsw i32 %17898, %17895" -> "  %17900 = lshr i32 %17899, 16"
"  %17900 = lshr i32 %17899, 16"
"  %17900 = lshr i32 %17899, 16" -> "  %17902 = add nuw nsw i32 %17901, %17900"
"  %17901 = and i32 %17894, 65535"
"  %17901 = and i32 %17894, 65535" -> "  %17902 = add nuw nsw i32 %17901, %17900"
"  %17902 = add nuw nsw i32 %17901, %17900"
"  %17902 = add nuw nsw i32 %17901, %17900" -> "  %18592 = and i32 %17902, 65535""  %17902 = add nuw nsw i32 %17901, %17900" -> "  %17908 = lshr i32 %17902, 16"
"  %17903 = and i32 %17871, 65535"
"  %17903 = and i32 %17871, 65535" -> "  %17905 = add nuw nsw i32 %17904, %17903"
"  %17904 = lshr i32 %17891, 16"
"  %17904 = lshr i32 %17891, 16" -> "  %17905 = add nuw nsw i32 %17904, %17903"
"  %17905 = add nuw nsw i32 %17904, %17903"
"  %17905 = add nuw nsw i32 %17904, %17903" -> "  %17907 = add nuw nsw i32 %17905, %17906"
"  %17906 = lshr i32 %17894, 16"
"  %17906 = lshr i32 %17894, 16" -> "  %17907 = add nuw nsw i32 %17905, %17906"
"  %17907 = add nuw nsw i32 %17905, %17906"
"  %17907 = add nuw nsw i32 %17905, %17906" -> "  %17909 = add nuw nsw i32 %17907, %17908"
"  %17908 = lshr i32 %17902, 16"
"  %17908 = lshr i32 %17902, 16" -> "  %17909 = add nuw nsw i32 %17907, %17908"
"  %17909 = add nuw nsw i32 %17907, %17908"
"  %17909 = add nuw nsw i32 %17907, %17908" -> "  %18603 = and i32 %17909, 65535""  %17909 = add nuw nsw i32 %17907, %17908" -> "  %17911 = lshr i32 %17909, 16"
"  %17910 = and i32 %17874, 65535"
"  %17910 = and i32 %17874, 65535" -> "  %17912 = add nuw nsw i32 %17911, %17910"
"  %17911 = lshr i32 %17909, 16"
"  %17911 = lshr i32 %17909, 16" -> "  %17912 = add nuw nsw i32 %17911, %17910"
"  %17912 = add nuw nsw i32 %17911, %17910"
"  %17912 = add nuw nsw i32 %17911, %17910" -> "  %18606 = and i32 %17912, 65535""  %17912 = add nuw nsw i32 %17911, %17910" -> "  %17913 = lshr i32 %17912, 16"
"  %17913 = lshr i32 %17912, 16"
"  %17913 = lshr i32 %17912, 16" -> "  %17914 = add nuw i32 %17876, %17913"
"  %17914 = add nuw i32 %17876, %17913"
"  %17914 = add nuw i32 %17876, %17913" -> "  %18612 = and i32 %17914, 65535""  %17914 = add nuw i32 %17876, %17913" -> "  %18615 = lshr i32 %17914, 16"
"  %17915 = and i32 %17205, 65535"
"  %17915 = and i32 %17205, 65535" -> "  %19708 = mul nuw nsw i32 %17915, 4087""  %17915 = and i32 %17205, 65535" -> "  %19715 = mul nuw nsw i32 %17915, 11561""  %17915 = and i32 %17205, 65535" -> "  %19764 = mul nuw i32 %17915, 36786""  %17915 = and i32 %17205, 65535" -> "  %19422 = mul nuw i32 %17915, 42779""  %17915 = and i32 %17205, 65535" -> "  %19429 = mul nuw nsw i32 %17915, 9871""  %17915 = and i32 %17205, 65535" -> "  %19471 = mul nuw nsw i32 %17915, 24315""  %17915 = and i32 %17205, 65535" -> "  %19478 = mul nuw nsw i32 %17915, 29744""  %17915 = and i32 %17205, 65535" -> "  %18215 = mul nuw nsw i32 %17915, 17857""  %17915 = and i32 %17205, 65535" -> "  %18222 = mul nuw i32 %17915, 46547""  %17915 = and i32 %17205, 65535" -> "  %18264 = mul nuw nsw i32 %17915, 31112""  %17915 = and i32 %17205, 65535" -> "  %18271 = mul nuw i32 %17915, 42170""  %17915 = and i32 %17205, 65535" -> "  %17978 = mul nuw i32 %17915, 62728""  %17915 = and i32 %17205, 65535" -> "  %17924 = mul nuw i32 %17915, 45147""  %17915 = and i32 %17205, 65535" -> "  %17916 = mul nuw i32 %17915, 37996""  %17915 = and i32 %17205, 65535" -> "  %19757 = mul nuw nsw i32 %17915, 21884""  %17915 = and i32 %17205, 65535" -> "  %17971 = mul nuw nsw i32 %17915, 1324"
"  %17916 = mul nuw i32 %17915, 37996"
"  %17916 = mul nuw i32 %17915, 37996" -> "  %18578 = and i32 %17916, 65532""  %17916 = mul nuw i32 %17915, 37996" -> "  %17917 = lshr i32 %17916, 16"
"  %17917 = lshr i32 %17916, 16"
"  %17917 = lshr i32 %17916, 16" -> "  %17921 = add nuw nsw i32 %17920, %17917"
"  %17918 = and i32 %17211, 65535"
"  %17918 = and i32 %17211, 65535" -> "  %17919 = mul nuw i32 %17918, 37996""  %17918 = and i32 %17211, 65535" -> "  %17928 = mul nuw i32 %17918, 45147""  %17918 = and i32 %17211, 65535" -> "  %17973 = mul nuw nsw i32 %17918, 1324""  %17918 = and i32 %17211, 65535" -> "  %17982 = mul nuw i32 %17918, 62728""  %17918 = and i32 %17211, 65535" -> "  %18275 = mul nuw i32 %17918, 42170""  %17918 = and i32 %17211, 65535" -> "  %18266 = mul nuw nsw i32 %17918, 31112""  %17918 = and i32 %17211, 65535" -> "  %18226 = mul nuw i32 %17918, 46547""  %17918 = and i32 %17211, 65535" -> "  %18217 = mul nuw nsw i32 %17918, 17857""  %17918 = and i32 %17211, 65535" -> "  %19482 = mul nuw nsw i32 %17918, 29744""  %17918 = and i32 %17211, 65535" -> "  %19473 = mul nuw nsw i32 %17918, 24315""  %17918 = and i32 %17211, 65535" -> "  %19433 = mul nuw nsw i32 %17918, 9871""  %17918 = and i32 %17211, 65535" -> "  %19424 = mul nuw i32 %17918, 42779""  %17918 = and i32 %17211, 65535" -> "  %19768 = mul nuw i32 %17918, 36786""  %17918 = and i32 %17211, 65535" -> "  %19759 = mul nuw nsw i32 %17918, 21884""  %17918 = and i32 %17211, 65535" -> "  %19719 = mul nuw nsw i32 %17918, 11561""  %17918 = and i32 %17211, 65535" -> "  %19710 = mul nuw nsw i32 %17918, 4087"
"  %17919 = mul nuw i32 %17918, 37996"
"  %17919 = mul nuw i32 %17918, 37996" -> "  %17922 = and i32 %17919, -65536""  %17919 = mul nuw i32 %17918, 37996" -> "  %17920 = and i32 %17919, 65532"
"  %17920 = and i32 %17919, 65532"
"  %17920 = and i32 %17919, 65532" -> "  %17921 = add nuw nsw i32 %17920, %17917"
"  %17921 = add nuw nsw i32 %17920, %17917"
"  %17921 = add nuw nsw i32 %17920, %17917" -> "  %17923 = add nuw i32 %17921, %17922"
"  %17922 = and i32 %17919, -65536"
"  %17922 = and i32 %17919, -65536" -> "  %17923 = add nuw i32 %17921, %17922"
"  %17923 = add nuw i32 %17921, %17922"
"  %17923 = add nuw i32 %17921, %17922" -> "  %17927 = lshr i32 %17923, 16""  %17923 = add nuw i32 %17921, %17922" -> "  %17925 = and i32 %17923, 65535"
"  %17924 = mul nuw i32 %17915, 45147"
"  %17924 = mul nuw i32 %17915, 45147" -> "  %17926 = add nuw i32 %17925, %17924"
"  %17925 = and i32 %17923, 65535"
"  %17925 = and i32 %17923, 65535" -> "  %17926 = add nuw i32 %17925, %17924"
"  %17926 = add nuw i32 %17925, %17924"
"  %17926 = add nuw i32 %17925, %17924" -> "  %18581 = and i32 %17926, 65535""  %17926 = add nuw i32 %17925, %17924" -> "  %17930 = lshr i32 %17926, 16"
"  %17927 = lshr i32 %17923, 16"
"  %17927 = lshr i32 %17923, 16" -> "  %17929 = add nuw i32 %17927, %17928"
"  %17928 = mul nuw i32 %17918, 45147"
"  %17928 = mul nuw i32 %17918, 45147" -> "  %17929 = add nuw i32 %17927, %17928"
"  %17929 = add nuw i32 %17927, %17928"
"  %17929 = add nuw i32 %17927, %17928" -> "  %17933 = and i32 %17929, -65536""  %17929 = add nuw i32 %17927, %17928" -> "  %17931 = and i32 %17929, 65535"
"  %17930 = lshr i32 %17926, 16"
"  %17930 = lshr i32 %17926, 16" -> "  %17932 = add nuw nsw i32 %17930, %17931"
"  %17931 = and i32 %17929, 65535"
"  %17931 = and i32 %17929, 65535" -> "  %17932 = add nuw nsw i32 %17930, %17931"
"  %17932 = add nuw nsw i32 %17930, %17931"
"  %17932 = add nuw nsw i32 %17930, %17931" -> "  %17934 = add nuw i32 %17932, %17933"
"  %17933 = and i32 %17929, -65536"
"  %17933 = and i32 %17929, -65536" -> "  %17934 = add nuw i32 %17932, %17933"
"  %17934 = add nuw i32 %17932, %17933"
"  %17934 = add nuw i32 %17932, %17933" -> "  %17959 = lshr i32 %17934, 16""  %17934 = add nuw i32 %17932, %17933" -> "  %17955 = and i32 %17934, 65535"
"  %17935 = and i32 %17225, 65535"
"  %17935 = and i32 %17225, 65535" -> "  %19726 = mul nuw nsw i32 %17935, 4087""  %17935 = and i32 %17225, 65535" -> "  %19440 = mul nuw i32 %17935, 42779""  %17935 = and i32 %17225, 65535" -> "  %17936 = mul nuw i32 %17935, 37996""  %17935 = and i32 %17225, 65535" -> "  %17944 = mul nuw i32 %17935, 45147""  %17935 = and i32 %17225, 65535" -> "  %18009 = mul nuw i32 %17935, 62728""  %17935 = and i32 %17225, 65535" -> "  %18002 = mul nuw nsw i32 %17935, 1324""  %17935 = and i32 %17225, 65535" -> "  %18302 = mul nuw i32 %17935, 42170""  %17935 = and i32 %17225, 65535" -> "  %18295 = mul nuw nsw i32 %17935, 31112""  %17935 = and i32 %17225, 65535" -> "  %18240 = mul nuw i32 %17935, 46547""  %17935 = and i32 %17225, 65535" -> "  %18233 = mul nuw nsw i32 %17935, 17857""  %17935 = and i32 %17225, 65535" -> "  %19506 = mul nuw nsw i32 %17935, 29744""  %17935 = and i32 %17225, 65535" -> "  %19502 = mul nuw nsw i32 %17935, 24315""  %17935 = and i32 %17225, 65535" -> "  %19447 = mul nuw nsw i32 %17935, 9871""  %17935 = and i32 %17225, 65535" -> "  %19795 = mul nuw i32 %17935, 36786""  %17935 = and i32 %17225, 65535" -> "  %19788 = mul nuw nsw i32 %17935, 21884""  %17935 = and i32 %17225, 65535" -> "  %19733 = mul nuw nsw i32 %17935, 11561"
"  %17936 = mul nuw i32 %17935, 37996"
"  %17936 = mul nuw i32 %17935, 37996" -> "  %17956 = and i32 %17936, 65532""  %17936 = mul nuw i32 %17935, 37996" -> "  %17937 = lshr i32 %17936, 16"
"  %17937 = lshr i32 %17936, 16"
"  %17937 = lshr i32 %17936, 16" -> "  %17941 = add nuw nsw i32 %17940, %17937"
"  %17938 = and i32 %17228, 65535"
"  %17938 = and i32 %17228, 65535" -> "  %17939 = mul nuw i32 %17938, 37996""  %17938 = and i32 %17228, 65535" -> "  %17948 = mul nuw i32 %17938, 45147""  %17938 = and i32 %17228, 65535" -> "  %18013 = mul nuw i32 %17938, 62728""  %17938 = and i32 %17228, 65535" -> "  %18004 = mul nuw nsw i32 %17938, 1324""  %17938 = and i32 %17228, 65535" -> "  %18306 = mul nuw i32 %17938, 42170""  %17938 = and i32 %17228, 65535" -> "  %18297 = mul nuw nsw i32 %17938, 31112""  %17938 = and i32 %17228, 65535" -> "  %18244 = mul nuw i32 %17938, 46547""  %17938 = and i32 %17228, 65535" -> "  %18235 = mul nuw nsw i32 %17938, 17857""  %17938 = and i32 %17228, 65535" -> "  %19510 = mul nuw nsw i32 %17938, 29744""  %17938 = and i32 %17228, 65535" -> "  %19504 = mul nuw nsw i32 %17938, 24315""  %17938 = and i32 %17228, 65535" -> "  %19451 = mul nuw nsw i32 %17938, 9871""  %17938 = and i32 %17228, 65535" -> "  %19442 = mul nuw i32 %17938, 42779""  %17938 = and i32 %17228, 65535" -> "  %19799 = mul nuw i32 %17938, 36786""  %17938 = and i32 %17228, 65535" -> "  %19790 = mul nuw nsw i32 %17938, 21884""  %17938 = and i32 %17228, 65535" -> "  %19737 = mul nuw nsw i32 %17938, 11561""  %17938 = and i32 %17228, 65535" -> "  %19728 = mul nuw nsw i32 %17938, 4087"
"  %17939 = mul nuw i32 %17938, 37996"
"  %17939 = mul nuw i32 %17938, 37996" -> "  %17942 = and i32 %17939, -65536""  %17939 = mul nuw i32 %17938, 37996" -> "  %17940 = and i32 %17939, 65532"
"  %17940 = and i32 %17939, 65532"
"  %17940 = and i32 %17939, 65532" -> "  %17941 = add nuw nsw i32 %17940, %17937"
"  %17941 = add nuw nsw i32 %17940, %17937"
"  %17941 = add nuw nsw i32 %17940, %17937" -> "  %17943 = add nuw i32 %17941, %17942"
"  %17942 = and i32 %17939, -65536"
"  %17942 = and i32 %17939, -65536" -> "  %17943 = add nuw i32 %17941, %17942"
"  %17943 = add nuw i32 %17941, %17942"
"  %17943 = add nuw i32 %17941, %17942" -> "  %17947 = lshr i32 %17943, 16""  %17943 = add nuw i32 %17941, %17942" -> "  %17945 = and i32 %17943, 65535"
"  %17944 = mul nuw i32 %17935, 45147"
"  %17944 = mul nuw i32 %17935, 45147" -> "  %17946 = add nuw i32 %17945, %17944"
"  %17945 = and i32 %17943, 65535"
"  %17945 = and i32 %17943, 65535" -> "  %17946 = add nuw i32 %17945, %17944"
"  %17946 = add nuw i32 %17945, %17944"
"  %17946 = add nuw i32 %17945, %17944" -> "  %17958 = and i32 %17946, 65535""  %17946 = add nuw i32 %17945, %17944" -> "  %17950 = lshr i32 %17946, 16"
"  %17947 = lshr i32 %17943, 16"
"  %17947 = lshr i32 %17943, 16" -> "  %17949 = add nuw i32 %17947, %17948"
"  %17948 = mul nuw i32 %17938, 45147"
"  %17948 = mul nuw i32 %17938, 45147" -> "  %17949 = add nuw i32 %17947, %17948"
"  %17949 = add nuw i32 %17947, %17948"
"  %17949 = add nuw i32 %17947, %17948" -> "  %17953 = and i32 %17949, -65536""  %17949 = add nuw i32 %17947, %17948" -> "  %17951 = and i32 %17949, 65535"
"  %17950 = lshr i32 %17946, 16"
"  %17950 = lshr i32 %17946, 16" -> "  %17952 = add nuw nsw i32 %17950, %17951"
"  %17951 = and i32 %17949, 65535"
"  %17951 = and i32 %17949, 65535" -> "  %17952 = add nuw nsw i32 %17950, %17951"
"  %17952 = add nuw nsw i32 %17950, %17951"
"  %17952 = add nuw nsw i32 %17950, %17951" -> "  %17954 = add nuw i32 %17952, %17953"
"  %17953 = and i32 %17949, -65536"
"  %17953 = and i32 %17949, -65536" -> "  %17954 = add nuw i32 %17952, %17953"
"  %17954 = add nuw i32 %17952, %17953"
"  %17954 = add nuw i32 %17952, %17953" -> "  %17967 = and i32 %17954, -65536""  %17954 = add nuw i32 %17952, %17953" -> "  %17965 = and i32 %17954, 65535"
"  %17955 = and i32 %17934, 65535"
"  %17955 = and i32 %17934, 65535" -> "  %17957 = add nuw nsw i32 %17955, %17956"
"  %17956 = and i32 %17936, 65532"
"  %17956 = and i32 %17936, 65532" -> "  %17957 = add nuw nsw i32 %17955, %17956"
"  %17957 = add nuw nsw i32 %17955, %17956"
"  %17957 = add nuw nsw i32 %17955, %17956" -> "  %17989 = and i32 %17957, 65535""  %17957 = add nuw nsw i32 %17955, %17956" -> "  %17961 = lshr i32 %17957, 16"
"  %17958 = and i32 %17946, 65535"
"  %17958 = and i32 %17946, 65535" -> "  %17960 = add nuw nsw i32 %17958, %17959"
"  %17959 = lshr i32 %17934, 16"
"  %17959 = lshr i32 %17934, 16" -> "  %17960 = add nuw nsw i32 %17958, %17959"
"  %17960 = add nuw nsw i32 %17958, %17959"
"  %17960 = add nuw nsw i32 %17958, %17959" -> "  %17964 = lshr i32 %17960, 16""  %17960 = add nuw nsw i32 %17958, %17959" -> "  %17962 = and i32 %17960, 65535"
"  %17961 = lshr i32 %17957, 16"
"  %17961 = lshr i32 %17957, 16" -> "  %17963 = add nuw nsw i32 %17962, %17961"
"  %17962 = and i32 %17960, 65535"
"  %17962 = and i32 %17960, 65535" -> "  %17963 = add nuw nsw i32 %17962, %17961"
"  %17963 = add nuw nsw i32 %17962, %17961"
"  %17963 = add nuw nsw i32 %17962, %17961" -> "  %17992 = and i32 %17963, 65535""  %17963 = add nuw nsw i32 %17962, %17961" -> "  %17969 = lshr i32 %17963, 16"
"  %17964 = lshr i32 %17960, 16"
"  %17964 = lshr i32 %17960, 16" -> "  %17966 = add nuw nsw i32 %17965, %17964"
"  %17965 = and i32 %17954, 65535"
"  %17965 = and i32 %17954, 65535" -> "  %17966 = add nuw nsw i32 %17965, %17964"
"  %17966 = add nuw nsw i32 %17965, %17964"
"  %17966 = add nuw nsw i32 %17965, %17964" -> "  %17968 = add nuw i32 %17966, %17967"
"  %17967 = and i32 %17954, -65536"
"  %17967 = and i32 %17954, -65536" -> "  %17968 = add nuw i32 %17966, %17967"
"  %17968 = add nuw i32 %17966, %17967"
"  %17968 = add nuw i32 %17966, %17967" -> "  %17970 = add nuw i32 %17968, %17969"
"  %17969 = lshr i32 %17963, 16"
"  %17969 = lshr i32 %17963, 16" -> "  %17970 = add nuw i32 %17968, %17969"
"  %17970 = add nuw i32 %17968, %17969"
"  %17970 = add nuw i32 %17968, %17969" -> "  %18020 = and i32 %17970, 65535""  %17970 = add nuw i32 %17968, %17969" -> "  %18024 = lshr i32 %17970, 16"
"  %17971 = mul nuw nsw i32 %17915, 1324"
"  %17971 = mul nuw nsw i32 %17915, 1324" -> "  %17990 = and i32 %17971, 65532""  %17971 = mul nuw nsw i32 %17915, 1324" -> "  %17972 = lshr i32 %17971, 16"
"  %17972 = lshr i32 %17971, 16"
"  %17972 = lshr i32 %17971, 16" -> "  %17975 = add nuw nsw i32 %17974, %17972"
"  %17973 = mul nuw nsw i32 %17918, 1324"
"  %17973 = mul nuw nsw i32 %17918, 1324" -> "  %17976 = and i32 %17973, 134152192""  %17973 = mul nuw nsw i32 %17918, 1324" -> "  %17974 = and i32 %17973, 65532"
"  %17974 = and i32 %17973, 65532"
"  %17974 = and i32 %17973, 65532" -> "  %17975 = add nuw nsw i32 %17974, %17972"
"  %17975 = add nuw nsw i32 %17974, %17972"
"  %17975 = add nuw nsw i32 %17974, %17972" -> "  %17977 = add nuw nsw i32 %17975, %17976"
"  %17976 = and i32 %17973, 134152192"
"  %17976 = and i32 %17973, 134152192" -> "  %17977 = add nuw nsw i32 %17975, %17976"
"  %17977 = add nuw nsw i32 %17975, %17976"
"  %17977 = add nuw nsw i32 %17975, %17976" -> "  %17981 = lshr i32 %17977, 16""  %17977 = add nuw nsw i32 %17975, %17976" -> "  %17979 = and i32 %17977, 65535"
"  %17978 = mul nuw i32 %17915, 62728"
"  %17978 = mul nuw i32 %17915, 62728" -> "  %17980 = add nuw i32 %17979, %17978"
"  %17979 = and i32 %17977, 65535"
"  %17979 = and i32 %17977, 65535" -> "  %17980 = add nuw i32 %17979, %17978"
"  %17980 = add nuw i32 %17979, %17978"
"  %17980 = add nuw i32 %17979, %17978" -> "  %17993 = and i32 %17980, 65535""  %17980 = add nuw i32 %17979, %17978" -> "  %17984 = lshr i32 %17980, 16"
"  %17981 = lshr i32 %17977, 16"
"  %17981 = lshr i32 %17977, 16" -> "  %17983 = add nuw i32 %17981, %17982"
"  %17982 = mul nuw i32 %17918, 62728"
"  %17982 = mul nuw i32 %17918, 62728" -> "  %17983 = add nuw i32 %17981, %17982"
"  %17983 = add nuw i32 %17981, %17982"
"  %17983 = add nuw i32 %17981, %17982" -> "  %17987 = and i32 %17983, -65536""  %17983 = add nuw i32 %17981, %17982" -> "  %17985 = and i32 %17983, 65535"
"  %17984 = lshr i32 %17980, 16"
"  %17984 = lshr i32 %17980, 16" -> "  %17986 = add nuw nsw i32 %17984, %17985"
"  %17985 = and i32 %17983, 65535"
"  %17985 = and i32 %17983, 65535" -> "  %17986 = add nuw nsw i32 %17984, %17985"
"  %17986 = add nuw nsw i32 %17984, %17985"
"  %17986 = add nuw nsw i32 %17984, %17985" -> "  %17988 = add nuw i32 %17986, %17987"
"  %17987 = and i32 %17983, -65536"
"  %17987 = and i32 %17983, -65536" -> "  %17988 = add nuw i32 %17986, %17987"
"  %17988 = add nuw i32 %17986, %17987"
"  %17988 = add nuw i32 %17986, %17987" -> "  %17996 = add nuw i32 %17988, %17995"
"  %17989 = and i32 %17957, 65535"
"  %17989 = and i32 %17957, 65535" -> "  %17991 = add nuw nsw i32 %17989, %17990"
"  %17990 = and i32 %17971, 65532"
"  %17990 = and i32 %17971, 65532" -> "  %17991 = add nuw nsw i32 %17989, %17990"
"  %17991 = add nuw nsw i32 %17989, %17990"
"  %17991 = add nuw nsw i32 %17989, %17990" -> "  %18590 = and i32 %17991, 65535""  %17991 = add nuw nsw i32 %17989, %17990" -> "  %17998 = lshr i32 %17991, 16"
"  %17992 = and i32 %17963, 65535"
"  %17992 = and i32 %17963, 65535" -> "  %17994 = add nuw nsw i32 %17992, %17993"
"  %17993 = and i32 %17980, 65535"
"  %17993 = and i32 %17980, 65535" -> "  %17994 = add nuw nsw i32 %17992, %17993"
"  %17994 = add nuw nsw i32 %17992, %17993"
"  %17994 = add nuw nsw i32 %17992, %17993" -> "  %17997 = and i32 %17994, 65535""  %17994 = add nuw nsw i32 %17992, %17993" -> "  %17995 = lshr i32 %17994, 16"
"  %17995 = lshr i32 %17994, 16"
"  %17995 = lshr i32 %17994, 16" -> "  %17996 = add nuw i32 %17988, %17995"
"  %17996 = add nuw i32 %17988, %17995"
"  %17996 = add nuw i32 %17988, %17995" -> "  %18001 = add nuw i32 %17996, %18000"
"  %17997 = and i32 %17994, 65535"
"  %17997 = and i32 %17994, 65535" -> "  %17999 = add nuw nsw i32 %17997, %17998"
"  %17998 = lshr i32 %17991, 16"
"  %17998 = lshr i32 %17991, 16" -> "  %17999 = add nuw nsw i32 %17997, %17998"
"  %17999 = add nuw nsw i32 %17997, %17998"
"  %17999 = add nuw nsw i32 %17997, %17998" -> "  %18593 = and i32 %17999, 65535""  %17999 = add nuw nsw i32 %17997, %17998" -> "  %18000 = lshr i32 %17999, 16"
"  %18000 = lshr i32 %17999, 16"
"  %18000 = lshr i32 %17999, 16" -> "  %18001 = add nuw i32 %17996, %18000"
"  %18001 = add nuw i32 %17996, %18000"
"  %18001 = add nuw i32 %17996, %18000" -> "  %18037 = lshr i32 %18001, 16""  %18001 = add nuw i32 %17996, %18000" -> "  %18034 = and i32 %18001, 65535"
"  %18002 = mul nuw nsw i32 %17935, 1324"
"  %18002 = mul nuw nsw i32 %17935, 1324" -> "  %18021 = and i32 %18002, 65532""  %18002 = mul nuw nsw i32 %17935, 1324" -> "  %18003 = lshr i32 %18002, 16"
"  %18003 = lshr i32 %18002, 16"
"  %18003 = lshr i32 %18002, 16" -> "  %18006 = add nuw nsw i32 %18005, %18003"
"  %18004 = mul nuw nsw i32 %17938, 1324"
"  %18004 = mul nuw nsw i32 %17938, 1324" -> "  %18007 = and i32 %18004, 134152192""  %18004 = mul nuw nsw i32 %17938, 1324" -> "  %18005 = and i32 %18004, 65532"
"  %18005 = and i32 %18004, 65532"
"  %18005 = and i32 %18004, 65532" -> "  %18006 = add nuw nsw i32 %18005, %18003"
"  %18006 = add nuw nsw i32 %18005, %18003"
"  %18006 = add nuw nsw i32 %18005, %18003" -> "  %18008 = add nuw nsw i32 %18006, %18007"
"  %18007 = and i32 %18004, 134152192"
"  %18007 = and i32 %18004, 134152192" -> "  %18008 = add nuw nsw i32 %18006, %18007"
"  %18008 = add nuw nsw i32 %18006, %18007"
"  %18008 = add nuw nsw i32 %18006, %18007" -> "  %18012 = lshr i32 %18008, 16""  %18008 = add nuw nsw i32 %18006, %18007" -> "  %18010 = and i32 %18008, 65535"
"  %18009 = mul nuw i32 %17935, 62728"
"  %18009 = mul nuw i32 %17935, 62728" -> "  %18011 = add nuw i32 %18010, %18009"
"  %18010 = and i32 %18008, 65535"
"  %18010 = and i32 %18008, 65535" -> "  %18011 = add nuw i32 %18010, %18009"
"  %18011 = add nuw i32 %18010, %18009"
"  %18011 = add nuw i32 %18010, %18009" -> "  %18023 = and i32 %18011, 65535""  %18011 = add nuw i32 %18010, %18009" -> "  %18015 = lshr i32 %18011, 16"
"  %18012 = lshr i32 %18008, 16"
"  %18012 = lshr i32 %18008, 16" -> "  %18014 = add nuw i32 %18012, %18013"
"  %18013 = mul nuw i32 %17938, 62728"
"  %18013 = mul nuw i32 %17938, 62728" -> "  %18014 = add nuw i32 %18012, %18013"
"  %18014 = add nuw i32 %18012, %18013"
"  %18014 = add nuw i32 %18012, %18013" -> "  %18018 = and i32 %18014, -65536""  %18014 = add nuw i32 %18012, %18013" -> "  %18016 = and i32 %18014, 65535"
"  %18015 = lshr i32 %18011, 16"
"  %18015 = lshr i32 %18011, 16" -> "  %18017 = add nuw nsw i32 %18015, %18016"
"  %18016 = and i32 %18014, 65535"
"  %18016 = and i32 %18014, 65535" -> "  %18017 = add nuw nsw i32 %18015, %18016"
"  %18017 = add nuw nsw i32 %18015, %18016"
"  %18017 = add nuw nsw i32 %18015, %18016" -> "  %18019 = add nuw i32 %18017, %18018"
"  %18018 = and i32 %18014, -65536"
"  %18018 = and i32 %18014, -65536" -> "  %18019 = add nuw i32 %18017, %18018"
"  %18019 = add nuw i32 %18017, %18018"
"  %18019 = add nuw i32 %18017, %18018" -> "  %18027 = add nuw i32 %18019, %18026"
"  %18020 = and i32 %17970, 65535"
"  %18020 = and i32 %17970, 65535" -> "  %18022 = add nuw nsw i32 %18020, %18021"
"  %18021 = and i32 %18002, 65532"
"  %18021 = and i32 %18002, 65532" -> "  %18022 = add nuw nsw i32 %18020, %18021"
"  %18022 = add nuw nsw i32 %18020, %18021"
"  %18022 = add nuw nsw i32 %18020, %18021" -> "  %18033 = and i32 %18022, 65535""  %18022 = add nuw nsw i32 %18020, %18021" -> "  %18029 = lshr i32 %18022, 16"
"  %18023 = and i32 %18011, 65535"
"  %18023 = and i32 %18011, 65535" -> "  %18025 = add nuw nsw i32 %18024, %18023"
"  %18024 = lshr i32 %17970, 16"
"  %18024 = lshr i32 %17970, 16" -> "  %18025 = add nuw nsw i32 %18024, %18023"
"  %18025 = add nuw nsw i32 %18024, %18023"
"  %18025 = add nuw nsw i32 %18024, %18023" -> "  %18028 = and i32 %18025, 65535""  %18025 = add nuw nsw i32 %18024, %18023" -> "  %18026 = lshr i32 %18025, 16"
"  %18026 = lshr i32 %18025, 16"
"  %18026 = lshr i32 %18025, 16" -> "  %18027 = add nuw i32 %18019, %18026"
"  %18027 = add nuw i32 %18019, %18026"
"  %18027 = add nuw i32 %18019, %18026" -> "  %18032 = add nuw i32 %18027, %18031"
"  %18028 = and i32 %18025, 65535"
"  %18028 = and i32 %18025, 65535" -> "  %18030 = add nuw nsw i32 %18028, %18029"
"  %18029 = lshr i32 %18022, 16"
"  %18029 = lshr i32 %18022, 16" -> "  %18030 = add nuw nsw i32 %18028, %18029"
"  %18030 = add nuw nsw i32 %18028, %18029"
"  %18030 = add nuw nsw i32 %18028, %18029" -> "  %18036 = and i32 %18030, 65535""  %18030 = add nuw nsw i32 %18028, %18029" -> "  %18031 = lshr i32 %18030, 16"
"  %18031 = lshr i32 %18030, 16"
"  %18031 = lshr i32 %18030, 16" -> "  %18032 = add nuw i32 %18027, %18031"
"  %18032 = add nuw i32 %18027, %18031"
"  %18032 = add nuw i32 %18027, %18031" -> "  %18045 = and i32 %18032, -65536""  %18032 = add nuw i32 %18027, %18031" -> "  %18043 = and i32 %18032, 65535"
"  %18033 = and i32 %18022, 65535"
"  %18033 = and i32 %18022, 65535" -> "  %18035 = add nuw nsw i32 %18034, %18033"
"  %18034 = and i32 %18001, 65535"
"  %18034 = and i32 %18001, 65535" -> "  %18035 = add nuw nsw i32 %18034, %18033"
"  %18035 = add nuw nsw i32 %18034, %18033"
"  %18035 = add nuw nsw i32 %18034, %18033" -> "  %18176 = and i32 %18035, 65535""  %18035 = add nuw nsw i32 %18034, %18033" -> "  %18039 = lshr i32 %18035, 16"
"  %18036 = and i32 %18030, 65535"
"  %18036 = and i32 %18030, 65535" -> "  %18038 = add nuw nsw i32 %18036, %18037"
"  %18037 = lshr i32 %18001, 16"
"  %18037 = lshr i32 %18001, 16" -> "  %18038 = add nuw nsw i32 %18036, %18037"
"  %18038 = add nuw nsw i32 %18036, %18037"
"  %18038 = add nuw nsw i32 %18036, %18037" -> "  %18042 = lshr i32 %18038, 16""  %18038 = add nuw nsw i32 %18036, %18037" -> "  %18040 = and i32 %18038, 65535"
"  %18039 = lshr i32 %18035, 16"
"  %18039 = lshr i32 %18035, 16" -> "  %18041 = add nuw nsw i32 %18040, %18039"
"  %18040 = and i32 %18038, 65535"
"  %18040 = and i32 %18038, 65535" -> "  %18041 = add nuw nsw i32 %18040, %18039"
"  %18041 = add nuw nsw i32 %18040, %18039"
"  %18041 = add nuw nsw i32 %18040, %18039" -> "  %18179 = and i32 %18041, 65535""  %18041 = add nuw nsw i32 %18040, %18039" -> "  %18047 = lshr i32 %18041, 16"
"  %18042 = lshr i32 %18038, 16"
"  %18042 = lshr i32 %18038, 16" -> "  %18044 = add nuw nsw i32 %18042, %18043"
"  %18043 = and i32 %18032, 65535"
"  %18043 = and i32 %18032, 65535" -> "  %18044 = add nuw nsw i32 %18042, %18043"
"  %18044 = add nuw nsw i32 %18042, %18043"
"  %18044 = add nuw nsw i32 %18042, %18043" -> "  %18046 = add nuw i32 %18044, %18045"
"  %18045 = and i32 %18032, -65536"
"  %18045 = and i32 %18032, -65536" -> "  %18046 = add nuw i32 %18044, %18045"
"  %18046 = add nuw i32 %18044, %18045"
"  %18046 = add nuw i32 %18044, %18045" -> "  %18048 = add nuw i32 %18046, %18047"
"  %18047 = lshr i32 %18041, 16"
"  %18047 = lshr i32 %18041, 16" -> "  %18048 = add nuw i32 %18046, %18047"
"  %18048 = add nuw i32 %18046, %18047"
"  %18048 = add nuw i32 %18046, %18047" -> "  %18184 = and i32 %18048, 65535""  %18048 = add nuw i32 %18046, %18047" -> "  %18187 = lshr i32 %18048, 16"
"  %18049 = and i32 %17235, 65535"
"  %18049 = and i32 %17235, 65535" -> "  %19929 = mul nuw i32 %18049, 36786""  %18049 = and i32 %17235, 65535" -> "  %19922 = mul nuw nsw i32 %18049, 21884""  %18049 = and i32 %17235, 65535" -> "  %19599 = mul nuw nsw i32 %18049, 29744""  %18049 = and i32 %17235, 65535" -> "  %19592 = mul nuw nsw i32 %18049, 24315""  %18049 = and i32 %17235, 65535" -> "  %18051 = mul nuw i32 %18049, 37996""  %18049 = and i32 %17235, 65535" -> "  %18058 = mul nuw i32 %18049, 45147""  %18049 = and i32 %17235, 65535" -> "  %18105 = mul nuw nsw i32 %18049, 1324""  %18049 = and i32 %17235, 65535" -> "  %18112 = mul nuw i32 %18049, 62728""  %18049 = and i32 %17235, 65535" -> "  %18433 = mul nuw i32 %18049, 42170""  %18049 = and i32 %17235, 65535" -> "  %18426 = mul nuw nsw i32 %18049, 31112""  %18049 = and i32 %17235, 65535" -> "  %18384 = mul nuw i32 %18049, 46547""  %18049 = and i32 %17235, 65535" -> "  %18377 = mul nuw nsw i32 %18049, 17857""  %18049 = and i32 %17235, 65535" -> "  %19550 = mul nuw nsw i32 %18049, 9871""  %18049 = and i32 %17235, 65535" -> "  %19543 = mul nuw i32 %18049, 42779""  %18049 = and i32 %17235, 65535" -> "  %19880 = mul nuw nsw i32 %18049, 11561""  %18049 = and i32 %17235, 65535" -> "  %19873 = mul nuw nsw i32 %18049, 4087"
"  %18050 = and i32 %17238, 65535"
"  %18050 = and i32 %17238, 65535" -> "  %18053 = mul nuw i32 %18050, 37996""  %18050 = and i32 %17238, 65535" -> "  %18062 = mul nuw i32 %18050, 45147""  %18050 = and i32 %17238, 65535" -> "  %18107 = mul nuw nsw i32 %18050, 1324""  %18050 = and i32 %17238, 65535" -> "  %18116 = mul nuw i32 %18050, 62728""  %18050 = and i32 %17238, 65535" -> "  %18437 = mul nuw i32 %18050, 42170""  %18050 = and i32 %17238, 65535" -> "  %18428 = mul nuw nsw i32 %18050, 31112""  %18050 = and i32 %17238, 65535" -> "  %18388 = mul nuw i32 %18050, 46547""  %18050 = and i32 %17238, 65535" -> "  %18379 = mul nuw nsw i32 %18050, 17857""  %18050 = and i32 %17238, 65535" -> "  %19603 = mul nuw nsw i32 %18050, 29744""  %18050 = and i32 %17238, 65535" -> "  %19594 = mul nuw nsw i32 %18050, 24315""  %18050 = and i32 %17238, 65535" -> "  %19554 = mul nuw nsw i32 %18050, 9871""  %18050 = and i32 %17238, 65535" -> "  %19545 = mul nuw i32 %18050, 42779""  %18050 = and i32 %17238, 65535" -> "  %19933 = mul nuw i32 %18050, 36786""  %18050 = and i32 %17238, 65535" -> "  %19924 = mul nuw nsw i32 %18050, 21884""  %18050 = and i32 %17238, 65535" -> "  %19884 = mul nuw nsw i32 %18050, 11561""  %18050 = and i32 %17238, 65535" -> "  %19875 = mul nuw nsw i32 %18050, 4087"
"  %18051 = mul nuw i32 %18049, 37996"
"  %18051 = mul nuw i32 %18049, 37996" -> "  %18175 = and i32 %18051, 65532""  %18051 = mul nuw i32 %18049, 37996" -> "  %18052 = lshr i32 %18051, 16"
"  %18052 = lshr i32 %18051, 16"
"  %18052 = lshr i32 %18051, 16" -> "  %18055 = add nuw nsw i32 %18054, %18052"
"  %18053 = mul nuw i32 %18050, 37996"
"  %18053 = mul nuw i32 %18050, 37996" -> "  %18056 = and i32 %18053, -65536""  %18053 = mul nuw i32 %18050, 37996" -> "  %18054 = and i32 %18053, 65532"
"  %18054 = and i32 %18053, 65532"
"  %18054 = and i32 %18053, 65532" -> "  %18055 = add nuw nsw i32 %18054, %18052"
"  %18055 = add nuw nsw i32 %18054, %18052"
"  %18055 = add nuw nsw i32 %18054, %18052" -> "  %18057 = add nuw i32 %18055, %18056"
"  %18056 = and i32 %18053, -65536"
"  %18056 = and i32 %18053, -65536" -> "  %18057 = add nuw i32 %18055, %18056"
"  %18057 = add nuw i32 %18055, %18056"
"  %18057 = add nuw i32 %18055, %18056" -> "  %18061 = lshr i32 %18057, 16""  %18057 = add nuw i32 %18055, %18056" -> "  %18059 = and i32 %18057, 65535"
"  %18058 = mul nuw i32 %18049, 45147"
"  %18058 = mul nuw i32 %18049, 45147" -> "  %18060 = add nuw i32 %18059, %18058"
"  %18059 = and i32 %18057, 65535"
"  %18059 = and i32 %18057, 65535" -> "  %18060 = add nuw i32 %18059, %18058"
"  %18060 = add nuw i32 %18059, %18058"
"  %18060 = add nuw i32 %18059, %18058" -> "  %18178 = and i32 %18060, 65535""  %18060 = add nuw i32 %18059, %18058" -> "  %18064 = lshr i32 %18060, 16"
"  %18061 = lshr i32 %18057, 16"
"  %18061 = lshr i32 %18057, 16" -> "  %18063 = add nuw i32 %18061, %18062"
"  %18062 = mul nuw i32 %18050, 45147"
"  %18062 = mul nuw i32 %18050, 45147" -> "  %18063 = add nuw i32 %18061, %18062"
"  %18063 = add nuw i32 %18061, %18062"
"  %18063 = add nuw i32 %18061, %18062" -> "  %18067 = and i32 %18063, -65536""  %18063 = add nuw i32 %18061, %18062" -> "  %18065 = and i32 %18063, 65535"
"  %18064 = lshr i32 %18060, 16"
"  %18064 = lshr i32 %18060, 16" -> "  %18066 = add nuw nsw i32 %18064, %18065"
"  %18065 = and i32 %18063, 65535"
"  %18065 = and i32 %18063, 65535" -> "  %18066 = add nuw nsw i32 %18064, %18065"
"  %18066 = add nuw nsw i32 %18064, %18065"
"  %18066 = add nuw nsw i32 %18064, %18065" -> "  %18068 = add nuw i32 %18066, %18067"
"  %18067 = and i32 %18063, -65536"
"  %18067 = and i32 %18063, -65536" -> "  %18068 = add nuw i32 %18066, %18067"
"  %18068 = add nuw i32 %18066, %18067"
"  %18068 = add nuw i32 %18066, %18067" -> "  %18093 = lshr i32 %18068, 16""  %18068 = add nuw i32 %18066, %18067" -> "  %18089 = and i32 %18068, 65535"
"  %18069 = and i32 %17240, 65535"
"  %18069 = and i32 %17240, 65535" -> "  %18136 = mul nuw nsw i32 %18069, 1324""  %18069 = and i32 %17240, 65535" -> "  %19891 = mul nuw nsw i32 %18069, 4087""  %18069 = and i32 %17240, 65535" -> "  %19898 = mul nuw nsw i32 %18069, 11561""  %18069 = and i32 %17240, 65535" -> "  %19953 = mul nuw nsw i32 %18069, 21884""  %18069 = and i32 %17240, 65535" -> "  %19960 = mul nuw i32 %18069, 36786""  %18069 = and i32 %17240, 65535" -> "  %19561 = mul nuw i32 %18069, 42779""  %18069 = and i32 %17240, 65535" -> "  %19568 = mul nuw nsw i32 %18069, 9871""  %18069 = and i32 %17240, 65535" -> "  %19623 = mul nuw nsw i32 %18069, 24315""  %18069 = and i32 %17240, 65535" -> "  %19630 = mul nuw nsw i32 %18069, 29744""  %18069 = and i32 %17240, 65535" -> "  %18395 = mul nuw nsw i32 %18069, 17857""  %18069 = and i32 %17240, 65535" -> "  %18402 = mul nuw i32 %18069, 46547""  %18069 = and i32 %17240, 65535" -> "  %18457 = mul nuw nsw i32 %18069, 31112""  %18069 = and i32 %17240, 65535" -> "  %18464 = mul nuw i32 %18069, 42170""  %18069 = and i32 %17240, 65535" -> "  %18140 = mul nuw i32 %18069, 62728""  %18069 = and i32 %17240, 65535" -> "  %18078 = mul nuw i32 %18069, 45147""  %18069 = and i32 %17240, 65535" -> "  %18071 = mul nuw i32 %18069, 37996"
"  %18070 = lshr i32 %17240, 16"
"  %18070 = lshr i32 %17240, 16" -> "  %19893 = mul nuw nsw i32 %18070, 4087""  %18070 = lshr i32 %17240, 16" -> "  %19902 = mul nuw nsw i32 %18070, 11561""  %18070 = lshr i32 %17240, 16" -> "  %19955 = mul nuw nsw i32 %18070, 21884""  %18070 = lshr i32 %17240, 16" -> "  %19964 = mul nuw i32 %18070, 36786""  %18070 = lshr i32 %17240, 16" -> "  %19563 = mul nuw i32 %18070, 42779""  %18070 = lshr i32 %17240, 16" -> "  %19572 = mul nuw nsw i32 %18070, 9871""  %18070 = lshr i32 %17240, 16" -> "  %19625 = mul nuw nsw i32 %18070, 24315""  %18070 = lshr i32 %17240, 16" -> "  %19634 = mul nuw nsw i32 %18070, 29744""  %18070 = lshr i32 %17240, 16" -> "  %18397 = mul nuw nsw i32 %18070, 17857""  %18070 = lshr i32 %17240, 16" -> "  %18406 = mul nuw i32 %18070, 46547""  %18070 = lshr i32 %17240, 16" -> "  %18459 = mul nuw nsw i32 %18070, 31112""  %18070 = lshr i32 %17240, 16" -> "  %18468 = mul nuw i32 %18070, 42170""  %18070 = lshr i32 %17240, 16" -> "  %18144 = mul nuw i32 %18070, 62728""  %18070 = lshr i32 %17240, 16" -> "  %18138 = mul nuw nsw i32 %18070, 1324""  %18070 = lshr i32 %17240, 16" -> "  %18082 = mul nuw i32 %18070, 45147""  %18070 = lshr i32 %17240, 16" -> "  %18073 = mul nuw i32 %18070, 37996"
"  %18071 = mul nuw i32 %18069, 37996"
"  %18071 = mul nuw i32 %18069, 37996" -> "  %18090 = and i32 %18071, 65532""  %18071 = mul nuw i32 %18069, 37996" -> "  %18072 = lshr i32 %18071, 16"
"  %18072 = lshr i32 %18071, 16"
"  %18072 = lshr i32 %18071, 16" -> "  %18075 = add nuw nsw i32 %18072, %18074"
"  %18073 = mul nuw i32 %18070, 37996"
"  %18073 = mul nuw i32 %18070, 37996" -> "  %18076 = and i32 %18073, -65536""  %18073 = mul nuw i32 %18070, 37996" -> "  %18074 = and i32 %18073, 65532"
"  %18074 = and i32 %18073, 65532"
"  %18074 = and i32 %18073, 65532" -> "  %18075 = add nuw nsw i32 %18072, %18074"
"  %18075 = add nuw nsw i32 %18072, %18074"
"  %18075 = add nuw nsw i32 %18072, %18074" -> "  %18077 = add nuw i32 %18075, %18076"
"  %18076 = and i32 %18073, -65536"
"  %18076 = and i32 %18073, -65536" -> "  %18077 = add nuw i32 %18075, %18076"
"  %18077 = add nuw i32 %18075, %18076"
"  %18077 = add nuw i32 %18075, %18076" -> "  %18081 = lshr i32 %18077, 16""  %18077 = add nuw i32 %18075, %18076" -> "  %18079 = and i32 %18077, 65535"
"  %18078 = mul nuw i32 %18069, 45147"
"  %18078 = mul nuw i32 %18069, 45147" -> "  %18080 = add nuw i32 %18079, %18078"
"  %18079 = and i32 %18077, 65535"
"  %18079 = and i32 %18077, 65535" -> "  %18080 = add nuw i32 %18079, %18078"
"  %18080 = add nuw i32 %18079, %18078"
"  %18080 = add nuw i32 %18079, %18078" -> "  %18092 = and i32 %18080, 65535""  %18080 = add nuw i32 %18079, %18078" -> "  %18084 = lshr i32 %18080, 16"
"  %18081 = lshr i32 %18077, 16"
"  %18081 = lshr i32 %18077, 16" -> "  %18083 = add nuw i32 %18081, %18082"
"  %18082 = mul nuw i32 %18070, 45147"
"  %18082 = mul nuw i32 %18070, 45147" -> "  %18083 = add nuw i32 %18081, %18082"
"  %18083 = add nuw i32 %18081, %18082"
"  %18083 = add nuw i32 %18081, %18082" -> "  %18087 = and i32 %18083, -65536""  %18083 = add nuw i32 %18081, %18082" -> "  %18085 = and i32 %18083, 65535"
"  %18084 = lshr i32 %18080, 16"
"  %18084 = lshr i32 %18080, 16" -> "  %18086 = add nuw nsw i32 %18084, %18085"
"  %18085 = and i32 %18083, 65535"
"  %18085 = and i32 %18083, 65535" -> "  %18086 = add nuw nsw i32 %18084, %18085"
"  %18086 = add nuw nsw i32 %18084, %18085"
"  %18086 = add nuw nsw i32 %18084, %18085" -> "  %18088 = add nuw i32 %18086, %18087"
"  %18087 = and i32 %18083, -65536"
"  %18087 = and i32 %18083, -65536" -> "  %18088 = add nuw i32 %18086, %18087"
"  %18088 = add nuw i32 %18086, %18087"
"  %18088 = add nuw i32 %18086, %18087" -> "  %18101 = and i32 %18088, -65536""  %18088 = add nuw i32 %18086, %18087" -> "  %18099 = and i32 %18088, 65535"
"  %18089 = and i32 %18068, 65535"
"  %18089 = and i32 %18068, 65535" -> "  %18091 = add nuw nsw i32 %18089, %18090"
"  %18090 = and i32 %18071, 65532"
"  %18090 = and i32 %18071, 65532" -> "  %18091 = add nuw nsw i32 %18089, %18090"
"  %18091 = add nuw nsw i32 %18089, %18090"
"  %18091 = add nuw nsw i32 %18089, %18090" -> "  %18123 = and i32 %18091, 65535""  %18091 = add nuw nsw i32 %18089, %18090" -> "  %18095 = lshr i32 %18091, 16"
"  %18092 = and i32 %18080, 65535"
"  %18092 = and i32 %18080, 65535" -> "  %18094 = add nuw nsw i32 %18093, %18092"
"  %18093 = lshr i32 %18068, 16"
"  %18093 = lshr i32 %18068, 16" -> "  %18094 = add nuw nsw i32 %18093, %18092"
"  %18094 = add nuw nsw i32 %18093, %18092"
"  %18094 = add nuw nsw i32 %18093, %18092" -> "  %18098 = lshr i32 %18094, 16""  %18094 = add nuw nsw i32 %18093, %18092" -> "  %18096 = and i32 %18094, 65535"
"  %18095 = lshr i32 %18091, 16"
"  %18095 = lshr i32 %18091, 16" -> "  %18097 = add nuw nsw i32 %18096, %18095"
"  %18096 = and i32 %18094, 65535"
"  %18096 = and i32 %18094, 65535" -> "  %18097 = add nuw nsw i32 %18096, %18095"
"  %18097 = add nuw nsw i32 %18096, %18095"
"  %18097 = add nuw nsw i32 %18096, %18095" -> "  %18126 = and i32 %18097, 65535""  %18097 = add nuw nsw i32 %18096, %18095" -> "  %18103 = lshr i32 %18097, 16"
"  %18098 = lshr i32 %18094, 16"
"  %18098 = lshr i32 %18094, 16" -> "  %18100 = add nuw nsw i32 %18099, %18098"
"  %18099 = and i32 %18088, 65535"
"  %18099 = and i32 %18088, 65535" -> "  %18100 = add nuw nsw i32 %18099, %18098"
"  %18100 = add nuw nsw i32 %18099, %18098"
"  %18100 = add nuw nsw i32 %18099, %18098" -> "  %18102 = add nuw i32 %18100, %18101"
"  %18101 = and i32 %18088, -65536"
"  %18101 = and i32 %18088, -65536" -> "  %18102 = add nuw i32 %18100, %18101"
"  %18102 = add nuw i32 %18100, %18101"
"  %18102 = add nuw i32 %18100, %18101" -> "  %18104 = add nuw i32 %18102, %18103"
"  %18103 = lshr i32 %18097, 16"
"  %18103 = lshr i32 %18097, 16" -> "  %18104 = add nuw i32 %18102, %18103"
"  %18104 = add nuw i32 %18102, %18103"
"  %18104 = add nuw i32 %18102, %18103" -> "  %18155 = lshr i32 %18104, 16""  %18104 = add nuw i32 %18102, %18103" -> "  %18151 = and i32 %18104, 65535"
"  %18105 = mul nuw nsw i32 %18049, 1324"
"  %18105 = mul nuw nsw i32 %18049, 1324" -> "  %18124 = and i32 %18105, 65532""  %18105 = mul nuw nsw i32 %18049, 1324" -> "  %18106 = lshr i32 %18105, 16"
"  %18106 = lshr i32 %18105, 16"
"  %18106 = lshr i32 %18105, 16" -> "  %18109 = add nuw nsw i32 %18108, %18106"
"  %18107 = mul nuw nsw i32 %18050, 1324"
"  %18107 = mul nuw nsw i32 %18050, 1324" -> "  %18110 = and i32 %18107, 134152192""  %18107 = mul nuw nsw i32 %18050, 1324" -> "  %18108 = and i32 %18107, 65532"
"  %18108 = and i32 %18107, 65532"
"  %18108 = and i32 %18107, 65532" -> "  %18109 = add nuw nsw i32 %18108, %18106"
"  %18109 = add nuw nsw i32 %18108, %18106"
"  %18109 = add nuw nsw i32 %18108, %18106" -> "  %18111 = add nuw nsw i32 %18109, %18110"
"  %18110 = and i32 %18107, 134152192"
"  %18110 = and i32 %18107, 134152192" -> "  %18111 = add nuw nsw i32 %18109, %18110"
"  %18111 = add nuw nsw i32 %18109, %18110"
"  %18111 = add nuw nsw i32 %18109, %18110" -> "  %18115 = lshr i32 %18111, 16""  %18111 = add nuw nsw i32 %18109, %18110" -> "  %18113 = and i32 %18111, 65535"
"  %18112 = mul nuw i32 %18049, 62728"
"  %18112 = mul nuw i32 %18049, 62728" -> "  %18114 = add nuw i32 %18113, %18112"
"  %18113 = and i32 %18111, 65535"
"  %18113 = and i32 %18111, 65535" -> "  %18114 = add nuw i32 %18113, %18112"
"  %18114 = add nuw i32 %18113, %18112"
"  %18114 = add nuw i32 %18113, %18112" -> "  %18127 = and i32 %18114, 65535""  %18114 = add nuw i32 %18113, %18112" -> "  %18118 = lshr i32 %18114, 16"
"  %18115 = lshr i32 %18111, 16"
"  %18115 = lshr i32 %18111, 16" -> "  %18117 = add nuw i32 %18115, %18116"
"  %18116 = mul nuw i32 %18050, 62728"
"  %18116 = mul nuw i32 %18050, 62728" -> "  %18117 = add nuw i32 %18115, %18116"
"  %18117 = add nuw i32 %18115, %18116"
"  %18117 = add nuw i32 %18115, %18116" -> "  %18121 = and i32 %18117, -65536""  %18117 = add nuw i32 %18115, %18116" -> "  %18119 = and i32 %18117, 65535"
"  %18118 = lshr i32 %18114, 16"
"  %18118 = lshr i32 %18114, 16" -> "  %18120 = add nuw nsw i32 %18118, %18119"
"  %18119 = and i32 %18117, 65535"
"  %18119 = and i32 %18117, 65535" -> "  %18120 = add nuw nsw i32 %18118, %18119"
"  %18120 = add nuw nsw i32 %18118, %18119"
"  %18120 = add nuw nsw i32 %18118, %18119" -> "  %18122 = add nuw i32 %18120, %18121"
"  %18121 = and i32 %18117, -65536"
"  %18121 = and i32 %18117, -65536" -> "  %18122 = add nuw i32 %18120, %18121"
"  %18122 = add nuw i32 %18120, %18121"
"  %18122 = add nuw i32 %18120, %18121" -> "  %18130 = add nuw i32 %18122, %18129"
"  %18123 = and i32 %18091, 65535"
"  %18123 = and i32 %18091, 65535" -> "  %18125 = add nuw nsw i32 %18123, %18124"
"  %18124 = and i32 %18105, 65532"
"  %18124 = and i32 %18105, 65532" -> "  %18125 = add nuw nsw i32 %18123, %18124"
"  %18125 = add nuw nsw i32 %18123, %18124"
"  %18125 = add nuw nsw i32 %18123, %18124" -> "  %18185 = and i32 %18125, 65535""  %18125 = add nuw nsw i32 %18123, %18124" -> "  %18132 = lshr i32 %18125, 16"
"  %18126 = and i32 %18097, 65535"
"  %18126 = and i32 %18097, 65535" -> "  %18128 = add nuw nsw i32 %18126, %18127"
"  %18127 = and i32 %18114, 65535"
"  %18127 = and i32 %18114, 65535" -> "  %18128 = add nuw nsw i32 %18126, %18127"
"  %18128 = add nuw nsw i32 %18126, %18127"
"  %18128 = add nuw nsw i32 %18126, %18127" -> "  %18131 = and i32 %18128, 65535""  %18128 = add nuw nsw i32 %18126, %18127" -> "  %18129 = lshr i32 %18128, 16"
"  %18129 = lshr i32 %18128, 16"
"  %18129 = lshr i32 %18128, 16" -> "  %18130 = add nuw i32 %18122, %18129"
"  %18130 = add nuw i32 %18122, %18129"
"  %18130 = add nuw i32 %18122, %18129" -> "  %18135 = add nuw i32 %18130, %18134"
"  %18131 = and i32 %18128, 65535"
"  %18131 = and i32 %18128, 65535" -> "  %18133 = add nuw nsw i32 %18131, %18132"
"  %18132 = lshr i32 %18125, 16"
"  %18132 = lshr i32 %18125, 16" -> "  %18133 = add nuw nsw i32 %18131, %18132"
"  %18133 = add nuw nsw i32 %18131, %18132"
"  %18133 = add nuw nsw i32 %18131, %18132" -> "  %18188 = and i32 %18133, 65535""  %18133 = add nuw nsw i32 %18131, %18132" -> "  %18134 = lshr i32 %18133, 16"
"  %18134 = lshr i32 %18133, 16"
"  %18134 = lshr i32 %18133, 16" -> "  %18135 = add nuw i32 %18130, %18134"
"  %18135 = add nuw i32 %18130, %18134"
"  %18135 = add nuw i32 %18130, %18134" -> "  %18164 = and i32 %18135, 65535""  %18135 = add nuw i32 %18130, %18134" -> "  %18167 = lshr i32 %18135, 16"
"  %18136 = mul nuw nsw i32 %18069, 1324"
"  %18136 = mul nuw nsw i32 %18069, 1324" -> "  %18152 = and i32 %18136, 65532""  %18136 = mul nuw nsw i32 %18069, 1324" -> "  %18137 = lshr i32 %18136, 16"
"  %18137 = lshr i32 %18136, 16"
"  %18137 = lshr i32 %18136, 16" -> "  %18139 = add nuw nsw i32 %18137, %18138"
"  %18138 = mul nuw nsw i32 %18070, 1324"
"  %18138 = mul nuw nsw i32 %18070, 1324" -> "  %18139 = add nuw nsw i32 %18137, %18138"
"  %18139 = add nuw nsw i32 %18137, %18138"
"  %18139 = add nuw nsw i32 %18137, %18138" -> "  %18143 = lshr i32 %18139, 16""  %18139 = add nuw nsw i32 %18137, %18138" -> "  %18141 = and i32 %18139, 65535"
"  %18140 = mul nuw i32 %18069, 62728"
"  %18140 = mul nuw i32 %18069, 62728" -> "  %18142 = add nuw i32 %18141, %18140"
"  %18141 = and i32 %18139, 65535"
"  %18141 = and i32 %18139, 65535" -> "  %18142 = add nuw i32 %18141, %18140"
"  %18142 = add nuw i32 %18141, %18140"
"  %18142 = add nuw i32 %18141, %18140" -> "  %18154 = and i32 %18142, 65535""  %18142 = add nuw i32 %18141, %18140" -> "  %18146 = lshr i32 %18142, 16"
"  %18143 = lshr i32 %18139, 16"
"  %18143 = lshr i32 %18139, 16" -> "  %18145 = add nuw i32 %18143, %18144"
"  %18144 = mul nuw i32 %18070, 62728"
"  %18144 = mul nuw i32 %18070, 62728" -> "  %18145 = add nuw i32 %18143, %18144"
"  %18145 = add nuw i32 %18143, %18144"
"  %18145 = add nuw i32 %18143, %18144" -> "  %18149 = and i32 %18145, -65536""  %18145 = add nuw i32 %18143, %18144" -> "  %18147 = and i32 %18145, 65535"
"  %18146 = lshr i32 %18142, 16"
"  %18146 = lshr i32 %18142, 16" -> "  %18148 = add nuw nsw i32 %18146, %18147"
"  %18147 = and i32 %18145, 65535"
"  %18147 = and i32 %18145, 65535" -> "  %18148 = add nuw nsw i32 %18146, %18147"
"  %18148 = add nuw nsw i32 %18146, %18147"
"  %18148 = add nuw nsw i32 %18146, %18147" -> "  %18150 = add nuw i32 %18148, %18149"
"  %18149 = and i32 %18145, -65536"
"  %18149 = and i32 %18145, -65536" -> "  %18150 = add nuw i32 %18148, %18149"
"  %18150 = add nuw i32 %18148, %18149"
"  %18150 = add nuw i32 %18148, %18149" -> "  %18158 = add nuw i32 %18150, %18157"
"  %18151 = and i32 %18104, 65535"
"  %18151 = and i32 %18104, 65535" -> "  %18153 = add nuw nsw i32 %18151, %18152"
"  %18152 = and i32 %18136, 65532"
"  %18152 = and i32 %18136, 65532" -> "  %18153 = add nuw nsw i32 %18151, %18152"
"  %18153 = add nuw nsw i32 %18151, %18152"
"  %18153 = add nuw nsw i32 %18151, %18152" -> "  %18165 = and i32 %18153, 65535""  %18153 = add nuw nsw i32 %18151, %18152" -> "  %18160 = lshr i32 %18153, 16"
"  %18154 = and i32 %18142, 65535"
"  %18154 = and i32 %18142, 65535" -> "  %18156 = add nuw nsw i32 %18155, %18154"
"  %18155 = lshr i32 %18104, 16"
"  %18155 = lshr i32 %18104, 16" -> "  %18156 = add nuw nsw i32 %18155, %18154"
"  %18156 = add nuw nsw i32 %18155, %18154"
"  %18156 = add nuw nsw i32 %18155, %18154" -> "  %18159 = and i32 %18156, 65535""  %18156 = add nuw nsw i32 %18155, %18154" -> "  %18157 = lshr i32 %18156, 16"
"  %18157 = lshr i32 %18156, 16"
"  %18157 = lshr i32 %18156, 16" -> "  %18158 = add nuw i32 %18150, %18157"
"  %18158 = add nuw i32 %18150, %18157"
"  %18158 = add nuw i32 %18150, %18157" -> "  %18163 = add nuw i32 %18158, %18162"
"  %18159 = and i32 %18156, 65535"
"  %18159 = and i32 %18156, 65535" -> "  %18161 = add nuw nsw i32 %18160, %18159"
"  %18160 = lshr i32 %18153, 16"
"  %18160 = lshr i32 %18153, 16" -> "  %18161 = add nuw nsw i32 %18160, %18159"
"  %18161 = add nuw nsw i32 %18160, %18159"
"  %18161 = add nuw nsw i32 %18160, %18159" -> "  %18168 = and i32 %18161, 65535""  %18161 = add nuw nsw i32 %18160, %18159" -> "  %18162 = lshr i32 %18161, 16"
"  %18162 = lshr i32 %18161, 16"
"  %18162 = lshr i32 %18161, 16" -> "  %18163 = add nuw i32 %18158, %18162"
"  %18163 = add nuw i32 %18158, %18162"
"  %18163 = add nuw i32 %18158, %18162" -> "  %18212 = add nuw i32 %18163, %18173"
"  %18164 = and i32 %18135, 65535"
"  %18164 = and i32 %18135, 65535" -> "  %18166 = add nuw nsw i32 %18164, %18165"
"  %18165 = and i32 %18153, 65535"
"  %18165 = and i32 %18153, 65535" -> "  %18166 = add nuw nsw i32 %18164, %18165"
"  %18166 = add nuw nsw i32 %18164, %18165"
"  %18166 = add nuw nsw i32 %18164, %18165" -> "  %18201 = and i32 %18166, 65535""  %18166 = add nuw nsw i32 %18164, %18165" -> "  %18170 = lshr i32 %18166, 16"
"  %18167 = lshr i32 %18135, 16"
"  %18167 = lshr i32 %18135, 16" -> "  %18169 = add nuw nsw i32 %18168, %18167"
"  %18168 = and i32 %18161, 65535"
"  %18168 = and i32 %18161, 65535" -> "  %18169 = add nuw nsw i32 %18168, %18167"
"  %18169 = add nuw nsw i32 %18168, %18167"
"  %18169 = add nuw nsw i32 %18168, %18167" -> "  %18173 = lshr i32 %18169, 16""  %18169 = add nuw nsw i32 %18168, %18167" -> "  %18171 = and i32 %18169, 65535"
"  %18170 = lshr i32 %18166, 16"
"  %18170 = lshr i32 %18166, 16" -> "  %18172 = add nuw nsw i32 %18171, %18170"
"  %18171 = and i32 %18169, 65535"
"  %18171 = and i32 %18169, 65535" -> "  %18172 = add nuw nsw i32 %18171, %18170"
"  %18172 = add nuw nsw i32 %18171, %18170"
"  %18172 = add nuw nsw i32 %18171, %18170" -> "  %18208 = and i32 %18172, 65535""  %18172 = add nuw nsw i32 %18171, %18170" -> "  %18174 = lshr i32 %18172, 16"
"  %18173 = lshr i32 %18169, 16"
"  %18173 = lshr i32 %18169, 16" -> "  %18212 = add nuw i32 %18163, %18173"
"  %18174 = lshr i32 %18172, 16"
"  %18174 = lshr i32 %18172, 16" -> "  %18213 = add nuw i32 %18212, %18174"
"  %18175 = and i32 %18051, 65532"
"  %18175 = and i32 %18051, 65532" -> "  %18177 = add nuw nsw i32 %18176, %18175"
"  %18176 = and i32 %18035, 65535"
"  %18176 = and i32 %18035, 65535" -> "  %18177 = add nuw nsw i32 %18176, %18175"
"  %18177 = add nuw nsw i32 %18176, %18175"
"  %18177 = add nuw nsw i32 %18176, %18175" -> "  %18338 = and i32 %18177, 65535""  %18177 = add nuw nsw i32 %18176, %18175" -> "  %18181 = lshr i32 %18177, 16"
"  %18178 = and i32 %18060, 65535"
"  %18178 = and i32 %18060, 65535" -> "  %18180 = add nuw nsw i32 %18179, %18178"
"  %18179 = and i32 %18041, 65535"
"  %18179 = and i32 %18041, 65535" -> "  %18180 = add nuw nsw i32 %18179, %18178"
"  %18180 = add nuw nsw i32 %18179, %18178"
"  %18180 = add nuw nsw i32 %18179, %18178" -> "  %18194 = lshr i32 %18180, 16""  %18180 = add nuw nsw i32 %18179, %18178" -> "  %18182 = and i32 %18180, 65535"
"  %18181 = lshr i32 %18177, 16"
"  %18181 = lshr i32 %18177, 16" -> "  %18183 = add nuw nsw i32 %18182, %18181"
"  %18182 = and i32 %18180, 65535"
"  %18182 = and i32 %18180, 65535" -> "  %18183 = add nuw nsw i32 %18182, %18181"
"  %18183 = add nuw nsw i32 %18182, %18181"
"  %18183 = add nuw nsw i32 %18182, %18181" -> "  %18341 = and i32 %18183, 65535""  %18183 = add nuw nsw i32 %18182, %18181" -> "  %18195 = lshr i32 %18183, 16"
"  %18184 = and i32 %18048, 65535"
"  %18184 = and i32 %18048, 65535" -> "  %18186 = add nuw nsw i32 %18184, %18185"
"  %18185 = and i32 %18125, 65535"
"  %18185 = and i32 %18125, 65535" -> "  %18186 = add nuw nsw i32 %18184, %18185"
"  %18186 = add nuw nsw i32 %18184, %18185"
"  %18186 = add nuw nsw i32 %18184, %18185" -> "  %18193 = and i32 %18186, 65535""  %18186 = add nuw nsw i32 %18184, %18185" -> "  %18190 = lshr i32 %18186, 16"
"  %18187 = lshr i32 %18048, 16"
"  %18187 = lshr i32 %18048, 16" -> "  %18189 = add nuw nsw i32 %18187, %18188"
"  %18188 = and i32 %18133, 65535"
"  %18188 = and i32 %18133, 65535" -> "  %18189 = add nuw nsw i32 %18187, %18188"
"  %18189 = add nuw nsw i32 %18187, %18188"
"  %18189 = add nuw nsw i32 %18187, %18188" -> "  %18202 = lshr i32 %18189, 16""  %18189 = add nuw nsw i32 %18187, %18188" -> "  %18191 = and i32 %18189, 65535"
"  %18190 = lshr i32 %18186, 16"
"  %18190 = lshr i32 %18186, 16" -> "  %18192 = add nuw nsw i32 %18191, %18190"
"  %18191 = and i32 %18189, 65535"
"  %18191 = and i32 %18189, 65535" -> "  %18192 = add nuw nsw i32 %18191, %18190"
"  %18192 = add nuw nsw i32 %18191, %18190"
"  %18192 = add nuw nsw i32 %18191, %18190" -> "  %18204 = lshr i32 %18192, 16""  %18192 = add nuw nsw i32 %18191, %18190" -> "  %18199 = and i32 %18192, 65535"
"  %18193 = and i32 %18186, 65535"
"  %18193 = and i32 %18186, 65535" -> "  %18196 = add nuw nsw i32 %18193, %18194"
"  %18194 = lshr i32 %18180, 16"
"  %18194 = lshr i32 %18180, 16" -> "  %18196 = add nuw nsw i32 %18193, %18194"
"  %18195 = lshr i32 %18183, 16"
"  %18195 = lshr i32 %18183, 16" -> "  %18197 = add nuw nsw i32 %18196, %18195"
"  %18196 = add nuw nsw i32 %18193, %18194"
"  %18196 = add nuw nsw i32 %18193, %18194" -> "  %18197 = add nuw nsw i32 %18196, %18195"
"  %18197 = add nuw nsw i32 %18196, %18195"
"  %18197 = add nuw nsw i32 %18196, %18195" -> "  %18348 = and i32 %18197, 65535""  %18197 = add nuw nsw i32 %18196, %18195" -> "  %18198 = lshr i32 %18197, 16"
"  %18198 = lshr i32 %18197, 16"
"  %18198 = lshr i32 %18197, 16" -> "  %18200 = add nuw nsw i32 %18198, %18199"
"  %18199 = and i32 %18192, 65535"
"  %18199 = and i32 %18192, 65535" -> "  %18200 = add nuw nsw i32 %18198, %18199"
"  %18200 = add nuw nsw i32 %18198, %18199"
"  %18200 = add nuw nsw i32 %18198, %18199" -> "  %18352 = and i32 %18200, 65535""  %18200 = add nuw nsw i32 %18198, %18199" -> "  %18206 = lshr i32 %18200, 16"
"  %18201 = and i32 %18166, 65535"
"  %18201 = and i32 %18166, 65535" -> "  %18203 = add nuw nsw i32 %18201, %18202"
"  %18202 = lshr i32 %18189, 16"
"  %18202 = lshr i32 %18189, 16" -> "  %18203 = add nuw nsw i32 %18201, %18202"
"  %18203 = add nuw nsw i32 %18201, %18202"
"  %18203 = add nuw nsw i32 %18201, %18202" -> "  %18205 = add nuw nsw i32 %18203, %18204"
"  %18204 = lshr i32 %18192, 16"
"  %18204 = lshr i32 %18192, 16" -> "  %18205 = add nuw nsw i32 %18203, %18204"
"  %18205 = add nuw nsw i32 %18203, %18204"
"  %18205 = add nuw nsw i32 %18203, %18204" -> "  %18207 = add nuw nsw i32 %18205, %18206"
"  %18206 = lshr i32 %18200, 16"
"  %18206 = lshr i32 %18200, 16" -> "  %18207 = add nuw nsw i32 %18205, %18206"
"  %18207 = add nuw nsw i32 %18205, %18206"
"  %18207 = add nuw nsw i32 %18205, %18206" -> "  %18500 = and i32 %18207, 65535""  %18207 = add nuw nsw i32 %18205, %18206" -> "  %18209 = lshr i32 %18207, 16"
"  %18208 = and i32 %18172, 65535"
"  %18208 = and i32 %18172, 65535" -> "  %18210 = add nuw nsw i32 %18209, %18208"
"  %18209 = lshr i32 %18207, 16"
"  %18209 = lshr i32 %18207, 16" -> "  %18210 = add nuw nsw i32 %18209, %18208"
"  %18210 = add nuw nsw i32 %18209, %18208"
"  %18210 = add nuw nsw i32 %18209, %18208" -> "  %18503 = and i32 %18210, 65535""  %18210 = add nuw nsw i32 %18209, %18208" -> "  %18211 = lshr i32 %18210, 16"
"  %18211 = lshr i32 %18210, 16"
"  %18211 = lshr i32 %18210, 16" -> "  %18214 = add nuw i32 %18213, %18211"
"  %18212 = add nuw i32 %18163, %18173"
"  %18212 = add nuw i32 %18163, %18173" -> "  %18213 = add nuw i32 %18212, %18174"
"  %18213 = add nuw i32 %18212, %18174"
"  %18213 = add nuw i32 %18212, %18174" -> "  %18214 = add nuw i32 %18213, %18211"
"  %18214 = add nuw i32 %18213, %18211"
"  %18214 = add nuw i32 %18213, %18211" -> "  %18508 = and i32 %18214, 65535""  %18214 = add nuw i32 %18213, %18211" -> "  %18511 = lshr i32 %18214, 16"
"  %18215 = mul nuw nsw i32 %17915, 17857"
"  %18215 = mul nuw nsw i32 %17915, 17857" -> "  %18337 = and i32 %18215, 65535""  %18215 = mul nuw nsw i32 %17915, 17857" -> "  %18216 = lshr i32 %18215, 16"
"  %18216 = lshr i32 %18215, 16"
"  %18216 = lshr i32 %18215, 16" -> "  %18219 = add nuw nsw i32 %18218, %18216"
"  %18217 = mul nuw nsw i32 %17918, 17857"
"  %18217 = mul nuw nsw i32 %17918, 17857" -> "  %18220 = and i32 %18217, 2147418112""  %18217 = mul nuw nsw i32 %17918, 17857" -> "  %18218 = and i32 %18217, 65535"
"  %18218 = and i32 %18217, 65535"
"  %18218 = and i32 %18217, 65535" -> "  %18219 = add nuw nsw i32 %18218, %18216"
"  %18219 = add nuw nsw i32 %18218, %18216"
"  %18219 = add nuw nsw i32 %18218, %18216" -> "  %18221 = add nuw nsw i32 %18219, %18220"
"  %18220 = and i32 %18217, 2147418112"
"  %18220 = and i32 %18217, 2147418112" -> "  %18221 = add nuw nsw i32 %18219, %18220"
"  %18221 = add nuw nsw i32 %18219, %18220"
"  %18221 = add nuw nsw i32 %18219, %18220" -> "  %18225 = lshr i32 %18221, 16""  %18221 = add nuw nsw i32 %18219, %18220" -> "  %18223 = and i32 %18221, 65535"
"  %18222 = mul nuw i32 %17915, 46547"
"  %18222 = mul nuw i32 %17915, 46547" -> "  %18224 = add nuw i32 %18223, %18222"
"  %18223 = and i32 %18221, 65535"
"  %18223 = and i32 %18221, 65535" -> "  %18224 = add nuw i32 %18223, %18222"
"  %18224 = add nuw i32 %18223, %18222"
"  %18224 = add nuw i32 %18223, %18222" -> "  %18340 = and i32 %18224, 65535""  %18224 = add nuw i32 %18223, %18222" -> "  %18228 = lshr i32 %18224, 16"
"  %18225 = lshr i32 %18221, 16"
"  %18225 = lshr i32 %18221, 16" -> "  %18227 = add nuw i32 %18225, %18226"
"  %18226 = mul nuw i32 %17918, 46547"
"  %18226 = mul nuw i32 %17918, 46547" -> "  %18227 = add nuw i32 %18225, %18226"
"  %18227 = add nuw i32 %18225, %18226"
"  %18227 = add nuw i32 %18225, %18226" -> "  %18231 = and i32 %18227, -65536""  %18227 = add nuw i32 %18225, %18226" -> "  %18229 = and i32 %18227, 65535"
"  %18228 = lshr i32 %18224, 16"
"  %18228 = lshr i32 %18224, 16" -> "  %18230 = add nuw nsw i32 %18228, %18229"
"  %18229 = and i32 %18227, 65535"
"  %18229 = and i32 %18227, 65535" -> "  %18230 = add nuw nsw i32 %18228, %18229"
"  %18230 = add nuw nsw i32 %18228, %18229"
"  %18230 = add nuw nsw i32 %18228, %18229" -> "  %18232 = add nuw i32 %18230, %18231"
"  %18231 = and i32 %18227, -65536"
"  %18231 = and i32 %18227, -65536" -> "  %18232 = add nuw i32 %18230, %18231"
"  %18232 = add nuw i32 %18230, %18231"
"  %18232 = add nuw i32 %18230, %18231" -> "  %18255 = lshr i32 %18232, 16""  %18232 = add nuw i32 %18230, %18231" -> "  %18251 = and i32 %18232, 65535"
"  %18233 = mul nuw nsw i32 %17935, 17857"
"  %18233 = mul nuw nsw i32 %17935, 17857" -> "  %18252 = and i32 %18233, 65535""  %18233 = mul nuw nsw i32 %17935, 17857" -> "  %18234 = lshr i32 %18233, 16"
"  %18234 = lshr i32 %18233, 16"
"  %18234 = lshr i32 %18233, 16" -> "  %18237 = add nuw nsw i32 %18236, %18234"
"  %18235 = mul nuw nsw i32 %17938, 17857"
"  %18235 = mul nuw nsw i32 %17938, 17857" -> "  %18238 = and i32 %18235, 2147418112""  %18235 = mul nuw nsw i32 %17938, 17857" -> "  %18236 = and i32 %18235, 65535"
"  %18236 = and i32 %18235, 65535"
"  %18236 = and i32 %18235, 65535" -> "  %18237 = add nuw nsw i32 %18236, %18234"
"  %18237 = add nuw nsw i32 %18236, %18234"
"  %18237 = add nuw nsw i32 %18236, %18234" -> "  %18239 = add nuw nsw i32 %18237, %18238"
"  %18238 = and i32 %18235, 2147418112"
"  %18238 = and i32 %18235, 2147418112" -> "  %18239 = add nuw nsw i32 %18237, %18238"
"  %18239 = add nuw nsw i32 %18237, %18238"
"  %18239 = add nuw nsw i32 %18237, %18238" -> "  %18243 = lshr i32 %18239, 16""  %18239 = add nuw nsw i32 %18237, %18238" -> "  %18241 = and i32 %18239, 65535"
"  %18240 = mul nuw i32 %17935, 46547"
"  %18240 = mul nuw i32 %17935, 46547" -> "  %18242 = add nuw i32 %18241, %18240"
"  %18241 = and i32 %18239, 65535"
"  %18241 = and i32 %18239, 65535" -> "  %18242 = add nuw i32 %18241, %18240"
"  %18242 = add nuw i32 %18241, %18240"
"  %18242 = add nuw i32 %18241, %18240" -> "  %18254 = and i32 %18242, 65535""  %18242 = add nuw i32 %18241, %18240" -> "  %18246 = lshr i32 %18242, 16"
"  %18243 = lshr i32 %18239, 16"
"  %18243 = lshr i32 %18239, 16" -> "  %18245 = add nuw i32 %18243, %18244"
"  %18244 = mul nuw i32 %17938, 46547"
"  %18244 = mul nuw i32 %17938, 46547" -> "  %18245 = add nuw i32 %18243, %18244"
"  %18245 = add nuw i32 %18243, %18244"
"  %18245 = add nuw i32 %18243, %18244" -> "  %18249 = and i32 %18245, -65536""  %18245 = add nuw i32 %18243, %18244" -> "  %18247 = and i32 %18245, 65535"
"  %18246 = lshr i32 %18242, 16"
"  %18246 = lshr i32 %18242, 16" -> "  %18248 = add nuw nsw i32 %18246, %18247"
"  %18247 = and i32 %18245, 65535"
"  %18247 = and i32 %18245, 65535" -> "  %18248 = add nuw nsw i32 %18246, %18247"
"  %18248 = add nuw nsw i32 %18246, %18247"
"  %18248 = add nuw nsw i32 %18246, %18247" -> "  %18250 = add nuw i32 %18248, %18249"
"  %18249 = and i32 %18245, -65536"
"  %18249 = and i32 %18245, -65536" -> "  %18250 = add nuw i32 %18248, %18249"
"  %18250 = add nuw i32 %18248, %18249"
"  %18250 = add nuw i32 %18248, %18249" -> "  %18258 = add nuw i32 %18250, %18257"
"  %18251 = and i32 %18232, 65535"
"  %18251 = and i32 %18232, 65535" -> "  %18253 = add nuw nsw i32 %18251, %18252"
"  %18252 = and i32 %18233, 65535"
"  %18252 = and i32 %18233, 65535" -> "  %18253 = add nuw nsw i32 %18251, %18252"
"  %18253 = add nuw nsw i32 %18251, %18252"
"  %18253 = add nuw nsw i32 %18251, %18252" -> "  %18282 = and i32 %18253, 65535""  %18253 = add nuw nsw i32 %18251, %18252" -> "  %18260 = lshr i32 %18253, 16"
"  %18254 = and i32 %18242, 65535"
"  %18254 = and i32 %18242, 65535" -> "  %18256 = add nuw nsw i32 %18254, %18255"
"  %18255 = lshr i32 %18232, 16"
"  %18255 = lshr i32 %18232, 16" -> "  %18256 = add nuw nsw i32 %18254, %18255"
"  %18256 = add nuw nsw i32 %18254, %18255"
"  %18256 = add nuw nsw i32 %18254, %18255" -> "  %18259 = and i32 %18256, 65535""  %18256 = add nuw nsw i32 %18254, %18255" -> "  %18257 = lshr i32 %18256, 16"
"  %18257 = lshr i32 %18256, 16"
"  %18257 = lshr i32 %18256, 16" -> "  %18258 = add nuw i32 %18250, %18257"
"  %18258 = add nuw i32 %18250, %18257"
"  %18258 = add nuw i32 %18250, %18257" -> "  %18263 = add nuw i32 %18258, %18262"
"  %18259 = and i32 %18256, 65535"
"  %18259 = and i32 %18256, 65535" -> "  %18261 = add nuw nsw i32 %18259, %18260"
"  %18260 = lshr i32 %18253, 16"
"  %18260 = lshr i32 %18253, 16" -> "  %18261 = add nuw nsw i32 %18259, %18260"
"  %18261 = add nuw nsw i32 %18259, %18260"
"  %18261 = add nuw nsw i32 %18259, %18260" -> "  %18285 = and i32 %18261, 65535""  %18261 = add nuw nsw i32 %18259, %18260" -> "  %18262 = lshr i32 %18261, 16"
"  %18262 = lshr i32 %18261, 16"
"  %18262 = lshr i32 %18261, 16" -> "  %18263 = add nuw i32 %18258, %18262"
"  %18263 = add nuw i32 %18258, %18262"
"  %18263 = add nuw i32 %18258, %18262" -> "  %18317 = lshr i32 %18263, 16""  %18263 = add nuw i32 %18258, %18262" -> "  %18313 = and i32 %18263, 65535"
"  %18264 = mul nuw nsw i32 %17915, 31112"
"  %18264 = mul nuw nsw i32 %17915, 31112" -> "  %18283 = and i32 %18264, 65528""  %18264 = mul nuw nsw i32 %17915, 31112" -> "  %18265 = lshr i32 %18264, 16"
"  %18265 = lshr i32 %18264, 16"
"  %18265 = lshr i32 %18264, 16" -> "  %18268 = add nuw nsw i32 %18267, %18265"
"  %18266 = mul nuw nsw i32 %17918, 31112"
"  %18266 = mul nuw nsw i32 %17918, 31112" -> "  %18269 = and i32 %18266, 2147418112""  %18266 = mul nuw nsw i32 %17918, 31112" -> "  %18267 = and i32 %18266, 65528"
"  %18267 = and i32 %18266, 65528"
"  %18267 = and i32 %18266, 65528" -> "  %18268 = add nuw nsw i32 %18267, %18265"
"  %18268 = add nuw nsw i32 %18267, %18265"
"  %18268 = add nuw nsw i32 %18267, %18265" -> "  %18270 = add nuw nsw i32 %18268, %18269"
"  %18269 = and i32 %18266, 2147418112"
"  %18269 = and i32 %18266, 2147418112" -> "  %18270 = add nuw nsw i32 %18268, %18269"
"  %18270 = add nuw nsw i32 %18268, %18269"
"  %18270 = add nuw nsw i32 %18268, %18269" -> "  %18274 = lshr i32 %18270, 16""  %18270 = add nuw nsw i32 %18268, %18269" -> "  %18272 = and i32 %18270, 65535"
"  %18271 = mul nuw i32 %17915, 42170"
"  %18271 = mul nuw i32 %17915, 42170" -> "  %18273 = add nuw i32 %18272, %18271"
"  %18272 = and i32 %18270, 65535"
"  %18272 = and i32 %18270, 65535" -> "  %18273 = add nuw i32 %18272, %18271"
"  %18273 = add nuw i32 %18272, %18271"
"  %18273 = add nuw i32 %18272, %18271" -> "  %18286 = and i32 %18273, 65535""  %18273 = add nuw i32 %18272, %18271" -> "  %18277 = lshr i32 %18273, 16"
"  %18274 = lshr i32 %18270, 16"
"  %18274 = lshr i32 %18270, 16" -> "  %18276 = add nuw i32 %18274, %18275"
"  %18275 = mul nuw i32 %17918, 42170"
"  %18275 = mul nuw i32 %17918, 42170" -> "  %18276 = add nuw i32 %18274, %18275"
"  %18276 = add nuw i32 %18274, %18275"
"  %18276 = add nuw i32 %18274, %18275" -> "  %18280 = and i32 %18276, -65536""  %18276 = add nuw i32 %18274, %18275" -> "  %18278 = and i32 %18276, 65535"
"  %18277 = lshr i32 %18273, 16"
"  %18277 = lshr i32 %18273, 16" -> "  %18279 = add nuw nsw i32 %18277, %18278"
"  %18278 = and i32 %18276, 65535"
"  %18278 = and i32 %18276, 65535" -> "  %18279 = add nuw nsw i32 %18277, %18278"
"  %18279 = add nuw nsw i32 %18277, %18278"
"  %18279 = add nuw nsw i32 %18277, %18278" -> "  %18281 = add nuw i32 %18279, %18280"
"  %18280 = and i32 %18276, -65536"
"  %18280 = and i32 %18276, -65536" -> "  %18281 = add nuw i32 %18279, %18280"
"  %18281 = add nuw i32 %18279, %18280"
"  %18281 = add nuw i32 %18279, %18280" -> "  %18289 = add nuw i32 %18281, %18288"
"  %18282 = and i32 %18253, 65535"
"  %18282 = and i32 %18253, 65535" -> "  %18284 = add nuw nsw i32 %18282, %18283"
"  %18283 = and i32 %18264, 65528"
"  %18283 = and i32 %18264, 65528" -> "  %18284 = add nuw nsw i32 %18282, %18283"
"  %18284 = add nuw nsw i32 %18282, %18283"
"  %18284 = add nuw nsw i32 %18282, %18283" -> "  %18349 = and i32 %18284, 65535""  %18284 = add nuw nsw i32 %18282, %18283" -> "  %18291 = lshr i32 %18284, 16"
"  %18285 = and i32 %18261, 65535"
"  %18285 = and i32 %18261, 65535" -> "  %18287 = add nuw nsw i32 %18285, %18286"
"  %18286 = and i32 %18273, 65535"
"  %18286 = and i32 %18273, 65535" -> "  %18287 = add nuw nsw i32 %18285, %18286"
"  %18287 = add nuw nsw i32 %18285, %18286"
"  %18287 = add nuw nsw i32 %18285, %18286" -> "  %18290 = and i32 %18287, 65535""  %18287 = add nuw nsw i32 %18285, %18286" -> "  %18288 = lshr i32 %18287, 16"
"  %18288 = lshr i32 %18287, 16"
"  %18288 = lshr i32 %18287, 16" -> "  %18289 = add nuw i32 %18281, %18288"
"  %18289 = add nuw i32 %18281, %18288"
"  %18289 = add nuw i32 %18281, %18288" -> "  %18294 = add nuw i32 %18289, %18293"
"  %18290 = and i32 %18287, 65535"
"  %18290 = and i32 %18287, 65535" -> "  %18292 = add nuw nsw i32 %18290, %18291"
"  %18291 = lshr i32 %18284, 16"
"  %18291 = lshr i32 %18284, 16" -> "  %18292 = add nuw nsw i32 %18290, %18291"
"  %18292 = add nuw nsw i32 %18290, %18291"
"  %18292 = add nuw nsw i32 %18290, %18291" -> "  %18351 = and i32 %18292, 65535""  %18292 = add nuw nsw i32 %18290, %18291" -> "  %18293 = lshr i32 %18292, 16"
"  %18293 = lshr i32 %18292, 16"
"  %18293 = lshr i32 %18292, 16" -> "  %18294 = add nuw i32 %18289, %18293"
"  %18294 = add nuw i32 %18289, %18293"
"  %18294 = add nuw i32 %18289, %18293" -> "  %18326 = and i32 %18294, 65535""  %18294 = add nuw i32 %18289, %18293" -> "  %18329 = lshr i32 %18294, 16"
"  %18295 = mul nuw nsw i32 %17935, 31112"
"  %18295 = mul nuw nsw i32 %17935, 31112" -> "  %18314 = and i32 %18295, 65528""  %18295 = mul nuw nsw i32 %17935, 31112" -> "  %18296 = lshr i32 %18295, 16"
"  %18296 = lshr i32 %18295, 16"
"  %18296 = lshr i32 %18295, 16" -> "  %18299 = add nuw nsw i32 %18298, %18296"
"  %18297 = mul nuw nsw i32 %17938, 31112"
"  %18297 = mul nuw nsw i32 %17938, 31112" -> "  %18300 = and i32 %18297, 2147418112""  %18297 = mul nuw nsw i32 %17938, 31112" -> "  %18298 = and i32 %18297, 65528"
"  %18298 = and i32 %18297, 65528"
"  %18298 = and i32 %18297, 65528" -> "  %18299 = add nuw nsw i32 %18298, %18296"
"  %18299 = add nuw nsw i32 %18298, %18296"
"  %18299 = add nuw nsw i32 %18298, %18296" -> "  %18301 = add nuw nsw i32 %18299, %18300"
"  %18300 = and i32 %18297, 2147418112"
"  %18300 = and i32 %18297, 2147418112" -> "  %18301 = add nuw nsw i32 %18299, %18300"
"  %18301 = add nuw nsw i32 %18299, %18300"
"  %18301 = add nuw nsw i32 %18299, %18300" -> "  %18305 = lshr i32 %18301, 16""  %18301 = add nuw nsw i32 %18299, %18300" -> "  %18303 = and i32 %18301, 65535"
"  %18302 = mul nuw i32 %17935, 42170"
"  %18302 = mul nuw i32 %17935, 42170" -> "  %18304 = add nuw i32 %18303, %18302"
"  %18303 = and i32 %18301, 65535"
"  %18303 = and i32 %18301, 65535" -> "  %18304 = add nuw i32 %18303, %18302"
"  %18304 = add nuw i32 %18303, %18302"
"  %18304 = add nuw i32 %18303, %18302" -> "  %18316 = and i32 %18304, 65535""  %18304 = add nuw i32 %18303, %18302" -> "  %18308 = lshr i32 %18304, 16"
"  %18305 = lshr i32 %18301, 16"
"  %18305 = lshr i32 %18301, 16" -> "  %18307 = add nuw i32 %18305, %18306"
"  %18306 = mul nuw i32 %17938, 42170"
"  %18306 = mul nuw i32 %17938, 42170" -> "  %18307 = add nuw i32 %18305, %18306"
"  %18307 = add nuw i32 %18305, %18306"
"  %18307 = add nuw i32 %18305, %18306" -> "  %18311 = and i32 %18307, -65536""  %18307 = add nuw i32 %18305, %18306" -> "  %18309 = and i32 %18307, 65535"
"  %18308 = lshr i32 %18304, 16"
"  %18308 = lshr i32 %18304, 16" -> "  %18310 = add nuw nsw i32 %18308, %18309"
"  %18309 = and i32 %18307, 65535"
"  %18309 = and i32 %18307, 65535" -> "  %18310 = add nuw nsw i32 %18308, %18309"
"  %18310 = add nuw nsw i32 %18308, %18309"
"  %18310 = add nuw nsw i32 %18308, %18309" -> "  %18312 = add nuw i32 %18310, %18311"
"  %18311 = and i32 %18307, -65536"
"  %18311 = and i32 %18307, -65536" -> "  %18312 = add nuw i32 %18310, %18311"
"  %18312 = add nuw i32 %18310, %18311"
"  %18312 = add nuw i32 %18310, %18311" -> "  %18320 = add nuw i32 %18312, %18319"
"  %18313 = and i32 %18263, 65535"
"  %18313 = and i32 %18263, 65535" -> "  %18315 = add nuw nsw i32 %18313, %18314"
"  %18314 = and i32 %18295, 65528"
"  %18314 = and i32 %18295, 65528" -> "  %18315 = add nuw nsw i32 %18313, %18314"
"  %18315 = add nuw nsw i32 %18313, %18314"
"  %18315 = add nuw nsw i32 %18313, %18314" -> "  %18327 = and i32 %18315, 65535""  %18315 = add nuw nsw i32 %18313, %18314" -> "  %18322 = lshr i32 %18315, 16"
"  %18316 = and i32 %18304, 65535"
"  %18316 = and i32 %18304, 65535" -> "  %18318 = add nuw nsw i32 %18317, %18316"
"  %18317 = lshr i32 %18263, 16"
"  %18317 = lshr i32 %18263, 16" -> "  %18318 = add nuw nsw i32 %18317, %18316"
"  %18318 = add nuw nsw i32 %18317, %18316"
"  %18318 = add nuw nsw i32 %18317, %18316" -> "  %18321 = and i32 %18318, 65535""  %18318 = add nuw nsw i32 %18317, %18316" -> "  %18319 = lshr i32 %18318, 16"
"  %18319 = lshr i32 %18318, 16"
"  %18319 = lshr i32 %18318, 16" -> "  %18320 = add nuw i32 %18312, %18319"
"  %18320 = add nuw i32 %18312, %18319"
"  %18320 = add nuw i32 %18312, %18319" -> "  %18325 = add nuw i32 %18320, %18324"
"  %18321 = and i32 %18318, 65535"
"  %18321 = and i32 %18318, 65535" -> "  %18323 = add nuw nsw i32 %18322, %18321"
"  %18322 = lshr i32 %18315, 16"
"  %18322 = lshr i32 %18315, 16" -> "  %18323 = add nuw nsw i32 %18322, %18321"
"  %18323 = add nuw nsw i32 %18322, %18321"
"  %18323 = add nuw nsw i32 %18322, %18321" -> "  %18330 = and i32 %18323, 65535""  %18323 = add nuw nsw i32 %18322, %18321" -> "  %18324 = lshr i32 %18323, 16"
"  %18324 = lshr i32 %18323, 16"
"  %18324 = lshr i32 %18323, 16" -> "  %18325 = add nuw i32 %18320, %18324"
"  %18325 = add nuw i32 %18320, %18324"
"  %18325 = add nuw i32 %18320, %18324" -> "  %18374 = add nuw i32 %18325, %18335"
"  %18326 = and i32 %18294, 65535"
"  %18326 = and i32 %18294, 65535" -> "  %18328 = add nuw nsw i32 %18326, %18327"
"  %18327 = and i32 %18315, 65535"
"  %18327 = and i32 %18315, 65535" -> "  %18328 = add nuw nsw i32 %18326, %18327"
"  %18328 = add nuw nsw i32 %18326, %18327"
"  %18328 = add nuw nsw i32 %18326, %18327" -> "  %18363 = and i32 %18328, 65535""  %18328 = add nuw nsw i32 %18326, %18327" -> "  %18332 = lshr i32 %18328, 16"
"  %18329 = lshr i32 %18294, 16"
"  %18329 = lshr i32 %18294, 16" -> "  %18331 = add nuw nsw i32 %18329, %18330"
"  %18330 = and i32 %18323, 65535"
"  %18330 = and i32 %18323, 65535" -> "  %18331 = add nuw nsw i32 %18329, %18330"
"  %18331 = add nuw nsw i32 %18329, %18330"
"  %18331 = add nuw nsw i32 %18329, %18330" -> "  %18335 = lshr i32 %18331, 16""  %18331 = add nuw nsw i32 %18329, %18330" -> "  %18333 = and i32 %18331, 65535"
"  %18332 = lshr i32 %18328, 16"
"  %18332 = lshr i32 %18328, 16" -> "  %18334 = add nuw nsw i32 %18333, %18332"
"  %18333 = and i32 %18331, 65535"
"  %18333 = and i32 %18331, 65535" -> "  %18334 = add nuw nsw i32 %18333, %18332"
"  %18334 = add nuw nsw i32 %18333, %18332"
"  %18334 = add nuw nsw i32 %18333, %18332" -> "  %18370 = and i32 %18334, 65535""  %18334 = add nuw nsw i32 %18333, %18332" -> "  %18336 = lshr i32 %18334, 16"
"  %18335 = lshr i32 %18331, 16"
"  %18335 = lshr i32 %18331, 16" -> "  %18374 = add nuw i32 %18325, %18335"
"  %18336 = lshr i32 %18334, 16"
"  %18336 = lshr i32 %18334, 16" -> "  %18375 = add nuw i32 %18374, %18336"
"  %18337 = and i32 %18215, 65535"
"  %18337 = and i32 %18215, 65535" -> "  %18339 = add nuw nsw i32 %18338, %18337"
"  %18338 = and i32 %18177, 65535"
"  %18338 = and i32 %18177, 65535" -> "  %18339 = add nuw nsw i32 %18338, %18337"
"  %18339 = add nuw nsw i32 %18338, %18337"
"  %18339 = add nuw nsw i32 %18338, %18337" -> "  %18604 = and i32 %18339, 65535""  %18339 = add nuw nsw i32 %18338, %18337" -> "  %18343 = lshr i32 %18339, 16"
"  %18340 = and i32 %18224, 65535"
"  %18340 = and i32 %18224, 65535" -> "  %18342 = add nuw nsw i32 %18341, %18340"
"  %18341 = and i32 %18183, 65535"
"  %18341 = and i32 %18183, 65535" -> "  %18342 = add nuw nsw i32 %18341, %18340"
"  %18342 = add nuw nsw i32 %18341, %18340"
"  %18342 = add nuw nsw i32 %18341, %18340" -> "  %18346 = lshr i32 %18342, 16""  %18342 = add nuw nsw i32 %18341, %18340" -> "  %18344 = and i32 %18342, 65535"
"  %18343 = lshr i32 %18339, 16"
"  %18343 = lshr i32 %18339, 16" -> "  %18345 = add nuw nsw i32 %18344, %18343"
"  %18344 = and i32 %18342, 65535"
"  %18344 = and i32 %18342, 65535" -> "  %18345 = add nuw nsw i32 %18344, %18343"
"  %18345 = add nuw nsw i32 %18344, %18343"
"  %18345 = add nuw nsw i32 %18344, %18343" -> "  %18607 = and i32 %18345, 65535""  %18345 = add nuw nsw i32 %18344, %18343" -> "  %18347 = lshr i32 %18345, 16"
"  %18346 = lshr i32 %18342, 16"
"  %18346 = lshr i32 %18342, 16" -> "  %18358 = add nuw nsw i32 %18347, %18346"
"  %18347 = lshr i32 %18345, 16"
"  %18347 = lshr i32 %18345, 16" -> "  %18358 = add nuw nsw i32 %18347, %18346"
"  %18348 = and i32 %18197, 65535"
"  %18348 = and i32 %18197, 65535" -> "  %18350 = add nuw nsw i32 %18348, %18349"
"  %18349 = and i32 %18284, 65535"
"  %18349 = and i32 %18284, 65535" -> "  %18350 = add nuw nsw i32 %18348, %18349"
"  %18350 = add nuw nsw i32 %18348, %18349"
"  %18350 = add nuw nsw i32 %18348, %18349" -> "  %18357 = and i32 %18350, 65535""  %18350 = add nuw nsw i32 %18348, %18349" -> "  %18354 = lshr i32 %18350, 16"
"  %18351 = and i32 %18292, 65535"
"  %18351 = and i32 %18292, 65535" -> "  %18353 = add nuw nsw i32 %18352, %18351"
"  %18352 = and i32 %18200, 65535"
"  %18352 = and i32 %18200, 65535" -> "  %18353 = add nuw nsw i32 %18352, %18351"
"  %18353 = add nuw nsw i32 %18352, %18351"
"  %18353 = add nuw nsw i32 %18352, %18351" -> "  %18364 = lshr i32 %18353, 16""  %18353 = add nuw nsw i32 %18352, %18351" -> "  %18355 = and i32 %18353, 65535"
"  %18354 = lshr i32 %18350, 16"
"  %18354 = lshr i32 %18350, 16" -> "  %18356 = add nuw nsw i32 %18355, %18354"
"  %18355 = and i32 %18353, 65535"
"  %18355 = and i32 %18353, 65535" -> "  %18356 = add nuw nsw i32 %18355, %18354"
"  %18356 = add nuw nsw i32 %18355, %18354"
"  %18356 = add nuw nsw i32 %18355, %18354" -> "  %18366 = lshr i32 %18356, 16""  %18356 = add nuw nsw i32 %18355, %18354" -> "  %18361 = and i32 %18356, 65535"
"  %18357 = and i32 %18350, 65535"
"  %18357 = and i32 %18350, 65535" -> "  %18359 = add nuw nsw i32 %18358, %18357"
"  %18358 = add nuw nsw i32 %18347, %18346"
"  %18358 = add nuw nsw i32 %18347, %18346" -> "  %18359 = add nuw nsw i32 %18358, %18357"
"  %18359 = add nuw nsw i32 %18358, %18357"
"  %18359 = add nuw nsw i32 %18358, %18357" -> "  %18613 = and i32 %18359, 65535""  %18359 = add nuw nsw i32 %18358, %18357" -> "  %18360 = lshr i32 %18359, 16"
"  %18360 = lshr i32 %18359, 16"
"  %18360 = lshr i32 %18359, 16" -> "  %18362 = add nuw nsw i32 %18361, %18360"
"  %18361 = and i32 %18356, 65535"
"  %18361 = and i32 %18356, 65535" -> "  %18362 = add nuw nsw i32 %18361, %18360"
"  %18362 = add nuw nsw i32 %18361, %18360"
"  %18362 = add nuw nsw i32 %18361, %18360" -> "  %18616 = and i32 %18362, 65535""  %18362 = add nuw nsw i32 %18361, %18360" -> "  %18368 = lshr i32 %18362, 16"
"  %18363 = and i32 %18328, 65535"
"  %18363 = and i32 %18328, 65535" -> "  %18365 = add nuw nsw i32 %18364, %18363"
"  %18364 = lshr i32 %18353, 16"
"  %18364 = lshr i32 %18353, 16" -> "  %18365 = add nuw nsw i32 %18364, %18363"
"  %18365 = add nuw nsw i32 %18364, %18363"
"  %18365 = add nuw nsw i32 %18364, %18363" -> "  %18367 = add nuw nsw i32 %18365, %18366"
"  %18366 = lshr i32 %18356, 16"
"  %18366 = lshr i32 %18356, 16" -> "  %18367 = add nuw nsw i32 %18365, %18366"
"  %18367 = add nuw nsw i32 %18365, %18366"
"  %18367 = add nuw nsw i32 %18365, %18366" -> "  %18369 = add nuw nsw i32 %18367, %18368"
"  %18368 = lshr i32 %18362, 16"
"  %18368 = lshr i32 %18362, 16" -> "  %18369 = add nuw nsw i32 %18367, %18368"
"  %18369 = add nuw nsw i32 %18367, %18368"
"  %18369 = add nuw nsw i32 %18367, %18368" -> "  %18537 = and i32 %18369, 65535""  %18369 = add nuw nsw i32 %18367, %18368" -> "  %18371 = lshr i32 %18369, 16"
"  %18370 = and i32 %18334, 65535"
"  %18370 = and i32 %18334, 65535" -> "  %18372 = add nuw nsw i32 %18371, %18370"
"  %18371 = lshr i32 %18369, 16"
"  %18371 = lshr i32 %18369, 16" -> "  %18372 = add nuw nsw i32 %18371, %18370"
"  %18372 = add nuw nsw i32 %18371, %18370"
"  %18372 = add nuw nsw i32 %18371, %18370" -> "  %18540 = and i32 %18372, 65535""  %18372 = add nuw nsw i32 %18371, %18370" -> "  %18373 = lshr i32 %18372, 16"
"  %18373 = lshr i32 %18372, 16"
"  %18373 = lshr i32 %18372, 16" -> "  %18376 = add nuw i32 %18375, %18373"
"  %18374 = add nuw i32 %18325, %18335"
"  %18374 = add nuw i32 %18325, %18335" -> "  %18375 = add nuw i32 %18374, %18336"
"  %18375 = add nuw i32 %18374, %18336"
"  %18375 = add nuw i32 %18374, %18336" -> "  %18376 = add nuw i32 %18375, %18373"
"  %18376 = add nuw i32 %18375, %18373"
"  %18376 = add nuw i32 %18375, %18373" -> "  %18546 = and i32 %18376, 65535""  %18376 = add nuw i32 %18375, %18373" -> "  %18549 = lshr i32 %18376, 16"
"  %18377 = mul nuw nsw i32 %18049, 17857"
"  %18377 = mul nuw nsw i32 %18049, 17857" -> "  %18499 = and i32 %18377, 65535""  %18377 = mul nuw nsw i32 %18049, 17857" -> "  %18378 = lshr i32 %18377, 16"
"  %18378 = lshr i32 %18377, 16"
"  %18378 = lshr i32 %18377, 16" -> "  %18381 = add nuw nsw i32 %18380, %18378"
"  %18379 = mul nuw nsw i32 %18050, 17857"
"  %18379 = mul nuw nsw i32 %18050, 17857" -> "  %18382 = and i32 %18379, 2147418112""  %18379 = mul nuw nsw i32 %18050, 17857" -> "  %18380 = and i32 %18379, 65535"
"  %18380 = and i32 %18379, 65535"
"  %18380 = and i32 %18379, 65535" -> "  %18381 = add nuw nsw i32 %18380, %18378"
"  %18381 = add nuw nsw i32 %18380, %18378"
"  %18381 = add nuw nsw i32 %18380, %18378" -> "  %18383 = add nuw nsw i32 %18381, %18382"
"  %18382 = and i32 %18379, 2147418112"
"  %18382 = and i32 %18379, 2147418112" -> "  %18383 = add nuw nsw i32 %18381, %18382"
"  %18383 = add nuw nsw i32 %18381, %18382"
"  %18383 = add nuw nsw i32 %18381, %18382" -> "  %18387 = lshr i32 %18383, 16""  %18383 = add nuw nsw i32 %18381, %18382" -> "  %18385 = and i32 %18383, 65535"
"  %18384 = mul nuw i32 %18049, 46547"
"  %18384 = mul nuw i32 %18049, 46547" -> "  %18386 = add nuw i32 %18385, %18384"
"  %18385 = and i32 %18383, 65535"
"  %18385 = and i32 %18383, 65535" -> "  %18386 = add nuw i32 %18385, %18384"
"  %18386 = add nuw i32 %18385, %18384"
"  %18386 = add nuw i32 %18385, %18384" -> "  %18502 = and i32 %18386, 65535""  %18386 = add nuw i32 %18385, %18384" -> "  %18390 = lshr i32 %18386, 16"
"  %18387 = lshr i32 %18383, 16"
"  %18387 = lshr i32 %18383, 16" -> "  %18389 = add nuw i32 %18387, %18388"
"  %18388 = mul nuw i32 %18050, 46547"
"  %18388 = mul nuw i32 %18050, 46547" -> "  %18389 = add nuw i32 %18387, %18388"
"  %18389 = add nuw i32 %18387, %18388"
"  %18389 = add nuw i32 %18387, %18388" -> "  %18393 = and i32 %18389, -65536""  %18389 = add nuw i32 %18387, %18388" -> "  %18391 = and i32 %18389, 65535"
"  %18390 = lshr i32 %18386, 16"
"  %18390 = lshr i32 %18386, 16" -> "  %18392 = add nuw nsw i32 %18390, %18391"
"  %18391 = and i32 %18389, 65535"
"  %18391 = and i32 %18389, 65535" -> "  %18392 = add nuw nsw i32 %18390, %18391"
"  %18392 = add nuw nsw i32 %18390, %18391"
"  %18392 = add nuw nsw i32 %18390, %18391" -> "  %18394 = add nuw i32 %18392, %18393"
"  %18393 = and i32 %18389, -65536"
"  %18393 = and i32 %18389, -65536" -> "  %18394 = add nuw i32 %18392, %18393"
"  %18394 = add nuw i32 %18392, %18393"
"  %18394 = add nuw i32 %18392, %18393" -> "  %18417 = lshr i32 %18394, 16""  %18394 = add nuw i32 %18392, %18393" -> "  %18413 = and i32 %18394, 65535"
"  %18395 = mul nuw nsw i32 %18069, 17857"
"  %18395 = mul nuw nsw i32 %18069, 17857" -> "  %18414 = and i32 %18395, 65535""  %18395 = mul nuw nsw i32 %18069, 17857" -> "  %18396 = lshr i32 %18395, 16"
"  %18396 = lshr i32 %18395, 16"
"  %18396 = lshr i32 %18395, 16" -> "  %18399 = add nuw nsw i32 %18398, %18396"
"  %18397 = mul nuw nsw i32 %18070, 17857"
"  %18397 = mul nuw nsw i32 %18070, 17857" -> "  %18400 = and i32 %18397, 2147418112""  %18397 = mul nuw nsw i32 %18070, 17857" -> "  %18398 = and i32 %18397, 65535"
"  %18398 = and i32 %18397, 65535"
"  %18398 = and i32 %18397, 65535" -> "  %18399 = add nuw nsw i32 %18398, %18396"
"  %18399 = add nuw nsw i32 %18398, %18396"
"  %18399 = add nuw nsw i32 %18398, %18396" -> "  %18401 = add nuw nsw i32 %18399, %18400"
"  %18400 = and i32 %18397, 2147418112"
"  %18400 = and i32 %18397, 2147418112" -> "  %18401 = add nuw nsw i32 %18399, %18400"
"  %18401 = add nuw nsw i32 %18399, %18400"
"  %18401 = add nuw nsw i32 %18399, %18400" -> "  %18405 = lshr i32 %18401, 16""  %18401 = add nuw nsw i32 %18399, %18400" -> "  %18403 = and i32 %18401, 65535"
"  %18402 = mul nuw i32 %18069, 46547"
"  %18402 = mul nuw i32 %18069, 46547" -> "  %18404 = add nuw i32 %18403, %18402"
"  %18403 = and i32 %18401, 65535"
"  %18403 = and i32 %18401, 65535" -> "  %18404 = add nuw i32 %18403, %18402"
"  %18404 = add nuw i32 %18403, %18402"
"  %18404 = add nuw i32 %18403, %18402" -> "  %18416 = and i32 %18404, 65535""  %18404 = add nuw i32 %18403, %18402" -> "  %18408 = lshr i32 %18404, 16"
"  %18405 = lshr i32 %18401, 16"
"  %18405 = lshr i32 %18401, 16" -> "  %18407 = add nuw i32 %18405, %18406"
"  %18406 = mul nuw i32 %18070, 46547"
"  %18406 = mul nuw i32 %18070, 46547" -> "  %18407 = add nuw i32 %18405, %18406"
"  %18407 = add nuw i32 %18405, %18406"
"  %18407 = add nuw i32 %18405, %18406" -> "  %18411 = and i32 %18407, -65536""  %18407 = add nuw i32 %18405, %18406" -> "  %18409 = and i32 %18407, 65535"
"  %18408 = lshr i32 %18404, 16"
"  %18408 = lshr i32 %18404, 16" -> "  %18410 = add nuw nsw i32 %18408, %18409"
"  %18409 = and i32 %18407, 65535"
"  %18409 = and i32 %18407, 65535" -> "  %18410 = add nuw nsw i32 %18408, %18409"
"  %18410 = add nuw nsw i32 %18408, %18409"
"  %18410 = add nuw nsw i32 %18408, %18409" -> "  %18412 = add nuw i32 %18410, %18411"
"  %18411 = and i32 %18407, -65536"
"  %18411 = and i32 %18407, -65536" -> "  %18412 = add nuw i32 %18410, %18411"
"  %18412 = add nuw i32 %18410, %18411"
"  %18412 = add nuw i32 %18410, %18411" -> "  %18420 = add nuw i32 %18412, %18419"
"  %18413 = and i32 %18394, 65535"
"  %18413 = and i32 %18394, 65535" -> "  %18415 = add nuw nsw i32 %18413, %18414"
"  %18414 = and i32 %18395, 65535"
"  %18414 = and i32 %18395, 65535" -> "  %18415 = add nuw nsw i32 %18413, %18414"
"  %18415 = add nuw nsw i32 %18413, %18414"
"  %18415 = add nuw nsw i32 %18413, %18414" -> "  %18444 = and i32 %18415, 65535""  %18415 = add nuw nsw i32 %18413, %18414" -> "  %18422 = lshr i32 %18415, 16"
"  %18416 = and i32 %18404, 65535"
"  %18416 = and i32 %18404, 65535" -> "  %18418 = add nuw nsw i32 %18417, %18416"
"  %18417 = lshr i32 %18394, 16"
"  %18417 = lshr i32 %18394, 16" -> "  %18418 = add nuw nsw i32 %18417, %18416"
"  %18418 = add nuw nsw i32 %18417, %18416"
"  %18418 = add nuw nsw i32 %18417, %18416" -> "  %18421 = and i32 %18418, 65535""  %18418 = add nuw nsw i32 %18417, %18416" -> "  %18419 = lshr i32 %18418, 16"
"  %18419 = lshr i32 %18418, 16"
"  %18419 = lshr i32 %18418, 16" -> "  %18420 = add nuw i32 %18412, %18419"
"  %18420 = add nuw i32 %18412, %18419"
"  %18420 = add nuw i32 %18412, %18419" -> "  %18425 = add nuw i32 %18420, %18424"
"  %18421 = and i32 %18418, 65535"
"  %18421 = and i32 %18418, 65535" -> "  %18423 = add nuw nsw i32 %18421, %18422"
"  %18422 = lshr i32 %18415, 16"
"  %18422 = lshr i32 %18415, 16" -> "  %18423 = add nuw nsw i32 %18421, %18422"
"  %18423 = add nuw nsw i32 %18421, %18422"
"  %18423 = add nuw nsw i32 %18421, %18422" -> "  %18447 = and i32 %18423, 65535""  %18423 = add nuw nsw i32 %18421, %18422" -> "  %18424 = lshr i32 %18423, 16"
"  %18424 = lshr i32 %18423, 16"
"  %18424 = lshr i32 %18423, 16" -> "  %18425 = add nuw i32 %18420, %18424"
"  %18425 = add nuw i32 %18420, %18424"
"  %18425 = add nuw i32 %18420, %18424" -> "  %18479 = lshr i32 %18425, 16""  %18425 = add nuw i32 %18420, %18424" -> "  %18475 = and i32 %18425, 65535"
"  %18426 = mul nuw nsw i32 %18049, 31112"
"  %18426 = mul nuw nsw i32 %18049, 31112" -> "  %18445 = and i32 %18426, 65528""  %18426 = mul nuw nsw i32 %18049, 31112" -> "  %18427 = lshr i32 %18426, 16"
"  %18427 = lshr i32 %18426, 16"
"  %18427 = lshr i32 %18426, 16" -> "  %18430 = add nuw nsw i32 %18429, %18427"
"  %18428 = mul nuw nsw i32 %18050, 31112"
"  %18428 = mul nuw nsw i32 %18050, 31112" -> "  %18431 = and i32 %18428, 2147418112""  %18428 = mul nuw nsw i32 %18050, 31112" -> "  %18429 = and i32 %18428, 65528"
"  %18429 = and i32 %18428, 65528"
"  %18429 = and i32 %18428, 65528" -> "  %18430 = add nuw nsw i32 %18429, %18427"
"  %18430 = add nuw nsw i32 %18429, %18427"
"  %18430 = add nuw nsw i32 %18429, %18427" -> "  %18432 = add nuw nsw i32 %18430, %18431"
"  %18431 = and i32 %18428, 2147418112"
"  %18431 = and i32 %18428, 2147418112" -> "  %18432 = add nuw nsw i32 %18430, %18431"
"  %18432 = add nuw nsw i32 %18430, %18431"
"  %18432 = add nuw nsw i32 %18430, %18431" -> "  %18436 = lshr i32 %18432, 16""  %18432 = add nuw nsw i32 %18430, %18431" -> "  %18434 = and i32 %18432, 65535"
"  %18433 = mul nuw i32 %18049, 42170"
"  %18433 = mul nuw i32 %18049, 42170" -> "  %18435 = add nuw i32 %18434, %18433"
"  %18434 = and i32 %18432, 65535"
"  %18434 = and i32 %18432, 65535" -> "  %18435 = add nuw i32 %18434, %18433"
"  %18435 = add nuw i32 %18434, %18433"
"  %18435 = add nuw i32 %18434, %18433" -> "  %18448 = and i32 %18435, 65535""  %18435 = add nuw i32 %18434, %18433" -> "  %18439 = lshr i32 %18435, 16"
"  %18436 = lshr i32 %18432, 16"
"  %18436 = lshr i32 %18432, 16" -> "  %18438 = add nuw i32 %18436, %18437"
"  %18437 = mul nuw i32 %18050, 42170"
"  %18437 = mul nuw i32 %18050, 42170" -> "  %18438 = add nuw i32 %18436, %18437"
"  %18438 = add nuw i32 %18436, %18437"
"  %18438 = add nuw i32 %18436, %18437" -> "  %18442 = and i32 %18438, -65536""  %18438 = add nuw i32 %18436, %18437" -> "  %18440 = and i32 %18438, 65535"
"  %18439 = lshr i32 %18435, 16"
"  %18439 = lshr i32 %18435, 16" -> "  %18441 = add nuw nsw i32 %18439, %18440"
"  %18440 = and i32 %18438, 65535"
"  %18440 = and i32 %18438, 65535" -> "  %18441 = add nuw nsw i32 %18439, %18440"
"  %18441 = add nuw nsw i32 %18439, %18440"
"  %18441 = add nuw nsw i32 %18439, %18440" -> "  %18443 = add nuw i32 %18441, %18442"
"  %18442 = and i32 %18438, -65536"
"  %18442 = and i32 %18438, -65536" -> "  %18443 = add nuw i32 %18441, %18442"
"  %18443 = add nuw i32 %18441, %18442"
"  %18443 = add nuw i32 %18441, %18442" -> "  %18451 = add nuw i32 %18443, %18450"
"  %18444 = and i32 %18415, 65535"
"  %18444 = and i32 %18415, 65535" -> "  %18446 = add nuw nsw i32 %18444, %18445"
"  %18445 = and i32 %18426, 65528"
"  %18445 = and i32 %18426, 65528" -> "  %18446 = add nuw nsw i32 %18444, %18445"
"  %18446 = add nuw nsw i32 %18444, %18445"
"  %18446 = add nuw nsw i32 %18444, %18445" -> "  %18509 = and i32 %18446, 65535""  %18446 = add nuw nsw i32 %18444, %18445" -> "  %18453 = lshr i32 %18446, 16"
"  %18447 = and i32 %18423, 65535"
"  %18447 = and i32 %18423, 65535" -> "  %18449 = add nuw nsw i32 %18447, %18448"
"  %18448 = and i32 %18435, 65535"
"  %18448 = and i32 %18435, 65535" -> "  %18449 = add nuw nsw i32 %18447, %18448"
"  %18449 = add nuw nsw i32 %18447, %18448"
"  %18449 = add nuw nsw i32 %18447, %18448" -> "  %18452 = and i32 %18449, 65535""  %18449 = add nuw nsw i32 %18447, %18448" -> "  %18450 = lshr i32 %18449, 16"
"  %18450 = lshr i32 %18449, 16"
"  %18450 = lshr i32 %18449, 16" -> "  %18451 = add nuw i32 %18443, %18450"
"  %18451 = add nuw i32 %18443, %18450"
"  %18451 = add nuw i32 %18443, %18450" -> "  %18456 = add nuw i32 %18451, %18455"
"  %18452 = and i32 %18449, 65535"
"  %18452 = and i32 %18449, 65535" -> "  %18454 = add nuw nsw i32 %18452, %18453"
"  %18453 = lshr i32 %18446, 16"
"  %18453 = lshr i32 %18446, 16" -> "  %18454 = add nuw nsw i32 %18452, %18453"
"  %18454 = add nuw nsw i32 %18452, %18453"
"  %18454 = add nuw nsw i32 %18452, %18453" -> "  %18512 = and i32 %18454, 65535""  %18454 = add nuw nsw i32 %18452, %18453" -> "  %18455 = lshr i32 %18454, 16"
"  %18455 = lshr i32 %18454, 16"
"  %18455 = lshr i32 %18454, 16" -> "  %18456 = add nuw i32 %18451, %18455"
"  %18456 = add nuw i32 %18451, %18455"
"  %18456 = add nuw i32 %18451, %18455" -> "  %18488 = and i32 %18456, 65535""  %18456 = add nuw i32 %18451, %18455" -> "  %18492 = lshr i32 %18456, 16"
"  %18457 = mul nuw nsw i32 %18069, 31112"
"  %18457 = mul nuw nsw i32 %18069, 31112" -> "  %18476 = and i32 %18457, 65528""  %18457 = mul nuw nsw i32 %18069, 31112" -> "  %18458 = lshr i32 %18457, 16"
"  %18458 = lshr i32 %18457, 16"
"  %18458 = lshr i32 %18457, 16" -> "  %18461 = add nuw nsw i32 %18460, %18458"
"  %18459 = mul nuw nsw i32 %18070, 31112"
"  %18459 = mul nuw nsw i32 %18070, 31112" -> "  %18462 = and i32 %18459, 2147418112""  %18459 = mul nuw nsw i32 %18070, 31112" -> "  %18460 = and i32 %18459, 65528"
"  %18460 = and i32 %18459, 65528"
"  %18460 = and i32 %18459, 65528" -> "  %18461 = add nuw nsw i32 %18460, %18458"
"  %18461 = add nuw nsw i32 %18460, %18458"
"  %18461 = add nuw nsw i32 %18460, %18458" -> "  %18463 = add nuw nsw i32 %18461, %18462"
"  %18462 = and i32 %18459, 2147418112"
"  %18462 = and i32 %18459, 2147418112" -> "  %18463 = add nuw nsw i32 %18461, %18462"
"  %18463 = add nuw nsw i32 %18461, %18462"
"  %18463 = add nuw nsw i32 %18461, %18462" -> "  %18467 = lshr i32 %18463, 16""  %18463 = add nuw nsw i32 %18461, %18462" -> "  %18465 = and i32 %18463, 65535"
"  %18464 = mul nuw i32 %18069, 42170"
"  %18464 = mul nuw i32 %18069, 42170" -> "  %18466 = add nuw i32 %18465, %18464"
"  %18465 = and i32 %18463, 65535"
"  %18465 = and i32 %18463, 65535" -> "  %18466 = add nuw i32 %18465, %18464"
"  %18466 = add nuw i32 %18465, %18464"
"  %18466 = add nuw i32 %18465, %18464" -> "  %18478 = and i32 %18466, 65535""  %18466 = add nuw i32 %18465, %18464" -> "  %18470 = lshr i32 %18466, 16"
"  %18467 = lshr i32 %18463, 16"
"  %18467 = lshr i32 %18463, 16" -> "  %18469 = add nuw i32 %18467, %18468"
"  %18468 = mul nuw i32 %18070, 42170"
"  %18468 = mul nuw i32 %18070, 42170" -> "  %18469 = add nuw i32 %18467, %18468"
"  %18469 = add nuw i32 %18467, %18468"
"  %18469 = add nuw i32 %18467, %18468" -> "  %18473 = and i32 %18469, -65536""  %18469 = add nuw i32 %18467, %18468" -> "  %18471 = and i32 %18469, 65535"
"  %18470 = lshr i32 %18466, 16"
"  %18470 = lshr i32 %18466, 16" -> "  %18472 = add nuw nsw i32 %18470, %18471"
"  %18471 = and i32 %18469, 65535"
"  %18471 = and i32 %18469, 65535" -> "  %18472 = add nuw nsw i32 %18470, %18471"
"  %18472 = add nuw nsw i32 %18470, %18471"
"  %18472 = add nuw nsw i32 %18470, %18471" -> "  %18474 = add nuw i32 %18472, %18473"
"  %18473 = and i32 %18469, -65536"
"  %18473 = and i32 %18469, -65536" -> "  %18474 = add nuw i32 %18472, %18473"
"  %18474 = add nuw i32 %18472, %18473"
"  %18474 = add nuw i32 %18472, %18473" -> "  %18482 = add nuw i32 %18474, %18481"
"  %18475 = and i32 %18425, 65535"
"  %18475 = and i32 %18425, 65535" -> "  %18477 = add nuw nsw i32 %18475, %18476"
"  %18476 = and i32 %18457, 65528"
"  %18476 = and i32 %18457, 65528" -> "  %18477 = add nuw nsw i32 %18475, %18476"
"  %18477 = add nuw nsw i32 %18475, %18476"
"  %18477 = add nuw nsw i32 %18475, %18476" -> "  %18489 = and i32 %18477, 65535""  %18477 = add nuw nsw i32 %18475, %18476" -> "  %18484 = lshr i32 %18477, 16"
"  %18478 = and i32 %18466, 65535"
"  %18478 = and i32 %18466, 65535" -> "  %18480 = add nuw nsw i32 %18479, %18478"
"  %18479 = lshr i32 %18425, 16"
"  %18479 = lshr i32 %18425, 16" -> "  %18480 = add nuw nsw i32 %18479, %18478"
"  %18480 = add nuw nsw i32 %18479, %18478"
"  %18480 = add nuw nsw i32 %18479, %18478" -> "  %18483 = and i32 %18480, 65535""  %18480 = add nuw nsw i32 %18479, %18478" -> "  %18481 = lshr i32 %18480, 16"
"  %18481 = lshr i32 %18480, 16"
"  %18481 = lshr i32 %18480, 16" -> "  %18482 = add nuw i32 %18474, %18481"
"  %18482 = add nuw i32 %18474, %18481"
"  %18482 = add nuw i32 %18474, %18481" -> "  %18487 = add nuw i32 %18482, %18486"
"  %18483 = and i32 %18480, 65535"
"  %18483 = and i32 %18480, 65535" -> "  %18485 = add nuw nsw i32 %18484, %18483"
"  %18484 = lshr i32 %18477, 16"
"  %18484 = lshr i32 %18477, 16" -> "  %18485 = add nuw nsw i32 %18484, %18483"
"  %18485 = add nuw nsw i32 %18484, %18483"
"  %18485 = add nuw nsw i32 %18484, %18483" -> "  %18491 = and i32 %18485, 65535""  %18485 = add nuw nsw i32 %18484, %18483" -> "  %18486 = lshr i32 %18485, 16"
"  %18486 = lshr i32 %18485, 16"
"  %18486 = lshr i32 %18485, 16" -> "  %18487 = add nuw i32 %18482, %18486"
"  %18487 = add nuw i32 %18482, %18486"
"  %18487 = add nuw i32 %18482, %18486" -> "  %18573 = add nuw i32 %18487, %18497"
"  %18488 = and i32 %18456, 65535"
"  %18488 = and i32 %18456, 65535" -> "  %18490 = add nuw nsw i32 %18488, %18489"
"  %18489 = and i32 %18477, 65535"
"  %18489 = and i32 %18477, 65535" -> "  %18490 = add nuw nsw i32 %18488, %18489"
"  %18490 = add nuw nsw i32 %18488, %18489"
"  %18490 = add nuw nsw i32 %18488, %18489" -> "  %18525 = and i32 %18490, 65535""  %18490 = add nuw nsw i32 %18488, %18489" -> "  %18494 = lshr i32 %18490, 16"
"  %18491 = and i32 %18485, 65535"
"  %18491 = and i32 %18485, 65535" -> "  %18493 = add nuw nsw i32 %18492, %18491"
"  %18492 = lshr i32 %18456, 16"
"  %18492 = lshr i32 %18456, 16" -> "  %18493 = add nuw nsw i32 %18492, %18491"
"  %18493 = add nuw nsw i32 %18492, %18491"
"  %18493 = add nuw nsw i32 %18492, %18491" -> "  %18497 = lshr i32 %18493, 16""  %18493 = add nuw nsw i32 %18492, %18491" -> "  %18495 = and i32 %18493, 65535"
"  %18494 = lshr i32 %18490, 16"
"  %18494 = lshr i32 %18490, 16" -> "  %18496 = add nuw nsw i32 %18495, %18494"
"  %18495 = and i32 %18493, 65535"
"  %18495 = and i32 %18493, 65535" -> "  %18496 = add nuw nsw i32 %18495, %18494"
"  %18496 = add nuw nsw i32 %18495, %18494"
"  %18496 = add nuw nsw i32 %18495, %18494" -> "  %18532 = and i32 %18496, 65535""  %18496 = add nuw nsw i32 %18495, %18494" -> "  %18498 = lshr i32 %18496, 16"
"  %18497 = lshr i32 %18493, 16"
"  %18497 = lshr i32 %18493, 16" -> "  %18573 = add nuw i32 %18487, %18497"
"  %18498 = lshr i32 %18496, 16"
"  %18498 = lshr i32 %18496, 16" -> "  %18574 = add nuw i32 %18573, %18498"
"  %18499 = and i32 %18377, 65535"
"  %18499 = and i32 %18377, 65535" -> "  %18501 = add nuw nsw i32 %18500, %18499"
"  %18500 = and i32 %18207, 65535"
"  %18500 = and i32 %18207, 65535" -> "  %18501 = add nuw nsw i32 %18500, %18499"
"  %18501 = add nuw nsw i32 %18500, %18499"
"  %18501 = add nuw nsw i32 %18500, %18499" -> "  %18536 = and i32 %18501, 65535""  %18501 = add nuw nsw i32 %18500, %18499" -> "  %18505 = lshr i32 %18501, 16"
"  %18502 = and i32 %18386, 65535"
"  %18502 = and i32 %18386, 65535" -> "  %18504 = add nuw nsw i32 %18503, %18502"
"  %18503 = and i32 %18210, 65535"
"  %18503 = and i32 %18210, 65535" -> "  %18504 = add nuw nsw i32 %18503, %18502"
"  %18504 = add nuw nsw i32 %18503, %18502"
"  %18504 = add nuw nsw i32 %18503, %18502" -> "  %18518 = lshr i32 %18504, 16""  %18504 = add nuw nsw i32 %18503, %18502" -> "  %18506 = and i32 %18504, 65535"
"  %18505 = lshr i32 %18501, 16"
"  %18505 = lshr i32 %18501, 16" -> "  %18507 = add nuw nsw i32 %18506, %18505"
"  %18506 = and i32 %18504, 65535"
"  %18506 = and i32 %18504, 65535" -> "  %18507 = add nuw nsw i32 %18506, %18505"
"  %18507 = add nuw nsw i32 %18506, %18505"
"  %18507 = add nuw nsw i32 %18506, %18505" -> "  %18539 = and i32 %18507, 65535""  %18507 = add nuw nsw i32 %18506, %18505" -> "  %18520 = lshr i32 %18507, 16"
"  %18508 = and i32 %18214, 65535"
"  %18508 = and i32 %18214, 65535" -> "  %18510 = add nuw nsw i32 %18508, %18509"
"  %18509 = and i32 %18446, 65535"
"  %18509 = and i32 %18446, 65535" -> "  %18510 = add nuw nsw i32 %18508, %18509"
"  %18510 = add nuw nsw i32 %18508, %18509"
"  %18510 = add nuw nsw i32 %18508, %18509" -> "  %18517 = and i32 %18510, 65535""  %18510 = add nuw nsw i32 %18508, %18509" -> "  %18514 = lshr i32 %18510, 16"
"  %18511 = lshr i32 %18214, 16"
"  %18511 = lshr i32 %18214, 16" -> "  %18513 = add nuw nsw i32 %18511, %18512"
"  %18512 = and i32 %18454, 65535"
"  %18512 = and i32 %18454, 65535" -> "  %18513 = add nuw nsw i32 %18511, %18512"
"  %18513 = add nuw nsw i32 %18511, %18512"
"  %18513 = add nuw nsw i32 %18511, %18512" -> "  %18526 = lshr i32 %18513, 16""  %18513 = add nuw nsw i32 %18511, %18512" -> "  %18515 = and i32 %18513, 65535"
"  %18514 = lshr i32 %18510, 16"
"  %18514 = lshr i32 %18510, 16" -> "  %18516 = add nuw nsw i32 %18515, %18514"
"  %18515 = and i32 %18513, 65535"
"  %18515 = and i32 %18513, 65535" -> "  %18516 = add nuw nsw i32 %18515, %18514"
"  %18516 = add nuw nsw i32 %18515, %18514"
"  %18516 = add nuw nsw i32 %18515, %18514" -> "  %18528 = lshr i32 %18516, 16""  %18516 = add nuw nsw i32 %18515, %18514" -> "  %18523 = and i32 %18516, 65535"
"  %18517 = and i32 %18510, 65535"
"  %18517 = and i32 %18510, 65535" -> "  %18519 = add nuw nsw i32 %18517, %18518"
"  %18518 = lshr i32 %18504, 16"
"  %18518 = lshr i32 %18504, 16" -> "  %18519 = add nuw nsw i32 %18517, %18518"
"  %18519 = add nuw nsw i32 %18517, %18518"
"  %18519 = add nuw nsw i32 %18517, %18518" -> "  %18521 = add nuw nsw i32 %18519, %18520"
"  %18520 = lshr i32 %18507, 16"
"  %18520 = lshr i32 %18507, 16" -> "  %18521 = add nuw nsw i32 %18519, %18520"
"  %18521 = add nuw nsw i32 %18519, %18520"
"  %18521 = add nuw nsw i32 %18519, %18520" -> "  %18545 = and i32 %18521, 65535""  %18521 = add nuw nsw i32 %18519, %18520" -> "  %18522 = lshr i32 %18521, 16"
"  %18522 = lshr i32 %18521, 16"
"  %18522 = lshr i32 %18521, 16" -> "  %18524 = add nuw nsw i32 %18522, %18523"
"  %18523 = and i32 %18516, 65535"
"  %18523 = and i32 %18516, 65535" -> "  %18524 = add nuw nsw i32 %18522, %18523"
"  %18524 = add nuw nsw i32 %18522, %18523"
"  %18524 = add nuw nsw i32 %18522, %18523" -> "  %18548 = and i32 %18524, 65535""  %18524 = add nuw nsw i32 %18522, %18523" -> "  %18530 = lshr i32 %18524, 16"
"  %18525 = and i32 %18490, 65535"
"  %18525 = and i32 %18490, 65535" -> "  %18527 = add nuw nsw i32 %18526, %18525"
"  %18526 = lshr i32 %18513, 16"
"  %18526 = lshr i32 %18513, 16" -> "  %18527 = add nuw nsw i32 %18526, %18525"
"  %18527 = add nuw nsw i32 %18526, %18525"
"  %18527 = add nuw nsw i32 %18526, %18525" -> "  %18529 = add nuw nsw i32 %18527, %18528"
"  %18528 = lshr i32 %18516, 16"
"  %18528 = lshr i32 %18516, 16" -> "  %18529 = add nuw nsw i32 %18527, %18528"
"  %18529 = add nuw nsw i32 %18527, %18528"
"  %18529 = add nuw nsw i32 %18527, %18528" -> "  %18531 = add nuw nsw i32 %18529, %18530"
"  %18530 = lshr i32 %18524, 16"
"  %18530 = lshr i32 %18524, 16" -> "  %18531 = add nuw nsw i32 %18529, %18530"
"  %18531 = add nuw nsw i32 %18529, %18530"
"  %18531 = add nuw nsw i32 %18529, %18530" -> "  %18562 = and i32 %18531, 65535""  %18531 = add nuw nsw i32 %18529, %18530" -> "  %18533 = lshr i32 %18531, 16"
"  %18532 = and i32 %18496, 65535"
"  %18532 = and i32 %18496, 65535" -> "  %18534 = add nuw nsw i32 %18533, %18532"
"  %18533 = lshr i32 %18531, 16"
"  %18533 = lshr i32 %18531, 16" -> "  %18534 = add nuw nsw i32 %18533, %18532"
"  %18534 = add nuw nsw i32 %18533, %18532"
"  %18534 = add nuw nsw i32 %18533, %18532" -> "  %18569 = and i32 %18534, 65535""  %18534 = add nuw nsw i32 %18533, %18532" -> "  %18535 = lshr i32 %18534, 16"
"  %18535 = lshr i32 %18534, 16"
"  %18535 = lshr i32 %18534, 16" -> "  %18575 = add nuw i32 %18574, %18535"
"  %18536 = and i32 %18501, 65535"
"  %18536 = and i32 %18501, 65535" -> "  %18538 = add nuw nsw i32 %18537, %18536"
"  %18537 = and i32 %18369, 65535"
"  %18537 = and i32 %18369, 65535" -> "  %18538 = add nuw nsw i32 %18537, %18536"
"  %18538 = add nuw nsw i32 %18537, %18536"
"  %18538 = add nuw nsw i32 %18537, %18536" -> "  %18650 = and i32 %18538, 65535""  %18538 = add nuw nsw i32 %18537, %18536" -> "  %18542 = lshr i32 %18538, 16"
"  %18539 = and i32 %18507, 65535"
"  %18539 = and i32 %18507, 65535" -> "  %18541 = add nuw nsw i32 %18540, %18539"
"  %18540 = and i32 %18372, 65535"
"  %18540 = and i32 %18372, 65535" -> "  %18541 = add nuw nsw i32 %18540, %18539"
"  %18541 = add nuw nsw i32 %18540, %18539"
"  %18541 = add nuw nsw i32 %18540, %18539" -> "  %18555 = lshr i32 %18541, 16""  %18541 = add nuw nsw i32 %18540, %18539" -> "  %18543 = and i32 %18541, 65535"
"  %18542 = lshr i32 %18538, 16"
"  %18542 = lshr i32 %18538, 16" -> "  %18544 = add nuw nsw i32 %18543, %18542"
"  %18543 = and i32 %18541, 65535"
"  %18543 = and i32 %18541, 65535" -> "  %18544 = add nuw nsw i32 %18543, %18542"
"  %18544 = add nuw nsw i32 %18543, %18542"
"  %18544 = add nuw nsw i32 %18543, %18542" -> "  %18654 = and i32 %18544, 65535""  %18544 = add nuw nsw i32 %18543, %18542" -> "  %18557 = lshr i32 %18544, 16"
"  %18545 = and i32 %18521, 65535"
"  %18545 = and i32 %18521, 65535" -> "  %18547 = add nuw nsw i32 %18546, %18545"
"  %18546 = and i32 %18376, 65535"
"  %18546 = and i32 %18376, 65535" -> "  %18547 = add nuw nsw i32 %18546, %18545"
"  %18547 = add nuw nsw i32 %18546, %18545"
"  %18547 = add nuw nsw i32 %18546, %18545" -> "  %18554 = and i32 %18547, 65535""  %18547 = add nuw nsw i32 %18546, %18545" -> "  %18551 = lshr i32 %18547, 16"
"  %18548 = and i32 %18524, 65535"
"  %18548 = and i32 %18524, 65535" -> "  %18550 = add nuw nsw i32 %18548, %18549"
"  %18549 = lshr i32 %18376, 16"
"  %18549 = lshr i32 %18376, 16" -> "  %18550 = add nuw nsw i32 %18548, %18549"
"  %18550 = add nuw nsw i32 %18548, %18549"
"  %18550 = add nuw nsw i32 %18548, %18549" -> "  %18563 = lshr i32 %18550, 16""  %18550 = add nuw nsw i32 %18548, %18549" -> "  %18552 = and i32 %18550, 65535"
"  %18551 = lshr i32 %18547, 16"
"  %18551 = lshr i32 %18547, 16" -> "  %18553 = add nuw nsw i32 %18552, %18551"
"  %18552 = and i32 %18550, 65535"
"  %18552 = and i32 %18550, 65535" -> "  %18553 = add nuw nsw i32 %18552, %18551"
"  %18553 = add nuw nsw i32 %18552, %18551"
"  %18553 = add nuw nsw i32 %18552, %18551" -> "  %18565 = lshr i32 %18553, 16""  %18553 = add nuw nsw i32 %18552, %18551" -> "  %18560 = and i32 %18553, 65535"
"  %18554 = and i32 %18547, 65535"
"  %18554 = and i32 %18547, 65535" -> "  %18556 = add nuw nsw i32 %18554, %18555"
"  %18555 = lshr i32 %18541, 16"
"  %18555 = lshr i32 %18541, 16" -> "  %18556 = add nuw nsw i32 %18554, %18555"
"  %18556 = add nuw nsw i32 %18554, %18555"
"  %18556 = add nuw nsw i32 %18554, %18555" -> "  %18558 = add nuw nsw i32 %18556, %18557"
"  %18557 = lshr i32 %18544, 16"
"  %18557 = lshr i32 %18544, 16" -> "  %18558 = add nuw nsw i32 %18556, %18557"
"  %18558 = add nuw nsw i32 %18556, %18557"
"  %18558 = add nuw nsw i32 %18556, %18557" -> "  %18657 = and i32 %18558, 65535""  %18558 = add nuw nsw i32 %18556, %18557" -> "  %18559 = lshr i32 %18558, 16"
"  %18559 = lshr i32 %18558, 16"
"  %18559 = lshr i32 %18558, 16" -> "  %18561 = add nuw nsw i32 %18560, %18559"
"  %18560 = and i32 %18553, 65535"
"  %18560 = and i32 %18553, 65535" -> "  %18561 = add nuw nsw i32 %18560, %18559"
"  %18561 = add nuw nsw i32 %18560, %18559"
"  %18561 = add nuw nsw i32 %18560, %18559" -> "  %18661 = and i32 %18561, 65535""  %18561 = add nuw nsw i32 %18560, %18559" -> "  %18567 = lshr i32 %18561, 16"
"  %18562 = and i32 %18531, 65535"
"  %18562 = and i32 %18531, 65535" -> "  %18564 = add nuw nsw i32 %18563, %18562"
"  %18563 = lshr i32 %18550, 16"
"  %18563 = lshr i32 %18550, 16" -> "  %18564 = add nuw nsw i32 %18563, %18562"
"  %18564 = add nuw nsw i32 %18563, %18562"
"  %18564 = add nuw nsw i32 %18563, %18562" -> "  %18566 = add nuw nsw i32 %18564, %18565"
"  %18565 = lshr i32 %18553, 16"
"  %18565 = lshr i32 %18553, 16" -> "  %18566 = add nuw nsw i32 %18564, %18565"
"  %18566 = add nuw nsw i32 %18564, %18565"
"  %18566 = add nuw nsw i32 %18564, %18565" -> "  %18568 = add nuw nsw i32 %18566, %18567"
"  %18567 = lshr i32 %18561, 16"
"  %18567 = lshr i32 %18561, 16" -> "  %18568 = add nuw nsw i32 %18566, %18567"
"  %18568 = add nuw nsw i32 %18566, %18567"
"  %18568 = add nuw nsw i32 %18566, %18567" -> "  %18664 = and i32 %18568, 65535""  %18568 = add nuw nsw i32 %18566, %18567" -> "  %18570 = lshr i32 %18568, 16"
"  %18569 = and i32 %18534, 65535"
"  %18569 = and i32 %18534, 65535" -> "  %18571 = add nuw nsw i32 %18570, %18569"
"  %18570 = lshr i32 %18568, 16"
"  %18570 = lshr i32 %18568, 16" -> "  %18571 = add nuw nsw i32 %18570, %18569"
"  %18571 = add nuw nsw i32 %18570, %18569"
"  %18571 = add nuw nsw i32 %18570, %18569" -> "  %18667 = and i32 %18571, 65535""  %18571 = add nuw nsw i32 %18570, %18569" -> "  %18572 = lshr i32 %18571, 16"
"  %18572 = lshr i32 %18571, 16"
"  %18572 = lshr i32 %18571, 16" -> "  %18576 = add nuw i32 %18575, %18572"
"  %18573 = add nuw i32 %18487, %18497"
"  %18573 = add nuw i32 %18487, %18497" -> "  %18574 = add nuw i32 %18573, %18498"
"  %18574 = add nuw i32 %18573, %18498"
"  %18574 = add nuw i32 %18573, %18498" -> "  %18575 = add nuw i32 %18574, %18535"
"  %18575 = add nuw i32 %18574, %18535"
"  %18575 = add nuw i32 %18574, %18535" -> "  %18576 = add nuw i32 %18575, %18572"
"  %18576 = add nuw i32 %18575, %18572"
"  %18576 = add nuw i32 %18575, %18572" -> "  %18670 = add nuw i32 %18576, %18669"
"  %18577 = and i32 %17879, 65535"
"  %18577 = and i32 %17879, 65535" -> "  %18579 = add nuw nsw i32 %18577, %18578"
"  %18578 = and i32 %17916, 65532"
"  %18578 = and i32 %17916, 65532" -> "  %18579 = add nuw nsw i32 %18577, %18578"
"  %18579 = add nuw nsw i32 %18577, %18578"
"  %18579 = add nuw nsw i32 %18577, %18578" -> "  %19328 = and i32 %18579, 65535""  %18579 = add nuw nsw i32 %18577, %18578" -> "  %18583 = lshr i32 %18579, 16"
"  %18580 = and i32 %17885, 65535"
"  %18580 = and i32 %17885, 65535" -> "  %18582 = add nuw nsw i32 %18580, %18581"
"  %18581 = and i32 %17926, 65535"
"  %18581 = and i32 %17926, 65535" -> "  %18582 = add nuw nsw i32 %18580, %18581"
"  %18582 = add nuw nsw i32 %18580, %18581"
"  %18582 = add nuw nsw i32 %18580, %18581" -> "  %18586 = lshr i32 %18582, 16""  %18582 = add nuw nsw i32 %18580, %18581" -> "  %18584 = and i32 %18582, 65535"
"  %18583 = lshr i32 %18579, 16"
"  %18583 = lshr i32 %18579, 16" -> "  %18585 = add nuw nsw i32 %18584, %18583"
"  %18584 = and i32 %18582, 65535"
"  %18584 = and i32 %18582, 65535" -> "  %18585 = add nuw nsw i32 %18584, %18583"
"  %18585 = add nuw nsw i32 %18584, %18583"
"  %18585 = add nuw nsw i32 %18584, %18583" -> "  %19331 = and i32 %18585, 65535""  %18585 = add nuw nsw i32 %18584, %18583" -> "  %18587 = lshr i32 %18585, 16"
"  %18586 = lshr i32 %18582, 16"
"  %18586 = lshr i32 %18582, 16" -> "  %18588 = add nuw nsw i32 %18587, %18586"
"  %18587 = lshr i32 %18585, 16"
"  %18587 = lshr i32 %18585, 16" -> "  %18588 = add nuw nsw i32 %18587, %18586"
"  %18588 = add nuw nsw i32 %18587, %18586"
"  %18588 = add nuw nsw i32 %18587, %18586" -> "  %18599 = add nuw nsw i32 %18588, %18598"
"  %18589 = and i32 %17899, 65535"
"  %18589 = and i32 %17899, 65535" -> "  %18591 = add nuw nsw i32 %18589, %18590"
"  %18590 = and i32 %17991, 65535"
"  %18590 = and i32 %17991, 65535" -> "  %18591 = add nuw nsw i32 %18589, %18590"
"  %18591 = add nuw nsw i32 %18589, %18590"
"  %18591 = add nuw nsw i32 %18589, %18590" -> "  %18598 = and i32 %18591, 65535""  %18591 = add nuw nsw i32 %18589, %18590" -> "  %18595 = lshr i32 %18591, 16"
"  %18592 = and i32 %17902, 65535"
"  %18592 = and i32 %17902, 65535" -> "  %18594 = add nuw nsw i32 %18592, %18593"
"  %18593 = and i32 %17999, 65535"
"  %18593 = and i32 %17999, 65535" -> "  %18594 = add nuw nsw i32 %18592, %18593"
"  %18594 = add nuw nsw i32 %18592, %18593"
"  %18594 = add nuw nsw i32 %18592, %18593" -> "  %18634 = lshr i32 %18594, 16""  %18594 = add nuw nsw i32 %18592, %18593" -> "  %18596 = and i32 %18594, 65535"
"  %18595 = lshr i32 %18591, 16"
"  %18595 = lshr i32 %18591, 16" -> "  %18597 = add nuw nsw i32 %18596, %18595"
"  %18596 = and i32 %18594, 65535"
"  %18596 = and i32 %18594, 65535" -> "  %18597 = add nuw nsw i32 %18596, %18595"
"  %18597 = add nuw nsw i32 %18596, %18595"
"  %18597 = add nuw nsw i32 %18596, %18595" -> "  %18635 = lshr i32 %18597, 16""  %18597 = add nuw nsw i32 %18596, %18595" -> "  %18601 = and i32 %18597, 65535"
"  %18598 = and i32 %18591, 65535"
"  %18598 = and i32 %18591, 65535" -> "  %18599 = add nuw nsw i32 %18588, %18598"
"  %18599 = add nuw nsw i32 %18588, %18598"
"  %18599 = add nuw nsw i32 %18588, %18598" -> "  %19340 = and i32 %18599, 65535""  %18599 = add nuw nsw i32 %18588, %18598" -> "  %18600 = lshr i32 %18599, 16"
"  %18600 = lshr i32 %18599, 16"
"  %18600 = lshr i32 %18599, 16" -> "  %18602 = add nuw nsw i32 %18601, %18600"
"  %18601 = and i32 %18597, 65535"
"  %18601 = and i32 %18597, 65535" -> "  %18602 = add nuw nsw i32 %18601, %18600"
"  %18602 = add nuw nsw i32 %18601, %18600"
"  %18602 = add nuw nsw i32 %18601, %18600" -> "  %19343 = and i32 %18602, 65535""  %18602 = add nuw nsw i32 %18601, %18600" -> "  %18636 = lshr i32 %18602, 16"
"  %18603 = and i32 %17909, 65535"
"  %18603 = and i32 %17909, 65535" -> "  %18605 = add nuw nsw i32 %18603, %18604"
"  %18604 = and i32 %18339, 65535"
"  %18604 = and i32 %18339, 65535" -> "  %18605 = add nuw nsw i32 %18603, %18604"
"  %18605 = add nuw nsw i32 %18603, %18604"
"  %18605 = add nuw nsw i32 %18603, %18604" -> "  %18633 = and i32 %18605, 65535""  %18605 = add nuw nsw i32 %18603, %18604" -> "  %18609 = lshr i32 %18605, 16"
"  %18606 = and i32 %17912, 65535"
"  %18606 = and i32 %17912, 65535" -> "  %18608 = add nuw nsw i32 %18606, %18607"
"  %18607 = and i32 %18345, 65535"
"  %18607 = and i32 %18345, 65535" -> "  %18608 = add nuw nsw i32 %18606, %18607"
"  %18608 = add nuw nsw i32 %18606, %18607"
"  %18608 = add nuw nsw i32 %18606, %18607" -> "  %18625 = lshr i32 %18608, 16""  %18608 = add nuw nsw i32 %18606, %18607" -> "  %18610 = and i32 %18608, 65535"
"  %18609 = lshr i32 %18605, 16"
"  %18609 = lshr i32 %18605, 16" -> "  %18611 = add nuw nsw i32 %18610, %18609"
"  %18610 = and i32 %18608, 65535"
"  %18610 = and i32 %18608, 65535" -> "  %18611 = add nuw nsw i32 %18610, %18609"
"  %18611 = add nuw nsw i32 %18610, %18609"
"  %18611 = add nuw nsw i32 %18610, %18609" -> "  %18640 = and i32 %18611, 65535""  %18611 = add nuw nsw i32 %18610, %18609" -> "  %18626 = lshr i32 %18611, 16"
"  %18612 = and i32 %17914, 65535"
"  %18612 = and i32 %17914, 65535" -> "  %18614 = add nuw nsw i32 %18613, %18612"
"  %18613 = and i32 %18359, 65535"
"  %18613 = and i32 %18359, 65535" -> "  %18614 = add nuw nsw i32 %18613, %18612"
"  %18614 = add nuw nsw i32 %18613, %18612"
"  %18614 = add nuw nsw i32 %18613, %18612" -> "  %18624 = and i32 %18614, 65535""  %18614 = add nuw nsw i32 %18613, %18612" -> "  %18618 = lshr i32 %18614, 16"
"  %18615 = lshr i32 %17914, 16"
"  %18615 = lshr i32 %17914, 16" -> "  %18617 = add nuw nsw i32 %18616, %18615"
"  %18616 = and i32 %18362, 65535"
"  %18616 = and i32 %18362, 65535" -> "  %18617 = add nuw nsw i32 %18616, %18615"
"  %18617 = add nuw nsw i32 %18616, %18615"
"  %18617 = add nuw nsw i32 %18616, %18615" -> "  %18621 = lshr i32 %18617, 16""  %18617 = add nuw nsw i32 %18616, %18615" -> "  %18619 = and i32 %18617, 65535"
"  %18618 = lshr i32 %18614, 16"
"  %18618 = lshr i32 %18614, 16" -> "  %18620 = add nuw nsw i32 %18619, %18618"
"  %18619 = and i32 %18617, 65535"
"  %18619 = and i32 %18617, 65535" -> "  %18620 = add nuw nsw i32 %18619, %18618"
"  %18620 = add nuw nsw i32 %18619, %18618"
"  %18620 = add nuw nsw i32 %18619, %18618" -> "  %18629 = and i32 %18620, 65535""  %18620 = add nuw nsw i32 %18619, %18618" -> "  %18622 = lshr i32 %18620, 16"
"  %18621 = lshr i32 %18617, 16"
"  %18621 = lshr i32 %18617, 16" -> "  %18623 = add nuw nsw i32 %18622, %18621"
"  %18622 = lshr i32 %18620, 16"
"  %18622 = lshr i32 %18620, 16" -> "  %18623 = add nuw nsw i32 %18622, %18621"
"  %18623 = add nuw nsw i32 %18622, %18621"
"  %18623 = add nuw nsw i32 %18622, %18621" -> "  %18651 = add nuw nsw i32 %18623, %18650"
"  %18624 = and i32 %18614, 65535"
"  %18624 = and i32 %18614, 65535" -> "  %18628 = add nuw nsw i32 %18627, %18624"
"  %18625 = lshr i32 %18608, 16"
"  %18625 = lshr i32 %18608, 16" -> "  %18627 = add nuw nsw i32 %18626, %18625"
"  %18626 = lshr i32 %18611, 16"
"  %18626 = lshr i32 %18611, 16" -> "  %18627 = add nuw nsw i32 %18626, %18625"
"  %18627 = add nuw nsw i32 %18626, %18625"
"  %18627 = add nuw nsw i32 %18626, %18625" -> "  %18628 = add nuw nsw i32 %18627, %18624"
"  %18628 = add nuw nsw i32 %18627, %18624"
"  %18628 = add nuw nsw i32 %18627, %18624" -> "  %18644 = and i32 %18628, 65535""  %18628 = add nuw nsw i32 %18627, %18624" -> "  %18630 = lshr i32 %18628, 16"
"  %18629 = and i32 %18620, 65535"
"  %18629 = and i32 %18620, 65535" -> "  %18631 = add nuw nsw i32 %18629, %18630"
"  %18630 = lshr i32 %18628, 16"
"  %18630 = lshr i32 %18628, 16" -> "  %18631 = add nuw nsw i32 %18629, %18630"
"  %18631 = add nuw nsw i32 %18629, %18630"
"  %18631 = add nuw nsw i32 %18629, %18630" -> "  %18647 = and i32 %18631, 65535""  %18631 = add nuw nsw i32 %18629, %18630" -> "  %18632 = lshr i32 %18631, 16"
"  %18632 = lshr i32 %18631, 16"
"  %18632 = lshr i32 %18631, 16" -> "  %18652 = add nuw nsw i32 %18651, %18632"
"  %18633 = and i32 %18605, 65535"
"  %18633 = and i32 %18605, 65535" -> "  %18638 = add nuw nsw i32 %18637, %18633"
"  %18634 = lshr i32 %18594, 16"
"  %18634 = lshr i32 %18594, 16" -> "  %18637 = add nuw nsw i32 %18635, %18634"
"  %18635 = lshr i32 %18597, 16"
"  %18635 = lshr i32 %18597, 16" -> "  %18637 = add nuw nsw i32 %18635, %18634"
"  %18636 = lshr i32 %18602, 16"
"  %18636 = lshr i32 %18602, 16" -> "  %18639 = add nuw nsw i32 %18638, %18636"
"  %18637 = add nuw nsw i32 %18635, %18634"
"  %18637 = add nuw nsw i32 %18635, %18634" -> "  %18638 = add nuw nsw i32 %18637, %18633"
"  %18638 = add nuw nsw i32 %18637, %18633"
"  %18638 = add nuw nsw i32 %18637, %18633" -> "  %18639 = add nuw nsw i32 %18638, %18636"
"  %18639 = add nuw nsw i32 %18638, %18636"
"  %18639 = add nuw nsw i32 %18638, %18636" -> "  %19354 = and i32 %18639, 65535""  %18639 = add nuw nsw i32 %18638, %18636" -> "  %18641 = lshr i32 %18639, 16"
"  %18640 = and i32 %18611, 65535"
"  %18640 = and i32 %18611, 65535" -> "  %18642 = add nuw nsw i32 %18640, %18641"
"  %18641 = lshr i32 %18639, 16"
"  %18641 = lshr i32 %18639, 16" -> "  %18642 = add nuw nsw i32 %18640, %18641"
"  %18642 = add nuw nsw i32 %18640, %18641"
"  %18642 = add nuw nsw i32 %18640, %18641" -> "  %19357 = and i32 %18642, 65535""  %18642 = add nuw nsw i32 %18640, %18641" -> "  %18643 = lshr i32 %18642, 16"
"  %18643 = lshr i32 %18642, 16"
"  %18643 = lshr i32 %18642, 16" -> "  %18645 = add nuw nsw i32 %18644, %18643"
"  %18644 = and i32 %18628, 65535"
"  %18644 = and i32 %18628, 65535" -> "  %18645 = add nuw nsw i32 %18644, %18643"
"  %18645 = add nuw nsw i32 %18644, %18643"
"  %18645 = add nuw nsw i32 %18644, %18643" -> "  %19366 = and i32 %18645, 65535""  %18645 = add nuw nsw i32 %18644, %18643" -> "  %18646 = lshr i32 %18645, 16"
"  %18646 = lshr i32 %18645, 16"
"  %18646 = lshr i32 %18645, 16" -> "  %18648 = add nuw nsw i32 %18647, %18646"
"  %18647 = and i32 %18631, 65535"
"  %18647 = and i32 %18631, 65535" -> "  %18648 = add nuw nsw i32 %18647, %18646"
"  %18648 = add nuw nsw i32 %18647, %18646"
"  %18648 = add nuw nsw i32 %18647, %18646" -> "  %19369 = and i32 %18648, 65535""  %18648 = add nuw nsw i32 %18647, %18646" -> "  %18649 = lshr i32 %18648, 16"
"  %18649 = lshr i32 %18648, 16"
"  %18649 = lshr i32 %18648, 16" -> "  %18653 = add nuw nsw i32 %18652, %18649"
"  %18650 = and i32 %18538, 65535"
"  %18650 = and i32 %18538, 65535" -> "  %18651 = add nuw nsw i32 %18623, %18650"
"  %18651 = add nuw nsw i32 %18623, %18650"
"  %18651 = add nuw nsw i32 %18623, %18650" -> "  %18652 = add nuw nsw i32 %18651, %18632"
"  %18652 = add nuw nsw i32 %18651, %18632"
"  %18652 = add nuw nsw i32 %18651, %18632" -> "  %18653 = add nuw nsw i32 %18652, %18649"
"  %18653 = add nuw nsw i32 %18652, %18649"
"  %18653 = add nuw nsw i32 %18652, %18649" -> "  %20076 = and i32 %18653, 65535""  %18653 = add nuw nsw i32 %18652, %18649" -> "  %18655 = lshr i32 %18653, 16"
"  %18654 = and i32 %18544, 65535"
"  %18654 = and i32 %18544, 65535" -> "  %18656 = add nuw nsw i32 %18655, %18654"
"  %18655 = lshr i32 %18653, 16"
"  %18655 = lshr i32 %18653, 16" -> "  %18656 = add nuw nsw i32 %18655, %18654"
"  %18656 = add nuw nsw i32 %18655, %18654"
"  %18656 = add nuw nsw i32 %18655, %18654" -> "  %20079 = and i32 %18656, 65535""  %18656 = add nuw nsw i32 %18655, %18654" -> "  %18658 = lshr i32 %18656, 16""  %18656 = add nuw nsw i32 %18655, %18654" -> "  store i32 %18656, i32* %556, align 1, !noalias !50"
"  store i32 %18656, i32* %556, align 1, !noalias !50"

"  %18657 = and i32 %18558, 65535"
"  %18657 = and i32 %18558, 65535" -> "  %18659 = add nuw nsw i32 %18658, %18657"
"  %18658 = lshr i32 %18656, 16"
"  %18658 = lshr i32 %18656, 16" -> "  %18659 = add nuw nsw i32 %18658, %18657"
"  %18659 = add nuw nsw i32 %18658, %18657"
"  %18659 = add nuw nsw i32 %18658, %18657" -> "  %20085 = and i32 %18659, 65535""  %18659 = add nuw nsw i32 %18658, %18657" -> "  %18660 = lshr i32 %18659, 16""  %18659 = add nuw nsw i32 %18658, %18657" -> "  store i32 %18659, i32* %391, align 1, !noalias !50"
"  store i32 %18659, i32* %391, align 1, !noalias !50"

"  %18660 = lshr i32 %18659, 16"
"  %18660 = lshr i32 %18659, 16" -> "  %18662 = add nuw nsw i32 %18660, %18661"
"  %18661 = and i32 %18561, 65535"
"  %18661 = and i32 %18561, 65535" -> "  %18662 = add nuw nsw i32 %18660, %18661"
"  %18662 = add nuw nsw i32 %18660, %18661"
"  %18662 = add nuw nsw i32 %18660, %18661" -> "  %20088 = and i32 %18662, 65535""  %18662 = add nuw nsw i32 %18660, %18661" -> "  %18663 = lshr i32 %18662, 16""  %18662 = add nuw nsw i32 %18660, %18661" -> "  store i32 %18662, i32* %575, align 1, !noalias !50"
"  store i32 %18662, i32* %575, align 1, !noalias !50"

"  %18663 = lshr i32 %18662, 16"
"  %18663 = lshr i32 %18662, 16" -> "  %18665 = add nuw nsw i32 %18663, %18664"
"  %18664 = and i32 %18568, 65535"
"  %18664 = and i32 %18568, 65535" -> "  %18665 = add nuw nsw i32 %18663, %18664"
"  %18665 = add nuw nsw i32 %18663, %18664"
"  %18665 = add nuw nsw i32 %18663, %18664" -> "  %20102 = and i32 %18665, 65535""  %18665 = add nuw nsw i32 %18663, %18664" -> "  %18666 = lshr i32 %18665, 16""  %18665 = add nuw nsw i32 %18663, %18664" -> "  store i32 %18665, i32* %565, align 1, !noalias !50"
"  store i32 %18665, i32* %565, align 1, !noalias !50"

"  %18666 = lshr i32 %18665, 16"
"  %18666 = lshr i32 %18665, 16" -> "  %18668 = add nuw nsw i32 %18666, %18667"
"  %18667 = and i32 %18571, 65535"
"  %18667 = and i32 %18571, 65535" -> "  %18668 = add nuw nsw i32 %18666, %18667"
"  %18668 = add nuw nsw i32 %18666, %18667"
"  %18668 = add nuw nsw i32 %18666, %18667" -> "  %20105 = and i32 %18668, 65535""  %18668 = add nuw nsw i32 %18666, %18667" -> "  %18669 = lshr i32 %18668, 16""  %18668 = add nuw nsw i32 %18666, %18667" -> "  store i32 %18668, i32* %560, align 1, !noalias !50"
"  store i32 %18668, i32* %560, align 1, !noalias !50"

"  %18669 = lshr i32 %18668, 16"
"  %18669 = lshr i32 %18668, 16" -> "  %18670 = add nuw i32 %18576, %18669"
"  %18670 = add nuw i32 %18576, %18669"
"  %18670 = add nuw i32 %18576, %18669" -> "  %20111 = and i32 %18670, 65535""  %18670 = add nuw i32 %18576, %18669" -> "  %20114 = lshr i32 %18670, 16""  %18670 = add nuw i32 %18576, %18669" -> "  store i32 %18670, i32* %534, align 1, !noalias !50"
"  store i32 %18670, i32* %534, align 1, !noalias !50"

"  %18671 = mul nuw i32 %17241, 42779"
"  %18671 = mul nuw i32 %17241, 42779" -> "  %19329 = and i32 %18671, 65535""  %18671 = mul nuw i32 %17241, 42779" -> "  %18672 = lshr i32 %18671, 16"
"  %18672 = lshr i32 %18671, 16"
"  %18672 = lshr i32 %18671, 16" -> "  %18675 = add nuw nsw i32 %18674, %18672"
"  %18673 = mul nuw i32 %17244, 42779"
"  %18673 = mul nuw i32 %17244, 42779" -> "  %18676 = and i32 %18673, -65536""  %18673 = mul nuw i32 %17244, 42779" -> "  %18674 = and i32 %18673, 65535"
"  %18674 = and i32 %18673, 65535"
"  %18674 = and i32 %18673, 65535" -> "  %18675 = add nuw nsw i32 %18674, %18672"
"  %18675 = add nuw nsw i32 %18674, %18672"
"  %18675 = add nuw nsw i32 %18674, %18672" -> "  %18677 = add nuw i32 %18675, %18676"
"  %18676 = and i32 %18673, -65536"
"  %18676 = and i32 %18673, -65536" -> "  %18677 = add nuw i32 %18675, %18676"
"  %18677 = add nuw i32 %18675, %18676"
"  %18677 = add nuw i32 %18675, %18676" -> "  %18681 = lshr i32 %18677, 16""  %18677 = add nuw i32 %18675, %18676" -> "  %18679 = and i32 %18677, 65535"
"  %18678 = mul nuw nsw i32 %17241, 9871"
"  %18678 = mul nuw nsw i32 %17241, 9871" -> "  %18680 = add nuw nsw i32 %18679, %18678"
"  %18679 = and i32 %18677, 65535"
"  %18679 = and i32 %18677, 65535" -> "  %18680 = add nuw nsw i32 %18679, %18678"
"  %18680 = add nuw nsw i32 %18679, %18678"
"  %18680 = add nuw nsw i32 %18679, %18678" -> "  %19332 = and i32 %18680, 65535""  %18680 = add nuw nsw i32 %18679, %18678" -> "  %18684 = lshr i32 %18680, 16"
"  %18681 = lshr i32 %18677, 16"
"  %18681 = lshr i32 %18677, 16" -> "  %18683 = add nuw nsw i32 %18681, %18682"
"  %18682 = mul nuw nsw i32 %17244, 9871"
"  %18682 = mul nuw nsw i32 %17244, 9871" -> "  %18683 = add nuw nsw i32 %18681, %18682"
"  %18683 = add nuw nsw i32 %18681, %18682"
"  %18683 = add nuw nsw i32 %18681, %18682" -> "  %18687 = and i32 %18683, 2147418112""  %18683 = add nuw nsw i32 %18681, %18682" -> "  %18685 = and i32 %18683, 65535"
"  %18684 = lshr i32 %18680, 16"
"  %18684 = lshr i32 %18680, 16" -> "  %18686 = add nuw nsw i32 %18684, %18685"
"  %18685 = and i32 %18683, 65535"
"  %18685 = and i32 %18683, 65535" -> "  %18686 = add nuw nsw i32 %18684, %18685"
"  %18686 = add nuw nsw i32 %18684, %18685"
"  %18686 = add nuw nsw i32 %18684, %18685" -> "  %18688 = add nuw nsw i32 %18686, %18687"
"  %18687 = and i32 %18683, 2147418112"
"  %18687 = and i32 %18683, 2147418112" -> "  %18688 = add nuw nsw i32 %18686, %18687"
"  %18688 = add nuw nsw i32 %18686, %18687"
"  %18688 = add nuw nsw i32 %18686, %18687" -> "  %18711 = lshr i32 %18688, 16""  %18688 = add nuw nsw i32 %18686, %18687" -> "  %18707 = and i32 %18688, 65535"
"  %18689 = mul nuw i32 %17261, 42779"
"  %18689 = mul nuw i32 %17261, 42779" -> "  %18708 = and i32 %18689, 65535""  %18689 = mul nuw i32 %17261, 42779" -> "  %18690 = lshr i32 %18689, 16"
"  %18690 = lshr i32 %18689, 16"
"  %18690 = lshr i32 %18689, 16" -> "  %18693 = add nuw nsw i32 %18692, %18690"
"  %18691 = mul nuw i32 %17264, 42779"
"  %18691 = mul nuw i32 %17264, 42779" -> "  %18694 = and i32 %18691, -65536""  %18691 = mul nuw i32 %17264, 42779" -> "  %18692 = and i32 %18691, 65535"
"  %18692 = and i32 %18691, 65535"
"  %18692 = and i32 %18691, 65535" -> "  %18693 = add nuw nsw i32 %18692, %18690"
"  %18693 = add nuw nsw i32 %18692, %18690"
"  %18693 = add nuw nsw i32 %18692, %18690" -> "  %18695 = add nuw i32 %18693, %18694"
"  %18694 = and i32 %18691, -65536"
"  %18694 = and i32 %18691, -65536" -> "  %18695 = add nuw i32 %18693, %18694"
"  %18695 = add nuw i32 %18693, %18694"
"  %18695 = add nuw i32 %18693, %18694" -> "  %18699 = lshr i32 %18695, 16""  %18695 = add nuw i32 %18693, %18694" -> "  %18697 = and i32 %18695, 65535"
"  %18696 = mul nuw nsw i32 %17261, 9871"
"  %18696 = mul nuw nsw i32 %17261, 9871" -> "  %18698 = add nuw nsw i32 %18697, %18696"
"  %18697 = and i32 %18695, 65535"
"  %18697 = and i32 %18695, 65535" -> "  %18698 = add nuw nsw i32 %18697, %18696"
"  %18698 = add nuw nsw i32 %18697, %18696"
"  %18698 = add nuw nsw i32 %18697, %18696" -> "  %18710 = and i32 %18698, 65535""  %18698 = add nuw nsw i32 %18697, %18696" -> "  %18702 = lshr i32 %18698, 16"
"  %18699 = lshr i32 %18695, 16"
"  %18699 = lshr i32 %18695, 16" -> "  %18701 = add nuw nsw i32 %18699, %18700"
"  %18700 = mul nuw nsw i32 %17264, 9871"
"  %18700 = mul nuw nsw i32 %17264, 9871" -> "  %18701 = add nuw nsw i32 %18699, %18700"
"  %18701 = add nuw nsw i32 %18699, %18700"
"  %18701 = add nuw nsw i32 %18699, %18700" -> "  %18705 = and i32 %18701, 2147418112""  %18701 = add nuw nsw i32 %18699, %18700" -> "  %18703 = and i32 %18701, 65535"
"  %18702 = lshr i32 %18698, 16"
"  %18702 = lshr i32 %18698, 16" -> "  %18704 = add nuw nsw i32 %18702, %18703"
"  %18703 = and i32 %18701, 65535"
"  %18703 = and i32 %18701, 65535" -> "  %18704 = add nuw nsw i32 %18702, %18703"
"  %18704 = add nuw nsw i32 %18702, %18703"
"  %18704 = add nuw nsw i32 %18702, %18703" -> "  %18706 = add nuw nsw i32 %18704, %18705"
"  %18705 = and i32 %18701, 2147418112"
"  %18705 = and i32 %18701, 2147418112" -> "  %18706 = add nuw nsw i32 %18704, %18705"
"  %18706 = add nuw nsw i32 %18704, %18705"
"  %18706 = add nuw nsw i32 %18704, %18705" -> "  %18714 = add nuw nsw i32 %18706, %18713"
"  %18707 = and i32 %18688, 65535"
"  %18707 = and i32 %18688, 65535" -> "  %18709 = add nuw nsw i32 %18707, %18708"
"  %18708 = and i32 %18689, 65535"
"  %18708 = and i32 %18689, 65535" -> "  %18709 = add nuw nsw i32 %18707, %18708"
"  %18709 = add nuw nsw i32 %18707, %18708"
"  %18709 = add nuw nsw i32 %18707, %18708" -> "  %18738 = and i32 %18709, 65535""  %18709 = add nuw nsw i32 %18707, %18708" -> "  %18716 = lshr i32 %18709, 16"
"  %18710 = and i32 %18698, 65535"
"  %18710 = and i32 %18698, 65535" -> "  %18712 = add nuw nsw i32 %18710, %18711"
"  %18711 = lshr i32 %18688, 16"
"  %18711 = lshr i32 %18688, 16" -> "  %18712 = add nuw nsw i32 %18710, %18711"
"  %18712 = add nuw nsw i32 %18710, %18711"
"  %18712 = add nuw nsw i32 %18710, %18711" -> "  %18715 = and i32 %18712, 65535""  %18712 = add nuw nsw i32 %18710, %18711" -> "  %18713 = lshr i32 %18712, 16"
"  %18713 = lshr i32 %18712, 16"
"  %18713 = lshr i32 %18712, 16" -> "  %18714 = add nuw nsw i32 %18706, %18713"
"  %18714 = add nuw nsw i32 %18706, %18713"
"  %18714 = add nuw nsw i32 %18706, %18713" -> "  %18719 = add nuw nsw i32 %18714, %18718"
"  %18715 = and i32 %18712, 65535"
"  %18715 = and i32 %18712, 65535" -> "  %18717 = add nuw nsw i32 %18715, %18716"
"  %18716 = lshr i32 %18709, 16"
"  %18716 = lshr i32 %18709, 16" -> "  %18717 = add nuw nsw i32 %18715, %18716"
"  %18717 = add nuw nsw i32 %18715, %18716"
"  %18717 = add nuw nsw i32 %18715, %18716" -> "  %18741 = and i32 %18717, 65535""  %18717 = add nuw nsw i32 %18715, %18716" -> "  %18718 = lshr i32 %18717, 16"
"  %18718 = lshr i32 %18717, 16"
"  %18718 = lshr i32 %18717, 16" -> "  %18719 = add nuw nsw i32 %18714, %18718"
"  %18719 = add nuw nsw i32 %18714, %18718"
"  %18719 = add nuw nsw i32 %18714, %18718" -> "  %18773 = lshr i32 %18719, 16""  %18719 = add nuw nsw i32 %18714, %18718" -> "  %18769 = and i32 %18719, 65535"
"  %18720 = mul nuw nsw i32 %17241, 24315"
"  %18720 = mul nuw nsw i32 %17241, 24315" -> "  %18739 = and i32 %18720, 65535""  %18720 = mul nuw nsw i32 %17241, 24315" -> "  %18721 = lshr i32 %18720, 16"
"  %18721 = lshr i32 %18720, 16"
"  %18721 = lshr i32 %18720, 16" -> "  %18724 = add nuw nsw i32 %18723, %18721"
"  %18722 = mul nuw nsw i32 %17244, 24315"
"  %18722 = mul nuw nsw i32 %17244, 24315" -> "  %18725 = and i32 %18722, 2147418112""  %18722 = mul nuw nsw i32 %17244, 24315" -> "  %18723 = and i32 %18722, 65535"
"  %18723 = and i32 %18722, 65535"
"  %18723 = and i32 %18722, 65535" -> "  %18724 = add nuw nsw i32 %18723, %18721"
"  %18724 = add nuw nsw i32 %18723, %18721"
"  %18724 = add nuw nsw i32 %18723, %18721" -> "  %18726 = add nuw nsw i32 %18724, %18725"
"  %18725 = and i32 %18722, 2147418112"
"  %18725 = and i32 %18722, 2147418112" -> "  %18726 = add nuw nsw i32 %18724, %18725"
"  %18726 = add nuw nsw i32 %18724, %18725"
"  %18726 = add nuw nsw i32 %18724, %18725" -> "  %18730 = lshr i32 %18726, 16""  %18726 = add nuw nsw i32 %18724, %18725" -> "  %18728 = and i32 %18726, 65535"
"  %18727 = mul nuw nsw i32 %17241, 29744"
"  %18727 = mul nuw nsw i32 %17241, 29744" -> "  %18729 = add nuw nsw i32 %18728, %18727"
"  %18728 = and i32 %18726, 65535"
"  %18728 = and i32 %18726, 65535" -> "  %18729 = add nuw nsw i32 %18728, %18727"
"  %18729 = add nuw nsw i32 %18728, %18727"
"  %18729 = add nuw nsw i32 %18728, %18727" -> "  %18742 = and i32 %18729, 65535""  %18729 = add nuw nsw i32 %18728, %18727" -> "  %18733 = lshr i32 %18729, 16"
"  %18730 = lshr i32 %18726, 16"
"  %18730 = lshr i32 %18726, 16" -> "  %18732 = add nuw nsw i32 %18730, %18731"
"  %18731 = mul nuw nsw i32 %17244, 29744"
"  %18731 = mul nuw nsw i32 %17244, 29744" -> "  %18732 = add nuw nsw i32 %18730, %18731"
"  %18732 = add nuw nsw i32 %18730, %18731"
"  %18732 = add nuw nsw i32 %18730, %18731" -> "  %18736 = and i32 %18732, 2147418112""  %18732 = add nuw nsw i32 %18730, %18731" -> "  %18734 = and i32 %18732, 65535"
"  %18733 = lshr i32 %18729, 16"
"  %18733 = lshr i32 %18729, 16" -> "  %18735 = add nuw nsw i32 %18733, %18734"
"  %18734 = and i32 %18732, 65535"
"  %18734 = and i32 %18732, 65535" -> "  %18735 = add nuw nsw i32 %18733, %18734"
"  %18735 = add nuw nsw i32 %18733, %18734"
"  %18735 = add nuw nsw i32 %18733, %18734" -> "  %18737 = add nuw nsw i32 %18735, %18736"
"  %18736 = and i32 %18732, 2147418112"
"  %18736 = and i32 %18732, 2147418112" -> "  %18737 = add nuw nsw i32 %18735, %18736"
"  %18737 = add nuw nsw i32 %18735, %18736"
"  %18737 = add nuw nsw i32 %18735, %18736" -> "  %18745 = add nuw nsw i32 %18737, %18744"
"  %18738 = and i32 %18709, 65535"
"  %18738 = and i32 %18709, 65535" -> "  %18740 = add nuw nsw i32 %18738, %18739"
"  %18739 = and i32 %18720, 65535"
"  %18739 = and i32 %18720, 65535" -> "  %18740 = add nuw nsw i32 %18738, %18739"
"  %18740 = add nuw nsw i32 %18738, %18739"
"  %18740 = add nuw nsw i32 %18738, %18739" -> "  %19341 = and i32 %18740, 65535""  %18740 = add nuw nsw i32 %18738, %18739" -> "  %18747 = lshr i32 %18740, 16"
"  %18741 = and i32 %18717, 65535"
"  %18741 = and i32 %18717, 65535" -> "  %18743 = add nuw nsw i32 %18741, %18742"
"  %18742 = and i32 %18729, 65535"
"  %18742 = and i32 %18729, 65535" -> "  %18743 = add nuw nsw i32 %18741, %18742"
"  %18743 = add nuw nsw i32 %18741, %18742"
"  %18743 = add nuw nsw i32 %18741, %18742" -> "  %18746 = and i32 %18743, 65535""  %18743 = add nuw nsw i32 %18741, %18742" -> "  %18744 = lshr i32 %18743, 16"
"  %18744 = lshr i32 %18743, 16"
"  %18744 = lshr i32 %18743, 16" -> "  %18745 = add nuw nsw i32 %18737, %18744"
"  %18745 = add nuw nsw i32 %18737, %18744"
"  %18745 = add nuw nsw i32 %18737, %18744" -> "  %18750 = add nuw nsw i32 %18745, %18749"
"  %18746 = and i32 %18743, 65535"
"  %18746 = and i32 %18743, 65535" -> "  %18748 = add nuw nsw i32 %18746, %18747"
"  %18747 = lshr i32 %18740, 16"
"  %18747 = lshr i32 %18740, 16" -> "  %18748 = add nuw nsw i32 %18746, %18747"
"  %18748 = add nuw nsw i32 %18746, %18747"
"  %18748 = add nuw nsw i32 %18746, %18747" -> "  %19344 = and i32 %18748, 65535""  %18748 = add nuw nsw i32 %18746, %18747" -> "  %18749 = lshr i32 %18748, 16"
"  %18749 = lshr i32 %18748, 16"
"  %18749 = lshr i32 %18748, 16" -> "  %18750 = add nuw nsw i32 %18745, %18749"
"  %18750 = add nuw nsw i32 %18745, %18749"
"  %18750 = add nuw nsw i32 %18745, %18749" -> "  %18786 = lshr i32 %18750, 16""  %18750 = add nuw nsw i32 %18745, %18749" -> "  %18783 = and i32 %18750, 65535"
"  %18751 = mul nuw nsw i32 %17261, 24315"
"  %18751 = mul nuw nsw i32 %17261, 24315" -> "  %18770 = and i32 %18751, 65535""  %18751 = mul nuw nsw i32 %17261, 24315" -> "  %18752 = lshr i32 %18751, 16"
"  %18752 = lshr i32 %18751, 16"
"  %18752 = lshr i32 %18751, 16" -> "  %18755 = add nuw nsw i32 %18754, %18752"
"  %18753 = mul nuw nsw i32 %17264, 24315"
"  %18753 = mul nuw nsw i32 %17264, 24315" -> "  %18756 = and i32 %18753, 2147418112""  %18753 = mul nuw nsw i32 %17264, 24315" -> "  %18754 = and i32 %18753, 65535"
"  %18754 = and i32 %18753, 65535"
"  %18754 = and i32 %18753, 65535" -> "  %18755 = add nuw nsw i32 %18754, %18752"
"  %18755 = add nuw nsw i32 %18754, %18752"
"  %18755 = add nuw nsw i32 %18754, %18752" -> "  %18757 = add nuw nsw i32 %18755, %18756"
"  %18756 = and i32 %18753, 2147418112"
"  %18756 = and i32 %18753, 2147418112" -> "  %18757 = add nuw nsw i32 %18755, %18756"
"  %18757 = add nuw nsw i32 %18755, %18756"
"  %18757 = add nuw nsw i32 %18755, %18756" -> "  %18761 = lshr i32 %18757, 16""  %18757 = add nuw nsw i32 %18755, %18756" -> "  %18759 = and i32 %18757, 65535"
"  %18758 = mul nuw nsw i32 %17261, 29744"
"  %18758 = mul nuw nsw i32 %17261, 29744" -> "  %18760 = add nuw nsw i32 %18759, %18758"
"  %18759 = and i32 %18757, 65535"
"  %18759 = and i32 %18757, 65535" -> "  %18760 = add nuw nsw i32 %18759, %18758"
"  %18760 = add nuw nsw i32 %18759, %18758"
"  %18760 = add nuw nsw i32 %18759, %18758" -> "  %18772 = and i32 %18760, 65535""  %18760 = add nuw nsw i32 %18759, %18758" -> "  %18764 = lshr i32 %18760, 16"
"  %18761 = lshr i32 %18757, 16"
"  %18761 = lshr i32 %18757, 16" -> "  %18763 = add nuw nsw i32 %18761, %18762"
"  %18762 = mul nuw nsw i32 %17264, 29744"
"  %18762 = mul nuw nsw i32 %17264, 29744" -> "  %18763 = add nuw nsw i32 %18761, %18762"
"  %18763 = add nuw nsw i32 %18761, %18762"
"  %18763 = add nuw nsw i32 %18761, %18762" -> "  %18767 = and i32 %18763, 2147418112""  %18763 = add nuw nsw i32 %18761, %18762" -> "  %18765 = and i32 %18763, 65535"
"  %18764 = lshr i32 %18760, 16"
"  %18764 = lshr i32 %18760, 16" -> "  %18766 = add nuw nsw i32 %18764, %18765"
"  %18765 = and i32 %18763, 65535"
"  %18765 = and i32 %18763, 65535" -> "  %18766 = add nuw nsw i32 %18764, %18765"
"  %18766 = add nuw nsw i32 %18764, %18765"
"  %18766 = add nuw nsw i32 %18764, %18765" -> "  %18768 = add nuw nsw i32 %18766, %18767"
"  %18767 = and i32 %18763, 2147418112"
"  %18767 = and i32 %18763, 2147418112" -> "  %18768 = add nuw nsw i32 %18766, %18767"
"  %18768 = add nuw nsw i32 %18766, %18767"
"  %18768 = add nuw nsw i32 %18766, %18767" -> "  %18776 = add nuw nsw i32 %18768, %18775"
"  %18769 = and i32 %18719, 65535"
"  %18769 = and i32 %18719, 65535" -> "  %18771 = add nuw nsw i32 %18769, %18770"
"  %18770 = and i32 %18751, 65535"
"  %18770 = and i32 %18751, 65535" -> "  %18771 = add nuw nsw i32 %18769, %18770"
"  %18771 = add nuw nsw i32 %18769, %18770"
"  %18771 = add nuw nsw i32 %18769, %18770" -> "  %18782 = and i32 %18771, 65535""  %18771 = add nuw nsw i32 %18769, %18770" -> "  %18778 = lshr i32 %18771, 16"
"  %18772 = and i32 %18760, 65535"
"  %18772 = and i32 %18760, 65535" -> "  %18774 = add nuw nsw i32 %18773, %18772"
"  %18773 = lshr i32 %18719, 16"
"  %18773 = lshr i32 %18719, 16" -> "  %18774 = add nuw nsw i32 %18773, %18772"
"  %18774 = add nuw nsw i32 %18773, %18772"
"  %18774 = add nuw nsw i32 %18773, %18772" -> "  %18777 = and i32 %18774, 65535""  %18774 = add nuw nsw i32 %18773, %18772" -> "  %18775 = lshr i32 %18774, 16"
"  %18775 = lshr i32 %18774, 16"
"  %18775 = lshr i32 %18774, 16" -> "  %18776 = add nuw nsw i32 %18768, %18775"
"  %18776 = add nuw nsw i32 %18768, %18775"
"  %18776 = add nuw nsw i32 %18768, %18775" -> "  %18781 = add nuw nsw i32 %18776, %18780"
"  %18777 = and i32 %18774, 65535"
"  %18777 = and i32 %18774, 65535" -> "  %18779 = add nuw nsw i32 %18778, %18777"
"  %18778 = lshr i32 %18771, 16"
"  %18778 = lshr i32 %18771, 16" -> "  %18779 = add nuw nsw i32 %18778, %18777"
"  %18779 = add nuw nsw i32 %18778, %18777"
"  %18779 = add nuw nsw i32 %18778, %18777" -> "  %18785 = and i32 %18779, 65535""  %18779 = add nuw nsw i32 %18778, %18777" -> "  %18780 = lshr i32 %18779, 16"
"  %18780 = lshr i32 %18779, 16"
"  %18780 = lshr i32 %18779, 16" -> "  %18781 = add nuw nsw i32 %18776, %18780"
"  %18781 = add nuw nsw i32 %18776, %18780"
"  %18781 = add nuw nsw i32 %18776, %18780" -> "  %18794 = and i32 %18781, 2147418112""  %18781 = add nuw nsw i32 %18776, %18780" -> "  %18792 = and i32 %18781, 65535"
"  %18782 = and i32 %18771, 65535"
"  %18782 = and i32 %18771, 65535" -> "  %18784 = add nuw nsw i32 %18783, %18782"
"  %18783 = and i32 %18750, 65535"
"  %18783 = and i32 %18750, 65535" -> "  %18784 = add nuw nsw i32 %18783, %18782"
"  %18784 = add nuw nsw i32 %18783, %18782"
"  %18784 = add nuw nsw i32 %18783, %18782" -> "  %18923 = and i32 %18784, 65535""  %18784 = add nuw nsw i32 %18783, %18782" -> "  %18788 = lshr i32 %18784, 16"
"  %18785 = and i32 %18779, 65535"
"  %18785 = and i32 %18779, 65535" -> "  %18787 = add nuw nsw i32 %18786, %18785"
"  %18786 = lshr i32 %18750, 16"
"  %18786 = lshr i32 %18750, 16" -> "  %18787 = add nuw nsw i32 %18786, %18785"
"  %18787 = add nuw nsw i32 %18786, %18785"
"  %18787 = add nuw nsw i32 %18786, %18785" -> "  %18791 = lshr i32 %18787, 16""  %18787 = add nuw nsw i32 %18786, %18785" -> "  %18789 = and i32 %18787, 65535"
"  %18788 = lshr i32 %18784, 16"
"  %18788 = lshr i32 %18784, 16" -> "  %18790 = add nuw nsw i32 %18788, %18789"
"  %18789 = and i32 %18787, 65535"
"  %18789 = and i32 %18787, 65535" -> "  %18790 = add nuw nsw i32 %18788, %18789"
"  %18790 = add nuw nsw i32 %18788, %18789"
"  %18790 = add nuw nsw i32 %18788, %18789" -> "  %18926 = and i32 %18790, 65535""  %18790 = add nuw nsw i32 %18788, %18789" -> "  %18796 = lshr i32 %18790, 16"
"  %18791 = lshr i32 %18787, 16"
"  %18791 = lshr i32 %18787, 16" -> "  %18793 = add nuw nsw i32 %18791, %18792"
"  %18792 = and i32 %18781, 65535"
"  %18792 = and i32 %18781, 65535" -> "  %18793 = add nuw nsw i32 %18791, %18792"
"  %18793 = add nuw nsw i32 %18791, %18792"
"  %18793 = add nuw nsw i32 %18791, %18792" -> "  %18795 = add nuw nsw i32 %18793, %18794"
"  %18794 = and i32 %18781, 2147418112"
"  %18794 = and i32 %18781, 2147418112" -> "  %18795 = add nuw nsw i32 %18793, %18794"
"  %18795 = add nuw nsw i32 %18793, %18794"
"  %18795 = add nuw nsw i32 %18793, %18794" -> "  %18797 = add nuw nsw i32 %18795, %18796"
"  %18796 = lshr i32 %18790, 16"
"  %18796 = lshr i32 %18790, 16" -> "  %18797 = add nuw nsw i32 %18795, %18796"
"  %18797 = add nuw nsw i32 %18795, %18796"
"  %18797 = add nuw nsw i32 %18795, %18796" -> "  %18938 = lshr i32 %18797, 16""  %18797 = add nuw nsw i32 %18795, %18796" -> "  %18935 = and i32 %18797, 65535"
"  %18798 = mul nuw i32 %17375, 42779"
"  %18798 = mul nuw i32 %17375, 42779" -> "  %18922 = and i32 %18798, 65535""  %18798 = mul nuw i32 %17375, 42779" -> "  %18799 = lshr i32 %18798, 16"
"  %18799 = lshr i32 %18798, 16"
"  %18799 = lshr i32 %18798, 16" -> "  %18802 = add nuw nsw i32 %18801, %18799"
"  %18800 = mul nuw i32 %17376, 42779"
"  %18800 = mul nuw i32 %17376, 42779" -> "  %18803 = and i32 %18800, -65536""  %18800 = mul nuw i32 %17376, 42779" -> "  %18801 = and i32 %18800, 65535"
"  %18801 = and i32 %18800, 65535"
"  %18801 = and i32 %18800, 65535" -> "  %18802 = add nuw nsw i32 %18801, %18799"
"  %18802 = add nuw nsw i32 %18801, %18799"
"  %18802 = add nuw nsw i32 %18801, %18799" -> "  %18804 = add nuw i32 %18802, %18803"
"  %18803 = and i32 %18800, -65536"
"  %18803 = and i32 %18800, -65536" -> "  %18804 = add nuw i32 %18802, %18803"
"  %18804 = add nuw i32 %18802, %18803"
"  %18804 = add nuw i32 %18802, %18803" -> "  %18808 = lshr i32 %18804, 16""  %18804 = add nuw i32 %18802, %18803" -> "  %18806 = and i32 %18804, 65535"
"  %18805 = mul nuw nsw i32 %17375, 9871"
"  %18805 = mul nuw nsw i32 %17375, 9871" -> "  %18807 = add nuw nsw i32 %18806, %18805"
"  %18806 = and i32 %18804, 65535"
"  %18806 = and i32 %18804, 65535" -> "  %18807 = add nuw nsw i32 %18806, %18805"
"  %18807 = add nuw nsw i32 %18806, %18805"
"  %18807 = add nuw nsw i32 %18806, %18805" -> "  %18925 = and i32 %18807, 65535""  %18807 = add nuw nsw i32 %18806, %18805" -> "  %18811 = lshr i32 %18807, 16"
"  %18808 = lshr i32 %18804, 16"
"  %18808 = lshr i32 %18804, 16" -> "  %18810 = add nuw nsw i32 %18808, %18809"
"  %18809 = mul nuw nsw i32 %17376, 9871"
"  %18809 = mul nuw nsw i32 %17376, 9871" -> "  %18810 = add nuw nsw i32 %18808, %18809"
"  %18810 = add nuw nsw i32 %18808, %18809"
"  %18810 = add nuw nsw i32 %18808, %18809" -> "  %18814 = and i32 %18810, 2147418112""  %18810 = add nuw nsw i32 %18808, %18809" -> "  %18812 = and i32 %18810, 65535"
"  %18811 = lshr i32 %18807, 16"
"  %18811 = lshr i32 %18807, 16" -> "  %18813 = add nuw nsw i32 %18811, %18812"
"  %18812 = and i32 %18810, 65535"
"  %18812 = and i32 %18810, 65535" -> "  %18813 = add nuw nsw i32 %18811, %18812"
"  %18813 = add nuw nsw i32 %18811, %18812"
"  %18813 = add nuw nsw i32 %18811, %18812" -> "  %18815 = add nuw nsw i32 %18813, %18814"
"  %18814 = and i32 %18810, 2147418112"
"  %18814 = and i32 %18810, 2147418112" -> "  %18815 = add nuw nsw i32 %18813, %18814"
"  %18815 = add nuw nsw i32 %18813, %18814"
"  %18815 = add nuw nsw i32 %18813, %18814" -> "  %18838 = lshr i32 %18815, 16""  %18815 = add nuw nsw i32 %18813, %18814" -> "  %18834 = and i32 %18815, 65535"
"  %18816 = mul nuw i32 %17395, 42779"
"  %18816 = mul nuw i32 %17395, 42779" -> "  %18835 = and i32 %18816, 65535""  %18816 = mul nuw i32 %17395, 42779" -> "  %18817 = lshr i32 %18816, 16"
"  %18817 = lshr i32 %18816, 16"
"  %18817 = lshr i32 %18816, 16" -> "  %18820 = add nuw nsw i32 %18819, %18817"
"  %18818 = mul nuw i32 %17398, 42779"
"  %18818 = mul nuw i32 %17398, 42779" -> "  %18821 = and i32 %18818, -65536""  %18818 = mul nuw i32 %17398, 42779" -> "  %18819 = and i32 %18818, 65535"
"  %18819 = and i32 %18818, 65535"
"  %18819 = and i32 %18818, 65535" -> "  %18820 = add nuw nsw i32 %18819, %18817"
"  %18820 = add nuw nsw i32 %18819, %18817"
"  %18820 = add nuw nsw i32 %18819, %18817" -> "  %18822 = add nuw i32 %18820, %18821"
"  %18821 = and i32 %18818, -65536"
"  %18821 = and i32 %18818, -65536" -> "  %18822 = add nuw i32 %18820, %18821"
"  %18822 = add nuw i32 %18820, %18821"
"  %18822 = add nuw i32 %18820, %18821" -> "  %18826 = lshr i32 %18822, 16""  %18822 = add nuw i32 %18820, %18821" -> "  %18824 = and i32 %18822, 65535"
"  %18823 = mul nuw nsw i32 %17395, 9871"
"  %18823 = mul nuw nsw i32 %17395, 9871" -> "  %18825 = add nuw nsw i32 %18824, %18823"
"  %18824 = and i32 %18822, 65535"
"  %18824 = and i32 %18822, 65535" -> "  %18825 = add nuw nsw i32 %18824, %18823"
"  %18825 = add nuw nsw i32 %18824, %18823"
"  %18825 = add nuw nsw i32 %18824, %18823" -> "  %18837 = and i32 %18825, 65535""  %18825 = add nuw nsw i32 %18824, %18823" -> "  %18829 = lshr i32 %18825, 16"
"  %18826 = lshr i32 %18822, 16"
"  %18826 = lshr i32 %18822, 16" -> "  %18828 = add nuw nsw i32 %18826, %18827"
"  %18827 = mul nuw nsw i32 %17398, 9871"
"  %18827 = mul nuw nsw i32 %17398, 9871" -> "  %18828 = add nuw nsw i32 %18826, %18827"
"  %18828 = add nuw nsw i32 %18826, %18827"
"  %18828 = add nuw nsw i32 %18826, %18827" -> "  %18832 = and i32 %18828, 2147418112""  %18828 = add nuw nsw i32 %18826, %18827" -> "  %18830 = and i32 %18828, 65535"
"  %18829 = lshr i32 %18825, 16"
"  %18829 = lshr i32 %18825, 16" -> "  %18831 = add nuw nsw i32 %18829, %18830"
"  %18830 = and i32 %18828, 65535"
"  %18830 = and i32 %18828, 65535" -> "  %18831 = add nuw nsw i32 %18829, %18830"
"  %18831 = add nuw nsw i32 %18829, %18830"
"  %18831 = add nuw nsw i32 %18829, %18830" -> "  %18833 = add nuw nsw i32 %18831, %18832"
"  %18832 = and i32 %18828, 2147418112"
"  %18832 = and i32 %18828, 2147418112" -> "  %18833 = add nuw nsw i32 %18831, %18832"
"  %18833 = add nuw nsw i32 %18831, %18832"
"  %18833 = add nuw nsw i32 %18831, %18832" -> "  %18841 = add nuw nsw i32 %18833, %18840"
"  %18834 = and i32 %18815, 65535"
"  %18834 = and i32 %18815, 65535" -> "  %18836 = add nuw nsw i32 %18834, %18835"
"  %18835 = and i32 %18816, 65535"
"  %18835 = and i32 %18816, 65535" -> "  %18836 = add nuw nsw i32 %18834, %18835"
"  %18836 = add nuw nsw i32 %18834, %18835"
"  %18836 = add nuw nsw i32 %18834, %18835" -> "  %18865 = and i32 %18836, 65535""  %18836 = add nuw nsw i32 %18834, %18835" -> "  %18843 = lshr i32 %18836, 16"
"  %18837 = and i32 %18825, 65535"
"  %18837 = and i32 %18825, 65535" -> "  %18839 = add nuw nsw i32 %18837, %18838"
"  %18838 = lshr i32 %18815, 16"
"  %18838 = lshr i32 %18815, 16" -> "  %18839 = add nuw nsw i32 %18837, %18838"
"  %18839 = add nuw nsw i32 %18837, %18838"
"  %18839 = add nuw nsw i32 %18837, %18838" -> "  %18842 = and i32 %18839, 65535""  %18839 = add nuw nsw i32 %18837, %18838" -> "  %18840 = lshr i32 %18839, 16"
"  %18840 = lshr i32 %18839, 16"
"  %18840 = lshr i32 %18839, 16" -> "  %18841 = add nuw nsw i32 %18833, %18840"
"  %18841 = add nuw nsw i32 %18833, %18840"
"  %18841 = add nuw nsw i32 %18833, %18840" -> "  %18846 = add nuw nsw i32 %18841, %18845"
"  %18842 = and i32 %18839, 65535"
"  %18842 = and i32 %18839, 65535" -> "  %18844 = add nuw nsw i32 %18842, %18843"
"  %18843 = lshr i32 %18836, 16"
"  %18843 = lshr i32 %18836, 16" -> "  %18844 = add nuw nsw i32 %18842, %18843"
"  %18844 = add nuw nsw i32 %18842, %18843"
"  %18844 = add nuw nsw i32 %18842, %18843" -> "  %18868 = and i32 %18844, 65535""  %18844 = add nuw nsw i32 %18842, %18843" -> "  %18845 = lshr i32 %18844, 16"
"  %18845 = lshr i32 %18844, 16"
"  %18845 = lshr i32 %18844, 16" -> "  %18846 = add nuw nsw i32 %18841, %18845"
"  %18846 = add nuw nsw i32 %18841, %18845"
"  %18846 = add nuw nsw i32 %18841, %18845" -> "  %18897 = lshr i32 %18846, 16""  %18846 = add nuw nsw i32 %18841, %18845" -> "  %18893 = and i32 %18846, 65535"
"  %18847 = mul nuw nsw i32 %17375, 24315"
"  %18847 = mul nuw nsw i32 %17375, 24315" -> "  %18866 = and i32 %18847, 65535""  %18847 = mul nuw nsw i32 %17375, 24315" -> "  %18848 = lshr i32 %18847, 16"
"  %18848 = lshr i32 %18847, 16"
"  %18848 = lshr i32 %18847, 16" -> "  %18851 = add nuw nsw i32 %18850, %18848"
"  %18849 = mul nuw nsw i32 %17376, 24315"
"  %18849 = mul nuw nsw i32 %17376, 24315" -> "  %18852 = and i32 %18849, 2147418112""  %18849 = mul nuw nsw i32 %17376, 24315" -> "  %18850 = and i32 %18849, 65535"
"  %18850 = and i32 %18849, 65535"
"  %18850 = and i32 %18849, 65535" -> "  %18851 = add nuw nsw i32 %18850, %18848"
"  %18851 = add nuw nsw i32 %18850, %18848"
"  %18851 = add nuw nsw i32 %18850, %18848" -> "  %18853 = add nuw nsw i32 %18851, %18852"
"  %18852 = and i32 %18849, 2147418112"
"  %18852 = and i32 %18849, 2147418112" -> "  %18853 = add nuw nsw i32 %18851, %18852"
"  %18853 = add nuw nsw i32 %18851, %18852"
"  %18853 = add nuw nsw i32 %18851, %18852" -> "  %18857 = lshr i32 %18853, 16""  %18853 = add nuw nsw i32 %18851, %18852" -> "  %18855 = and i32 %18853, 65535"
"  %18854 = mul nuw nsw i32 %17375, 29744"
"  %18854 = mul nuw nsw i32 %17375, 29744" -> "  %18856 = add nuw nsw i32 %18855, %18854"
"  %18855 = and i32 %18853, 65535"
"  %18855 = and i32 %18853, 65535" -> "  %18856 = add nuw nsw i32 %18855, %18854"
"  %18856 = add nuw nsw i32 %18855, %18854"
"  %18856 = add nuw nsw i32 %18855, %18854" -> "  %18869 = and i32 %18856, 65535""  %18856 = add nuw nsw i32 %18855, %18854" -> "  %18860 = lshr i32 %18856, 16"
"  %18857 = lshr i32 %18853, 16"
"  %18857 = lshr i32 %18853, 16" -> "  %18859 = add nuw nsw i32 %18857, %18858"
"  %18858 = mul nuw nsw i32 %17376, 29744"
"  %18858 = mul nuw nsw i32 %17376, 29744" -> "  %18859 = add nuw nsw i32 %18857, %18858"
"  %18859 = add nuw nsw i32 %18857, %18858"
"  %18859 = add nuw nsw i32 %18857, %18858" -> "  %18863 = and i32 %18859, 2147418112""  %18859 = add nuw nsw i32 %18857, %18858" -> "  %18861 = and i32 %18859, 65535"
"  %18860 = lshr i32 %18856, 16"
"  %18860 = lshr i32 %18856, 16" -> "  %18862 = add nuw nsw i32 %18860, %18861"
"  %18861 = and i32 %18859, 65535"
"  %18861 = and i32 %18859, 65535" -> "  %18862 = add nuw nsw i32 %18860, %18861"
"  %18862 = add nuw nsw i32 %18860, %18861"
"  %18862 = add nuw nsw i32 %18860, %18861" -> "  %18864 = add nuw nsw i32 %18862, %18863"
"  %18863 = and i32 %18859, 2147418112"
"  %18863 = and i32 %18859, 2147418112" -> "  %18864 = add nuw nsw i32 %18862, %18863"
"  %18864 = add nuw nsw i32 %18862, %18863"
"  %18864 = add nuw nsw i32 %18862, %18863" -> "  %18872 = add nuw nsw i32 %18864, %18871"
"  %18865 = and i32 %18836, 65535"
"  %18865 = and i32 %18836, 65535" -> "  %18867 = add nuw nsw i32 %18865, %18866"
"  %18866 = and i32 %18847, 65535"
"  %18866 = and i32 %18847, 65535" -> "  %18867 = add nuw nsw i32 %18865, %18866"
"  %18867 = add nuw nsw i32 %18865, %18866"
"  %18867 = add nuw nsw i32 %18865, %18866" -> "  %18934 = and i32 %18867, 65535""  %18867 = add nuw nsw i32 %18865, %18866" -> "  %18874 = lshr i32 %18867, 16"
"  %18868 = and i32 %18844, 65535"
"  %18868 = and i32 %18844, 65535" -> "  %18870 = add nuw nsw i32 %18868, %18869"
"  %18869 = and i32 %18856, 65535"
"  %18869 = and i32 %18856, 65535" -> "  %18870 = add nuw nsw i32 %18868, %18869"
"  %18870 = add nuw nsw i32 %18868, %18869"
"  %18870 = add nuw nsw i32 %18868, %18869" -> "  %18873 = and i32 %18870, 65535""  %18870 = add nuw nsw i32 %18868, %18869" -> "  %18871 = lshr i32 %18870, 16"
"  %18871 = lshr i32 %18870, 16"
"  %18871 = lshr i32 %18870, 16" -> "  %18872 = add nuw nsw i32 %18864, %18871"
"  %18872 = add nuw nsw i32 %18864, %18871"
"  %18872 = add nuw nsw i32 %18864, %18871" -> "  %18877 = add nuw nsw i32 %18872, %18876"
"  %18873 = and i32 %18870, 65535"
"  %18873 = and i32 %18870, 65535" -> "  %18875 = add nuw nsw i32 %18873, %18874"
"  %18874 = lshr i32 %18867, 16"
"  %18874 = lshr i32 %18867, 16" -> "  %18875 = add nuw nsw i32 %18873, %18874"
"  %18875 = add nuw nsw i32 %18873, %18874"
"  %18875 = add nuw nsw i32 %18873, %18874" -> "  %18937 = and i32 %18875, 65535""  %18875 = add nuw nsw i32 %18873, %18874" -> "  %18876 = lshr i32 %18875, 16"
"  %18876 = lshr i32 %18875, 16"
"  %18876 = lshr i32 %18875, 16" -> "  %18877 = add nuw nsw i32 %18872, %18876"
"  %18877 = add nuw nsw i32 %18872, %18876"
"  %18877 = add nuw nsw i32 %18872, %18876" -> "  %18910 = lshr i32 %18877, 16""  %18877 = add nuw nsw i32 %18872, %18876" -> "  %18907 = and i32 %18877, 65535"
"  %18878 = mul nuw nsw i32 %17395, 24315"
"  %18878 = mul nuw nsw i32 %17395, 24315" -> "  %18894 = and i32 %18878, 65535""  %18878 = mul nuw nsw i32 %17395, 24315" -> "  %18879 = lshr i32 %18878, 16"
"  %18879 = lshr i32 %18878, 16"
"  %18879 = lshr i32 %18878, 16" -> "  %18881 = add nuw nsw i32 %18880, %18879"
"  %18880 = mul nuw nsw i32 %17398, 24315"
"  %18880 = mul nuw nsw i32 %17398, 24315" -> "  %18881 = add nuw nsw i32 %18880, %18879"
"  %18881 = add nuw nsw i32 %18880, %18879"
"  %18881 = add nuw nsw i32 %18880, %18879" -> "  %18885 = lshr i32 %18881, 16""  %18881 = add nuw nsw i32 %18880, %18879" -> "  %18883 = and i32 %18881, 65535"
"  %18882 = mul nuw nsw i32 %17395, 29744"
"  %18882 = mul nuw nsw i32 %17395, 29744" -> "  %18884 = add nuw nsw i32 %18883, %18882"
"  %18883 = and i32 %18881, 65535"
"  %18883 = and i32 %18881, 65535" -> "  %18884 = add nuw nsw i32 %18883, %18882"
"  %18884 = add nuw nsw i32 %18883, %18882"
"  %18884 = add nuw nsw i32 %18883, %18882" -> "  %18896 = and i32 %18884, 65535""  %18884 = add nuw nsw i32 %18883, %18882" -> "  %18888 = lshr i32 %18884, 16"
"  %18885 = lshr i32 %18881, 16"
"  %18885 = lshr i32 %18881, 16" -> "  %18887 = add nuw nsw i32 %18885, %18886"
"  %18886 = mul nuw nsw i32 %17398, 29744"
"  %18886 = mul nuw nsw i32 %17398, 29744" -> "  %18887 = add nuw nsw i32 %18885, %18886"
"  %18887 = add nuw nsw i32 %18885, %18886"
"  %18887 = add nuw nsw i32 %18885, %18886" -> "  %18891 = and i32 %18887, 2147418112""  %18887 = add nuw nsw i32 %18885, %18886" -> "  %18889 = and i32 %18887, 65535"
"  %18888 = lshr i32 %18884, 16"
"  %18888 = lshr i32 %18884, 16" -> "  %18890 = add nuw nsw i32 %18888, %18889"
"  %18889 = and i32 %18887, 65535"
"  %18889 = and i32 %18887, 65535" -> "  %18890 = add nuw nsw i32 %18888, %18889"
"  %18890 = add nuw nsw i32 %18888, %18889"
"  %18890 = add nuw nsw i32 %18888, %18889" -> "  %18892 = add nuw nsw i32 %18890, %18891"
"  %18891 = and i32 %18887, 2147418112"
"  %18891 = and i32 %18887, 2147418112" -> "  %18892 = add nuw nsw i32 %18890, %18891"
"  %18892 = add nuw nsw i32 %18890, %18891"
"  %18892 = add nuw nsw i32 %18890, %18891" -> "  %18900 = add nuw nsw i32 %18892, %18899"
"  %18893 = and i32 %18846, 65535"
"  %18893 = and i32 %18846, 65535" -> "  %18895 = add nuw nsw i32 %18893, %18894"
"  %18894 = and i32 %18878, 65535"
"  %18894 = and i32 %18878, 65535" -> "  %18895 = add nuw nsw i32 %18893, %18894"
"  %18895 = add nuw nsw i32 %18893, %18894"
"  %18895 = add nuw nsw i32 %18893, %18894" -> "  %18906 = and i32 %18895, 65535""  %18895 = add nuw nsw i32 %18893, %18894" -> "  %18902 = lshr i32 %18895, 16"
"  %18896 = and i32 %18884, 65535"
"  %18896 = and i32 %18884, 65535" -> "  %18898 = add nuw nsw i32 %18897, %18896"
"  %18897 = lshr i32 %18846, 16"
"  %18897 = lshr i32 %18846, 16" -> "  %18898 = add nuw nsw i32 %18897, %18896"
"  %18898 = add nuw nsw i32 %18897, %18896"
"  %18898 = add nuw nsw i32 %18897, %18896" -> "  %18901 = and i32 %18898, 65535""  %18898 = add nuw nsw i32 %18897, %18896" -> "  %18899 = lshr i32 %18898, 16"
"  %18899 = lshr i32 %18898, 16"
"  %18899 = lshr i32 %18898, 16" -> "  %18900 = add nuw nsw i32 %18892, %18899"
"  %18900 = add nuw nsw i32 %18892, %18899"
"  %18900 = add nuw nsw i32 %18892, %18899" -> "  %18905 = add nuw nsw i32 %18900, %18904"
"  %18901 = and i32 %18898, 65535"
"  %18901 = and i32 %18898, 65535" -> "  %18903 = add nuw nsw i32 %18901, %18902"
"  %18902 = lshr i32 %18895, 16"
"  %18902 = lshr i32 %18895, 16" -> "  %18903 = add nuw nsw i32 %18901, %18902"
"  %18903 = add nuw nsw i32 %18901, %18902"
"  %18903 = add nuw nsw i32 %18901, %18902" -> "  %18909 = and i32 %18903, 65535""  %18903 = add nuw nsw i32 %18901, %18902" -> "  %18904 = lshr i32 %18903, 16"
"  %18904 = lshr i32 %18903, 16"
"  %18904 = lshr i32 %18903, 16" -> "  %18905 = add nuw nsw i32 %18900, %18904"
"  %18905 = add nuw nsw i32 %18900, %18904"
"  %18905 = add nuw nsw i32 %18900, %18904" -> "  %18918 = and i32 %18905, 2147418112""  %18905 = add nuw nsw i32 %18900, %18904" -> "  %18916 = and i32 %18905, 65535"
"  %18906 = and i32 %18895, 65535"
"  %18906 = and i32 %18895, 65535" -> "  %18908 = add nuw nsw i32 %18907, %18906"
"  %18907 = and i32 %18877, 65535"
"  %18907 = and i32 %18877, 65535" -> "  %18908 = add nuw nsw i32 %18907, %18906"
"  %18908 = add nuw nsw i32 %18907, %18906"
"  %18908 = add nuw nsw i32 %18907, %18906" -> "  %18948 = and i32 %18908, 65535""  %18908 = add nuw nsw i32 %18907, %18906" -> "  %18912 = lshr i32 %18908, 16"
"  %18909 = and i32 %18903, 65535"
"  %18909 = and i32 %18903, 65535" -> "  %18911 = add nuw nsw i32 %18909, %18910"
"  %18910 = lshr i32 %18877, 16"
"  %18910 = lshr i32 %18877, 16" -> "  %18911 = add nuw nsw i32 %18909, %18910"
"  %18911 = add nuw nsw i32 %18909, %18910"
"  %18911 = add nuw nsw i32 %18909, %18910" -> "  %18915 = lshr i32 %18911, 16""  %18911 = add nuw nsw i32 %18909, %18910" -> "  %18913 = and i32 %18911, 65535"
"  %18912 = lshr i32 %18908, 16"
"  %18912 = lshr i32 %18908, 16" -> "  %18914 = add nuw nsw i32 %18913, %18912"
"  %18913 = and i32 %18911, 65535"
"  %18913 = and i32 %18911, 65535" -> "  %18914 = add nuw nsw i32 %18913, %18912"
"  %18914 = add nuw nsw i32 %18913, %18912"
"  %18914 = add nuw nsw i32 %18913, %18912" -> "  %18955 = and i32 %18914, 65535""  %18914 = add nuw nsw i32 %18913, %18912" -> "  %18920 = lshr i32 %18914, 16"
"  %18915 = lshr i32 %18911, 16"
"  %18915 = lshr i32 %18911, 16" -> "  %18917 = add nuw nsw i32 %18915, %18916"
"  %18916 = and i32 %18905, 65535"
"  %18916 = and i32 %18905, 65535" -> "  %18917 = add nuw nsw i32 %18915, %18916"
"  %18917 = add nuw nsw i32 %18915, %18916"
"  %18917 = add nuw nsw i32 %18915, %18916" -> "  %18919 = add nuw nsw i32 %18917, %18918"
"  %18918 = and i32 %18905, 2147418112"
"  %18918 = and i32 %18905, 2147418112" -> "  %18919 = add nuw nsw i32 %18917, %18918"
"  %18919 = add nuw nsw i32 %18917, %18918"
"  %18919 = add nuw nsw i32 %18917, %18918" -> "  %18921 = add nuw nsw i32 %18919, %18920"
"  %18920 = lshr i32 %18914, 16"
"  %18920 = lshr i32 %18914, 16" -> "  %18921 = add nuw nsw i32 %18919, %18920"
"  %18921 = add nuw nsw i32 %18919, %18920"
"  %18921 = add nuw nsw i32 %18919, %18920" -> "  %18959 = add nuw nsw i32 %18921, %18958"
"  %18922 = and i32 %18798, 65535"
"  %18922 = and i32 %18798, 65535" -> "  %18924 = add nuw nsw i32 %18923, %18922"
"  %18923 = and i32 %18784, 65535"
"  %18923 = and i32 %18784, 65535" -> "  %18924 = add nuw nsw i32 %18923, %18922"
"  %18924 = add nuw nsw i32 %18923, %18922"
"  %18924 = add nuw nsw i32 %18923, %18922" -> "  %19088 = and i32 %18924, 65535""  %18924 = add nuw nsw i32 %18923, %18922" -> "  %18928 = lshr i32 %18924, 16"
"  %18925 = and i32 %18807, 65535"
"  %18925 = and i32 %18807, 65535" -> "  %18927 = add nuw nsw i32 %18925, %18926"
"  %18926 = and i32 %18790, 65535"
"  %18926 = and i32 %18790, 65535" -> "  %18927 = add nuw nsw i32 %18925, %18926"
"  %18927 = add nuw nsw i32 %18925, %18926"
"  %18927 = add nuw nsw i32 %18925, %18926" -> "  %18931 = lshr i32 %18927, 16""  %18927 = add nuw nsw i32 %18925, %18926" -> "  %18929 = and i32 %18927, 65535"
"  %18928 = lshr i32 %18924, 16"
"  %18928 = lshr i32 %18924, 16" -> "  %18930 = add nuw nsw i32 %18929, %18928"
"  %18929 = and i32 %18927, 65535"
"  %18929 = and i32 %18927, 65535" -> "  %18930 = add nuw nsw i32 %18929, %18928"
"  %18930 = add nuw nsw i32 %18929, %18928"
"  %18930 = add nuw nsw i32 %18929, %18928" -> "  %19091 = and i32 %18930, 65535""  %18930 = add nuw nsw i32 %18929, %18928" -> "  %18932 = lshr i32 %18930, 16"
"  %18931 = lshr i32 %18927, 16"
"  %18931 = lshr i32 %18927, 16" -> "  %18933 = add nuw nsw i32 %18932, %18931"
"  %18932 = lshr i32 %18930, 16"
"  %18932 = lshr i32 %18930, 16" -> "  %18933 = add nuw nsw i32 %18932, %18931"
"  %18933 = add nuw nsw i32 %18932, %18931"
"  %18933 = add nuw nsw i32 %18932, %18931" -> "  %18944 = add nuw nsw i32 %18933, %18943"
"  %18934 = and i32 %18867, 65535"
"  %18934 = and i32 %18867, 65535" -> "  %18936 = add nuw nsw i32 %18934, %18935"
"  %18935 = and i32 %18797, 65535"
"  %18935 = and i32 %18797, 65535" -> "  %18936 = add nuw nsw i32 %18934, %18935"
"  %18936 = add nuw nsw i32 %18934, %18935"
"  %18936 = add nuw nsw i32 %18934, %18935" -> "  %18943 = and i32 %18936, 65535""  %18936 = add nuw nsw i32 %18934, %18935" -> "  %18940 = lshr i32 %18936, 16"
"  %18937 = and i32 %18875, 65535"
"  %18937 = and i32 %18875, 65535" -> "  %18939 = add nuw nsw i32 %18937, %18938"
"  %18938 = lshr i32 %18797, 16"
"  %18938 = lshr i32 %18797, 16" -> "  %18939 = add nuw nsw i32 %18937, %18938"
"  %18939 = add nuw nsw i32 %18937, %18938"
"  %18939 = add nuw nsw i32 %18937, %18938" -> "  %18949 = lshr i32 %18939, 16""  %18939 = add nuw nsw i32 %18937, %18938" -> "  %18941 = and i32 %18939, 65535"
"  %18940 = lshr i32 %18936, 16"
"  %18940 = lshr i32 %18936, 16" -> "  %18942 = add nuw nsw i32 %18941, %18940"
"  %18941 = and i32 %18939, 65535"
"  %18941 = and i32 %18939, 65535" -> "  %18942 = add nuw nsw i32 %18941, %18940"
"  %18942 = add nuw nsw i32 %18941, %18940"
"  %18942 = add nuw nsw i32 %18941, %18940" -> "  %18951 = lshr i32 %18942, 16""  %18942 = add nuw nsw i32 %18941, %18940" -> "  %18946 = and i32 %18942, 65535"
"  %18943 = and i32 %18936, 65535"
"  %18943 = and i32 %18936, 65535" -> "  %18944 = add nuw nsw i32 %18933, %18943"
"  %18944 = add nuw nsw i32 %18933, %18943"
"  %18944 = add nuw nsw i32 %18933, %18943" -> "  %19099 = and i32 %18944, 65535""  %18944 = add nuw nsw i32 %18933, %18943" -> "  %18945 = lshr i32 %18944, 16"
"  %18945 = lshr i32 %18944, 16"
"  %18945 = lshr i32 %18944, 16" -> "  %18947 = add nuw nsw i32 %18946, %18945"
"  %18946 = and i32 %18942, 65535"
"  %18946 = and i32 %18942, 65535" -> "  %18947 = add nuw nsw i32 %18946, %18945"
"  %18947 = add nuw nsw i32 %18946, %18945"
"  %18947 = add nuw nsw i32 %18946, %18945" -> "  %19102 = and i32 %18947, 65535""  %18947 = add nuw nsw i32 %18946, %18945" -> "  %18953 = lshr i32 %18947, 16"
"  %18948 = and i32 %18908, 65535"
"  %18948 = and i32 %18908, 65535" -> "  %18950 = add nuw nsw i32 %18948, %18949"
"  %18949 = lshr i32 %18939, 16"
"  %18949 = lshr i32 %18939, 16" -> "  %18950 = add nuw nsw i32 %18948, %18949"
"  %18950 = add nuw nsw i32 %18948, %18949"
"  %18950 = add nuw nsw i32 %18948, %18949" -> "  %18952 = add nuw nsw i32 %18950, %18951"
"  %18951 = lshr i32 %18942, 16"
"  %18951 = lshr i32 %18942, 16" -> "  %18952 = add nuw nsw i32 %18950, %18951"
"  %18952 = add nuw nsw i32 %18950, %18951"
"  %18952 = add nuw nsw i32 %18950, %18951" -> "  %18954 = add nuw nsw i32 %18952, %18953"
"  %18953 = lshr i32 %18947, 16"
"  %18953 = lshr i32 %18947, 16" -> "  %18954 = add nuw nsw i32 %18952, %18953"
"  %18954 = add nuw nsw i32 %18952, %18953"
"  %18954 = add nuw nsw i32 %18952, %18953" -> "  %19253 = and i32 %18954, 65535""  %18954 = add nuw nsw i32 %18952, %18953" -> "  %18956 = lshr i32 %18954, 16"
"  %18955 = and i32 %18914, 65535"
"  %18955 = and i32 %18914, 65535" -> "  %18957 = add nuw nsw i32 %18956, %18955"
"  %18956 = lshr i32 %18954, 16"
"  %18956 = lshr i32 %18954, 16" -> "  %18957 = add nuw nsw i32 %18956, %18955"
"  %18957 = add nuw nsw i32 %18956, %18955"
"  %18957 = add nuw nsw i32 %18956, %18955" -> "  %19256 = and i32 %18957, 65535""  %18957 = add nuw nsw i32 %18956, %18955" -> "  %18958 = lshr i32 %18957, 16"
"  %18958 = lshr i32 %18957, 16"
"  %18958 = lshr i32 %18957, 16" -> "  %18959 = add nuw nsw i32 %18921, %18958"
"  %18959 = add nuw nsw i32 %18921, %18958"
"  %18959 = add nuw nsw i32 %18921, %18958" -> "  %19262 = and i32 %18959, 65535""  %18959 = add nuw nsw i32 %18921, %18958" -> "  %19265 = lshr i32 %18959, 16"
"  %18960 = mul nuw nsw i32 %17241, 4087"
"  %18960 = mul nuw nsw i32 %17241, 4087" -> "  %19087 = and i32 %18960, 65535""  %18960 = mul nuw nsw i32 %17241, 4087" -> "  %18961 = lshr i32 %18960, 16"
"  %18961 = lshr i32 %18960, 16"
"  %18961 = lshr i32 %18960, 16" -> "  %18964 = add nuw nsw i32 %18963, %18961"
"  %18962 = mul nuw nsw i32 %17244, 4087"
"  %18962 = mul nuw nsw i32 %17244, 4087" -> "  %18965 = and i32 %18962, 268369920""  %18962 = mul nuw nsw i32 %17244, 4087" -> "  %18963 = and i32 %18962, 65535"
"  %18963 = and i32 %18962, 65535"
"  %18963 = and i32 %18962, 65535" -> "  %18964 = add nuw nsw i32 %18963, %18961"
"  %18964 = add nuw nsw i32 %18963, %18961"
"  %18964 = add nuw nsw i32 %18963, %18961" -> "  %18966 = add nuw nsw i32 %18964, %18965"
"  %18965 = and i32 %18962, 268369920"
"  %18965 = and i32 %18962, 268369920" -> "  %18966 = add nuw nsw i32 %18964, %18965"
"  %18966 = add nuw nsw i32 %18964, %18965"
"  %18966 = add nuw nsw i32 %18964, %18965" -> "  %18970 = lshr i32 %18966, 16""  %18966 = add nuw nsw i32 %18964, %18965" -> "  %18968 = and i32 %18966, 65535"
"  %18967 = mul nuw nsw i32 %17241, 11561"
"  %18967 = mul nuw nsw i32 %17241, 11561" -> "  %18969 = add nuw nsw i32 %18968, %18967"
"  %18968 = and i32 %18966, 65535"
"  %18968 = and i32 %18966, 65535" -> "  %18969 = add nuw nsw i32 %18968, %18967"
"  %18969 = add nuw nsw i32 %18968, %18967"
"  %18969 = add nuw nsw i32 %18968, %18967" -> "  %19090 = and i32 %18969, 65535""  %18969 = add nuw nsw i32 %18968, %18967" -> "  %18973 = lshr i32 %18969, 16"
"  %18970 = lshr i32 %18966, 16"
"  %18970 = lshr i32 %18966, 16" -> "  %18972 = add nuw nsw i32 %18970, %18971"
"  %18971 = mul nuw nsw i32 %17244, 11561"
"  %18971 = mul nuw nsw i32 %17244, 11561" -> "  %18972 = add nuw nsw i32 %18970, %18971"
"  %18972 = add nuw nsw i32 %18970, %18971"
"  %18972 = add nuw nsw i32 %18970, %18971" -> "  %18976 = and i32 %18972, 2147418112""  %18972 = add nuw nsw i32 %18970, %18971" -> "  %18974 = and i32 %18972, 65535"
"  %18973 = lshr i32 %18969, 16"
"  %18973 = lshr i32 %18969, 16" -> "  %18975 = add nuw nsw i32 %18973, %18974"
"  %18974 = and i32 %18972, 65535"
"  %18974 = and i32 %18972, 65535" -> "  %18975 = add nuw nsw i32 %18973, %18974"
"  %18975 = add nuw nsw i32 %18973, %18974"
"  %18975 = add nuw nsw i32 %18973, %18974" -> "  %18977 = add nuw nsw i32 %18975, %18976"
"  %18976 = and i32 %18972, 2147418112"
"  %18976 = and i32 %18972, 2147418112" -> "  %18977 = add nuw nsw i32 %18975, %18976"
"  %18977 = add nuw nsw i32 %18975, %18976"
"  %18977 = add nuw nsw i32 %18975, %18976" -> "  %19000 = lshr i32 %18977, 16""  %18977 = add nuw nsw i32 %18975, %18976" -> "  %18996 = and i32 %18977, 65535"
"  %18978 = mul nuw nsw i32 %17261, 4087"
"  %18978 = mul nuw nsw i32 %17261, 4087" -> "  %18997 = and i32 %18978, 65535""  %18978 = mul nuw nsw i32 %17261, 4087" -> "  %18979 = lshr i32 %18978, 16"
"  %18979 = lshr i32 %18978, 16"
"  %18979 = lshr i32 %18978, 16" -> "  %18982 = add nuw nsw i32 %18981, %18979"
"  %18980 = mul nuw nsw i32 %17264, 4087"
"  %18980 = mul nuw nsw i32 %17264, 4087" -> "  %18983 = and i32 %18980, 268369920""  %18980 = mul nuw nsw i32 %17264, 4087" -> "  %18981 = and i32 %18980, 65535"
"  %18981 = and i32 %18980, 65535"
"  %18981 = and i32 %18980, 65535" -> "  %18982 = add nuw nsw i32 %18981, %18979"
"  %18982 = add nuw nsw i32 %18981, %18979"
"  %18982 = add nuw nsw i32 %18981, %18979" -> "  %18984 = add nuw nsw i32 %18982, %18983"
"  %18983 = and i32 %18980, 268369920"
"  %18983 = and i32 %18980, 268369920" -> "  %18984 = add nuw nsw i32 %18982, %18983"
"  %18984 = add nuw nsw i32 %18982, %18983"
"  %18984 = add nuw nsw i32 %18982, %18983" -> "  %18988 = lshr i32 %18984, 16""  %18984 = add nuw nsw i32 %18982, %18983" -> "  %18986 = and i32 %18984, 65535"
"  %18985 = mul nuw nsw i32 %17261, 11561"
"  %18985 = mul nuw nsw i32 %17261, 11561" -> "  %18987 = add nuw nsw i32 %18986, %18985"
"  %18986 = and i32 %18984, 65535"
"  %18986 = and i32 %18984, 65535" -> "  %18987 = add nuw nsw i32 %18986, %18985"
"  %18987 = add nuw nsw i32 %18986, %18985"
"  %18987 = add nuw nsw i32 %18986, %18985" -> "  %18999 = and i32 %18987, 65535""  %18987 = add nuw nsw i32 %18986, %18985" -> "  %18991 = lshr i32 %18987, 16"
"  %18988 = lshr i32 %18984, 16"
"  %18988 = lshr i32 %18984, 16" -> "  %18990 = add nuw nsw i32 %18988, %18989"
"  %18989 = mul nuw nsw i32 %17264, 11561"
"  %18989 = mul nuw nsw i32 %17264, 11561" -> "  %18990 = add nuw nsw i32 %18988, %18989"
"  %18990 = add nuw nsw i32 %18988, %18989"
"  %18990 = add nuw nsw i32 %18988, %18989" -> "  %18994 = and i32 %18990, 2147418112""  %18990 = add nuw nsw i32 %18988, %18989" -> "  %18992 = and i32 %18990, 65535"
"  %18991 = lshr i32 %18987, 16"
"  %18991 = lshr i32 %18987, 16" -> "  %18993 = add nuw nsw i32 %18991, %18992"
"  %18992 = and i32 %18990, 65535"
"  %18992 = and i32 %18990, 65535" -> "  %18993 = add nuw nsw i32 %18991, %18992"
"  %18993 = add nuw nsw i32 %18991, %18992"
"  %18993 = add nuw nsw i32 %18991, %18992" -> "  %18995 = add nuw nsw i32 %18993, %18994"
"  %18994 = and i32 %18990, 2147418112"
"  %18994 = and i32 %18990, 2147418112" -> "  %18995 = add nuw nsw i32 %18993, %18994"
"  %18995 = add nuw nsw i32 %18993, %18994"
"  %18995 = add nuw nsw i32 %18993, %18994" -> "  %19003 = add nuw nsw i32 %18995, %19002"
"  %18996 = and i32 %18977, 65535"
"  %18996 = and i32 %18977, 65535" -> "  %18998 = add nuw nsw i32 %18996, %18997"
"  %18997 = and i32 %18978, 65535"
"  %18997 = and i32 %18978, 65535" -> "  %18998 = add nuw nsw i32 %18996, %18997"
"  %18998 = add nuw nsw i32 %18996, %18997"
"  %18998 = add nuw nsw i32 %18996, %18997" -> "  %19027 = and i32 %18998, 65535""  %18998 = add nuw nsw i32 %18996, %18997" -> "  %19005 = lshr i32 %18998, 16"
"  %18999 = and i32 %18987, 65535"
"  %18999 = and i32 %18987, 65535" -> "  %19001 = add nuw nsw i32 %18999, %19000"
"  %19000 = lshr i32 %18977, 16"
"  %19000 = lshr i32 %18977, 16" -> "  %19001 = add nuw nsw i32 %18999, %19000"
"  %19001 = add nuw nsw i32 %18999, %19000"
"  %19001 = add nuw nsw i32 %18999, %19000" -> "  %19004 = and i32 %19001, 65535""  %19001 = add nuw nsw i32 %18999, %19000" -> "  %19002 = lshr i32 %19001, 16"
"  %19002 = lshr i32 %19001, 16"
"  %19002 = lshr i32 %19001, 16" -> "  %19003 = add nuw nsw i32 %18995, %19002"
"  %19003 = add nuw nsw i32 %18995, %19002"
"  %19003 = add nuw nsw i32 %18995, %19002" -> "  %19008 = add nuw nsw i32 %19003, %19007"
"  %19004 = and i32 %19001, 65535"
"  %19004 = and i32 %19001, 65535" -> "  %19006 = add nuw nsw i32 %19004, %19005"
"  %19005 = lshr i32 %18998, 16"
"  %19005 = lshr i32 %18998, 16" -> "  %19006 = add nuw nsw i32 %19004, %19005"
"  %19006 = add nuw nsw i32 %19004, %19005"
"  %19006 = add nuw nsw i32 %19004, %19005" -> "  %19030 = and i32 %19006, 65535""  %19006 = add nuw nsw i32 %19004, %19005" -> "  %19007 = lshr i32 %19006, 16"
"  %19007 = lshr i32 %19006, 16"
"  %19007 = lshr i32 %19006, 16" -> "  %19008 = add nuw nsw i32 %19003, %19007"
"  %19008 = add nuw nsw i32 %19003, %19007"
"  %19008 = add nuw nsw i32 %19003, %19007" -> "  %19062 = lshr i32 %19008, 16""  %19008 = add nuw nsw i32 %19003, %19007" -> "  %19058 = and i32 %19008, 65535"
"  %19009 = mul nuw nsw i32 %17241, 21884"
"  %19009 = mul nuw nsw i32 %17241, 21884" -> "  %19028 = and i32 %19009, 65532""  %19009 = mul nuw nsw i32 %17241, 21884" -> "  %19010 = lshr i32 %19009, 16"
"  %19010 = lshr i32 %19009, 16"
"  %19010 = lshr i32 %19009, 16" -> "  %19013 = add nuw nsw i32 %19012, %19010"
"  %19011 = mul nuw nsw i32 %17244, 21884"
"  %19011 = mul nuw nsw i32 %17244, 21884" -> "  %19014 = and i32 %19011, 2147418112""  %19011 = mul nuw nsw i32 %17244, 21884" -> "  %19012 = and i32 %19011, 65532"
"  %19012 = and i32 %19011, 65532"
"  %19012 = and i32 %19011, 65532" -> "  %19013 = add nuw nsw i32 %19012, %19010"
"  %19013 = add nuw nsw i32 %19012, %19010"
"  %19013 = add nuw nsw i32 %19012, %19010" -> "  %19015 = add nuw nsw i32 %19013, %19014"
"  %19014 = and i32 %19011, 2147418112"
"  %19014 = and i32 %19011, 2147418112" -> "  %19015 = add nuw nsw i32 %19013, %19014"
"  %19015 = add nuw nsw i32 %19013, %19014"
"  %19015 = add nuw nsw i32 %19013, %19014" -> "  %19019 = lshr i32 %19015, 16""  %19015 = add nuw nsw i32 %19013, %19014" -> "  %19017 = and i32 %19015, 65535"
"  %19016 = mul nuw i32 %17241, 36786"
"  %19016 = mul nuw i32 %17241, 36786" -> "  %19018 = add nuw i32 %19017, %19016"
"  %19017 = and i32 %19015, 65535"
"  %19017 = and i32 %19015, 65535" -> "  %19018 = add nuw i32 %19017, %19016"
"  %19018 = add nuw i32 %19017, %19016"
"  %19018 = add nuw i32 %19017, %19016" -> "  %19031 = and i32 %19018, 65535""  %19018 = add nuw i32 %19017, %19016" -> "  %19022 = lshr i32 %19018, 16"
"  %19019 = lshr i32 %19015, 16"
"  %19019 = lshr i32 %19015, 16" -> "  %19021 = add nuw i32 %19019, %19020"
"  %19020 = mul nuw i32 %17244, 36786"
"  %19020 = mul nuw i32 %17244, 36786" -> "  %19021 = add nuw i32 %19019, %19020"
"  %19021 = add nuw i32 %19019, %19020"
"  %19021 = add nuw i32 %19019, %19020" -> "  %19025 = and i32 %19021, -65536""  %19021 = add nuw i32 %19019, %19020" -> "  %19023 = and i32 %19021, 65535"
"  %19022 = lshr i32 %19018, 16"
"  %19022 = lshr i32 %19018, 16" -> "  %19024 = add nuw nsw i32 %19022, %19023"
"  %19023 = and i32 %19021, 65535"
"  %19023 = and i32 %19021, 65535" -> "  %19024 = add nuw nsw i32 %19022, %19023"
"  %19024 = add nuw nsw i32 %19022, %19023"
"  %19024 = add nuw nsw i32 %19022, %19023" -> "  %19026 = add nuw i32 %19024, %19025"
"  %19025 = and i32 %19021, -65536"
"  %19025 = and i32 %19021, -65536" -> "  %19026 = add nuw i32 %19024, %19025"
"  %19026 = add nuw i32 %19024, %19025"
"  %19026 = add nuw i32 %19024, %19025" -> "  %19034 = add nuw i32 %19026, %19033"
"  %19027 = and i32 %18998, 65535"
"  %19027 = and i32 %18998, 65535" -> "  %19029 = add nuw nsw i32 %19027, %19028"
"  %19028 = and i32 %19009, 65532"
"  %19028 = and i32 %19009, 65532" -> "  %19029 = add nuw nsw i32 %19027, %19028"
"  %19029 = add nuw nsw i32 %19027, %19028"
"  %19029 = add nuw nsw i32 %19027, %19028" -> "  %19098 = and i32 %19029, 65535""  %19029 = add nuw nsw i32 %19027, %19028" -> "  %19036 = lshr i32 %19029, 16"
"  %19030 = and i32 %19006, 65535"
"  %19030 = and i32 %19006, 65535" -> "  %19032 = add nuw nsw i32 %19030, %19031"
"  %19031 = and i32 %19018, 65535"
"  %19031 = and i32 %19018, 65535" -> "  %19032 = add nuw nsw i32 %19030, %19031"
"  %19032 = add nuw nsw i32 %19030, %19031"
"  %19032 = add nuw nsw i32 %19030, %19031" -> "  %19035 = and i32 %19032, 65535""  %19032 = add nuw nsw i32 %19030, %19031" -> "  %19033 = lshr i32 %19032, 16"
"  %19033 = lshr i32 %19032, 16"
"  %19033 = lshr i32 %19032, 16" -> "  %19034 = add nuw i32 %19026, %19033"
"  %19034 = add nuw i32 %19026, %19033"
"  %19034 = add nuw i32 %19026, %19033" -> "  %19039 = add nuw i32 %19034, %19038"
"  %19035 = and i32 %19032, 65535"
"  %19035 = and i32 %19032, 65535" -> "  %19037 = add nuw nsw i32 %19035, %19036"
"  %19036 = lshr i32 %19029, 16"
"  %19036 = lshr i32 %19029, 16" -> "  %19037 = add nuw nsw i32 %19035, %19036"
"  %19037 = add nuw nsw i32 %19035, %19036"
"  %19037 = add nuw nsw i32 %19035, %19036" -> "  %19101 = and i32 %19037, 65535""  %19037 = add nuw nsw i32 %19035, %19036" -> "  %19038 = lshr i32 %19037, 16"
"  %19038 = lshr i32 %19037, 16"
"  %19038 = lshr i32 %19037, 16" -> "  %19039 = add nuw i32 %19034, %19038"
"  %19039 = add nuw i32 %19034, %19038"
"  %19039 = add nuw i32 %19034, %19038" -> "  %19075 = lshr i32 %19039, 16""  %19039 = add nuw i32 %19034, %19038" -> "  %19072 = and i32 %19039, 65535"
"  %19040 = mul nuw nsw i32 %17261, 21884"
"  %19040 = mul nuw nsw i32 %17261, 21884" -> "  %19059 = and i32 %19040, 65532""  %19040 = mul nuw nsw i32 %17261, 21884" -> "  %19041 = lshr i32 %19040, 16"
"  %19041 = lshr i32 %19040, 16"
"  %19041 = lshr i32 %19040, 16" -> "  %19044 = add nuw nsw i32 %19043, %19041"
"  %19042 = mul nuw nsw i32 %17264, 21884"
"  %19042 = mul nuw nsw i32 %17264, 21884" -> "  %19045 = and i32 %19042, 2147418112""  %19042 = mul nuw nsw i32 %17264, 21884" -> "  %19043 = and i32 %19042, 65532"
"  %19043 = and i32 %19042, 65532"
"  %19043 = and i32 %19042, 65532" -> "  %19044 = add nuw nsw i32 %19043, %19041"
"  %19044 = add nuw nsw i32 %19043, %19041"
"  %19044 = add nuw nsw i32 %19043, %19041" -> "  %19046 = add nuw nsw i32 %19044, %19045"
"  %19045 = and i32 %19042, 2147418112"
"  %19045 = and i32 %19042, 2147418112" -> "  %19046 = add nuw nsw i32 %19044, %19045"
"  %19046 = add nuw nsw i32 %19044, %19045"
"  %19046 = add nuw nsw i32 %19044, %19045" -> "  %19050 = lshr i32 %19046, 16""  %19046 = add nuw nsw i32 %19044, %19045" -> "  %19048 = and i32 %19046, 65535"
"  %19047 = mul nuw i32 %17261, 36786"
"  %19047 = mul nuw i32 %17261, 36786" -> "  %19049 = add nuw i32 %19048, %19047"
"  %19048 = and i32 %19046, 65535"
"  %19048 = and i32 %19046, 65535" -> "  %19049 = add nuw i32 %19048, %19047"
"  %19049 = add nuw i32 %19048, %19047"
"  %19049 = add nuw i32 %19048, %19047" -> "  %19061 = and i32 %19049, 65535""  %19049 = add nuw i32 %19048, %19047" -> "  %19053 = lshr i32 %19049, 16"
"  %19050 = lshr i32 %19046, 16"
"  %19050 = lshr i32 %19046, 16" -> "  %19052 = add nuw i32 %19050, %19051"
"  %19051 = mul nuw i32 %17264, 36786"
"  %19051 = mul nuw i32 %17264, 36786" -> "  %19052 = add nuw i32 %19050, %19051"
"  %19052 = add nuw i32 %19050, %19051"
"  %19052 = add nuw i32 %19050, %19051" -> "  %19056 = and i32 %19052, -65536""  %19052 = add nuw i32 %19050, %19051" -> "  %19054 = and i32 %19052, 65535"
"  %19053 = lshr i32 %19049, 16"
"  %19053 = lshr i32 %19049, 16" -> "  %19055 = add nuw nsw i32 %19053, %19054"
"  %19054 = and i32 %19052, 65535"
"  %19054 = and i32 %19052, 65535" -> "  %19055 = add nuw nsw i32 %19053, %19054"
"  %19055 = add nuw nsw i32 %19053, %19054"
"  %19055 = add nuw nsw i32 %19053, %19054" -> "  %19057 = add nuw i32 %19055, %19056"
"  %19056 = and i32 %19052, -65536"
"  %19056 = and i32 %19052, -65536" -> "  %19057 = add nuw i32 %19055, %19056"
"  %19057 = add nuw i32 %19055, %19056"
"  %19057 = add nuw i32 %19055, %19056" -> "  %19065 = add nuw i32 %19057, %19064"
"  %19058 = and i32 %19008, 65535"
"  %19058 = and i32 %19008, 65535" -> "  %19060 = add nuw nsw i32 %19058, %19059"
"  %19059 = and i32 %19040, 65532"
"  %19059 = and i32 %19040, 65532" -> "  %19060 = add nuw nsw i32 %19058, %19059"
"  %19060 = add nuw nsw i32 %19058, %19059"
"  %19060 = add nuw nsw i32 %19058, %19059" -> "  %19071 = and i32 %19060, 65535""  %19060 = add nuw nsw i32 %19058, %19059" -> "  %19067 = lshr i32 %19060, 16"
"  %19061 = and i32 %19049, 65535"
"  %19061 = and i32 %19049, 65535" -> "  %19063 = add nuw nsw i32 %19062, %19061"
"  %19062 = lshr i32 %19008, 16"
"  %19062 = lshr i32 %19008, 16" -> "  %19063 = add nuw nsw i32 %19062, %19061"
"  %19063 = add nuw nsw i32 %19062, %19061"
"  %19063 = add nuw nsw i32 %19062, %19061" -> "  %19066 = and i32 %19063, 65535""  %19063 = add nuw nsw i32 %19062, %19061" -> "  %19064 = lshr i32 %19063, 16"
"  %19064 = lshr i32 %19063, 16"
"  %19064 = lshr i32 %19063, 16" -> "  %19065 = add nuw i32 %19057, %19064"
"  %19065 = add nuw i32 %19057, %19064"
"  %19065 = add nuw i32 %19057, %19064" -> "  %19070 = add nuw i32 %19065, %19069"
"  %19066 = and i32 %19063, 65535"
"  %19066 = and i32 %19063, 65535" -> "  %19068 = add nuw nsw i32 %19067, %19066"
"  %19067 = lshr i32 %19060, 16"
"  %19067 = lshr i32 %19060, 16" -> "  %19068 = add nuw nsw i32 %19067, %19066"
"  %19068 = add nuw nsw i32 %19067, %19066"
"  %19068 = add nuw nsw i32 %19067, %19066" -> "  %19074 = and i32 %19068, 65535""  %19068 = add nuw nsw i32 %19067, %19066" -> "  %19069 = lshr i32 %19068, 16"
"  %19069 = lshr i32 %19068, 16"
"  %19069 = lshr i32 %19068, 16" -> "  %19070 = add nuw i32 %19065, %19069"
"  %19070 = add nuw i32 %19065, %19069"
"  %19070 = add nuw i32 %19065, %19069" -> "  %19083 = and i32 %19070, -65536""  %19070 = add nuw i32 %19065, %19069" -> "  %19081 = and i32 %19070, 65535"
"  %19071 = and i32 %19060, 65535"
"  %19071 = and i32 %19060, 65535" -> "  %19073 = add nuw nsw i32 %19072, %19071"
"  %19072 = and i32 %19039, 65535"
"  %19072 = and i32 %19039, 65535" -> "  %19073 = add nuw nsw i32 %19072, %19071"
"  %19073 = add nuw nsw i32 %19072, %19071"
"  %19073 = add nuw nsw i32 %19072, %19071" -> "  %19113 = and i32 %19073, 65535""  %19073 = add nuw nsw i32 %19072, %19071" -> "  %19077 = lshr i32 %19073, 16"
"  %19074 = and i32 %19068, 65535"
"  %19074 = and i32 %19068, 65535" -> "  %19076 = add nuw nsw i32 %19075, %19074"
"  %19075 = lshr i32 %19039, 16"
"  %19075 = lshr i32 %19039, 16" -> "  %19076 = add nuw nsw i32 %19075, %19074"
"  %19076 = add nuw nsw i32 %19075, %19074"
"  %19076 = add nuw nsw i32 %19075, %19074" -> "  %19080 = lshr i32 %19076, 16""  %19076 = add nuw nsw i32 %19075, %19074" -> "  %19078 = and i32 %19076, 65535"
"  %19077 = lshr i32 %19073, 16"
"  %19077 = lshr i32 %19073, 16" -> "  %19079 = add nuw nsw i32 %19077, %19078"
"  %19078 = and i32 %19076, 65535"
"  %19078 = and i32 %19076, 65535" -> "  %19079 = add nuw nsw i32 %19077, %19078"
"  %19079 = add nuw nsw i32 %19077, %19078"
"  %19079 = add nuw nsw i32 %19077, %19078" -> "  %19121 = and i32 %19079, 65535""  %19079 = add nuw nsw i32 %19077, %19078" -> "  %19085 = lshr i32 %19079, 16"
"  %19080 = lshr i32 %19076, 16"
"  %19080 = lshr i32 %19076, 16" -> "  %19082 = add nuw nsw i32 %19080, %19081"
"  %19081 = and i32 %19070, 65535"
"  %19081 = and i32 %19070, 65535" -> "  %19082 = add nuw nsw i32 %19080, %19081"
"  %19082 = add nuw nsw i32 %19080, %19081"
"  %19082 = add nuw nsw i32 %19080, %19081" -> "  %19084 = add nuw i32 %19082, %19083"
"  %19083 = and i32 %19070, -65536"
"  %19083 = and i32 %19070, -65536" -> "  %19084 = add nuw i32 %19082, %19083"
"  %19084 = add nuw i32 %19082, %19083"
"  %19084 = add nuw i32 %19082, %19083" -> "  %19086 = add nuw i32 %19084, %19085"
"  %19085 = lshr i32 %19079, 16"
"  %19085 = lshr i32 %19079, 16" -> "  %19086 = add nuw i32 %19084, %19085"
"  %19086 = add nuw i32 %19084, %19085"
"  %19086 = add nuw i32 %19084, %19085" -> "  %19124 = add nuw i32 %19086, %19123"
"  %19087 = and i32 %18960, 65535"
"  %19087 = and i32 %18960, 65535" -> "  %19089 = add nuw nsw i32 %19088, %19087"
"  %19088 = and i32 %18924, 65535"
"  %19088 = and i32 %18924, 65535" -> "  %19089 = add nuw nsw i32 %19088, %19087"
"  %19089 = add nuw nsw i32 %19088, %19087"
"  %19089 = add nuw nsw i32 %19088, %19087" -> "  %19355 = and i32 %19089, 65535""  %19089 = add nuw nsw i32 %19088, %19087" -> "  %19093 = lshr i32 %19089, 16""  %19089 = add nuw nsw i32 %19088, %19087" -> "  store i32 %19089, i32* %2018, align 1, !noalias !53"
"  store i32 %19089, i32* %2018, align 1, !noalias !53"

"  %19090 = and i32 %18969, 65535"
"  %19090 = and i32 %18969, 65535" -> "  %19092 = add nuw nsw i32 %19091, %19090"
"  %19091 = and i32 %18930, 65535"
"  %19091 = and i32 %18930, 65535" -> "  %19092 = add nuw nsw i32 %19091, %19090"
"  %19092 = add nuw nsw i32 %19091, %19090"
"  %19092 = add nuw nsw i32 %19091, %19090" -> "  %19096 = lshr i32 %19092, 16""  %19092 = add nuw nsw i32 %19091, %19090" -> "  %19094 = and i32 %19092, 65535"
"  %19093 = lshr i32 %19089, 16"
"  %19093 = lshr i32 %19089, 16" -> "  %19095 = add nuw nsw i32 %19094, %19093"
"  %19094 = and i32 %19092, 65535"
"  %19094 = and i32 %19092, 65535" -> "  %19095 = add nuw nsw i32 %19094, %19093"
"  %19095 = add nuw nsw i32 %19094, %19093"
"  %19095 = add nuw nsw i32 %19094, %19093" -> "  %19358 = and i32 %19095, 65535""  %19095 = add nuw nsw i32 %19094, %19093" -> "  %19097 = lshr i32 %19095, 16"
"  %19096 = lshr i32 %19092, 16"
"  %19096 = lshr i32 %19092, 16" -> "  %19108 = add nuw nsw i32 %19097, %19096"
"  %19097 = lshr i32 %19095, 16"
"  %19097 = lshr i32 %19095, 16" -> "  %19108 = add nuw nsw i32 %19097, %19096"
"  %19098 = and i32 %19029, 65535"
"  %19098 = and i32 %19029, 65535" -> "  %19100 = add nuw nsw i32 %19099, %19098"
"  %19099 = and i32 %18944, 65535"
"  %19099 = and i32 %18944, 65535" -> "  %19100 = add nuw nsw i32 %19099, %19098"
"  %19100 = add nuw nsw i32 %19099, %19098"
"  %19100 = add nuw nsw i32 %19099, %19098" -> "  %19107 = and i32 %19100, 65535""  %19100 = add nuw nsw i32 %19099, %19098" -> "  %19104 = lshr i32 %19100, 16"
"  %19101 = and i32 %19037, 65535"
"  %19101 = and i32 %19037, 65535" -> "  %19103 = add nuw nsw i32 %19102, %19101"
"  %19102 = and i32 %18947, 65535"
"  %19102 = and i32 %18947, 65535" -> "  %19103 = add nuw nsw i32 %19102, %19101"
"  %19103 = add nuw nsw i32 %19102, %19101"
"  %19103 = add nuw nsw i32 %19102, %19101" -> "  %19114 = lshr i32 %19103, 16""  %19103 = add nuw nsw i32 %19102, %19101" -> "  %19105 = and i32 %19103, 65535"
"  %19104 = lshr i32 %19100, 16"
"  %19104 = lshr i32 %19100, 16" -> "  %19106 = add nuw nsw i32 %19105, %19104"
"  %19105 = and i32 %19103, 65535"
"  %19105 = and i32 %19103, 65535" -> "  %19106 = add nuw nsw i32 %19105, %19104"
"  %19106 = add nuw nsw i32 %19105, %19104"
"  %19106 = add nuw nsw i32 %19105, %19104" -> "  %19116 = lshr i32 %19106, 16""  %19106 = add nuw nsw i32 %19105, %19104" -> "  %19111 = and i32 %19106, 65535"
"  %19107 = and i32 %19100, 65535"
"  %19107 = and i32 %19100, 65535" -> "  %19109 = add nuw nsw i32 %19108, %19107"
"  %19108 = add nuw nsw i32 %19097, %19096"
"  %19108 = add nuw nsw i32 %19097, %19096" -> "  %19109 = add nuw nsw i32 %19108, %19107"
"  %19109 = add nuw nsw i32 %19108, %19107"
"  %19109 = add nuw nsw i32 %19108, %19107" -> "  %19367 = and i32 %19109, 65535""  %19109 = add nuw nsw i32 %19108, %19107" -> "  %19110 = lshr i32 %19109, 16""  %19109 = add nuw nsw i32 %19108, %19107" -> "  store i32 %19109, i32* %2054, align 1, !noalias !53"
"  store i32 %19109, i32* %2054, align 1, !noalias !53"

"  %19110 = lshr i32 %19109, 16"
"  %19110 = lshr i32 %19109, 16" -> "  %19112 = add nuw nsw i32 %19111, %19110"
"  %19111 = and i32 %19106, 65535"
"  %19111 = and i32 %19106, 65535" -> "  %19112 = add nuw nsw i32 %19111, %19110"
"  %19112 = add nuw nsw i32 %19111, %19110"
"  %19112 = add nuw nsw i32 %19111, %19110" -> "  %19370 = and i32 %19112, 65535""  %19112 = add nuw nsw i32 %19111, %19110" -> "  %19118 = lshr i32 %19112, 16""  %19112 = add nuw nsw i32 %19111, %19110" -> "  store i32 %19112, i32* %2203, align 1, !noalias !53"
"  store i32 %19112, i32* %2203, align 1, !noalias !53"

"  %19113 = and i32 %19073, 65535"
"  %19113 = and i32 %19073, 65535" -> "  %19115 = add nuw nsw i32 %19114, %19113"
"  %19114 = lshr i32 %19103, 16"
"  %19114 = lshr i32 %19103, 16" -> "  %19115 = add nuw nsw i32 %19114, %19113"
"  %19115 = add nuw nsw i32 %19114, %19113"
"  %19115 = add nuw nsw i32 %19114, %19113" -> "  %19117 = add nuw nsw i32 %19115, %19116"
"  %19116 = lshr i32 %19106, 16"
"  %19116 = lshr i32 %19106, 16" -> "  %19117 = add nuw nsw i32 %19115, %19116"
"  %19117 = add nuw nsw i32 %19115, %19116"
"  %19117 = add nuw nsw i32 %19115, %19116" -> "  %19119 = add nuw nsw i32 %19117, %19118"
"  %19118 = lshr i32 %19112, 16"
"  %19118 = lshr i32 %19112, 16" -> "  %19119 = add nuw nsw i32 %19117, %19118"
"  %19119 = add nuw nsw i32 %19117, %19118"
"  %19119 = add nuw nsw i32 %19117, %19118" -> "  %19291 = and i32 %19119, 65535""  %19119 = add nuw nsw i32 %19117, %19118" -> "  %19120 = lshr i32 %19119, 16"
"  %19120 = lshr i32 %19119, 16"
"  %19120 = lshr i32 %19119, 16" -> "  %19122 = add nuw nsw i32 %19120, %19121"
"  %19121 = and i32 %19079, 65535"
"  %19121 = and i32 %19079, 65535" -> "  %19122 = add nuw nsw i32 %19120, %19121"
"  %19122 = add nuw nsw i32 %19120, %19121"
"  %19122 = add nuw nsw i32 %19120, %19121" -> "  %19294 = and i32 %19122, 65535""  %19122 = add nuw nsw i32 %19120, %19121" -> "  %19123 = lshr i32 %19122, 16"
"  %19123 = lshr i32 %19122, 16"
"  %19123 = lshr i32 %19122, 16" -> "  %19124 = add nuw i32 %19086, %19123"
"  %19124 = add nuw i32 %19086, %19123"
"  %19124 = add nuw i32 %19086, %19123" -> "  %19299 = and i32 %19124, 65535""  %19124 = add nuw i32 %19086, %19123" -> "  %19302 = lshr i32 %19124, 16""  %19124 = add nuw i32 %19086, %19123" -> "  store i32 %19124, i32* %2209, align 1, !noalias !56"
"  store i32 %19124, i32* %2209, align 1, !noalias !56"

"  %19125 = mul nuw nsw i32 %17375, 4087"
"  %19125 = mul nuw nsw i32 %17375, 4087" -> "  %19252 = and i32 %19125, 65535""  %19125 = mul nuw nsw i32 %17375, 4087" -> "  %19126 = lshr i32 %19125, 16""  %19125 = mul nuw nsw i32 %17375, 4087" -> "  store i32 %19125, i32* %2389, align 1, !noalias !56"
"  store i32 %19125, i32* %2389, align 1, !noalias !56"

"  %19126 = lshr i32 %19125, 16"
"  %19126 = lshr i32 %19125, 16" -> "  %19129 = add nuw nsw i32 %19128, %19126"
"  %19127 = mul nuw nsw i32 %17376, 4087"
"  %19127 = mul nuw nsw i32 %17376, 4087" -> "  %19130 = and i32 %19127, 268369920""  %19127 = mul nuw nsw i32 %17376, 4087" -> "  %19128 = and i32 %19127, 65535"
"  %19128 = and i32 %19127, 65535"
"  %19128 = and i32 %19127, 65535" -> "  %19129 = add nuw nsw i32 %19128, %19126"
"  %19129 = add nuw nsw i32 %19128, %19126"
"  %19129 = add nuw nsw i32 %19128, %19126" -> "  %19131 = add nuw nsw i32 %19129, %19130"
"  %19130 = and i32 %19127, 268369920"
"  %19130 = and i32 %19127, 268369920" -> "  %19131 = add nuw nsw i32 %19129, %19130"
"  %19131 = add nuw nsw i32 %19129, %19130"
"  %19131 = add nuw nsw i32 %19129, %19130" -> "  %19135 = lshr i32 %19131, 16""  %19131 = add nuw nsw i32 %19129, %19130" -> "  %19133 = and i32 %19131, 65535"
"  %19132 = mul nuw nsw i32 %17375, 11561"
"  %19132 = mul nuw nsw i32 %17375, 11561" -> "  %19134 = add nuw nsw i32 %19133, %19132"
"  %19133 = and i32 %19131, 65535"
"  %19133 = and i32 %19131, 65535" -> "  %19134 = add nuw nsw i32 %19133, %19132"
"  %19134 = add nuw nsw i32 %19133, %19132"
"  %19134 = add nuw nsw i32 %19133, %19132" -> "  %19255 = and i32 %19134, 65535""  %19134 = add nuw nsw i32 %19133, %19132" -> "  %19138 = lshr i32 %19134, 16"
"  %19135 = lshr i32 %19131, 16"
"  %19135 = lshr i32 %19131, 16" -> "  %19137 = add nuw nsw i32 %19135, %19136"
"  %19136 = mul nuw nsw i32 %17376, 11561"
"  %19136 = mul nuw nsw i32 %17376, 11561" -> "  %19137 = add nuw nsw i32 %19135, %19136"
"  %19137 = add nuw nsw i32 %19135, %19136"
"  %19137 = add nuw nsw i32 %19135, %19136" -> "  %19141 = and i32 %19137, 2147418112""  %19137 = add nuw nsw i32 %19135, %19136" -> "  %19139 = and i32 %19137, 65535"
"  %19138 = lshr i32 %19134, 16"
"  %19138 = lshr i32 %19134, 16" -> "  %19140 = add nuw nsw i32 %19138, %19139"
"  %19139 = and i32 %19137, 65535"
"  %19139 = and i32 %19137, 65535" -> "  %19140 = add nuw nsw i32 %19138, %19139"
"  %19140 = add nuw nsw i32 %19138, %19139"
"  %19140 = add nuw nsw i32 %19138, %19139" -> "  %19142 = add nuw nsw i32 %19140, %19141"
"  %19141 = and i32 %19137, 2147418112"
"  %19141 = and i32 %19137, 2147418112" -> "  %19142 = add nuw nsw i32 %19140, %19141"
"  %19142 = add nuw nsw i32 %19140, %19141"
"  %19142 = add nuw nsw i32 %19140, %19141" -> "  %19165 = lshr i32 %19142, 16""  %19142 = add nuw nsw i32 %19140, %19141" -> "  %19161 = and i32 %19142, 65535"
"  %19143 = mul nuw nsw i32 %17395, 4087"
"  %19143 = mul nuw nsw i32 %17395, 4087" -> "  %19162 = and i32 %19143, 65535""  %19143 = mul nuw nsw i32 %17395, 4087" -> "  %19144 = lshr i32 %19143, 16"
"  %19144 = lshr i32 %19143, 16"
"  %19144 = lshr i32 %19143, 16" -> "  %19147 = add nuw nsw i32 %19146, %19144"
"  %19145 = mul nuw nsw i32 %17398, 4087"
"  %19145 = mul nuw nsw i32 %17398, 4087" -> "  %19148 = and i32 %19145, 268369920""  %19145 = mul nuw nsw i32 %17398, 4087" -> "  %19146 = and i32 %19145, 65535"
"  %19146 = and i32 %19145, 65535"
"  %19146 = and i32 %19145, 65535" -> "  %19147 = add nuw nsw i32 %19146, %19144"
"  %19147 = add nuw nsw i32 %19146, %19144"
"  %19147 = add nuw nsw i32 %19146, %19144" -> "  %19149 = add nuw nsw i32 %19147, %19148"
"  %19148 = and i32 %19145, 268369920"
"  %19148 = and i32 %19145, 268369920" -> "  %19149 = add nuw nsw i32 %19147, %19148"
"  %19149 = add nuw nsw i32 %19147, %19148"
"  %19149 = add nuw nsw i32 %19147, %19148" -> "  %19153 = lshr i32 %19149, 16""  %19149 = add nuw nsw i32 %19147, %19148" -> "  %19151 = and i32 %19149, 65535"
"  %19150 = mul nuw nsw i32 %17395, 11561"
"  %19150 = mul nuw nsw i32 %17395, 11561" -> "  %19152 = add nuw nsw i32 %19151, %19150"
"  %19151 = and i32 %19149, 65535"
"  %19151 = and i32 %19149, 65535" -> "  %19152 = add nuw nsw i32 %19151, %19150"
"  %19152 = add nuw nsw i32 %19151, %19150"
"  %19152 = add nuw nsw i32 %19151, %19150" -> "  %19164 = and i32 %19152, 65535""  %19152 = add nuw nsw i32 %19151, %19150" -> "  %19156 = lshr i32 %19152, 16"
"  %19153 = lshr i32 %19149, 16"
"  %19153 = lshr i32 %19149, 16" -> "  %19155 = add nuw nsw i32 %19153, %19154"
"  %19154 = mul nuw nsw i32 %17398, 11561"
"  %19154 = mul nuw nsw i32 %17398, 11561" -> "  %19155 = add nuw nsw i32 %19153, %19154"
"  %19155 = add nuw nsw i32 %19153, %19154"
"  %19155 = add nuw nsw i32 %19153, %19154" -> "  %19159 = and i32 %19155, 2147418112""  %19155 = add nuw nsw i32 %19153, %19154" -> "  %19157 = and i32 %19155, 65535"
"  %19156 = lshr i32 %19152, 16"
"  %19156 = lshr i32 %19152, 16" -> "  %19158 = add nuw nsw i32 %19156, %19157"
"  %19157 = and i32 %19155, 65535"
"  %19157 = and i32 %19155, 65535" -> "  %19158 = add nuw nsw i32 %19156, %19157"
"  %19158 = add nuw nsw i32 %19156, %19157"
"  %19158 = add nuw nsw i32 %19156, %19157" -> "  %19160 = add nuw nsw i32 %19158, %19159"
"  %19159 = and i32 %19155, 2147418112"
"  %19159 = and i32 %19155, 2147418112" -> "  %19160 = add nuw nsw i32 %19158, %19159"
"  %19160 = add nuw nsw i32 %19158, %19159"
"  %19160 = add nuw nsw i32 %19158, %19159" -> "  %19168 = add nuw nsw i32 %19160, %19167"
"  %19161 = and i32 %19142, 65535"
"  %19161 = and i32 %19142, 65535" -> "  %19163 = add nuw nsw i32 %19161, %19162"
"  %19162 = and i32 %19143, 65535"
"  %19162 = and i32 %19143, 65535" -> "  %19163 = add nuw nsw i32 %19161, %19162"
"  %19163 = add nuw nsw i32 %19161, %19162"
"  %19163 = add nuw nsw i32 %19161, %19162" -> "  %19192 = and i32 %19163, 65535""  %19163 = add nuw nsw i32 %19161, %19162" -> "  %19170 = lshr i32 %19163, 16"
"  %19164 = and i32 %19152, 65535"
"  %19164 = and i32 %19152, 65535" -> "  %19166 = add nuw nsw i32 %19164, %19165"
"  %19165 = lshr i32 %19142, 16"
"  %19165 = lshr i32 %19142, 16" -> "  %19166 = add nuw nsw i32 %19164, %19165"
"  %19166 = add nuw nsw i32 %19164, %19165"
"  %19166 = add nuw nsw i32 %19164, %19165" -> "  %19169 = and i32 %19166, 65535""  %19166 = add nuw nsw i32 %19164, %19165" -> "  %19167 = lshr i32 %19166, 16"
"  %19167 = lshr i32 %19166, 16"
"  %19167 = lshr i32 %19166, 16" -> "  %19168 = add nuw nsw i32 %19160, %19167"
"  %19168 = add nuw nsw i32 %19160, %19167"
"  %19168 = add nuw nsw i32 %19160, %19167" -> "  %19173 = add nuw nsw i32 %19168, %19172"
"  %19169 = and i32 %19166, 65535"
"  %19169 = and i32 %19166, 65535" -> "  %19171 = add nuw nsw i32 %19169, %19170"
"  %19170 = lshr i32 %19163, 16"
"  %19170 = lshr i32 %19163, 16" -> "  %19171 = add nuw nsw i32 %19169, %19170"
"  %19171 = add nuw nsw i32 %19169, %19170"
"  %19171 = add nuw nsw i32 %19169, %19170" -> "  %19195 = and i32 %19171, 65535""  %19171 = add nuw nsw i32 %19169, %19170" -> "  %19172 = lshr i32 %19171, 16"
"  %19172 = lshr i32 %19171, 16"
"  %19172 = lshr i32 %19171, 16" -> "  %19173 = add nuw nsw i32 %19168, %19172"
"  %19173 = add nuw nsw i32 %19168, %19172"
"  %19173 = add nuw nsw i32 %19168, %19172" -> "  %19227 = lshr i32 %19173, 16""  %19173 = add nuw nsw i32 %19168, %19172" -> "  %19223 = and i32 %19173, 65535"
"  %19174 = mul nuw nsw i32 %17375, 21884"
"  %19174 = mul nuw nsw i32 %17375, 21884" -> "  %19193 = and i32 %19174, 65532""  %19174 = mul nuw nsw i32 %17375, 21884" -> "  %19175 = lshr i32 %19174, 16"
"  %19175 = lshr i32 %19174, 16"
"  %19175 = lshr i32 %19174, 16" -> "  %19178 = add nuw nsw i32 %19177, %19175"
"  %19176 = mul nuw nsw i32 %17376, 21884"
"  %19176 = mul nuw nsw i32 %17376, 21884" -> "  %19179 = and i32 %19176, 2147418112""  %19176 = mul nuw nsw i32 %17376, 21884" -> "  %19177 = and i32 %19176, 65532"
"  %19177 = and i32 %19176, 65532"
"  %19177 = and i32 %19176, 65532" -> "  %19178 = add nuw nsw i32 %19177, %19175"
"  %19178 = add nuw nsw i32 %19177, %19175"
"  %19178 = add nuw nsw i32 %19177, %19175" -> "  %19180 = add nuw nsw i32 %19178, %19179"
"  %19179 = and i32 %19176, 2147418112"
"  %19179 = and i32 %19176, 2147418112" -> "  %19180 = add nuw nsw i32 %19178, %19179"
"  %19180 = add nuw nsw i32 %19178, %19179"
"  %19180 = add nuw nsw i32 %19178, %19179" -> "  %19184 = lshr i32 %19180, 16""  %19180 = add nuw nsw i32 %19178, %19179" -> "  %19182 = and i32 %19180, 65535"
"  %19181 = mul nuw i32 %17375, 36786"
"  %19181 = mul nuw i32 %17375, 36786" -> "  %19183 = add nuw i32 %19182, %19181"
"  %19182 = and i32 %19180, 65535"
"  %19182 = and i32 %19180, 65535" -> "  %19183 = add nuw i32 %19182, %19181"
"  %19183 = add nuw i32 %19182, %19181"
"  %19183 = add nuw i32 %19182, %19181" -> "  %19196 = and i32 %19183, 65535""  %19183 = add nuw i32 %19182, %19181" -> "  %19187 = lshr i32 %19183, 16"
"  %19184 = lshr i32 %19180, 16"
"  %19184 = lshr i32 %19180, 16" -> "  %19186 = add nuw i32 %19184, %19185"
"  %19185 = mul nuw i32 %17376, 36786"
"  %19185 = mul nuw i32 %17376, 36786" -> "  %19186 = add nuw i32 %19184, %19185"
"  %19186 = add nuw i32 %19184, %19185"
"  %19186 = add nuw i32 %19184, %19185" -> "  %19190 = and i32 %19186, -65536""  %19186 = add nuw i32 %19184, %19185" -> "  %19188 = and i32 %19186, 65535"
"  %19187 = lshr i32 %19183, 16"
"  %19187 = lshr i32 %19183, 16" -> "  %19189 = add nuw nsw i32 %19187, %19188"
"  %19188 = and i32 %19186, 65535"
"  %19188 = and i32 %19186, 65535" -> "  %19189 = add nuw nsw i32 %19187, %19188"
"  %19189 = add nuw nsw i32 %19187, %19188"
"  %19189 = add nuw nsw i32 %19187, %19188" -> "  %19191 = add nuw i32 %19189, %19190"
"  %19190 = and i32 %19186, -65536"
"  %19190 = and i32 %19186, -65536" -> "  %19191 = add nuw i32 %19189, %19190"
"  %19191 = add nuw i32 %19189, %19190"
"  %19191 = add nuw i32 %19189, %19190" -> "  %19199 = add nuw i32 %19191, %19198"
"  %19192 = and i32 %19163, 65535"
"  %19192 = and i32 %19163, 65535" -> "  %19194 = add nuw nsw i32 %19192, %19193"
"  %19193 = and i32 %19174, 65532"
"  %19193 = and i32 %19174, 65532" -> "  %19194 = add nuw nsw i32 %19192, %19193"
"  %19194 = add nuw nsw i32 %19192, %19193"
"  %19194 = add nuw nsw i32 %19192, %19193" -> "  %19261 = and i32 %19194, 65535""  %19194 = add nuw nsw i32 %19192, %19193" -> "  %19201 = lshr i32 %19194, 16"
"  %19195 = and i32 %19171, 65535"
"  %19195 = and i32 %19171, 65535" -> "  %19197 = add nuw nsw i32 %19195, %19196"
"  %19196 = and i32 %19183, 65535"
"  %19196 = and i32 %19183, 65535" -> "  %19197 = add nuw nsw i32 %19195, %19196"
"  %19197 = add nuw nsw i32 %19195, %19196"
"  %19197 = add nuw nsw i32 %19195, %19196" -> "  %19200 = and i32 %19197, 65535""  %19197 = add nuw nsw i32 %19195, %19196" -> "  %19198 = lshr i32 %19197, 16"
"  %19198 = lshr i32 %19197, 16"
"  %19198 = lshr i32 %19197, 16" -> "  %19199 = add nuw i32 %19191, %19198"
"  %19199 = add nuw i32 %19191, %19198"
"  %19199 = add nuw i32 %19191, %19198" -> "  %19204 = add nuw i32 %19199, %19203"
"  %19200 = and i32 %19197, 65535"
"  %19200 = and i32 %19197, 65535" -> "  %19202 = add nuw nsw i32 %19200, %19201"
"  %19201 = lshr i32 %19194, 16"
"  %19201 = lshr i32 %19194, 16" -> "  %19202 = add nuw nsw i32 %19200, %19201"
"  %19202 = add nuw nsw i32 %19200, %19201"
"  %19202 = add nuw nsw i32 %19200, %19201" -> "  %19264 = and i32 %19202, 65535""  %19202 = add nuw nsw i32 %19200, %19201" -> "  %19203 = lshr i32 %19202, 16"
"  %19203 = lshr i32 %19202, 16"
"  %19203 = lshr i32 %19202, 16" -> "  %19204 = add nuw i32 %19199, %19203"
"  %19204 = add nuw i32 %19199, %19203"
"  %19204 = add nuw i32 %19199, %19203" -> "  %19240 = lshr i32 %19204, 16""  %19204 = add nuw i32 %19199, %19203" -> "  %19237 = and i32 %19204, 65535"
"  %19205 = mul nuw nsw i32 %17395, 21884"
"  %19205 = mul nuw nsw i32 %17395, 21884" -> "  %19224 = and i32 %19205, 65532""  %19205 = mul nuw nsw i32 %17395, 21884" -> "  %19206 = lshr i32 %19205, 16"
"  %19206 = lshr i32 %19205, 16"
"  %19206 = lshr i32 %19205, 16" -> "  %19209 = add nuw nsw i32 %19208, %19206"
"  %19207 = mul nuw nsw i32 %17398, 21884"
"  %19207 = mul nuw nsw i32 %17398, 21884" -> "  %19210 = and i32 %19207, 2147418112""  %19207 = mul nuw nsw i32 %17398, 21884" -> "  %19208 = and i32 %19207, 65532"
"  %19208 = and i32 %19207, 65532"
"  %19208 = and i32 %19207, 65532" -> "  %19209 = add nuw nsw i32 %19208, %19206"
"  %19209 = add nuw nsw i32 %19208, %19206"
"  %19209 = add nuw nsw i32 %19208, %19206" -> "  %19211 = add nuw nsw i32 %19209, %19210"
"  %19210 = and i32 %19207, 2147418112"
"  %19210 = and i32 %19207, 2147418112" -> "  %19211 = add nuw nsw i32 %19209, %19210"
"  %19211 = add nuw nsw i32 %19209, %19210"
"  %19211 = add nuw nsw i32 %19209, %19210" -> "  %19215 = lshr i32 %19211, 16""  %19211 = add nuw nsw i32 %19209, %19210" -> "  %19213 = and i32 %19211, 65535"
"  %19212 = mul nuw i32 %17395, 36786"
"  %19212 = mul nuw i32 %17395, 36786" -> "  %19214 = add nuw i32 %19213, %19212"
"  %19213 = and i32 %19211, 65535"
"  %19213 = and i32 %19211, 65535" -> "  %19214 = add nuw i32 %19213, %19212"
"  %19214 = add nuw i32 %19213, %19212"
"  %19214 = add nuw i32 %19213, %19212" -> "  %19226 = and i32 %19214, 65535""  %19214 = add nuw i32 %19213, %19212" -> "  %19218 = lshr i32 %19214, 16"
"  %19215 = lshr i32 %19211, 16"
"  %19215 = lshr i32 %19211, 16" -> "  %19217 = add nuw i32 %19215, %19216"
"  %19216 = mul nuw i32 %17398, 36786"
"  %19216 = mul nuw i32 %17398, 36786" -> "  %19217 = add nuw i32 %19215, %19216"
"  %19217 = add nuw i32 %19215, %19216"
"  %19217 = add nuw i32 %19215, %19216" -> "  %19221 = and i32 %19217, -65536""  %19217 = add nuw i32 %19215, %19216" -> "  %19219 = and i32 %19217, 65535"
"  %19218 = lshr i32 %19214, 16"
"  %19218 = lshr i32 %19214, 16" -> "  %19220 = add nuw nsw i32 %19218, %19219"
"  %19219 = and i32 %19217, 65535"
"  %19219 = and i32 %19217, 65535" -> "  %19220 = add nuw nsw i32 %19218, %19219"
"  %19220 = add nuw nsw i32 %19218, %19219"
"  %19220 = add nuw nsw i32 %19218, %19219" -> "  %19222 = add nuw i32 %19220, %19221"
"  %19221 = and i32 %19217, -65536"
"  %19221 = and i32 %19217, -65536" -> "  %19222 = add nuw i32 %19220, %19221"
"  %19222 = add nuw i32 %19220, %19221"
"  %19222 = add nuw i32 %19220, %19221" -> "  %19230 = add nuw i32 %19222, %19229"
"  %19223 = and i32 %19173, 65535"
"  %19223 = and i32 %19173, 65535" -> "  %19225 = add nuw nsw i32 %19223, %19224"
"  %19224 = and i32 %19205, 65532"
"  %19224 = and i32 %19205, 65532" -> "  %19225 = add nuw nsw i32 %19223, %19224"
"  %19225 = add nuw nsw i32 %19223, %19224"
"  %19225 = add nuw nsw i32 %19223, %19224" -> "  %19236 = and i32 %19225, 65535""  %19225 = add nuw nsw i32 %19223, %19224" -> "  %19232 = lshr i32 %19225, 16"
"  %19226 = and i32 %19214, 65535"
"  %19226 = and i32 %19214, 65535" -> "  %19228 = add nuw nsw i32 %19227, %19226"
"  %19227 = lshr i32 %19173, 16"
"  %19227 = lshr i32 %19173, 16" -> "  %19228 = add nuw nsw i32 %19227, %19226"
"  %19228 = add nuw nsw i32 %19227, %19226"
"  %19228 = add nuw nsw i32 %19227, %19226" -> "  %19231 = and i32 %19228, 65535""  %19228 = add nuw nsw i32 %19227, %19226" -> "  %19229 = lshr i32 %19228, 16"
"  %19229 = lshr i32 %19228, 16"
"  %19229 = lshr i32 %19228, 16" -> "  %19230 = add nuw i32 %19222, %19229"
"  %19230 = add nuw i32 %19222, %19229"
"  %19230 = add nuw i32 %19222, %19229" -> "  %19235 = add nuw i32 %19230, %19234"
"  %19231 = and i32 %19228, 65535"
"  %19231 = and i32 %19228, 65535" -> "  %19233 = add nuw nsw i32 %19232, %19231"
"  %19232 = lshr i32 %19225, 16"
"  %19232 = lshr i32 %19225, 16" -> "  %19233 = add nuw nsw i32 %19232, %19231"
"  %19233 = add nuw nsw i32 %19232, %19231"
"  %19233 = add nuw nsw i32 %19232, %19231" -> "  %19239 = and i32 %19233, 65535""  %19233 = add nuw nsw i32 %19232, %19231" -> "  %19234 = lshr i32 %19233, 16"
"  %19234 = lshr i32 %19233, 16"
"  %19234 = lshr i32 %19233, 16" -> "  %19235 = add nuw i32 %19230, %19234"
"  %19235 = add nuw i32 %19230, %19234"
"  %19235 = add nuw i32 %19230, %19234" -> "  %19248 = and i32 %19235, -65536""  %19235 = add nuw i32 %19230, %19234" -> "  %19246 = and i32 %19235, 65535"
"  %19236 = and i32 %19225, 65535"
"  %19236 = and i32 %19225, 65535" -> "  %19238 = add nuw nsw i32 %19237, %19236"
"  %19237 = and i32 %19204, 65535"
"  %19237 = and i32 %19204, 65535" -> "  %19238 = add nuw nsw i32 %19237, %19236"
"  %19238 = add nuw nsw i32 %19237, %19236"
"  %19238 = add nuw nsw i32 %19237, %19236" -> "  %19278 = and i32 %19238, 65535""  %19238 = add nuw nsw i32 %19237, %19236" -> "  %19242 = lshr i32 %19238, 16"
"  %19239 = and i32 %19233, 65535"
"  %19239 = and i32 %19233, 65535" -> "  %19241 = add nuw nsw i32 %19240, %19239"
"  %19240 = lshr i32 %19204, 16"
"  %19240 = lshr i32 %19204, 16" -> "  %19241 = add nuw nsw i32 %19240, %19239"
"  %19241 = add nuw nsw i32 %19240, %19239"
"  %19241 = add nuw nsw i32 %19240, %19239" -> "  %19245 = lshr i32 %19241, 16""  %19241 = add nuw nsw i32 %19240, %19239" -> "  %19243 = and i32 %19241, 65535"
"  %19242 = lshr i32 %19238, 16"
"  %19242 = lshr i32 %19238, 16" -> "  %19244 = add nuw nsw i32 %19242, %19243"
"  %19243 = and i32 %19241, 65535"
"  %19243 = and i32 %19241, 65535" -> "  %19244 = add nuw nsw i32 %19242, %19243"
"  %19244 = add nuw nsw i32 %19242, %19243"
"  %19244 = add nuw nsw i32 %19242, %19243" -> "  %19286 = and i32 %19244, 65535""  %19244 = add nuw nsw i32 %19242, %19243" -> "  %19250 = lshr i32 %19244, 16"
"  %19245 = lshr i32 %19241, 16"
"  %19245 = lshr i32 %19241, 16" -> "  %19247 = add nuw nsw i32 %19245, %19246"
"  %19246 = and i32 %19235, 65535"
"  %19246 = and i32 %19235, 65535" -> "  %19247 = add nuw nsw i32 %19245, %19246"
"  %19247 = add nuw nsw i32 %19245, %19246"
"  %19247 = add nuw nsw i32 %19245, %19246" -> "  %19249 = add nuw i32 %19247, %19248"
"  %19248 = and i32 %19235, -65536"
"  %19248 = and i32 %19235, -65536" -> "  %19249 = add nuw i32 %19247, %19248"
"  %19249 = add nuw i32 %19247, %19248"
"  %19249 = add nuw i32 %19247, %19248" -> "  %19251 = add nuw i32 %19249, %19250"
"  %19250 = lshr i32 %19244, 16"
"  %19250 = lshr i32 %19244, 16" -> "  %19251 = add nuw i32 %19249, %19250"
"  %19251 = add nuw i32 %19249, %19250"
"  %19251 = add nuw i32 %19249, %19250" -> "  %19289 = add nuw i32 %19251, %19288"
"  %19252 = and i32 %19125, 65535"
"  %19252 = and i32 %19125, 65535" -> "  %19254 = add nuw nsw i32 %19253, %19252"
"  %19253 = and i32 %18954, 65535"
"  %19253 = and i32 %18954, 65535" -> "  %19254 = add nuw nsw i32 %19253, %19252"
"  %19254 = add nuw nsw i32 %19253, %19252"
"  %19254 = add nuw nsw i32 %19253, %19252" -> "  %19290 = and i32 %19254, 65535""  %19254 = add nuw nsw i32 %19253, %19252" -> "  %19258 = lshr i32 %19254, 16"
"  %19255 = and i32 %19134, 65535"
"  %19255 = and i32 %19134, 65535" -> "  %19257 = add nuw nsw i32 %19256, %19255"
"  %19256 = and i32 %18957, 65535"
"  %19256 = and i32 %18957, 65535" -> "  %19257 = add nuw nsw i32 %19256, %19255"
"  %19257 = add nuw nsw i32 %19256, %19255"
"  %19257 = add nuw nsw i32 %19256, %19255" -> "  %19271 = lshr i32 %19257, 16""  %19257 = add nuw nsw i32 %19256, %19255" -> "  %19259 = and i32 %19257, 65535"
"  %19258 = lshr i32 %19254, 16"
"  %19258 = lshr i32 %19254, 16" -> "  %19260 = add nuw nsw i32 %19259, %19258"
"  %19259 = and i32 %19257, 65535"
"  %19259 = and i32 %19257, 65535" -> "  %19260 = add nuw nsw i32 %19259, %19258"
"  %19260 = add nuw nsw i32 %19259, %19258"
"  %19260 = add nuw nsw i32 %19259, %19258" -> "  %19293 = and i32 %19260, 65535""  %19260 = add nuw nsw i32 %19259, %19258" -> "  %19272 = lshr i32 %19260, 16"
"  %19261 = and i32 %19194, 65535"
"  %19261 = and i32 %19194, 65535" -> "  %19263 = add nuw nsw i32 %19262, %19261"
"  %19262 = and i32 %18959, 65535"
"  %19262 = and i32 %18959, 65535" -> "  %19263 = add nuw nsw i32 %19262, %19261"
"  %19263 = add nuw nsw i32 %19262, %19261"
"  %19263 = add nuw nsw i32 %19262, %19261" -> "  %19270 = and i32 %19263, 65535""  %19263 = add nuw nsw i32 %19262, %19261" -> "  %19267 = lshr i32 %19263, 16"
"  %19264 = and i32 %19202, 65535"
"  %19264 = and i32 %19202, 65535" -> "  %19266 = add nuw nsw i32 %19265, %19264"
"  %19265 = lshr i32 %18959, 16"
"  %19265 = lshr i32 %18959, 16" -> "  %19266 = add nuw nsw i32 %19265, %19264"
"  %19266 = add nuw nsw i32 %19265, %19264"
"  %19266 = add nuw nsw i32 %19265, %19264" -> "  %19279 = lshr i32 %19266, 16""  %19266 = add nuw nsw i32 %19265, %19264" -> "  %19268 = and i32 %19266, 65535"
"  %19267 = lshr i32 %19263, 16"
"  %19267 = lshr i32 %19263, 16" -> "  %19269 = add nuw nsw i32 %19268, %19267"
"  %19268 = and i32 %19266, 65535"
"  %19268 = and i32 %19266, 65535" -> "  %19269 = add nuw nsw i32 %19268, %19267"
"  %19269 = add nuw nsw i32 %19268, %19267"
"  %19269 = add nuw nsw i32 %19268, %19267" -> "  %19281 = lshr i32 %19269, 16""  %19269 = add nuw nsw i32 %19268, %19267" -> "  %19276 = and i32 %19269, 65535"
"  %19270 = and i32 %19263, 65535"
"  %19270 = and i32 %19263, 65535" -> "  %19274 = add nuw nsw i32 %19273, %19270"
"  %19271 = lshr i32 %19257, 16"
"  %19271 = lshr i32 %19257, 16" -> "  %19273 = add nuw nsw i32 %19272, %19271"
"  %19272 = lshr i32 %19260, 16"
"  %19272 = lshr i32 %19260, 16" -> "  %19273 = add nuw nsw i32 %19272, %19271"
"  %19273 = add nuw nsw i32 %19272, %19271"
"  %19273 = add nuw nsw i32 %19272, %19271" -> "  %19274 = add nuw nsw i32 %19273, %19270"
"  %19274 = add nuw nsw i32 %19273, %19270"
"  %19274 = add nuw nsw i32 %19273, %19270" -> "  %19300 = and i32 %19274, 65535""  %19274 = add nuw nsw i32 %19273, %19270" -> "  %19275 = lshr i32 %19274, 16"
"  %19275 = lshr i32 %19274, 16"
"  %19275 = lshr i32 %19274, 16" -> "  %19277 = add nuw nsw i32 %19275, %19276"
"  %19276 = and i32 %19269, 65535"
"  %19276 = and i32 %19269, 65535" -> "  %19277 = add nuw nsw i32 %19275, %19276"
"  %19277 = add nuw nsw i32 %19275, %19276"
"  %19277 = add nuw nsw i32 %19275, %19276" -> "  %19303 = and i32 %19277, 65535""  %19277 = add nuw nsw i32 %19275, %19276" -> "  %19283 = lshr i32 %19277, 16"
"  %19278 = and i32 %19238, 65535"
"  %19278 = and i32 %19238, 65535" -> "  %19280 = add nuw nsw i32 %19279, %19278"
"  %19279 = lshr i32 %19266, 16"
"  %19279 = lshr i32 %19266, 16" -> "  %19280 = add nuw nsw i32 %19279, %19278"
"  %19280 = add nuw nsw i32 %19279, %19278"
"  %19280 = add nuw nsw i32 %19279, %19278" -> "  %19282 = add nuw nsw i32 %19280, %19281"
"  %19281 = lshr i32 %19269, 16"
"  %19281 = lshr i32 %19269, 16" -> "  %19282 = add nuw nsw i32 %19280, %19281"
"  %19282 = add nuw nsw i32 %19280, %19281"
"  %19282 = add nuw nsw i32 %19280, %19281" -> "  %19284 = add nuw nsw i32 %19282, %19283"
"  %19283 = lshr i32 %19277, 16"
"  %19283 = lshr i32 %19277, 16" -> "  %19284 = add nuw nsw i32 %19282, %19283"
"  %19284 = add nuw nsw i32 %19282, %19283"
"  %19284 = add nuw nsw i32 %19282, %19283" -> "  %19317 = and i32 %19284, 65535""  %19284 = add nuw nsw i32 %19282, %19283" -> "  %19285 = lshr i32 %19284, 16"
"  %19285 = lshr i32 %19284, 16"
"  %19285 = lshr i32 %19284, 16" -> "  %19287 = add nuw nsw i32 %19285, %19286"
"  %19286 = and i32 %19244, 65535"
"  %19286 = and i32 %19244, 65535" -> "  %19287 = add nuw nsw i32 %19285, %19286"
"  %19287 = add nuw nsw i32 %19285, %19286"
"  %19287 = add nuw nsw i32 %19285, %19286" -> "  %19323 = and i32 %19287, 65535""  %19287 = add nuw nsw i32 %19285, %19286" -> "  %19288 = lshr i32 %19287, 16"
"  %19288 = lshr i32 %19287, 16"
"  %19288 = lshr i32 %19287, 16" -> "  %19289 = add nuw i32 %19251, %19288"
"  %19289 = add nuw i32 %19251, %19288"
"  %19289 = add nuw i32 %19251, %19288" -> "  %19327 = add nuw i32 %19289, %19326"
"  %19290 = and i32 %19254, 65535"
"  %19290 = and i32 %19254, 65535" -> "  %19292 = add nuw nsw i32 %19291, %19290"
"  %19291 = and i32 %19119, 65535"
"  %19291 = and i32 %19119, 65535" -> "  %19292 = add nuw nsw i32 %19291, %19290"
"  %19292 = add nuw nsw i32 %19291, %19290"
"  %19292 = add nuw nsw i32 %19291, %19290" -> "  %19400 = and i32 %19292, 65535""  %19292 = add nuw nsw i32 %19291, %19290" -> "  %19296 = lshr i32 %19292, 16"
"  %19293 = and i32 %19260, 65535"
"  %19293 = and i32 %19260, 65535" -> "  %19295 = add nuw nsw i32 %19294, %19293"
"  %19294 = and i32 %19122, 65535"
"  %19294 = and i32 %19122, 65535" -> "  %19295 = add nuw nsw i32 %19294, %19293"
"  %19295 = add nuw nsw i32 %19294, %19293"
"  %19295 = add nuw nsw i32 %19294, %19293" -> "  %19309 = lshr i32 %19295, 16""  %19295 = add nuw nsw i32 %19294, %19293" -> "  %19297 = and i32 %19295, 65535"
"  %19296 = lshr i32 %19292, 16"
"  %19296 = lshr i32 %19292, 16" -> "  %19298 = add nuw nsw i32 %19297, %19296"
"  %19297 = and i32 %19295, 65535"
"  %19297 = and i32 %19295, 65535" -> "  %19298 = add nuw nsw i32 %19297, %19296"
"  %19298 = add nuw nsw i32 %19297, %19296"
"  %19298 = add nuw nsw i32 %19297, %19296" -> "  %19405 = and i32 %19298, 65535""  %19298 = add nuw nsw i32 %19297, %19296" -> "  %19310 = lshr i32 %19298, 16"
"  %19299 = and i32 %19124, 65535"
"  %19299 = and i32 %19124, 65535" -> "  %19301 = add nuw nsw i32 %19299, %19300"
"  %19300 = and i32 %19274, 65535"
"  %19300 = and i32 %19274, 65535" -> "  %19301 = add nuw nsw i32 %19299, %19300"
"  %19301 = add nuw nsw i32 %19299, %19300"
"  %19301 = add nuw nsw i32 %19299, %19300" -> "  %19308 = and i32 %19301, 65535""  %19301 = add nuw nsw i32 %19299, %19300" -> "  %19305 = lshr i32 %19301, 16"
"  %19302 = lshr i32 %19124, 16"
"  %19302 = lshr i32 %19124, 16" -> "  %19304 = add nuw nsw i32 %19303, %19302"
"  %19303 = and i32 %19277, 65535"
"  %19303 = and i32 %19277, 65535" -> "  %19304 = add nuw nsw i32 %19303, %19302"
"  %19304 = add nuw nsw i32 %19303, %19302"
"  %19304 = add nuw nsw i32 %19303, %19302" -> "  %19316 = lshr i32 %19304, 16""  %19304 = add nuw nsw i32 %19303, %19302" -> "  %19306 = and i32 %19304, 65535"
"  %19305 = lshr i32 %19301, 16"
"  %19305 = lshr i32 %19301, 16" -> "  %19307 = add nuw nsw i32 %19306, %19305"
"  %19306 = and i32 %19304, 65535"
"  %19306 = and i32 %19304, 65535" -> "  %19307 = add nuw nsw i32 %19306, %19305"
"  %19307 = add nuw nsw i32 %19306, %19305"
"  %19307 = add nuw nsw i32 %19306, %19305" -> "  %19319 = lshr i32 %19307, 16""  %19307 = add nuw nsw i32 %19306, %19305" -> "  %19314 = and i32 %19307, 65535"
"  %19308 = and i32 %19301, 65535"
"  %19308 = and i32 %19301, 65535" -> "  %19312 = add nuw nsw i32 %19311, %19308"
"  %19309 = lshr i32 %19295, 16"
"  %19309 = lshr i32 %19295, 16" -> "  %19311 = add nuw nsw i32 %19310, %19309"
"  %19310 = lshr i32 %19298, 16"
"  %19310 = lshr i32 %19298, 16" -> "  %19311 = add nuw nsw i32 %19310, %19309"
"  %19311 = add nuw nsw i32 %19310, %19309"
"  %19311 = add nuw nsw i32 %19310, %19309" -> "  %19312 = add nuw nsw i32 %19311, %19308"
"  %19312 = add nuw nsw i32 %19311, %19308"
"  %19312 = add nuw nsw i32 %19311, %19308" -> "  %19406 = and i32 %19312, 65535""  %19312 = add nuw nsw i32 %19311, %19308" -> "  %19313 = lshr i32 %19312, 16"
"  %19313 = lshr i32 %19312, 16"
"  %19313 = lshr i32 %19312, 16" -> "  %19315 = add nuw nsw i32 %19314, %19313"
"  %19314 = and i32 %19307, 65535"
"  %19314 = and i32 %19307, 65535" -> "  %19315 = add nuw nsw i32 %19314, %19313"
"  %19315 = add nuw nsw i32 %19314, %19313"
"  %19315 = add nuw nsw i32 %19314, %19313" -> "  %19411 = and i32 %19315, 65535""  %19315 = add nuw nsw i32 %19314, %19313" -> "  %19321 = lshr i32 %19315, 16"
"  %19316 = lshr i32 %19304, 16"
"  %19316 = lshr i32 %19304, 16" -> "  %19318 = add nuw nsw i32 %19316, %19317"
"  %19317 = and i32 %19284, 65535"
"  %19317 = and i32 %19284, 65535" -> "  %19318 = add nuw nsw i32 %19316, %19317"
"  %19318 = add nuw nsw i32 %19316, %19317"
"  %19318 = add nuw nsw i32 %19316, %19317" -> "  %19320 = add nuw nsw i32 %19318, %19319"
"  %19319 = lshr i32 %19307, 16"
"  %19319 = lshr i32 %19307, 16" -> "  %19320 = add nuw nsw i32 %19318, %19319"
"  %19320 = add nuw nsw i32 %19318, %19319"
"  %19320 = add nuw nsw i32 %19318, %19319" -> "  %19322 = add nuw nsw i32 %19320, %19321"
"  %19321 = lshr i32 %19315, 16"
"  %19321 = lshr i32 %19315, 16" -> "  %19322 = add nuw nsw i32 %19320, %19321"
"  %19322 = add nuw nsw i32 %19320, %19321"
"  %19322 = add nuw nsw i32 %19320, %19321" -> "  %19414 = and i32 %19322, 65535""  %19322 = add nuw nsw i32 %19320, %19321" -> "  %19324 = lshr i32 %19322, 16"
"  %19323 = and i32 %19287, 65535"
"  %19323 = and i32 %19287, 65535" -> "  %19325 = add nuw nsw i32 %19324, %19323"
"  %19324 = lshr i32 %19322, 16"
"  %19324 = lshr i32 %19322, 16" -> "  %19325 = add nuw nsw i32 %19324, %19323"
"  %19325 = add nuw nsw i32 %19324, %19323"
"  %19325 = add nuw nsw i32 %19324, %19323" -> "  %19417 = and i32 %19325, 65535""  %19325 = add nuw nsw i32 %19324, %19323" -> "  %19326 = lshr i32 %19325, 16"
"  %19326 = lshr i32 %19325, 16"
"  %19326 = lshr i32 %19325, 16" -> "  %19327 = add nuw i32 %19289, %19326"
"  %19327 = add nuw i32 %19289, %19326"
"  %19327 = add nuw i32 %19289, %19326" -> "  %19421 = add nuw i32 %19327, %19420"
"  %19328 = and i32 %18579, 65535"
"  %19328 = and i32 %18579, 65535" -> "  %19330 = add nuw nsw i32 %19328, %19329"
"  %19329 = and i32 %18671, 65535"
"  %19329 = and i32 %18671, 65535" -> "  %19330 = add nuw nsw i32 %19328, %19329"
"  %19330 = add nuw nsw i32 %19328, %19329"
"  %19330 = add nuw nsw i32 %19328, %19329" -> "  %19334 = lshr i32 %19330, 16"
"  %19331 = and i32 %18585, 65535"
"  %19331 = and i32 %18585, 65535" -> "  %19333 = add nuw nsw i32 %19331, %19332"
"  %19332 = and i32 %18680, 65535"
"  %19332 = and i32 %18680, 65535" -> "  %19333 = add nuw nsw i32 %19331, %19332"
"  %19333 = add nuw nsw i32 %19331, %19332"
"  %19333 = add nuw nsw i32 %19331, %19332" -> "  %19337 = lshr i32 %19333, 16""  %19333 = add nuw nsw i32 %19331, %19332" -> "  %19335 = and i32 %19333, 65535"
"  %19334 = lshr i32 %19330, 16"
"  %19334 = lshr i32 %19330, 16" -> "  %19336 = add nuw nsw i32 %19335, %19334"
"  %19335 = and i32 %19333, 65535"
"  %19335 = and i32 %19333, 65535" -> "  %19336 = add nuw nsw i32 %19335, %19334"
"  %19336 = add nuw nsw i32 %19335, %19334"
"  %19336 = add nuw nsw i32 %19335, %19334" -> "  %19338 = lshr i32 %19336, 16"
"  %19337 = lshr i32 %19333, 16"
"  %19337 = lshr i32 %19333, 16" -> "  %19339 = add nuw nsw i32 %19338, %19337"
"  %19338 = lshr i32 %19336, 16"
"  %19338 = lshr i32 %19336, 16" -> "  %19339 = add nuw nsw i32 %19338, %19337"
"  %19339 = add nuw nsw i32 %19338, %19337"
"  %19339 = add nuw nsw i32 %19338, %19337" -> "  %19350 = add nuw nsw i32 %19339, %19349"
"  %19340 = and i32 %18599, 65535"
"  %19340 = and i32 %18599, 65535" -> "  %19342 = add nuw nsw i32 %19340, %19341"
"  %19341 = and i32 %18740, 65535"
"  %19341 = and i32 %18740, 65535" -> "  %19342 = add nuw nsw i32 %19340, %19341"
"  %19342 = add nuw nsw i32 %19340, %19341"
"  %19342 = add nuw nsw i32 %19340, %19341" -> "  %19349 = and i32 %19342, 65535""  %19342 = add nuw nsw i32 %19340, %19341" -> "  %19346 = lshr i32 %19342, 16"
"  %19343 = and i32 %18602, 65535"
"  %19343 = and i32 %18602, 65535" -> "  %19345 = add nuw nsw i32 %19343, %19344"
"  %19344 = and i32 %18748, 65535"
"  %19344 = and i32 %18748, 65535" -> "  %19345 = add nuw nsw i32 %19343, %19344"
"  %19345 = add nuw nsw i32 %19343, %19344"
"  %19345 = add nuw nsw i32 %19343, %19344" -> "  %19384 = lshr i32 %19345, 16""  %19345 = add nuw nsw i32 %19343, %19344" -> "  %19347 = and i32 %19345, 65535"
"  %19346 = lshr i32 %19342, 16"
"  %19346 = lshr i32 %19342, 16" -> "  %19348 = add nuw nsw i32 %19347, %19346"
"  %19347 = and i32 %19345, 65535"
"  %19347 = and i32 %19345, 65535" -> "  %19348 = add nuw nsw i32 %19347, %19346"
"  %19348 = add nuw nsw i32 %19347, %19346"
"  %19348 = add nuw nsw i32 %19347, %19346" -> "  %19386 = lshr i32 %19348, 16""  %19348 = add nuw nsw i32 %19347, %19346" -> "  %19352 = and i32 %19348, 65535"
"  %19349 = and i32 %19342, 65535"
"  %19349 = and i32 %19342, 65535" -> "  %19350 = add nuw nsw i32 %19339, %19349"
"  %19350 = add nuw nsw i32 %19339, %19349"
"  %19350 = add nuw nsw i32 %19339, %19349" -> "  %19351 = lshr i32 %19350, 16"
"  %19351 = lshr i32 %19350, 16"
"  %19351 = lshr i32 %19350, 16" -> "  %19353 = add nuw nsw i32 %19352, %19351"
"  %19352 = and i32 %19348, 65535"
"  %19352 = and i32 %19348, 65535" -> "  %19353 = add nuw nsw i32 %19352, %19351"
"  %19353 = add nuw nsw i32 %19352, %19351"
"  %19353 = add nuw nsw i32 %19352, %19351" -> "  %19388 = lshr i32 %19353, 16"
"  %19354 = and i32 %18639, 65535"
"  %19354 = and i32 %18639, 65535" -> "  %19356 = add nuw nsw i32 %19354, %19355"
"  %19355 = and i32 %19089, 65535"
"  %19355 = and i32 %19089, 65535" -> "  %19356 = add nuw nsw i32 %19354, %19355"
"  %19356 = add nuw nsw i32 %19354, %19355"
"  %19356 = add nuw nsw i32 %19354, %19355" -> "  %19383 = and i32 %19356, 65535""  %19356 = add nuw nsw i32 %19354, %19355" -> "  %19360 = lshr i32 %19356, 16"
"  %19357 = and i32 %18642, 65535"
"  %19357 = and i32 %18642, 65535" -> "  %19359 = add nuw nsw i32 %19357, %19358"
"  %19358 = and i32 %19095, 65535"
"  %19358 = and i32 %19095, 65535" -> "  %19359 = add nuw nsw i32 %19357, %19358"
"  %19359 = add nuw nsw i32 %19357, %19358"
"  %19359 = add nuw nsw i32 %19357, %19358" -> "  %19363 = lshr i32 %19359, 16""  %19359 = add nuw nsw i32 %19357, %19358" -> "  %19361 = and i32 %19359, 65535"
"  %19360 = lshr i32 %19356, 16"
"  %19360 = lshr i32 %19356, 16" -> "  %19362 = add nuw nsw i32 %19361, %19360"
"  %19361 = and i32 %19359, 65535"
"  %19361 = and i32 %19359, 65535" -> "  %19362 = add nuw nsw i32 %19361, %19360"
"  %19362 = add nuw nsw i32 %19361, %19360"
"  %19362 = add nuw nsw i32 %19361, %19360" -> "  %19390 = and i32 %19362, 65535""  %19362 = add nuw nsw i32 %19361, %19360" -> "  %19364 = lshr i32 %19362, 16"
"  %19363 = lshr i32 %19359, 16"
"  %19363 = lshr i32 %19359, 16" -> "  %19365 = add nuw nsw i32 %19364, %19363"
"  %19364 = lshr i32 %19362, 16"
"  %19364 = lshr i32 %19362, 16" -> "  %19365 = add nuw nsw i32 %19364, %19363"
"  %19365 = add nuw nsw i32 %19364, %19363"
"  %19365 = add nuw nsw i32 %19364, %19363" -> "  %19378 = add nuw nsw i32 %19365, %19377"
"  %19366 = and i32 %18645, 65535"
"  %19366 = and i32 %18645, 65535" -> "  %19368 = add nuw nsw i32 %19366, %19367"
"  %19367 = and i32 %19109, 65535"
"  %19367 = and i32 %19109, 65535" -> "  %19368 = add nuw nsw i32 %19366, %19367"
"  %19368 = add nuw nsw i32 %19366, %19367"
"  %19368 = add nuw nsw i32 %19366, %19367" -> "  %19377 = and i32 %19368, 65535""  %19368 = add nuw nsw i32 %19366, %19367" -> "  %19372 = lshr i32 %19368, 16"
"  %19369 = and i32 %18648, 65535"
"  %19369 = and i32 %18648, 65535" -> "  %19371 = add nuw nsw i32 %19369, %19370"
"  %19370 = and i32 %19112, 65535"
"  %19370 = and i32 %19112, 65535" -> "  %19371 = add nuw nsw i32 %19369, %19370"
"  %19371 = add nuw nsw i32 %19369, %19370"
"  %19371 = add nuw nsw i32 %19369, %19370" -> "  %19375 = lshr i32 %19371, 16""  %19371 = add nuw nsw i32 %19369, %19370" -> "  %19373 = and i32 %19371, 65535"
"  %19372 = lshr i32 %19368, 16"
"  %19372 = lshr i32 %19368, 16" -> "  %19374 = add nuw nsw i32 %19373, %19372"
"  %19373 = and i32 %19371, 65535"
"  %19373 = and i32 %19371, 65535" -> "  %19374 = add nuw nsw i32 %19373, %19372"
"  %19374 = add nuw nsw i32 %19373, %19372"
"  %19374 = add nuw nsw i32 %19373, %19372" -> "  %19379 = and i32 %19374, 65535""  %19374 = add nuw nsw i32 %19373, %19372" -> "  %19376 = lshr i32 %19374, 16"
"  %19375 = lshr i32 %19371, 16"
"  %19375 = lshr i32 %19371, 16" -> "  %19401 = add nuw nsw i32 %19375, %19400"
"  %19376 = lshr i32 %19374, 16"
"  %19376 = lshr i32 %19374, 16" -> "  %19402 = add nuw nsw i32 %19401, %19376"
"  %19377 = and i32 %19368, 65535"
"  %19377 = and i32 %19368, 65535" -> "  %19378 = add nuw nsw i32 %19365, %19377"
"  %19378 = add nuw nsw i32 %19365, %19377"
"  %19378 = add nuw nsw i32 %19365, %19377" -> "  %19393 = and i32 %19378, 65535""  %19378 = add nuw nsw i32 %19365, %19377" -> "  %19380 = lshr i32 %19378, 16"
"  %19379 = and i32 %19374, 65535"
"  %19379 = and i32 %19374, 65535" -> "  %19381 = add nuw nsw i32 %19379, %19380"
"  %19380 = lshr i32 %19378, 16"
"  %19380 = lshr i32 %19378, 16" -> "  %19381 = add nuw nsw i32 %19379, %19380"
"  %19381 = add nuw nsw i32 %19379, %19380"
"  %19381 = add nuw nsw i32 %19379, %19380" -> "  %19396 = and i32 %19381, 65535""  %19381 = add nuw nsw i32 %19379, %19380" -> "  %19382 = lshr i32 %19381, 16"
"  %19382 = lshr i32 %19381, 16"
"  %19382 = lshr i32 %19381, 16" -> "  %19403 = add nuw nsw i32 %19402, %19382"
"  %19383 = and i32 %19356, 65535"
"  %19383 = and i32 %19356, 65535" -> "  %19385 = add nuw nsw i32 %19383, %19384"
"  %19384 = lshr i32 %19345, 16"
"  %19384 = lshr i32 %19345, 16" -> "  %19385 = add nuw nsw i32 %19383, %19384"
"  %19385 = add nuw nsw i32 %19383, %19384"
"  %19385 = add nuw nsw i32 %19383, %19384" -> "  %19387 = add nuw nsw i32 %19385, %19386"
"  %19386 = lshr i32 %19348, 16"
"  %19386 = lshr i32 %19348, 16" -> "  %19387 = add nuw nsw i32 %19385, %19386"
"  %19387 = add nuw nsw i32 %19385, %19386"
"  %19387 = add nuw nsw i32 %19385, %19386" -> "  %19389 = add nuw nsw i32 %19387, %19388"
"  %19388 = lshr i32 %19353, 16"
"  %19388 = lshr i32 %19353, 16" -> "  %19389 = add nuw nsw i32 %19387, %19388"
"  %19389 = add nuw nsw i32 %19387, %19388"
"  %19389 = add nuw nsw i32 %19387, %19388" -> "  %19391 = lshr i32 %19389, 16"
"  %19390 = and i32 %19362, 65535"
"  %19390 = and i32 %19362, 65535" -> "  %19392 = add nuw nsw i32 %19390, %19391"
"  %19391 = lshr i32 %19389, 16"
"  %19391 = lshr i32 %19389, 16" -> "  %19392 = add nuw nsw i32 %19390, %19391"
"  %19392 = add nuw nsw i32 %19390, %19391"
"  %19392 = add nuw nsw i32 %19390, %19391" -> "  %19394 = lshr i32 %19392, 16"
"  %19393 = and i32 %19378, 65535"
"  %19393 = and i32 %19378, 65535" -> "  %19395 = add nuw nsw i32 %19393, %19394"
"  %19394 = lshr i32 %19392, 16"
"  %19394 = lshr i32 %19392, 16" -> "  %19395 = add nuw nsw i32 %19393, %19394"
"  %19395 = add nuw nsw i32 %19393, %19394"
"  %19395 = add nuw nsw i32 %19393, %19394" -> "  %19397 = lshr i32 %19395, 16"
"  %19396 = and i32 %19381, 65535"
"  %19396 = and i32 %19381, 65535" -> "  %19398 = add nuw nsw i32 %19396, %19397"
"  %19397 = lshr i32 %19395, 16"
"  %19397 = lshr i32 %19395, 16" -> "  %19398 = add nuw nsw i32 %19396, %19397"
"  %19398 = add nuw nsw i32 %19396, %19397"
"  %19398 = add nuw nsw i32 %19396, %19397" -> "  %19399 = lshr i32 %19398, 16"
"  %19399 = lshr i32 %19398, 16"
"  %19399 = lshr i32 %19398, 16" -> "  %19404 = add nuw nsw i32 %19403, %19399"
"  %19400 = and i32 %19292, 65535"
"  %19400 = and i32 %19292, 65535" -> "  %19401 = add nuw nsw i32 %19375, %19400"
"  %19401 = add nuw nsw i32 %19375, %19400"
"  %19401 = add nuw nsw i32 %19375, %19400" -> "  %19402 = add nuw nsw i32 %19401, %19376"
"  %19402 = add nuw nsw i32 %19401, %19376"
"  %19402 = add nuw nsw i32 %19401, %19376" -> "  %19403 = add nuw nsw i32 %19402, %19382"
"  %19403 = add nuw nsw i32 %19402, %19382"
"  %19403 = add nuw nsw i32 %19402, %19382" -> "  %19404 = add nuw nsw i32 %19403, %19399"
"  %19404 = add nuw nsw i32 %19403, %19399"
"  %19404 = add nuw nsw i32 %19403, %19399" -> "  %20170 = and i32 %19404, 65535""  %19404 = add nuw nsw i32 %19403, %19399" -> "  %19407 = lshr i32 %19404, 16""  %19404 = add nuw nsw i32 %19403, %19399" -> "  store i32 %19404, i32* %662, align 1, !noalias !59"
"  store i32 %19404, i32* %662, align 1, !noalias !59"

"  %19405 = and i32 %19298, 65535"
"  %19405 = and i32 %19298, 65535" -> "  %19408 = add nuw nsw i32 %19407, %19405"
"  %19406 = and i32 %19312, 65535"
"  %19406 = and i32 %19312, 65535" -> "  %19410 = add nuw nsw i32 %19409, %19406"
"  %19407 = lshr i32 %19404, 16"
"  %19407 = lshr i32 %19404, 16" -> "  %19408 = add nuw nsw i32 %19407, %19405"
"  %19408 = add nuw nsw i32 %19407, %19405"
"  %19408 = add nuw nsw i32 %19407, %19405" -> "  %20173 = and i32 %19408, 65535""  %19408 = add nuw nsw i32 %19407, %19405" -> "  %19409 = lshr i32 %19408, 16""  %19408 = add nuw nsw i32 %19407, %19405" -> "  store i32 %19408, i32* %682, align 1, !noalias !59"
"  store i32 %19408, i32* %682, align 1, !noalias !59"

"  %19409 = lshr i32 %19408, 16"
"  %19409 = lshr i32 %19408, 16" -> "  %19410 = add nuw nsw i32 %19409, %19406"
"  %19410 = add nuw nsw i32 %19409, %19406"
"  %19410 = add nuw nsw i32 %19409, %19406" -> "  %20180 = and i32 %19410, 65535""  %19410 = add nuw nsw i32 %19409, %19406" -> "  %19412 = lshr i32 %19410, 16""  %19410 = add nuw nsw i32 %19409, %19406" -> "  store i32 %19410, i32* %638, align 1, !noalias !59"
"  store i32 %19410, i32* %638, align 1, !noalias !59"

"  %19411 = and i32 %19315, 65535"
"  %19411 = and i32 %19315, 65535" -> "  %19413 = add nuw nsw i32 %19412, %19411"
"  %19412 = lshr i32 %19410, 16"
"  %19412 = lshr i32 %19410, 16" -> "  %19413 = add nuw nsw i32 %19412, %19411"
"  %19413 = add nuw nsw i32 %19412, %19411"
"  %19413 = add nuw nsw i32 %19412, %19411" -> "  %20183 = and i32 %19413, 65535""  %19413 = add nuw nsw i32 %19412, %19411" -> "  %19415 = lshr i32 %19413, 16""  %19413 = add nuw nsw i32 %19412, %19411" -> "  store i32 %19413, i32* %624, align 1, !noalias !59"
"  store i32 %19413, i32* %624, align 1, !noalias !59"

"  %19414 = and i32 %19322, 65535"
"  %19414 = and i32 %19322, 65535" -> "  %19416 = add nuw nsw i32 %19415, %19414"
"  %19415 = lshr i32 %19413, 16"
"  %19415 = lshr i32 %19413, 16" -> "  %19416 = add nuw nsw i32 %19415, %19414"
"  %19416 = add nuw nsw i32 %19415, %19414"
"  %19416 = add nuw nsw i32 %19415, %19414" -> "  %20197 = and i32 %19416, 65535""  %19416 = add nuw nsw i32 %19415, %19414" -> "  %19418 = lshr i32 %19416, 16""  %19416 = add nuw nsw i32 %19415, %19414" -> "  store i32 %19416, i32* %614, align 1, !noalias !59"
"  store i32 %19416, i32* %614, align 1, !noalias !59"

"  %19417 = and i32 %19325, 65535"
"  %19417 = and i32 %19325, 65535" -> "  %19419 = add nuw nsw i32 %19418, %19417"
"  %19418 = lshr i32 %19416, 16"
"  %19418 = lshr i32 %19416, 16" -> "  %19419 = add nuw nsw i32 %19418, %19417"
"  %19419 = add nuw nsw i32 %19418, %19417"
"  %19419 = add nuw nsw i32 %19418, %19417" -> "  %20200 = and i32 %19419, 65535""  %19419 = add nuw nsw i32 %19418, %19417" -> "  %19420 = lshr i32 %19419, 16""  %19419 = add nuw nsw i32 %19418, %19417" -> "  store i32 %19419, i32* %587, align 1, !noalias !59"
"  store i32 %19419, i32* %587, align 1, !noalias !59"

"  %19420 = lshr i32 %19419, 16"
"  %19420 = lshr i32 %19419, 16" -> "  %19421 = add nuw i32 %19327, %19420"
"  %19421 = add nuw i32 %19327, %19420"
"  %19421 = add nuw i32 %19327, %19420" -> "  %20206 = and i32 %19421, 65535""  %19421 = add nuw i32 %19327, %19420" -> "  %20209 = lshr i32 %19421, 16"
"  %19422 = mul nuw i32 %17915, 42779"
"  %19422 = mul nuw i32 %17915, 42779" -> "  %20077 = and i32 %19422, 65535""  %19422 = mul nuw i32 %17915, 42779" -> "  %19423 = lshr i32 %19422, 16""  %19422 = mul nuw i32 %17915, 42779" -> "  store i32 %19422, i32* %1353, align 1, !noalias !59"
"  store i32 %19422, i32* %1353, align 1, !noalias !59"

"  %19423 = lshr i32 %19422, 16"
"  %19423 = lshr i32 %19422, 16" -> "  %19426 = add nuw nsw i32 %19425, %19423"
"  %19424 = mul nuw i32 %17918, 42779"
"  %19424 = mul nuw i32 %17918, 42779" -> "  %19427 = and i32 %19424, -65536""  %19424 = mul nuw i32 %17918, 42779" -> "  %19425 = and i32 %19424, 65535"
"  %19425 = and i32 %19424, 65535"
"  %19425 = and i32 %19424, 65535" -> "  %19426 = add nuw nsw i32 %19425, %19423"
"  %19426 = add nuw nsw i32 %19425, %19423"
"  %19426 = add nuw nsw i32 %19425, %19423" -> "  %19428 = add nuw i32 %19426, %19427"
"  %19427 = and i32 %19424, -65536"
"  %19427 = and i32 %19424, -65536" -> "  %19428 = add nuw i32 %19426, %19427"
"  %19428 = add nuw i32 %19426, %19427"
"  %19428 = add nuw i32 %19426, %19427" -> "  %19432 = lshr i32 %19428, 16""  %19428 = add nuw i32 %19426, %19427" -> "  %19430 = and i32 %19428, 65535"
"  %19429 = mul nuw nsw i32 %17915, 9871"
"  %19429 = mul nuw nsw i32 %17915, 9871" -> "  %19431 = add nuw nsw i32 %19430, %19429"
"  %19430 = and i32 %19428, 65535"
"  %19430 = and i32 %19428, 65535" -> "  %19431 = add nuw nsw i32 %19430, %19429"
"  %19431 = add nuw nsw i32 %19430, %19429"
"  %19431 = add nuw nsw i32 %19430, %19429" -> "  %20080 = and i32 %19431, 65535""  %19431 = add nuw nsw i32 %19430, %19429" -> "  %19435 = lshr i32 %19431, 16""  %19431 = add nuw nsw i32 %19430, %19429" -> "  store i32 %19431, i32* %1694, align 1, !noalias !59"
"  store i32 %19431, i32* %1694, align 1, !noalias !59"

"  %19432 = lshr i32 %19428, 16"
"  %19432 = lshr i32 %19428, 16" -> "  %19434 = add nuw nsw i32 %19432, %19433"
"  %19433 = mul nuw nsw i32 %17918, 9871"
"  %19433 = mul nuw nsw i32 %17918, 9871" -> "  %19434 = add nuw nsw i32 %19432, %19433"
"  %19434 = add nuw nsw i32 %19432, %19433"
"  %19434 = add nuw nsw i32 %19432, %19433" -> "  %19438 = and i32 %19434, 2147418112""  %19434 = add nuw nsw i32 %19432, %19433" -> "  %19436 = and i32 %19434, 65535"
"  %19435 = lshr i32 %19431, 16"
"  %19435 = lshr i32 %19431, 16" -> "  %19437 = add nuw nsw i32 %19435, %19436"
"  %19436 = and i32 %19434, 65535"
"  %19436 = and i32 %19434, 65535" -> "  %19437 = add nuw nsw i32 %19435, %19436"
"  %19437 = add nuw nsw i32 %19435, %19436"
"  %19437 = add nuw nsw i32 %19435, %19436" -> "  %19439 = add nuw nsw i32 %19437, %19438"
"  %19438 = and i32 %19434, 2147418112"
"  %19438 = and i32 %19434, 2147418112" -> "  %19439 = add nuw nsw i32 %19437, %19438"
"  %19439 = add nuw nsw i32 %19437, %19438"
"  %19439 = add nuw nsw i32 %19437, %19438" -> "  %19458 = and i32 %19439, 65535""  %19439 = add nuw nsw i32 %19437, %19438" -> "  %19462 = lshr i32 %19439, 16"
"  %19440 = mul nuw i32 %17935, 42779"
"  %19440 = mul nuw i32 %17935, 42779" -> "  %19441 = lshr i32 %19440, 16""  %19440 = mul nuw i32 %17935, 42779" -> "  %19459 = and i32 %19440, 65535"
"  %19441 = lshr i32 %19440, 16"
"  %19441 = lshr i32 %19440, 16" -> "  %19444 = add nuw nsw i32 %19443, %19441"
"  %19442 = mul nuw i32 %17938, 42779"
"  %19442 = mul nuw i32 %17938, 42779" -> "  %19445 = and i32 %19442, -65536""  %19442 = mul nuw i32 %17938, 42779" -> "  %19443 = and i32 %19442, 65535"
"  %19443 = and i32 %19442, 65535"
"  %19443 = and i32 %19442, 65535" -> "  %19444 = add nuw nsw i32 %19443, %19441"
"  %19444 = add nuw nsw i32 %19443, %19441"
"  %19444 = add nuw nsw i32 %19443, %19441" -> "  %19446 = add nuw i32 %19444, %19445"
"  %19445 = and i32 %19442, -65536"
"  %19445 = and i32 %19442, -65536" -> "  %19446 = add nuw i32 %19444, %19445"
"  %19446 = add nuw i32 %19444, %19445"
"  %19446 = add nuw i32 %19444, %19445" -> "  %19450 = lshr i32 %19446, 16""  %19446 = add nuw i32 %19444, %19445" -> "  %19448 = and i32 %19446, 65535"
"  %19447 = mul nuw nsw i32 %17935, 9871"
"  %19447 = mul nuw nsw i32 %17935, 9871" -> "  %19449 = add nuw nsw i32 %19448, %19447"
"  %19448 = and i32 %19446, 65535"
"  %19448 = and i32 %19446, 65535" -> "  %19449 = add nuw nsw i32 %19448, %19447"
"  %19449 = add nuw nsw i32 %19448, %19447"
"  %19449 = add nuw nsw i32 %19448, %19447" -> "  %19461 = and i32 %19449, 65535""  %19449 = add nuw nsw i32 %19448, %19447" -> "  %19453 = lshr i32 %19449, 16"
"  %19450 = lshr i32 %19446, 16"
"  %19450 = lshr i32 %19446, 16" -> "  %19452 = add nuw nsw i32 %19450, %19451"
"  %19451 = mul nuw nsw i32 %17938, 9871"
"  %19451 = mul nuw nsw i32 %17938, 9871" -> "  %19452 = add nuw nsw i32 %19450, %19451"
"  %19452 = add nuw nsw i32 %19450, %19451"
"  %19452 = add nuw nsw i32 %19450, %19451" -> "  %19456 = and i32 %19452, 2147418112""  %19452 = add nuw nsw i32 %19450, %19451" -> "  %19454 = and i32 %19452, 65535"
"  %19453 = lshr i32 %19449, 16"
"  %19453 = lshr i32 %19449, 16" -> "  %19455 = add nuw nsw i32 %19453, %19454"
"  %19454 = and i32 %19452, 65535"
"  %19454 = and i32 %19452, 65535" -> "  %19455 = add nuw nsw i32 %19453, %19454"
"  %19455 = add nuw nsw i32 %19453, %19454"
"  %19455 = add nuw nsw i32 %19453, %19454" -> "  %19457 = add nuw nsw i32 %19455, %19456"
"  %19456 = and i32 %19452, 2147418112"
"  %19456 = and i32 %19452, 2147418112" -> "  %19457 = add nuw nsw i32 %19455, %19456"
"  %19457 = add nuw nsw i32 %19455, %19456"
"  %19457 = add nuw nsw i32 %19455, %19456" -> "  %19465 = add nuw nsw i32 %19457, %19464"
"  %19458 = and i32 %19439, 65535"
"  %19458 = and i32 %19439, 65535" -> "  %19460 = add nuw nsw i32 %19458, %19459"
"  %19459 = and i32 %19440, 65535"
"  %19459 = and i32 %19440, 65535" -> "  %19460 = add nuw nsw i32 %19458, %19459"
"  %19460 = add nuw nsw i32 %19458, %19459"
"  %19460 = add nuw nsw i32 %19458, %19459" -> "  %19489 = and i32 %19460, 65535""  %19460 = add nuw nsw i32 %19458, %19459" -> "  %19467 = lshr i32 %19460, 16"
"  %19461 = and i32 %19449, 65535"
"  %19461 = and i32 %19449, 65535" -> "  %19463 = add nuw nsw i32 %19461, %19462"
"  %19462 = lshr i32 %19439, 16"
"  %19462 = lshr i32 %19439, 16" -> "  %19463 = add nuw nsw i32 %19461, %19462"
"  %19463 = add nuw nsw i32 %19461, %19462"
"  %19463 = add nuw nsw i32 %19461, %19462" -> "  %19466 = and i32 %19463, 65535""  %19463 = add nuw nsw i32 %19461, %19462" -> "  %19464 = lshr i32 %19463, 16"
"  %19464 = lshr i32 %19463, 16"
"  %19464 = lshr i32 %19463, 16" -> "  %19465 = add nuw nsw i32 %19457, %19464"
"  %19465 = add nuw nsw i32 %19457, %19464"
"  %19465 = add nuw nsw i32 %19457, %19464" -> "  %19470 = add nuw nsw i32 %19465, %19469"
"  %19466 = and i32 %19463, 65535"
"  %19466 = and i32 %19463, 65535" -> "  %19468 = add nuw nsw i32 %19466, %19467"
"  %19467 = lshr i32 %19460, 16"
"  %19467 = lshr i32 %19460, 16" -> "  %19468 = add nuw nsw i32 %19466, %19467"
"  %19468 = add nuw nsw i32 %19466, %19467"
"  %19468 = add nuw nsw i32 %19466, %19467" -> "  %19492 = and i32 %19468, 65535""  %19468 = add nuw nsw i32 %19466, %19467" -> "  %19469 = lshr i32 %19468, 16"
"  %19469 = lshr i32 %19468, 16"
"  %19469 = lshr i32 %19468, 16" -> "  %19470 = add nuw nsw i32 %19465, %19469"
"  %19470 = add nuw nsw i32 %19465, %19469"
"  %19470 = add nuw nsw i32 %19465, %19469" -> "  %19521 = lshr i32 %19470, 16""  %19470 = add nuw nsw i32 %19465, %19469" -> "  %19517 = and i32 %19470, 65535"
"  %19471 = mul nuw nsw i32 %17915, 24315"
"  %19471 = mul nuw nsw i32 %17915, 24315" -> "  %19490 = and i32 %19471, 65535""  %19471 = mul nuw nsw i32 %17915, 24315" -> "  %19472 = lshr i32 %19471, 16"
"  %19472 = lshr i32 %19471, 16"
"  %19472 = lshr i32 %19471, 16" -> "  %19475 = add nuw nsw i32 %19474, %19472"
"  %19473 = mul nuw nsw i32 %17918, 24315"
"  %19473 = mul nuw nsw i32 %17918, 24315" -> "  %19476 = and i32 %19473, 2147418112""  %19473 = mul nuw nsw i32 %17918, 24315" -> "  %19474 = and i32 %19473, 65535"
"  %19474 = and i32 %19473, 65535"
"  %19474 = and i32 %19473, 65535" -> "  %19475 = add nuw nsw i32 %19474, %19472"
"  %19475 = add nuw nsw i32 %19474, %19472"
"  %19475 = add nuw nsw i32 %19474, %19472" -> "  %19477 = add nuw nsw i32 %19475, %19476"
"  %19476 = and i32 %19473, 2147418112"
"  %19476 = and i32 %19473, 2147418112" -> "  %19477 = add nuw nsw i32 %19475, %19476"
"  %19477 = add nuw nsw i32 %19475, %19476"
"  %19477 = add nuw nsw i32 %19475, %19476" -> "  %19481 = lshr i32 %19477, 16""  %19477 = add nuw nsw i32 %19475, %19476" -> "  %19479 = and i32 %19477, 65535"
"  %19478 = mul nuw nsw i32 %17915, 29744"
"  %19478 = mul nuw nsw i32 %17915, 29744" -> "  %19480 = add nuw nsw i32 %19479, %19478"
"  %19479 = and i32 %19477, 65535"
"  %19479 = and i32 %19477, 65535" -> "  %19480 = add nuw nsw i32 %19479, %19478"
"  %19480 = add nuw nsw i32 %19479, %19478"
"  %19480 = add nuw nsw i32 %19479, %19478" -> "  %19493 = and i32 %19480, 65535""  %19480 = add nuw nsw i32 %19479, %19478" -> "  %19484 = lshr i32 %19480, 16"
"  %19481 = lshr i32 %19477, 16"
"  %19481 = lshr i32 %19477, 16" -> "  %19483 = add nuw nsw i32 %19481, %19482"
"  %19482 = mul nuw nsw i32 %17918, 29744"
"  %19482 = mul nuw nsw i32 %17918, 29744" -> "  %19483 = add nuw nsw i32 %19481, %19482"
"  %19483 = add nuw nsw i32 %19481, %19482"
"  %19483 = add nuw nsw i32 %19481, %19482" -> "  %19487 = and i32 %19483, 2147418112""  %19483 = add nuw nsw i32 %19481, %19482" -> "  %19485 = and i32 %19483, 65535"
"  %19484 = lshr i32 %19480, 16"
"  %19484 = lshr i32 %19480, 16" -> "  %19486 = add nuw nsw i32 %19484, %19485"
"  %19485 = and i32 %19483, 65535"
"  %19485 = and i32 %19483, 65535" -> "  %19486 = add nuw nsw i32 %19484, %19485"
"  %19486 = add nuw nsw i32 %19484, %19485"
"  %19486 = add nuw nsw i32 %19484, %19485" -> "  %19488 = add nuw nsw i32 %19486, %19487"
"  %19487 = and i32 %19483, 2147418112"
"  %19487 = and i32 %19483, 2147418112" -> "  %19488 = add nuw nsw i32 %19486, %19487"
"  %19488 = add nuw nsw i32 %19486, %19487"
"  %19488 = add nuw nsw i32 %19486, %19487" -> "  %19496 = add nuw nsw i32 %19488, %19495"
"  %19489 = and i32 %19460, 65535"
"  %19489 = and i32 %19460, 65535" -> "  %19491 = add nuw nsw i32 %19489, %19490"
"  %19490 = and i32 %19471, 65535"
"  %19490 = and i32 %19471, 65535" -> "  %19491 = add nuw nsw i32 %19489, %19490"
"  %19491 = add nuw nsw i32 %19489, %19490"
"  %19491 = add nuw nsw i32 %19489, %19490" -> "  %20086 = and i32 %19491, 65535""  %19491 = add nuw nsw i32 %19489, %19490" -> "  %19498 = lshr i32 %19491, 16""  %19491 = add nuw nsw i32 %19489, %19490" -> "  store i32 %19491, i32* %1859, align 1, !noalias !62"
"  store i32 %19491, i32* %1859, align 1, !noalias !62"

"  %19492 = and i32 %19468, 65535"
"  %19492 = and i32 %19468, 65535" -> "  %19494 = add nuw nsw i32 %19492, %19493"
"  %19493 = and i32 %19480, 65535"
"  %19493 = and i32 %19480, 65535" -> "  %19494 = add nuw nsw i32 %19492, %19493"
"  %19494 = add nuw nsw i32 %19492, %19493"
"  %19494 = add nuw nsw i32 %19492, %19493" -> "  %19497 = and i32 %19494, 65535""  %19494 = add nuw nsw i32 %19492, %19493" -> "  %19495 = lshr i32 %19494, 16"
"  %19495 = lshr i32 %19494, 16"
"  %19495 = lshr i32 %19494, 16" -> "  %19496 = add nuw nsw i32 %19488, %19495"
"  %19496 = add nuw nsw i32 %19488, %19495"
"  %19496 = add nuw nsw i32 %19488, %19495" -> "  %19501 = add nuw nsw i32 %19496, %19500"
"  %19497 = and i32 %19494, 65535"
"  %19497 = and i32 %19494, 65535" -> "  %19499 = add nuw nsw i32 %19497, %19498"
"  %19498 = lshr i32 %19491, 16"
"  %19498 = lshr i32 %19491, 16" -> "  %19499 = add nuw nsw i32 %19497, %19498"
"  %19499 = add nuw nsw i32 %19497, %19498"
"  %19499 = add nuw nsw i32 %19497, %19498" -> "  %20089 = and i32 %19499, 65535""  %19499 = add nuw nsw i32 %19497, %19498" -> "  %19500 = lshr i32 %19499, 16""  %19499 = add nuw nsw i32 %19497, %19498" -> "  store i32 %19499, i32* %1728, align 1, !noalias !62"
"  store i32 %19499, i32* %1728, align 1, !noalias !62"

"  %19500 = lshr i32 %19499, 16"
"  %19500 = lshr i32 %19499, 16" -> "  %19501 = add nuw nsw i32 %19496, %19500"
"  %19501 = add nuw nsw i32 %19496, %19500"
"  %19501 = add nuw nsw i32 %19496, %19500" -> "  %19534 = lshr i32 %19501, 16""  %19501 = add nuw nsw i32 %19496, %19500" -> "  %19531 = and i32 %19501, 65535"
"  %19502 = mul nuw nsw i32 %17935, 24315"
"  %19502 = mul nuw nsw i32 %17935, 24315" -> "  %19518 = and i32 %19502, 65535""  %19502 = mul nuw nsw i32 %17935, 24315" -> "  %19503 = lshr i32 %19502, 16"
"  %19503 = lshr i32 %19502, 16"
"  %19503 = lshr i32 %19502, 16" -> "  %19505 = add nuw nsw i32 %19504, %19503"
"  %19504 = mul nuw nsw i32 %17938, 24315"
"  %19504 = mul nuw nsw i32 %17938, 24315" -> "  %19505 = add nuw nsw i32 %19504, %19503"
"  %19505 = add nuw nsw i32 %19504, %19503"
"  %19505 = add nuw nsw i32 %19504, %19503" -> "  %19509 = lshr i32 %19505, 16""  %19505 = add nuw nsw i32 %19504, %19503" -> "  %19507 = and i32 %19505, 65535"
"  %19506 = mul nuw nsw i32 %17935, 29744"
"  %19506 = mul nuw nsw i32 %17935, 29744" -> "  %19508 = add nuw nsw i32 %19507, %19506"
"  %19507 = and i32 %19505, 65535"
"  %19507 = and i32 %19505, 65535" -> "  %19508 = add nuw nsw i32 %19507, %19506"
"  %19508 = add nuw nsw i32 %19507, %19506"
"  %19508 = add nuw nsw i32 %19507, %19506" -> "  %19520 = and i32 %19508, 65535""  %19508 = add nuw nsw i32 %19507, %19506" -> "  %19512 = lshr i32 %19508, 16"
"  %19509 = lshr i32 %19505, 16"
"  %19509 = lshr i32 %19505, 16" -> "  %19511 = add nuw nsw i32 %19509, %19510"
"  %19510 = mul nuw nsw i32 %17938, 29744"
"  %19510 = mul nuw nsw i32 %17938, 29744" -> "  %19511 = add nuw nsw i32 %19509, %19510"
"  %19511 = add nuw nsw i32 %19509, %19510"
"  %19511 = add nuw nsw i32 %19509, %19510" -> "  %19515 = and i32 %19511, 2147418112""  %19511 = add nuw nsw i32 %19509, %19510" -> "  %19513 = and i32 %19511, 65535"
"  %19512 = lshr i32 %19508, 16"
"  %19512 = lshr i32 %19508, 16" -> "  %19514 = add nuw nsw i32 %19512, %19513"
"  %19513 = and i32 %19511, 65535"
"  %19513 = and i32 %19511, 65535" -> "  %19514 = add nuw nsw i32 %19512, %19513"
"  %19514 = add nuw nsw i32 %19512, %19513"
"  %19514 = add nuw nsw i32 %19512, %19513" -> "  %19516 = add nuw nsw i32 %19514, %19515"
"  %19515 = and i32 %19511, 2147418112"
"  %19515 = and i32 %19511, 2147418112" -> "  %19516 = add nuw nsw i32 %19514, %19515"
"  %19516 = add nuw nsw i32 %19514, %19515"
"  %19516 = add nuw nsw i32 %19514, %19515" -> "  %19524 = add nuw nsw i32 %19516, %19523"
"  %19517 = and i32 %19470, 65535"
"  %19517 = and i32 %19470, 65535" -> "  %19519 = add nuw nsw i32 %19517, %19518"
"  %19518 = and i32 %19502, 65535"
"  %19518 = and i32 %19502, 65535" -> "  %19519 = add nuw nsw i32 %19517, %19518"
"  %19519 = add nuw nsw i32 %19517, %19518"
"  %19519 = add nuw nsw i32 %19517, %19518" -> "  %19530 = and i32 %19519, 65535""  %19519 = add nuw nsw i32 %19517, %19518" -> "  %19526 = lshr i32 %19519, 16"
"  %19520 = and i32 %19508, 65535"
"  %19520 = and i32 %19508, 65535" -> "  %19522 = add nuw nsw i32 %19521, %19520"
"  %19521 = lshr i32 %19470, 16"
"  %19521 = lshr i32 %19470, 16" -> "  %19522 = add nuw nsw i32 %19521, %19520"
"  %19522 = add nuw nsw i32 %19521, %19520"
"  %19522 = add nuw nsw i32 %19521, %19520" -> "  %19525 = and i32 %19522, 65535""  %19522 = add nuw nsw i32 %19521, %19520" -> "  %19523 = lshr i32 %19522, 16"
"  %19523 = lshr i32 %19522, 16"
"  %19523 = lshr i32 %19522, 16" -> "  %19524 = add nuw nsw i32 %19516, %19523"
"  %19524 = add nuw nsw i32 %19516, %19523"
"  %19524 = add nuw nsw i32 %19516, %19523" -> "  %19529 = add nuw nsw i32 %19524, %19528"
"  %19525 = and i32 %19522, 65535"
"  %19525 = and i32 %19522, 65535" -> "  %19527 = add nuw nsw i32 %19526, %19525"
"  %19526 = lshr i32 %19519, 16"
"  %19526 = lshr i32 %19519, 16" -> "  %19527 = add nuw nsw i32 %19526, %19525"
"  %19527 = add nuw nsw i32 %19526, %19525"
"  %19527 = add nuw nsw i32 %19526, %19525" -> "  %19533 = and i32 %19527, 65535""  %19527 = add nuw nsw i32 %19526, %19525" -> "  %19528 = lshr i32 %19527, 16"
"  %19528 = lshr i32 %19527, 16"
"  %19528 = lshr i32 %19527, 16" -> "  %19529 = add nuw nsw i32 %19524, %19528"
"  %19529 = add nuw nsw i32 %19524, %19528"
"  %19529 = add nuw nsw i32 %19524, %19528" -> "  %19541 = add nuw nsw i32 %19529, %19539"
"  %19530 = and i32 %19519, 65535"
"  %19530 = and i32 %19519, 65535" -> "  %19532 = add nuw nsw i32 %19531, %19530"
"  %19531 = and i32 %19501, 65535"
"  %19531 = and i32 %19501, 65535" -> "  %19532 = add nuw nsw i32 %19531, %19530"
"  %19532 = add nuw nsw i32 %19531, %19530"
"  %19532 = add nuw nsw i32 %19531, %19530" -> "  %19671 = and i32 %19532, 65535""  %19532 = add nuw nsw i32 %19531, %19530" -> "  %19536 = lshr i32 %19532, 16"
"  %19533 = and i32 %19527, 65535"
"  %19533 = and i32 %19527, 65535" -> "  %19535 = add nuw nsw i32 %19534, %19533"
"  %19534 = lshr i32 %19501, 16"
"  %19534 = lshr i32 %19501, 16" -> "  %19535 = add nuw nsw i32 %19534, %19533"
"  %19535 = add nuw nsw i32 %19534, %19533"
"  %19535 = add nuw nsw i32 %19534, %19533" -> "  %19539 = lshr i32 %19535, 16""  %19535 = add nuw nsw i32 %19534, %19533" -> "  %19537 = and i32 %19535, 65535"
"  %19536 = lshr i32 %19532, 16"
"  %19536 = lshr i32 %19532, 16" -> "  %19538 = add nuw nsw i32 %19536, %19537"
"  %19537 = and i32 %19535, 65535"
"  %19537 = and i32 %19535, 65535" -> "  %19538 = add nuw nsw i32 %19536, %19537"
"  %19538 = add nuw nsw i32 %19536, %19537"
"  %19538 = add nuw nsw i32 %19536, %19537" -> "  %19674 = and i32 %19538, 65535""  %19538 = add nuw nsw i32 %19536, %19537" -> "  %19540 = lshr i32 %19538, 16"
"  %19539 = lshr i32 %19535, 16"
"  %19539 = lshr i32 %19535, 16" -> "  %19541 = add nuw nsw i32 %19529, %19539"
"  %19540 = lshr i32 %19538, 16"
"  %19540 = lshr i32 %19538, 16" -> "  %19542 = add nuw nsw i32 %19541, %19540"
"  %19541 = add nuw nsw i32 %19529, %19539"
"  %19541 = add nuw nsw i32 %19529, %19539" -> "  %19542 = add nuw nsw i32 %19541, %19540"
"  %19542 = add nuw nsw i32 %19541, %19540"
"  %19542 = add nuw nsw i32 %19541, %19540" -> "  %19680 = and i32 %19542, 65535""  %19542 = add nuw nsw i32 %19541, %19540" -> "  %19683 = lshr i32 %19542, 16"
"  %19543 = mul nuw i32 %18049, 42779"
"  %19543 = mul nuw i32 %18049, 42779" -> "  %19670 = and i32 %19543, 65535""  %19543 = mul nuw i32 %18049, 42779" -> "  %19544 = lshr i32 %19543, 16"
"  %19544 = lshr i32 %19543, 16"
"  %19544 = lshr i32 %19543, 16" -> "  %19547 = add nuw nsw i32 %19546, %19544"
"  %19545 = mul nuw i32 %18050, 42779"
"  %19545 = mul nuw i32 %18050, 42779" -> "  %19548 = and i32 %19545, -65536""  %19545 = mul nuw i32 %18050, 42779" -> "  %19546 = and i32 %19545, 65535"
"  %19546 = and i32 %19545, 65535"
"  %19546 = and i32 %19545, 65535" -> "  %19547 = add nuw nsw i32 %19546, %19544"
"  %19547 = add nuw nsw i32 %19546, %19544"
"  %19547 = add nuw nsw i32 %19546, %19544" -> "  %19549 = add nuw i32 %19547, %19548"
"  %19548 = and i32 %19545, -65536"
"  %19548 = and i32 %19545, -65536" -> "  %19549 = add nuw i32 %19547, %19548"
"  %19549 = add nuw i32 %19547, %19548"
"  %19549 = add nuw i32 %19547, %19548" -> "  %19553 = lshr i32 %19549, 16""  %19549 = add nuw i32 %19547, %19548" -> "  %19551 = and i32 %19549, 65535"
"  %19550 = mul nuw nsw i32 %18049, 9871"
"  %19550 = mul nuw nsw i32 %18049, 9871" -> "  %19552 = add nuw nsw i32 %19551, %19550"
"  %19551 = and i32 %19549, 65535"
"  %19551 = and i32 %19549, 65535" -> "  %19552 = add nuw nsw i32 %19551, %19550"
"  %19552 = add nuw nsw i32 %19551, %19550"
"  %19552 = add nuw nsw i32 %19551, %19550" -> "  %19673 = and i32 %19552, 65535""  %19552 = add nuw nsw i32 %19551, %19550" -> "  %19556 = lshr i32 %19552, 16"
"  %19553 = lshr i32 %19549, 16"
"  %19553 = lshr i32 %19549, 16" -> "  %19555 = add nuw nsw i32 %19553, %19554"
"  %19554 = mul nuw nsw i32 %18050, 9871"
"  %19554 = mul nuw nsw i32 %18050, 9871" -> "  %19555 = add nuw nsw i32 %19553, %19554"
"  %19555 = add nuw nsw i32 %19553, %19554"
"  %19555 = add nuw nsw i32 %19553, %19554" -> "  %19559 = and i32 %19555, 2147418112""  %19555 = add nuw nsw i32 %19553, %19554" -> "  %19557 = and i32 %19555, 65535"
"  %19556 = lshr i32 %19552, 16"
"  %19556 = lshr i32 %19552, 16" -> "  %19558 = add nuw nsw i32 %19556, %19557"
"  %19557 = and i32 %19555, 65535"
"  %19557 = and i32 %19555, 65535" -> "  %19558 = add nuw nsw i32 %19556, %19557"
"  %19558 = add nuw nsw i32 %19556, %19557"
"  %19558 = add nuw nsw i32 %19556, %19557" -> "  %19560 = add nuw nsw i32 %19558, %19559"
"  %19559 = and i32 %19555, 2147418112"
"  %19559 = and i32 %19555, 2147418112" -> "  %19560 = add nuw nsw i32 %19558, %19559"
"  %19560 = add nuw nsw i32 %19558, %19559"
"  %19560 = add nuw nsw i32 %19558, %19559" -> "  %19583 = lshr i32 %19560, 16""  %19560 = add nuw nsw i32 %19558, %19559" -> "  %19579 = and i32 %19560, 65535"
"  %19561 = mul nuw i32 %18069, 42779"
"  %19561 = mul nuw i32 %18069, 42779" -> "  %19580 = and i32 %19561, 65535""  %19561 = mul nuw i32 %18069, 42779" -> "  %19562 = lshr i32 %19561, 16"
"  %19562 = lshr i32 %19561, 16"
"  %19562 = lshr i32 %19561, 16" -> "  %19565 = add nuw nsw i32 %19564, %19562"
"  %19563 = mul nuw i32 %18070, 42779"
"  %19563 = mul nuw i32 %18070, 42779" -> "  %19566 = and i32 %19563, -65536""  %19563 = mul nuw i32 %18070, 42779" -> "  %19564 = and i32 %19563, 65535"
"  %19564 = and i32 %19563, 65535"
"  %19564 = and i32 %19563, 65535" -> "  %19565 = add nuw nsw i32 %19564, %19562"
"  %19565 = add nuw nsw i32 %19564, %19562"
"  %19565 = add nuw nsw i32 %19564, %19562" -> "  %19567 = add nuw i32 %19565, %19566"
"  %19566 = and i32 %19563, -65536"
"  %19566 = and i32 %19563, -65536" -> "  %19567 = add nuw i32 %19565, %19566"
"  %19567 = add nuw i32 %19565, %19566"
"  %19567 = add nuw i32 %19565, %19566" -> "  %19571 = lshr i32 %19567, 16""  %19567 = add nuw i32 %19565, %19566" -> "  %19569 = and i32 %19567, 65535"
"  %19568 = mul nuw nsw i32 %18069, 9871"
"  %19568 = mul nuw nsw i32 %18069, 9871" -> "  %19570 = add nuw nsw i32 %19569, %19568"
"  %19569 = and i32 %19567, 65535"
"  %19569 = and i32 %19567, 65535" -> "  %19570 = add nuw nsw i32 %19569, %19568"
"  %19570 = add nuw nsw i32 %19569, %19568"
"  %19570 = add nuw nsw i32 %19569, %19568" -> "  %19582 = and i32 %19570, 65535""  %19570 = add nuw nsw i32 %19569, %19568" -> "  %19574 = lshr i32 %19570, 16"
"  %19571 = lshr i32 %19567, 16"
"  %19571 = lshr i32 %19567, 16" -> "  %19573 = add nuw nsw i32 %19571, %19572"
"  %19572 = mul nuw nsw i32 %18070, 9871"
"  %19572 = mul nuw nsw i32 %18070, 9871" -> "  %19573 = add nuw nsw i32 %19571, %19572"
"  %19573 = add nuw nsw i32 %19571, %19572"
"  %19573 = add nuw nsw i32 %19571, %19572" -> "  %19577 = and i32 %19573, 2147418112""  %19573 = add nuw nsw i32 %19571, %19572" -> "  %19575 = and i32 %19573, 65535"
"  %19574 = lshr i32 %19570, 16"
"  %19574 = lshr i32 %19570, 16" -> "  %19576 = add nuw nsw i32 %19574, %19575"
"  %19575 = and i32 %19573, 65535"
"  %19575 = and i32 %19573, 65535" -> "  %19576 = add nuw nsw i32 %19574, %19575"
"  %19576 = add nuw nsw i32 %19574, %19575"
"  %19576 = add nuw nsw i32 %19574, %19575" -> "  %19578 = add nuw nsw i32 %19576, %19577"
"  %19577 = and i32 %19573, 2147418112"
"  %19577 = and i32 %19573, 2147418112" -> "  %19578 = add nuw nsw i32 %19576, %19577"
"  %19578 = add nuw nsw i32 %19576, %19577"
"  %19578 = add nuw nsw i32 %19576, %19577" -> "  %19586 = add nuw nsw i32 %19578, %19585"
"  %19579 = and i32 %19560, 65535"
"  %19579 = and i32 %19560, 65535" -> "  %19581 = add nuw nsw i32 %19579, %19580"
"  %19580 = and i32 %19561, 65535"
"  %19580 = and i32 %19561, 65535" -> "  %19581 = add nuw nsw i32 %19579, %19580"
"  %19581 = add nuw nsw i32 %19579, %19580"
"  %19581 = add nuw nsw i32 %19579, %19580" -> "  %19610 = and i32 %19581, 65535""  %19581 = add nuw nsw i32 %19579, %19580" -> "  %19588 = lshr i32 %19581, 16"
"  %19582 = and i32 %19570, 65535"
"  %19582 = and i32 %19570, 65535" -> "  %19584 = add nuw nsw i32 %19583, %19582"
"  %19583 = lshr i32 %19560, 16"
"  %19583 = lshr i32 %19560, 16" -> "  %19584 = add nuw nsw i32 %19583, %19582"
"  %19584 = add nuw nsw i32 %19583, %19582"
"  %19584 = add nuw nsw i32 %19583, %19582" -> "  %19587 = and i32 %19584, 65535""  %19584 = add nuw nsw i32 %19583, %19582" -> "  %19585 = lshr i32 %19584, 16"
"  %19585 = lshr i32 %19584, 16"
"  %19585 = lshr i32 %19584, 16" -> "  %19586 = add nuw nsw i32 %19578, %19585"
"  %19586 = add nuw nsw i32 %19578, %19585"
"  %19586 = add nuw nsw i32 %19578, %19585" -> "  %19591 = add nuw nsw i32 %19586, %19590"
"  %19587 = and i32 %19584, 65535"
"  %19587 = and i32 %19584, 65535" -> "  %19589 = add nuw nsw i32 %19587, %19588"
"  %19588 = lshr i32 %19581, 16"
"  %19588 = lshr i32 %19581, 16" -> "  %19589 = add nuw nsw i32 %19587, %19588"
"  %19589 = add nuw nsw i32 %19587, %19588"
"  %19589 = add nuw nsw i32 %19587, %19588" -> "  %19614 = and i32 %19589, 65535""  %19589 = add nuw nsw i32 %19587, %19588" -> "  %19590 = lshr i32 %19589, 16"
"  %19590 = lshr i32 %19589, 16"
"  %19590 = lshr i32 %19589, 16" -> "  %19591 = add nuw nsw i32 %19586, %19590"
"  %19591 = add nuw nsw i32 %19586, %19590"
"  %19591 = add nuw nsw i32 %19586, %19590" -> "  %19641 = and i32 %19591, 65535""  %19591 = add nuw nsw i32 %19586, %19590" -> "  %19645 = lshr i32 %19591, 16"
"  %19592 = mul nuw nsw i32 %18049, 24315"
"  %19592 = mul nuw nsw i32 %18049, 24315" -> "  %19593 = lshr i32 %19592, 16""  %19592 = mul nuw nsw i32 %18049, 24315" -> "  %19611 = and i32 %19592, 65535"
"  %19593 = lshr i32 %19592, 16"
"  %19593 = lshr i32 %19592, 16" -> "  %19596 = add nuw nsw i32 %19595, %19593"
"  %19594 = mul nuw nsw i32 %18050, 24315"
"  %19594 = mul nuw nsw i32 %18050, 24315" -> "  %19597 = and i32 %19594, 2147418112""  %19594 = mul nuw nsw i32 %18050, 24315" -> "  %19595 = and i32 %19594, 65535"
"  %19595 = and i32 %19594, 65535"
"  %19595 = and i32 %19594, 65535" -> "  %19596 = add nuw nsw i32 %19595, %19593"
"  %19596 = add nuw nsw i32 %19595, %19593"
"  %19596 = add nuw nsw i32 %19595, %19593" -> "  %19598 = add nuw nsw i32 %19596, %19597"
"  %19597 = and i32 %19594, 2147418112"
"  %19597 = and i32 %19594, 2147418112" -> "  %19598 = add nuw nsw i32 %19596, %19597"
"  %19598 = add nuw nsw i32 %19596, %19597"
"  %19598 = add nuw nsw i32 %19596, %19597" -> "  %19602 = lshr i32 %19598, 16""  %19598 = add nuw nsw i32 %19596, %19597" -> "  %19600 = and i32 %19598, 65535"
"  %19599 = mul nuw nsw i32 %18049, 29744"
"  %19599 = mul nuw nsw i32 %18049, 29744" -> "  %19601 = add nuw nsw i32 %19600, %19599"
"  %19600 = and i32 %19598, 65535"
"  %19600 = and i32 %19598, 65535" -> "  %19601 = add nuw nsw i32 %19600, %19599"
"  %19601 = add nuw nsw i32 %19600, %19599"
"  %19601 = add nuw nsw i32 %19600, %19599" -> "  %19613 = and i32 %19601, 65535""  %19601 = add nuw nsw i32 %19600, %19599" -> "  %19605 = lshr i32 %19601, 16"
"  %19602 = lshr i32 %19598, 16"
"  %19602 = lshr i32 %19598, 16" -> "  %19604 = add nuw nsw i32 %19602, %19603"
"  %19603 = mul nuw nsw i32 %18050, 29744"
"  %19603 = mul nuw nsw i32 %18050, 29744" -> "  %19604 = add nuw nsw i32 %19602, %19603"
"  %19604 = add nuw nsw i32 %19602, %19603"
"  %19604 = add nuw nsw i32 %19602, %19603" -> "  %19608 = and i32 %19604, 2147418112""  %19604 = add nuw nsw i32 %19602, %19603" -> "  %19606 = and i32 %19604, 65535"
"  %19605 = lshr i32 %19601, 16"
"  %19605 = lshr i32 %19601, 16" -> "  %19607 = add nuw nsw i32 %19606, %19605"
"  %19606 = and i32 %19604, 65535"
"  %19606 = and i32 %19604, 65535" -> "  %19607 = add nuw nsw i32 %19606, %19605"
"  %19607 = add nuw nsw i32 %19606, %19605"
"  %19607 = add nuw nsw i32 %19606, %19605" -> "  %19609 = add nuw nsw i32 %19607, %19608"
"  %19608 = and i32 %19604, 2147418112"
"  %19608 = and i32 %19604, 2147418112" -> "  %19609 = add nuw nsw i32 %19607, %19608"
"  %19609 = add nuw nsw i32 %19607, %19608"
"  %19609 = add nuw nsw i32 %19607, %19608" -> "  %19617 = add nuw nsw i32 %19609, %19616"
"  %19610 = and i32 %19581, 65535"
"  %19610 = and i32 %19581, 65535" -> "  %19612 = add nuw nsw i32 %19610, %19611"
"  %19611 = and i32 %19592, 65535"
"  %19611 = and i32 %19592, 65535" -> "  %19612 = add nuw nsw i32 %19610, %19611"
"  %19612 = add nuw nsw i32 %19610, %19611"
"  %19612 = add nuw nsw i32 %19610, %19611" -> "  %19679 = and i32 %19612, 65535""  %19612 = add nuw nsw i32 %19610, %19611" -> "  %19619 = lshr i32 %19612, 16"
"  %19613 = and i32 %19601, 65535"
"  %19613 = and i32 %19601, 65535" -> "  %19615 = add nuw nsw i32 %19614, %19613"
"  %19614 = and i32 %19589, 65535"
"  %19614 = and i32 %19589, 65535" -> "  %19615 = add nuw nsw i32 %19614, %19613"
"  %19615 = add nuw nsw i32 %19614, %19613"
"  %19615 = add nuw nsw i32 %19614, %19613" -> "  %19618 = and i32 %19615, 65535""  %19615 = add nuw nsw i32 %19614, %19613" -> "  %19616 = lshr i32 %19615, 16"
"  %19616 = lshr i32 %19615, 16"
"  %19616 = lshr i32 %19615, 16" -> "  %19617 = add nuw nsw i32 %19609, %19616"
"  %19617 = add nuw nsw i32 %19609, %19616"
"  %19617 = add nuw nsw i32 %19609, %19616" -> "  %19622 = add nuw nsw i32 %19617, %19621"
"  %19618 = and i32 %19615, 65535"
"  %19618 = and i32 %19615, 65535" -> "  %19620 = add nuw nsw i32 %19618, %19619"
"  %19619 = lshr i32 %19612, 16"
"  %19619 = lshr i32 %19612, 16" -> "  %19620 = add nuw nsw i32 %19618, %19619"
"  %19620 = add nuw nsw i32 %19618, %19619"
"  %19620 = add nuw nsw i32 %19618, %19619" -> "  %19682 = and i32 %19620, 65535""  %19620 = add nuw nsw i32 %19618, %19619" -> "  %19621 = lshr i32 %19620, 16"
"  %19621 = lshr i32 %19620, 16"
"  %19621 = lshr i32 %19620, 16" -> "  %19622 = add nuw nsw i32 %19617, %19621"
"  %19622 = add nuw nsw i32 %19617, %19621"
"  %19622 = add nuw nsw i32 %19617, %19621" -> "  %19658 = lshr i32 %19622, 16""  %19622 = add nuw nsw i32 %19617, %19621" -> "  %19655 = and i32 %19622, 65535"
"  %19623 = mul nuw nsw i32 %18069, 24315"
"  %19623 = mul nuw nsw i32 %18069, 24315" -> "  %19642 = and i32 %19623, 65535""  %19623 = mul nuw nsw i32 %18069, 24315" -> "  %19624 = lshr i32 %19623, 16"
"  %19624 = lshr i32 %19623, 16"
"  %19624 = lshr i32 %19623, 16" -> "  %19627 = add nuw nsw i32 %19626, %19624"
"  %19625 = mul nuw nsw i32 %18070, 24315"
"  %19625 = mul nuw nsw i32 %18070, 24315" -> "  %19628 = and i32 %19625, 2147418112""  %19625 = mul nuw nsw i32 %18070, 24315" -> "  %19626 = and i32 %19625, 65535"
"  %19626 = and i32 %19625, 65535"
"  %19626 = and i32 %19625, 65535" -> "  %19627 = add nuw nsw i32 %19626, %19624"
"  %19627 = add nuw nsw i32 %19626, %19624"
"  %19627 = add nuw nsw i32 %19626, %19624" -> "  %19629 = add nuw nsw i32 %19627, %19628"
"  %19628 = and i32 %19625, 2147418112"
"  %19628 = and i32 %19625, 2147418112" -> "  %19629 = add nuw nsw i32 %19627, %19628"
"  %19629 = add nuw nsw i32 %19627, %19628"
"  %19629 = add nuw nsw i32 %19627, %19628" -> "  %19633 = lshr i32 %19629, 16""  %19629 = add nuw nsw i32 %19627, %19628" -> "  %19631 = and i32 %19629, 65535"
"  %19630 = mul nuw nsw i32 %18069, 29744"
"  %19630 = mul nuw nsw i32 %18069, 29744" -> "  %19632 = add nuw nsw i32 %19631, %19630"
"  %19631 = and i32 %19629, 65535"
"  %19631 = and i32 %19629, 65535" -> "  %19632 = add nuw nsw i32 %19631, %19630"
"  %19632 = add nuw nsw i32 %19631, %19630"
"  %19632 = add nuw nsw i32 %19631, %19630" -> "  %19644 = and i32 %19632, 65535""  %19632 = add nuw nsw i32 %19631, %19630" -> "  %19636 = lshr i32 %19632, 16"
"  %19633 = lshr i32 %19629, 16"
"  %19633 = lshr i32 %19629, 16" -> "  %19635 = add nuw nsw i32 %19633, %19634"
"  %19634 = mul nuw nsw i32 %18070, 29744"
"  %19634 = mul nuw nsw i32 %18070, 29744" -> "  %19635 = add nuw nsw i32 %19633, %19634"
"  %19635 = add nuw nsw i32 %19633, %19634"
"  %19635 = add nuw nsw i32 %19633, %19634" -> "  %19639 = and i32 %19635, 2147418112""  %19635 = add nuw nsw i32 %19633, %19634" -> "  %19637 = and i32 %19635, 65535"
"  %19636 = lshr i32 %19632, 16"
"  %19636 = lshr i32 %19632, 16" -> "  %19638 = add nuw nsw i32 %19636, %19637"
"  %19637 = and i32 %19635, 65535"
"  %19637 = and i32 %19635, 65535" -> "  %19638 = add nuw nsw i32 %19636, %19637"
"  %19638 = add nuw nsw i32 %19636, %19637"
"  %19638 = add nuw nsw i32 %19636, %19637" -> "  %19640 = add nuw nsw i32 %19638, %19639"
"  %19639 = and i32 %19635, 2147418112"
"  %19639 = and i32 %19635, 2147418112" -> "  %19640 = add nuw nsw i32 %19638, %19639"
"  %19640 = add nuw nsw i32 %19638, %19639"
"  %19640 = add nuw nsw i32 %19638, %19639" -> "  %19648 = add nuw nsw i32 %19640, %19647"
"  %19641 = and i32 %19591, 65535"
"  %19641 = and i32 %19591, 65535" -> "  %19643 = add nuw nsw i32 %19641, %19642"
"  %19642 = and i32 %19623, 65535"
"  %19642 = and i32 %19623, 65535" -> "  %19643 = add nuw nsw i32 %19641, %19642"
"  %19643 = add nuw nsw i32 %19641, %19642"
"  %19643 = add nuw nsw i32 %19641, %19642" -> "  %19654 = and i32 %19643, 65535""  %19643 = add nuw nsw i32 %19641, %19642" -> "  %19650 = lshr i32 %19643, 16"
"  %19644 = and i32 %19632, 65535"
"  %19644 = and i32 %19632, 65535" -> "  %19646 = add nuw nsw i32 %19645, %19644"
"  %19645 = lshr i32 %19591, 16"
"  %19645 = lshr i32 %19591, 16" -> "  %19646 = add nuw nsw i32 %19645, %19644"
"  %19646 = add nuw nsw i32 %19645, %19644"
"  %19646 = add nuw nsw i32 %19645, %19644" -> "  %19649 = and i32 %19646, 65535""  %19646 = add nuw nsw i32 %19645, %19644" -> "  %19647 = lshr i32 %19646, 16"
"  %19647 = lshr i32 %19646, 16"
"  %19647 = lshr i32 %19646, 16" -> "  %19648 = add nuw nsw i32 %19640, %19647"
"  %19648 = add nuw nsw i32 %19640, %19647"
"  %19648 = add nuw nsw i32 %19640, %19647" -> "  %19653 = add nuw nsw i32 %19648, %19652"
"  %19649 = and i32 %19646, 65535"
"  %19649 = and i32 %19646, 65535" -> "  %19651 = add nuw nsw i32 %19649, %19650"
"  %19650 = lshr i32 %19643, 16"
"  %19650 = lshr i32 %19643, 16" -> "  %19651 = add nuw nsw i32 %19649, %19650"
"  %19651 = add nuw nsw i32 %19649, %19650"
"  %19651 = add nuw nsw i32 %19649, %19650" -> "  %19657 = and i32 %19651, 65535""  %19651 = add nuw nsw i32 %19649, %19650" -> "  %19652 = lshr i32 %19651, 16"
"  %19652 = lshr i32 %19651, 16"
"  %19652 = lshr i32 %19651, 16" -> "  %19653 = add nuw nsw i32 %19648, %19652"
"  %19653 = add nuw nsw i32 %19648, %19652"
"  %19653 = add nuw nsw i32 %19648, %19652" -> "  %19666 = and i32 %19653, 2147418112""  %19653 = add nuw nsw i32 %19648, %19652" -> "  %19664 = and i32 %19653, 65535"
"  %19654 = and i32 %19643, 65535"
"  %19654 = and i32 %19643, 65535" -> "  %19656 = add nuw nsw i32 %19655, %19654"
"  %19655 = and i32 %19622, 65535"
"  %19655 = and i32 %19622, 65535" -> "  %19656 = add nuw nsw i32 %19655, %19654"
"  %19656 = add nuw nsw i32 %19655, %19654"
"  %19656 = add nuw nsw i32 %19655, %19654" -> "  %19696 = and i32 %19656, 65535""  %19656 = add nuw nsw i32 %19655, %19654" -> "  %19660 = lshr i32 %19656, 16"
"  %19657 = and i32 %19651, 65535"
"  %19657 = and i32 %19651, 65535" -> "  %19659 = add nuw nsw i32 %19657, %19658"
"  %19658 = lshr i32 %19622, 16"
"  %19658 = lshr i32 %19622, 16" -> "  %19659 = add nuw nsw i32 %19657, %19658"
"  %19659 = add nuw nsw i32 %19657, %19658"
"  %19659 = add nuw nsw i32 %19657, %19658" -> "  %19663 = lshr i32 %19659, 16""  %19659 = add nuw nsw i32 %19657, %19658" -> "  %19661 = and i32 %19659, 65535"
"  %19660 = lshr i32 %19656, 16"
"  %19660 = lshr i32 %19656, 16" -> "  %19662 = add nuw nsw i32 %19661, %19660"
"  %19661 = and i32 %19659, 65535"
"  %19661 = and i32 %19659, 65535" -> "  %19662 = add nuw nsw i32 %19661, %19660"
"  %19662 = add nuw nsw i32 %19661, %19660"
"  %19662 = add nuw nsw i32 %19661, %19660" -> "  %19703 = and i32 %19662, 65535""  %19662 = add nuw nsw i32 %19661, %19660" -> "  %19668 = lshr i32 %19662, 16"
"  %19663 = lshr i32 %19659, 16"
"  %19663 = lshr i32 %19659, 16" -> "  %19665 = add nuw nsw i32 %19663, %19664"
"  %19664 = and i32 %19653, 65535"
"  %19664 = and i32 %19653, 65535" -> "  %19665 = add nuw nsw i32 %19663, %19664"
"  %19665 = add nuw nsw i32 %19663, %19664"
"  %19665 = add nuw nsw i32 %19663, %19664" -> "  %19667 = add nuw nsw i32 %19665, %19666"
"  %19666 = and i32 %19653, 2147418112"
"  %19666 = and i32 %19653, 2147418112" -> "  %19667 = add nuw nsw i32 %19665, %19666"
"  %19667 = add nuw nsw i32 %19665, %19666"
"  %19667 = add nuw nsw i32 %19665, %19666" -> "  %19669 = add nuw nsw i32 %19667, %19668"
"  %19668 = lshr i32 %19662, 16"
"  %19668 = lshr i32 %19662, 16" -> "  %19669 = add nuw nsw i32 %19667, %19668"
"  %19669 = add nuw nsw i32 %19667, %19668"
"  %19669 = add nuw nsw i32 %19667, %19668" -> "  %19707 = add nuw nsw i32 %19669, %19706"
"  %19670 = and i32 %19543, 65535"
"  %19670 = and i32 %19543, 65535" -> "  %19672 = add nuw nsw i32 %19671, %19670"
"  %19671 = and i32 %19532, 65535"
"  %19671 = and i32 %19532, 65535" -> "  %19672 = add nuw nsw i32 %19671, %19670"
"  %19672 = add nuw nsw i32 %19671, %19670"
"  %19672 = add nuw nsw i32 %19671, %19670" -> "  %19836 = and i32 %19672, 65535""  %19672 = add nuw nsw i32 %19671, %19670" -> "  %19676 = lshr i32 %19672, 16"
"  %19673 = and i32 %19552, 65535"
"  %19673 = and i32 %19552, 65535" -> "  %19675 = add nuw nsw i32 %19674, %19673"
"  %19674 = and i32 %19538, 65535"
"  %19674 = and i32 %19538, 65535" -> "  %19675 = add nuw nsw i32 %19674, %19673"
"  %19675 = add nuw nsw i32 %19674, %19673"
"  %19675 = add nuw nsw i32 %19674, %19673" -> "  %19689 = lshr i32 %19675, 16""  %19675 = add nuw nsw i32 %19674, %19673" -> "  %19677 = and i32 %19675, 65535"
"  %19676 = lshr i32 %19672, 16"
"  %19676 = lshr i32 %19672, 16" -> "  %19678 = add nuw nsw i32 %19677, %19676"
"  %19677 = and i32 %19675, 65535"
"  %19677 = and i32 %19675, 65535" -> "  %19678 = add nuw nsw i32 %19677, %19676"
"  %19678 = add nuw nsw i32 %19677, %19676"
"  %19678 = add nuw nsw i32 %19677, %19676" -> "  %19839 = and i32 %19678, 65535""  %19678 = add nuw nsw i32 %19677, %19676" -> "  %19691 = lshr i32 %19678, 16"
"  %19679 = and i32 %19612, 65535"
"  %19679 = and i32 %19612, 65535" -> "  %19681 = add nuw nsw i32 %19680, %19679"
"  %19680 = and i32 %19542, 65535"
"  %19680 = and i32 %19542, 65535" -> "  %19681 = add nuw nsw i32 %19680, %19679"
"  %19681 = add nuw nsw i32 %19680, %19679"
"  %19681 = add nuw nsw i32 %19680, %19679" -> "  %19688 = and i32 %19681, 65535""  %19681 = add nuw nsw i32 %19680, %19679" -> "  %19685 = lshr i32 %19681, 16"
"  %19682 = and i32 %19620, 65535"
"  %19682 = and i32 %19620, 65535" -> "  %19684 = add nuw nsw i32 %19683, %19682"
"  %19683 = lshr i32 %19542, 16"
"  %19683 = lshr i32 %19542, 16" -> "  %19684 = add nuw nsw i32 %19683, %19682"
"  %19684 = add nuw nsw i32 %19683, %19682"
"  %19684 = add nuw nsw i32 %19683, %19682" -> "  %19697 = lshr i32 %19684, 16""  %19684 = add nuw nsw i32 %19683, %19682" -> "  %19686 = and i32 %19684, 65535"
"  %19685 = lshr i32 %19681, 16"
"  %19685 = lshr i32 %19681, 16" -> "  %19687 = add nuw nsw i32 %19686, %19685"
"  %19686 = and i32 %19684, 65535"
"  %19686 = and i32 %19684, 65535" -> "  %19687 = add nuw nsw i32 %19686, %19685"
"  %19687 = add nuw nsw i32 %19686, %19685"
"  %19687 = add nuw nsw i32 %19686, %19685" -> "  %19699 = lshr i32 %19687, 16""  %19687 = add nuw nsw i32 %19686, %19685" -> "  %19694 = and i32 %19687, 65535"
"  %19688 = and i32 %19681, 65535"
"  %19688 = and i32 %19681, 65535" -> "  %19690 = add nuw nsw i32 %19688, %19689"
"  %19689 = lshr i32 %19675, 16"
"  %19689 = lshr i32 %19675, 16" -> "  %19690 = add nuw nsw i32 %19688, %19689"
"  %19690 = add nuw nsw i32 %19688, %19689"
"  %19690 = add nuw nsw i32 %19688, %19689" -> "  %19692 = add nuw nsw i32 %19690, %19691"
"  %19691 = lshr i32 %19678, 16"
"  %19691 = lshr i32 %19678, 16" -> "  %19692 = add nuw nsw i32 %19690, %19691"
"  %19692 = add nuw nsw i32 %19690, %19691"
"  %19692 = add nuw nsw i32 %19690, %19691" -> "  %19847 = and i32 %19692, 65535""  %19692 = add nuw nsw i32 %19690, %19691" -> "  %19693 = lshr i32 %19692, 16"
"  %19693 = lshr i32 %19692, 16"
"  %19693 = lshr i32 %19692, 16" -> "  %19695 = add nuw nsw i32 %19693, %19694"
"  %19694 = and i32 %19687, 65535"
"  %19694 = and i32 %19687, 65535" -> "  %19695 = add nuw nsw i32 %19693, %19694"
"  %19695 = add nuw nsw i32 %19693, %19694"
"  %19695 = add nuw nsw i32 %19693, %19694" -> "  %19850 = and i32 %19695, 65535""  %19695 = add nuw nsw i32 %19693, %19694" -> "  %19701 = lshr i32 %19695, 16"
"  %19696 = and i32 %19656, 65535"
"  %19696 = and i32 %19656, 65535" -> "  %19698 = add nuw nsw i32 %19696, %19697"
"  %19697 = lshr i32 %19684, 16"
"  %19697 = lshr i32 %19684, 16" -> "  %19698 = add nuw nsw i32 %19696, %19697"
"  %19698 = add nuw nsw i32 %19696, %19697"
"  %19698 = add nuw nsw i32 %19696, %19697" -> "  %19700 = add nuw nsw i32 %19698, %19699"
"  %19699 = lshr i32 %19687, 16"
"  %19699 = lshr i32 %19687, 16" -> "  %19700 = add nuw nsw i32 %19698, %19699"
"  %19700 = add nuw nsw i32 %19698, %19699"
"  %19700 = add nuw nsw i32 %19698, %19699" -> "  %19702 = add nuw nsw i32 %19700, %19701"
"  %19701 = lshr i32 %19695, 16"
"  %19701 = lshr i32 %19695, 16" -> "  %19702 = add nuw nsw i32 %19700, %19701"
"  %19702 = add nuw nsw i32 %19700, %19701"
"  %19702 = add nuw nsw i32 %19700, %19701" -> "  %20001 = and i32 %19702, 65535""  %19702 = add nuw nsw i32 %19700, %19701" -> "  %19704 = lshr i32 %19702, 16""  %19702 = add nuw nsw i32 %19700, %19701" -> "  store i32 %19702, i32* %1809, align 1, !noalias !65"
"  store i32 %19702, i32* %1809, align 1, !noalias !65"

"  %19703 = and i32 %19662, 65535"
"  %19703 = and i32 %19662, 65535" -> "  %19705 = add nuw nsw i32 %19704, %19703"
"  %19704 = lshr i32 %19702, 16"
"  %19704 = lshr i32 %19702, 16" -> "  %19705 = add nuw nsw i32 %19704, %19703"
"  %19705 = add nuw nsw i32 %19704, %19703"
"  %19705 = add nuw nsw i32 %19704, %19703" -> "  %20004 = and i32 %19705, 65535""  %19705 = add nuw nsw i32 %19704, %19703" -> "  %19706 = lshr i32 %19705, 16""  %19705 = add nuw nsw i32 %19704, %19703" -> "  store i32 %19705, i32* %1820, align 1, !noalias !65"
"  store i32 %19705, i32* %1820, align 1, !noalias !65"

"  %19706 = lshr i32 %19705, 16"
"  %19706 = lshr i32 %19705, 16" -> "  %19707 = add nuw nsw i32 %19669, %19706"
"  %19707 = add nuw nsw i32 %19669, %19706"
"  %19707 = add nuw nsw i32 %19669, %19706" -> "  %20010 = and i32 %19707, 65535""  %19707 = add nuw nsw i32 %19669, %19706" -> "  %20013 = lshr i32 %19707, 16"
"  %19708 = mul nuw nsw i32 %17915, 4087"
"  %19708 = mul nuw nsw i32 %17915, 4087" -> "  %19835 = and i32 %19708, 65535""  %19708 = mul nuw nsw i32 %17915, 4087" -> "  %19709 = lshr i32 %19708, 16""  %19708 = mul nuw nsw i32 %17915, 4087" -> "  store i32 %19708, i32* %2009, align 1, !noalias !65"
"  store i32 %19708, i32* %2009, align 1, !noalias !65"

"  %19709 = lshr i32 %19708, 16"
"  %19709 = lshr i32 %19708, 16" -> "  %19712 = add nuw nsw i32 %19711, %19709"
"  %19710 = mul nuw nsw i32 %17918, 4087"
"  %19710 = mul nuw nsw i32 %17918, 4087" -> "  %19713 = and i32 %19710, 268369920""  %19710 = mul nuw nsw i32 %17918, 4087" -> "  %19711 = and i32 %19710, 65535"
"  %19711 = and i32 %19710, 65535"
"  %19711 = and i32 %19710, 65535" -> "  %19712 = add nuw nsw i32 %19711, %19709"
"  %19712 = add nuw nsw i32 %19711, %19709"
"  %19712 = add nuw nsw i32 %19711, %19709" -> "  %19714 = add nuw nsw i32 %19712, %19713"
"  %19713 = and i32 %19710, 268369920"
"  %19713 = and i32 %19710, 268369920" -> "  %19714 = add nuw nsw i32 %19712, %19713"
"  %19714 = add nuw nsw i32 %19712, %19713"
"  %19714 = add nuw nsw i32 %19712, %19713" -> "  %19718 = lshr i32 %19714, 16""  %19714 = add nuw nsw i32 %19712, %19713" -> "  %19716 = and i32 %19714, 65535"
"  %19715 = mul nuw nsw i32 %17915, 11561"
"  %19715 = mul nuw nsw i32 %17915, 11561" -> "  %19717 = add nuw nsw i32 %19716, %19715"
"  %19716 = and i32 %19714, 65535"
"  %19716 = and i32 %19714, 65535" -> "  %19717 = add nuw nsw i32 %19716, %19715"
"  %19717 = add nuw nsw i32 %19716, %19715"
"  %19717 = add nuw nsw i32 %19716, %19715" -> "  %19838 = and i32 %19717, 65535""  %19717 = add nuw nsw i32 %19716, %19715" -> "  %19721 = lshr i32 %19717, 16"
"  %19718 = lshr i32 %19714, 16"
"  %19718 = lshr i32 %19714, 16" -> "  %19720 = add nuw nsw i32 %19718, %19719"
"  %19719 = mul nuw nsw i32 %17918, 11561"
"  %19719 = mul nuw nsw i32 %17918, 11561" -> "  %19720 = add nuw nsw i32 %19718, %19719"
"  %19720 = add nuw nsw i32 %19718, %19719"
"  %19720 = add nuw nsw i32 %19718, %19719" -> "  %19724 = and i32 %19720, 2147418112""  %19720 = add nuw nsw i32 %19718, %19719" -> "  %19722 = and i32 %19720, 65535"
"  %19721 = lshr i32 %19717, 16"
"  %19721 = lshr i32 %19717, 16" -> "  %19723 = add nuw nsw i32 %19721, %19722"
"  %19722 = and i32 %19720, 65535"
"  %19722 = and i32 %19720, 65535" -> "  %19723 = add nuw nsw i32 %19721, %19722"
"  %19723 = add nuw nsw i32 %19721, %19722"
"  %19723 = add nuw nsw i32 %19721, %19722" -> "  %19725 = add nuw nsw i32 %19723, %19724"
"  %19724 = and i32 %19720, 2147418112"
"  %19724 = and i32 %19720, 2147418112" -> "  %19725 = add nuw nsw i32 %19723, %19724"
"  %19725 = add nuw nsw i32 %19723, %19724"
"  %19725 = add nuw nsw i32 %19723, %19724" -> "  %19748 = lshr i32 %19725, 16""  %19725 = add nuw nsw i32 %19723, %19724" -> "  %19744 = and i32 %19725, 65535"
"  %19726 = mul nuw nsw i32 %17935, 4087"
"  %19726 = mul nuw nsw i32 %17935, 4087" -> "  %19745 = and i32 %19726, 65535""  %19726 = mul nuw nsw i32 %17935, 4087" -> "  %19727 = lshr i32 %19726, 16"
"  %19727 = lshr i32 %19726, 16"
"  %19727 = lshr i32 %19726, 16" -> "  %19730 = add nuw nsw i32 %19729, %19727"
"  %19728 = mul nuw nsw i32 %17938, 4087"
"  %19728 = mul nuw nsw i32 %17938, 4087" -> "  %19731 = and i32 %19728, 268369920""  %19728 = mul nuw nsw i32 %17938, 4087" -> "  %19729 = and i32 %19728, 65535"
"  %19729 = and i32 %19728, 65535"
"  %19729 = and i32 %19728, 65535" -> "  %19730 = add nuw nsw i32 %19729, %19727"
"  %19730 = add nuw nsw i32 %19729, %19727"
"  %19730 = add nuw nsw i32 %19729, %19727" -> "  %19732 = add nuw nsw i32 %19730, %19731"
"  %19731 = and i32 %19728, 268369920"
"  %19731 = and i32 %19728, 268369920" -> "  %19732 = add nuw nsw i32 %19730, %19731"
"  %19732 = add nuw nsw i32 %19730, %19731"
"  %19732 = add nuw nsw i32 %19730, %19731" -> "  %19736 = lshr i32 %19732, 16""  %19732 = add nuw nsw i32 %19730, %19731" -> "  %19734 = and i32 %19732, 65535"
"  %19733 = mul nuw nsw i32 %17935, 11561"
"  %19733 = mul nuw nsw i32 %17935, 11561" -> "  %19735 = add nuw nsw i32 %19734, %19733"
"  %19734 = and i32 %19732, 65535"
"  %19734 = and i32 %19732, 65535" -> "  %19735 = add nuw nsw i32 %19734, %19733"
"  %19735 = add nuw nsw i32 %19734, %19733"
"  %19735 = add nuw nsw i32 %19734, %19733" -> "  %19747 = and i32 %19735, 65535""  %19735 = add nuw nsw i32 %19734, %19733" -> "  %19739 = lshr i32 %19735, 16"
"  %19736 = lshr i32 %19732, 16"
"  %19736 = lshr i32 %19732, 16" -> "  %19738 = add nuw nsw i32 %19736, %19737"
"  %19737 = mul nuw nsw i32 %17938, 11561"
"  %19737 = mul nuw nsw i32 %17938, 11561" -> "  %19738 = add nuw nsw i32 %19736, %19737"
"  %19738 = add nuw nsw i32 %19736, %19737"
"  %19738 = add nuw nsw i32 %19736, %19737" -> "  %19742 = and i32 %19738, 2147418112""  %19738 = add nuw nsw i32 %19736, %19737" -> "  %19740 = and i32 %19738, 65535"
"  %19739 = lshr i32 %19735, 16"
"  %19739 = lshr i32 %19735, 16" -> "  %19741 = add nuw nsw i32 %19739, %19740"
"  %19740 = and i32 %19738, 65535"
"  %19740 = and i32 %19738, 65535" -> "  %19741 = add nuw nsw i32 %19739, %19740"
"  %19741 = add nuw nsw i32 %19739, %19740"
"  %19741 = add nuw nsw i32 %19739, %19740" -> "  %19743 = add nuw nsw i32 %19741, %19742"
"  %19742 = and i32 %19738, 2147418112"
"  %19742 = and i32 %19738, 2147418112" -> "  %19743 = add nuw nsw i32 %19741, %19742"
"  %19743 = add nuw nsw i32 %19741, %19742"
"  %19743 = add nuw nsw i32 %19741, %19742" -> "  %19751 = add nuw nsw i32 %19743, %19750"
"  %19744 = and i32 %19725, 65535"
"  %19744 = and i32 %19725, 65535" -> "  %19746 = add nuw nsw i32 %19744, %19745"
"  %19745 = and i32 %19726, 65535"
"  %19745 = and i32 %19726, 65535" -> "  %19746 = add nuw nsw i32 %19744, %19745"
"  %19746 = add nuw nsw i32 %19744, %19745"
"  %19746 = add nuw nsw i32 %19744, %19745" -> "  %19775 = and i32 %19746, 65535""  %19746 = add nuw nsw i32 %19744, %19745" -> "  %19753 = lshr i32 %19746, 16"
"  %19747 = and i32 %19735, 65535"
"  %19747 = and i32 %19735, 65535" -> "  %19749 = add nuw nsw i32 %19747, %19748"
"  %19748 = lshr i32 %19725, 16"
"  %19748 = lshr i32 %19725, 16" -> "  %19749 = add nuw nsw i32 %19747, %19748"
"  %19749 = add nuw nsw i32 %19747, %19748"
"  %19749 = add nuw nsw i32 %19747, %19748" -> "  %19752 = and i32 %19749, 65535""  %19749 = add nuw nsw i32 %19747, %19748" -> "  %19750 = lshr i32 %19749, 16"
"  %19750 = lshr i32 %19749, 16"
"  %19750 = lshr i32 %19749, 16" -> "  %19751 = add nuw nsw i32 %19743, %19750"
"  %19751 = add nuw nsw i32 %19743, %19750"
"  %19751 = add nuw nsw i32 %19743, %19750" -> "  %19756 = add nuw nsw i32 %19751, %19755"
"  %19752 = and i32 %19749, 65535"
"  %19752 = and i32 %19749, 65535" -> "  %19754 = add nuw nsw i32 %19752, %19753"
"  %19753 = lshr i32 %19746, 16"
"  %19753 = lshr i32 %19746, 16" -> "  %19754 = add nuw nsw i32 %19752, %19753"
"  %19754 = add nuw nsw i32 %19752, %19753"
"  %19754 = add nuw nsw i32 %19752, %19753" -> "  %19779 = and i32 %19754, 65535""  %19754 = add nuw nsw i32 %19752, %19753" -> "  %19755 = lshr i32 %19754, 16"
"  %19755 = lshr i32 %19754, 16"
"  %19755 = lshr i32 %19754, 16" -> "  %19756 = add nuw nsw i32 %19751, %19755"
"  %19756 = add nuw nsw i32 %19751, %19755"
"  %19756 = add nuw nsw i32 %19751, %19755" -> "  %19806 = and i32 %19756, 65535""  %19756 = add nuw nsw i32 %19751, %19755" -> "  %19810 = lshr i32 %19756, 16"
"  %19757 = mul nuw nsw i32 %17915, 21884"
"  %19757 = mul nuw nsw i32 %17915, 21884" -> "  %19776 = and i32 %19757, 65532""  %19757 = mul nuw nsw i32 %17915, 21884" -> "  %19758 = lshr i32 %19757, 16"
"  %19758 = lshr i32 %19757, 16"
"  %19758 = lshr i32 %19757, 16" -> "  %19761 = add nuw nsw i32 %19760, %19758"
"  %19759 = mul nuw nsw i32 %17918, 21884"
"  %19759 = mul nuw nsw i32 %17918, 21884" -> "  %19762 = and i32 %19759, 2147418112""  %19759 = mul nuw nsw i32 %17918, 21884" -> "  %19760 = and i32 %19759, 65532"
"  %19760 = and i32 %19759, 65532"
"  %19760 = and i32 %19759, 65532" -> "  %19761 = add nuw nsw i32 %19760, %19758"
"  %19761 = add nuw nsw i32 %19760, %19758"
"  %19761 = add nuw nsw i32 %19760, %19758" -> "  %19763 = add nuw nsw i32 %19761, %19762"
"  %19762 = and i32 %19759, 2147418112"
"  %19762 = and i32 %19759, 2147418112" -> "  %19763 = add nuw nsw i32 %19761, %19762"
"  %19763 = add nuw nsw i32 %19761, %19762"
"  %19763 = add nuw nsw i32 %19761, %19762" -> "  %19765 = and i32 %19763, 65535""  %19763 = add nuw nsw i32 %19761, %19762" -> "  %19767 = lshr i32 %19763, 16"
"  %19764 = mul nuw i32 %17915, 36786"
"  %19764 = mul nuw i32 %17915, 36786" -> "  %19766 = add nuw i32 %19765, %19764"
"  %19765 = and i32 %19763, 65535"
"  %19765 = and i32 %19763, 65535" -> "  %19766 = add nuw i32 %19765, %19764"
"  %19766 = add nuw i32 %19765, %19764"
"  %19766 = add nuw i32 %19765, %19764" -> "  %19778 = and i32 %19766, 65535""  %19766 = add nuw i32 %19765, %19764" -> "  %19770 = lshr i32 %19766, 16"
"  %19767 = lshr i32 %19763, 16"
"  %19767 = lshr i32 %19763, 16" -> "  %19769 = add nuw i32 %19767, %19768"
"  %19768 = mul nuw i32 %17918, 36786"
"  %19768 = mul nuw i32 %17918, 36786" -> "  %19769 = add nuw i32 %19767, %19768"
"  %19769 = add nuw i32 %19767, %19768"
"  %19769 = add nuw i32 %19767, %19768" -> "  %19773 = and i32 %19769, -65536""  %19769 = add nuw i32 %19767, %19768" -> "  %19771 = and i32 %19769, 65535"
"  %19770 = lshr i32 %19766, 16"
"  %19770 = lshr i32 %19766, 16" -> "  %19772 = add nuw nsw i32 %19771, %19770"
"  %19771 = and i32 %19769, 65535"
"  %19771 = and i32 %19769, 65535" -> "  %19772 = add nuw nsw i32 %19771, %19770"
"  %19772 = add nuw nsw i32 %19771, %19770"
"  %19772 = add nuw nsw i32 %19771, %19770" -> "  %19774 = add nuw i32 %19772, %19773"
"  %19773 = and i32 %19769, -65536"
"  %19773 = and i32 %19769, -65536" -> "  %19774 = add nuw i32 %19772, %19773"
"  %19774 = add nuw i32 %19772, %19773"
"  %19774 = add nuw i32 %19772, %19773" -> "  %19782 = add nuw i32 %19774, %19781"
"  %19775 = and i32 %19746, 65535"
"  %19775 = and i32 %19746, 65535" -> "  %19777 = add nuw nsw i32 %19775, %19776"
"  %19776 = and i32 %19757, 65532"
"  %19776 = and i32 %19757, 65532" -> "  %19777 = add nuw nsw i32 %19775, %19776"
"  %19777 = add nuw nsw i32 %19775, %19776"
"  %19777 = add nuw nsw i32 %19775, %19776" -> "  %19846 = and i32 %19777, 65535""  %19777 = add nuw nsw i32 %19775, %19776" -> "  %19784 = lshr i32 %19777, 16"
"  %19778 = and i32 %19766, 65535"
"  %19778 = and i32 %19766, 65535" -> "  %19780 = add nuw nsw i32 %19779, %19778"
"  %19779 = and i32 %19754, 65535"
"  %19779 = and i32 %19754, 65535" -> "  %19780 = add nuw nsw i32 %19779, %19778"
"  %19780 = add nuw nsw i32 %19779, %19778"
"  %19780 = add nuw nsw i32 %19779, %19778" -> "  %19783 = and i32 %19780, 65535""  %19780 = add nuw nsw i32 %19779, %19778" -> "  %19781 = lshr i32 %19780, 16"
"  %19781 = lshr i32 %19780, 16"
"  %19781 = lshr i32 %19780, 16" -> "  %19782 = add nuw i32 %19774, %19781"
"  %19782 = add nuw i32 %19774, %19781"
"  %19782 = add nuw i32 %19774, %19781" -> "  %19787 = add nuw i32 %19782, %19786"
"  %19783 = and i32 %19780, 65535"
"  %19783 = and i32 %19780, 65535" -> "  %19785 = add nuw nsw i32 %19783, %19784"
"  %19784 = lshr i32 %19777, 16"
"  %19784 = lshr i32 %19777, 16" -> "  %19785 = add nuw nsw i32 %19783, %19784"
"  %19785 = add nuw nsw i32 %19783, %19784"
"  %19785 = add nuw nsw i32 %19783, %19784" -> "  %19849 = and i32 %19785, 65535""  %19785 = add nuw nsw i32 %19783, %19784" -> "  %19786 = lshr i32 %19785, 16"
"  %19786 = lshr i32 %19785, 16"
"  %19786 = lshr i32 %19785, 16" -> "  %19787 = add nuw i32 %19782, %19786"
"  %19787 = add nuw i32 %19782, %19786"
"  %19787 = add nuw i32 %19782, %19786" -> "  %19823 = lshr i32 %19787, 16""  %19787 = add nuw i32 %19782, %19786" -> "  %19820 = and i32 %19787, 65535"
"  %19788 = mul nuw nsw i32 %17935, 21884"
"  %19788 = mul nuw nsw i32 %17935, 21884" -> "  %19807 = and i32 %19788, 65532""  %19788 = mul nuw nsw i32 %17935, 21884" -> "  %19789 = lshr i32 %19788, 16"
"  %19789 = lshr i32 %19788, 16"
"  %19789 = lshr i32 %19788, 16" -> "  %19792 = add nuw nsw i32 %19791, %19789"
"  %19790 = mul nuw nsw i32 %17938, 21884"
"  %19790 = mul nuw nsw i32 %17938, 21884" -> "  %19793 = and i32 %19790, 2147418112""  %19790 = mul nuw nsw i32 %17938, 21884" -> "  %19791 = and i32 %19790, 65532"
"  %19791 = and i32 %19790, 65532"
"  %19791 = and i32 %19790, 65532" -> "  %19792 = add nuw nsw i32 %19791, %19789"
"  %19792 = add nuw nsw i32 %19791, %19789"
"  %19792 = add nuw nsw i32 %19791, %19789" -> "  %19794 = add nuw nsw i32 %19792, %19793"
"  %19793 = and i32 %19790, 2147418112"
"  %19793 = and i32 %19790, 2147418112" -> "  %19794 = add nuw nsw i32 %19792, %19793"
"  %19794 = add nuw nsw i32 %19792, %19793"
"  %19794 = add nuw nsw i32 %19792, %19793" -> "  %19798 = lshr i32 %19794, 16""  %19794 = add nuw nsw i32 %19792, %19793" -> "  %19796 = and i32 %19794, 65535"
"  %19795 = mul nuw i32 %17935, 36786"
"  %19795 = mul nuw i32 %17935, 36786" -> "  %19797 = add nuw i32 %19796, %19795"
"  %19796 = and i32 %19794, 65535"
"  %19796 = and i32 %19794, 65535" -> "  %19797 = add nuw i32 %19796, %19795"
"  %19797 = add nuw i32 %19796, %19795"
"  %19797 = add nuw i32 %19796, %19795" -> "  %19809 = and i32 %19797, 65535""  %19797 = add nuw i32 %19796, %19795" -> "  %19801 = lshr i32 %19797, 16"
"  %19798 = lshr i32 %19794, 16"
"  %19798 = lshr i32 %19794, 16" -> "  %19800 = add nuw i32 %19798, %19799"
"  %19799 = mul nuw i32 %17938, 36786"
"  %19799 = mul nuw i32 %17938, 36786" -> "  %19800 = add nuw i32 %19798, %19799"
"  %19800 = add nuw i32 %19798, %19799"
"  %19800 = add nuw i32 %19798, %19799" -> "  %19804 = and i32 %19800, -65536""  %19800 = add nuw i32 %19798, %19799" -> "  %19802 = and i32 %19800, 65535"
"  %19801 = lshr i32 %19797, 16"
"  %19801 = lshr i32 %19797, 16" -> "  %19803 = add nuw nsw i32 %19801, %19802"
"  %19802 = and i32 %19800, 65535"
"  %19802 = and i32 %19800, 65535" -> "  %19803 = add nuw nsw i32 %19801, %19802"
"  %19803 = add nuw nsw i32 %19801, %19802"
"  %19803 = add nuw nsw i32 %19801, %19802" -> "  %19805 = add nuw i32 %19803, %19804"
"  %19804 = and i32 %19800, -65536"
"  %19804 = and i32 %19800, -65536" -> "  %19805 = add nuw i32 %19803, %19804"
"  %19805 = add nuw i32 %19803, %19804"
"  %19805 = add nuw i32 %19803, %19804" -> "  %19813 = add nuw i32 %19805, %19812"
"  %19806 = and i32 %19756, 65535"
"  %19806 = and i32 %19756, 65535" -> "  %19808 = add nuw nsw i32 %19806, %19807"
"  %19807 = and i32 %19788, 65532"
"  %19807 = and i32 %19788, 65532" -> "  %19808 = add nuw nsw i32 %19806, %19807"
"  %19808 = add nuw nsw i32 %19806, %19807"
"  %19808 = add nuw nsw i32 %19806, %19807" -> "  %19819 = and i32 %19808, 65535""  %19808 = add nuw nsw i32 %19806, %19807" -> "  %19815 = lshr i32 %19808, 16"
"  %19809 = and i32 %19797, 65535"
"  %19809 = and i32 %19797, 65535" -> "  %19811 = add nuw nsw i32 %19810, %19809"
"  %19810 = lshr i32 %19756, 16"
"  %19810 = lshr i32 %19756, 16" -> "  %19811 = add nuw nsw i32 %19810, %19809"
"  %19811 = add nuw nsw i32 %19810, %19809"
"  %19811 = add nuw nsw i32 %19810, %19809" -> "  %19814 = and i32 %19811, 65535""  %19811 = add nuw nsw i32 %19810, %19809" -> "  %19812 = lshr i32 %19811, 16"
"  %19812 = lshr i32 %19811, 16"
"  %19812 = lshr i32 %19811, 16" -> "  %19813 = add nuw i32 %19805, %19812"
"  %19813 = add nuw i32 %19805, %19812"
"  %19813 = add nuw i32 %19805, %19812" -> "  %19818 = add nuw i32 %19813, %19817"
"  %19814 = and i32 %19811, 65535"
"  %19814 = and i32 %19811, 65535" -> "  %19816 = add nuw nsw i32 %19814, %19815"
"  %19815 = lshr i32 %19808, 16"
"  %19815 = lshr i32 %19808, 16" -> "  %19816 = add nuw nsw i32 %19814, %19815"
"  %19816 = add nuw nsw i32 %19814, %19815"
"  %19816 = add nuw nsw i32 %19814, %19815" -> "  %19822 = and i32 %19816, 65535""  %19816 = add nuw nsw i32 %19814, %19815" -> "  %19817 = lshr i32 %19816, 16"
"  %19817 = lshr i32 %19816, 16"
"  %19817 = lshr i32 %19816, 16" -> "  %19818 = add nuw i32 %19813, %19817"
"  %19818 = add nuw i32 %19813, %19817"
"  %19818 = add nuw i32 %19813, %19817" -> "  %19831 = and i32 %19818, -65536""  %19818 = add nuw i32 %19813, %19817" -> "  %19829 = and i32 %19818, 65535"
"  %19819 = and i32 %19808, 65535"
"  %19819 = and i32 %19808, 65535" -> "  %19821 = add nuw nsw i32 %19820, %19819"
"  %19820 = and i32 %19787, 65535"
"  %19820 = and i32 %19787, 65535" -> "  %19821 = add nuw nsw i32 %19820, %19819"
"  %19821 = add nuw nsw i32 %19820, %19819"
"  %19821 = add nuw nsw i32 %19820, %19819" -> "  %19861 = and i32 %19821, 65535""  %19821 = add nuw nsw i32 %19820, %19819" -> "  %19825 = lshr i32 %19821, 16"
"  %19822 = and i32 %19816, 65535"
"  %19822 = and i32 %19816, 65535" -> "  %19824 = add nuw nsw i32 %19822, %19823"
"  %19823 = lshr i32 %19787, 16"
"  %19823 = lshr i32 %19787, 16" -> "  %19824 = add nuw nsw i32 %19822, %19823"
"  %19824 = add nuw nsw i32 %19822, %19823"
"  %19824 = add nuw nsw i32 %19822, %19823" -> "  %19828 = lshr i32 %19824, 16""  %19824 = add nuw nsw i32 %19822, %19823" -> "  %19826 = and i32 %19824, 65535"
"  %19825 = lshr i32 %19821, 16"
"  %19825 = lshr i32 %19821, 16" -> "  %19827 = add nuw nsw i32 %19826, %19825"
"  %19826 = and i32 %19824, 65535"
"  %19826 = and i32 %19824, 65535" -> "  %19827 = add nuw nsw i32 %19826, %19825"
"  %19827 = add nuw nsw i32 %19826, %19825"
"  %19827 = add nuw nsw i32 %19826, %19825" -> "  %19868 = and i32 %19827, 65535""  %19827 = add nuw nsw i32 %19826, %19825" -> "  %19833 = lshr i32 %19827, 16"
"  %19828 = lshr i32 %19824, 16"
"  %19828 = lshr i32 %19824, 16" -> "  %19830 = add nuw nsw i32 %19828, %19829"
"  %19829 = and i32 %19818, 65535"
"  %19829 = and i32 %19818, 65535" -> "  %19830 = add nuw nsw i32 %19828, %19829"
"  %19830 = add nuw nsw i32 %19828, %19829"
"  %19830 = add nuw nsw i32 %19828, %19829" -> "  %19832 = add nuw i32 %19830, %19831"
"  %19831 = and i32 %19818, -65536"
"  %19831 = and i32 %19818, -65536" -> "  %19832 = add nuw i32 %19830, %19831"
"  %19832 = add nuw i32 %19830, %19831"
"  %19832 = add nuw i32 %19830, %19831" -> "  %19834 = add nuw i32 %19832, %19833"
"  %19833 = lshr i32 %19827, 16"
"  %19833 = lshr i32 %19827, 16" -> "  %19834 = add nuw i32 %19832, %19833"
"  %19834 = add nuw i32 %19832, %19833"
"  %19834 = add nuw i32 %19832, %19833" -> "  %19872 = add nuw i32 %19834, %19871"
"  %19835 = and i32 %19708, 65535"
"  %19835 = and i32 %19708, 65535" -> "  %19837 = add nuw nsw i32 %19836, %19835"
"  %19836 = and i32 %19672, 65535"
"  %19836 = and i32 %19672, 65535" -> "  %19837 = add nuw nsw i32 %19836, %19835"
"  %19837 = add nuw nsw i32 %19836, %19835"
"  %19837 = add nuw nsw i32 %19836, %19835" -> "  %20103 = and i32 %19837, 65535""  %19837 = add nuw nsw i32 %19836, %19835" -> "  %19841 = lshr i32 %19837, 16"
"  %19838 = and i32 %19717, 65535"
"  %19838 = and i32 %19717, 65535" -> "  %19840 = add nuw nsw i32 %19839, %19838"
"  %19839 = and i32 %19678, 65535"
"  %19839 = and i32 %19678, 65535" -> "  %19840 = add nuw nsw i32 %19839, %19838"
"  %19840 = add nuw nsw i32 %19839, %19838"
"  %19840 = add nuw nsw i32 %19839, %19838" -> "  %19844 = lshr i32 %19840, 16""  %19840 = add nuw nsw i32 %19839, %19838" -> "  %19842 = and i32 %19840, 65535"
"  %19841 = lshr i32 %19837, 16"
"  %19841 = lshr i32 %19837, 16" -> "  %19843 = add nuw nsw i32 %19842, %19841"
"  %19842 = and i32 %19840, 65535"
"  %19842 = and i32 %19840, 65535" -> "  %19843 = add nuw nsw i32 %19842, %19841"
"  %19843 = add nuw nsw i32 %19842, %19841"
"  %19843 = add nuw nsw i32 %19842, %19841" -> "  %20106 = and i32 %19843, 65535""  %19843 = add nuw nsw i32 %19842, %19841" -> "  %19845 = lshr i32 %19843, 16"
"  %19844 = lshr i32 %19840, 16"
"  %19844 = lshr i32 %19840, 16" -> "  %19856 = add nuw nsw i32 %19845, %19844"
"  %19845 = lshr i32 %19843, 16"
"  %19845 = lshr i32 %19843, 16" -> "  %19856 = add nuw nsw i32 %19845, %19844"
"  %19846 = and i32 %19777, 65535"
"  %19846 = and i32 %19777, 65535" -> "  %19848 = add nuw nsw i32 %19847, %19846"
"  %19847 = and i32 %19692, 65535"
"  %19847 = and i32 %19692, 65535" -> "  %19848 = add nuw nsw i32 %19847, %19846"
"  %19848 = add nuw nsw i32 %19847, %19846"
"  %19848 = add nuw nsw i32 %19847, %19846" -> "  %19855 = and i32 %19848, 65535""  %19848 = add nuw nsw i32 %19847, %19846" -> "  %19852 = lshr i32 %19848, 16"
"  %19849 = and i32 %19785, 65535"
"  %19849 = and i32 %19785, 65535" -> "  %19851 = add nuw nsw i32 %19850, %19849"
"  %19850 = and i32 %19695, 65535"
"  %19850 = and i32 %19695, 65535" -> "  %19851 = add nuw nsw i32 %19850, %19849"
"  %19851 = add nuw nsw i32 %19850, %19849"
"  %19851 = add nuw nsw i32 %19850, %19849" -> "  %19862 = lshr i32 %19851, 16""  %19851 = add nuw nsw i32 %19850, %19849" -> "  %19853 = and i32 %19851, 65535"
"  %19852 = lshr i32 %19848, 16"
"  %19852 = lshr i32 %19848, 16" -> "  %19854 = add nuw nsw i32 %19853, %19852"
"  %19853 = and i32 %19851, 65535"
"  %19853 = and i32 %19851, 65535" -> "  %19854 = add nuw nsw i32 %19853, %19852"
"  %19854 = add nuw nsw i32 %19853, %19852"
"  %19854 = add nuw nsw i32 %19853, %19852" -> "  %19864 = lshr i32 %19854, 16""  %19854 = add nuw nsw i32 %19853, %19852" -> "  %19859 = and i32 %19854, 65535"
"  %19855 = and i32 %19848, 65535"
"  %19855 = and i32 %19848, 65535" -> "  %19857 = add nuw nsw i32 %19856, %19855"
"  %19856 = add nuw nsw i32 %19845, %19844"
"  %19856 = add nuw nsw i32 %19845, %19844" -> "  %19857 = add nuw nsw i32 %19856, %19855"
"  %19857 = add nuw nsw i32 %19856, %19855"
"  %19857 = add nuw nsw i32 %19856, %19855" -> "  %20112 = and i32 %19857, 65535""  %19857 = add nuw nsw i32 %19856, %19855" -> "  %19858 = lshr i32 %19857, 16"
"  %19858 = lshr i32 %19857, 16"
"  %19858 = lshr i32 %19857, 16" -> "  %19860 = add nuw nsw i32 %19859, %19858"
"  %19859 = and i32 %19854, 65535"
"  %19859 = and i32 %19854, 65535" -> "  %19860 = add nuw nsw i32 %19859, %19858"
"  %19860 = add nuw nsw i32 %19859, %19858"
"  %19860 = add nuw nsw i32 %19859, %19858" -> "  %20115 = and i32 %19860, 65535""  %19860 = add nuw nsw i32 %19859, %19858" -> "  %19866 = lshr i32 %19860, 16""  %19860 = add nuw nsw i32 %19859, %19858" -> "  store i32 %19860, i32* %267, align 1, !noalias !68"
"  store i32 %19860, i32* %267, align 1, !noalias !68"

"  %19861 = and i32 %19821, 65535"
"  %19861 = and i32 %19821, 65535" -> "  %19863 = add nuw nsw i32 %19862, %19861"
"  %19862 = lshr i32 %19851, 16"
"  %19862 = lshr i32 %19851, 16" -> "  %19863 = add nuw nsw i32 %19862, %19861"
"  %19863 = add nuw nsw i32 %19862, %19861"
"  %19863 = add nuw nsw i32 %19862, %19861" -> "  %19865 = add nuw nsw i32 %19863, %19864"
"  %19864 = lshr i32 %19854, 16"
"  %19864 = lshr i32 %19854, 16" -> "  %19865 = add nuw nsw i32 %19863, %19864"
"  %19865 = add nuw nsw i32 %19863, %19864"
"  %19865 = add nuw nsw i32 %19863, %19864" -> "  %19867 = add nuw nsw i32 %19865, %19866"
"  %19866 = lshr i32 %19860, 16"
"  %19866 = lshr i32 %19860, 16" -> "  %19867 = add nuw nsw i32 %19865, %19866"
"  %19867 = add nuw nsw i32 %19865, %19866"
"  %19867 = add nuw nsw i32 %19865, %19866" -> "  %20039 = and i32 %19867, 65535""  %19867 = add nuw nsw i32 %19865, %19866" -> "  %19869 = lshr i32 %19867, 16"
"  %19868 = and i32 %19827, 65535"
"  %19868 = and i32 %19827, 65535" -> "  %19870 = add nuw nsw i32 %19869, %19868"
"  %19869 = lshr i32 %19867, 16"
"  %19869 = lshr i32 %19867, 16" -> "  %19870 = add nuw nsw i32 %19869, %19868"
"  %19870 = add nuw nsw i32 %19869, %19868"
"  %19870 = add nuw nsw i32 %19869, %19868" -> "  %20042 = and i32 %19870, 65535""  %19870 = add nuw nsw i32 %19869, %19868" -> "  %19871 = lshr i32 %19870, 16"
"  %19871 = lshr i32 %19870, 16"
"  %19871 = lshr i32 %19870, 16" -> "  %19872 = add nuw i32 %19834, %19871"
"  %19872 = add nuw i32 %19834, %19871"
"  %19872 = add nuw i32 %19834, %19871" -> "  %20048 = and i32 %19872, 65535""  %19872 = add nuw i32 %19834, %19871" -> "  %20051 = lshr i32 %19872, 16""  %19872 = add nuw i32 %19834, %19871" -> "  store i32 %19872, i32* %1877, align 1, !noalias !68"
"  store i32 %19872, i32* %1877, align 1, !noalias !68"

"  %19873 = mul nuw nsw i32 %18049, 4087"
"  %19873 = mul nuw nsw i32 %18049, 4087" -> "  %20000 = and i32 %19873, 65535""  %19873 = mul nuw nsw i32 %18049, 4087" -> "  %19874 = lshr i32 %19873, 16""  %19873 = mul nuw nsw i32 %18049, 4087" -> "  store i32 %19873, i32* %2045, align 1, !noalias !68"
"  store i32 %19873, i32* %2045, align 1, !noalias !68"

"  %19874 = lshr i32 %19873, 16"
"  %19874 = lshr i32 %19873, 16" -> "  %19877 = add nuw nsw i32 %19876, %19874"
"  %19875 = mul nuw nsw i32 %18050, 4087"
"  %19875 = mul nuw nsw i32 %18050, 4087" -> "  %19878 = and i32 %19875, 268369920""  %19875 = mul nuw nsw i32 %18050, 4087" -> "  %19876 = and i32 %19875, 65535"
"  %19876 = and i32 %19875, 65535"
"  %19876 = and i32 %19875, 65535" -> "  %19877 = add nuw nsw i32 %19876, %19874"
"  %19877 = add nuw nsw i32 %19876, %19874"
"  %19877 = add nuw nsw i32 %19876, %19874" -> "  %19879 = add nuw nsw i32 %19877, %19878"
"  %19878 = and i32 %19875, 268369920"
"  %19878 = and i32 %19875, 268369920" -> "  %19879 = add nuw nsw i32 %19877, %19878"
"  %19879 = add nuw nsw i32 %19877, %19878"
"  %19879 = add nuw nsw i32 %19877, %19878" -> "  %19883 = lshr i32 %19879, 16""  %19879 = add nuw nsw i32 %19877, %19878" -> "  %19881 = and i32 %19879, 65535"
"  %19880 = mul nuw nsw i32 %18049, 11561"
"  %19880 = mul nuw nsw i32 %18049, 11561" -> "  %19882 = add nuw nsw i32 %19881, %19880"
"  %19881 = and i32 %19879, 65535"
"  %19881 = and i32 %19879, 65535" -> "  %19882 = add nuw nsw i32 %19881, %19880"
"  %19882 = add nuw nsw i32 %19881, %19880"
"  %19882 = add nuw nsw i32 %19881, %19880" -> "  %20003 = and i32 %19882, 65535""  %19882 = add nuw nsw i32 %19881, %19880" -> "  %19886 = lshr i32 %19882, 16"
"  %19883 = lshr i32 %19879, 16"
"  %19883 = lshr i32 %19879, 16" -> "  %19885 = add nuw nsw i32 %19883, %19884"
"  %19884 = mul nuw nsw i32 %18050, 11561"
"  %19884 = mul nuw nsw i32 %18050, 11561" -> "  %19885 = add nuw nsw i32 %19883, %19884"
"  %19885 = add nuw nsw i32 %19883, %19884"
"  %19885 = add nuw nsw i32 %19883, %19884" -> "  %19889 = and i32 %19885, 2147418112""  %19885 = add nuw nsw i32 %19883, %19884" -> "  %19887 = and i32 %19885, 65535"
"  %19886 = lshr i32 %19882, 16"
"  %19886 = lshr i32 %19882, 16" -> "  %19888 = add nuw nsw i32 %19886, %19887"
"  %19887 = and i32 %19885, 65535"
"  %19887 = and i32 %19885, 65535" -> "  %19888 = add nuw nsw i32 %19886, %19887"
"  %19888 = add nuw nsw i32 %19886, %19887"
"  %19888 = add nuw nsw i32 %19886, %19887" -> "  %19890 = add nuw nsw i32 %19888, %19889"
"  %19889 = and i32 %19885, 2147418112"
"  %19889 = and i32 %19885, 2147418112" -> "  %19890 = add nuw nsw i32 %19888, %19889"
"  %19890 = add nuw nsw i32 %19888, %19889"
"  %19890 = add nuw nsw i32 %19888, %19889" -> "  %19913 = lshr i32 %19890, 16""  %19890 = add nuw nsw i32 %19888, %19889" -> "  %19909 = and i32 %19890, 65535"
"  %19891 = mul nuw nsw i32 %18069, 4087"
"  %19891 = mul nuw nsw i32 %18069, 4087" -> "  %19910 = and i32 %19891, 65535""  %19891 = mul nuw nsw i32 %18069, 4087" -> "  %19892 = lshr i32 %19891, 16"
"  %19892 = lshr i32 %19891, 16"
"  %19892 = lshr i32 %19891, 16" -> "  %19895 = add nuw nsw i32 %19894, %19892"
"  %19893 = mul nuw nsw i32 %18070, 4087"
"  %19893 = mul nuw nsw i32 %18070, 4087" -> "  %19896 = and i32 %19893, 268369920""  %19893 = mul nuw nsw i32 %18070, 4087" -> "  %19894 = and i32 %19893, 65535"
"  %19894 = and i32 %19893, 65535"
"  %19894 = and i32 %19893, 65535" -> "  %19895 = add nuw nsw i32 %19894, %19892"
"  %19895 = add nuw nsw i32 %19894, %19892"
"  %19895 = add nuw nsw i32 %19894, %19892" -> "  %19897 = add nuw nsw i32 %19895, %19896"
"  %19896 = and i32 %19893, 268369920"
"  %19896 = and i32 %19893, 268369920" -> "  %19897 = add nuw nsw i32 %19895, %19896"
"  %19897 = add nuw nsw i32 %19895, %19896"
"  %19897 = add nuw nsw i32 %19895, %19896" -> "  %19901 = lshr i32 %19897, 16""  %19897 = add nuw nsw i32 %19895, %19896" -> "  %19899 = and i32 %19897, 65535"
"  %19898 = mul nuw nsw i32 %18069, 11561"
"  %19898 = mul nuw nsw i32 %18069, 11561" -> "  %19900 = add nuw nsw i32 %19899, %19898"
"  %19899 = and i32 %19897, 65535"
"  %19899 = and i32 %19897, 65535" -> "  %19900 = add nuw nsw i32 %19899, %19898"
"  %19900 = add nuw nsw i32 %19899, %19898"
"  %19900 = add nuw nsw i32 %19899, %19898" -> "  %19912 = and i32 %19900, 65535""  %19900 = add nuw nsw i32 %19899, %19898" -> "  %19904 = lshr i32 %19900, 16"
"  %19901 = lshr i32 %19897, 16"
"  %19901 = lshr i32 %19897, 16" -> "  %19903 = add nuw nsw i32 %19901, %19902"
"  %19902 = mul nuw nsw i32 %18070, 11561"
"  %19902 = mul nuw nsw i32 %18070, 11561" -> "  %19903 = add nuw nsw i32 %19901, %19902"
"  %19903 = add nuw nsw i32 %19901, %19902"
"  %19903 = add nuw nsw i32 %19901, %19902" -> "  %19907 = and i32 %19903, 2147418112""  %19903 = add nuw nsw i32 %19901, %19902" -> "  %19905 = and i32 %19903, 65535"
"  %19904 = lshr i32 %19900, 16"
"  %19904 = lshr i32 %19900, 16" -> "  %19906 = add nuw nsw i32 %19904, %19905"
"  %19905 = and i32 %19903, 65535"
"  %19905 = and i32 %19903, 65535" -> "  %19906 = add nuw nsw i32 %19904, %19905"
"  %19906 = add nuw nsw i32 %19904, %19905"
"  %19906 = add nuw nsw i32 %19904, %19905" -> "  %19908 = add nuw nsw i32 %19906, %19907"
"  %19907 = and i32 %19903, 2147418112"
"  %19907 = and i32 %19903, 2147418112" -> "  %19908 = add nuw nsw i32 %19906, %19907"
"  %19908 = add nuw nsw i32 %19906, %19907"
"  %19908 = add nuw nsw i32 %19906, %19907" -> "  %19916 = add nuw nsw i32 %19908, %19915"
"  %19909 = and i32 %19890, 65535"
"  %19909 = and i32 %19890, 65535" -> "  %19911 = add nuw nsw i32 %19909, %19910"
"  %19910 = and i32 %19891, 65535"
"  %19910 = and i32 %19891, 65535" -> "  %19911 = add nuw nsw i32 %19909, %19910"
"  %19911 = add nuw nsw i32 %19909, %19910"
"  %19911 = add nuw nsw i32 %19909, %19910" -> "  %19940 = and i32 %19911, 65535""  %19911 = add nuw nsw i32 %19909, %19910" -> "  %19918 = lshr i32 %19911, 16"
"  %19912 = and i32 %19900, 65535"
"  %19912 = and i32 %19900, 65535" -> "  %19914 = add nuw nsw i32 %19913, %19912"
"  %19913 = lshr i32 %19890, 16"
"  %19913 = lshr i32 %19890, 16" -> "  %19914 = add nuw nsw i32 %19913, %19912"
"  %19914 = add nuw nsw i32 %19913, %19912"
"  %19914 = add nuw nsw i32 %19913, %19912" -> "  %19917 = and i32 %19914, 65535""  %19914 = add nuw nsw i32 %19913, %19912" -> "  %19915 = lshr i32 %19914, 16"
"  %19915 = lshr i32 %19914, 16"
"  %19915 = lshr i32 %19914, 16" -> "  %19916 = add nuw nsw i32 %19908, %19915"
"  %19916 = add nuw nsw i32 %19908, %19915"
"  %19916 = add nuw nsw i32 %19908, %19915" -> "  %19921 = add nuw nsw i32 %19916, %19920"
"  %19917 = and i32 %19914, 65535"
"  %19917 = and i32 %19914, 65535" -> "  %19919 = add nuw nsw i32 %19917, %19918"
"  %19918 = lshr i32 %19911, 16"
"  %19918 = lshr i32 %19911, 16" -> "  %19919 = add nuw nsw i32 %19917, %19918"
"  %19919 = add nuw nsw i32 %19917, %19918"
"  %19919 = add nuw nsw i32 %19917, %19918" -> "  %19944 = and i32 %19919, 65535""  %19919 = add nuw nsw i32 %19917, %19918" -> "  %19920 = lshr i32 %19919, 16"
"  %19920 = lshr i32 %19919, 16"
"  %19920 = lshr i32 %19919, 16" -> "  %19921 = add nuw nsw i32 %19916, %19920"
"  %19921 = add nuw nsw i32 %19916, %19920"
"  %19921 = add nuw nsw i32 %19916, %19920" -> "  %19971 = and i32 %19921, 65535""  %19921 = add nuw nsw i32 %19916, %19920" -> "  %19975 = lshr i32 %19921, 16"
"  %19922 = mul nuw nsw i32 %18049, 21884"
"  %19922 = mul nuw nsw i32 %18049, 21884" -> "  %19923 = lshr i32 %19922, 16""  %19922 = mul nuw nsw i32 %18049, 21884" -> "  %19941 = and i32 %19922, 65532"
"  %19923 = lshr i32 %19922, 16"
"  %19923 = lshr i32 %19922, 16" -> "  %19926 = add nuw nsw i32 %19925, %19923"
"  %19924 = mul nuw nsw i32 %18050, 21884"
"  %19924 = mul nuw nsw i32 %18050, 21884" -> "  %19927 = and i32 %19924, 2147418112""  %19924 = mul nuw nsw i32 %18050, 21884" -> "  %19925 = and i32 %19924, 65532"
"  %19925 = and i32 %19924, 65532"
"  %19925 = and i32 %19924, 65532" -> "  %19926 = add nuw nsw i32 %19925, %19923"
"  %19926 = add nuw nsw i32 %19925, %19923"
"  %19926 = add nuw nsw i32 %19925, %19923" -> "  %19928 = add nuw nsw i32 %19926, %19927"
"  %19927 = and i32 %19924, 2147418112"
"  %19927 = and i32 %19924, 2147418112" -> "  %19928 = add nuw nsw i32 %19926, %19927"
"  %19928 = add nuw nsw i32 %19926, %19927"
"  %19928 = add nuw nsw i32 %19926, %19927" -> "  %19930 = and i32 %19928, 65535""  %19928 = add nuw nsw i32 %19926, %19927" -> "  %19932 = lshr i32 %19928, 16"
"  %19929 = mul nuw i32 %18049, 36786"
"  %19929 = mul nuw i32 %18049, 36786" -> "  %19931 = add nuw i32 %19930, %19929"
"  %19930 = and i32 %19928, 65535"
"  %19930 = and i32 %19928, 65535" -> "  %19931 = add nuw i32 %19930, %19929"
"  %19931 = add nuw i32 %19930, %19929"
"  %19931 = add nuw i32 %19930, %19929" -> "  %19943 = and i32 %19931, 65535""  %19931 = add nuw i32 %19930, %19929" -> "  %19935 = lshr i32 %19931, 16"
"  %19932 = lshr i32 %19928, 16"
"  %19932 = lshr i32 %19928, 16" -> "  %19934 = add nuw i32 %19932, %19933"
"  %19933 = mul nuw i32 %18050, 36786"
"  %19933 = mul nuw i32 %18050, 36786" -> "  %19934 = add nuw i32 %19932, %19933"
"  %19934 = add nuw i32 %19932, %19933"
"  %19934 = add nuw i32 %19932, %19933" -> "  %19938 = and i32 %19934, -65536""  %19934 = add nuw i32 %19932, %19933" -> "  %19936 = and i32 %19934, 65535"
"  %19935 = lshr i32 %19931, 16"
"  %19935 = lshr i32 %19931, 16" -> "  %19937 = add nuw nsw i32 %19936, %19935"
"  %19936 = and i32 %19934, 65535"
"  %19936 = and i32 %19934, 65535" -> "  %19937 = add nuw nsw i32 %19936, %19935"
"  %19937 = add nuw nsw i32 %19936, %19935"
"  %19937 = add nuw nsw i32 %19936, %19935" -> "  %19939 = add nuw i32 %19937, %19938"
"  %19938 = and i32 %19934, -65536"
"  %19938 = and i32 %19934, -65536" -> "  %19939 = add nuw i32 %19937, %19938"
"  %19939 = add nuw i32 %19937, %19938"
"  %19939 = add nuw i32 %19937, %19938" -> "  %19947 = add nuw i32 %19939, %19946"
"  %19940 = and i32 %19911, 65535"
"  %19940 = and i32 %19911, 65535" -> "  %19942 = add nuw nsw i32 %19940, %19941"
"  %19941 = and i32 %19922, 65532"
"  %19941 = and i32 %19922, 65532" -> "  %19942 = add nuw nsw i32 %19940, %19941"
"  %19942 = add nuw nsw i32 %19940, %19941"
"  %19942 = add nuw nsw i32 %19940, %19941" -> "  %20009 = and i32 %19942, 65535""  %19942 = add nuw nsw i32 %19940, %19941" -> "  %19949 = lshr i32 %19942, 16"
"  %19943 = and i32 %19931, 65535"
"  %19943 = and i32 %19931, 65535" -> "  %19945 = add nuw nsw i32 %19944, %19943"
"  %19944 = and i32 %19919, 65535"
"  %19944 = and i32 %19919, 65535" -> "  %19945 = add nuw nsw i32 %19944, %19943"
"  %19945 = add nuw nsw i32 %19944, %19943"
"  %19945 = add nuw nsw i32 %19944, %19943" -> "  %19948 = and i32 %19945, 65535""  %19945 = add nuw nsw i32 %19944, %19943" -> "  %19946 = lshr i32 %19945, 16"
"  %19946 = lshr i32 %19945, 16"
"  %19946 = lshr i32 %19945, 16" -> "  %19947 = add nuw i32 %19939, %19946"
"  %19947 = add nuw i32 %19939, %19946"
"  %19947 = add nuw i32 %19939, %19946" -> "  %19952 = add nuw i32 %19947, %19951"
"  %19948 = and i32 %19945, 65535"
"  %19948 = and i32 %19945, 65535" -> "  %19950 = add nuw nsw i32 %19948, %19949"
"  %19949 = lshr i32 %19942, 16"
"  %19949 = lshr i32 %19942, 16" -> "  %19950 = add nuw nsw i32 %19948, %19949"
"  %19950 = add nuw nsw i32 %19948, %19949"
"  %19950 = add nuw nsw i32 %19948, %19949" -> "  %20012 = and i32 %19950, 65535""  %19950 = add nuw nsw i32 %19948, %19949" -> "  %19951 = lshr i32 %19950, 16"
"  %19951 = lshr i32 %19950, 16"
"  %19951 = lshr i32 %19950, 16" -> "  %19952 = add nuw i32 %19947, %19951"
"  %19952 = add nuw i32 %19947, %19951"
"  %19952 = add nuw i32 %19947, %19951" -> "  %19988 = lshr i32 %19952, 16""  %19952 = add nuw i32 %19947, %19951" -> "  %19985 = and i32 %19952, 65535"
"  %19953 = mul nuw nsw i32 %18069, 21884"
"  %19953 = mul nuw nsw i32 %18069, 21884" -> "  %19972 = and i32 %19953, 65532""  %19953 = mul nuw nsw i32 %18069, 21884" -> "  %19954 = lshr i32 %19953, 16"
"  %19954 = lshr i32 %19953, 16"
"  %19954 = lshr i32 %19953, 16" -> "  %19957 = add nuw nsw i32 %19956, %19954"
"  %19955 = mul nuw nsw i32 %18070, 21884"
"  %19955 = mul nuw nsw i32 %18070, 21884" -> "  %19958 = and i32 %19955, 2147418112""  %19955 = mul nuw nsw i32 %18070, 21884" -> "  %19956 = and i32 %19955, 65532"
"  %19956 = and i32 %19955, 65532"
"  %19956 = and i32 %19955, 65532" -> "  %19957 = add nuw nsw i32 %19956, %19954"
"  %19957 = add nuw nsw i32 %19956, %19954"
"  %19957 = add nuw nsw i32 %19956, %19954" -> "  %19959 = add nuw nsw i32 %19957, %19958"
"  %19958 = and i32 %19955, 2147418112"
"  %19958 = and i32 %19955, 2147418112" -> "  %19959 = add nuw nsw i32 %19957, %19958"
"  %19959 = add nuw nsw i32 %19957, %19958"
"  %19959 = add nuw nsw i32 %19957, %19958" -> "  %19963 = lshr i32 %19959, 16""  %19959 = add nuw nsw i32 %19957, %19958" -> "  %19961 = and i32 %19959, 65535"
"  %19960 = mul nuw i32 %18069, 36786"
"  %19960 = mul nuw i32 %18069, 36786" -> "  %19962 = add nuw i32 %19961, %19960"
"  %19961 = and i32 %19959, 65535"
"  %19961 = and i32 %19959, 65535" -> "  %19962 = add nuw i32 %19961, %19960"
"  %19962 = add nuw i32 %19961, %19960"
"  %19962 = add nuw i32 %19961, %19960" -> "  %19974 = and i32 %19962, 65535""  %19962 = add nuw i32 %19961, %19960" -> "  %19966 = lshr i32 %19962, 16"
"  %19963 = lshr i32 %19959, 16"
"  %19963 = lshr i32 %19959, 16" -> "  %19965 = add nuw i32 %19963, %19964"
"  %19964 = mul nuw i32 %18070, 36786"
"  %19964 = mul nuw i32 %18070, 36786" -> "  %19965 = add nuw i32 %19963, %19964"
"  %19965 = add nuw i32 %19963, %19964"
"  %19965 = add nuw i32 %19963, %19964" -> "  %19969 = and i32 %19965, -65536""  %19965 = add nuw i32 %19963, %19964" -> "  %19967 = and i32 %19965, 65535"
"  %19966 = lshr i32 %19962, 16"
"  %19966 = lshr i32 %19962, 16" -> "  %19968 = add nuw nsw i32 %19966, %19967"
"  %19967 = and i32 %19965, 65535"
"  %19967 = and i32 %19965, 65535" -> "  %19968 = add nuw nsw i32 %19966, %19967"
"  %19968 = add nuw nsw i32 %19966, %19967"
"  %19968 = add nuw nsw i32 %19966, %19967" -> "  %19970 = add nuw i32 %19968, %19969"
"  %19969 = and i32 %19965, -65536"
"  %19969 = and i32 %19965, -65536" -> "  %19970 = add nuw i32 %19968, %19969"
"  %19970 = add nuw i32 %19968, %19969"
"  %19970 = add nuw i32 %19968, %19969" -> "  %19978 = add nuw i32 %19970, %19977"
"  %19971 = and i32 %19921, 65535"
"  %19971 = and i32 %19921, 65535" -> "  %19973 = add nuw nsw i32 %19971, %19972"
"  %19972 = and i32 %19953, 65532"
"  %19972 = and i32 %19953, 65532" -> "  %19973 = add nuw nsw i32 %19971, %19972"
"  %19973 = add nuw nsw i32 %19971, %19972"
"  %19973 = add nuw nsw i32 %19971, %19972" -> "  %19984 = and i32 %19973, 65535""  %19973 = add nuw nsw i32 %19971, %19972" -> "  %19980 = lshr i32 %19973, 16"
"  %19974 = and i32 %19962, 65535"
"  %19974 = and i32 %19962, 65535" -> "  %19976 = add nuw nsw i32 %19975, %19974"
"  %19975 = lshr i32 %19921, 16"
"  %19975 = lshr i32 %19921, 16" -> "  %19976 = add nuw nsw i32 %19975, %19974"
"  %19976 = add nuw nsw i32 %19975, %19974"
"  %19976 = add nuw nsw i32 %19975, %19974" -> "  %19979 = and i32 %19976, 65535""  %19976 = add nuw nsw i32 %19975, %19974" -> "  %19977 = lshr i32 %19976, 16"
"  %19977 = lshr i32 %19976, 16"
"  %19977 = lshr i32 %19976, 16" -> "  %19978 = add nuw i32 %19970, %19977"
"  %19978 = add nuw i32 %19970, %19977"
"  %19978 = add nuw i32 %19970, %19977" -> "  %19983 = add nuw i32 %19978, %19982"
"  %19979 = and i32 %19976, 65535"
"  %19979 = and i32 %19976, 65535" -> "  %19981 = add nuw nsw i32 %19979, %19980"
"  %19980 = lshr i32 %19973, 16"
"  %19980 = lshr i32 %19973, 16" -> "  %19981 = add nuw nsw i32 %19979, %19980"
"  %19981 = add nuw nsw i32 %19979, %19980"
"  %19981 = add nuw nsw i32 %19979, %19980" -> "  %19987 = and i32 %19981, 65535""  %19981 = add nuw nsw i32 %19979, %19980" -> "  %19982 = lshr i32 %19981, 16"
"  %19982 = lshr i32 %19981, 16"
"  %19982 = lshr i32 %19981, 16" -> "  %19983 = add nuw i32 %19978, %19982"
"  %19983 = add nuw i32 %19978, %19982"
"  %19983 = add nuw i32 %19978, %19982" -> "  %19996 = and i32 %19983, -65536""  %19983 = add nuw i32 %19978, %19982" -> "  %19994 = and i32 %19983, 65535"
"  %19984 = and i32 %19973, 65535"
"  %19984 = and i32 %19973, 65535" -> "  %19986 = add nuw nsw i32 %19985, %19984"
"  %19985 = and i32 %19952, 65535"
"  %19985 = and i32 %19952, 65535" -> "  %19986 = add nuw nsw i32 %19985, %19984"
"  %19986 = add nuw nsw i32 %19985, %19984"
"  %19986 = add nuw nsw i32 %19985, %19984" -> "  %20026 = and i32 %19986, 65535""  %19986 = add nuw nsw i32 %19985, %19984" -> "  %19990 = lshr i32 %19986, 16"
"  %19987 = and i32 %19981, 65535"
"  %19987 = and i32 %19981, 65535" -> "  %19989 = add nuw nsw i32 %19987, %19988"
"  %19988 = lshr i32 %19952, 16"
"  %19988 = lshr i32 %19952, 16" -> "  %19989 = add nuw nsw i32 %19987, %19988"
"  %19989 = add nuw nsw i32 %19987, %19988"
"  %19989 = add nuw nsw i32 %19987, %19988" -> "  %19993 = lshr i32 %19989, 16""  %19989 = add nuw nsw i32 %19987, %19988" -> "  %19991 = and i32 %19989, 65535"
"  %19990 = lshr i32 %19986, 16"
"  %19990 = lshr i32 %19986, 16" -> "  %19992 = add nuw nsw i32 %19991, %19990"
"  %19991 = and i32 %19989, 65535"
"  %19991 = and i32 %19989, 65535" -> "  %19992 = add nuw nsw i32 %19991, %19990"
"  %19992 = add nuw nsw i32 %19991, %19990"
"  %19992 = add nuw nsw i32 %19991, %19990" -> "  %20033 = and i32 %19992, 65535""  %19992 = add nuw nsw i32 %19991, %19990" -> "  %19998 = lshr i32 %19992, 16"
"  %19993 = lshr i32 %19989, 16"
"  %19993 = lshr i32 %19989, 16" -> "  %19995 = add nuw nsw i32 %19993, %19994"
"  %19994 = and i32 %19983, 65535"
"  %19994 = and i32 %19983, 65535" -> "  %19995 = add nuw nsw i32 %19993, %19994"
"  %19995 = add nuw nsw i32 %19993, %19994"
"  %19995 = add nuw nsw i32 %19993, %19994" -> "  %19997 = add nuw i32 %19995, %19996"
"  %19996 = and i32 %19983, -65536"
"  %19996 = and i32 %19983, -65536" -> "  %19997 = add nuw i32 %19995, %19996"
"  %19997 = add nuw i32 %19995, %19996"
"  %19997 = add nuw i32 %19995, %19996" -> "  %19999 = add nuw i32 %19997, %19998"
"  %19998 = lshr i32 %19992, 16"
"  %19998 = lshr i32 %19992, 16" -> "  %19999 = add nuw i32 %19997, %19998"
"  %19999 = add nuw i32 %19997, %19998"
"  %19999 = add nuw i32 %19997, %19998" -> "  %20037 = add nuw i32 %19999, %20036"
"  %20000 = and i32 %19873, 65535"
"  %20000 = and i32 %19873, 65535" -> "  %20002 = add nuw nsw i32 %20001, %20000"
"  %20001 = and i32 %19702, 65535"
"  %20001 = and i32 %19702, 65535" -> "  %20002 = add nuw nsw i32 %20001, %20000"
"  %20002 = add nuw nsw i32 %20001, %20000"
"  %20002 = add nuw nsw i32 %20001, %20000" -> "  %20038 = and i32 %20002, 65535""  %20002 = add nuw nsw i32 %20001, %20000" -> "  %20006 = lshr i32 %20002, 16"
"  %20003 = and i32 %19882, 65535"
"  %20003 = and i32 %19882, 65535" -> "  %20005 = add nuw nsw i32 %20004, %20003"
"  %20004 = and i32 %19705, 65535"
"  %20004 = and i32 %19705, 65535" -> "  %20005 = add nuw nsw i32 %20004, %20003"
"  %20005 = add nuw nsw i32 %20004, %20003"
"  %20005 = add nuw nsw i32 %20004, %20003" -> "  %20019 = lshr i32 %20005, 16""  %20005 = add nuw nsw i32 %20004, %20003" -> "  %20007 = and i32 %20005, 65535"
"  %20006 = lshr i32 %20002, 16"
"  %20006 = lshr i32 %20002, 16" -> "  %20008 = add nuw nsw i32 %20007, %20006"
"  %20007 = and i32 %20005, 65535"
"  %20007 = and i32 %20005, 65535" -> "  %20008 = add nuw nsw i32 %20007, %20006"
"  %20008 = add nuw nsw i32 %20007, %20006"
"  %20008 = add nuw nsw i32 %20007, %20006" -> "  %20041 = and i32 %20008, 65535""  %20008 = add nuw nsw i32 %20007, %20006" -> "  %20021 = lshr i32 %20008, 16"
"  %20009 = and i32 %19942, 65535"
"  %20009 = and i32 %19942, 65535" -> "  %20011 = add nuw nsw i32 %20010, %20009"
"  %20010 = and i32 %19707, 65535"
"  %20010 = and i32 %19707, 65535" -> "  %20011 = add nuw nsw i32 %20010, %20009"
"  %20011 = add nuw nsw i32 %20010, %20009"
"  %20011 = add nuw nsw i32 %20010, %20009" -> "  %20018 = and i32 %20011, 65535""  %20011 = add nuw nsw i32 %20010, %20009" -> "  %20015 = lshr i32 %20011, 16"
"  %20012 = and i32 %19950, 65535"
"  %20012 = and i32 %19950, 65535" -> "  %20014 = add nuw nsw i32 %20013, %20012"
"  %20013 = lshr i32 %19707, 16"
"  %20013 = lshr i32 %19707, 16" -> "  %20014 = add nuw nsw i32 %20013, %20012"
"  %20014 = add nuw nsw i32 %20013, %20012"
"  %20014 = add nuw nsw i32 %20013, %20012" -> "  %20027 = lshr i32 %20014, 16""  %20014 = add nuw nsw i32 %20013, %20012" -> "  %20016 = and i32 %20014, 65535"
"  %20015 = lshr i32 %20011, 16"
"  %20015 = lshr i32 %20011, 16" -> "  %20017 = add nuw nsw i32 %20015, %20016"
"  %20016 = and i32 %20014, 65535"
"  %20016 = and i32 %20014, 65535" -> "  %20017 = add nuw nsw i32 %20015, %20016"
"  %20017 = add nuw nsw i32 %20015, %20016"
"  %20017 = add nuw nsw i32 %20015, %20016" -> "  %20029 = lshr i32 %20017, 16""  %20017 = add nuw nsw i32 %20015, %20016" -> "  %20024 = and i32 %20017, 65535"
"  %20018 = and i32 %20011, 65535"
"  %20018 = and i32 %20011, 65535" -> "  %20020 = add nuw nsw i32 %20018, %20019"
"  %20019 = lshr i32 %20005, 16"
"  %20019 = lshr i32 %20005, 16" -> "  %20020 = add nuw nsw i32 %20018, %20019"
"  %20020 = add nuw nsw i32 %20018, %20019"
"  %20020 = add nuw nsw i32 %20018, %20019" -> "  %20022 = add nuw nsw i32 %20020, %20021"
"  %20021 = lshr i32 %20008, 16"
"  %20021 = lshr i32 %20008, 16" -> "  %20022 = add nuw nsw i32 %20020, %20021"
"  %20022 = add nuw nsw i32 %20020, %20021"
"  %20022 = add nuw nsw i32 %20020, %20021" -> "  %20047 = and i32 %20022, 65535""  %20022 = add nuw nsw i32 %20020, %20021" -> "  %20023 = lshr i32 %20022, 16"
"  %20023 = lshr i32 %20022, 16"
"  %20023 = lshr i32 %20022, 16" -> "  %20025 = add nuw nsw i32 %20023, %20024"
"  %20024 = and i32 %20017, 65535"
"  %20024 = and i32 %20017, 65535" -> "  %20025 = add nuw nsw i32 %20023, %20024"
"  %20025 = add nuw nsw i32 %20023, %20024"
"  %20025 = add nuw nsw i32 %20023, %20024" -> "  %20050 = and i32 %20025, 65535""  %20025 = add nuw nsw i32 %20023, %20024" -> "  %20031 = lshr i32 %20025, 16"
"  %20026 = and i32 %19986, 65535"
"  %20026 = and i32 %19986, 65535" -> "  %20028 = add nuw nsw i32 %20027, %20026"
"  %20027 = lshr i32 %20014, 16"
"  %20027 = lshr i32 %20014, 16" -> "  %20028 = add nuw nsw i32 %20027, %20026"
"  %20028 = add nuw nsw i32 %20027, %20026"
"  %20028 = add nuw nsw i32 %20027, %20026" -> "  %20030 = add nuw nsw i32 %20028, %20029"
"  %20029 = lshr i32 %20017, 16"
"  %20029 = lshr i32 %20017, 16" -> "  %20030 = add nuw nsw i32 %20028, %20029"
"  %20030 = add nuw nsw i32 %20028, %20029"
"  %20030 = add nuw nsw i32 %20028, %20029" -> "  %20032 = add nuw nsw i32 %20030, %20031"
"  %20031 = lshr i32 %20025, 16"
"  %20031 = lshr i32 %20025, 16" -> "  %20032 = add nuw nsw i32 %20030, %20031"
"  %20032 = add nuw nsw i32 %20030, %20031"
"  %20032 = add nuw nsw i32 %20030, %20031" -> "  %20064 = and i32 %20032, 65535""  %20032 = add nuw nsw i32 %20030, %20031" -> "  %20034 = lshr i32 %20032, 16"
"  %20033 = and i32 %19992, 65535"
"  %20033 = and i32 %19992, 65535" -> "  %20035 = add nuw nsw i32 %20034, %20033"
"  %20034 = lshr i32 %20032, 16"
"  %20034 = lshr i32 %20032, 16" -> "  %20035 = add nuw nsw i32 %20034, %20033"
"  %20035 = add nuw nsw i32 %20034, %20033"
"  %20035 = add nuw nsw i32 %20034, %20033" -> "  %20071 = and i32 %20035, 65535""  %20035 = add nuw nsw i32 %20034, %20033" -> "  %20036 = lshr i32 %20035, 16"
"  %20036 = lshr i32 %20035, 16"
"  %20036 = lshr i32 %20035, 16" -> "  %20037 = add nuw i32 %19999, %20036"
"  %20037 = add nuw i32 %19999, %20036"
"  %20037 = add nuw i32 %19999, %20036" -> "  %20075 = add nuw i32 %20037, %20074"
"  %20038 = and i32 %20002, 65535"
"  %20038 = and i32 %20002, 65535" -> "  %20040 = add nuw nsw i32 %20039, %20038"
"  %20039 = and i32 %19867, 65535"
"  %20039 = and i32 %19867, 65535" -> "  %20040 = add nuw nsw i32 %20039, %20038"
"  %20040 = add nuw nsw i32 %20039, %20038"
"  %20040 = add nuw nsw i32 %20039, %20038" -> "  %20148 = and i32 %20040, 65535""  %20040 = add nuw nsw i32 %20039, %20038" -> "  %20044 = lshr i32 %20040, 16"
"  %20041 = and i32 %20008, 65535"
"  %20041 = and i32 %20008, 65535" -> "  %20043 = add nuw nsw i32 %20042, %20041"
"  %20042 = and i32 %19870, 65535"
"  %20042 = and i32 %19870, 65535" -> "  %20043 = add nuw nsw i32 %20042, %20041"
"  %20043 = add nuw nsw i32 %20042, %20041"
"  %20043 = add nuw nsw i32 %20042, %20041" -> "  %20057 = lshr i32 %20043, 16""  %20043 = add nuw nsw i32 %20042, %20041" -> "  %20045 = and i32 %20043, 65535"
"  %20044 = lshr i32 %20040, 16"
"  %20044 = lshr i32 %20040, 16" -> "  %20046 = add nuw nsw i32 %20045, %20044"
"  %20045 = and i32 %20043, 65535"
"  %20045 = and i32 %20043, 65535" -> "  %20046 = add nuw nsw i32 %20045, %20044"
"  %20046 = add nuw nsw i32 %20045, %20044"
"  %20046 = add nuw nsw i32 %20045, %20044" -> "  %20153 = and i32 %20046, 65535""  %20046 = add nuw nsw i32 %20045, %20044" -> "  %20058 = lshr i32 %20046, 16""  %20046 = add nuw nsw i32 %20045, %20044" -> "  store i32 %20046, i32* %240, align 1, !noalias !71"
"  store i32 %20046, i32* %240, align 1, !noalias !71"

"  %20047 = and i32 %20022, 65535"
"  %20047 = and i32 %20022, 65535" -> "  %20049 = add nuw nsw i32 %20048, %20047"
"  %20048 = and i32 %19872, 65535"
"  %20048 = and i32 %19872, 65535" -> "  %20049 = add nuw nsw i32 %20048, %20047"
"  %20049 = add nuw nsw i32 %20048, %20047"
"  %20049 = add nuw nsw i32 %20048, %20047" -> "  %20056 = and i32 %20049, 65535""  %20049 = add nuw nsw i32 %20048, %20047" -> "  %20053 = lshr i32 %20049, 16"
"  %20050 = and i32 %20025, 65535"
"  %20050 = and i32 %20025, 65535" -> "  %20052 = add nuw nsw i32 %20050, %20051"
"  %20051 = lshr i32 %19872, 16"
"  %20051 = lshr i32 %19872, 16" -> "  %20052 = add nuw nsw i32 %20050, %20051"
"  %20052 = add nuw nsw i32 %20050, %20051"
"  %20052 = add nuw nsw i32 %20050, %20051" -> "  %20065 = lshr i32 %20052, 16""  %20052 = add nuw nsw i32 %20050, %20051" -> "  %20054 = and i32 %20052, 65535"
"  %20053 = lshr i32 %20049, 16"
"  %20053 = lshr i32 %20049, 16" -> "  %20055 = add nuw nsw i32 %20054, %20053"
"  %20054 = and i32 %20052, 65535"
"  %20054 = and i32 %20052, 65535" -> "  %20055 = add nuw nsw i32 %20054, %20053"
"  %20055 = add nuw nsw i32 %20054, %20053"
"  %20055 = add nuw nsw i32 %20054, %20053" -> "  %20067 = lshr i32 %20055, 16""  %20055 = add nuw nsw i32 %20054, %20053" -> "  %20062 = and i32 %20055, 65535"
"  %20056 = and i32 %20049, 65535"
"  %20056 = and i32 %20049, 65535" -> "  %20060 = add nuw nsw i32 %20059, %20056"
"  %20057 = lshr i32 %20043, 16"
"  %20057 = lshr i32 %20043, 16" -> "  %20059 = add nuw nsw i32 %20058, %20057"
"  %20058 = lshr i32 %20046, 16"
"  %20058 = lshr i32 %20046, 16" -> "  %20059 = add nuw nsw i32 %20058, %20057"
"  %20059 = add nuw nsw i32 %20058, %20057"
"  %20059 = add nuw nsw i32 %20058, %20057" -> "  %20060 = add nuw nsw i32 %20059, %20056"
"  %20060 = add nuw nsw i32 %20059, %20056"
"  %20060 = add nuw nsw i32 %20059, %20056" -> "  %20156 = and i32 %20060, 65535""  %20060 = add nuw nsw i32 %20059, %20056" -> "  %20061 = lshr i32 %20060, 16""  %20060 = add nuw nsw i32 %20059, %20056" -> "  store i32 %20060, i32* %1741, align 1, !noalias !71"
"  store i32 %20060, i32* %1741, align 1, !noalias !71"

"  %20061 = lshr i32 %20060, 16"
"  %20061 = lshr i32 %20060, 16" -> "  %20063 = add nuw nsw i32 %20062, %20061"
"  %20062 = and i32 %20055, 65535"
"  %20062 = and i32 %20055, 65535" -> "  %20063 = add nuw nsw i32 %20062, %20061"
"  %20063 = add nuw nsw i32 %20062, %20061"
"  %20063 = add nuw nsw i32 %20062, %20061" -> "  %20160 = and i32 %20063, 65535""  %20063 = add nuw nsw i32 %20062, %20061" -> "  %20069 = lshr i32 %20063, 16"
"  %20064 = and i32 %20032, 65535"
"  %20064 = and i32 %20032, 65535" -> "  %20066 = add nuw nsw i32 %20065, %20064"
"  %20065 = lshr i32 %20052, 16"
"  %20065 = lshr i32 %20052, 16" -> "  %20066 = add nuw nsw i32 %20065, %20064"
"  %20066 = add nuw nsw i32 %20065, %20064"
"  %20066 = add nuw nsw i32 %20065, %20064" -> "  %20068 = add nuw nsw i32 %20066, %20067"
"  %20067 = lshr i32 %20055, 16"
"  %20067 = lshr i32 %20055, 16" -> "  %20068 = add nuw nsw i32 %20066, %20067"
"  %20068 = add nuw nsw i32 %20066, %20067"
"  %20068 = add nuw nsw i32 %20066, %20067" -> "  %20070 = add nuw nsw i32 %20068, %20069"
"  %20069 = lshr i32 %20063, 16"
"  %20069 = lshr i32 %20063, 16" -> "  %20070 = add nuw nsw i32 %20068, %20069"
"  %20070 = add nuw nsw i32 %20068, %20069"
"  %20070 = add nuw nsw i32 %20068, %20069" -> "  %20163 = and i32 %20070, 65535""  %20070 = add nuw nsw i32 %20068, %20069" -> "  %20072 = lshr i32 %20070, 16"
"  %20071 = and i32 %20035, 65535"
"  %20071 = and i32 %20035, 65535" -> "  %20073 = add nuw nsw i32 %20072, %20071"
"  %20072 = lshr i32 %20070, 16"
"  %20072 = lshr i32 %20070, 16" -> "  %20073 = add nuw nsw i32 %20072, %20071"
"  %20073 = add nuw nsw i32 %20072, %20071"
"  %20073 = add nuw nsw i32 %20072, %20071" -> "  %20166 = and i32 %20073, 65535""  %20073 = add nuw nsw i32 %20072, %20071" -> "  %20074 = lshr i32 %20073, 16"
"  %20074 = lshr i32 %20073, 16"
"  %20074 = lshr i32 %20073, 16" -> "  %20075 = add nuw i32 %20037, %20074"
"  %20075 = add nuw i32 %20037, %20074"
"  %20075 = add nuw i32 %20037, %20074" -> "  %20169 = add nuw i32 %20075, %20168"
"  %20076 = and i32 %18653, 65535"
"  %20076 = and i32 %18653, 65535" -> "  %20078 = add nuw nsw i32 %20076, %20077"
"  %20077 = and i32 %19422, 65535"
"  %20077 = and i32 %19422, 65535" -> "  %20078 = add nuw nsw i32 %20076, %20077"
"  %20078 = add nuw nsw i32 %20076, %20077"
"  %20078 = add nuw nsw i32 %20076, %20077" -> "  %20171 = and i32 %20078, 65535""  %20078 = add nuw nsw i32 %20076, %20077" -> "  %20082 = lshr i32 %20078, 16""  %20078 = add nuw nsw i32 %20076, %20077" -> "  store i32 %20078, i32* %297, align 1, !noalias !71"
"  store i32 %20078, i32* %297, align 1, !noalias !71"

"  %20079 = and i32 %18656, 65535"
"  %20079 = and i32 %18656, 65535" -> "  %20081 = add nuw nsw i32 %20079, %20080"
"  %20080 = and i32 %19431, 65535"
"  %20080 = and i32 %19431, 65535" -> "  %20081 = add nuw nsw i32 %20079, %20080"
"  %20081 = add nuw nsw i32 %20079, %20080"
"  %20081 = add nuw nsw i32 %20079, %20080" -> "  %20094 = lshr i32 %20081, 16""  %20081 = add nuw nsw i32 %20079, %20080" -> "  %20083 = and i32 %20081, 65535"
"  %20082 = lshr i32 %20078, 16"
"  %20082 = lshr i32 %20078, 16" -> "  %20084 = add nuw nsw i32 %20083, %20082"
"  %20083 = and i32 %20081, 65535"
"  %20083 = and i32 %20081, 65535" -> "  %20084 = add nuw nsw i32 %20083, %20082"
"  %20084 = add nuw nsw i32 %20083, %20082"
"  %20084 = add nuw nsw i32 %20083, %20082" -> "  %20174 = and i32 %20084, 65535""  %20084 = add nuw nsw i32 %20083, %20082" -> "  %20096 = lshr i32 %20084, 16""  %20084 = add nuw nsw i32 %20083, %20082" -> "  store i32 %20084, i32* %648, align 1, !noalias !71"
"  store i32 %20084, i32* %648, align 1, !noalias !71"

"  %20085 = and i32 %18659, 65535"
"  %20085 = and i32 %18659, 65535" -> "  %20087 = add nuw nsw i32 %20085, %20086"
"  %20086 = and i32 %19491, 65535"
"  %20086 = and i32 %19491, 65535" -> "  %20087 = add nuw nsw i32 %20085, %20086"
"  %20087 = add nuw nsw i32 %20085, %20086"
"  %20087 = add nuw nsw i32 %20085, %20086" -> "  %20095 = and i32 %20087, 65535""  %20087 = add nuw nsw i32 %20085, %20086" -> "  %20091 = lshr i32 %20087, 16"
"  %20088 = and i32 %18662, 65535"
"  %20088 = and i32 %18662, 65535" -> "  %20090 = add nuw nsw i32 %20088, %20089"
"  %20089 = and i32 %19499, 65535"
"  %20089 = and i32 %19499, 65535" -> "  %20090 = add nuw nsw i32 %20088, %20089"
"  %20090 = add nuw nsw i32 %20088, %20089"
"  %20090 = add nuw nsw i32 %20088, %20089" -> "  %20132 = lshr i32 %20090, 16""  %20090 = add nuw nsw i32 %20088, %20089" -> "  %20092 = and i32 %20090, 65535"
"  %20091 = lshr i32 %20087, 16"
"  %20091 = lshr i32 %20087, 16" -> "  %20093 = add nuw nsw i32 %20092, %20091"
"  %20092 = and i32 %20090, 65535"
"  %20092 = and i32 %20090, 65535" -> "  %20093 = add nuw nsw i32 %20092, %20091"
"  %20093 = add nuw nsw i32 %20092, %20091"
"  %20093 = add nuw nsw i32 %20092, %20091" -> "  %20133 = lshr i32 %20093, 16""  %20093 = add nuw nsw i32 %20092, %20091" -> "  %20100 = and i32 %20093, 65535"
"  %20094 = lshr i32 %20081, 16"
"  %20094 = lshr i32 %20081, 16" -> "  %20097 = add nuw nsw i32 %20096, %20094"
"  %20095 = and i32 %20087, 65535"
"  %20095 = and i32 %20087, 65535" -> "  %20098 = add nuw nsw i32 %20097, %20095"
"  %20096 = lshr i32 %20084, 16"
"  %20096 = lshr i32 %20084, 16" -> "  %20097 = add nuw nsw i32 %20096, %20094"
"  %20097 = add nuw nsw i32 %20096, %20094"
"  %20097 = add nuw nsw i32 %20096, %20094" -> "  %20098 = add nuw nsw i32 %20097, %20095"
"  %20098 = add nuw nsw i32 %20097, %20095"
"  %20098 = add nuw nsw i32 %20097, %20095" -> "  %20179 = and i32 %20098, 65535""  %20098 = add nuw nsw i32 %20097, %20095" -> "  %20099 = lshr i32 %20098, 16"
"  %20099 = lshr i32 %20098, 16"
"  %20099 = lshr i32 %20098, 16" -> "  %20101 = add nuw nsw i32 %20100, %20099"
"  %20100 = and i32 %20093, 65535"
"  %20100 = and i32 %20093, 65535" -> "  %20101 = add nuw nsw i32 %20100, %20099"
"  %20101 = add nuw nsw i32 %20100, %20099"
"  %20101 = add nuw nsw i32 %20100, %20099" -> "  %20182 = and i32 %20101, 65535""  %20101 = add nuw nsw i32 %20100, %20099" -> "  %20134 = lshr i32 %20101, 16"
"  %20102 = and i32 %18665, 65535"
"  %20102 = and i32 %18665, 65535" -> "  %20104 = add nuw nsw i32 %20102, %20103"
"  %20103 = and i32 %19837, 65535"
"  %20103 = and i32 %19837, 65535" -> "  %20104 = add nuw nsw i32 %20102, %20103"
"  %20104 = add nuw nsw i32 %20102, %20103"
"  %20104 = add nuw nsw i32 %20102, %20103" -> "  %20131 = and i32 %20104, 65535""  %20104 = add nuw nsw i32 %20102, %20103" -> "  %20108 = lshr i32 %20104, 16"
"  %20105 = and i32 %18668, 65535"
"  %20105 = and i32 %18668, 65535" -> "  %20107 = add nuw nsw i32 %20105, %20106"
"  %20106 = and i32 %19843, 65535"
"  %20106 = and i32 %19843, 65535" -> "  %20107 = add nuw nsw i32 %20105, %20106"
"  %20107 = add nuw nsw i32 %20105, %20106"
"  %20107 = add nuw nsw i32 %20105, %20106" -> "  %20123 = lshr i32 %20107, 16""  %20107 = add nuw nsw i32 %20105, %20106" -> "  %20109 = and i32 %20107, 65535"
"  %20108 = lshr i32 %20104, 16"
"  %20108 = lshr i32 %20104, 16" -> "  %20110 = add nuw nsw i32 %20109, %20108"
"  %20109 = and i32 %20107, 65535"
"  %20109 = and i32 %20107, 65535" -> "  %20110 = add nuw nsw i32 %20109, %20108"
"  %20110 = add nuw nsw i32 %20109, %20108"
"  %20110 = add nuw nsw i32 %20109, %20108" -> "  %20138 = and i32 %20110, 65535""  %20110 = add nuw nsw i32 %20109, %20108" -> "  %20125 = lshr i32 %20110, 16"
"  %20111 = and i32 %18670, 65535"
"  %20111 = and i32 %18670, 65535" -> "  %20113 = add nuw nsw i32 %20111, %20112"
"  %20112 = and i32 %19857, 65535"
"  %20112 = and i32 %19857, 65535" -> "  %20113 = add nuw nsw i32 %20111, %20112"
"  %20113 = add nuw nsw i32 %20111, %20112"
"  %20113 = add nuw nsw i32 %20111, %20112" -> "  %20122 = and i32 %20113, 65535""  %20113 = add nuw nsw i32 %20111, %20112" -> "  %20117 = lshr i32 %20113, 16"
"  %20114 = lshr i32 %18670, 16"
"  %20114 = lshr i32 %18670, 16" -> "  %20116 = add nuw nsw i32 %20114, %20115"
"  %20115 = and i32 %19860, 65535"
"  %20115 = and i32 %19860, 65535" -> "  %20116 = add nuw nsw i32 %20114, %20115"
"  %20116 = add nuw nsw i32 %20114, %20115"
"  %20116 = add nuw nsw i32 %20114, %20115" -> "  %20120 = lshr i32 %20116, 16""  %20116 = add nuw nsw i32 %20114, %20115" -> "  %20118 = and i32 %20116, 65535"
"  %20117 = lshr i32 %20113, 16"
"  %20117 = lshr i32 %20113, 16" -> "  %20119 = add nuw nsw i32 %20118, %20117"
"  %20118 = and i32 %20116, 65535"
"  %20118 = and i32 %20116, 65535" -> "  %20119 = add nuw nsw i32 %20118, %20117"
"  %20119 = add nuw nsw i32 %20118, %20117"
"  %20119 = add nuw nsw i32 %20118, %20117" -> "  %20127 = and i32 %20119, 65535""  %20119 = add nuw nsw i32 %20118, %20117" -> "  %20121 = lshr i32 %20119, 16"
"  %20120 = lshr i32 %20116, 16"
"  %20120 = lshr i32 %20116, 16" -> "  %20149 = add nuw nsw i32 %20120, %20148"
"  %20121 = lshr i32 %20119, 16"
"  %20121 = lshr i32 %20119, 16" -> "  %20150 = add nuw nsw i32 %20149, %20121"
"  %20122 = and i32 %20113, 65535"
"  %20122 = and i32 %20113, 65535" -> "  %20124 = add nuw nsw i32 %20122, %20123"
"  %20123 = lshr i32 %20107, 16"
"  %20123 = lshr i32 %20107, 16" -> "  %20124 = add nuw nsw i32 %20122, %20123"
"  %20124 = add nuw nsw i32 %20122, %20123"
"  %20124 = add nuw nsw i32 %20122, %20123" -> "  %20126 = add nuw nsw i32 %20124, %20125"
"  %20125 = lshr i32 %20110, 16"
"  %20125 = lshr i32 %20110, 16" -> "  %20126 = add nuw nsw i32 %20124, %20125"
"  %20126 = add nuw nsw i32 %20124, %20125"
"  %20126 = add nuw nsw i32 %20124, %20125" -> "  %20141 = and i32 %20126, 65535""  %20126 = add nuw nsw i32 %20124, %20125" -> "  %20128 = lshr i32 %20126, 16"
"  %20127 = and i32 %20119, 65535"
"  %20127 = and i32 %20119, 65535" -> "  %20129 = add nuw nsw i32 %20128, %20127"
"  %20128 = lshr i32 %20126, 16"
"  %20128 = lshr i32 %20126, 16" -> "  %20129 = add nuw nsw i32 %20128, %20127"
"  %20129 = add nuw nsw i32 %20128, %20127"
"  %20129 = add nuw nsw i32 %20128, %20127" -> "  %20144 = and i32 %20129, 65535""  %20129 = add nuw nsw i32 %20128, %20127" -> "  %20130 = lshr i32 %20129, 16"
"  %20130 = lshr i32 %20129, 16"
"  %20130 = lshr i32 %20129, 16" -> "  %20151 = add nuw nsw i32 %20150, %20130"
"  %20131 = and i32 %20104, 65535"
"  %20131 = and i32 %20104, 65535" -> "  %20136 = add nuw nsw i32 %20135, %20131"
"  %20132 = lshr i32 %20090, 16"
"  %20132 = lshr i32 %20090, 16" -> "  %20135 = add nuw nsw i32 %20133, %20132"
"  %20133 = lshr i32 %20093, 16"
"  %20133 = lshr i32 %20093, 16" -> "  %20135 = add nuw nsw i32 %20133, %20132"
"  %20134 = lshr i32 %20101, 16"
"  %20134 = lshr i32 %20101, 16" -> "  %20137 = add nuw nsw i32 %20136, %20134"
"  %20135 = add nuw nsw i32 %20133, %20132"
"  %20135 = add nuw nsw i32 %20133, %20132" -> "  %20136 = add nuw nsw i32 %20135, %20131"
"  %20136 = add nuw nsw i32 %20135, %20131"
"  %20136 = add nuw nsw i32 %20135, %20131" -> "  %20137 = add nuw nsw i32 %20136, %20134"
"  %20137 = add nuw nsw i32 %20136, %20134"
"  %20137 = add nuw nsw i32 %20136, %20134" -> "  %20196 = and i32 %20137, 65535""  %20137 = add nuw nsw i32 %20136, %20134" -> "  %20139 = lshr i32 %20137, 16"
"  %20138 = and i32 %20110, 65535"
"  %20138 = and i32 %20110, 65535" -> "  %20140 = add nuw nsw i32 %20139, %20138"
"  %20139 = lshr i32 %20137, 16"
"  %20139 = lshr i32 %20137, 16" -> "  %20140 = add nuw nsw i32 %20139, %20138"
"  %20140 = add nuw nsw i32 %20139, %20138"
"  %20140 = add nuw nsw i32 %20139, %20138" -> "  %20199 = and i32 %20140, 65535""  %20140 = add nuw nsw i32 %20139, %20138" -> "  %20142 = lshr i32 %20140, 16"
"  %20141 = and i32 %20126, 65535"
"  %20141 = and i32 %20126, 65535" -> "  %20143 = add nuw nsw i32 %20141, %20142"
"  %20142 = lshr i32 %20140, 16"
"  %20142 = lshr i32 %20140, 16" -> "  %20143 = add nuw nsw i32 %20141, %20142"
"  %20143 = add nuw nsw i32 %20141, %20142"
"  %20143 = add nuw nsw i32 %20141, %20142" -> "  %20205 = and i32 %20143, 65535""  %20143 = add nuw nsw i32 %20141, %20142" -> "  %20145 = lshr i32 %20143, 16"
"  %20144 = and i32 %20129, 65535"
"  %20144 = and i32 %20129, 65535" -> "  %20146 = add nuw nsw i32 %20145, %20144"
"  %20145 = lshr i32 %20143, 16"
"  %20145 = lshr i32 %20143, 16" -> "  %20146 = add nuw nsw i32 %20145, %20144"
"  %20146 = add nuw nsw i32 %20145, %20144"
"  %20146 = add nuw nsw i32 %20145, %20144" -> "  %20208 = and i32 %20146, 65535""  %20146 = add nuw nsw i32 %20145, %20144" -> "  %20147 = lshr i32 %20146, 16"
"  %20147 = lshr i32 %20146, 16"
"  %20147 = lshr i32 %20146, 16" -> "  %20152 = add nuw nsw i32 %20151, %20147"
"  %20148 = and i32 %20040, 65535"
"  %20148 = and i32 %20040, 65535" -> "  %20149 = add nuw nsw i32 %20120, %20148"
"  %20149 = add nuw nsw i32 %20120, %20148"
"  %20149 = add nuw nsw i32 %20120, %20148" -> "  %20150 = add nuw nsw i32 %20149, %20121"
"  %20150 = add nuw nsw i32 %20149, %20121"
"  %20150 = add nuw nsw i32 %20149, %20121" -> "  %20151 = add nuw nsw i32 %20150, %20130"
"  %20151 = add nuw nsw i32 %20150, %20130"
"  %20151 = add nuw nsw i32 %20150, %20130" -> "  %20152 = add nuw nsw i32 %20151, %20147"
"  %20152 = add nuw nsw i32 %20151, %20147"
"  %20152 = add nuw nsw i32 %20151, %20147" -> "  %20243 = and i32 %20152, 65535""  %20152 = add nuw nsw i32 %20151, %20147" -> "  %20154 = lshr i32 %20152, 16"
"  %20153 = and i32 %20046, 65535"
"  %20153 = and i32 %20046, 65535" -> "  %20155 = add nuw nsw i32 %20154, %20153"
"  %20154 = lshr i32 %20152, 16"
"  %20154 = lshr i32 %20152, 16" -> "  %20155 = add nuw nsw i32 %20154, %20153"
"  %20155 = add nuw nsw i32 %20154, %20153"
"  %20155 = add nuw nsw i32 %20154, %20153" -> "  %20242 = and i32 %20155, 65535""  %20155 = add nuw nsw i32 %20154, %20153" -> "  %20157 = lshr i32 %20155, 16"
"  %20156 = and i32 %20060, 65535"
"  %20156 = and i32 %20060, 65535" -> "  %20158 = add nuw nsw i32 %20157, %20156"
"  %20157 = lshr i32 %20155, 16"
"  %20157 = lshr i32 %20155, 16" -> "  %20158 = add nuw nsw i32 %20157, %20156"
"  %20158 = add nuw nsw i32 %20157, %20156"
"  %20158 = add nuw nsw i32 %20157, %20156" -> "  %20248 = and i32 %20158, 65535""  %20158 = add nuw nsw i32 %20157, %20156" -> "  %20159 = lshr i32 %20158, 16"
"  %20159 = lshr i32 %20158, 16"
"  %20159 = lshr i32 %20158, 16" -> "  %20161 = add nuw nsw i32 %20159, %20160"
"  %20160 = and i32 %20063, 65535"
"  %20160 = and i32 %20063, 65535" -> "  %20161 = add nuw nsw i32 %20159, %20160"
"  %20161 = add nuw nsw i32 %20159, %20160"
"  %20161 = add nuw nsw i32 %20159, %20160" -> "  %20255 = and i32 %20161, 65535""  %20161 = add nuw nsw i32 %20159, %20160" -> "  %20162 = lshr i32 %20161, 16"
"  %20162 = lshr i32 %20161, 16"
"  %20162 = lshr i32 %20161, 16" -> "  %20164 = add nuw nsw i32 %20162, %20163"
"  %20163 = and i32 %20070, 65535"
"  %20163 = and i32 %20070, 65535" -> "  %20164 = add nuw nsw i32 %20162, %20163"
"  %20164 = add nuw nsw i32 %20162, %20163"
"  %20164 = add nuw nsw i32 %20162, %20163" -> "  %20259 = and i32 %20164, 65535""  %20164 = add nuw nsw i32 %20162, %20163" -> "  %20165 = lshr i32 %20164, 16"
"  %20165 = lshr i32 %20164, 16"
"  %20165 = lshr i32 %20164, 16" -> "  %20167 = add nuw nsw i32 %20165, %20166"
"  %20166 = and i32 %20073, 65535"
"  %20166 = and i32 %20073, 65535" -> "  %20167 = add nuw nsw i32 %20165, %20166"
"  %20167 = add nuw nsw i32 %20165, %20166"
"  %20167 = add nuw nsw i32 %20165, %20166" -> "  %20262 = and i32 %20167, 65535""  %20167 = add nuw nsw i32 %20165, %20166" -> "  %20168 = lshr i32 %20167, 16"
"  %20168 = lshr i32 %20167, 16"
"  %20168 = lshr i32 %20167, 16" -> "  %20169 = add nuw i32 %20075, %20168"
"  %20169 = add nuw i32 %20075, %20168"
"  %20169 = add nuw i32 %20075, %20168" -> "  %20266 = add nuw i32 %20169, %20265"
"  %20170 = and i32 %19404, 65535"
"  %20170 = and i32 %19404, 65535" -> "  %20172 = add nuw nsw i32 %20170, %20171"
"  %20171 = and i32 %20078, 65535"
"  %20171 = and i32 %20078, 65535" -> "  %20172 = add nuw nsw i32 %20170, %20171"
"  %20172 = add nuw nsw i32 %20170, %20171"
"  %20172 = add nuw nsw i32 %20170, %20171" -> "  %20176 = lshr i32 %20172, 16"
"  %20173 = and i32 %19408, 65535"
"  %20173 = and i32 %19408, 65535" -> "  %20175 = add nuw nsw i32 %20173, %20174"
"  %20174 = and i32 %20084, 65535"
"  %20174 = and i32 %20084, 65535" -> "  %20175 = add nuw nsw i32 %20173, %20174"
"  %20175 = add nuw nsw i32 %20173, %20174"
"  %20175 = add nuw nsw i32 %20173, %20174" -> "  %20189 = lshr i32 %20175, 16""  %20175 = add nuw nsw i32 %20173, %20174" -> "  %20177 = and i32 %20175, 65535"
"  %20176 = lshr i32 %20172, 16"
"  %20176 = lshr i32 %20172, 16" -> "  %20178 = add nuw nsw i32 %20177, %20176"
"  %20177 = and i32 %20175, 65535"
"  %20177 = and i32 %20175, 65535" -> "  %20178 = add nuw nsw i32 %20177, %20176"
"  %20178 = add nuw nsw i32 %20177, %20176"
"  %20178 = add nuw nsw i32 %20177, %20176" -> "  %20191 = lshr i32 %20178, 16"
"  %20179 = and i32 %20098, 65535"
"  %20179 = and i32 %20098, 65535" -> "  %20181 = add nuw nsw i32 %20180, %20179"
"  %20180 = and i32 %19410, 65535"
"  %20180 = and i32 %19410, 65535" -> "  %20181 = add nuw nsw i32 %20180, %20179"
"  %20181 = add nuw nsw i32 %20180, %20179"
"  %20181 = add nuw nsw i32 %20180, %20179" -> "  %20188 = and i32 %20181, 65535""  %20181 = add nuw nsw i32 %20180, %20179" -> "  %20185 = lshr i32 %20181, 16"
"  %20182 = and i32 %20101, 65535"
"  %20182 = and i32 %20101, 65535" -> "  %20184 = add nuw nsw i32 %20183, %20182"
"  %20183 = and i32 %19413, 65535"
"  %20183 = and i32 %19413, 65535" -> "  %20184 = add nuw nsw i32 %20183, %20182"
"  %20184 = add nuw nsw i32 %20183, %20182"
"  %20184 = add nuw nsw i32 %20183, %20182" -> "  %20226 = lshr i32 %20184, 16""  %20184 = add nuw nsw i32 %20183, %20182" -> "  %20186 = and i32 %20184, 65535"
"  %20185 = lshr i32 %20181, 16"
"  %20185 = lshr i32 %20181, 16" -> "  %20187 = add nuw nsw i32 %20186, %20185"
"  %20186 = and i32 %20184, 65535"
"  %20186 = and i32 %20184, 65535" -> "  %20187 = add nuw nsw i32 %20186, %20185"
"  %20187 = add nuw nsw i32 %20186, %20185"
"  %20187 = add nuw nsw i32 %20186, %20185" -> "  %20228 = lshr i32 %20187, 16""  %20187 = add nuw nsw i32 %20186, %20185" -> "  %20194 = and i32 %20187, 65535"
"  %20188 = and i32 %20181, 65535"
"  %20188 = and i32 %20181, 65535" -> "  %20190 = add nuw nsw i32 %20188, %20189"
"  %20189 = lshr i32 %20175, 16"
"  %20189 = lshr i32 %20175, 16" -> "  %20190 = add nuw nsw i32 %20188, %20189"
"  %20190 = add nuw nsw i32 %20188, %20189"
"  %20190 = add nuw nsw i32 %20188, %20189" -> "  %20192 = add nuw nsw i32 %20190, %20191"
"  %20191 = lshr i32 %20178, 16"
"  %20191 = lshr i32 %20178, 16" -> "  %20192 = add nuw nsw i32 %20190, %20191"
"  %20192 = add nuw nsw i32 %20190, %20191"
"  %20192 = add nuw nsw i32 %20190, %20191" -> "  %20193 = lshr i32 %20192, 16"
"  %20193 = lshr i32 %20192, 16"
"  %20193 = lshr i32 %20192, 16" -> "  %20195 = add nuw nsw i32 %20194, %20193"
"  %20194 = and i32 %20187, 65535"
"  %20194 = and i32 %20187, 65535" -> "  %20195 = add nuw nsw i32 %20194, %20193"
"  %20195 = add nuw nsw i32 %20194, %20193"
"  %20195 = add nuw nsw i32 %20194, %20193" -> "  %20230 = lshr i32 %20195, 16"
"  %20196 = and i32 %20137, 65535"
"  %20196 = and i32 %20137, 65535" -> "  %20198 = add nuw nsw i32 %20197, %20196"
"  %20197 = and i32 %19416, 65535"
"  %20197 = and i32 %19416, 65535" -> "  %20198 = add nuw nsw i32 %20197, %20196"
"  %20198 = add nuw nsw i32 %20197, %20196"
"  %20198 = add nuw nsw i32 %20197, %20196" -> "  %20225 = and i32 %20198, 65535""  %20198 = add nuw nsw i32 %20197, %20196" -> "  %20202 = lshr i32 %20198, 16"
"  %20199 = and i32 %20140, 65535"
"  %20199 = and i32 %20140, 65535" -> "  %20201 = add nuw nsw i32 %20200, %20199"
"  %20200 = and i32 %19419, 65535"
"  %20200 = and i32 %19419, 65535" -> "  %20201 = add nuw nsw i32 %20200, %20199"
"  %20201 = add nuw nsw i32 %20200, %20199"
"  %20201 = add nuw nsw i32 %20200, %20199" -> "  %20217 = lshr i32 %20201, 16""  %20201 = add nuw nsw i32 %20200, %20199" -> "  %20203 = and i32 %20201, 65535"
"  %20202 = lshr i32 %20198, 16"
"  %20202 = lshr i32 %20198, 16" -> "  %20204 = add nuw nsw i32 %20203, %20202"
"  %20203 = and i32 %20201, 65535"
"  %20203 = and i32 %20201, 65535" -> "  %20204 = add nuw nsw i32 %20203, %20202"
"  %20204 = add nuw nsw i32 %20203, %20202"
"  %20204 = add nuw nsw i32 %20203, %20202" -> "  %20232 = and i32 %20204, 65535""  %20204 = add nuw nsw i32 %20203, %20202" -> "  %20219 = lshr i32 %20204, 16"
"  %20205 = and i32 %20143, 65535"
"  %20205 = and i32 %20143, 65535" -> "  %20207 = add nuw nsw i32 %20206, %20205"
"  %20206 = and i32 %19421, 65535"
"  %20206 = and i32 %19421, 65535" -> "  %20207 = add nuw nsw i32 %20206, %20205"
"  %20207 = add nuw nsw i32 %20206, %20205"
"  %20207 = add nuw nsw i32 %20206, %20205" -> "  %20216 = and i32 %20207, 65535""  %20207 = add nuw nsw i32 %20206, %20205" -> "  %20211 = lshr i32 %20207, 16"
"  %20208 = and i32 %20146, 65535"
"  %20208 = and i32 %20146, 65535" -> "  %20210 = add nuw nsw i32 %20208, %20209"
"  %20209 = lshr i32 %19421, 16"
"  %20209 = lshr i32 %19421, 16" -> "  %20210 = add nuw nsw i32 %20208, %20209"
"  %20210 = add nuw nsw i32 %20208, %20209"
"  %20210 = add nuw nsw i32 %20208, %20209" -> "  %20214 = lshr i32 %20210, 16""  %20210 = add nuw nsw i32 %20208, %20209" -> "  %20212 = and i32 %20210, 65535"
"  %20211 = lshr i32 %20207, 16"
"  %20211 = lshr i32 %20207, 16" -> "  %20213 = add nuw nsw i32 %20212, %20211"
"  %20212 = and i32 %20210, 65535"
"  %20212 = and i32 %20210, 65535" -> "  %20213 = add nuw nsw i32 %20212, %20211"
"  %20213 = add nuw nsw i32 %20212, %20211"
"  %20213 = add nuw nsw i32 %20212, %20211" -> "  %20221 = and i32 %20213, 65535""  %20213 = add nuw nsw i32 %20212, %20211" -> "  %20215 = lshr i32 %20213, 16"
"  %20214 = lshr i32 %20210, 16"
"  %20214 = lshr i32 %20210, 16" -> "  %20244 = add nuw nsw i32 %20243, %20214"
"  %20215 = lshr i32 %20213, 16"
"  %20215 = lshr i32 %20213, 16" -> "  %20245 = add nuw nsw i32 %20244, %20215"
"  %20216 = and i32 %20207, 65535"
"  %20216 = and i32 %20207, 65535" -> "  %20218 = add nuw nsw i32 %20216, %20217"
"  %20217 = lshr i32 %20201, 16"
"  %20217 = lshr i32 %20201, 16" -> "  %20218 = add nuw nsw i32 %20216, %20217"
"  %20218 = add nuw nsw i32 %20216, %20217"
"  %20218 = add nuw nsw i32 %20216, %20217" -> "  %20220 = add nuw nsw i32 %20218, %20219"
"  %20219 = lshr i32 %20204, 16"
"  %20219 = lshr i32 %20204, 16" -> "  %20220 = add nuw nsw i32 %20218, %20219"
"  %20220 = add nuw nsw i32 %20218, %20219"
"  %20220 = add nuw nsw i32 %20218, %20219" -> "  %20235 = and i32 %20220, 65535""  %20220 = add nuw nsw i32 %20218, %20219" -> "  %20222 = lshr i32 %20220, 16"
"  %20221 = and i32 %20213, 65535"
"  %20221 = and i32 %20213, 65535" -> "  %20223 = add nuw nsw i32 %20222, %20221"
"  %20222 = lshr i32 %20220, 16"
"  %20222 = lshr i32 %20220, 16" -> "  %20223 = add nuw nsw i32 %20222, %20221"
"  %20223 = add nuw nsw i32 %20222, %20221"
"  %20223 = add nuw nsw i32 %20222, %20221" -> "  %20238 = and i32 %20223, 65535""  %20223 = add nuw nsw i32 %20222, %20221" -> "  %20224 = lshr i32 %20223, 16"
"  %20224 = lshr i32 %20223, 16"
"  %20224 = lshr i32 %20223, 16" -> "  %20246 = add nuw nsw i32 %20245, %20224"
"  %20225 = and i32 %20198, 65535"
"  %20225 = and i32 %20198, 65535" -> "  %20227 = add nuw nsw i32 %20225, %20226"
"  %20226 = lshr i32 %20184, 16"
"  %20226 = lshr i32 %20184, 16" -> "  %20227 = add nuw nsw i32 %20225, %20226"
"  %20227 = add nuw nsw i32 %20225, %20226"
"  %20227 = add nuw nsw i32 %20225, %20226" -> "  %20229 = add nuw nsw i32 %20227, %20228"
"  %20228 = lshr i32 %20187, 16"
"  %20228 = lshr i32 %20187, 16" -> "  %20229 = add nuw nsw i32 %20227, %20228"
"  %20229 = add nuw nsw i32 %20227, %20228"
"  %20229 = add nuw nsw i32 %20227, %20228" -> "  %20231 = add nuw nsw i32 %20229, %20230"
"  %20230 = lshr i32 %20195, 16"
"  %20230 = lshr i32 %20195, 16" -> "  %20231 = add nuw nsw i32 %20229, %20230"
"  %20231 = add nuw nsw i32 %20229, %20230"
"  %20231 = add nuw nsw i32 %20229, %20230" -> "  %20233 = lshr i32 %20231, 16"
"  %20232 = and i32 %20204, 65535"
"  %20232 = and i32 %20204, 65535" -> "  %20234 = add nuw nsw i32 %20233, %20232"
"  %20233 = lshr i32 %20231, 16"
"  %20233 = lshr i32 %20231, 16" -> "  %20234 = add nuw nsw i32 %20233, %20232"
"  %20234 = add nuw nsw i32 %20233, %20232"
"  %20234 = add nuw nsw i32 %20233, %20232" -> "  %20236 = lshr i32 %20234, 16"
"  %20235 = and i32 %20220, 65535"
"  %20235 = and i32 %20220, 65535" -> "  %20237 = add nuw nsw i32 %20235, %20236"
"  %20236 = lshr i32 %20234, 16"
"  %20236 = lshr i32 %20234, 16" -> "  %20237 = add nuw nsw i32 %20235, %20236"
"  %20237 = add nuw nsw i32 %20235, %20236"
"  %20237 = add nuw nsw i32 %20235, %20236" -> "  %20239 = lshr i32 %20237, 16"
"  %20238 = and i32 %20223, 65535"
"  %20238 = and i32 %20223, 65535" -> "  %20240 = add nuw nsw i32 %20239, %20238"
"  %20239 = lshr i32 %20237, 16"
"  %20239 = lshr i32 %20237, 16" -> "  %20240 = add nuw nsw i32 %20239, %20238"
"  %20240 = add nuw nsw i32 %20239, %20238"
"  %20240 = add nuw nsw i32 %20239, %20238" -> "  %20289 = lshr i32 %20240, 15""  %20240 = add nuw nsw i32 %20239, %20238" -> "  %20241 = lshr i32 %20240, 16"
"  %20241 = lshr i32 %20240, 16"
"  %20241 = lshr i32 %20240, 16" -> "  %20247 = add nuw nsw i32 %20246, %20241"
"  %20242 = and i32 %20155, 65535"
"  %20242 = and i32 %20155, 65535" -> "  %20250 = add nuw nsw i32 %20249, %20242"
"  %20243 = and i32 %20152, 65535"
"  %20243 = and i32 %20152, 65535" -> "  %20244 = add nuw nsw i32 %20243, %20214"
"  %20244 = add nuw nsw i32 %20243, %20214"
"  %20244 = add nuw nsw i32 %20243, %20214" -> "  %20245 = add nuw nsw i32 %20244, %20215"
"  %20245 = add nuw nsw i32 %20244, %20215"
"  %20245 = add nuw nsw i32 %20244, %20215" -> "  %20246 = add nuw nsw i32 %20245, %20224"
"  %20246 = add nuw nsw i32 %20245, %20224"
"  %20246 = add nuw nsw i32 %20245, %20224" -> "  %20247 = add nuw nsw i32 %20246, %20241"
"  %20247 = add nuw nsw i32 %20246, %20241"
"  %20247 = add nuw nsw i32 %20246, %20241" -> "  %20276 = and i32 %20247, 65535""  %20247 = add nuw nsw i32 %20246, %20241" -> "  %20249 = lshr i32 %20247, 16"
"  %20248 = and i32 %20158, 65535"
"  %20248 = and i32 %20158, 65535" -> "  %20252 = add nuw nsw i32 %20251, %20248"
"  %20249 = lshr i32 %20247, 16"
"  %20249 = lshr i32 %20247, 16" -> "  %20250 = add nuw nsw i32 %20249, %20242"
"  %20250 = add nuw nsw i32 %20249, %20242"
"  %20250 = add nuw nsw i32 %20249, %20242" -> "  %20251 = lshr i32 %20250, 16""  %20250 = add nuw nsw i32 %20249, %20242" -> "  %20278 = shl nuw nsw i32 %20250, 1""  %20250 = add nuw nsw i32 %20249, %20242" -> "  %20271 = lshr i32 %20250, 15"
"  %20251 = lshr i32 %20250, 16"
"  %20251 = lshr i32 %20250, 16" -> "  %20252 = add nuw nsw i32 %20251, %20248"
"  %20252 = add nuw nsw i32 %20251, %20248"
"  %20252 = add nuw nsw i32 %20251, %20248" -> "  %20273 = shl nuw nsw i32 %20252, 1""  %20252 = add nuw nsw i32 %20251, %20248" -> "  %20254 = lshr i32 %20252, 16""  %20252 = add nuw nsw i32 %20251, %20248" -> "  %20253 = lshr i32 %20252, 15"
"  %20253 = lshr i32 %20252, 15"
"  %20253 = lshr i32 %20252, 15" -> "  %20267 = and i32 %20253, 1"
"  %20254 = lshr i32 %20252, 16"
"  %20254 = lshr i32 %20252, 16" -> "  %20256 = add nuw nsw i32 %20254, %20255"
"  %20255 = and i32 %20161, 65535"
"  %20255 = and i32 %20161, 65535" -> "  %20256 = add nuw nsw i32 %20254, %20255"
"  %20256 = add nuw nsw i32 %20254, %20255"
"  %20256 = add nuw nsw i32 %20254, %20255" -> "  %20268 = shl nuw nsw i32 %20256, 1""  %20256 = add nuw nsw i32 %20254, %20255" -> "  %20258 = lshr i32 %20256, 16""  %20256 = add nuw nsw i32 %20254, %20255" -> "  %20257 = lshr i32 %20256, 15"
"  %20257 = lshr i32 %20256, 15"
"  %20257 = lshr i32 %20256, 15" -> "  %20285 = and i32 %20257, 1"
"  %20258 = lshr i32 %20256, 16"
"  %20258 = lshr i32 %20256, 16" -> "  %20260 = add nuw nsw i32 %20258, %20259"
"  %20259 = and i32 %20164, 65535"
"  %20259 = and i32 %20164, 65535" -> "  %20260 = add nuw nsw i32 %20258, %20259"
"  %20260 = add nuw nsw i32 %20258, %20259"
"  %20260 = add nuw nsw i32 %20258, %20259" -> "  %20491 = lshr i32 %20260, 15""  %20260 = add nuw nsw i32 %20258, %20259" -> "  %20286 = shl nuw nsw i32 %20260, 1""  %20260 = add nuw nsw i32 %20258, %20259" -> "  %20261 = lshr i32 %20260, 16"
"  %20261 = lshr i32 %20260, 16"
"  %20261 = lshr i32 %20260, 16" -> "  %20263 = add nuw nsw i32 %20261, %20262"
"  %20262 = and i32 %20167, 65535"
"  %20262 = and i32 %20167, 65535" -> "  %20263 = add nuw nsw i32 %20261, %20262"
"  %20263 = add nuw nsw i32 %20261, %20262"
"  %20263 = add nuw nsw i32 %20261, %20262" -> "  %20493 = shl nuw nsw i32 %20263, 1""  %20263 = add nuw nsw i32 %20261, %20262" -> "  %20265 = lshr i32 %20263, 16""  %20263 = add nuw nsw i32 %20261, %20262" -> "  %20264 = lshr i32 %20263, 15"
"  %20264 = lshr i32 %20263, 15"
"  %20264 = lshr i32 %20263, 15" -> "  %20281 = and i32 %20264, 1"
"  %20265 = lshr i32 %20263, 16"
"  %20265 = lshr i32 %20263, 16" -> "  %20266 = add nuw i32 %20169, %20265"
"  %20266 = add nuw i32 %20169, %20265"
"  %20266 = add nuw i32 %20169, %20265" -> "  %20514 = lshr i32 %20266, 15""  %20266 = add nuw i32 %20169, %20265" -> "  %20282 = shl i32 %20266, 1""  %20266 = add nuw i32 %20169, %20265" -> "  store i32 %20266, i32* %256, align 1, !noalias !74"
"  %20267 = and i32 %20253, 1"
"  %20267 = and i32 %20253, 1" -> "  %20270 = or i32 %20269, %20267"
"  %20268 = shl nuw nsw i32 %20256, 1"
"  %20268 = shl nuw nsw i32 %20256, 1" -> "  %20269 = and i32 %20268, 65534"
"  %20269 = and i32 %20268, 65534"
"  %20269 = and i32 %20268, 65534" -> "  %20270 = or i32 %20269, %20267"
"  %20270 = or i32 %20269, %20267"
"  %20270 = or i32 %20269, %20267" -> "  %20446 = mul nuw nsw i32 %20270, 1146""  %20270 = or i32 %20269, %20267" -> "  %20382 = mul nuw i32 %20270, 63663""  %20270 = or i32 %20269, %20267" -> "  %20378 = mul nuw nsw i32 %20270, 7935""  %20270 = or i32 %20269, %20267" -> "  %20354 = mul nuw i32 %20270, 34017""  %20270 = or i32 %20269, %20267" -> "  %20350 = mul nuw nsw i32 %20270, 17399"
"  %20271 = lshr i32 %20250, 15"
"  %20271 = lshr i32 %20250, 15" -> "  %20272 = and i32 %20271, 1"
"  %20272 = and i32 %20271, 1"
"  %20272 = and i32 %20271, 1" -> "  %20275 = or i32 %20274, %20272"
"  %20273 = shl nuw nsw i32 %20252, 1"
"  %20273 = shl nuw nsw i32 %20252, 1" -> "  %20274 = and i32 %20273, 65534"
"  %20274 = and i32 %20273, 65534"
"  %20274 = and i32 %20273, 65534" -> "  %20275 = or i32 %20274, %20272"
"  %20275 = or i32 %20274, %20272"
"  %20275 = or i32 %20274, %20272" -> "  %20374 = mul nuw nsw i32 %20275, 7935""  %20275 = or i32 %20274, %20272" -> "  %20444 = mul nuw nsw i32 %20275, 1146""  %20275 = or i32 %20274, %20272" -> "  %20443 = mul nuw i32 %20275, 43563""  %20275 = or i32 %20274, %20272" -> "  %20376 = mul nuw i32 %20275, 63663""  %20275 = or i32 %20274, %20272" -> "  %20345 = mul nuw i32 %20275, 34017""  %20275 = or i32 %20274, %20272" -> "  %20343 = mul nuw nsw i32 %20275, 17399"
"  %20276 = and i32 %20247, 65535"
"  %20276 = and i32 %20247, 65535" -> "  %20277 = lshr i32 %20276, 15""  %20276 = and i32 %20247, 65535" -> "  %20291 = shl nuw nsw i32 %20276, 1"
"  %20277 = lshr i32 %20276, 15"
"  %20277 = lshr i32 %20276, 15" -> "  %20280 = or i32 %20279, %20277"
"  %20278 = shl nuw nsw i32 %20250, 1"
"  %20278 = shl nuw nsw i32 %20250, 1" -> "  %20279 = and i32 %20278, 65534"
"  %20279 = and i32 %20278, 65534"
"  %20279 = and i32 %20278, 65534" -> "  %20280 = or i32 %20279, %20277"
"  %20280 = or i32 %20279, %20277"
"  %20280 = or i32 %20279, %20277" -> "  %20439 = mul nuw nsw i32 %20280, 13953""  %20280 = or i32 %20279, %20277" -> "  %20429 = mul nuw i32 %20280, 43563""  %20280 = or i32 %20279, %20277" -> "  %20425 = mul nuw nsw i32 %20280, 1146""  %20280 = or i32 %20279, %20277" -> "  %20323 = mul nuw i32 %20280, 63663""  %20280 = or i32 %20279, %20277" -> "  %20319 = mul nuw nsw i32 %20280, 7935""  %20280 = or i32 %20279, %20277" -> "  %20305 = mul nuw i32 %20280, 34017""  %20280 = or i32 %20279, %20277" -> "  %20301 = mul nuw nsw i32 %20280, 17399"
"  %20281 = and i32 %20264, 1"
"  %20281 = and i32 %20264, 1" -> "  %20284 = or i32 %20283, %20281"
"  store i32 %20266, i32* %256, align 1, !noalias !74"

"  %20282 = shl i32 %20266, 1"
"  %20282 = shl i32 %20266, 1" -> "  %20283 = and i32 %20282, 65534"
"  %20283 = and i32 %20282, 65534"
"  %20283 = and i32 %20282, 65534" -> "  %20284 = or i32 %20283, %20281"
"  %20284 = or i32 %20283, %20281"
"  %20284 = or i32 %20283, %20281" -> "  %20517 = mul nuw i32 %20284, 34017""  %20284 = or i32 %20283, %20281" -> "  %20518 = mul nuw nsw i32 %20284, 17399""  %20284 = or i32 %20283, %20281" -> "  store i32 %20284, i32* %288, align 1, !noalias !74"
"  store i32 %20284, i32* %288, align 1, !noalias !74"

"  %20285 = and i32 %20257, 1"
"  %20285 = and i32 %20257, 1" -> "  %20288 = or i32 %20287, %20285"
"  %20286 = shl nuw nsw i32 %20260, 1"
"  %20286 = shl nuw nsw i32 %20260, 1" -> "  %20287 = and i32 %20286, 65534"
"  %20287 = and i32 %20286, 65534"
"  %20287 = and i32 %20286, 65534" -> "  %20288 = or i32 %20287, %20285"
"  %20288 = or i32 %20287, %20285"
"  %20288 = or i32 %20287, %20285" -> "  %20484 = mul nuw nsw i32 %20288, 17399""  %20288 = or i32 %20287, %20285" -> "  %20486 = mul nuw i32 %20288, 34017""  %20288 = or i32 %20287, %20285" -> "  %20507 = mul nuw nsw i32 %20288, 7935""  %20288 = or i32 %20287, %20285" -> "  %20509 = mul nuw i32 %20288, 63663""  %20288 = or i32 %20287, %20285" -> "  store i32 %20288, i32* %651, align 1, !noalias !74"
"  store i32 %20288, i32* %651, align 1, !noalias !74"

"  %20289 = lshr i32 %20240, 15"
"  %20289 = lshr i32 %20240, 15" -> "  %20290 = and i32 %20289, 1"
"  %20290 = and i32 %20289, 1"
"  %20290 = and i32 %20289, 1" -> "  %20293 = or i32 %20292, %20290"
"  %20291 = shl nuw nsw i32 %20276, 1"
"  %20291 = shl nuw nsw i32 %20276, 1" -> "  %20292 = and i32 %20291, 65534"
"  %20292 = and i32 %20291, 65534"
"  %20292 = and i32 %20291, 65534" -> "  %20293 = or i32 %20292, %20290"
"  %20293 = or i32 %20292, %20290"
"  %20293 = or i32 %20292, %20290" -> "  %20418 = mul nuw nsw i32 %20293, 1146""  %20293 = or i32 %20292, %20290" -> "  %20420 = mul nuw i32 %20293, 43563""  %20293 = or i32 %20292, %20290" -> "  %20438 = mul nuw i32 %20293, 58377""  %20293 = or i32 %20292, %20290" -> "  %20436 = mul nuw nsw i32 %20293, 13953""  %20293 = or i32 %20292, %20290" -> "  %20314 = mul nuw i32 %20293, 63663""  %20293 = or i32 %20292, %20290" -> "  %20312 = mul nuw nsw i32 %20293, 7935""  %20293 = or i32 %20292, %20290" -> "  %20296 = mul nuw i32 %20293, 34017""  %20293 = or i32 %20292, %20290" -> "  %20294 = mul nuw nsw i32 %20293, 17399"
"  %20294 = mul nuw nsw i32 %20293, 17399"
"  %20294 = mul nuw nsw i32 %20293, 17399" -> "  %20558 = and i32 %20294, 65535""  %20294 = mul nuw nsw i32 %20293, 17399" -> "  %20295 = lshr i32 %20294, 16""  %20294 = mul nuw nsw i32 %20293, 17399" -> "  store i32 %20294, i32* %273, align 1, !noalias !74"
"  store i32 %20294, i32* %273, align 1, !noalias !74"

"  %20295 = lshr i32 %20294, 16"
"  %20295 = lshr i32 %20294, 16" -> "  %20298 = add nuw nsw i32 %20295, %20297"
"  %20296 = mul nuw i32 %20293, 34017"
"  %20296 = mul nuw i32 %20293, 34017" -> "  %20299 = and i32 %20296, -65536""  %20296 = mul nuw i32 %20293, 34017" -> "  %20297 = and i32 %20296, 65535"
"  %20297 = and i32 %20296, 65535"
"  %20297 = and i32 %20296, 65535" -> "  %20298 = add nuw nsw i32 %20295, %20297"
"  %20298 = add nuw nsw i32 %20295, %20297"
"  %20298 = add nuw nsw i32 %20295, %20297" -> "  %20300 = add nuw i32 %20298, %20299"
"  %20299 = and i32 %20296, -65536"
"  %20299 = and i32 %20296, -65536" -> "  %20300 = add nuw i32 %20298, %20299"
"  %20300 = add nuw i32 %20298, %20299"
"  %20300 = add nuw i32 %20298, %20299" -> "  %20304 = lshr i32 %20300, 16""  %20300 = add nuw i32 %20298, %20299" -> "  %20302 = and i32 %20300, 65535"
"  %20301 = mul nuw nsw i32 %20280, 17399"
"  %20301 = mul nuw nsw i32 %20280, 17399" -> "  %20303 = add nuw nsw i32 %20302, %20301"
"  %20302 = and i32 %20300, 65535"
"  %20302 = and i32 %20300, 65535" -> "  %20303 = add nuw nsw i32 %20302, %20301"
"  %20303 = add nuw nsw i32 %20302, %20301"
"  %20303 = add nuw nsw i32 %20302, %20301" -> "  %20560 = and i32 %20303, 65535""  %20303 = add nuw nsw i32 %20302, %20301" -> "  %20307 = lshr i32 %20303, 16""  %20303 = add nuw nsw i32 %20302, %20301" -> "  store i32 %20303, i32* %221, align 1, !noalias !74"
"  %20304 = lshr i32 %20300, 16"
"  %20304 = lshr i32 %20300, 16" -> "  %20306 = add nuw i32 %20304, %20305"
"  %20305 = mul nuw i32 %20280, 34017"
"  %20305 = mul nuw i32 %20280, 34017" -> "  %20306 = add nuw i32 %20304, %20305"
"  %20306 = add nuw i32 %20304, %20305"
"  %20306 = add nuw i32 %20304, %20305" -> "  %20310 = and i32 %20306, -65536""  %20306 = add nuw i32 %20304, %20305" -> "  %20308 = and i32 %20306, 65535"
"  store i32 %20303, i32* %221, align 1, !noalias !74"

"  %20307 = lshr i32 %20303, 16"
"  %20307 = lshr i32 %20303, 16" -> "  %20309 = add nuw nsw i32 %20307, %20308"
"  %20308 = and i32 %20306, 65535"
"  %20308 = and i32 %20306, 65535" -> "  %20309 = add nuw nsw i32 %20307, %20308"
"  %20309 = add nuw nsw i32 %20307, %20308"
"  %20309 = add nuw nsw i32 %20307, %20308" -> "  %20311 = add nuw i32 %20309, %20310"
"  %20310 = and i32 %20306, -65536"
"  %20310 = and i32 %20306, -65536" -> "  %20311 = add nuw i32 %20309, %20310"
"  %20311 = add nuw i32 %20309, %20310"
"  %20311 = add nuw i32 %20309, %20310" -> "  %20334 = lshr i32 %20311, 16""  %20311 = add nuw i32 %20309, %20310" -> "  %20330 = and i32 %20311, 65535"
"  %20312 = mul nuw nsw i32 %20293, 7935"
"  %20312 = mul nuw nsw i32 %20293, 7935" -> "  %20331 = and i32 %20312, 65535""  %20312 = mul nuw nsw i32 %20293, 7935" -> "  %20313 = lshr i32 %20312, 16"
"  %20313 = lshr i32 %20312, 16"
"  %20313 = lshr i32 %20312, 16" -> "  %20316 = add nuw nsw i32 %20313, %20315"
"  %20314 = mul nuw i32 %20293, 63663"
"  %20314 = mul nuw i32 %20293, 63663" -> "  %20317 = and i32 %20314, -65536""  %20314 = mul nuw i32 %20293, 63663" -> "  %20315 = and i32 %20314, 65535"
"  %20315 = and i32 %20314, 65535"
"  %20315 = and i32 %20314, 65535" -> "  %20316 = add nuw nsw i32 %20313, %20315"
"  %20316 = add nuw nsw i32 %20313, %20315"
"  %20316 = add nuw nsw i32 %20313, %20315" -> "  %20318 = add nuw i32 %20316, %20317"
"  %20317 = and i32 %20314, -65536"
"  %20317 = and i32 %20314, -65536" -> "  %20318 = add nuw i32 %20316, %20317"
"  %20318 = add nuw i32 %20316, %20317"
"  %20318 = add nuw i32 %20316, %20317" -> "  %20322 = lshr i32 %20318, 16""  %20318 = add nuw i32 %20316, %20317" -> "  %20320 = and i32 %20318, 65535"
"  %20319 = mul nuw nsw i32 %20280, 7935"
"  %20319 = mul nuw nsw i32 %20280, 7935" -> "  %20321 = add nuw nsw i32 %20320, %20319"
"  %20320 = and i32 %20318, 65535"
"  %20320 = and i32 %20318, 65535" -> "  %20321 = add nuw nsw i32 %20320, %20319"
"  %20321 = add nuw nsw i32 %20320, %20319"
"  %20321 = add nuw nsw i32 %20320, %20319" -> "  %20333 = and i32 %20321, 65535""  %20321 = add nuw nsw i32 %20320, %20319" -> "  %20325 = lshr i32 %20321, 16"
"  %20322 = lshr i32 %20318, 16"
"  %20322 = lshr i32 %20318, 16" -> "  %20324 = add nuw i32 %20322, %20323"
"  %20323 = mul nuw i32 %20280, 63663"
"  %20323 = mul nuw i32 %20280, 63663" -> "  %20324 = add nuw i32 %20322, %20323"
"  %20324 = add nuw i32 %20322, %20323"
"  %20324 = add nuw i32 %20322, %20323" -> "  %20328 = and i32 %20324, -65536""  %20324 = add nuw i32 %20322, %20323" -> "  %20326 = and i32 %20324, 65535"
"  %20325 = lshr i32 %20321, 16"
"  %20325 = lshr i32 %20321, 16" -> "  %20327 = add nuw nsw i32 %20325, %20326"
"  %20326 = and i32 %20324, 65535"
"  %20326 = and i32 %20324, 65535" -> "  %20327 = add nuw nsw i32 %20325, %20326"
"  %20327 = add nuw nsw i32 %20325, %20326"
"  %20327 = add nuw nsw i32 %20325, %20326" -> "  %20329 = add nuw i32 %20327, %20328"
"  %20328 = and i32 %20324, -65536"
"  %20328 = and i32 %20324, -65536" -> "  %20329 = add nuw i32 %20327, %20328"
"  %20329 = add nuw i32 %20327, %20328"
"  %20329 = add nuw i32 %20327, %20328" -> "  %20337 = add nuw i32 %20329, %20336"
"  %20330 = and i32 %20311, 65535"
"  %20330 = and i32 %20311, 65535" -> "  %20332 = add nuw nsw i32 %20330, %20331"
"  %20331 = and i32 %20312, 65535"
"  %20331 = and i32 %20312, 65535" -> "  %20332 = add nuw nsw i32 %20330, %20331"
"  %20332 = add nuw nsw i32 %20330, %20331"
"  %20332 = add nuw nsw i32 %20330, %20331" -> "  %20361 = and i32 %20332, 65535""  %20332 = add nuw nsw i32 %20330, %20331" -> "  %20339 = lshr i32 %20332, 16"
"  %20333 = and i32 %20321, 65535"
"  %20333 = and i32 %20321, 65535" -> "  %20335 = add nuw nsw i32 %20334, %20333"
"  %20334 = lshr i32 %20311, 16"
"  %20334 = lshr i32 %20311, 16" -> "  %20335 = add nuw nsw i32 %20334, %20333"
"  %20335 = add nuw nsw i32 %20334, %20333"
"  %20335 = add nuw nsw i32 %20334, %20333" -> "  %20338 = and i32 %20335, 65535""  %20335 = add nuw nsw i32 %20334, %20333" -> "  %20336 = lshr i32 %20335, 16"
"  %20336 = lshr i32 %20335, 16"
"  %20336 = lshr i32 %20335, 16" -> "  %20337 = add nuw i32 %20329, %20336"
"  %20337 = add nuw i32 %20329, %20336"
"  %20337 = add nuw i32 %20329, %20336" -> "  %20342 = add nuw i32 %20337, %20341"
"  %20338 = and i32 %20335, 65535"
"  %20338 = and i32 %20335, 65535" -> "  %20340 = add nuw nsw i32 %20339, %20338"
"  %20339 = lshr i32 %20332, 16"
"  %20339 = lshr i32 %20332, 16" -> "  %20340 = add nuw nsw i32 %20339, %20338"
"  %20340 = add nuw nsw i32 %20339, %20338"
"  %20340 = add nuw nsw i32 %20339, %20338" -> "  %20364 = and i32 %20340, 65535""  %20340 = add nuw nsw i32 %20339, %20338" -> "  %20341 = lshr i32 %20340, 16"
"  %20341 = lshr i32 %20340, 16"
"  %20341 = lshr i32 %20340, 16" -> "  %20342 = add nuw i32 %20337, %20341"
"  %20342 = add nuw i32 %20337, %20341"
"  %20342 = add nuw i32 %20337, %20341" -> "  %20393 = lshr i32 %20342, 16""  %20342 = add nuw i32 %20337, %20341" -> "  %20389 = and i32 %20342, 65535"
"  %20343 = mul nuw nsw i32 %20275, 17399"
"  %20343 = mul nuw nsw i32 %20275, 17399" -> "  %20362 = and i32 %20343, 65535""  %20343 = mul nuw nsw i32 %20275, 17399" -> "  %20344 = lshr i32 %20343, 16"
"  %20344 = lshr i32 %20343, 16"
"  %20344 = lshr i32 %20343, 16" -> "  %20347 = add nuw nsw i32 %20344, %20346"
"  %20345 = mul nuw i32 %20275, 34017"
"  %20345 = mul nuw i32 %20275, 34017" -> "  %20348 = and i32 %20345, -65536""  %20345 = mul nuw i32 %20275, 34017" -> "  %20346 = and i32 %20345, 65535"
"  %20346 = and i32 %20345, 65535"
"  %20346 = and i32 %20345, 65535" -> "  %20347 = add nuw nsw i32 %20344, %20346"
"  %20347 = add nuw nsw i32 %20344, %20346"
"  %20347 = add nuw nsw i32 %20344, %20346" -> "  %20349 = add nuw i32 %20347, %20348"
"  %20348 = and i32 %20345, -65536"
"  %20348 = and i32 %20345, -65536" -> "  %20349 = add nuw i32 %20347, %20348"
"  %20349 = add nuw i32 %20347, %20348"
"  %20349 = add nuw i32 %20347, %20348" -> "  %20353 = lshr i32 %20349, 16""  %20349 = add nuw i32 %20347, %20348" -> "  %20351 = and i32 %20349, 65535"
"  %20350 = mul nuw nsw i32 %20270, 17399"
"  %20350 = mul nuw nsw i32 %20270, 17399" -> "  %20352 = add nuw nsw i32 %20351, %20350"
"  %20351 = and i32 %20349, 65535"
"  %20351 = and i32 %20349, 65535" -> "  %20352 = add nuw nsw i32 %20351, %20350"
"  %20352 = add nuw nsw i32 %20351, %20350"
"  %20352 = add nuw nsw i32 %20351, %20350" -> "  %20365 = and i32 %20352, 65535""  %20352 = add nuw nsw i32 %20351, %20350" -> "  %20356 = lshr i32 %20352, 16"
"  %20353 = lshr i32 %20349, 16"
"  %20353 = lshr i32 %20349, 16" -> "  %20355 = add nuw i32 %20353, %20354"
"  %20354 = mul nuw i32 %20270, 34017"
"  %20354 = mul nuw i32 %20270, 34017" -> "  %20355 = add nuw i32 %20353, %20354"
"  %20355 = add nuw i32 %20353, %20354"
"  %20355 = add nuw i32 %20353, %20354" -> "  %20359 = and i32 %20355, -65536""  %20355 = add nuw i32 %20353, %20354" -> "  %20357 = and i32 %20355, 65535"
"  %20356 = lshr i32 %20352, 16"
"  %20356 = lshr i32 %20352, 16" -> "  %20358 = add nuw nsw i32 %20356, %20357"
"  %20357 = and i32 %20355, 65535"
"  %20357 = and i32 %20355, 65535" -> "  %20358 = add nuw nsw i32 %20356, %20357"
"  %20358 = add nuw nsw i32 %20356, %20357"
"  %20358 = add nuw nsw i32 %20356, %20357" -> "  %20360 = add nuw i32 %20358, %20359"
"  %20359 = and i32 %20355, -65536"
"  %20359 = and i32 %20355, -65536" -> "  %20360 = add nuw i32 %20358, %20359"
"  %20360 = add nuw i32 %20358, %20359"
"  %20360 = add nuw i32 %20358, %20359" -> "  %20368 = add nuw i32 %20360, %20367"
"  %20361 = and i32 %20332, 65535"
"  %20361 = and i32 %20332, 65535" -> "  %20363 = add nuw nsw i32 %20361, %20362"
"  %20362 = and i32 %20343, 65535"
"  %20362 = and i32 %20343, 65535" -> "  %20363 = add nuw nsw i32 %20361, %20362"
"  %20363 = add nuw nsw i32 %20361, %20362"
"  %20363 = add nuw nsw i32 %20361, %20362" -> "  %20564 = and i32 %20363, 65535""  %20363 = add nuw nsw i32 %20361, %20362" -> "  %20370 = lshr i32 %20363, 16"
"  %20364 = and i32 %20340, 65535"
"  %20364 = and i32 %20340, 65535" -> "  %20366 = add nuw nsw i32 %20364, %20365"
"  %20365 = and i32 %20352, 65535"
"  %20365 = and i32 %20352, 65535" -> "  %20366 = add nuw nsw i32 %20364, %20365"
"  %20366 = add nuw nsw i32 %20364, %20365"
"  %20366 = add nuw nsw i32 %20364, %20365" -> "  %20369 = and i32 %20366, 65535""  %20366 = add nuw nsw i32 %20364, %20365" -> "  %20367 = lshr i32 %20366, 16"
"  %20367 = lshr i32 %20366, 16"
"  %20367 = lshr i32 %20366, 16" -> "  %20368 = add nuw i32 %20360, %20367"
"  %20368 = add nuw i32 %20360, %20367"
"  %20368 = add nuw i32 %20360, %20367" -> "  %20373 = add nuw i32 %20368, %20372"
"  %20369 = and i32 %20366, 65535"
"  %20369 = and i32 %20366, 65535" -> "  %20371 = add nuw nsw i32 %20369, %20370"
"  %20370 = lshr i32 %20363, 16"
"  %20370 = lshr i32 %20363, 16" -> "  %20371 = add nuw nsw i32 %20369, %20370"
"  %20371 = add nuw nsw i32 %20369, %20370"
"  %20371 = add nuw nsw i32 %20369, %20370" -> "  %20569 = and i32 %20371, 65535""  %20371 = add nuw nsw i32 %20369, %20370" -> "  %20372 = lshr i32 %20371, 16""  %20371 = add nuw nsw i32 %20369, %20370" -> "  store i32 %20371, i32* %260, align 1, !noalias !74"
"  store i32 %20371, i32* %260, align 1, !noalias !74"

"  %20372 = lshr i32 %20371, 16"
"  %20372 = lshr i32 %20371, 16" -> "  %20373 = add nuw i32 %20368, %20372"
"  %20373 = add nuw i32 %20368, %20372"
"  %20373 = add nuw i32 %20368, %20372" -> "  %20406 = lshr i32 %20373, 16""  %20373 = add nuw i32 %20368, %20372" -> "  %20403 = and i32 %20373, 65535"
"  %20374 = mul nuw nsw i32 %20275, 7935"
"  %20374 = mul nuw nsw i32 %20275, 7935" -> "  %20390 = and i32 %20374, 65535""  %20374 = mul nuw nsw i32 %20275, 7935" -> "  %20375 = lshr i32 %20374, 16"
"  %20375 = lshr i32 %20374, 16"
"  %20375 = lshr i32 %20374, 16" -> "  %20377 = add i32 %20375, %20376"
"  %20376 = mul nuw i32 %20275, 63663"
"  %20376 = mul nuw i32 %20275, 63663" -> "  %20377 = add i32 %20375, %20376"
"  %20377 = add i32 %20375, %20376"
"  %20377 = add i32 %20375, %20376" -> "  %20381 = lshr i32 %20377, 16""  %20377 = add i32 %20375, %20376" -> "  %20379 = and i32 %20377, 65535"
"  %20378 = mul nuw nsw i32 %20270, 7935"
"  %20378 = mul nuw nsw i32 %20270, 7935" -> "  %20380 = add nuw nsw i32 %20379, %20378"
"  %20379 = and i32 %20377, 65535"
"  %20379 = and i32 %20377, 65535" -> "  %20380 = add nuw nsw i32 %20379, %20378"
"  %20380 = add nuw nsw i32 %20379, %20378"
"  %20380 = add nuw nsw i32 %20379, %20378" -> "  %20392 = and i32 %20380, 65535""  %20380 = add nuw nsw i32 %20379, %20378" -> "  %20384 = lshr i32 %20380, 16"
"  %20381 = lshr i32 %20377, 16"
"  %20381 = lshr i32 %20377, 16" -> "  %20383 = add nuw i32 %20381, %20382"
"  %20382 = mul nuw i32 %20270, 63663"
"  %20382 = mul nuw i32 %20270, 63663" -> "  %20383 = add nuw i32 %20381, %20382"
"  %20383 = add nuw i32 %20381, %20382"
"  %20383 = add nuw i32 %20381, %20382" -> "  %20387 = and i32 %20383, -65536""  %20383 = add nuw i32 %20381, %20382" -> "  %20385 = and i32 %20383, 65535"
"  %20384 = lshr i32 %20380, 16"
"  %20384 = lshr i32 %20380, 16" -> "  %20386 = add nuw nsw i32 %20384, %20385"
"  %20385 = and i32 %20383, 65535"
"  %20385 = and i32 %20383, 65535" -> "  %20386 = add nuw nsw i32 %20384, %20385"
"  %20386 = add nuw nsw i32 %20384, %20385"
"  %20386 = add nuw nsw i32 %20384, %20385" -> "  %20388 = add nuw i32 %20386, %20387"
"  %20387 = and i32 %20383, -65536"
"  %20387 = and i32 %20383, -65536" -> "  %20388 = add nuw i32 %20386, %20387"
"  %20388 = add nuw i32 %20386, %20387"
"  %20388 = add nuw i32 %20386, %20387" -> "  %20396 = add nuw i32 %20388, %20395"
"  %20389 = and i32 %20342, 65535"
"  %20389 = and i32 %20342, 65535" -> "  %20391 = add nuw nsw i32 %20389, %20390"
"  %20390 = and i32 %20374, 65535"
"  %20390 = and i32 %20374, 65535" -> "  %20391 = add nuw nsw i32 %20389, %20390"
"  %20391 = add nuw nsw i32 %20389, %20390"
"  %20391 = add nuw nsw i32 %20389, %20390" -> "  %20402 = and i32 %20391, 65535""  %20391 = add nuw nsw i32 %20389, %20390" -> "  %20398 = lshr i32 %20391, 16"
"  %20392 = and i32 %20380, 65535"
"  %20392 = and i32 %20380, 65535" -> "  %20394 = add nuw nsw i32 %20393, %20392"
"  %20393 = lshr i32 %20342, 16"
"  %20393 = lshr i32 %20342, 16" -> "  %20394 = add nuw nsw i32 %20393, %20392"
"  %20394 = add nuw nsw i32 %20393, %20392"
"  %20394 = add nuw nsw i32 %20393, %20392" -> "  %20397 = and i32 %20394, 65535""  %20394 = add nuw nsw i32 %20393, %20392" -> "  %20395 = lshr i32 %20394, 16"
"  %20395 = lshr i32 %20394, 16"
"  %20395 = lshr i32 %20394, 16" -> "  %20396 = add nuw i32 %20388, %20395"
"  %20396 = add nuw i32 %20388, %20395"
"  %20396 = add nuw i32 %20388, %20395" -> "  %20401 = add nuw i32 %20396, %20400"
"  %20397 = and i32 %20394, 65535"
"  %20397 = and i32 %20394, 65535" -> "  %20399 = add nuw nsw i32 %20398, %20397"
"  %20398 = lshr i32 %20391, 16"
"  %20398 = lshr i32 %20391, 16" -> "  %20399 = add nuw nsw i32 %20398, %20397"
"  %20399 = add nuw nsw i32 %20398, %20397"
"  %20399 = add nuw nsw i32 %20398, %20397" -> "  %20405 = and i32 %20399, 65535""  %20399 = add nuw nsw i32 %20398, %20397" -> "  %20400 = lshr i32 %20399, 16"
"  %20400 = lshr i32 %20399, 16"
"  %20400 = lshr i32 %20399, 16" -> "  %20401 = add nuw i32 %20396, %20400"
"  %20401 = add nuw i32 %20396, %20400"
"  %20401 = add nuw i32 %20396, %20400" -> "  %20414 = and i32 %20401, -65536""  %20401 = add nuw i32 %20396, %20400" -> "  %20412 = and i32 %20401, 65535"
"  %20402 = and i32 %20391, 65535"
"  %20402 = and i32 %20391, 65535" -> "  %20404 = add nuw nsw i32 %20403, %20402"
"  %20403 = and i32 %20373, 65535"
"  %20403 = and i32 %20373, 65535" -> "  %20404 = add nuw nsw i32 %20403, %20402"
"  %20404 = add nuw nsw i32 %20403, %20402"
"  %20404 = add nuw nsw i32 %20403, %20402" -> "  %20455 = and i32 %20404, 65535""  %20404 = add nuw nsw i32 %20403, %20402" -> "  %20408 = lshr i32 %20404, 16"
"  %20405 = and i32 %20399, 65535"
"  %20405 = and i32 %20399, 65535" -> "  %20407 = add nuw nsw i32 %20406, %20405"
"  %20406 = lshr i32 %20373, 16"
"  %20406 = lshr i32 %20373, 16" -> "  %20407 = add nuw nsw i32 %20406, %20405"
"  %20407 = add nuw nsw i32 %20406, %20405"
"  %20407 = add nuw nsw i32 %20406, %20405" -> "  %20411 = lshr i32 %20407, 16""  %20407 = add nuw nsw i32 %20406, %20405" -> "  %20409 = and i32 %20407, 65535"
"  %20408 = lshr i32 %20404, 16"
"  %20408 = lshr i32 %20404, 16" -> "  %20410 = add nuw nsw i32 %20408, %20409"
"  %20409 = and i32 %20407, 65535"
"  %20409 = and i32 %20407, 65535" -> "  %20410 = add nuw nsw i32 %20408, %20409"
"  %20410 = add nuw nsw i32 %20408, %20409"
"  %20410 = add nuw nsw i32 %20408, %20409" -> "  %20458 = and i32 %20410, 65535""  %20410 = add nuw nsw i32 %20408, %20409" -> "  %20416 = lshr i32 %20410, 16"
"  %20411 = lshr i32 %20407, 16"
"  %20411 = lshr i32 %20407, 16" -> "  %20413 = add nuw nsw i32 %20411, %20412"
"  %20412 = and i32 %20401, 65535"
"  %20412 = and i32 %20401, 65535" -> "  %20413 = add nuw nsw i32 %20411, %20412"
"  %20413 = add nuw nsw i32 %20411, %20412"
"  %20413 = add nuw nsw i32 %20411, %20412" -> "  %20415 = add nuw i32 %20413, %20414"
"  %20414 = and i32 %20401, -65536"
"  %20414 = and i32 %20401, -65536" -> "  %20415 = add nuw i32 %20413, %20414"
"  %20415 = add nuw i32 %20413, %20414"
"  %20415 = add nuw i32 %20413, %20414" -> "  %20417 = add nuw i32 %20415, %20416"
"  %20416 = lshr i32 %20410, 16"
"  %20416 = lshr i32 %20410, 16" -> "  %20417 = add nuw i32 %20415, %20416"
"  %20417 = add nuw i32 %20415, %20416"
"  %20417 = add nuw i32 %20415, %20416" -> "  %20464 = and i32 %20417, 65535""  %20417 = add nuw i32 %20415, %20416" -> "  %20453 = lshr i32 %20417, 16"
"  %20418 = mul nuw nsw i32 %20293, 1146"
"  %20418 = mul nuw nsw i32 %20293, 1146" -> "  %20454 = and i32 %20418, 65534""  %20418 = mul nuw nsw i32 %20293, 1146" -> "  %20419 = lshr i32 %20418, 16"
"  %20419 = lshr i32 %20418, 16"
"  %20419 = lshr i32 %20418, 16" -> "  %20422 = add nuw nsw i32 %20421, %20419"
"  %20420 = mul nuw i32 %20293, 43563"
"  %20420 = mul nuw i32 %20293, 43563" -> "  %20421 = and i32 %20420, 65535""  %20420 = mul nuw i32 %20293, 43563" -> "  %20423 = and i32 %20420, -65536"
"  %20421 = and i32 %20420, 65535"
"  %20421 = and i32 %20420, 65535" -> "  %20422 = add nuw nsw i32 %20421, %20419"
"  %20422 = add nuw nsw i32 %20421, %20419"
"  %20422 = add nuw nsw i32 %20421, %20419" -> "  %20424 = add i32 %20422, %20423"
"  %20423 = and i32 %20420, -65536"
"  %20423 = and i32 %20420, -65536" -> "  %20424 = add i32 %20422, %20423"
"  %20424 = add i32 %20422, %20423"
"  %20424 = add i32 %20422, %20423" -> "  %20428 = lshr i32 %20424, 16""  %20424 = add i32 %20422, %20423" -> "  %20426 = and i32 %20424, 65535"
"  %20425 = mul nuw nsw i32 %20280, 1146"
"  %20425 = mul nuw nsw i32 %20280, 1146" -> "  %20427 = add nuw nsw i32 %20426, %20425"
"  %20426 = and i32 %20424, 65535"
"  %20426 = and i32 %20424, 65535" -> "  %20427 = add nuw nsw i32 %20426, %20425"
"  %20427 = add nuw nsw i32 %20426, %20425"
"  %20427 = add nuw nsw i32 %20426, %20425" -> "  %20457 = and i32 %20427, 65535""  %20427 = add nuw nsw i32 %20426, %20425" -> "  %20431 = lshr i32 %20427, 16"
"  %20428 = lshr i32 %20424, 16"
"  %20428 = lshr i32 %20424, 16" -> "  %20430 = add i32 %20428, %20429"
"  %20429 = mul nuw i32 %20280, 43563"
"  %20429 = mul nuw i32 %20280, 43563" -> "  %20430 = add i32 %20428, %20429"
"  %20430 = add i32 %20428, %20429"
"  %20430 = add i32 %20428, %20429" -> "  %20434 = and i32 %20430, -65536""  %20430 = add i32 %20428, %20429" -> "  %20432 = and i32 %20430, 65535"
"  %20431 = lshr i32 %20427, 16"
"  %20431 = lshr i32 %20427, 16" -> "  %20433 = add nuw nsw i32 %20431, %20432"
"  %20432 = and i32 %20430, 65535"
"  %20432 = and i32 %20430, 65535" -> "  %20433 = add nuw nsw i32 %20431, %20432"
"  %20433 = add nuw nsw i32 %20431, %20432"
"  %20433 = add nuw nsw i32 %20431, %20432" -> "  %20435 = add i32 %20433, %20434"
"  %20434 = and i32 %20430, -65536"
"  %20434 = and i32 %20430, -65536" -> "  %20435 = add i32 %20433, %20434"
"  %20435 = add i32 %20433, %20434"
"  %20435 = add i32 %20433, %20434" -> "  %20447 = lshr i32 %20435, 16""  %20435 = add i32 %20433, %20434" -> "  %20440 = and i32 %20435, 65535"
"  %20436 = mul nuw nsw i32 %20293, 13953"
"  %20436 = mul nuw nsw i32 %20293, 13953" -> "  %20441 = and i32 %20436, 65535""  %20436 = mul nuw nsw i32 %20293, 13953" -> "  %20437 = lshr i32 %20436, 16"
"  %20437 = lshr i32 %20436, 16"
"  %20437 = lshr i32 %20436, 16" -> "  %20474 = add i32 %20473, %20437"
"  %20438 = mul nuw i32 %20293, 58377"
"  %20438 = mul nuw i32 %20293, 58377" -> "  %20473 = add i32 %20439, %20438"
"  %20439 = mul nuw nsw i32 %20280, 13953"
"  %20439 = mul nuw nsw i32 %20280, 13953" -> "  %20473 = add i32 %20439, %20438"
"  %20440 = and i32 %20435, 65535"
"  %20440 = and i32 %20435, 65535" -> "  %20442 = add nuw nsw i32 %20440, %20441"
"  %20441 = and i32 %20436, 65535"
"  %20441 = and i32 %20436, 65535" -> "  %20442 = add nuw nsw i32 %20440, %20441"
"  %20442 = add nuw nsw i32 %20440, %20441"
"  %20442 = add nuw nsw i32 %20440, %20441" -> "  %20449 = and i32 %20442, 65535""  %20442 = add nuw nsw i32 %20440, %20441" -> "  %20448 = lshr i32 %20442, 16"
"  %20443 = mul nuw i32 %20275, 43563"
"  %20443 = mul nuw i32 %20275, 43563" -> "  %20475 = add i32 %20474, %20443"
"  %20444 = mul nuw nsw i32 %20275, 1146"
"  %20444 = mul nuw nsw i32 %20275, 1146" -> "  %20450 = and i32 %20444, 65534""  %20444 = mul nuw nsw i32 %20275, 1146" -> "  %20445 = lshr i32 %20444, 16"
"  %20445 = lshr i32 %20444, 16"
"  %20445 = lshr i32 %20444, 16" -> "  %20476 = add i32 %20475, %20445"
"  %20446 = mul nuw nsw i32 %20270, 1146"
"  %20446 = mul nuw nsw i32 %20270, 1146" -> "  %20477 = add i32 %20476, %20446"
"  %20447 = lshr i32 %20435, 16"
"  %20447 = lshr i32 %20435, 16" -> "  %20478 = add i32 %20477, %20447"
"  %20448 = lshr i32 %20442, 16"
"  %20448 = lshr i32 %20442, 16" -> "  %20479 = add i32 %20478, %20448"
"  %20449 = and i32 %20442, 65535"
"  %20449 = and i32 %20442, 65535" -> "  %20451 = add nuw nsw i32 %20449, %20450"
"  %20450 = and i32 %20444, 65534"
"  %20450 = and i32 %20444, 65534" -> "  %20451 = add nuw nsw i32 %20449, %20450"
"  %20451 = add nuw nsw i32 %20449, %20450"
"  %20451 = add nuw nsw i32 %20449, %20450" -> "  %20463 = and i32 %20451, 65535""  %20451 = add nuw nsw i32 %20449, %20450" -> "  %20452 = lshr i32 %20451, 16"
"  %20452 = lshr i32 %20451, 16"
"  %20452 = lshr i32 %20451, 16" -> "  %20480 = add i32 %20479, %20452"
"  %20453 = lshr i32 %20417, 16"
"  %20453 = lshr i32 %20417, 16" -> "  %20481 = add i32 %20480, %20453"
"  %20454 = and i32 %20418, 65534"
"  %20454 = and i32 %20418, 65534" -> "  %20456 = add nuw nsw i32 %20455, %20454"
"  %20455 = and i32 %20404, 65535"
"  %20455 = and i32 %20404, 65535" -> "  %20456 = add nuw nsw i32 %20455, %20454"
"  %20456 = add nuw nsw i32 %20455, %20454"
"  %20456 = add nuw nsw i32 %20455, %20454" -> "  %20534 = and i32 %20456, 65535""  %20456 = add nuw nsw i32 %20455, %20454" -> "  %20460 = lshr i32 %20456, 16"
"  %20457 = and i32 %20427, 65535"
"  %20457 = and i32 %20427, 65535" -> "  %20459 = add nuw nsw i32 %20458, %20457"
"  %20458 = and i32 %20410, 65535"
"  %20458 = and i32 %20410, 65535" -> "  %20459 = add nuw nsw i32 %20458, %20457"
"  %20459 = add nuw nsw i32 %20458, %20457"
"  %20459 = add nuw nsw i32 %20458, %20457" -> "  %20468 = lshr i32 %20459, 16""  %20459 = add nuw nsw i32 %20458, %20457" -> "  %20461 = and i32 %20459, 65535"
"  %20460 = lshr i32 %20456, 16"
"  %20460 = lshr i32 %20456, 16" -> "  %20462 = add nuw nsw i32 %20461, %20460"
"  %20461 = and i32 %20459, 65535"
"  %20461 = and i32 %20459, 65535" -> "  %20462 = add nuw nsw i32 %20461, %20460"
"  %20462 = add nuw nsw i32 %20461, %20460"
"  %20462 = add nuw nsw i32 %20461, %20460" -> "  %20537 = and i32 %20462, 65535""  %20462 = add nuw nsw i32 %20461, %20460" -> "  %20469 = lshr i32 %20462, 16"
"  %20463 = and i32 %20451, 65535"
"  %20463 = and i32 %20451, 65535" -> "  %20465 = add nuw nsw i32 %20464, %20463"
"  %20464 = and i32 %20417, 65535"
"  %20464 = and i32 %20417, 65535" -> "  %20465 = add nuw nsw i32 %20464, %20463"
"  %20465 = add nuw nsw i32 %20464, %20463"
"  %20465 = add nuw nsw i32 %20464, %20463" -> "  %20467 = and i32 %20465, 65535""  %20465 = add nuw nsw i32 %20464, %20463" -> "  %20466 = lshr i32 %20465, 16"
"  %20466 = lshr i32 %20465, 16"
"  %20466 = lshr i32 %20465, 16" -> "  %20482 = add i32 %20481, %20466"
"  %20467 = and i32 %20465, 65535"
"  %20467 = and i32 %20465, 65535" -> "  %20471 = add nuw nsw i32 %20470, %20467"
"  %20468 = lshr i32 %20459, 16"
"  %20468 = lshr i32 %20459, 16" -> "  %20470 = add nuw nsw i32 %20469, %20468"
"  %20469 = lshr i32 %20462, 16"
"  %20469 = lshr i32 %20462, 16" -> "  %20470 = add nuw nsw i32 %20469, %20468"
"  %20470 = add nuw nsw i32 %20469, %20468"
"  %20470 = add nuw nsw i32 %20469, %20468" -> "  %20471 = add nuw nsw i32 %20470, %20467"
"  %20471 = add nuw nsw i32 %20470, %20467"
"  %20471 = add nuw nsw i32 %20470, %20467" -> "  %20547 = and i32 %20471, 65535""  %20471 = add nuw nsw i32 %20470, %20467" -> "  %20472 = lshr i32 %20471, 16"
"  %20472 = lshr i32 %20471, 16"
"  %20472 = lshr i32 %20471, 16" -> "  %20483 = add i32 %20482, %20472"
"  %20473 = add i32 %20439, %20438"
"  %20473 = add i32 %20439, %20438" -> "  %20474 = add i32 %20473, %20437"
"  %20474 = add i32 %20473, %20437"
"  %20474 = add i32 %20473, %20437" -> "  %20475 = add i32 %20474, %20443"
"  %20475 = add i32 %20474, %20443"
"  %20475 = add i32 %20474, %20443" -> "  %20476 = add i32 %20475, %20445"
"  %20476 = add i32 %20475, %20445"
"  %20476 = add i32 %20475, %20445" -> "  %20477 = add i32 %20476, %20446"
"  %20477 = add i32 %20476, %20446"
"  %20477 = add i32 %20476, %20446" -> "  %20478 = add i32 %20477, %20447"
"  %20478 = add i32 %20477, %20447"
"  %20478 = add i32 %20477, %20447" -> "  %20479 = add i32 %20478, %20448"
"  %20479 = add i32 %20478, %20448"
"  %20479 = add i32 %20478, %20448" -> "  %20480 = add i32 %20479, %20452"
"  %20480 = add i32 %20479, %20452"
"  %20480 = add i32 %20479, %20452" -> "  %20481 = add i32 %20480, %20453"
"  %20481 = add i32 %20480, %20453"
"  %20481 = add i32 %20480, %20453" -> "  %20482 = add i32 %20481, %20466"
"  %20482 = add i32 %20481, %20466"
"  %20482 = add i32 %20481, %20466" -> "  %20483 = add i32 %20482, %20472"
"  %20483 = add i32 %20482, %20472"
"  %20483 = add i32 %20482, %20472" -> "  %20549 = and i32 %20483, 65535"
"  %20484 = mul nuw nsw i32 %20288, 17399"
"  %20484 = mul nuw nsw i32 %20288, 17399" -> "  %20535 = and i32 %20484, 65535""  %20484 = mul nuw nsw i32 %20288, 17399" -> "  %20485 = lshr i32 %20484, 16"
"  %20485 = lshr i32 %20484, 16"
"  %20485 = lshr i32 %20484, 16" -> "  %20488 = add nuw nsw i32 %20485, %20487"
"  %20486 = mul nuw i32 %20288, 34017"
"  %20486 = mul nuw i32 %20288, 34017" -> "  %20489 = and i32 %20486, -65536""  %20486 = mul nuw i32 %20288, 34017" -> "  %20487 = and i32 %20486, 65535"
"  %20487 = and i32 %20486, 65535"
"  %20487 = and i32 %20486, 65535" -> "  %20488 = add nuw nsw i32 %20485, %20487"
"  %20488 = add nuw nsw i32 %20485, %20487"
"  %20488 = add nuw nsw i32 %20485, %20487" -> "  %20490 = add i32 %20488, %20489"
"  %20489 = and i32 %20486, -65536"
"  %20489 = and i32 %20486, -65536" -> "  %20490 = add i32 %20488, %20489"
"  %20490 = add i32 %20488, %20489"
"  %20490 = add i32 %20488, %20489" -> "  %20499 = lshr i32 %20490, 16""  %20490 = add i32 %20488, %20489" -> "  %20497 = and i32 %20490, 65535"
"  %20491 = lshr i32 %20260, 15"
"  %20491 = lshr i32 %20260, 15" -> "  %20492 = and i32 %20491, 1"
"  %20492 = and i32 %20491, 1"
"  %20492 = and i32 %20491, 1" -> "  %20495 = or i32 %20494, %20492"
"  %20493 = shl nuw nsw i32 %20263, 1"
"  %20493 = shl nuw nsw i32 %20263, 1" -> "  %20494 = and i32 %20493, 65534"
"  %20494 = and i32 %20493, 65534"
"  %20494 = and i32 %20493, 65534" -> "  %20495 = or i32 %20494, %20492"
"  %20495 = or i32 %20494, %20492"
"  %20495 = or i32 %20494, %20492" -> "  %20510 = mul nuw nsw i32 %20495, 7935""  %20495 = or i32 %20494, %20492" -> "  %20500 = mul nuw i32 %20495, 34017""  %20495 = or i32 %20494, %20492" -> "  %20496 = mul nuw nsw i32 %20495, 17399"
"  %20496 = mul nuw nsw i32 %20495, 17399"
"  %20496 = mul nuw nsw i32 %20495, 17399" -> "  %20498 = add nuw nsw i32 %20497, %20496"
"  %20497 = and i32 %20490, 65535"
"  %20497 = and i32 %20490, 65535" -> "  %20498 = add nuw nsw i32 %20497, %20496"
"  %20498 = add nuw nsw i32 %20497, %20496"
"  %20498 = add nuw nsw i32 %20497, %20496" -> "  %20538 = and i32 %20498, 65535""  %20498 = add nuw nsw i32 %20497, %20496" -> "  %20502 = lshr i32 %20498, 16"
"  %20499 = lshr i32 %20490, 16"
"  %20499 = lshr i32 %20490, 16" -> "  %20501 = add nuw i32 %20499, %20500"
"  %20500 = mul nuw i32 %20495, 34017"
"  %20500 = mul nuw i32 %20495, 34017" -> "  %20501 = add nuw i32 %20499, %20500"
"  %20501 = add nuw i32 %20499, %20500"
"  %20501 = add nuw i32 %20499, %20500" -> "  %20505 = and i32 %20501, -65536""  %20501 = add nuw i32 %20499, %20500" -> "  %20503 = and i32 %20501, 65535"
"  %20502 = lshr i32 %20498, 16"
"  %20502 = lshr i32 %20498, 16" -> "  %20504 = add nuw nsw i32 %20502, %20503"
"  %20503 = and i32 %20501, 65535"
"  %20503 = and i32 %20501, 65535" -> "  %20504 = add nuw nsw i32 %20502, %20503"
"  %20504 = add nuw nsw i32 %20502, %20503"
"  %20504 = add nuw nsw i32 %20502, %20503" -> "  %20506 = add nuw i32 %20504, %20505"
"  %20505 = and i32 %20501, -65536"
"  %20505 = and i32 %20501, -65536" -> "  %20506 = add nuw i32 %20504, %20505"
"  %20506 = add nuw i32 %20504, %20505"
"  %20506 = add nuw i32 %20504, %20505" -> "  %20520 = lshr i32 %20506, 16""  %20506 = add nuw i32 %20504, %20505" -> "  %20511 = and i32 %20506, 65535"
"  %20507 = mul nuw nsw i32 %20288, 7935"
"  %20507 = mul nuw nsw i32 %20288, 7935" -> "  %20512 = and i32 %20507, 65535""  %20507 = mul nuw nsw i32 %20288, 7935" -> "  %20508 = lshr i32 %20507, 16"
"  %20508 = lshr i32 %20507, 16"
"  %20508 = lshr i32 %20507, 16" -> "  %20526 = add i32 %20508, %20509"
"  %20509 = mul nuw i32 %20288, 63663"
"  %20509 = mul nuw i32 %20288, 63663" -> "  %20526 = add i32 %20508, %20509"
"  %20510 = mul nuw nsw i32 %20495, 7935"
"  %20510 = mul nuw nsw i32 %20495, 7935" -> "  %20527 = add i32 %20526, %20510"
"  %20511 = and i32 %20506, 65535"
"  %20511 = and i32 %20506, 65535" -> "  %20513 = add nuw nsw i32 %20511, %20512"
"  %20512 = and i32 %20507, 65535"
"  %20512 = and i32 %20507, 65535" -> "  %20513 = add nuw nsw i32 %20511, %20512"
"  %20513 = add nuw nsw i32 %20511, %20512"
"  %20513 = add nuw nsw i32 %20511, %20512" -> "  %20522 = and i32 %20513, 65535""  %20513 = add nuw nsw i32 %20511, %20512" -> "  %20521 = lshr i32 %20513, 16"
"  %20514 = lshr i32 %20266, 15"
"  %20514 = lshr i32 %20266, 15" -> "  %20515 = and i32 %20514, 65535"
"  %20515 = and i32 %20514, 65535"
"  %20515 = and i32 %20514, 65535" -> "  %20516 = mul nuw nsw i32 %20515, 17399"
"  %20516 = mul nuw nsw i32 %20515, 17399"
"  %20516 = mul nuw nsw i32 %20515, 17399" -> "  %20528 = add i32 %20527, %20516"
"  %20517 = mul nuw i32 %20284, 34017"
"  %20517 = mul nuw i32 %20284, 34017" -> "  %20529 = add i32 %20528, %20517"
"  %20518 = mul nuw nsw i32 %20284, 17399"
"  %20518 = mul nuw nsw i32 %20284, 17399" -> "  %20523 = and i32 %20518, 65535""  %20518 = mul nuw nsw i32 %20284, 17399" -> "  %20519 = lshr i32 %20518, 16"
"  %20519 = lshr i32 %20518, 16"
"  %20519 = lshr i32 %20518, 16" -> "  %20530 = add i32 %20529, %20519"
"  %20520 = lshr i32 %20506, 16"
"  %20520 = lshr i32 %20506, 16" -> "  %20531 = add i32 %20530, %20520"
"  %20521 = lshr i32 %20513, 16"
"  %20521 = lshr i32 %20513, 16" -> "  %20532 = add i32 %20531, %20521"
"  %20522 = and i32 %20513, 65535"
"  %20522 = and i32 %20513, 65535" -> "  %20524 = add nuw nsw i32 %20522, %20523"
"  %20523 = and i32 %20518, 65535"
"  %20523 = and i32 %20518, 65535" -> "  %20524 = add nuw nsw i32 %20522, %20523"
"  %20524 = add nuw nsw i32 %20522, %20523"
"  %20524 = add nuw nsw i32 %20522, %20523" -> "  %20546 = and i32 %20524, 65535""  %20524 = add nuw nsw i32 %20522, %20523" -> "  %20525 = lshr i32 %20524, 16"
"  %20525 = lshr i32 %20524, 16"
"  %20525 = lshr i32 %20524, 16" -> "  %20533 = add i32 %20532, %20525"
"  %20526 = add i32 %20508, %20509"
"  %20526 = add i32 %20508, %20509" -> "  %20527 = add i32 %20526, %20510"
"  %20527 = add i32 %20526, %20510"
"  %20527 = add i32 %20526, %20510" -> "  %20528 = add i32 %20527, %20516"
"  %20528 = add i32 %20527, %20516"
"  %20528 = add i32 %20527, %20516" -> "  %20529 = add i32 %20528, %20517"
"  %20529 = add i32 %20528, %20517"
"  %20529 = add i32 %20528, %20517" -> "  %20530 = add i32 %20529, %20519"
"  %20530 = add i32 %20529, %20519"
"  %20530 = add i32 %20529, %20519" -> "  %20531 = add i32 %20530, %20520"
"  %20531 = add i32 %20530, %20520"
"  %20531 = add i32 %20530, %20520" -> "  %20532 = add i32 %20531, %20521"
"  %20532 = add i32 %20531, %20521"
"  %20532 = add i32 %20531, %20521" -> "  %20533 = add i32 %20532, %20525"
"  %20533 = add i32 %20532, %20525"
"  %20533 = add i32 %20532, %20525" -> "  %20550 = and i32 %20533, 65535"
"  %20534 = and i32 %20456, 65535"
"  %20534 = and i32 %20456, 65535" -> "  %20536 = add nuw nsw i32 %20534, %20535"
"  %20535 = and i32 %20484, 65535"
"  %20535 = and i32 %20484, 65535" -> "  %20536 = add nuw nsw i32 %20534, %20535"
"  %20536 = add nuw nsw i32 %20534, %20535"
"  %20536 = add nuw nsw i32 %20534, %20535" -> "  %20575 = and i32 %20536, 65535""  %20536 = add nuw nsw i32 %20534, %20535" -> "  %20540 = lshr i32 %20536, 16"
"  %20537 = and i32 %20462, 65535"
"  %20537 = and i32 %20462, 65535" -> "  %20539 = add nuw nsw i32 %20537, %20538"
"  %20538 = and i32 %20498, 65535"
"  %20538 = and i32 %20498, 65535" -> "  %20539 = add nuw nsw i32 %20537, %20538"
"  %20539 = add nuw nsw i32 %20537, %20538"
"  %20539 = add nuw nsw i32 %20537, %20538" -> "  %20543 = lshr i32 %20539, 16""  %20539 = add nuw nsw i32 %20537, %20538" -> "  %20541 = and i32 %20539, 65535"
"  %20540 = lshr i32 %20536, 16"
"  %20540 = lshr i32 %20536, 16" -> "  %20542 = add nuw nsw i32 %20541, %20540"
"  %20541 = and i32 %20539, 65535"
"  %20541 = and i32 %20539, 65535" -> "  %20542 = add nuw nsw i32 %20541, %20540"
"  %20542 = add nuw nsw i32 %20541, %20540"
"  %20542 = add nuw nsw i32 %20541, %20540" -> "  %20579 = and i32 %20542, 65535""  %20542 = add nuw nsw i32 %20541, %20540" -> "  %20544 = lshr i32 %20542, 16"
"  %20543 = lshr i32 %20539, 16"
"  %20543 = lshr i32 %20539, 16" -> "  %20545 = add nuw nsw i32 %20544, %20543"
"  %20544 = lshr i32 %20542, 16"
"  %20544 = lshr i32 %20542, 16" -> "  %20545 = add nuw nsw i32 %20544, %20543"
"  %20545 = add nuw nsw i32 %20544, %20543"
"  %20545 = add nuw nsw i32 %20544, %20543" -> "  %20555 = add nuw nsw i32 %20545, %20554"
"  %20546 = and i32 %20524, 65535"
"  %20546 = and i32 %20524, 65535" -> "  %20548 = add nuw nsw i32 %20547, %20546"
"  %20547 = and i32 %20471, 65535"
"  %20547 = and i32 %20471, 65535" -> "  %20548 = add nuw nsw i32 %20547, %20546"
"  %20548 = add nuw nsw i32 %20547, %20546"
"  %20548 = add nuw nsw i32 %20547, %20546" -> "  %20554 = and i32 %20548, 65535""  %20548 = add nuw nsw i32 %20547, %20546" -> "  %20552 = lshr i32 %20548, 16"
"  %20549 = and i32 %20483, 65535"
"  %20549 = and i32 %20483, 65535" -> "  %20551 = add nuw nsw i32 %20549, %20550"
"  %20550 = and i32 %20533, 65535"
"  %20550 = and i32 %20533, 65535" -> "  %20551 = add nuw nsw i32 %20549, %20550"
"  %20551 = add nuw nsw i32 %20549, %20550"
"  %20551 = add nuw nsw i32 %20549, %20550" -> "  %20553 = add nuw nsw i32 %20551, %20552"
"  %20552 = lshr i32 %20548, 16"
"  %20552 = lshr i32 %20548, 16" -> "  %20553 = add nuw nsw i32 %20551, %20552"
"  %20553 = add nuw nsw i32 %20551, %20552"
"  %20553 = add nuw nsw i32 %20551, %20552" -> "  %20557 = add nuw nsw i32 %20553, %20556"
"  %20554 = and i32 %20548, 65535"
"  %20554 = and i32 %20548, 65535" -> "  %20555 = add nuw nsw i32 %20545, %20554"
"  %20555 = add nuw nsw i32 %20545, %20554"
"  %20555 = add nuw nsw i32 %20545, %20554" -> "  %20583 = and i32 %20555, 65535""  %20555 = add nuw nsw i32 %20545, %20554" -> "  %20556 = lshr i32 %20555, 16"
"  %20556 = lshr i32 %20555, 16"
"  %20556 = lshr i32 %20555, 16" -> "  %20557 = add nuw nsw i32 %20553, %20556"
"  %20557 = add nuw nsw i32 %20553, %20556"
"  %20557 = add nuw nsw i32 %20553, %20556" -> "  %20645 = xor i32 %20557, 65535"
"  %20558 = and i32 %20294, 65535"
"  %20558 = and i32 %20294, 65535" -> "  %20559 = sub nuw nsw i32 65536, %20558"
"  %20559 = sub nuw nsw i32 65536, %20558"
"  %20559 = sub nuw nsw i32 65536, %20558" -> "  %20587 = and i32 %20559, 65535""  %20559 = sub nuw nsw i32 65536, %20558" -> "  %20562 = lshr i32 %20559, 16"
"  %20560 = and i32 %20303, 65535"
"  %20560 = and i32 %20303, 65535" -> "  %20561 = xor i32 %20560, 65535"
"  %20561 = xor i32 %20560, 65535"
"  %20561 = xor i32 %20560, 65535" -> "  %20563 = add nuw nsw i32 %20561, %20562"
"  %20562 = lshr i32 %20559, 16"
"  %20562 = lshr i32 %20559, 16" -> "  %20563 = add nuw nsw i32 %20561, %20562"
"  %20563 = add nuw nsw i32 %20561, %20562"
"  %20563 = add nuw nsw i32 %20561, %20562" -> "  %20589 = and i32 %20563, 65535""  %20563 = add nuw nsw i32 %20561, %20562" -> "  %20566 = lshr i32 %20563, 16"
"  %20564 = and i32 %20363, 65535"
"  %20564 = and i32 %20363, 65535" -> "  %20565 = xor i32 %20564, 65535"
"  %20565 = xor i32 %20564, 65535"
"  %20565 = xor i32 %20564, 65535" -> "  %20567 = add nuw nsw i32 %20565, %20566"
"  %20566 = lshr i32 %20563, 16"
"  %20566 = lshr i32 %20563, 16" -> "  %20567 = add nuw nsw i32 %20565, %20566"
"  %20567 = add nuw nsw i32 %20565, %20566"
"  %20567 = add nuw nsw i32 %20565, %20566" -> "  %20605 = and i32 %20567, 65535""  %20567 = add nuw nsw i32 %20565, %20566" -> "  %20571 = lshr i32 %20567, 16""  %20567 = add nuw nsw i32 %20565, %20566" -> "  %20568 = zext i32 %20567 to i64"
"  %20568 = zext i32 %20567 to i64"
"  %20568 = zext i32 %20567 to i64" -> "  store i64 %20568, i64* %2, align 8, !tbaa !77, !alias.scope !79, !noalias !82"
"  store i64 %20568, i64* %2, align 8, !tbaa !77, !alias.scope !79, !noalias !82"

"  %20569 = and i32 %20371, 65535"
"  %20569 = and i32 %20371, 65535" -> "  %20570 = xor i32 %20569, 65535"
"  %20570 = xor i32 %20569, 65535"
"  %20570 = xor i32 %20569, 65535" -> "  %20572 = add nuw nsw i32 %20570, %20571"
"  %20571 = lshr i32 %20567, 16"
"  %20571 = lshr i32 %20567, 16" -> "  %20572 = add nuw nsw i32 %20570, %20571"
"  %20572 = add nuw nsw i32 %20570, %20571"
"  %20572 = add nuw nsw i32 %20570, %20571" -> "  %20609 = and i32 %20572, 65535""  %20572 = add nuw nsw i32 %20570, %20571" -> "  %20574 = lshr i32 %20572, 16""  %20572 = add nuw nsw i32 %20570, %20571" -> "  %20573 = zext i32 %20572 to i64"
"  %20573 = zext i32 %20572 to i64"
"  %20573 = zext i32 %20572 to i64" -> "  store i64 %20573, i64* %14, align 8, !tbaa !77, !alias.scope !79, !noalias !82"
"  store i64 %20573, i64* %14, align 8, !tbaa !77, !alias.scope !79, !noalias !82"

"  %20574 = lshr i32 %20572, 16"
"  %20574 = lshr i32 %20572, 16" -> "  %20577 = add nuw nsw i32 %20576, %20574"
"  %20575 = and i32 %20536, 65535"
"  %20575 = and i32 %20536, 65535" -> "  %20576 = xor i32 %20575, 65535"
"  %20576 = xor i32 %20575, 65535"
"  %20576 = xor i32 %20575, 65535" -> "  %20577 = add nuw nsw i32 %20576, %20574"
"  %20577 = add nuw nsw i32 %20576, %20574"
"  %20577 = add nuw nsw i32 %20576, %20574" -> "  %20631 = and i32 %20577, 65535""  %20577 = add nuw nsw i32 %20576, %20574" -> "  %20581 = lshr i32 %20577, 16""  %20577 = add nuw nsw i32 %20576, %20574" -> "  %20578 = zext i32 %20577 to i64"
"  %20578 = zext i32 %20577 to i64"
"  %20578 = zext i32 %20577 to i64" -> "  store i64 %20578, i64* %6, align 8, !tbaa !77, !alias.scope !79, !noalias !82"
"  store i64 %20578, i64* %6, align 8, !tbaa !77, !alias.scope !79, !noalias !82"

"  %20579 = and i32 %20542, 65535"
"  %20579 = and i32 %20542, 65535" -> "  %20580 = xor i32 %20579, 65535"
"  %20580 = xor i32 %20579, 65535"
"  %20580 = xor i32 %20579, 65535" -> "  %20582 = add nuw nsw i32 %20580, %20581"
"  %20581 = lshr i32 %20577, 16"
"  %20581 = lshr i32 %20577, 16" -> "  %20582 = add nuw nsw i32 %20580, %20581"
"  %20582 = add nuw nsw i32 %20580, %20581"
"  %20582 = add nuw nsw i32 %20580, %20581" -> "  %20635 = and i32 %20582, 65535""  %20582 = add nuw nsw i32 %20580, %20581" -> "  %20585 = lshr i32 %20582, 16"
"  %20583 = and i32 %20555, 65535"
"  %20583 = and i32 %20555, 65535" -> "  %20584 = xor i32 %20583, 65535"
"  %20584 = xor i32 %20583, 65535"
"  %20584 = xor i32 %20583, 65535" -> "  %20586 = add nuw nsw i32 %20584, %20585"
"  %20585 = lshr i32 %20582, 16"
"  %20585 = lshr i32 %20582, 16" -> "  %20586 = add nuw nsw i32 %20584, %20585"
"  %20586 = add nuw nsw i32 %20584, %20585"
"  %20586 = add nuw nsw i32 %20584, %20585" -> "  %20671 = add i32 %20670, %20586""  %20586 = add nuw nsw i32 %20584, %20585" -> "  %20642 = and i32 %20586, 65535"
"  %20587 = and i32 %20559, 65535"
"  %20587 = and i32 %20559, 65535" -> "  %20588 = add nuw nsw i32 %20587, %17241"
"  %20588 = add nuw nsw i32 %20587, %17241"
"  %20588 = add nuw nsw i32 %20587, %17241" -> "  %20594 = lshr i32 %20588, 16""  %20588 = add nuw nsw i32 %20587, %17241" -> "  %20591 = trunc i32 %20588 to i16"
"  %20589 = and i32 %20563, 65535"
"  %20589 = and i32 %20563, 65535" -> "  %20590 = add nuw nsw i32 %20589, %17244"
"  %20590 = add nuw nsw i32 %20589, %17244"
"  %20590 = add nuw nsw i32 %20589, %17244" -> "  %20596 = and i32 %20590, 65535""  %20590 = add nuw nsw i32 %20589, %17244" -> "  %20598 = lshr i32 %20590, 16"
"  store i64 %58, i64* %15, align 8, !tbaa !77, !alias.scope !79, !noalias !82"

"  %20591 = trunc i32 %20588 to i16"
"  %20591 = trunc i32 %20588 to i16" -> "  store i16 %20591, i16* %20593, align 1, !noalias !82"
"  %20592 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %58"
"  %20592 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %58" -> "  %20593 = bitcast i8* %20592 to i16*"
"  %20593 = bitcast i8* %20592 to i16*"
"  %20593 = bitcast i8* %20592 to i16*" -> "  store i16 %20591, i16* %20593, align 1, !noalias !82"
"  store i16 %20591, i16* %20593, align 1, !noalias !82"

"  %20594 = lshr i32 %20588, 16"
"  %20594 = lshr i32 %20588, 16" -> "  %20597 = add nuw nsw i32 %20596, %20594""  %20594 = lshr i32 %20588, 16" -> "  %20595 = zext i32 %20594 to i64"
"  %20595 = zext i32 %20594 to i64"
"  %20595 = zext i32 %20594 to i64" -> "  store i64 %20595, i64* %4, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20595, i64* %4, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  %20596 = and i32 %20590, 65535"
"  %20596 = and i32 %20590, 65535" -> "  %20597 = add nuw nsw i32 %20596, %20594"
"  %20597 = add nuw nsw i32 %20596, %20594"
"  %20597 = add nuw nsw i32 %20596, %20594" -> "  %20603 = lshr i32 %20597, 16""  %20597 = add nuw nsw i32 %20596, %20594" -> "  %20600 = trunc i32 %20597 to i16"
"  %20598 = lshr i32 %20590, 16"
"  %20598 = lshr i32 %20590, 16" -> "  %20604 = add nuw nsw i32 %20603, %20598"
"  %20599 = add i64 %58, 2"
"  %20599 = add i64 %58, 2" -> "  %20601 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20599"
"  %20600 = trunc i32 %20597 to i16"
"  %20600 = trunc i32 %20597 to i16" -> "  store i16 %20600, i16* %20602, align 1, !noalias !87"
"  %20601 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20599"
"  %20601 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20599" -> "  %20602 = bitcast i8* %20601 to i16*"
"  %20602 = bitcast i8* %20601 to i16*"
"  %20602 = bitcast i8* %20601 to i16*" -> "  store i16 %20600, i16* %20602, align 1, !noalias !87"
"  store i16 %20600, i16* %20602, align 1, !noalias !87"

"  %20603 = lshr i32 %20597, 16"
"  %20603 = lshr i32 %20597, 16" -> "  %20604 = add nuw nsw i32 %20603, %20598"
"  %20604 = add nuw nsw i32 %20603, %20598"
"  %20604 = add nuw nsw i32 %20603, %20598" -> "  %20618 = add nuw nsw i32 %20604, %20617"
"  %20605 = and i32 %20567, 65535"
"  %20605 = and i32 %20567, 65535" -> "  %20607 = add i32 %20605, %20606"
"  %20606 = load i32, i32* %73, align 1, !noalias !87"
"  %20606 = load i32, i32* %73, align 1, !noalias !87" -> "  %20607 = add i32 %20605, %20606"
"  %20607 = add i32 %20605, %20606"
"  %20607 = add i32 %20605, %20606" -> "  %20617 = and i32 %20607, 65535""  %20607 = add i32 %20605, %20606" -> "  %20608 = lshr i32 %20607, 16"
"  %20608 = lshr i32 %20607, 16"
"  %20608 = lshr i32 %20607, 16" -> "  %20614 = add nuw nsw i32 %20612, %20608"
"  %20609 = and i32 %20572, 65535"
"  %20609 = and i32 %20572, 65535" -> "  %20611 = add i32 %20609, %20610"
"  %20610 = load i32, i32* %86, align 1, !noalias !87"
"  %20610 = load i32, i32* %86, align 1, !noalias !87" -> "  %20611 = add i32 %20609, %20610"
"  %20611 = add i32 %20609, %20610"
"  %20611 = add i32 %20609, %20610" -> "  %20613 = lshr i32 %20611, 16""  %20611 = add i32 %20609, %20610" -> "  %20612 = and i32 %20611, 65535"
"  %20612 = and i32 %20611, 65535"
"  %20612 = and i32 %20611, 65535" -> "  %20614 = add nuw nsw i32 %20612, %20608"
"  %20613 = lshr i32 %20611, 16"
"  %20613 = lshr i32 %20611, 16" -> "  %20616 = add nuw nsw i32 %20615, %20613"
"  %20614 = add nuw nsw i32 %20612, %20608"
"  %20614 = add nuw nsw i32 %20612, %20608" -> "  %20619 = and i32 %20614, 65535""  %20614 = add nuw nsw i32 %20612, %20608" -> "  %20615 = lshr i32 %20614, 16"
"  %20615 = lshr i32 %20614, 16"
"  %20615 = lshr i32 %20614, 16" -> "  %20616 = add nuw nsw i32 %20615, %20613"
"  %20616 = add nuw nsw i32 %20615, %20613"
"  %20616 = add nuw nsw i32 %20615, %20613" -> "  %20652 = add nuw nsw i32 %20616, %20630"
"  %20617 = and i32 %20607, 65535"
"  %20617 = and i32 %20607, 65535" -> "  %20618 = add nuw nsw i32 %20604, %20617"
"  %20618 = add nuw nsw i32 %20604, %20617"
"  %20618 = add nuw nsw i32 %20604, %20617" -> "  %20624 = lshr i32 %20618, 16""  %20618 = add nuw nsw i32 %20604, %20617" -> "  %20621 = trunc i32 %20618 to i16"
"  %20619 = and i32 %20614, 65535"
"  %20619 = and i32 %20614, 65535" -> "  %20625 = add nuw nsw i32 %20619, %20624"
"  %20620 = add i64 %58, 4"
"  %20620 = add i64 %58, 4" -> "  %20622 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20620"
"  %20621 = trunc i32 %20618 to i16"
"  %20621 = trunc i32 %20618 to i16" -> "  store i16 %20621, i16* %20623, align 1, !noalias !87"
"  %20622 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20620"
"  %20622 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20620" -> "  %20623 = bitcast i8* %20622 to i16*"
"  %20623 = bitcast i8* %20622 to i16*"
"  %20623 = bitcast i8* %20622 to i16*" -> "  store i16 %20621, i16* %20623, align 1, !noalias !87"
"  store i16 %20621, i16* %20623, align 1, !noalias !87"

"  %20624 = lshr i32 %20618, 16"
"  %20624 = lshr i32 %20618, 16" -> "  %20625 = add nuw nsw i32 %20619, %20624"
"  %20625 = add nuw nsw i32 %20619, %20624"
"  %20625 = add nuw nsw i32 %20619, %20624" -> "  %20630 = lshr i32 %20625, 16""  %20625 = add nuw nsw i32 %20619, %20624" -> "  %20627 = trunc i32 %20625 to i16"
"  %20626 = add i64 %58, 6"
"  %20626 = add i64 %58, 6" -> "  %20628 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20626"
"  %20627 = trunc i32 %20625 to i16"
"  %20627 = trunc i32 %20625 to i16" -> "  store i16 %20627, i16* %20629, align 1, !noalias !87"
"  %20628 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20626"
"  %20628 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20626" -> "  %20629 = bitcast i8* %20628 to i16*"
"  %20629 = bitcast i8* %20628 to i16*"
"  %20629 = bitcast i8* %20628 to i16*" -> "  store i16 %20627, i16* %20629, align 1, !noalias !87"
"  store i16 %20627, i16* %20629, align 1, !noalias !87"

"  %20630 = lshr i32 %20625, 16"
"  %20630 = lshr i32 %20625, 16" -> "  %20652 = add nuw nsw i32 %20616, %20630"
"  %20631 = and i32 %20577, 65535"
"  %20631 = and i32 %20577, 65535" -> "  %20633 = add i32 %20631, %20632"
"  %20632 = load i32, i32* %127, align 1, !noalias !87"
"  %20632 = load i32, i32* %127, align 1, !noalias !87" -> "  %20633 = add i32 %20631, %20632"
"  %20633 = add i32 %20631, %20632"
"  %20633 = add i32 %20631, %20632" -> "  %20651 = and i32 %20633, 65535""  %20633 = add i32 %20631, %20632" -> "  %20634 = lshr i32 %20633, 16"
"  %20634 = lshr i32 %20633, 16"
"  %20634 = lshr i32 %20633, 16" -> "  %20640 = add nuw nsw i32 %20638, %20634"
"  %20635 = and i32 %20582, 65535"
"  %20635 = and i32 %20582, 65535" -> "  %20637 = add i32 %20635, %20636"
"  %20636 = load i32, i32* %316, align 1, !noalias !87"
"  %20636 = load i32, i32* %316, align 1, !noalias !87" -> "  %20637 = add i32 %20635, %20636"
"  %20637 = add i32 %20635, %20636"
"  %20637 = add i32 %20635, %20636" -> "  %20639 = lshr i32 %20637, 16""  %20637 = add i32 %20635, %20636" -> "  %20638 = and i32 %20637, 65535"
"  %20638 = and i32 %20637, 65535"
"  %20638 = and i32 %20637, 65535" -> "  %20640 = add nuw nsw i32 %20638, %20634"
"  %20639 = lshr i32 %20637, 16"
"  %20639 = lshr i32 %20637, 16" -> "  %20649 = add nuw nsw i32 %20641, %20639"
"  %20640 = add nuw nsw i32 %20638, %20634"
"  %20640 = add nuw nsw i32 %20638, %20634" -> "  %20654 = and i32 %20640, 65535""  %20640 = add nuw nsw i32 %20638, %20634" -> "  %20641 = lshr i32 %20640, 16"
"  %20641 = lshr i32 %20640, 16"
"  %20641 = lshr i32 %20640, 16" -> "  %20649 = add nuw nsw i32 %20641, %20639"
"  %20642 = and i32 %20586, 65535"
"  %20642 = and i32 %20586, 65535" -> "  %20644 = add i32 %20642, %20643"
"  %20643 = load i32, i32* %167, align 1, !noalias !87"
"  %20643 = load i32, i32* %167, align 1, !noalias !87" -> "  %20644 = add i32 %20642, %20643"
"  %20644 = add i32 %20642, %20643"
"  %20644 = add i32 %20642, %20643" -> "  %20673 = add i32 %20672, %20644""  %20644 = add i32 %20642, %20643" -> "  %20648 = and i32 %20644, 65535"
"  %20645 = xor i32 %20557, 65535"
"  %20645 = xor i32 %20557, 65535" -> "  %20647 = add i32 %20645, %20646"
"  %20646 = load i32, i32* %540, align 1, !noalias !87"
"  %20646 = load i32, i32* %540, align 1, !noalias !87" -> "  %20647 = add i32 %20645, %20646"
"  %20647 = add i32 %20645, %20646"
"  %20647 = add i32 %20645, %20646" -> "  %20670 = shl i32 %20647, 16"
"  %20648 = and i32 %20644, 65535"
"  %20648 = and i32 %20644, 65535" -> "  %20650 = add nuw nsw i32 %20649, %20648"
"  %20649 = add nuw nsw i32 %20641, %20639"
"  %20649 = add nuw nsw i32 %20641, %20639" -> "  %20650 = add nuw nsw i32 %20649, %20648"
"  %20650 = add nuw nsw i32 %20649, %20648"
"  %20650 = add nuw nsw i32 %20649, %20648" -> "  %20675 = add i32 %20674, %20650""  %20650 = add nuw nsw i32 %20649, %20648" -> "  %20667 = and i32 %20650, 65535"
"  %20651 = and i32 %20633, 65535"
"  %20651 = and i32 %20633, 65535" -> "  %20653 = add nuw nsw i32 %20652, %20651"
"  %20652 = add nuw nsw i32 %20616, %20630"
"  %20652 = add nuw nsw i32 %20616, %20630" -> "  %20653 = add nuw nsw i32 %20652, %20651"
"  %20653 = add nuw nsw i32 %20652, %20651"
"  %20653 = add nuw nsw i32 %20652, %20651" -> "  %20659 = lshr i32 %20653, 16""  %20653 = add nuw nsw i32 %20652, %20651" -> "  %20656 = trunc i32 %20653 to i16"
"  %20654 = and i32 %20640, 65535"
"  %20654 = and i32 %20640, 65535" -> "  %20660 = add nuw nsw i32 %20654, %20659"
"  %20655 = add i64 %58, 8"
"  %20655 = add i64 %58, 8" -> "  %20657 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20655"
"  %20656 = trunc i32 %20653 to i16"
"  %20656 = trunc i32 %20653 to i16" -> "  store i16 %20656, i16* %20658, align 1, !noalias !87"
"  %20657 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20655"
"  %20657 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20655" -> "  %20658 = bitcast i8* %20657 to i16*"
"  %20658 = bitcast i8* %20657 to i16*"
"  %20658 = bitcast i8* %20657 to i16*" -> "  store i16 %20656, i16* %20658, align 1, !noalias !87"
"  store i16 %20656, i16* %20658, align 1, !noalias !87"

"  %20659 = lshr i32 %20653, 16"
"  %20659 = lshr i32 %20653, 16" -> "  %20660 = add nuw nsw i32 %20654, %20659"
"  %20660 = add nuw nsw i32 %20654, %20659"
"  %20660 = add nuw nsw i32 %20654, %20659" -> "  %20665 = lshr i32 %20660, 16""  %20660 = add nuw nsw i32 %20654, %20659" -> "  %20662 = trunc i32 %20660 to i16"
"  %20661 = add i64 %58, 10"
"  %20661 = add i64 %58, 10" -> "  %20663 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20661"
"  %20662 = trunc i32 %20660 to i16"
"  %20662 = trunc i32 %20660 to i16" -> "  store i16 %20662, i16* %20664, align 1, !noalias !87"
"  %20663 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20661"
"  %20663 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20661" -> "  %20664 = bitcast i8* %20663 to i16*"
"  %20664 = bitcast i8* %20663 to i16*"
"  %20664 = bitcast i8* %20663 to i16*" -> "  store i16 %20662, i16* %20664, align 1, !noalias !87"
"  store i16 %20662, i16* %20664, align 1, !noalias !87"

"  %20665 = lshr i32 %20660, 16"
"  %20665 = lshr i32 %20660, 16" -> "  %20668 = add nuw nsw i32 %20667, %20665""  %20665 = lshr i32 %20660, 16" -> "  %20666 = zext i32 %20665 to i64"
"  %20666 = zext i32 %20665 to i64"
"  %20666 = zext i32 %20665 to i64" -> "  store i64 %20666, i64* %9, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20666, i64* %9, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  %20667 = and i32 %20650, 65535"
"  %20667 = and i32 %20650, 65535" -> "  %20668 = add nuw nsw i32 %20667, %20665"
"  %20668 = add nuw nsw i32 %20667, %20665"
"  %20668 = add nuw nsw i32 %20667, %20665" -> "  %20677 = add i32 %20676, %20668""  %20668 = add nuw nsw i32 %20667, %20665" -> "  %20669 = zext i32 %20668 to i64"
"  %20669 = zext i32 %20668 to i64"
"  %20669 = zext i32 %20668 to i64" -> "  store i64 %20669, i64* %3, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20669, i64* %3, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  %20670 = shl i32 %20647, 16"
"  %20670 = shl i32 %20647, 16" -> "  %20671 = add i32 %20670, %20586"
"  %20671 = add i32 %20670, %20586"
"  %20671 = add i32 %20670, %20586" -> "  %20672 = and i32 %20671, -65536"
"  %20672 = and i32 %20671, -65536"
"  %20672 = and i32 %20671, -65536" -> "  %20673 = add i32 %20672, %20644"
"  %20673 = add i32 %20672, %20644"
"  %20673 = add i32 %20672, %20644" -> "  %20674 = and i32 %20673, -65536"
"  %20674 = and i32 %20673, -65536"
"  %20674 = and i32 %20673, -65536" -> "  %20675 = add i32 %20674, %20650"
"  %20675 = add i32 %20674, %20650"
"  %20675 = add i32 %20674, %20650" -> "  %20676 = and i32 %20675, -65536"
"  %20676 = and i32 %20675, -65536"
"  %20676 = and i32 %20675, -65536" -> "  %20677 = add i32 %20676, %20668"
"  %20677 = add i32 %20676, %20668"
"  %20677 = add i32 %20676, %20668" -> "  %20682 = lshr i32 %20677, 16""  %20677 = add i32 %20676, %20668" -> "  %20679 = trunc i32 %20677 to i16"
"  %20678 = add i64 %58, 12"
"  %20678 = add i64 %58, 12" -> "  %20680 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20678"
"  %20679 = trunc i32 %20677 to i16"
"  %20679 = trunc i32 %20677 to i16" -> "  store i16 %20679, i16* %20681, align 1, !noalias !87"
"  %20680 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20678"
"  %20680 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20678" -> "  %20681 = bitcast i8* %20680 to i16*"
"  %20681 = bitcast i8* %20680 to i16*"
"  %20681 = bitcast i8* %20680 to i16*" -> "  store i16 %20679, i16* %20681, align 1, !noalias !87"
"  store i16 %20679, i16* %20681, align 1, !noalias !87"

"  %20682 = lshr i32 %20677, 16"
"  %20682 = lshr i32 %20677, 16" -> "  %20684 = trunc i32 %20682 to i16"
"  %20683 = add i64 %58, 14"
"  %20683 = add i64 %58, 14" -> "  %20685 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20683"
"  %20684 = trunc i32 %20682 to i16"
"  %20684 = trunc i32 %20682 to i16" -> "  store i16 %20684, i16* %20686, align 1, !noalias !87"
"  %20685 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20683"
"  %20685 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %20683" -> "  %20686 = bitcast i8* %20685 to i16*"
"  %20686 = bitcast i8* %20685 to i16*"
"  %20686 = bitcast i8* %20685 to i16*" -> "  store i16 %20684, i16* %20686, align 1, !noalias !87"
"  store i16 %20684, i16* %20686, align 1, !noalias !87"

"  %20687 = icmp ugt i64 %50, -233"
"  %20687 = icmp ugt i64 %50, -233" -> "  %20688 = zext i1 %20687 to i8"
"  %20688 = zext i1 %20687 to i8"
"  %20688 = zext i1 %20687 to i8" -> "  store i8 %20688, i8* %51, align 1, !tbaa !89, !alias.scope !84, !noalias !87"
"  store i8 %20688, i8* %51, align 1, !tbaa !89, !alias.scope !84, !noalias !87"

"  %20689 = trunc i64 %47 to i32"
"  %20689 = trunc i64 %47 to i32" -> "  %20690 = and i32 %20689, 255"
"  %20690 = and i32 %20689, 255"
"  %20690 = and i32 %20689, 255" -> "  %20691 = tail call i32 @llvm.ctpop.i32(i32 %20690) #2, !range !104"
"  %20691 = tail call i32 @llvm.ctpop.i32(i32 %20690) #2, !range !104"
"  %20691 = tail call i32 @llvm.ctpop.i32(i32 %20690) #2, !range !104" -> "  %20692 = trunc i32 %20691 to i8"
"  %20692 = trunc i32 %20691 to i8"
"  %20692 = trunc i32 %20691 to i8" -> "  %20693 = and i8 %20692, 1"
"  %20693 = and i8 %20692, 1"
"  %20693 = and i8 %20692, 1" -> "  %20694 = xor i8 %20693, 1"
"  %20694 = xor i8 %20693, 1"
"  %20694 = xor i8 %20693, 1" -> "  store i8 %20694, i8* %52, align 1, !tbaa !105, !alias.scope !84, !noalias !87"
"  store i8 %20694, i8* %52, align 1, !tbaa !105, !alias.scope !84, !noalias !87"

"  %20695 = xor i64 %47, %50"
"  %20695 = xor i64 %47, %50" -> "  %20696 = lshr i64 %20695, 4"
"  %20696 = lshr i64 %20695, 4"
"  %20696 = lshr i64 %20695, 4" -> "  %20697 = trunc i64 %20696 to i8"
"  %20697 = trunc i64 %20696 to i8"
"  %20697 = trunc i64 %20696 to i8" -> "  %20698 = and i8 %20697, 1"
"  %20698 = and i8 %20697, 1"
"  %20698 = and i8 %20697, 1" -> "  store i8 %20698, i8* %53, align 1, !tbaa !106, !alias.scope !84, !noalias !87"
"  store i8 %20698, i8* %53, align 1, !tbaa !106, !alias.scope !84, !noalias !87"

"  %20699 = icmp eq i64 %47, 0"
"  %20699 = icmp eq i64 %47, 0" -> "  %20700 = zext i1 %20699 to i8"
"  %20700 = zext i1 %20699 to i8"
"  %20700 = zext i1 %20699 to i8" -> "  store i8 %20700, i8* %54, align 1, !tbaa !107, !alias.scope !84, !noalias !87"
"  store i8 %20700, i8* %54, align 1, !tbaa !107, !alias.scope !84, !noalias !87"

"  %20701 = lshr i64 %47, 63"
"  %20701 = lshr i64 %47, 63" -> "  %20705 = add nuw nsw i64 %20704, %20701""  %20701 = lshr i64 %47, 63" -> "  %20704 = xor i64 %20701, %20703""  %20701 = lshr i64 %47, 63" -> "  %20702 = trunc i64 %20701 to i8"
"  %20702 = trunc i64 %20701 to i8"
"  %20702 = trunc i64 %20701 to i8" -> "  store i8 %20702, i8* %55, align 1, !tbaa !108, !alias.scope !84, !noalias !87"
"  store i8 %20702, i8* %55, align 1, !tbaa !108, !alias.scope !84, !noalias !87"

"  %20703 = lshr i64 %50, 63"
"  %20703 = lshr i64 %50, 63" -> "  %20704 = xor i64 %20701, %20703"
"  %20704 = xor i64 %20701, %20703"
"  %20704 = xor i64 %20701, %20703" -> "  %20705 = add nuw nsw i64 %20704, %20701"
"  %20705 = add nuw nsw i64 %20704, %20701"
"  %20705 = add nuw nsw i64 %20704, %20701" -> "  %20706 = icmp eq i64 %20705, 2"
"  %20706 = icmp eq i64 %20705, 2"
"  %20706 = icmp eq i64 %20705, 2" -> "  %20707 = zext i1 %20706 to i8"
"  %20707 = zext i1 %20706 to i8"
"  %20707 = zext i1 %20706 to i8" -> "  store i8 %20707, i8* %56, align 1, !tbaa !109, !alias.scope !84, !noalias !87"
"  store i8 %20707, i8* %56, align 1, !tbaa !109, !alias.scope !84, !noalias !87"

"  %20708 = load i64, i64* %49, align 1, !noalias !87"
"  %20708 = load i64, i64* %49, align 1, !noalias !87" -> "  store i64 %20708, i64* %12, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20708, i64* %12, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  %20709 = load i64, i64* %45, align 1, !noalias !87"
"  %20709 = load i64, i64* %45, align 1, !noalias !87" -> "  store i64 %20709, i64* %13, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20709, i64* %13, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  %20710 = load i64, i64* %41, align 1, !noalias !87"
"  %20710 = load i64, i64* %41, align 1, !noalias !87" -> "  store i64 %20710, i64* %11, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20710, i64* %11, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  %20711 = load i64, i64* %37, align 1, !noalias !87"
"  %20711 = load i64, i64* %37, align 1, !noalias !87" -> "  store i64 %20711, i64* %7, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20711, i64* %7, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  %20712 = load i64, i64* %33, align 1, !noalias !87"
"  %20712 = load i64, i64* %33, align 1, !noalias !87" -> "  store i64 %20712, i64* %5, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20712, i64* %5, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  %20713 = load i64, i64* %29, align 1, !noalias !87"
"  %20713 = load i64, i64* %29, align 1, !noalias !87" -> "  store i64 %20713, i64* %1, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20713, i64* %1, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  %20714 = load i64, i64* %25, align 1, !noalias !87"
"  %20714 = load i64, i64* %25, align 1, !noalias !87" -> "  store i64 %20714, i64* %8, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20714, i64* %8, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  %20715 = load i64, i64* %21, align 1, !noalias !87"
"  %20715 = load i64, i64* %21, align 1, !noalias !87" -> "  store i64 %20715, i64* %10, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20715, i64* %10, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  %20716 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %18"
"  %20716 = getelementptr inbounds [0 x i8], [0 x i8]* @RAM, i64 0, i64 %18" -> "  %20717 = bitcast i8* %20716 to i64*"
"  %20717 = bitcast i8* %20716 to i64*"
"  %20717 = bitcast i8* %20716 to i64*" -> "  %20718 = load i64, i64* %20717, align 1, !noalias !87"
"  %20718 = load i64, i64* %20717, align 1, !noalias !87"
"  %20718 = load i64, i64* %20717, align 1, !noalias !87" -> "  store i64 %20718, i64* %0, align 8, !alias.scope !84, !noalias !87"
"  %20719 = add i64 %18, 8"
"  %20719 = add i64 %18, 8" -> "  store i64 %20719, i64* %16, align 8, !tbaa !77, !alias.scope !84, !noalias !87"
"  store i64 %20719, i64* %16, align 8, !tbaa !77, !alias.scope !84, !noalias !87"

"  store i64 %20718, i64* %0, align 8, !alias.scope !84, !noalias !87"

"  ret %struct.Memory.0* %memory"

}
